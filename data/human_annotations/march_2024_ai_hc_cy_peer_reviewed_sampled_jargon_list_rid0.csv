arxiv_id,url,title,summary,jargon terms,comments,updated,published,authors,categories,primary_category,doi,journal_ref,peer_reviewed
2403.16190v1,http://arxiv.org/abs/2403.16190v1,"Logic-based Explanations for Linear Support Vector Classifiers with
  Reject Option","Support Vector Classifier (SVC) is a well-known Machine Learning (ML) model
for linear classification problems. It can be used in conjunction with a reject
option strategy to reject instances that are hard to correctly classify and
delegate them to a specialist. This further increases the confidence of the
model. Given this, obtaining an explanation of the cause of rejection is
important to not blindly trust the obtained results. While most of the related
work has developed means to give such explanations for machine learning models,
to the best of our knowledge none have done so for when reject option is
present. We propose a logic-based approach with formal guarantees on the
correctness and minimality of explanations for linear SVCs with reject option.
We evaluate our approach by comparing it to Anchors, which is a heuristic
algorithm for generating explanations. Obtained results show that our proposed
method gives shorter explanations with reduced time cost.","correctness,minimality,Anchors","16 pages, submitted to BRACIS 2023 (Brazilian Conference on
  Intelligent Systems), accepted version published in Intelligent Systems,
  LNCS, vol 14195",2024-03-24 15:14:44+00:00,2024-03-24 15:14:44+00:00,"['Francisco Mateus Rocha Filho', 'Thiago Alves Rocha', 'Reginaldo Pereira Fernandes Ribeiro', 'Ajalmar RÃªgo da Rocha Neto']","['cs.AI', 'cs.LG', 'cs.LO', 'I.2.4; I.2.6']",cs.AI,10.1007/978-3-031-45368-7_10,,TRUE
2307.05300v4,http://arxiv.org/abs/2307.05300v4,"Unleashing the Emergent Cognitive Synergy in Large Language Models: A
  Task-Solving Agent through Multi-Persona Self-Collaboration","Human intelligence thrives on cognitive synergy, where collaboration among
different minds yield superior outcomes compared to isolated individuals. In
this work, we propose Solo Performance Prompting (SPP), which transforms a
single LLM into a cognitive synergist by engaging in multi-turn
self-collaboration with multiple personas. A cognitive synergist is an
intelligent agent that collaboratively combines multiple minds' strengths and
knowledge to enhance problem-solving in complex tasks. By dynamically
identifying and simulating different personas based on task inputs, SPP
unleashes the potential of cognitive synergy in LLMs. Our in-depth analysis
shows that assigning multiple fine-grained personas in LLMs improves
problem-solving abilities compared to using a single or fixed number of
personas. We evaluate SPP on three challenging tasks: Trivia Creative Writing,
Codenames Collaborative, and Logic Grid Puzzle, encompassing both
knowledge-intensive and reasoning-intensive types. Unlike previous works, such
as Chain-of-Thought, that solely enhance the reasoning abilities in LLMs,
experimental results demonstrate that SPP effectively reduces factual
hallucination, and maintains strong reasoning capabilities. Additionally,
comparative experiments show that cognitive synergy only emerges in GPT-4 and
does not appear in less capable models, such as GPT-3.5-turbo and
Llama2-13b-chat, which draws an interesting analogy to human development. Code,
data, and prompts can be found at:
https://github.com/MikeWangWZHL/Solo-Performance-Prompting.git.","multi-turn,persona",Accepted as a main conference paper at NAACL 2024,2024-03-26 14:32:33+00:00,2023-07-11 14:45:19+00:00,"['Zhenhailong Wang', 'Shaoguang Mao', 'Wenshan Wu', 'Tao Ge', 'Furu Wei', 'Heng Ji']","['cs.AI', 'cs.CL']",cs.AI,,,TRUE
2403.16750v1,http://arxiv.org/abs/2403.16750v1,"All Artificial, Less Intelligence: GenAI through the Lens of Formal
  Verification","Modern hardware designs have grown increasingly efficient and complex.
However, they are often susceptible to Common Weakness Enumerations (CWEs).
This paper is focused on the formal verification of CWEs in a dataset of
hardware designs written in SystemVerilog from Regenerative Artificial
Intelligence (AI) powered by Large Language Models (LLMs). We applied formal
verification to categorize each hardware design as vulnerable or CWE-free. This
dataset was generated by 4 different LLMs and features a unique set of designs
for each of the 10 CWEs we target in our paper. We have associated the
identified vulnerabilities with CWE numbers for a dataset of 60,000 generated
SystemVerilog Register Transfer Level (RTL) code. It was also found that most
LLMs are not aware of any hardware CWEs; hence they are usually not considered
when generating the hardware code. Our study reveals that approximately 60% of
the hardware designs generated by LLMs are prone to CWEs, posing potential
safety and security risks. The dataset could be ideal for training LLMs and
Machine Learning (ML) algorithms to abstain from generating CWE-prone hardware
designs.","common weakeness enumerations,SystemVerilog,Regenrative Artificial Intelligence,formal verification,Register Transfer Level (RTL) code,CWE-prone hardware designs",Published in DVCon U.S. 2024,2024-03-25 13:23:24+00:00,2024-03-25 13:23:24+00:00,"['Deepak Narayan Gadde', 'Aman Kumar', 'Thomas Nalapat', 'Evgenii Rezunov', 'Fabio Cappellini']",['cs.AI'],cs.AI,,,TRUE
2311.10112v2,http://arxiv.org/abs/2311.10112v2,"zrLLM: Zero-Shot Relational Learning on Temporal Knowledge Graphs with
  Large Language Models","Modeling evolving knowledge over temporal knowledge graphs (TKGs) has become
a heated topic. Various methods have been proposed to forecast links on TKGs.
Most of them are embedding-based, where hidden representations are learned to
represent knowledge graph (KG) entities and relations based on the observed
graph contexts. Although these methods show strong performance on traditional
TKG forecasting (TKGF) benchmarks, they face a strong challenge in modeling the
unseen zero-shot relations that have no prior graph context. In this paper, we
try to mitigate this problem as follows. We first input the text descriptions
of KG relations into large language models (LLMs) for generating relation
representations, and then introduce them into embedding-based TKGF methods.
LLM-empowered representations can capture the semantic information in the
relation descriptions. This makes the relations, whether seen or unseen, with
similar semantic meanings stay close in the embedding space, enabling TKGF
models to recognize zero-shot relations even without any observed graph
context. Experimental results show that our approach helps TKGF models to
achieve much better performance in forecasting the facts with previously unseen
relations, while still maintaining their ability in link forecasting regarding
seen relations.","temporal knowledge graphs,embedding-based TKGF methods,TKG forecasting",Accepted to NAACL 2024 main conference,2024-03-15 15:38:07+00:00,2023-11-15 21:25:15+00:00,"['Zifeng Ding', 'Heling Cai', 'Jingpei Wu', 'Yunpu Ma', 'Ruotong Liao', 'Bo Xiong', 'Volker Tresp']","['cs.AI', 'cs.CL', 'cs.LG']",cs.AI,,,TRUE
2310.08992v3,http://arxiv.org/abs/2310.08992v3,"CodeChain: Towards Modular Code Generation Through Chain of
  Self-revisions with Representative Sub-modules","Large Language Models (LLMs) have already become quite proficient at solving
simpler programming tasks like those in HumanEval or MBPP benchmarks. However,
solving more complex and competitive programming tasks is still quite
challenging for these models - possibly due to their tendency to generate
solutions as monolithic code blocks instead of decomposing them into logical
sub-tasks and sub-modules. On the other hand, experienced programmers
instinctively write modularized code with abstraction for solving complex
tasks, often reusing previously developed modules. To address this gap, we
propose CodeChain, a novel framework for inference that elicits modularized
code generation through a chain of self-revisions, each being guided by some
representative sub-modules generated in previous iterations. Concretely,
CodeChain first instructs the LLM to generate modularized codes through
chain-of-thought prompting. Then it applies a chain of self-revisions by
iterating the two steps: 1) extracting and clustering the generated sub-modules
and selecting the cluster representatives as the more generic and re-usable
implementations, and 2) augmenting the original chain-of-thought prompt with
these selected module-implementations and instructing the LLM to re-generate
new modularized solutions. We find that by naturally encouraging the LLM to
reuse the previously developed and verified sub-modules, CodeChain can
significantly boost both modularity as well as correctness of the generated
solutions, achieving relative pass@1 improvements of 35% on APPS and 76% on
CodeContests. It is shown to be effective on both OpenAI LLMs as well as
open-sourced LLMs like WizardCoder. We also conduct comprehensive ablation
studies with different methods of prompting, number of clusters, model sizes,
program qualities, etc., to provide useful insights that underpin CodeChain's
success.","pass@1,APPS,CodeContests",Accepted to ICLR 2024,2024-03-14 03:29:09+00:00,2023-10-13 10:17:48+00:00,"['Hung Le', 'Hailin Chen', 'Amrita Saha', 'Akash Gokul', 'Doyen Sahoo', 'Shafiq Joty']","['cs.AI', 'cs.CL', 'cs.PL']",cs.AI,,,TRUE
2402.09565v2,http://arxiv.org/abs/2402.09565v2,"Graph-Skeleton: ~1% Nodes are Sufficient to Represent Billion-Scale
  Graph","Due to the ubiquity of graph data on the web, web graph mining has become a
hot research spot. Nonetheless, the prevalence of large-scale web graphs in
real applications poses significant challenges to storage, computational
capacity and graph model design. Despite numerous studies to enhance the
scalability of graph models, a noticeable gap remains between academic research
and practical web graph mining applications. One major cause is that in most
industrial scenarios, only a small part of nodes in a web graph are actually
required to be analyzed, where we term these nodes as target nodes, while
others as background nodes. In this paper, we argue that properly fetching and
condensing the background nodes from massive web graph data might be a more
economical shortcut to tackle the obstacles fundamentally. To this end, we make
the first attempt to study the problem of massive background nodes compression
for target nodes classification. Through extensive experiments, we reveal two
critical roles played by the background nodes in target node classification:
enhancing structural connectivity between target nodes, and feature correlation
with target nodes. Followingthis, we propose a novel Graph-Skeleton1 model,
which properly fetches the background nodes, and further condenses the semantic
and topological information of background nodes within similar
target-background local structures. Extensive experiments on various web graph
datasets demonstrate the effectiveness and efficiency of the proposed method.
In particular, for MAG240M dataset with 0.24 billion nodes, our generated
skeleton graph achieves highly comparable performance while only containing
1.8% nodes of the original graph.","background nodes,massive background nodes compression,structural connectivity,taget-background local structures","21 pages, 11 figures, In Proceedings of the ACM Web Conference 2024
  (WWW'24)",2024-03-06 22:22:33+00:00,2024-02-14 20:33:11+00:00,"['Linfeng Cao', 'Haoran Deng', 'Yang Yang', 'Chunping Wang', 'Lei Chen']",['cs.AI'],cs.AI,10.1145/3589334.3645452,,TRUE
2007.00714v4,http://arxiv.org/abs/2007.00714v4,"Quantifying intrinsic causal contributions via structure preserving
  interventions","We propose a notion of causal influence that describes the `intrinsic' part
of the contribution of a node on a target node in a DAG. By recursively writing
each node as a function of the upstream noise terms, we separate the intrinsic
information added by each node from the one obtained from its ancestors. To
interpret the intrinsic information as a {\it causal} contribution, we consider
`structure-preserving interventions' that randomize each node in a way that
mimics the usual dependence on the parents and does not perturb the observed
joint distribution. To get a measure that is invariant with respect to
relabelling nodes we use Shapley based symmetrization and show that it reduces
in the linear case to simple ANOVA after resolving the target node into noise
variables. We describe our contribution analysis for variance and entropy, but
contributions for other target metrics can be defined analogously. The code is
available in the package gcm of the open source library DoWhy.","structure-preserving interventions,relabelling nodes,Shapley based symmetrization,",to appear at AISTATS 2024,2024-03-08 13:33:03+00:00,2020-07-01 19:34:08+00:00,"['Dominik Janzing', 'Patrick BlÃ¶baum', 'Atalanti A. Mastakouri', 'Philipp M. Faller', 'Lenon Minorics', 'Kailash Budhathoki']","['cs.AI', 'cs.IT', 'math.IT', 'stat.ML']",cs.AI,,,TRUE
2311.02760v2,http://arxiv.org/abs/2311.02760v2,Causal Question Answering with Reinforcement Learning,"Causal questions inquire about causal relationships between different events
or phenomena. They are important for a variety of use cases, including virtual
assistants and search engines. However, many current approaches to causal
question answering cannot provide explanations or evidence for their answers.
Hence, in this paper, we aim to answer causal questions with a causality graph,
a large-scale dataset of causal relations between noun phrases along with the
relations' provenance data. Inspired by recent, successful applications of
reinforcement learning to knowledge graph tasks, such as link prediction and
fact-checking, we explore the application of reinforcement learning on a
causality graph for causal question answering. We introduce an
Actor-Critic-based agent which learns to search through the graph to answer
causal questions. We bootstrap the agent with a supervised learning procedure
to deal with large action spaces and sparse rewards. Our evaluation shows that
the agent successfully prunes the search space to answer binary causal
questions by visiting less than 30 nodes per question compared to over 3,000
nodes by a naive breadth-first search. Our ablation study indicates that our
supervised learning strategy provides a strong foundation upon which our
reinforcement learning agent improves. The paths returned by our agent explain
the mechanisms by which a cause produces an effect. Moreover, for each edge on
a path, our causality graph provides its original source allowing for easy
verification of paths.","relations' provenance data,large action spaces,sparse rewards,",Accepted at WWW 2024,2024-03-25 08:57:47+00:00,2023-11-05 20:33:18+00:00,"['Lukas BlÃ¼baum', 'Stefan Heindorf']","['cs.AI', 'cs.LG']",cs.AI,10.1145/3589334.3645610,,TRUE
2403.17358v1,http://arxiv.org/abs/2403.17358v1,Addressing Myopic Constrained POMDP Planning with Recursive Dual Ascent,"Lagrangian-guided Monte Carlo tree search with global dual ascent has been
applied to solve large constrained partially observable Markov decision
processes (CPOMDPs) online. In this work, we demonstrate that these global dual
parameters can lead to myopic action selection during exploration, ultimately
leading to suboptimal decision making. To address this, we introduce
history-dependent dual variables that guide local action selection and are
optimized with recursive dual ascent. We empirically compare the performance of
our approach on a motivating toy example and two large CPOMDPs, demonstrating
improved exploration, and ultimately, safer outcomes.","Lagrangian-guided Monte Carlo tree search,global dual ascent,large constrained partially observable Markov decision
processes (CPOMDPs),myopic action selection,recursive dual ascent","Accepted to the 2024 International Conference on Automated Planning
  and Scheduling (ICAPS)",2024-03-26 03:46:33+00:00,2024-03-26 03:46:33+00:00,"['Paula Stocco', 'Suhas Chundi', 'Arec Jamgochian', 'Mykel J. Kochenderfer']",['cs.AI'],cs.AI,,,TRUE
2403.04124v1,http://arxiv.org/abs/2403.04124v1,Privacy-preserving Fine-tuning of Large Language Models through Flatness,"The privacy concerns associated with the use of Large Language Models (LLMs)
have grown recently with the development of LLMs such as ChatGPT. Differential
Privacy (DP) techniques are explored in existing work to mitigate their privacy
risks at the cost of generalization degradation. Our paper reveals that the
flatness of DP-trained models' loss landscape plays an essential role in the
trade-off between their privacy and generalization. We further propose a
holistic framework to enforce appropriate weight flatness, which substantially
improves model generalization with competitive privacy preservation. It
innovates from three coarse-to-grained levels, including perturbation-aware
min-max optimization on model weights within a layer, flatness-guided sparse
prefix-tuning on weights across layers, and weight knowledge distillation
between DP \& non-DP weights copies. Comprehensive experiments of both
black-box and white-box scenarios are conducted to demonstrate the
effectiveness of our proposal in enhancing generalization and maintaining DP
characteristics. For instance, on text classification dataset QNLI, DP-Flat
achieves similar performance with non-private full fine-tuning but with DP
guarantee under privacy budget $\epsilon=3$, and even better performance given
higher privacy budgets. Codes are provided in the supplement.","generalization degradation,appropriate weight flatness,perturbation-aware
min-max optimization,flatness-guided sparse prefix-tuning,weight knowledge distillation,privacy budget",Accepted to ICLR 2024 SeT LLM Workshop,2024-03-07 00:44:11+00:00,2024-03-07 00:44:11+00:00,"['Tiejin Chen', 'Longchao Da', 'Huixue Zhou', 'Pingzhi Li', 'Kaixiong Zhou', 'Tianlong Chen', 'Hua Wei']","['cs.AI', 'I.2']",cs.AI,,,TRUE
2402.07398v2,http://arxiv.org/abs/2402.07398v2,"VisLingInstruct: Elevating Zero-Shot Learning in Multi-Modal Language
  Models with Autonomous Instruction Optimization","This paper presents VisLingInstruct, a novel approach to advancing
Multi-Modal Language Models (MMLMs) in zero-shot learning. Current MMLMs show
impressive zero-shot abilities in multi-modal tasks, but their performance
depends heavily on the quality of instructions. VisLingInstruct tackles this by
autonomously evaluating and optimizing instructional texts through In-Context
Learning, improving the synergy between visual perception and linguistic
expression in MMLMs. Alongside this instructional advancement, we have also
optimized the visual feature extraction modules in MMLMs, further augmenting
their responsiveness to textual cues. Our comprehensive experiments on MMLMs,
based on FlanT5 and Vicuna, show that VisLingInstruct significantly improves
zero-shot performance in visual multi-modal tasks. Notably, it achieves a 13.1%
and 9% increase in accuracy over the prior state-of-the-art on the TextVQA and
HatefulMemes datasets.","visual feature extraction modules,TextVQA,HatefulMemes",Accepted to NAACL2024 main conference,2024-03-14 14:30:14+00:00,2024-02-12 04:13:16+00:00,"['Dongsheng Zhu', 'Xunzhu Tang', 'Weidong Han', 'Jinghui Lu', 'Yukun Zhao', 'Guoliang Xing', 'Junfeng Wang', 'Dawei Yin']",['cs.AI'],cs.AI,,,TRUE
2309.03685v2,http://arxiv.org/abs/2309.03685v2,"PyGraft: Configurable Generation of Synthetic Schemas and Knowledge
  Graphs at Your Fingertips","Knowledge graphs (KGs) have emerged as a prominent data representation and
management paradigm. Being usually underpinned by a schema (e.g., an ontology),
KGs capture not only factual information but also contextual knowledge. In some
tasks, a few KGs established themselves as standard benchmarks. However, recent
works outline that relying on a limited collection of datasets is not
sufficient to assess the generalization capability of an approach. In some
data-sensitive fields such as education or medicine, access to public datasets
is even more limited. To remedy the aforementioned issues, we release PyGraft,
a Python-based tool that generates highly customized, domain-agnostic schemas
and KGs. The synthesized schemas encompass various RDFS and OWL constructs,
while the synthesized KGs emulate the characteristics and scale of real-world
KGs. Logical consistency of the generated resources is ultimately ensured by
running a description logic (DL) reasoner. By providing a way of generating
both a schema and KG in a single pipeline, PyGraft's aim is to empower the
generation of a more diverse array of KGs for benchmarking novel approaches in
areas such as graph-based machine learning (ML), or more generally KG
processing. In graph-based ML in particular, this should foster a more holistic
evaluation of model performance and generalization capability, thereby going
beyond the limited collection of available benchmarks. PyGraft is available at:
https://github.com/nicolas-hbt/pygraft.",description logic (DL) reasoner,Accepted in ESWC 2024,2024-03-05 21:56:43+00:00,2023-09-07 13:00:09+00:00,"['Nicolas Hubert', 'Pierre Monnin', ""Mathieu d'Aquin"", 'Davy Monticolo', 'Armelle Brun']","['cs.AI', 'cs.SE']",cs.AI,,,TRUE
2301.13755v3,http://arxiv.org/abs/2301.13755v3,Retrosynthetic Planning with Dual Value Networks,"Retrosynthesis, which aims to find a route to synthesize a target molecule
from commercially available starting materials, is a critical task in drug
discovery and materials design. Recently, the combination of ML-based
single-step reaction predictors with multi-step planners has led to promising
results. However, the single-step predictors are mostly trained offline to
optimize the single-step accuracy, without considering complete routes. Here,
we leverage reinforcement learning (RL) to improve the single-step predictor,
by using a tree-shaped MDP to optimize complete routes. Specifically, we
propose a novel online training algorithm, called Planning with Dual Value
Networks (PDVN), which alternates between the planning phase and updating
phase. In PDVN, we construct two separate value networks to predict the
synthesizability and cost of molecules, respectively. To maintain the
single-step accuracy, we design a two-branch network structure for the
single-step predictor. On the widely-used USPTO dataset, our PDVN algorithm
improves the search success rate of existing multi-step planners (e.g.,
increasing the success rate from 85.79% to 98.95% for Retro*, and reducing the
number of model calls by half while solving 99.47% molecules for RetroGraph).
Additionally, PDVN helps find shorter synthesis routes (e.g., reducing the
average route length from 5.76 to 4.83 for Retro*, and from 5.63 to 4.78 for
RetroGraph). Our code is available at \url{https://github.com/DiXue98/PDVN}.","single-step reaction predictors,multi-step planners,tree-shaped MDP,synthesizability,synthesis routes",Accepted to ICML 2023,2024-03-03 14:23:21+00:00,2023-01-31 16:43:53+00:00,"['Guoqing Liu', 'Di Xue', 'Shufang Xie', 'Yingce Xia', 'Austin Tripp', 'Krzysztof Maziarz', 'Marwin Segler', 'Tao Qin', 'Zongzhang Zhang', 'Tie-Yan Liu']","['cs.AI', 'cs.LG']",cs.AI,,,TRUE
2312.14106v2,http://arxiv.org/abs/2312.14106v2,Learning Human-like Representations to Enable Learning Human Values,"How can we build AI systems that are aligned with human values to avoid
causing harm or violating societal standards for acceptable behavior? We argue
that representational alignment between humans and AI agents facilitates value
alignment. Making AI systems learn human-like representations of the world has
many known benefits, including improving generalization, robustness to domain
shifts, and few-shot learning performance. We propose that this kind of
representational alignment between machine learning (ML) models and humans can
also support value alignment, allowing ML systems to conform to human values
and societal norms. We focus on ethics as one aspect of value alignment and
train ML agents using a variety of methods in a multi-armed bandit setting,
where rewards reflect the moral acceptability of the chosen action. We use a
synthetic experiment to demonstrate that agents' representational alignment
with the environment bounds their learning performance. We then repeat this
procedure in a realistic setting, using textual action descriptions and
similarity judgments collected from humans and a variety of language models, to
show that the results generalize and are model-agnostic when grounded in an
ethically relevant context.","domain shifts,moral acceptability,","Paper accepted in Human-Centric Representation Learning workshop at
  AAAI 2024 (https://hcrl-workshop.github.io/2024/)",2024-03-13 01:37:55+00:00,2023-12-21 18:31:33+00:00,"['Andrea Wynn', 'Ilia Sucholutsky', 'Thomas L. Griffiths']","['cs.AI', 'cs.LG']",cs.AI,,,TRUE
2312.00812v4,http://arxiv.org/abs/2312.00812v4,"Empowering Autonomous Driving with Large Language Models: A Safety
  Perspective","Autonomous Driving (AD) encounters significant safety hurdles in long-tail
unforeseen driving scenarios, largely stemming from the non-interpretability
and poor generalization of the deep neural networks within the AD system,
particularly in out-of-distribution and uncertain data. To this end, this paper
explores the integration of Large Language Models (LLMs) into AD systems,
leveraging their robust common-sense knowledge and reasoning abilities. The
proposed methodologies employ LLMs as intelligent decision-makers in behavioral
planning, augmented with a safety verifier shield for contextual safety
learning, for enhancing driving performance and safety. We present two key
studies in a simulated environment: an adaptive LLM-conditioned Model
Predictive Control (MPC) and an LLM-enabled interactive behavior planning
scheme with a state machine. Demonstrating superior performance and safety
metrics compared to state-of-the-art approaches, our approach shows the
promising potential for using LLMs for autonomous vehicles.","safety verifier shield,contextual safety learning,Model Predictive Control (MPC),behavior planning scheme,",Accepted to LLMAgent workshop @ICLR2024,2024-03-22 17:29:01+00:00,2023-11-28 03:13:09+00:00,"['Yixuan Wang', 'Ruochen Jiao', 'Sinong Simon Zhan', 'Chengtian Lang', 'Chao Huang', 'Zhaoran Wang', 'Zhuoran Yang', 'Qi Zhu']","['cs.AI', 'cs.LG', 'cs.SY', 'eess.SY']",cs.AI,,,TRUE
2403.04732v2,http://arxiv.org/abs/2403.04732v2,How Far Are We from Intelligent Visual Deductive Reasoning?,"Vision-Language Models (VLMs) such as GPT-4V have recently demonstrated
incredible strides on diverse vision language tasks. We dig into vision-based
deductive reasoning, a more sophisticated but less explored realm, and find
previously unexposed blindspots in the current SOTA VLMs. Specifically, we
leverage Raven's Progressive Matrices (RPMs), to assess VLMs' abilities to
perform multi-hop relational and deductive reasoning relying solely on visual
clues. We perform comprehensive evaluations of several popular VLMs employing
standard strategies such as in-context learning, self-consistency, and
Chain-of-thoughts (CoT) on three diverse datasets, including the Mensa IQ test,
IntelligenceTest, and RAVEN. The results reveal that despite the impressive
capabilities of LLMs in text-based reasoning, we are still far from achieving
comparable proficiency in visual deductive reasoning. We found that certain
standard strategies that are effective when applied to LLMs do not seamlessly
translate to the challenges presented by visual reasoning tasks. Moreover, a
detailed analysis reveals that VLMs struggle to solve these tasks mainly
because they are unable to perceive and comprehend multiple, confounding
abstract patterns in RPM examples.","Raven's Progressiive Matrices (RPMs),multi-hop relational and deductive reasoning,self-consistency,",ICLR 2024 AGI workshop. https://github.com/apple/ml-rpm-bench,2024-03-08 06:47:08+00:00,2024-03-07 18:35:54+00:00,"['Yizhe Zhang', 'He Bai', 'Ruixiang Zhang', 'Jiatao Gu', 'Shuangfei Zhai', 'Josh Susskind', 'Navdeep Jaitly']","['cs.AI', 'cs.CL', 'cs.CV']",cs.AI,,,TRUE
2307.03067v2,http://arxiv.org/abs/2307.03067v2,DeepOnto: A Python Package for Ontology Engineering with Deep Learning,"Integrating deep learning techniques, particularly language models (LMs),
with knowledge representation techniques like ontologies has raised widespread
attention, urging the need of a platform that supports both paradigms. Although
packages such as OWL API and Jena offer robust support for basic ontology
processing features, they lack the capability to transform various types of
information within ontologies into formats suitable for downstream deep
learning-based applications. Moreover, widely-used ontology APIs are primarily
Java-based while deep learning frameworks like PyTorch and Tensorflow are
mainly for Python programming. To address the needs, we present DeepOnto, a
Python package designed for ontology engineering with deep learning. The
package encompasses a core ontology processing module founded on the
widely-recognised and reliable OWL API, encapsulating its fundamental features
in a more ""Pythonic"" manner and extending its capabilities to incorporate other
essential components including reasoning, verbalisation, normalisation,
taxonomy, projection, and more. Building on this module, DeepOnto offers a
suite of tools, resources, and algorithms that support various ontology
engineering tasks, such as ontology alignment and completion, by harnessing
deep learning methods, primarily pre-trained LMs. In this paper, we also
demonstrate the practical utility of DeepOnto through two use-cases: the
Digital Health Coaching in Samsung Research UK and the Bio-ML track of the
Ontology Alignment Evaluation Initiative (OAEI).","verbalisation,normalisation,projection",Accepted by the Semantic Web Journal,2024-03-09 02:17:42+00:00,2023-07-06 15:35:02+00:00,"['Yuan He', 'Jiaoyan Chen', 'Hang Dong', 'Ian Horrocks', 'Carlo Allocca', 'Taehun Kim', 'Brahmananda Sapkota']","['cs.AI', 'cs.CL', 'cs.LG', 'cs.LO']",cs.AI,,,TRUE
2403.17873v1,http://arxiv.org/abs/2403.17873v1,"Addressing Social Misattributions of Large Language Models: An
  HCXAI-based Approach","Human-centered explainable AI (HCXAI) advocates for the integration of social
aspects into AI explanations. Central to the HCXAI discourse is the Social
Transparency (ST) framework, which aims to make the socio-organizational
context of AI systems accessible to their users. In this work, we suggest
extending the ST framework to address the risks of social misattributions in
Large Language Models (LLMs), particularly in sensitive areas like mental
health. In fact LLMs, which are remarkably capable of simulating roles and
personas, may lead to mismatches between designers' intentions and users'
perceptions of social attributes, risking to promote emotional manipulation and
dangerous behaviors, cases of epistemic injustice, and unwarranted trust. To
address these issues, we propose enhancing the ST framework with a fifth
'W-question' to clarify the specific social attributions assigned to LLMs by
its designers and users. This addition aims to bridge the gap between LLM
capabilities and user perceptions, promoting the ethically responsible
development and use of LLM-based technology.","Social Transparency (ST) framework,W-question","Extended version of the manuscript accepted for the ACM CHI Workshop
  on Human-Centered Explainable AI 2024 (HCXAI24)",2024-03-26 17:02:42+00:00,2024-03-26 17:02:42+00:00,"['Andrea Ferrario', 'Alberto Termine', 'Alessandro Facchini']",['cs.AI'],cs.AI,,,TRUE
2403.15875v1,http://arxiv.org/abs/2403.15875v1,"LAMPER: LanguAge Model and Prompt EngineeRing for zero-shot time series
  classification","This study constructs the LanguAge Model with Prompt EngineeRing (LAMPER)
framework, designed to systematically evaluate the adaptability of pre-trained
language models (PLMs) in accommodating diverse prompts and their integration
in zero-shot time series (TS) classification. We deploy LAMPER in experimental
assessments using 128 univariate TS datasets sourced from the UCR archive. Our
findings indicate that the feature representation capacity of LAMPER is
influenced by the maximum input token threshold imposed by PLMs.","zero-shot time series (TS) classification,UCR archive,feature representation capacity,maximum input token threshold,PLMs",Accepted as tiny paper in ICLR 2024,2024-03-23 15:52:37+00:00,2024-03-23 15:52:37+00:00,"['Zhicheng Du', 'Zhaotian Xie', 'Yan Tong', 'Peiwu Qin']","['cs.AI', 'cs.CL']",cs.AI,,,TRUE
2403.16508v1,http://arxiv.org/abs/2403.16508v1,"Return to Tradition: Learning Reliable Heuristics with Classical Machine
  Learning","Current approaches for learning for planning have yet to achieve competitive
performance against classical planners in several domains, and have poor
overall performance. In this work, we construct novel graph representations of
lifted planning tasks and use the WL algorithm to generate features from them.
These features are used with classical machine learning methods which have up
to 2 orders of magnitude fewer parameters and train up to 3 orders of magnitude
faster than the state-of-the-art deep learning for planning models. Our novel
approach, WL-GOOSE, reliably learns heuristics from scratch and outperforms the
$h^{\text{FF}}$ heuristic in a fair competition setting. It also outperforms or
ties with LAMA on 4 out of 10 domains on coverage and 7 out of 10 domains on
plan quality. WL-GOOSE is the first learning for planning model which achieves
these feats. Furthermore, we study the connections between our novel WL feature
generation method, previous theoretically flavoured learning architectures, and
Description Logic Features for planning.","classical planners,lifted planning tasks,WL algorithm,FF heuristic,learning for planning model,Description Logic Features",Extended version of ICAPS 2024 paper,2024-03-25 07:47:52+00:00,2024-03-25 07:47:52+00:00,"['Dillon Z. Chen', 'Felipe Trevizan', 'Sylvie ThiÃ©baux']",['cs.AI'],cs.AI,,,TRUE
2403.16289v1,http://arxiv.org/abs/2403.16289v1,"Engineering Safety Requirements for Autonomous Driving with Large
  Language Models","Changes and updates in the requirement artifacts, which can be frequent in
the automotive domain, are a challenge for SafetyOps. Large Language Models
(LLMs), with their impressive natural language understanding and generating
capabilities, can play a key role in automatically refining and decomposing
requirements after each update. In this study, we propose a prototype of a
pipeline of prompts and LLMs that receives an item definition and outputs
solutions in the form of safety requirements. This pipeline also performs a
review of the requirement dataset and identifies redundant or contradictory
requirements. We first identified the necessary characteristics for performing
HARA and then defined tests to assess an LLM's capability in meeting these
criteria. We used design science with multiple iterations and let experts from
different companies evaluate each cycle quantitatively and qualitatively.
Finally, the prototype was implemented at a case company and the responsible
team evaluated its efficiency.","requirement artifacts,decomposing requirements,requirement dataset","Accepted in 32nd IEEE International Requirements Engineering 2024
  conference, Iceland",2024-03-24 20:40:51+00:00,2024-03-24 20:40:51+00:00,"['Ali Nouri', 'Beatriz Cabrero-Daniel', 'Fredrik TÃ¶rner', 'HÈ§kan Sivencrona', 'Christian Berger']",['cs.AI'],cs.AI,,,TRUE
2403.17419v1,http://arxiv.org/abs/2403.17419v1,"AI Safety: Necessary, but insufficient and possibly problematic","This article critically examines the recent hype around AI safety. We first
start with noting the nature of the AI safety hype as being dominated by
governments and corporations, and contrast it with other avenues within AI
research on advancing social good. We consider what 'AI safety' actually means,
and outline the dominant concepts that the digital footprint of AI safety
aligns with. We posit that AI safety has a nuanced and uneasy relationship with
transparency and other allied notions associated with societal good, indicating
that it is an insufficient notion if the goal is that of societal good in a
broad sense. We note that the AI safety debate has already influenced some
regulatory efforts in AI, perhaps in not so desirable directions. We also share
our concerns on how AI safety may normalize AI that advances structural harm
through providing exploitative and harmful AI with a veneer of safety.",,AI & Soc (2024),2024-03-26 06:18:42+00:00,2024-03-26 06:18:42+00:00,['Deepak P'],"['cs.AI', 'cs.CY']",cs.AI,10.1007/s00146-024-01899-y,,TRUE
2402.01786v2,http://arxiv.org/abs/2402.01786v2,"COA-GPT: Generative Pre-trained Transformers for Accelerated Course of
  Action Development in Military Operations","The development of Courses of Action (COAs) in military operations is
traditionally a time-consuming and intricate process. Addressing this
challenge, this study introduces COA-GPT, a novel algorithm employing Large
Language Models (LLMs) for rapid and efficient generation of valid COAs.
COA-GPT incorporates military doctrine and domain expertise to LLMs through
in-context learning, allowing commanders to input mission information - in both
text and image formats - and receive strategically aligned COAs for review and
approval. Uniquely, COA-GPT not only accelerates COA development, producing
initial COAs within seconds, but also facilitates real-time refinement based on
commander feedback. This work evaluates COA-GPT in a military-relevant scenario
within a militarized version of the StarCraft II game, comparing its
performance against state-of-the-art reinforcement learning algorithms. Our
results demonstrate COA-GPT's superiority in generating strategically sound
COAs more swiftly, with added benefits of enhanced adaptability and alignment
with commander intentions. COA-GPT's capability to rapidly adapt and update
COAs during missions presents a transformative potential for military planning,
particularly in addressing planning discrepancies and capitalizing on emergent
windows of opportunities.","Courses of Action (COAs),","Accepted at the NATO Science and Technology Organization Symposium
  (ICMCIS) organized by the Information Systems Technology (IST) Panel,
  IST-205-RSY - the ICMCIS, held in Koblenz, Germany, 23-24 April 2024",2024-03-28 15:22:42+00:00,2024-02-01 21:51:09+00:00,"['Vinicius G. Goecks', 'Nicholas Waytowich']","['cs.AI', 'cs.CL', 'cs.HC', 'cs.LG', 'I.2.6; I.2.7; J.7']",cs.AI,,,TRUE
2403.10112v1,http://arxiv.org/abs/2403.10112v1,"Single- and Multi-Agent Private Active Sensing: A Deep Neuroevolution
  Approach","In this paper, we focus on one centralized and one decentralized problem of
active hypothesis testing in the presence of an eavesdropper. For the
centralized problem including a single legitimate agent, we present a new
framework based on NeuroEvolution (NE), whereas, for the decentralized problem,
we develop a novel NE-based method for solving collaborative multi-agent tasks,
which interestingly maintains all computational benefits of single-agent NE.
The superiority of the proposed EAHT approaches over conventional active
hypothesis testing policies, as well as learning-based methods, is validated
through numerical investigations in an example use case of anomaly detection
over wireless sensor networks.","centralized problem,legitimate agent,decentralized problem,NeuroEvolution (NE),collaborative multi-agent tasks,EAHT approaches,","7 pages, 5 figures, accepted at IEEE ICC 2024 (to be presented)",2024-03-15 08:55:56+00:00,2024-03-15 08:55:56+00:00,"['George Stamatelis', 'Angelos-Nikolaos Kanatas', 'Ioannis Asprogerakas', 'George C. Alexandropoulos']","['cs.AI', 'cs.CR', 'cs.MA', 'cs.NE']",cs.AI,,,TRUE
2403.07131v1,http://arxiv.org/abs/2403.07131v1,"Bigraph Matching Weighted with Learnt Incentive Function for Multi-Robot
  Task Allocation","Most real-world Multi-Robot Task Allocation (MRTA) problems require fast and
efficient decision-making, which is often achieved using heuristics-aided
methods such as genetic algorithms, auction-based methods, and bipartite graph
matching methods. These methods often assume a form that lends better
explainability compared to an end-to-end (learnt) neural network based policy
for MRTA. However, deriving suitable heuristics can be tedious, risky and in
some cases impractical if problems are too complex. This raises the question:
can these heuristics be learned? To this end, this paper particularly develops
a Graph Reinforcement Learning (GRL) framework to learn the heuristics or
incentives for a bipartite graph matching approach to MRTA. Specifically a
Capsule Attention policy model is used to learn how to weight task/robot
pairings (edges) in the bipartite graph that connects the set of tasks to the
set of robots. The original capsule attention network architecture is
fundamentally modified by adding encoding of robots' state graph, and two
Multihead Attention based decoders whose output are used to construct a
LogNormal distribution matrix from which positive bigraph weights can be drawn.
The performance of this new bigraph matching approach augmented with a
GRL-derived incentive is found to be at par with the original bigraph matching
approach that used expert-specified heuristics, with the former offering
notable robustness benefits. During training, the learned incentive policy is
found to get initially closer to the expert-specified incentive and then
slightly deviate from its trend.","Multi-Robot Task Allocation (MRTA) problems,Graph Reinforcement Learning (GRL) framework,bipartite graph matching approach,,Capsule Attention policy mode,robots' state graph,positive bigraph weights,learned incentive policy,expert-specified incentive","This paper was accepted for presentation in proceedings of IEEE
  International Conference on Robotics and Automation 2024",2024-03-11 19:55:08+00:00,2024-03-11 19:55:08+00:00,"['Steve Paul', 'Nathan Maurer', 'Souma Chowdhury']","['cs.AI', 'cs.MA']",cs.AI,,,TRUE
2403.05112v1,http://arxiv.org/abs/2403.05112v1,"RLPeri: Accelerating Visual Perimetry Test with Reinforcement Learning
  and Convolutional Feature Extraction","Visual perimetry is an important eye examination that helps detect vision
problems caused by ocular or neurological conditions. During the test, a
patient's gaze is fixed at a specific location while light stimuli of varying
intensities are presented in central and peripheral vision. Based on the
patient's responses to the stimuli, the visual field mapping and sensitivity
are determined. However, maintaining high levels of concentration throughout
the test can be challenging for patients, leading to increased examination
times and decreased accuracy.
  In this work, we present RLPeri, a reinforcement learning-based approach to
optimize visual perimetry testing. By determining the optimal sequence of
locations and initial stimulus values, we aim to reduce the examination time
without compromising accuracy. Additionally, we incorporate reward shaping
techniques to further improve the testing performance. To monitor the patient's
responses over time during testing, we represent the test's state as a pair of
3D matrices. We apply two different convolutional kernels to extract spatial
features across locations as well as features across different stimulus values
for each location. Through experiments, we demonstrate that our approach
results in a 10-20% reduction in examination time while maintaining the
accuracy as compared to state-of-the-art methods. With the presented approach,
we aim to make visual perimetry testing more efficient and patient-friendly,
while still providing accurate results.","reward shaping
techniques,initial stimulus values,",Published at AAAI-24,2024-03-08 07:19:43+00:00,2024-03-08 07:19:43+00:00,"['Tanvi Verma', 'Linh Le Dinh', 'Nicholas Tan', 'Xinxing Xu', 'Chingyu Cheng', 'Yong Liu']",['cs.AI'],cs.AI,,"The 38th Annual AAAI Conference on Artificial Intelligence, 2024",TRUE
2403.00431v1,http://arxiv.org/abs/2403.00431v1,"Robotic Process Automation as a Driver for Sustainable Innovation and
  Entrepreneurship","Technological innovation plays a crucial role in driving economic growth and
development. In this study, we investigate the extent to which technological
innovation contributes to a more sustainable future and fosters
entrepreneurship. To examine this, we focus on robotic process automation (RPA)
highly relevant technology. We conducted a comprehensive analysis by examining
the usage of RPA and its impact on environmental, social, and governance (ESG)
factors. Our research involved gathering data from the 300 largest companies in
terms of market capitalization. We assessed whether these companies used RPA
and obtained their corresponding ESG ratings. To investigate the relationship
between RPA and ESG, we employed a contingency table analysis, which involved
categorizing the data based on ESG ratings. We further used Pearson's
Chi-square Test of Independence to assess the impact of RPA on ESG. Our
findings revealed a statistically significant association between RPA and ESG
ratings, indicating their interconnection. The calculated value for Pearson's
Chi-square Test of Independence was 6.54, with a corresponding p-value of
0.0381. This indicates that at a significance level of five percent, the RPA
and ESG variables depend on each other. These results suggest that RPA,
representative of modern technologies, likely influences the achievement of a
sustainable future and the promotion of entrepreneurship. In conclusion, our
study provides empirical evidence supporting the notion that technological
innovations such as RPA have the potential to positively shape sustainability
efforts and entrepreneurial endeavours.","robotic process automation (RPA),contingency table analysis","XB-CON International Conference 2023, Zelezna Ruda, Czechia",2024-03-01 10:32:48+00:00,2024-03-01 10:32:48+00:00,['Petr Prucha'],['cs.CY'],cs.CY,,,TRUE
2403.17911v1,http://arxiv.org/abs/2403.17911v1,Domain-Specific Evaluation Strategies for AI in Journalism,"News organizations today rely on AI tools to increase efficiency and
productivity across various tasks in news production and distribution. These
tools are oriented towards stakeholders such as reporters, editors, and
readers. However, practitioners also express reservations around adopting AI
technologies into the newsroom, due to the technical and ethical challenges
involved in evaluating AI technology and its return on investments. This is to
some extent a result of the lack of domain-specific strategies to evaluate AI
models and applications. In this paper, we consider different aspects of AI
evaluation (model outputs, interaction, and ethics) that can benefit from
domain-specific tailoring, and suggest examples of how journalistic
considerations can lead to specialized metrics or strategies. In doing so, we
lay out a potential framework to guide AI evaluation in journalism, such as
seen in other disciplines (e.g. law, healthcare). We also consider directions
for future work, as well as how our approach might generalize to other domains.",,"Accepted to the Workshop on Evaluating AI at the ACM CHI conference
  on Human Factors in Computing Systems",2024-03-26 17:47:25+00:00,2024-03-26 17:47:25+00:00,"['Sachita Nishal', 'Charlotte Li', 'Nicholas Diakopoulos']","['cs.CY', 'I.2.1; H.5; K.4']",cs.CY,,,TRUE
2403.11952v1,http://arxiv.org/abs/2403.11952v1,"Exploring Estonia's Open Government Data Development as a Journey
  towards Excellence: Unveiling the Progress of Local Governments in Open Data
  Provision","Estonia has a global reputation of a digital state or e-country. However,
despite the success in digital governance, the country has faced challenges in
the realm of Open Government Data (OGD) area, with significant advancements in
its OGD ecosystem, as reflected in various open data rankings from 2020 and
onwards, in the recent years being recognized among trend-setters. This paper
aims to explore the evolution and positioning of Estonia's OGD development,
encompassing national and local levels, through an integrated analysis of
various indices, primary data from the Estonian OGD portal, and a thorough
literature review. The research shows that Estonia has made progress in the
national level open data ecosystem, primarily due to improvements in the OGD
portal usability and legislation amendments. However, the local level is not as
developed, with local governments lagging behind in OGD provision. The
literature review highlights the lack of previous research focusing on Estonian
and European local open data, emphasizing the need for future studies to
explore the barriers and enablers of municipal OGD. This study contributes to a
nuanced understanding of Estonia's dynamic journey in the OGD landscape,
shedding light on both achievements and areas warranting further attention for
establishing a sustainable open data ecosystem.",,"This paper has been accepted for publication in Proceedings of the
  25th Annual International Conference on Digital Government Research and this
  is a pre-print version of the manuscript. It is posted here for your personal
  use. Not for redistribution",2024-03-18 16:50:05+00:00,2024-03-18 16:50:05+00:00,"['Katrin RajamÃ¤e-Soosaar', 'Anastasija Nikiforova']","['cs.CY', 'cs.CE', 'cs.DB', 'cs.SE', 'cs.SI']",cs.CY,,,TRUE
2403.08451v1,http://arxiv.org/abs/2403.08451v1,"An Integrated Usability Framework for Evaluating Open Government Data
  Portals: Comparative Analysis of EU and GCC Countries","This study explores the critical role of open government data (OGD) portals
in fostering transparency and collaboration between diverse stakeholders.
Recognizing the challenges of usability, communication with diverse
populations, and strategic value creation, this paper develops an integrated
framework for evaluating OGD portal effectiveness that accommodates user
diversity (regardless of their data literacy and language), evaluates
collaboration and participation, and the ability of users to explore and
understand the data provided through them. The framework is validated by
applying it to 33 national portals across European Union and Gulf Cooperation
Council (GCC) countries, as a result of which we rank OGD portals, identify
some good practices that lower-performing portals can learn from, and common
shortcomings. Notably, the study unveils the competitive and innovative nature
of GCC OGD portals, pinpointing specific improvement areas such as multilingual
support and data understandability. The findings underscore the growing trend
of exposing data quality metrics and advocate for enhanced two-way
communication channels between users and portal representatives. Overall, the
study contributes to accelerating the development of user-friendly,
collaborative, and sustainable OGD portals while addressing gaps identified in
previous research.",,"This paper has been accepted for publication in Proceedings of the
  25th Annual International Conference on Digital Government Research and this
  is a preprint version of the manuscript",2024-03-13 12:06:42+00:00,2024-03-13 12:06:42+00:00,"['Fillip Molodtsov', 'Anastasija Nikiforova']","['cs.CY', 'cs.SE']",cs.CY,,,TRUE
2403.14686v1,http://arxiv.org/abs/2403.14686v1,"Evaluating Pedagogical Incentives in Undergraduate Computing: A Mixed
  Methods Approach Using Learning Analytics","In the context of higher education's evolving dynamics post-COVID-19, this
paper assesses the impact of new pedagogical incentives implemented in a
first-year undergraduate computing module at University College London. We
employ a mixed methods approach, combining learning analytics with qualitative
data, to evaluate the effectiveness of these incentives on increasing student
engagement.
  A longitudinal overview of resource interactions is mapped through Bayesian
network analysis of Moodle activity logs from 204 students. This analysis
identifies early resource engagement as a predictive indicator of continued
engagement while also suggesting that the new incentives disproportionately
benefit highly engaged students. Focus group discussions complement this
analysis, providing insights into student perceptions of the pedagogical
changes and the module design. These qualitative findings underscore the
challenge of sustaining engagement through the new incentives and highlight the
importance of communication in blended learning environments.
  Our paper introduces an interpretable and actionable model for student
engagement, which integrates objective, data-driven analysis with students'
perspectives. This model provides educators with a tool to evaluate and improve
instructional strategies. By demonstrating the effectiveness of our mixed
methods approach in capturing the intricacies of student behaviour in digital
learning environments, we underscore the model's potential to improve online
pedagogical practices across diverse educational settings.","Bayesian network analysis,blended learning environments,","5 pages, 1 figure. Accepted by IEEE Global Engineering Education
  Conference 2024",2024-03-13 16:39:38+00:00,2024-03-13 16:39:38+00:00,"['Laura J. Johnston', 'Takoua Jendoubi']",['cs.CY'],cs.CY,,,TRUE
2403.07082v1,http://arxiv.org/abs/2403.07082v1,"Exploring the Impact of ChatGPT on Student Interactions in
  Computer-Supported Collaborative Learning","The growing popularity of generative AI, particularly ChatGPT, has sparked
both enthusiasm and caution among practitioners and researchers in education.
To effectively harness the full potential of ChatGPT in educational contexts,
it is crucial to analyze its impact and suitability for different educational
purposes. This paper takes an initial step in exploring the applicability of
ChatGPT in a computer-supported collaborative learning (CSCL) environment.
Using statistical analysis, we validate the shifts in student interactions
during an asynchronous group brainstorming session by introducing ChatGPT as an
instantaneous question-answering agent.",,AAAI2024 Workshop on AI for Education (AI4ED),2024-03-11 18:18:18+00:00,2024-03-11 18:18:18+00:00,"['Han Kyul Kim', 'Shriniwas Nayak', 'Aleyeh Roknaldin', 'Xiaoci Zhang', 'Marlon Twyman', 'Stephen Lu']",['cs.CY'],cs.CY,,,TRUE
2401.09210v2,http://arxiv.org/abs/2401.09210v2,Narratives of Collective Action in YouTube's Discourse on Veganism,"Narratives can be powerful tools for inspiring action on pressing societal
issues such as climate change. While social science theories offer frameworks
for understanding the narratives that arise within collective movements, these
are rarely applied to the vast data available from social media platforms,
which play a significant role in shaping public opinion and mobilizing
collective action. This gap in the empirical evaluation of online narratives
limits our understanding of their relationship with public response. In this
study, we focus on plant-based diets as a form of pro-environmental action and
employ natural language processing to operationalize a theoretical framework of
moral narratives specific to the vegan movement. We apply this framework to
narratives found in YouTube videos promoting environmental initiatives such as
Veganuary, Meatless March, and No Meat May. Our analysis reveals that several
narrative types, as defined by the theory, are empirically present in the data.
To identify narratives with the potential to elicit positive public engagement,
we used text processing to estimate the proportion of comments supporting
collective action across narrative types. Video narratives advocating social
fight, whether through protest or through efforts to convert others to the
cause, are associated with a stronger sense of collective action in the
respective comments. These narrative types also demonstrate increased semantic
coherence and alignment between the message and public response, markers
typically associated with successful collective action. Our work offers new
insights into the complex factors that influence the emergence of collective
action, thereby informing the development of effective communication strategies
within social movements.","moral narratives,","15 pages, 7 figures, 7 tables. Accepted at ICWSM 2024",2024-03-28 11:39:59+00:00,2024-01-17 13:44:36+00:00,"['Arianna Pera', 'Luca Maria Aiello']","['cs.CY', 'physics.soc-ph']",cs.CY,,,TRUE
2308.10148v3,http://arxiv.org/abs/2308.10148v3,"Privacy Perceptions and Behaviors of Google Personal Account Holders in
  Saudi Arabia","While privacy perceptions and behaviors have been investigated in Western
societies, little is known about these issues in non-Western societies. To
bridge this gap, we interviewed 30 Google personal account holders in Saudi
Arabia about their privacy perceptions and behaviors regarding the activity
data that Google saves about them. Our study focuses on Google's Activity
Controls, which enable users to control whether, and how, Google saves their
Web \& App Activity, Location History, and YouTube History. Our results show
that although most participants have some level of awareness about Google's
data practices and the Activity Controls, many have only vague awareness, and
the majority have not used the available controls. When participants viewed
their saved activity data, many were surprised by what had been saved. While
many participants find Google's use of their data to improve the services
provided to them acceptable, the majority find the use of their data for ad
purposes unacceptable. We observe that our Saudi participants exhibit similar
trends and patterns in privacy awareness, attitudes, preferences, concerns, and
behaviors to what has been found in studies in the US. Our results emphasize
the need for: 1) improved techniques to inform users about privacy settings
during account sign-up, to remind users about their settings, and to raise
awareness about privacy settings; 2) improved privacy setting interfaces to
reduce the costs that deter many users from changing the settings; and 3)
further research to explore privacy concerns in non-Western cultures.",,"To appear in Proceedings of Human Computer Interaction International
  (HCII) 2024",2024-03-18 19:07:02+00:00,2023-08-20 03:25:18+00:00,"['Eman Alashwali', 'Lorrie Faith Cranor']","['cs.CY', 'cs.CR', 'cs.HC']",cs.CY,,,TRUE
2403.02908v1,http://arxiv.org/abs/2403.02908v1,"Preserving Tangible and Intangible Cultural Heritage: the Cases of
  Volterra and Atari","At first glance, the ruins of the Roman Theatre in the Italian town of
Volterra have little in common with cassette tapes containing Atari games. One
is certainly considered an important historical landmark, while the consensus
on the importance of the other is partial at best. Still, both are remnants of
times vastly different from the present and are at risk of oblivion. Unearthed
architectural structures are exposed to the elements just as the deteriorating
signals stored on magnetic tapes. However, the rate of deterioration is much
faster with the magnetic media, as their life expectancy is counted in decades,
whereas the Roman Theater, which is already in ruin, measures its lifespan in
centuries. Hence, both would benefit from some form of digital preservation and
reconstruction. In this panel, we discuss how to sustainably preserve tangible
and intangible cultural artifacts for future generations.",,"8 pages, including 1 page of bibliography, 9 figures. Panel summary
  to be published in proceedings from 11th Machine Intelligence and Digital
  Interaction MIDI Conference",2024-03-05 12:18:08+00:00,2024-03-05 12:18:08+00:00,"['Maciej Grzeszczuk', 'Kinga Skorupska', 'PaweÅ Grabarczyk', 'WÅadysÅaw Fuchs', 'Paul F. Aubin', 'Mark E. Dietrick', 'Barbara Karpowicz', 'RafaÅ MasÅyk', 'Pavlo Zinevych', 'Wiktor Stawski', 'StanisÅaw KnapiÅski', 'WiesÅaw KopeÄ']","['cs.CY', 'cs.DL', 'cs.HC']",cs.CY,,,TRUE
2310.06155v3,http://arxiv.org/abs/2310.06155v3,CoQuest: Exploring Research Question Co-Creation with an LLM-based Agent,"Developing novel research questions (RQs) often requires extensive literature
reviews, especially in interdisciplinary fields. To support RQ development
through human-AI co-creation, we leveraged Large Language Models (LLMs) to
build an LLM-based agent system named CoQuest. We conducted an experiment with
20 HCI researchers to examine the impact of two interaction designs:
breadth-first and depth-first RQ generation. The findings revealed that
participants perceived the breadth-first approach as more creative and
trustworthy upon task completion. Conversely, during the task, participants
considered the depth-first generated RQs as more creative. Additionally, we
discovered that AI processing delays allowed users to reflect on multiple RQs
simultaneously, leading to a higher quantity of generated RQs and an enhanced
sense of control. Our work makes both theoretical and practical contributions
by proposing and evaluating a mental model for human-AI co-creation of RQs. We
also address potential ethical issues, such as biases and over-reliance on AI,
advocating for using the system to improve human research creativity rather
than automating scientific inquiry.","breadth-first,depth-first RQ generation",Accepted to SIGCHI 2024,2024-03-20 20:43:03+00:00,2023-10-09 21:05:27+00:00,"['Yiren Liu', 'Si Chen', 'Haocong Cheng', 'Mengxia Yu', 'Xiao Ran', 'Andrew Mo', 'Yiliu Tang', 'Yun Huang']","['cs.HC', 'cs.CE']",cs.HC,,,TRUE
2403.01783v1,http://arxiv.org/abs/2403.01783v1,Towards A Diffractive Analysis of Prompt-Based Generative AI,"Recent developments in prompt-based generative AI has given rise to discourse
surrounding the perceived ethical concerns, economic implications, and
consequences for the future of cultural production. As generative imagery
becomes pervasive in mainstream society, dominated primarily by emerging
industry leaders, we encourage that the role of the CHI community be one of
inquiry; to investigate the numerous ways in which generative AI has the
potential to, and already is, augmenting human creativity. In this paper, we
conducted a diffractive analysis exploring the potential role of prompt-based
interfaces in artists' creative practice. Over a two week period, seven visual
artists were given access to a personalised instance of Stable Diffusion,
fine-tuned on a dataset of their work. In the following diffractive analysis,
we identified two dominant modes adopted by participants, AI for ideation, and
AI for production. We furthermore present a number of ethical design
considerations for the future development of generative AI interfaces.",diffractice analysis,Preprint of paper accepted for CHI 2024,2024-03-04 07:23:49+00:00,2024-03-04 07:23:49+00:00,"['Nina Rajcic', 'Maria Teresa Llano', 'Jon McCormack']","['cs.HC', 'J.5; H.1.2; H.5']",cs.HC,10.1145/3613904.3641971,,TRUE
2403.08940v1,http://arxiv.org/abs/2403.08940v1,"A Virtual Environment for Collaborative Inspection in Additive
  Manufacturing","Additive manufacturing (AM) techniques have been used to enhance the design
and fabrication of complex components for various applications in the medical,
aerospace, energy, and consumer products industries. A defining feature for
many AM parts is the complex internal geometry enabled by the printing process.
However, inspecting these internal structures requires volumetric imaging,
i.e., X-ray CT, leading to the well-known challenge of visualizing complex 3D
geometries using 2D desktop interfaces. Furthermore, existing tools are limited
to single-user systems making it difficult to jointly discuss or share findings
with a larger team, i.e., the designers, manufacturing experts, and evaluation
team. In this work, we present a collaborative virtual reality (VR) for the
exploration and inspection of AM parts. Geographically separated experts can
virtually inspect and jointly discuss data. It also supports VR and non-VR
users, who can be spectators in the VR environment. Various features for data
exploration and inspection are developed and enhanced via real-time
synchronization. We followed usability and interface verification guidelines
using Nielsen's heuristics approach. Furthermore, we conducted exploratory and
semi-structured interviews with domain experts to collect qualitative feedback.
Results reveal potential benefits, applicability, and current limitations. The
proposed collaborative VR environment provides a new basis and opens new
research directions for virtual inspection and team collaboration in AM
settings.","Additive manufacturing (AM),Nielsen's heuristics approach,",Conditionally Accepted - CHI LBW 2024,2024-03-13 20:16:16+00:00,2024-03-13 20:16:16+00:00,"['Vuthea Chheang', 'Brian Thomas Weston', 'Robert William Cerda', 'Brian Au', 'Brian Giera', 'Peer-Timo Bremer', 'Haichao Miao']","['cs.HC', 'cs.DC']",cs.HC,,,TRUE
2403.10851v1,http://arxiv.org/abs/2403.10851v1,"GustosonicSense: Towards understanding the design of playful gustosonic
  eating experiences","The pleasure that often comes with eating can be further enhanced with
intelligent technology, as the field of human-food interaction suggests.
However, knowledge on how to design such pleasure-supporting eating systems is
limited. To begin filling this knowledge gap, we designed ""GustosonicSense"", a
novel gustosonic eating system that utilizes wireless earbuds for sensing
different eating and drinking actions with a machine learning algorithm and
trigger playful sounds as a way to facilitate pleasurable eating experiences.
We present the findings from our design and a study that revealed how we can
support the ""stimulation"", ""hedonism"", and ""reflexivity"" for playful human-food
interactions. Ultimately, with our work, we aim to support interaction
designers in facilitating playful experiences with food.","gustosonic eating system,stimulation,hedonism,reflexivity","To appear at CHI'24: The ACM Conference on Human Factors in Computing
  Systems (CHI), Honolulu, Hawaii, 2024",2024-03-16 08:11:09+00:00,2024-03-16 08:11:09+00:00,"['Yan Wang', 'Humphrey O. Obie', 'Zhuying Li', 'Flora D. Salim', 'John Grundy', ""Florian 'Floyd' Mueller""]","['cs.HC', 'cs.MM']",cs.HC,,,TRUE
2403.04760v1,http://arxiv.org/abs/2403.04760v1,"iScore: Visual Analytics for Interpreting How Language Models
  Automatically Score Summaries","The recent explosion in popularity of large language models (LLMs) has
inspired learning engineers to incorporate them into adaptive educational tools
that automatically score summary writing. Understanding and evaluating LLMs is
vital before deploying them in critical learning environments, yet their
unprecedented size and expanding number of parameters inhibits transparency and
impedes trust when they underperform. Through a collaborative user-centered
design process with several learning engineers building and deploying summary
scoring LLMs, we characterized fundamental design challenges and goals around
interpreting their models, including aggregating large text inputs, tracking
score provenance, and scaling LLM interpretability methods. To address their
concerns, we developed iScore, an interactive visual analytics tool for
learning engineers to upload, score, and compare multiple summaries
simultaneously. Tightly integrated views allow users to iteratively revise the
language in summaries, track changes in the resulting LLM scores, and visualize
model weights at multiple levels of abstraction. To validate our approach, we
deployed iScore with three learning engineers over the course of a month. We
present a case study where interacting with iScore led a learning engineer to
improve their LLM's score accuracy by three percentage points. Finally, we
conducted qualitative interviews with the learning engineers that revealed how
iScore enabled them to understand, evaluate, and build trust in their LLMs
during deployment.",score provenance,"Accepted to IUI 2024. 16 pages, 5 figures, 1 table. For a demo video,
  see https://youtu.be/EYJX-_fQPf0 . For a live demo, visit
  https://adamcoscia.com/papers/iscore/demo/ . The source code is available at
  https://github.com/AdamCoscia/iScore",2024-03-07 18:56:39+00:00,2024-03-07 18:56:39+00:00,"['Adam Coscia', 'Langdon Holmes', 'Wesley Morris', 'Joon Suh Choi', 'Scott Crossley', 'Alex Endert']","['cs.HC', 'cs.AI', 'cs.CY', 'cs.LG']",cs.HC,10.1145/3640543.3645142,,TRUE
2403.09308v1,http://arxiv.org/abs/2403.09308v1,"Enabling Waypoint Generation for Collaborative Robots using LLMs and
  Mixed Reality","Programming a robotic is a complex task, as it demands the user to have a
good command of specific programming languages and awareness of the robot's
physical constraints. We propose a framework that simplifies robot deployment
by allowing direct communication using natural language. It uses large language
models (LLM) for prompt processing, workspace understanding, and waypoint
generation. It also employs Augmented Reality (AR) to provide visual feedback
of the planned outcome. We showcase the effectiveness of our framework with a
simple pick-and-place task, which we implement on a real robot. Moreover, we
present an early concept of expressive robot behavior and skill generation that
can be used to communicate with the user and learn new skills (e.g., object
grasping).","expressive robot behavior,skill generation","Submitted to VLMNM 2024 - Workshop, ICRA 2024. This work has been
  submitted to the IEEE for possible publication. Copyright may be transferred
  without notice, after which this version may no longer be accessible",2024-03-14 11:59:07+00:00,2024-03-14 11:59:07+00:00,"['Cathy Mengying Fang', 'Krzysztof ZieliÅski', 'Pattie Maes', 'Joe Paradiso', 'Bruce Blumberg', 'Mikkel Baun KjÃ¦rgaard']","['cs.HC', 'cs.RO']",cs.HC,,,TRUE
2403.02928v1,http://arxiv.org/abs/2403.02928v1,"User-Driven Adaptation: Tailoring Autonomous Driving Systems with
  Dynamic Preferences","In the realm of autonomous vehicles, dynamic user preferences are critical
yet challenging to accommodate. Existing methods often misrepresent these
preferences, either by overlooking their dynamism or overburdening users as
humans often find it challenging to express their objectives mathematically.
The previously introduced framework, which interprets dynamic preferences as
inherent uncertainty and includes a ``human-on-the-loop'' mechanism enabling
users to give feedback when dissatisfied with system behaviors, addresses this
gap. In this study, we further enhance the approach with a user study of 20
participants, focusing on aligning system behavior with user expectations
through feedback-driven adaptation. The findings affirm the approach's ability
to effectively merge algorithm-driven adjustments with user complaints, leading
to improved participants' subjective satisfaction in autonomous systems.",feedback-driven adaptation,accepted by CHI LBW 2024,2024-03-05 12:44:54+00:00,2024-03-05 12:44:54+00:00,"['Mingyue Zhang', 'Jialong Li', 'Nianyu Li', 'Eunsuk Kang', 'Kenji Tei']","['cs.HC', 'cs.SE']",cs.HC,,,TRUE
2403.07997v1,http://arxiv.org/abs/2403.07997v1,"Fast-Forward Reality: Authoring Error-Free Context-Aware Policies with
  Real-Time Unit Tests in Extended Reality","Advances in ubiquitous computing have enabled end-user authoring of
context-aware policies (CAPs) that control smart devices based on specific
contexts of the user and environment. However, authoring CAPs accurately and
avoiding run-time errors is challenging for end-users as it is difficult to
foresee CAP behaviors under complex real-world conditions. We propose
Fast-Forward Reality, an Extended Reality (XR) based authoring workflow that
enables end-users to iteratively author and refine CAPs by validating their
behaviors via simulated unit test cases. We develop a computational approach to
automatically generate test cases based on the authored CAP and the user's
context history. Our system delivers each test case with immersive
visualizations in XR, facilitating users to verify the CAP behavior and
identify necessary refinements. We evaluated Fast-Forward Reality in a user
study (N=12). Our authoring and validation process improved the accuracy of
CAPs and the users provided positive feedback on the system usability.",context-aware policies,"17 pages, 7 figures, ACM CHI 2024 Full Paper",2024-03-12 18:05:38+00:00,2024-03-12 18:05:38+00:00,"['Xun Qian', 'Tianyi Wang', 'Xuhai Xu', 'Tanya R Jonker', 'Kashyap Todi']","['cs.HC', 'H.5.2']",cs.HC,10.1145/3613904.3642158,,TRUE
2403.06267v1,http://arxiv.org/abs/2403.06267v1,"FARPLS: A Feature-Augmented Robot Trajectory Preference Labeling System
  to Assist Human Labelers' Preference Elicitation","Preference-based learning aims to align robot task objectives with human
values. One of the most common methods to infer human preferences is by
pairwise comparisons of robot task trajectories. Traditional comparison-based
preference labeling systems seldom support labelers to digest and identify
critical differences between complex trajectories recorded in videos. Our
formative study (N = 12) suggests that individuals may overlook non-salient
task features and establish biased preference criteria during their preference
elicitation process because of partial observations. In addition, they may
experience mental fatigue when given many pairs to compare, causing their label
quality to deteriorate. To mitigate these issues, we propose FARPLS, a
Feature-Augmented Robot trajectory Preference Labeling System. FARPLS
highlights potential outliers in a wide variety of task features that matter to
humans and extracts the corresponding video keyframes for easy review and
comparison. It also dynamically adjusts the labeling order according to users'
familiarities, difficulties of the trajectory pair, and level of disagreements.
At the same time, the system monitors labelers' consistency and provides
feedback on labeling progress to keep labelers engaged. A between-subjects
study (N = 42, 105 pairs of robot pick-and-place trajectories per person) shows
that FARPLS can help users establish preference criteria more easily and notice
more relevant details in the presented trajectories than the conventional
interface. FARPLS also improves labeling consistency and engagement, mitigating
challenges in preference elicitation without raising cognitive loads
significantly",robot task trajectories,"Accepted to ACM Conference on Intelligent User Interfaces (IUI) 2024,
  March 18-21, 2024, Greenville, SC, USA",2024-03-10 17:07:20+00:00,2024-03-10 17:07:20+00:00,"['Hanfang Lyu', 'Yuanchen Bai', 'Xin Liang', 'Ujaan Das', 'Chuhan Shi', 'Leiliang Gong', 'Yingchi Li', 'Mingfei Sun', 'Ming Ge', 'Xiaojuan Ma']","['cs.HC', 'cs.AI']",cs.HC,10.1145/3640543.3645145,,TRUE
2403.06039v1,http://arxiv.org/abs/2403.06039v1,"A Preliminary Exploration of YouTubers' Use of Generative-AI in Content
  Creation","Content creators increasingly utilize generative artificial intelligence
(Gen-AI) on platforms such as YouTube, TikTok, Instagram, and various blogging
sites to produce imaginative images, AI-generated videos, and articles using
Large Language Models (LLMs). Despite its growing popularity, there remains an
underexplored area concerning the specific domains where AI-generated content
is being applied, and the methodologies content creators employ with Gen-AI
tools during the creation process. This study initially explores this emerging
area through a qualitative analysis of 68 YouTube videos demonstrating Gen-AI
usage. Our research focuses on identifying the content domains, the variety of
tools used, the activities performed, and the nature of the final products
generated by Gen-AI in the context of user-generated content.",,Accepted at CHI LBW 2024,2024-03-09 23:22:56+00:00,2024-03-09 23:22:56+00:00,"['Yao Lyu', 'He Zhang', 'Shuo Niu', 'Jie Cai']","['cs.HC', 'cs.AI']",cs.HC,10.1145/3613905.3651057,,TRUE
2403.06823v2,http://arxiv.org/abs/2403.06823v2,"Transparent AI Disclosure Obligations: Who, What, When, Where, Why, How","Advances in Generative Artificial Intelligence (AI) are resulting in
AI-generated media output that is (nearly) indistinguishable from human-created
content. This can drastically impact users and the media sector, especially
given global risks of misinformation. While the currently discussed European AI
Act aims at addressing these risks through Article 52's AI transparency
obligations, its interpretation and implications remain unclear. In this early
work, we adopt a participatory AI approach to derive key questions based on
Article 52's disclosure obligations. We ran two workshops with researchers,
designers, and engineers across disciplines (N=16), where participants
deconstructed Article 52's relevant clauses using the 5W1H framework. We
contribute a set of 149 questions clustered into five themes and 18 sub-themes.
We believe these can not only help inform future legal developments and
interpretations of Article 52, but also provide a starting point for
Human-Computer Interaction research to (re-)examine disclosure transparency
from a human-centered AI lens.",5W1H framework,Accepted to CHI 2024 Late-Breaking Work,2024-03-13 08:40:33+00:00,2024-03-11 15:40:36+00:00,"['Abdallah El Ali', 'Karthikeya Puttur Venkatraj', 'Sophie Morosoli', 'Laurens Naudts', 'Natali Helberger', 'Pablo Cesar']","['cs.HC', 'cs.CY', 'H.5.m']",cs.HC,10.1145/3613905.3650750,,TRUE
2402.09494v2,http://arxiv.org/abs/2402.09494v2,Can AI and humans genuinely communicate?,"Can AI and humans genuinely communicate? In this article, after giving some
background and motivating my proposal (sections 1 to 3), I explore a way to
answer this question that I call the ""mental-behavioral methodology"" (sections
4 and 5). This methodology follows the following three steps: First, spell out
what mental capacities are sufficient for human communication (as opposed to
communication more generally). Second, spell out the experimental paradigms
required to test whether a behavior exhibits these capacities. Third, apply or
adapt these paradigms to test whether an AI displays the relevant behaviors. If
the first two steps are successfully completed, and if the AI passes the tests
with human-like results, this constitutes evidence that this AI and humans can
genuinely communicate. This mental-behavioral methodology has the advantage
that we don't need to understand the workings of black-box algorithms, such as
standard deep neural networks. This is comparable to the fact that we don't
need to understand how human brains work to know that humans can genuinely
communicate. This methodology also has its disadvantages and I will discuss
some of them (section 6).",,March 2024 preprint,2024-03-25 16:32:44+00:00,2024-02-14 13:00:40+00:00,['Constant Bonard'],"['cs.HC', 'cs.AI']",cs.HC,,,TRUE
2403.06431v1,http://arxiv.org/abs/2403.06431v1,"From Fitting Participation to Forging Relationships: The Art of
  Participatory ML","Participatory machine learning (ML) encourages the inclusion of end users and
people affected by ML systems in design and development processes. We
interviewed 18 participation brokers -- individuals who facilitate such
inclusion and transform the products of participants' labour into inputs for an
ML artefact or system -- across a range of organisational settings and project
locations. Our findings demonstrate the inherent challenges of integrating
messy contextual information generated through participation with the
structured data formats required by ML workflows and the uneven power dynamics
in project contexts. We advocate for evolution in the role of brokers to more
equitably balance value generated in Participatory ML projects for design and
development teams with value created for participants. To move beyond `fitting'
participation to existing processes and empower participants to envision
alternative futures through ML, brokers must become educators and advocates for
end users, while attending to frustration and dissent from indirect
stakeholders.",,"To appear in Proceedings of the 2024 CHI Conference on Human Factors
  in Computing Systems (CHI '24)",2024-03-11 04:44:34+00:00,2024-03-11 04:44:34+00:00,"['Ned Cooper', 'Alex Zafiroglu']","['cs.HC', 'cs.CY']",cs.HC,,,TRUE
2403.06034v1,http://arxiv.org/abs/2403.06034v1,"Content Moderation Justice and Fairness on Social Media: Comparisons
  Across Different Contexts and Platforms","Social media users may perceive moderation decisions by the platform
differently, which can lead to frustration and dropout. This study investigates
users' perceived justice and fairness of online moderation decisions when they
are exposed to various illegal versus legal scenarios, retributive versus
restorative moderation strategies, and user-moderated versus commercially
moderated platforms. We conduct an online experiment on 200 American social
media users of Reddit and Twitter. Results show that retributive moderation
delivers higher justice and fairness for commercially moderated than for
user-moderated platforms in illegal violations; restorative moderation delivers
higher fairness for legal violations than illegal ones. We discuss the
opportunities for platform policymaking to improve moderation system design.","retributive,restorative moderation strategies",Accepted by CHI LBW 2024,2024-03-09 22:50:06+00:00,2024-03-09 22:50:06+00:00,"['Jie Cai', 'Aashka Patel', 'Azadeh Naderi', 'Donghee Yvette Wohn']","['cs.HC', 'cs.CY']",cs.HC,10.1145/3613905.3650882,,TRUE
2403.06651v1,http://arxiv.org/abs/2403.06651v1,"SoniWeight Shoes: Investigating Effects and Personalization of a
  Wearable Sound Device for Altering Body Perception and Behavior","Changes in body perception influence behavior and emotion and can be induced
through multisensory feedback. Auditory feedback to one's actions can trigger
such alterations; however, it is unclear which individual factors modulate
these effects. We employ and evaluate SoniWeight Shoes, a wearable device based
on literature for altering one's weight perception through manipulated footstep
sounds. In a healthy population sample across a spectrum of individuals (n=84)
with varying degrees of eating disorder symptomatology, physical activity
levels, body concerns, and mental imagery capacities, we explore the effects of
three sound conditions (low-frequency, high-frequency and control) on extensive
body perception measures (demographic, behavioral, physiological,
psychological, and subjective). Analyses revealed an impact of individual
differences in each of these dimensions. Besides replicating previous findings,
we reveal and highlight the role of individual differences in body perception,
offering avenues for personalized sonification strategies. Datasets, technical
refinements, and novel body map quantification tools are provided.",,Conditionally Accepted in CHI '24 Conference,2024-03-11 12:16:14+00:00,2024-03-11 12:16:14+00:00,"[""A. D'Adamo"", 'M. Roel-Lesur', 'L. Turmo-Vidal', 'M. M. Dehshibi', 'D. De La Prida', 'J. R. Diaz-Duran', 'L. A. Azpicueta-Ruiz', 'A. VÃ¤ljamÃ¤e', 'A. Tajadura-JimÃ©nez']",['cs.HC'],cs.HC,10.1145/3613904.3642651,,TRUE
2403.08041v1,http://arxiv.org/abs/2403.08041v1,"What would Plato say? Concepts and notions from Greek philosophy applied
  to gamification mechanics for a meaningful and ethical gamification","Gamification, the integration of game mechanics in non-game settings, has
become increasingly prevalent in various digital platforms; however, its
ethical and societal impacts are often overlooked. This paper delves into how
Platonic and Aristotelian philosophies can provide a critical framework for
understanding and evaluating the ethical dimensions of gamification. Plato's
allegory of the cave and theory of forms are used to analyse the perception of
reality in gamified environments, questioning their authenticity and the value
of virtual achievements, while Aristotle's virtue ethics, with its emphasis on
moderation, virtue, and eudaimonia (true and full happiness), can help assess
how gamification influences user behaviour and ethical decision-making. The
paper critically examines various gamification elements, such as the hero's
journey, altruistic actions, badge levels, and user autonomy, through these
philosophical lenses, and addresses the ethical responsibilities of
gamification designers, advocating for a balanced approach that prioritizes
user well-being and ethical development over commercial interests. By bridging
ancient philosophical insights with modern digital culture, this research
contributes to a deeper understanding of the ethical implications of
gamification, emphasizing the need for responsible and virtuous design in
digital applications.",,Accepted for presentation at GamiFIN 2024,2024-03-12 19:25:13+00:00,2024-03-12 19:25:13+00:00,['Kostas Karpouzis'],['cs.HC'],cs.HC,,,TRUE
2403.12344v1,http://arxiv.org/abs/2403.12344v1,"Human Factors in Space Exploration: Opportunities for International and
  Interdisciplinary Collaboration","As humanity pushes the boundaries of space exploration, human factors
research becomes more important. Human factors encompass a broad spectrum of
psychological, physiological, and ergonomic factors that affect human
performance, well-being, and safety in the unique and challenging space
environment. This panel explores the multifaceted field of human factors in
space exploration and highlights the opportunities that lie in fostering
international and interdisciplinary cooperation. This exploration delves into
the current state of research on human factors in space missions, addressing
the physiological and psychological challenges astronauts face during long
space flights. It emphasizes the importance of interdisciplinary collaboration,
combining knowledge from fields such as psychology, medicine, engineering, and
design to address the complex interaction of factors affecting human
performance and adaptation to the space environment",,"13 pages including bibliography, 4 figures. To be published by
  Springer as MIDI 2023 Conference proceedings",2024-03-19 01:27:15+00:00,2024-03-19 01:27:15+00:00,"['WiesÅaw KopeÄ', 'Grzegorz Pochwatko', 'Monika Kornacka', 'Wiktor Stawski', 'Maciej Grzeszczuk', 'Kinga Skorupska', 'Barbara Karpowicz', 'RafaÅ MasÅyk', 'Pavlo Zinevych', 'StanisÅaw KnapiÅski', 'Steven Barnes', 'Cezary Biele']",['cs.HC'],cs.HC,,,TRUE
2403.19436v1,http://arxiv.org/abs/2403.19436v1,"""At the end of the day, I am accountable"": Gig Workers' Self-Tracking
  for Multi-Dimensional Accountability Management","Tracking is inherent in and central to the gig economy. Platforms track gig
workers' performance through metrics such as acceptance rate and punctuality,
while gig workers themselves engage in self-tracking. Although prior research
has extensively examined how gig platforms track workers through metrics --
with some studies briefly acknowledging the phenomenon of self-tracking among
workers -- there is a dearth of studies that explore how and why gig workers
track themselves. To address this, we conducted 25 semi-structured interviews,
revealing how gig workers self-tracking to manage accountabilities to
themselves and external entities across three identities: the holistic self,
the entrepreneurial self, and the platformized self. We connect our findings to
neoliberalism, through which we contextualize gig workers' self-accountability
and the invisible labor of self-tracking. We further discuss how self-tracking
mitigates information and power asymmetries in gig work and offer design
implications to support gig workers' multi-dimensional self-tracking.",,Accepted to CHI 2024,2024-03-28 14:04:30+00:00,2024-03-28 14:04:30+00:00,"['Rie Helene Hernandez', 'Qiurong Song', 'Yubo Kou', 'Xinning Gui']",['cs.HC'],cs.HC,,,TRUE
2401.10838v2,http://arxiv.org/abs/2401.10838v2,"Rambler: Supporting Writing With Speech via LLM-Assisted Gist
  Manipulation","Dictation enables efficient text input on mobile devices. However, writing
with speech can produce disfluent, wordy, and incoherent text and thus requires
heavy post-processing. This paper presents Rambler, an LLM-powered graphical
user interface that supports gist-level manipulation of dictated text with two
main sets of functions: gist extraction and macro revision. Gist extraction
generates keywords and summaries as anchors to support the review and
interaction with spoken text. LLM-assisted macro revisions allow users to
respeak, split, merge and transform dictated text without specifying precise
editing locations. Together they pave the way for interactive dictation and
revision that help close gaps between spontaneous spoken words and
well-structured writing. In a comparative study with 12 participants performing
verbal composition tasks, Rambler outperformed the baseline of a speech-to-text
editor + ChatGPT, as it better facilitates iterative revisions with enhanced
user control over the content while supporting surprisingly diverse user
strategies.",gist-level manipulation,To appear at ACM CHI 2024,2024-03-08 02:46:05+00:00,2024-01-19 17:39:56+00:00,"['Susan Lin', 'Jeremy Warner', 'J. D. Zamfirescu-Pereira', 'Matthew G. Lee', 'Sauhard Jain', 'Michael Xuelin Huang', 'Piyawat Lertvittayakumjorn', 'Shanqing Cai', 'Shumin Zhai', 'BjÃ¶rn Hartmann', 'Can Liu']",['cs.HC'],cs.HC,10.1145/3613904.3642217,,TRUE
2403.16018v1,http://arxiv.org/abs/2403.16018v1,"Understanding the Impact of Referent Design on Scale Perception in
  Immersive Data Visualization","Referents are often used to enhance scale perception in immersive
visualizations. Common referent designs include the considerations of referent
layout (side-by-side vs. in-situ) and referent size (small vs. medium vs.
large). This paper introduces a controlled user study to assess how different
referent designs affect the efficiency and accuracy of scale perception across
different data scales, on the performance of the size-matching task in the
virtual environment. Our results reveal that in-situ layouts significantly
enhance accuracy and confidence across various data scales, particularly with
large referents. Linear regression analyses further confirm that in-situ
layouts exhibit greater resilience to changes in data scale. For tasks
requiring efficiency, medium-sized referents emerge as the preferred choice.
Based on these findings, we offer design guidelines for selecting referent
layouts and sizes in immersive visualizations.",,"7 pages, 6 figures, Accepted to Extended Abstracts of the CHI
  Conference on Human Factors in Computing Systems (CHI EA '24)",2024-03-24 05:38:29+00:00,2024-03-24 05:38:29+00:00,"['Yihan Hou', 'Hao Cui', 'Rongrong Chen', 'Wei Zeng']",['cs.HC'],cs.HC,10.1145/3613905.3650783,,TRUE
2403.03822v1,http://arxiv.org/abs/2403.03822v1,"HoLens: A Visual Analytics Design for Higher-order Movement Modeling and
  Visualization","Higher-order patterns reveal sequential multistep state transitions, which
are usually superior to origin-destination analysis, which depicts only
first-order geospatial movement patterns. Conventional methods for higher-order
movement modeling first construct a directed acyclic graph (DAG) of movements,
then extract higher-order patterns from the DAG. However, DAG-based methods
heavily rely on the identification of movement keypoints that are challenging
for sparse movements and fail to consider the temporal variants that are
critical for movements in urban environments. To overcome the limitations, we
propose HoLens, a novel approach for modeling and visualizing higher-order
movement patterns in the context of an urban environment. HoLens mainly makes
twofold contributions: first, we design an auto-adaptive movement aggregation
algorithm that self-organizes movements hierarchically by considering spatial
proximity, contextual information, and temporal variability; second, we develop
an interactive visual analytics interface consisting of well-established
visualization techniques, including the H-Flow for visualizing the higher-order
patterns on the map and the higher-order state sequence chart for representing
the higher-order state transitions. Two real-world case studies manifest that
the method can adaptively aggregate the data and exhibit the process of how to
explore the higher-order patterns by HoLens. We also demonstrate our approach's
feasibility, usability, and effectiveness through an expert interview with
three domain experts.","sequential multistep state transitions,origin-destination analysis,auto-adaptive movement aggregation
algorithm,H-Flow","20 pages, 18 figures, is accepted by computational visual media
  journal",2024-03-06 16:08:51+00:00,2024-03-06 16:08:51+00:00,"['Zezheng Feng', 'Fang Zhu', 'Hongjun Wang', 'Jianing Hao', 'ShuangHua Yang', 'Wei Zeng', 'Huamin Qu']",['cs.HC'],cs.HC,,,TRUE
2403.08057v1,http://arxiv.org/abs/2403.08057v1,MineXR: Mining Personalized Extended Reality Interfaces,"Extended Reality (XR) interfaces offer engaging user experiences, but their
effective design requires a nuanced understanding of user behavior and
preferences. This knowledge is challenging to obtain without the widespread
adoption of XR devices. We introduce MineXR, a design mining workflow and data
analysis platform for collecting and analyzing personalized XR user interaction
and experience data. MineXR enables elicitation of personalized interfaces from
participants of a data collection: for any particular context, participants
create interface elements using application screenshots from their own
smartphone, place them in the environment, and simultaneously preview the
resulting XR layout on a headset. Using MineXR, we contribute a dataset of
personalized XR interfaces collected from 31 participants, consisting of 695 XR
widgets created from 178 unique applications. We provide insights for XR widget
functionalities, categories, clusters, UI element types, and placement. Our
open-source tools and data support researchers and designers in developing
future XR interfaces.",,"17 pages, 18 figures, Proceedings of the 2024 CHI Conference on Human
  Factors in Computing Systems",2024-03-12 20:05:14+00:00,2024-03-12 20:05:14+00:00,"['Hyunsung Cho', 'Yukang Yan', 'Kashyap Todi', 'Mark Parent', 'Missie Smith', 'Tanya R. Jonker', 'Hrvoje Benko', 'David Lindlbauer']","['cs.HC', 'H.5.2']",cs.HC,10.1145/3613904.3642394,,TRUE
2403.12730v1,http://arxiv.org/abs/2403.12730v1,"What Does Evaluation of Explainable Artificial Intelligence Actually
  Tell Us? A Case for Compositional and Contextual Validation of XAI Building
  Blocks","Despite significant progress, evaluation of explainable artificial
intelligence remains elusive and challenging. In this paper we propose a
fine-grained validation framework that is not overly reliant on any one facet
of these sociotechnical systems, and that recognises their inherent modular
structure: technical building blocks, user-facing explanatory artefacts and
social communication protocols. While we concur that user studies are
invaluable in assessing the quality and effectiveness of explanation
presentation and delivery strategies from the explainees' perspective in a
particular deployment context, the underlying explanation generation mechanisms
require a separate, predominantly algorithmic validation strategy that accounts
for the technical and human-centred desiderata of their (numerical) outputs.
Such a comprehensive sociotechnical utility-based evaluation framework could
allow to systematically reason about the properties and downstream influence of
different building blocks from which explainable artificial intelligence
systems are composed -- accounting for a diverse range of their engineering and
social aspects -- in view of the anticipated use case.",,"Published in Extended Abstracts of the 2024 CHI Conference on Human
  Factors in Computing Systems (CHI EA '24)",2024-03-19 13:45:34+00:00,2024-03-19 13:45:34+00:00,"['Kacper Sokol', 'Julia E. Vogt']","['cs.HC', 'cs.AI']",cs.HC,10.1145/3613905.3651047,,TRUE
2403.18173v1,http://arxiv.org/abs/2403.18173v1,"LLMs in HCI Data Work: Bridging the Gap Between Information Retrieval
  and Responsible Research Practices","Efficient and accurate information extraction from scientific papers is
significant in the rapidly developing human-computer interaction research in
the literature review process. Our paper introduces and analyses a new
information retrieval system using state-of-the-art Large Language Models
(LLMs) in combination with structured text analysis techniques to extract
experimental data from HCI literature, emphasizing key elements. Then We
analyze the challenges and risks of using LLMs in the world of research. We
performed a comprehensive analysis on our conducted dataset, which contained
the specified information of 300 CHI 2020-2022 papers, to evaluate the
performance of the two large language models, GPT-3.5 (text-davinci-003) and
Llama-2-70b, paired with structured text analysis techniques. The GPT-3.5 model
gains an accuracy of 58\% and a mean absolute error of 7.00. In contrast, the
Llama2 model indicates an accuracy of 56\% with a mean absolute error of 7.63.
The ability to answer questions was also included in the system in order to
work with streamlined data. By evaluating the risks and opportunities presented
by LLMs, our work contributes to the ongoing dialogue on establishing
methodological validity and ethical guidelines for LLM use in HCI data work.",,"5 pages, CHI2024 Workshop on LLMs as Research Tools: Applications and
  Evaluations in HCI Data Work",2024-03-27 01:01:09+00:00,2024-03-27 01:01:09+00:00,"['Neda Taghizadeh Serajeh', 'Iman Mohammadi', 'Vittorio Fuccella', 'Mattia De Rosa']","['cs.HC', 'cs.IR']",cs.HC,,,TRUE
2403.01697v1,http://arxiv.org/abs/2403.01697v1,"Dismantling Gender Blindness in Online Discussion of a Crime/Gender
  Dichotomy","Contemporary feminists utilize social media for activism, while backlashes
come along. The gender-related discourses are often diminished when addressing
public events regarding sexism and gender inequality on social media platforms.
The dichotomized debate around the Tangshan beating incident in China
epitomized how criminal interpretations of gender-related violence became a
backlash against feminist expressions. By analyzing posts on Weibo using mixed
methods, we describe the emerging discursive patterns around crime and gender,
uncovering the inherent gender-blind sexism that refutes feminist discourses on
the social platform. We also highlight the critical restrictions facing
grassroots feminist activism in Chinese cyberspace and propose implications for
the design and research related to digital feminist activism.",,"31 pages, 3 figures, Accepted for publication in Proceedings of the
  ACM on Human-Computer Interaction (CSCW 2024)",2024-03-04 03:17:54+00:00,2024-03-04 03:17:54+00:00,"['Yigang Qin', 'Weilun Duan', 'Qunfang Wu', 'Zhicong Lu']",['cs.HC'],cs.HC,,,TRUE
2403.01055v1,http://arxiv.org/abs/2403.01055v1,"Towards Full Authorship with AI: Supporting Revision with AI-Generated
  Views","Large language models (LLMs) are shaping a new user interface (UI) paradigm
in writing tools by enabling users to generate text through prompts. This
paradigm shifts some creative control from the user to the system, thereby
diminishing the user's authorship and autonomy in the writing process. To
restore autonomy, we introduce Textfocals, a UI prototype designed to
investigate a human-centered approach that emphasizes the user's role in
writing. Textfocals supports the writing process by providing LLM-generated
summaries, questions, and advice (i.e., LLM views) in a sidebar of a text
editor, encouraging reflection and self-driven revision in writing without
direct text generation. Textfocals' UI affordances, including contextually
adaptive views and scaffolding for prompt selection and customization, offer a
novel way to interact with LLMs where users maintain full authorship of their
writing. A formative user study with Textfocals showed promising evidence that
this approach might help users develop underdeveloped ideas, cater to the
rhetorical audience, and clarify their writing. However, the study also showed
interaction design challenges related to document navigation and scoping,
prompt engineering, and context management. Our work highlights the breadth of
the design space of writing support interfaces powered by generative AI that
maintain authorship integrity.",,"15 pages, 2 figures; Accepted to 5th Workshop on Human-AI Co-Creation
  with Generative Models (HAI-GEN) at ACM IUI 2024",2024-03-02 01:11:35+00:00,2024-03-02 01:11:35+00:00,"['Jiho Kim', 'Ray C. Flanagan', 'Noelle E. Haviland', 'ZeAi Sun', 'Souad N. Yakubu', 'Edom A. Maru', 'Kenneth C. Arnold']","['cs.HC', 'cs.AI', 'cs.CY', 'H.5.2; I.7.1; I.2.7']",cs.HC,,,TRUE
2305.11927v2,http://arxiv.org/abs/2305.11927v2,"Evaluating how interactive visualizations can assist in finding samples
  where and how computer vision models make mistakes","Creating Computer Vision (CV) models remains a complex practice, despite
their ubiquity. Access to data, the requirement for ML expertise, and model
opacity are just a few points of complexity that limit the ability of end-users
to build, inspect, and improve these models. Interactive ML perspectives have
helped address some of these issues by considering a teacher in the loop where
planning, teaching, and evaluating tasks take place. We present and evaluate
two interactive visualizations in the context of Sprite, a system for creating
CV classification and detection models for images originating from videos. We
study how these visualizations help Sprite's users identify (evaluate) and
select (plan) images where a model is struggling and can lead to improved
performance, compared to a baseline condition where users used a query
language. We found that users who had used the visualizations found more images
across a wider set of potential types of model errors.",,"Hayeong Song, Gonzalo Ramos, and Peter Bodik. ""Evaluating how
  interactive visualizations can assist in finding samples where and how
  computer vision models make mistakes"" 2024 IEEE Pacific Visualization
  Symposium (PacificVis). Ieee, 2024",2024-03-15 18:23:16+00:00,2023-05-19 14:43:00+00:00,"['Hayeong Song', 'Gonzalo Ramos', 'Peter Bodik']","['cs.HC', 'cs.CV', 'cs.LG']",cs.HC,,,TRUE
2403.00632v1,http://arxiv.org/abs/2403.00632v1,"Metamorpheus: Interactive, Affective, and Creative Dream Narration
  Through Metaphorical Visual Storytelling","Human emotions are essentially molded by lived experiences, from which we
construct personalised meaning. The engagement in such meaning-making process
has been practiced as an intervention in various psychotherapies to promote
wellness. Nevertheless, to support recollecting and recounting lived
experiences in everyday life remains under explored in HCI. It also remains
unknown how technologies such as generative AI models can facilitate the
meaning making process, and ultimately support affective mindfulness. In this
paper we present Metamorpheus, an affective interface that engages users in a
creative visual storytelling of emotional experiences during dreams.
Metamorpheus arranges the storyline based on a dream's emotional arc, and
provokes self-reflection through the creation of metaphorical images and text
depictions. The system provides metaphor suggestions, and generates visual
metaphors and text depictions using generative AI models, while users can apply
generations to recolour and re-arrange the interface to be visually affective.
Our experience-centred evaluation manifests that, by interacting with
Metamorpheus, users can recall their dreams in vivid detail, through which they
relive and reflect upon their experiences in a meaningful way.",affective interface,Accepted by CHI 2024,2024-03-01 16:09:32+00:00,2024-03-01 16:09:32+00:00,"['Qian Wan', 'Xin Feng', 'Yining Bei', 'Zhiqi Gao', 'Zhicong Lu']","['cs.HC', 'cs.AI', 'cs.CL', 'cs.CY']",cs.HC,,,TRUE
2309.15723v2,http://arxiv.org/abs/2309.15723v2,"Where Are We So Far? Understanding Data Storytelling Tools from the
  Perspective of Human-AI Collaboration","Data storytelling is powerful for communicating data insights, but it
requires diverse skills and considerable effort from human creators. Recent
research has widely explored the potential for artificial intelligence (AI) to
support and augment humans in data storytelling. However, there lacks a
systematic review to understand data storytelling tools from the perspective of
human-AI collaboration, which hinders researchers from reflecting on the
existing collaborative tool designs that promote humans' and AI's advantages
and mitigate their shortcomings. This paper investigated existing tools with a
framework from two perspectives: the stages in the storytelling workflow where
a tool serves, including analysis, planning, implementation, and communication,
and the roles of humans and AI in each stage, such as creators, assistants,
optimizers, and reviewers. Through our analysis, we recognize the common
collaboration patterns in existing tools, summarize lessons learned from these
patterns, and further illustrate research opportunities for human-AI
collaboration in data storytelling.",,Accepted by CHI 2024,2024-03-18 13:00:17+00:00,2023-09-27 15:30:50+00:00,"['Haotian Li', 'Yun Wang', 'Huamin Qu']","['cs.HC', 'cs.AI']",cs.HC,,,TRUE