{"0":{"arxiv_id":"2403.16190v1","url":"http:\/\/arxiv.org\/abs\/2403.16190v1","title":"Logic-based Explanations for Linear Support Vector Classifiers with\n  Reject Option","summary":"Support Vector Classifier (SVC) is a well-known Machine Learning (ML) model\nfor linear classification problems. It can be used in conjunction with a reject\noption strategy to reject instances that are hard to correctly classify and\ndelegate them to a specialist. This further increases the confidence of the\nmodel. Given this, obtaining an explanation of the cause of rejection is\nimportant to not blindly trust the obtained results. While most of the related\nwork has developed means to give such explanations for machine learning models,\nto the best of our knowledge none have done so for when reject option is\npresent. We propose a logic-based approach with formal guarantees on the\ncorrectness and minimality of explanations for linear SVCs with reject option.\nWe evaluate our approach by comparing it to Anchors, which is a heuristic\nalgorithm for generating explanations. Obtained results show that our proposed\nmethod gives shorter explanations with reduced time cost.","updated":1711293284000,"published":1711293284000,"authors":["Francisco Mateus Rocha Filho","Thiago Alves Rocha","Reginaldo Pereira Fernandes Ribeiro","Ajalmar R\u00eago da Rocha Neto"],"comments":"16 pages, submitted to BRACIS 2023 (Brazilian Conference on\n  Intelligent Systems), accepted version published in Intelligent Systems,\n  LNCS, vol 14195","categories":["cs.AI","cs.LG","cs.LO","I.2.4; I.2.6"],"primary_category":"cs.AI","doi":"10.1007\/978-3-031-45368-7_10","journal_ref":null,"peer_reviewed":true,"reader_id":"rid1","human_jargon_term":"Anchors","definition_text":"Anchors is an algorithm used to explain the decisions made by a machine learning model by identifying sets of conditions or rules that are highly influential in the model's prediction, providing a clear and understandable rationale for why a specific decision was made.","model":"gpt4_abstract","Accuracy":"accurate","Ranking":0,"Notes":""},"1":{"arxiv_id":"2403.16190v1","url":"http:\/\/arxiv.org\/abs\/2403.16190v1","title":"Logic-based Explanations for Linear Support Vector Classifiers with\n  Reject Option","summary":"Support Vector Classifier (SVC) is a well-known Machine Learning (ML) model\nfor linear classification problems. It can be used in conjunction with a reject\noption strategy to reject instances that are hard to correctly classify and\ndelegate them to a specialist. This further increases the confidence of the\nmodel. Given this, obtaining an explanation of the cause of rejection is\nimportant to not blindly trust the obtained results. While most of the related\nwork has developed means to give such explanations for machine learning models,\nto the best of our knowledge none have done so for when reject option is\npresent. We propose a logic-based approach with formal guarantees on the\ncorrectness and minimality of explanations for linear SVCs with reject option.\nWe evaluate our approach by comparing it to Anchors, which is a heuristic\nalgorithm for generating explanations. Obtained results show that our proposed\nmethod gives shorter explanations with reduced time cost.","updated":1711293284000,"published":1711293284000,"authors":["Francisco Mateus Rocha Filho","Thiago Alves Rocha","Reginaldo Pereira Fernandes Ribeiro","Ajalmar R\u00eago da Rocha Neto"],"comments":"16 pages, submitted to BRACIS 2023 (Brazilian Conference on\n  Intelligent Systems), accepted version published in Intelligent Systems,\n  LNCS, vol 14195","categories":["cs.AI","cs.LG","cs.LO","I.2.4; I.2.6"],"primary_category":"cs.AI","doi":"10.1007\/978-3-031-45368-7_10","journal_ref":null,"peer_reviewed":true,"reader_id":"rid1","human_jargon_term":"heuristic algorithm","definition_text":"A heuristic algorithm is a problem-solving method designed to find a good, although not necessarily optimal, solution quickly when traditional methods are too slow or complex. It uses shortcuts and approximations to speed up the process of finding a satisfactory solution.","model":"gpt4_abstract","Accuracy":"accurate","Ranking":2,"Notes":""},"2":{"arxiv_id":"2403.16190v1","url":"http:\/\/arxiv.org\/abs\/2403.16190v1","title":"Logic-based Explanations for Linear Support Vector Classifiers with\n  Reject Option","summary":"Support Vector Classifier (SVC) is a well-known Machine Learning (ML) model\nfor linear classification problems. It can be used in conjunction with a reject\noption strategy to reject instances that are hard to correctly classify and\ndelegate them to a specialist. This further increases the confidence of the\nmodel. Given this, obtaining an explanation of the cause of rejection is\nimportant to not blindly trust the obtained results. While most of the related\nwork has developed means to give such explanations for machine learning models,\nto the best of our knowledge none have done so for when reject option is\npresent. We propose a logic-based approach with formal guarantees on the\ncorrectness and minimality of explanations for linear SVCs with reject option.\nWe evaluate our approach by comparing it to Anchors, which is a heuristic\nalgorithm for generating explanations. Obtained results show that our proposed\nmethod gives shorter explanations with reduced time cost.","updated":1711293284000,"published":1711293284000,"authors":["Francisco Mateus Rocha Filho","Thiago Alves Rocha","Reginaldo Pereira Fernandes Ribeiro","Ajalmar R\u00eago da Rocha Neto"],"comments":"16 pages, submitted to BRACIS 2023 (Brazilian Conference on\n  Intelligent Systems), accepted version published in Intelligent Systems,\n  LNCS, vol 14195","categories":["cs.AI","cs.LG","cs.LO","I.2.4; I.2.6"],"primary_category":"cs.AI","doi":"10.1007\/978-3-031-45368-7_10","journal_ref":null,"peer_reviewed":true,"reader_id":"rid1","human_jargon_term":"reject option strategy","definition_text":"A reject option strategy in machine learning is a method where the system is designed to identify and set aside difficult-to-classify cases. These cases are then typically reviewed by a human expert, helping to ensure that the model remains as accurate and reliable as possible.","model":"gpt4_abstract","Accuracy":"accurate","Ranking":1,"Notes":""},"3":{"arxiv_id":"2307.05300v4","url":"http:\/\/arxiv.org\/abs\/2307.05300v4","title":"Unleashing the Emergent Cognitive Synergy in Large Language Models: A\n  Task-Solving Agent through Multi-Persona Self-Collaboration","summary":"Human intelligence thrives on cognitive synergy, where collaboration among\ndifferent minds yield superior outcomes compared to isolated individuals. In\nthis work, we propose Solo Performance Prompting (SPP), which transforms a\nsingle LLM into a cognitive synergist by engaging in multi-turn\nself-collaboration with multiple personas. A cognitive synergist is an\nintelligent agent that collaboratively combines multiple minds' strengths and\nknowledge to enhance problem-solving in complex tasks. By dynamically\nidentifying and simulating different personas based on task inputs, SPP\nunleashes the potential of cognitive synergy in LLMs. Our in-depth analysis\nshows that assigning multiple fine-grained personas in LLMs improves\nproblem-solving abilities compared to using a single or fixed number of\npersonas. We evaluate SPP on three challenging tasks: Trivia Creative Writing,\nCodenames Collaborative, and Logic Grid Puzzle, encompassing both\nknowledge-intensive and reasoning-intensive types. Unlike previous works, such\nas Chain-of-Thought, that solely enhance the reasoning abilities in LLMs,\nexperimental results demonstrate that SPP effectively reduces factual\nhallucination, and maintains strong reasoning capabilities. Additionally,\ncomparative experiments show that cognitive synergy only emerges in GPT-4 and\ndoes not appear in less capable models, such as GPT-3.5-turbo and\nLlama2-13b-chat, which draws an interesting analogy to human development. Code,\ndata, and prompts can be found at:\nhttps:\/\/github.com\/MikeWangWZHL\/Solo-Performance-Prompting.git.","updated":1711463553000,"published":1689086719000,"authors":["Zhenhailong Wang","Shaoguang Mao","Wenshan Wu","Tao Ge","Furu Wei","Heng Ji"],"comments":"Accepted as a main conference paper at NAACL 2024","categories":["cs.AI","cs.CL"],"primary_category":"cs.AI","doi":null,"journal_ref":null,"peer_reviewed":true,"reader_id":"rid1","human_jargon_term":"Chain-of-Thought","definition_text":"Chain-of-Thought is a method used in language models like GPT-4 to enhance their reasoning abilities by simulating a step-by-step thought process to reach a conclusion, similar to how humans logically think through a problem before answering. This helps the model to better understand and solve complex tasks by breaking them down into manageable parts.","model":"gpt4_abstract","Accuracy":"accurate","Ranking":1,"Notes":""},"4":{"arxiv_id":"2307.05300v4","url":"http:\/\/arxiv.org\/abs\/2307.05300v4","title":"Unleashing the Emergent Cognitive Synergy in Large Language Models: A\n  Task-Solving Agent through Multi-Persona Self-Collaboration","summary":"Human intelligence thrives on cognitive synergy, where collaboration among\ndifferent minds yield superior outcomes compared to isolated individuals. In\nthis work, we propose Solo Performance Prompting (SPP), which transforms a\nsingle LLM into a cognitive synergist by engaging in multi-turn\nself-collaboration with multiple personas. A cognitive synergist is an\nintelligent agent that collaboratively combines multiple minds' strengths and\nknowledge to enhance problem-solving in complex tasks. By dynamically\nidentifying and simulating different personas based on task inputs, SPP\nunleashes the potential of cognitive synergy in LLMs. Our in-depth analysis\nshows that assigning multiple fine-grained personas in LLMs improves\nproblem-solving abilities compared to using a single or fixed number of\npersonas. We evaluate SPP on three challenging tasks: Trivia Creative Writing,\nCodenames Collaborative, and Logic Grid Puzzle, encompassing both\nknowledge-intensive and reasoning-intensive types. Unlike previous works, such\nas Chain-of-Thought, that solely enhance the reasoning abilities in LLMs,\nexperimental results demonstrate that SPP effectively reduces factual\nhallucination, and maintains strong reasoning capabilities. Additionally,\ncomparative experiments show that cognitive synergy only emerges in GPT-4 and\ndoes not appear in less capable models, such as GPT-3.5-turbo and\nLlama2-13b-chat, which draws an interesting analogy to human development. Code,\ndata, and prompts can be found at:\nhttps:\/\/github.com\/MikeWangWZHL\/Solo-Performance-Prompting.git.","updated":1711463553000,"published":1689086719000,"authors":["Zhenhailong Wang","Shaoguang Mao","Wenshan Wu","Tao Ge","Furu Wei","Heng Ji"],"comments":"Accepted as a main conference paper at NAACL 2024","categories":["cs.AI","cs.CL"],"primary_category":"cs.AI","doi":null,"journal_ref":null,"peer_reviewed":true,"reader_id":"rid1","human_jargon_term":"Solo Performance Prompting","definition_text":"Solo Performance Prompting (SPP) is a technique that makes a single language model work as if it were multiple collaborative minds by giving it multiple personalities or roles to adopt depending on the task it's performing. This approach helps the model solve complex problems more effectively by combining different perspectives and types of thinking, much like a team of experts would.","model":"gpt4_abstract","Accuracy":"accurate","Ranking":1,"Notes":""},"5":{"arxiv_id":"2307.05300v4","url":"http:\/\/arxiv.org\/abs\/2307.05300v4","title":"Unleashing the Emergent Cognitive Synergy in Large Language Models: A\n  Task-Solving Agent through Multi-Persona Self-Collaboration","summary":"Human intelligence thrives on cognitive synergy, where collaboration among\ndifferent minds yield superior outcomes compared to isolated individuals. In\nthis work, we propose Solo Performance Prompting (SPP), which transforms a\nsingle LLM into a cognitive synergist by engaging in multi-turn\nself-collaboration with multiple personas. A cognitive synergist is an\nintelligent agent that collaboratively combines multiple minds' strengths and\nknowledge to enhance problem-solving in complex tasks. By dynamically\nidentifying and simulating different personas based on task inputs, SPP\nunleashes the potential of cognitive synergy in LLMs. Our in-depth analysis\nshows that assigning multiple fine-grained personas in LLMs improves\nproblem-solving abilities compared to using a single or fixed number of\npersonas. We evaluate SPP on three challenging tasks: Trivia Creative Writing,\nCodenames Collaborative, and Logic Grid Puzzle, encompassing both\nknowledge-intensive and reasoning-intensive types. Unlike previous works, such\nas Chain-of-Thought, that solely enhance the reasoning abilities in LLMs,\nexperimental results demonstrate that SPP effectively reduces factual\nhallucination, and maintains strong reasoning capabilities. Additionally,\ncomparative experiments show that cognitive synergy only emerges in GPT-4 and\ndoes not appear in less capable models, such as GPT-3.5-turbo and\nLlama2-13b-chat, which draws an interesting analogy to human development. Code,\ndata, and prompts can be found at:\nhttps:\/\/github.com\/MikeWangWZHL\/Solo-Performance-Prompting.git.","updated":1711463553000,"published":1689086719000,"authors":["Zhenhailong Wang","Shaoguang Mao","Wenshan Wu","Tao Ge","Furu Wei","Heng Ji"],"comments":"Accepted as a main conference paper at NAACL 2024","categories":["cs.AI","cs.CL"],"primary_category":"cs.AI","doi":null,"journal_ref":null,"peer_reviewed":true,"reader_id":"rid1","human_jargon_term":"multi-turn","definition_text":"\"Multi-turn\" refers to an interaction involving multiple exchanges, like a conversation, where each turn represents a response or continuation building on the previous communications. In the context of AI, it relates to a series of interactions where the system generates responses based on a progressing dialogue, enhancing coherence and context understanding with each step.","model":"gpt4_abstract","Accuracy":"accurate","Ranking":2,"Notes":""},"6":{"arxiv_id":"2403.16750v1","url":"http:\/\/arxiv.org\/abs\/2403.16750v1","title":"All Artificial, Less Intelligence: GenAI through the Lens of Formal\n  Verification","summary":"Modern hardware designs have grown increasingly efficient and complex.\nHowever, they are often susceptible to Common Weakness Enumerations (CWEs).\nThis paper is focused on the formal verification of CWEs in a dataset of\nhardware designs written in SystemVerilog from Regenerative Artificial\nIntelligence (AI) powered by Large Language Models (LLMs). We applied formal\nverification to categorize each hardware design as vulnerable or CWE-free. This\ndataset was generated by 4 different LLMs and features a unique set of designs\nfor each of the 10 CWEs we target in our paper. We have associated the\nidentified vulnerabilities with CWE numbers for a dataset of 60,000 generated\nSystemVerilog Register Transfer Level (RTL) code. It was also found that most\nLLMs are not aware of any hardware CWEs; hence they are usually not considered\nwhen generating the hardware code. Our study reveals that approximately 60% of\nthe hardware designs generated by LLMs are prone to CWEs, posing potential\nsafety and security risks. The dataset could be ideal for training LLMs and\nMachine Learning (ML) algorithms to abstain from generating CWE-prone hardware\ndesigns.","updated":1711373004000,"published":1711373004000,"authors":["Deepak Narayan Gadde","Aman Kumar","Thomas Nalapat","Evgenii Rezunov","Fabio Cappellini"],"comments":"Published in DVCon U.S. 2024","categories":["cs.AI"],"primary_category":"cs.AI","doi":null,"journal_ref":null,"peer_reviewed":true,"reader_id":"rid1","human_jargon_term":"Common Weakness Enumerations","definition_text":"Common Weakness Enumerations (CWEs) are a list of known security weaknesses or vulnerabilities that are frequently found in software and hardware designs. They serve as a standardized classification for identifying, assessing, and addressing these vulnerabilities to improve the security and integrity of technological systems.","model":"gpt4_abstract","Accuracy":"accurate","Ranking":0,"Notes":""},"7":{"arxiv_id":"2403.16750v1","url":"http:\/\/arxiv.org\/abs\/2403.16750v1","title":"All Artificial, Less Intelligence: GenAI through the Lens of Formal\n  Verification","summary":"Modern hardware designs have grown increasingly efficient and complex.\nHowever, they are often susceptible to Common Weakness Enumerations (CWEs).\nThis paper is focused on the formal verification of CWEs in a dataset of\nhardware designs written in SystemVerilog from Regenerative Artificial\nIntelligence (AI) powered by Large Language Models (LLMs). We applied formal\nverification to categorize each hardware design as vulnerable or CWE-free. This\ndataset was generated by 4 different LLMs and features a unique set of designs\nfor each of the 10 CWEs we target in our paper. We have associated the\nidentified vulnerabilities with CWE numbers for a dataset of 60,000 generated\nSystemVerilog Register Transfer Level (RTL) code. It was also found that most\nLLMs are not aware of any hardware CWEs; hence they are usually not considered\nwhen generating the hardware code. Our study reveals that approximately 60% of\nthe hardware designs generated by LLMs are prone to CWEs, posing potential\nsafety and security risks. The dataset could be ideal for training LLMs and\nMachine Learning (ML) algorithms to abstain from generating CWE-prone hardware\ndesigns.","updated":1711373004000,"published":1711373004000,"authors":["Deepak Narayan Gadde","Aman Kumar","Thomas Nalapat","Evgenii Rezunov","Fabio Cappellini"],"comments":"Published in DVCon U.S. 2024","categories":["cs.AI"],"primary_category":"cs.AI","doi":null,"journal_ref":null,"peer_reviewed":true,"reader_id":"rid1","human_jargon_term":"Regenerative Artificial\nIntelligence","definition_text":"Regenerative Artificial Intelligence refers to a type of AI that has the capability to generate new content or data, such as hardware designs in this case, by itself. This is typically powered by large language models that have been trained on vast amounts of data to produce outputs that are novel and not simply reproductions of existing examples.","model":"gpt4_abstract","Accuracy":"accurate","Ranking":1,"Notes":""},"8":{"arxiv_id":"2403.16750v1","url":"http:\/\/arxiv.org\/abs\/2403.16750v1","title":"All Artificial, Less Intelligence: GenAI through the Lens of Formal\n  Verification","summary":"Modern hardware designs have grown increasingly efficient and complex.\nHowever, they are often susceptible to Common Weakness Enumerations (CWEs).\nThis paper is focused on the formal verification of CWEs in a dataset of\nhardware designs written in SystemVerilog from Regenerative Artificial\nIntelligence (AI) powered by Large Language Models (LLMs). We applied formal\nverification to categorize each hardware design as vulnerable or CWE-free. This\ndataset was generated by 4 different LLMs and features a unique set of designs\nfor each of the 10 CWEs we target in our paper. We have associated the\nidentified vulnerabilities with CWE numbers for a dataset of 60,000 generated\nSystemVerilog Register Transfer Level (RTL) code. It was also found that most\nLLMs are not aware of any hardware CWEs; hence they are usually not considered\nwhen generating the hardware code. Our study reveals that approximately 60% of\nthe hardware designs generated by LLMs are prone to CWEs, posing potential\nsafety and security risks. The dataset could be ideal for training LLMs and\nMachine Learning (ML) algorithms to abstain from generating CWE-prone hardware\ndesigns.","updated":1711373004000,"published":1711373004000,"authors":["Deepak Narayan Gadde","Aman Kumar","Thomas Nalapat","Evgenii Rezunov","Fabio Cappellini"],"comments":"Published in DVCon U.S. 2024","categories":["cs.AI"],"primary_category":"cs.AI","doi":null,"journal_ref":null,"peer_reviewed":true,"reader_id":"rid1","human_jargon_term":"SystemVerilog","definition_text":"SystemVerilog is a programming language used to model, design, and verify electronic systems, particularly focusing on the behavior of complex circuits and systems before they are physically built. This helps engineers ensure that the hardware will function correctly when it is manufactured.","model":"gpt4_abstract","Accuracy":"accurate","Ranking":0,"Notes":""},"9":{"arxiv_id":"2403.16750v1","url":"http:\/\/arxiv.org\/abs\/2403.16750v1","title":"All Artificial, Less Intelligence: GenAI through the Lens of Formal\n  Verification","summary":"Modern hardware designs have grown increasingly efficient and complex.\nHowever, they are often susceptible to Common Weakness Enumerations (CWEs).\nThis paper is focused on the formal verification of CWEs in a dataset of\nhardware designs written in SystemVerilog from Regenerative Artificial\nIntelligence (AI) powered by Large Language Models (LLMs). We applied formal\nverification to categorize each hardware design as vulnerable or CWE-free. This\ndataset was generated by 4 different LLMs and features a unique set of designs\nfor each of the 10 CWEs we target in our paper. We have associated the\nidentified vulnerabilities with CWE numbers for a dataset of 60,000 generated\nSystemVerilog Register Transfer Level (RTL) code. It was also found that most\nLLMs are not aware of any hardware CWEs; hence they are usually not considered\nwhen generating the hardware code. Our study reveals that approximately 60% of\nthe hardware designs generated by LLMs are prone to CWEs, posing potential\nsafety and security risks. The dataset could be ideal for training LLMs and\nMachine Learning (ML) algorithms to abstain from generating CWE-prone hardware\ndesigns.","updated":1711373004000,"published":1711373004000,"authors":["Deepak Narayan Gadde","Aman Kumar","Thomas Nalapat","Evgenii Rezunov","Fabio Cappellini"],"comments":"Published in DVCon U.S. 2024","categories":["cs.AI"],"primary_category":"cs.AI","doi":null,"journal_ref":null,"peer_reviewed":true,"reader_id":"rid1","human_jargon_term":"SystemVerilog Register Transfer Level","definition_text":"SystemVerilog Register Transfer Level (RTL) is a coding methodology used in the design of electronic systems where the behavior of the system's circuits is defined in terms of data flow between hardware registers and the logical operations that occur on this data. This method is particularly used in designing complex chip functionalities ensuring precise control over how data moves and is processed within a chip's circuitry.","model":"gpt4_abstract","Accuracy":"accurate","Ranking":2,"Notes":""},"10":{"arxiv_id":"2311.10112v2","url":"http:\/\/arxiv.org\/abs\/2311.10112v2","title":"zrLLM: Zero-Shot Relational Learning on Temporal Knowledge Graphs with\n  Large Language Models","summary":"Modeling evolving knowledge over temporal knowledge graphs (TKGs) has become\na heated topic. Various methods have been proposed to forecast links on TKGs.\nMost of them are embedding-based, where hidden representations are learned to\nrepresent knowledge graph (KG) entities and relations based on the observed\ngraph contexts. Although these methods show strong performance on traditional\nTKG forecasting (TKGF) benchmarks, they face a strong challenge in modeling the\nunseen zero-shot relations that have no prior graph context. In this paper, we\ntry to mitigate this problem as follows. We first input the text descriptions\nof KG relations into large language models (LLMs) for generating relation\nrepresentations, and then introduce them into embedding-based TKGF methods.\nLLM-empowered representations can capture the semantic information in the\nrelation descriptions. This makes the relations, whether seen or unseen, with\nsimilar semantic meanings stay close in the embedding space, enabling TKGF\nmodels to recognize zero-shot relations even without any observed graph\ncontext. Experimental results show that our approach helps TKGF models to\nachieve much better performance in forecasting the facts with previously unseen\nrelations, while still maintaining their ability in link forecasting regarding\nseen relations.","updated":1710517087000,"published":1700083515000,"authors":["Zifeng Ding","Heling Cai","Jingpei Wu","Yunpu Ma","Ruotong Liao","Bo Xiong","Volker Tresp"],"comments":"Accepted to NAACL 2024 main conference","categories":["cs.AI","cs.CL","cs.LG"],"primary_category":"cs.AI","doi":null,"journal_ref":null,"peer_reviewed":true,"reader_id":"rid1","human_jargon_term":"embedding-based","definition_text":"Embedding-based methods involve creating digital representations, or \"embeddings,\" for items (such as entities and relationships in a knowledge graph) in a way that captures their similarities and relationships in a compact form. These embeddings help machines to understand and process complex data like graphs more effectively.","model":"gpt4_abstract","Accuracy":"accurate","Ranking":2,"Notes":""},"11":{"arxiv_id":"2311.10112v2","url":"http:\/\/arxiv.org\/abs\/2311.10112v2","title":"zrLLM: Zero-Shot Relational Learning on Temporal Knowledge Graphs with\n  Large Language Models","summary":"Modeling evolving knowledge over temporal knowledge graphs (TKGs) has become\na heated topic. Various methods have been proposed to forecast links on TKGs.\nMost of them are embedding-based, where hidden representations are learned to\nrepresent knowledge graph (KG) entities and relations based on the observed\ngraph contexts. Although these methods show strong performance on traditional\nTKG forecasting (TKGF) benchmarks, they face a strong challenge in modeling the\nunseen zero-shot relations that have no prior graph context. In this paper, we\ntry to mitigate this problem as follows. We first input the text descriptions\nof KG relations into large language models (LLMs) for generating relation\nrepresentations, and then introduce them into embedding-based TKGF methods.\nLLM-empowered representations can capture the semantic information in the\nrelation descriptions. This makes the relations, whether seen or unseen, with\nsimilar semantic meanings stay close in the embedding space, enabling TKGF\nmodels to recognize zero-shot relations even without any observed graph\ncontext. Experimental results show that our approach helps TKGF models to\nachieve much better performance in forecasting the facts with previously unseen\nrelations, while still maintaining their ability in link forecasting regarding\nseen relations.","updated":1710517087000,"published":1700083515000,"authors":["Zifeng Ding","Heling Cai","Jingpei Wu","Yunpu Ma","Ruotong Liao","Bo Xiong","Volker Tresp"],"comments":"Accepted to NAACL 2024 main conference","categories":["cs.AI","cs.CL","cs.LG"],"primary_category":"cs.AI","doi":null,"journal_ref":null,"peer_reviewed":true,"reader_id":"rid1","human_jargon_term":"temporal knowledge graphs","definition_text":"Temporal knowledge graphs (TKGs) are advanced databases that not only store facts but also track how these facts change over time. They provide a way to observe and analyze how relationships and information evolve, making them useful for understanding trends and patterns across various periods.","model":"gpt4_abstract","Accuracy":"accurate","Ranking":2,"Notes":""},"12":{"arxiv_id":"2311.10112v2","url":"http:\/\/arxiv.org\/abs\/2311.10112v2","title":"zrLLM: Zero-Shot Relational Learning on Temporal Knowledge Graphs with\n  Large Language Models","summary":"Modeling evolving knowledge over temporal knowledge graphs (TKGs) has become\na heated topic. Various methods have been proposed to forecast links on TKGs.\nMost of them are embedding-based, where hidden representations are learned to\nrepresent knowledge graph (KG) entities and relations based on the observed\ngraph contexts. Although these methods show strong performance on traditional\nTKG forecasting (TKGF) benchmarks, they face a strong challenge in modeling the\nunseen zero-shot relations that have no prior graph context. In this paper, we\ntry to mitigate this problem as follows. We first input the text descriptions\nof KG relations into large language models (LLMs) for generating relation\nrepresentations, and then introduce them into embedding-based TKGF methods.\nLLM-empowered representations can capture the semantic information in the\nrelation descriptions. This makes the relations, whether seen or unseen, with\nsimilar semantic meanings stay close in the embedding space, enabling TKGF\nmodels to recognize zero-shot relations even without any observed graph\ncontext. Experimental results show that our approach helps TKGF models to\nachieve much better performance in forecasting the facts with previously unseen\nrelations, while still maintaining their ability in link forecasting regarding\nseen relations.","updated":1710517087000,"published":1700083515000,"authors":["Zifeng Ding","Heling Cai","Jingpei Wu","Yunpu Ma","Ruotong Liao","Bo Xiong","Volker Tresp"],"comments":"Accepted to NAACL 2024 main conference","categories":["cs.AI","cs.CL","cs.LG"],"primary_category":"cs.AI","doi":null,"journal_ref":null,"peer_reviewed":true,"reader_id":"rid1","human_jargon_term":"zero-shot relations","definition_text":"Zero-shot relations refer to new or previously unseen connections or relationships between entities in a knowledge graph, for which no prior information or examples were available during the training of the model. This means the model must identify and handle these relations without having learned about them directly.","model":"gpt4_abstract","Accuracy":"accurate","Ranking":0,"Notes":""},"13":{"arxiv_id":"2310.08992v3","url":"http:\/\/arxiv.org\/abs\/2310.08992v3","title":"CodeChain: Towards Modular Code Generation Through Chain of\n  Self-revisions with Representative Sub-modules","summary":"Large Language Models (LLMs) have already become quite proficient at solving\nsimpler programming tasks like those in HumanEval or MBPP benchmarks. However,\nsolving more complex and competitive programming tasks is still quite\nchallenging for these models - possibly due to their tendency to generate\nsolutions as monolithic code blocks instead of decomposing them into logical\nsub-tasks and sub-modules. On the other hand, experienced programmers\ninstinctively write modularized code with abstraction for solving complex\ntasks, often reusing previously developed modules. To address this gap, we\npropose CodeChain, a novel framework for inference that elicits modularized\ncode generation through a chain of self-revisions, each being guided by some\nrepresentative sub-modules generated in previous iterations. Concretely,\nCodeChain first instructs the LLM to generate modularized codes through\nchain-of-thought prompting. Then it applies a chain of self-revisions by\niterating the two steps: 1) extracting and clustering the generated sub-modules\nand selecting the cluster representatives as the more generic and re-usable\nimplementations, and 2) augmenting the original chain-of-thought prompt with\nthese selected module-implementations and instructing the LLM to re-generate\nnew modularized solutions. We find that by naturally encouraging the LLM to\nreuse the previously developed and verified sub-modules, CodeChain can\nsignificantly boost both modularity as well as correctness of the generated\nsolutions, achieving relative pass@1 improvements of 35% on APPS and 76% on\nCodeContests. It is shown to be effective on both OpenAI LLMs as well as\nopen-sourced LLMs like WizardCoder. We also conduct comprehensive ablation\nstudies with different methods of prompting, number of clusters, model sizes,\nprogram qualities, etc., to provide useful insights that underpin CodeChain's\nsuccess.","updated":1710386949000,"published":1697192268000,"authors":["Hung Le","Hailin Chen","Amrita Saha","Akash Gokul","Doyen Sahoo","Shafiq Joty"],"comments":"Accepted to ICLR 2024","categories":["cs.AI","cs.CL","cs.PL"],"primary_category":"cs.AI","doi":null,"journal_ref":null,"peer_reviewed":true,"reader_id":"rid1","human_jargon_term":"HumanEval","definition_text":"HumanEval is a benchmark for evaluating the programming capabilities of large language models by presenting them with coding problems to solve.","model":"gpt4_abstract","Accuracy":"accurate","Ranking":0,"Notes":""},"14":{"arxiv_id":"2310.08992v3","url":"http:\/\/arxiv.org\/abs\/2310.08992v3","title":"CodeChain: Towards Modular Code Generation Through Chain of\n  Self-revisions with Representative Sub-modules","summary":"Large Language Models (LLMs) have already become quite proficient at solving\nsimpler programming tasks like those in HumanEval or MBPP benchmarks. However,\nsolving more complex and competitive programming tasks is still quite\nchallenging for these models - possibly due to their tendency to generate\nsolutions as monolithic code blocks instead of decomposing them into logical\nsub-tasks and sub-modules. On the other hand, experienced programmers\ninstinctively write modularized code with abstraction for solving complex\ntasks, often reusing previously developed modules. To address this gap, we\npropose CodeChain, a novel framework for inference that elicits modularized\ncode generation through a chain of self-revisions, each being guided by some\nrepresentative sub-modules generated in previous iterations. Concretely,\nCodeChain first instructs the LLM to generate modularized codes through\nchain-of-thought prompting. Then it applies a chain of self-revisions by\niterating the two steps: 1) extracting and clustering the generated sub-modules\nand selecting the cluster representatives as the more generic and re-usable\nimplementations, and 2) augmenting the original chain-of-thought prompt with\nthese selected module-implementations and instructing the LLM to re-generate\nnew modularized solutions. We find that by naturally encouraging the LLM to\nreuse the previously developed and verified sub-modules, CodeChain can\nsignificantly boost both modularity as well as correctness of the generated\nsolutions, achieving relative pass@1 improvements of 35% on APPS and 76% on\nCodeContests. It is shown to be effective on both OpenAI LLMs as well as\nopen-sourced LLMs like WizardCoder. We also conduct comprehensive ablation\nstudies with different methods of prompting, number of clusters, model sizes,\nprogram qualities, etc., to provide useful insights that underpin CodeChain's\nsuccess.","updated":1710386949000,"published":1697192268000,"authors":["Hung Le","Hailin Chen","Amrita Saha","Akash Gokul","Doyen Sahoo","Shafiq Joty"],"comments":"Accepted to ICLR 2024","categories":["cs.AI","cs.CL","cs.PL"],"primary_category":"cs.AI","doi":null,"journal_ref":null,"peer_reviewed":true,"reader_id":"rid1","human_jargon_term":"MBPP","definition_text":"MBPP, or Massively Multilingual Benchmark for Programming Problems, is a collection of programming tasks used to evaluate the capabilities of programming language models, assessing how well these models can understand and solve various coding challenges.","model":"gpt4_abstract","Accuracy":"accurate","Ranking":1,"Notes":""},"15":{"arxiv_id":"2310.08992v3","url":"http:\/\/arxiv.org\/abs\/2310.08992v3","title":"CodeChain: Towards Modular Code Generation Through Chain of\n  Self-revisions with Representative Sub-modules","summary":"Large Language Models (LLMs) have already become quite proficient at solving\nsimpler programming tasks like those in HumanEval or MBPP benchmarks. However,\nsolving more complex and competitive programming tasks is still quite\nchallenging for these models - possibly due to their tendency to generate\nsolutions as monolithic code blocks instead of decomposing them into logical\nsub-tasks and sub-modules. On the other hand, experienced programmers\ninstinctively write modularized code with abstraction for solving complex\ntasks, often reusing previously developed modules. To address this gap, we\npropose CodeChain, a novel framework for inference that elicits modularized\ncode generation through a chain of self-revisions, each being guided by some\nrepresentative sub-modules generated in previous iterations. Concretely,\nCodeChain first instructs the LLM to generate modularized codes through\nchain-of-thought prompting. Then it applies a chain of self-revisions by\niterating the two steps: 1) extracting and clustering the generated sub-modules\nand selecting the cluster representatives as the more generic and re-usable\nimplementations, and 2) augmenting the original chain-of-thought prompt with\nthese selected module-implementations and instructing the LLM to re-generate\nnew modularized solutions. We find that by naturally encouraging the LLM to\nreuse the previously developed and verified sub-modules, CodeChain can\nsignificantly boost both modularity as well as correctness of the generated\nsolutions, achieving relative pass@1 improvements of 35% on APPS and 76% on\nCodeContests. It is shown to be effective on both OpenAI LLMs as well as\nopen-sourced LLMs like WizardCoder. We also conduct comprehensive ablation\nstudies with different methods of prompting, number of clusters, model sizes,\nprogram qualities, etc., to provide useful insights that underpin CodeChain's\nsuccess.","updated":1710386949000,"published":1697192268000,"authors":["Hung Le","Hailin Chen","Amrita Saha","Akash Gokul","Doyen Sahoo","Shafiq Joty"],"comments":"Accepted to ICLR 2024","categories":["cs.AI","cs.CL","cs.PL"],"primary_category":"cs.AI","doi":null,"journal_ref":null,"peer_reviewed":true,"reader_id":"rid1","human_jargon_term":"modularized code","definition_text":"Modularized code refers to the practice of breaking down a large programming task into smaller, distinct sections or modules that each handle a specific part of the task. This approach simplifies writing, testing, and maintaining code, as each module can be developed and used independently yet works together as part of the larger program.","model":"gpt4_abstract","Accuracy":"accurate","Ranking":0,"Notes":""},"16":{"arxiv_id":"2310.08992v3","url":"http:\/\/arxiv.org\/abs\/2310.08992v3","title":"CodeChain: Towards Modular Code Generation Through Chain of\n  Self-revisions with Representative Sub-modules","summary":"Large Language Models (LLMs) have already become quite proficient at solving\nsimpler programming tasks like those in HumanEval or MBPP benchmarks. However,\nsolving more complex and competitive programming tasks is still quite\nchallenging for these models - possibly due to their tendency to generate\nsolutions as monolithic code blocks instead of decomposing them into logical\nsub-tasks and sub-modules. On the other hand, experienced programmers\ninstinctively write modularized code with abstraction for solving complex\ntasks, often reusing previously developed modules. To address this gap, we\npropose CodeChain, a novel framework for inference that elicits modularized\ncode generation through a chain of self-revisions, each being guided by some\nrepresentative sub-modules generated in previous iterations. Concretely,\nCodeChain first instructs the LLM to generate modularized codes through\nchain-of-thought prompting. Then it applies a chain of self-revisions by\niterating the two steps: 1) extracting and clustering the generated sub-modules\nand selecting the cluster representatives as the more generic and re-usable\nimplementations, and 2) augmenting the original chain-of-thought prompt with\nthese selected module-implementations and instructing the LLM to re-generate\nnew modularized solutions. We find that by naturally encouraging the LLM to\nreuse the previously developed and verified sub-modules, CodeChain can\nsignificantly boost both modularity as well as correctness of the generated\nsolutions, achieving relative pass@1 improvements of 35% on APPS and 76% on\nCodeContests. It is shown to be effective on both OpenAI LLMs as well as\nopen-sourced LLMs like WizardCoder. We also conduct comprehensive ablation\nstudies with different methods of prompting, number of clusters, model sizes,\nprogram qualities, etc., to provide useful insights that underpin CodeChain's\nsuccess.","updated":1710386949000,"published":1697192268000,"authors":["Hung Le","Hailin Chen","Amrita Saha","Akash Gokul","Doyen Sahoo","Shafiq Joty"],"comments":"Accepted to ICLR 2024","categories":["cs.AI","cs.CL","cs.PL"],"primary_category":"cs.AI","doi":null,"journal_ref":null,"peer_reviewed":true,"reader_id":"rid1","human_jargon_term":"monolithic","definition_text":"In the context of programming, \"monolithic\" refers to code that is written as a single large block or unit, without being broken down into smaller, more manageable parts or modules.","model":"gpt4_abstract","Accuracy":"accurate","Ranking":1,"Notes":""},"17":{"arxiv_id":"2402.09565v2","url":"http:\/\/arxiv.org\/abs\/2402.09565v2","title":"Graph-Skeleton: ~1% Nodes are Sufficient to Represent Billion-Scale\n  Graph","summary":"Due to the ubiquity of graph data on the web, web graph mining has become a\nhot research spot. Nonetheless, the prevalence of large-scale web graphs in\nreal applications poses significant challenges to storage, computational\ncapacity and graph model design. Despite numerous studies to enhance the\nscalability of graph models, a noticeable gap remains between academic research\nand practical web graph mining applications. One major cause is that in most\nindustrial scenarios, only a small part of nodes in a web graph are actually\nrequired to be analyzed, where we term these nodes as target nodes, while\nothers as background nodes. In this paper, we argue that properly fetching and\ncondensing the background nodes from massive web graph data might be a more\neconomical shortcut to tackle the obstacles fundamentally. To this end, we make\nthe first attempt to study the problem of massive background nodes compression\nfor target nodes classification. Through extensive experiments, we reveal two\ncritical roles played by the background nodes in target node classification:\nenhancing structural connectivity between target nodes, and feature correlation\nwith target nodes. Followingthis, we propose a novel Graph-Skeleton1 model,\nwhich properly fetches the background nodes, and further condenses the semantic\nand topological information of background nodes within similar\ntarget-background local structures. Extensive experiments on various web graph\ndatasets demonstrate the effectiveness and efficiency of the proposed method.\nIn particular, for MAG240M dataset with 0.24 billion nodes, our generated\nskeleton graph achieves highly comparable performance while only containing\n1.8% nodes of the original graph.","updated":1709763753000,"published":1707942791000,"authors":["Linfeng Cao","Haoran Deng","Yang Yang","Chunping Wang","Lei Chen"],"comments":"21 pages, 11 figures, In Proceedings of the ACM Web Conference 2024\n  (WWW'24)","categories":["cs.AI"],"primary_category":"cs.AI","doi":"10.1145\/3589334.3645452","journal_ref":null,"peer_reviewed":true,"reader_id":"rid1","human_jargon_term":"MAG240M dataset","definition_text":"The MAG240M dataset is a large collection of data consisting of 0.24 billion nodes, used for studying relationships and structures within a network, specifically in the context of web graphs for research and analysis. Such datasets help scientists and researchers explore the interactions and connections between different entities on the web.","model":"gpt4_abstract","Accuracy":"accurate","Ranking":0,"Notes":""},"18":{"arxiv_id":"2402.09565v2","url":"http:\/\/arxiv.org\/abs\/2402.09565v2","title":"Graph-Skeleton: ~1% Nodes are Sufficient to Represent Billion-Scale\n  Graph","summary":"Due to the ubiquity of graph data on the web, web graph mining has become a\nhot research spot. Nonetheless, the prevalence of large-scale web graphs in\nreal applications poses significant challenges to storage, computational\ncapacity and graph model design. Despite numerous studies to enhance the\nscalability of graph models, a noticeable gap remains between academic research\nand practical web graph mining applications. One major cause is that in most\nindustrial scenarios, only a small part of nodes in a web graph are actually\nrequired to be analyzed, where we term these nodes as target nodes, while\nothers as background nodes. In this paper, we argue that properly fetching and\ncondensing the background nodes from massive web graph data might be a more\neconomical shortcut to tackle the obstacles fundamentally. To this end, we make\nthe first attempt to study the problem of massive background nodes compression\nfor target nodes classification. Through extensive experiments, we reveal two\ncritical roles played by the background nodes in target node classification:\nenhancing structural connectivity between target nodes, and feature correlation\nwith target nodes. Followingthis, we propose a novel Graph-Skeleton1 model,\nwhich properly fetches the background nodes, and further condenses the semantic\nand topological information of background nodes within similar\ntarget-background local structures. Extensive experiments on various web graph\ndatasets demonstrate the effectiveness and efficiency of the proposed method.\nIn particular, for MAG240M dataset with 0.24 billion nodes, our generated\nskeleton graph achieves highly comparable performance while only containing\n1.8% nodes of the original graph.","updated":1709763753000,"published":1707942791000,"authors":["Linfeng Cao","Haoran Deng","Yang Yang","Chunping Wang","Lei Chen"],"comments":"21 pages, 11 figures, In Proceedings of the ACM Web Conference 2024\n  (WWW'24)","categories":["cs.AI"],"primary_category":"cs.AI","doi":"10.1145\/3589334.3645452","journal_ref":null,"peer_reviewed":true,"reader_id":"rid1","human_jargon_term":"background nodes","definition_text":"In the context of web graph mining, \"background nodes\" refer to those elements within a web graph that are not the primary focus of analysis but are still essential for providing context and connectivity to the more significant, or target, nodes which are being studied.","model":"gpt4_abstract","Accuracy":"accurate","Ranking":0,"Notes":""},"19":{"arxiv_id":"2007.00714v4","url":"http:\/\/arxiv.org\/abs\/2007.00714v4","title":"Quantifying intrinsic causal contributions via structure preserving\n  interventions","summary":"We propose a notion of causal influence that describes the `intrinsic' part\nof the contribution of a node on a target node in a DAG. By recursively writing\neach node as a function of the upstream noise terms, we separate the intrinsic\ninformation added by each node from the one obtained from its ancestors. To\ninterpret the intrinsic information as a {\\it causal} contribution, we consider\n`structure-preserving interventions' that randomize each node in a way that\nmimics the usual dependence on the parents and does not perturb the observed\njoint distribution. To get a measure that is invariant with respect to\nrelabelling nodes we use Shapley based symmetrization and show that it reduces\nin the linear case to simple ANOVA after resolving the target node into noise\nvariables. We describe our contribution analysis for variance and entropy, but\ncontributions for other target metrics can be defined analogously. The code is\navailable in the package gcm of the open source library DoWhy.","updated":1709904783000,"published":1593632048000,"authors":["Dominik Janzing","Patrick Bl\u00f6baum","Atalanti A. Mastakouri","Philipp M. Faller","Lenon Minorics","Kailash Budhathoki"],"comments":"to appear at AISTATS 2024","categories":["cs.AI","cs.IT","math.IT","stat.ML"],"primary_category":"cs.AI","doi":null,"journal_ref":null,"peer_reviewed":true,"reader_id":"rid1","human_jargon_term":"ANOVA","definition_text":"ANOVA, or Analysis of Variance, is a statistical method used to determine if there are any statistically significant differences between the means of three or more independent (unrelated) groups. This technique helps researchers decide if general patterns observed in the data are meaningful by comparing the groups' data points to see how much they vary from each other and the overall mean.","model":"gpt4_abstract","Accuracy":"accurate","Ranking":2,"Notes":""},"20":{"arxiv_id":"2007.00714v4","url":"http:\/\/arxiv.org\/abs\/2007.00714v4","title":"Quantifying intrinsic causal contributions via structure preserving\n  interventions","summary":"We propose a notion of causal influence that describes the `intrinsic' part\nof the contribution of a node on a target node in a DAG. By recursively writing\neach node as a function of the upstream noise terms, we separate the intrinsic\ninformation added by each node from the one obtained from its ancestors. To\ninterpret the intrinsic information as a {\\it causal} contribution, we consider\n`structure-preserving interventions' that randomize each node in a way that\nmimics the usual dependence on the parents and does not perturb the observed\njoint distribution. To get a measure that is invariant with respect to\nrelabelling nodes we use Shapley based symmetrization and show that it reduces\nin the linear case to simple ANOVA after resolving the target node into noise\nvariables. We describe our contribution analysis for variance and entropy, but\ncontributions for other target metrics can be defined analogously. The code is\navailable in the package gcm of the open source library DoWhy.","updated":1709904783000,"published":1593632048000,"authors":["Dominik Janzing","Patrick Bl\u00f6baum","Atalanti A. Mastakouri","Philipp M. Faller","Lenon Minorics","Kailash Budhathoki"],"comments":"to appear at AISTATS 2024","categories":["cs.AI","cs.IT","math.IT","stat.ML"],"primary_category":"cs.AI","doi":null,"journal_ref":null,"peer_reviewed":true,"reader_id":"rid1","human_jargon_term":"DAG","definition_text":"A Directed Acyclic Graph (DAG) is a diagram that shows a series of connections or influences between different things (like events or variables) where each connection points in one direction and the connections do not form any loops.","model":"gpt4_abstract","Accuracy":"accurate","Ranking":2,"Notes":""},"21":{"arxiv_id":"2007.00714v4","url":"http:\/\/arxiv.org\/abs\/2007.00714v4","title":"Quantifying intrinsic causal contributions via structure preserving\n  interventions","summary":"We propose a notion of causal influence that describes the `intrinsic' part\nof the contribution of a node on a target node in a DAG. By recursively writing\neach node as a function of the upstream noise terms, we separate the intrinsic\ninformation added by each node from the one obtained from its ancestors. To\ninterpret the intrinsic information as a {\\it causal} contribution, we consider\n`structure-preserving interventions' that randomize each node in a way that\nmimics the usual dependence on the parents and does not perturb the observed\njoint distribution. To get a measure that is invariant with respect to\nrelabelling nodes we use Shapley based symmetrization and show that it reduces\nin the linear case to simple ANOVA after resolving the target node into noise\nvariables. We describe our contribution analysis for variance and entropy, but\ncontributions for other target metrics can be defined analogously. The code is\navailable in the package gcm of the open source library DoWhy.","updated":1709904783000,"published":1593632048000,"authors":["Dominik Janzing","Patrick Bl\u00f6baum","Atalanti A. Mastakouri","Philipp M. Faller","Lenon Minorics","Kailash Budhathoki"],"comments":"to appear at AISTATS 2024","categories":["cs.AI","cs.IT","math.IT","stat.ML"],"primary_category":"cs.AI","doi":null,"journal_ref":null,"peer_reviewed":true,"reader_id":"rid1","human_jargon_term":"Shapley based symmetrization","definition_text":"Shapley based symmetrization is a method used to ensure that the measure of influence each element has in a system is fair and consistent, regardless of the order in which elements are labeled or considered. It uses a technique from game theory, attributed to Lloyd Shapley, which evaluates the contribution of each participant by simulating all possible scenarios of their involvement.","model":"gpt4_abstract","Accuracy":"accurate","Ranking":0,"Notes":""},"22":{"arxiv_id":"2007.00714v4","url":"http:\/\/arxiv.org\/abs\/2007.00714v4","title":"Quantifying intrinsic causal contributions via structure preserving\n  interventions","summary":"We propose a notion of causal influence that describes the `intrinsic' part\nof the contribution of a node on a target node in a DAG. By recursively writing\neach node as a function of the upstream noise terms, we separate the intrinsic\ninformation added by each node from the one obtained from its ancestors. To\ninterpret the intrinsic information as a {\\it causal} contribution, we consider\n`structure-preserving interventions' that randomize each node in a way that\nmimics the usual dependence on the parents and does not perturb the observed\njoint distribution. To get a measure that is invariant with respect to\nrelabelling nodes we use Shapley based symmetrization and show that it reduces\nin the linear case to simple ANOVA after resolving the target node into noise\nvariables. We describe our contribution analysis for variance and entropy, but\ncontributions for other target metrics can be defined analogously. The code is\navailable in the package gcm of the open source library DoWhy.","updated":1709904783000,"published":1593632048000,"authors":["Dominik Janzing","Patrick Bl\u00f6baum","Atalanti A. Mastakouri","Philipp M. Faller","Lenon Minorics","Kailash Budhathoki"],"comments":"to appear at AISTATS 2024","categories":["cs.AI","cs.IT","math.IT","stat.ML"],"primary_category":"cs.AI","doi":null,"journal_ref":null,"peer_reviewed":true,"reader_id":"rid1","human_jargon_term":"joint distribution","definition_text":"The term \"joint distribution\" refers to the way two or more variables combine and interact with one another in terms of their likelihoods or probabilities. In simpler words, it describes how the possible outcomes of multiple factors or variables are connected or related.","model":"gpt4_abstract","Accuracy":"accurate","Ranking":2,"Notes":""},"23":{"arxiv_id":"2007.00714v4","url":"http:\/\/arxiv.org\/abs\/2007.00714v4","title":"Quantifying intrinsic causal contributions via structure preserving\n  interventions","summary":"We propose a notion of causal influence that describes the `intrinsic' part\nof the contribution of a node on a target node in a DAG. By recursively writing\neach node as a function of the upstream noise terms, we separate the intrinsic\ninformation added by each node from the one obtained from its ancestors. To\ninterpret the intrinsic information as a {\\it causal} contribution, we consider\n`structure-preserving interventions' that randomize each node in a way that\nmimics the usual dependence on the parents and does not perturb the observed\njoint distribution. To get a measure that is invariant with respect to\nrelabelling nodes we use Shapley based symmetrization and show that it reduces\nin the linear case to simple ANOVA after resolving the target node into noise\nvariables. We describe our contribution analysis for variance and entropy, but\ncontributions for other target metrics can be defined analogously. The code is\navailable in the package gcm of the open source library DoWhy.","updated":1709904783000,"published":1593632048000,"authors":["Dominik Janzing","Patrick Bl\u00f6baum","Atalanti A. Mastakouri","Philipp M. Faller","Lenon Minorics","Kailash Budhathoki"],"comments":"to appear at AISTATS 2024","categories":["cs.AI","cs.IT","math.IT","stat.ML"],"primary_category":"cs.AI","doi":null,"journal_ref":null,"peer_reviewed":true,"reader_id":"rid1","human_jargon_term":"perturb","definition_text":"The term \"perturb\" means to disturb or alter something slightly, especially in a way that causes a temporary change or disruption in its normal state or path.","model":"gpt4_abstract","Accuracy":"accurate","Ranking":2,"Notes":""},"24":{"arxiv_id":"2007.00714v4","url":"http:\/\/arxiv.org\/abs\/2007.00714v4","title":"Quantifying intrinsic causal contributions via structure preserving\n  interventions","summary":"We propose a notion of causal influence that describes the `intrinsic' part\nof the contribution of a node on a target node in a DAG. By recursively writing\neach node as a function of the upstream noise terms, we separate the intrinsic\ninformation added by each node from the one obtained from its ancestors. To\ninterpret the intrinsic information as a {\\it causal} contribution, we consider\n`structure-preserving interventions' that randomize each node in a way that\nmimics the usual dependence on the parents and does not perturb the observed\njoint distribution. To get a measure that is invariant with respect to\nrelabelling nodes we use Shapley based symmetrization and show that it reduces\nin the linear case to simple ANOVA after resolving the target node into noise\nvariables. We describe our contribution analysis for variance and entropy, but\ncontributions for other target metrics can be defined analogously. The code is\navailable in the package gcm of the open source library DoWhy.","updated":1709904783000,"published":1593632048000,"authors":["Dominik Janzing","Patrick Bl\u00f6baum","Atalanti A. Mastakouri","Philipp M. Faller","Lenon Minorics","Kailash Budhathoki"],"comments":"to appear at AISTATS 2024","categories":["cs.AI","cs.IT","math.IT","stat.ML"],"primary_category":"cs.AI","doi":null,"journal_ref":null,"peer_reviewed":true,"reader_id":"rid1","human_jargon_term":"structure-preserving interventions","definition_text":"Structure-preserving interventions are changes made to a specific part of a system that are carefully designed to continue mimicking the usual behavior seen in that system, thereby not altering the overall observed relationships and behavior within the system. This approach helps in understanding the independent role of each component without disrupting the natural dynamics of the system.","model":"gpt4_abstract","Accuracy":"accurate","Ranking":0,"Notes":""},"25":{"arxiv_id":"2007.00714v4","url":"http:\/\/arxiv.org\/abs\/2007.00714v4","title":"Quantifying intrinsic causal contributions via structure preserving\n  interventions","summary":"We propose a notion of causal influence that describes the `intrinsic' part\nof the contribution of a node on a target node in a DAG. By recursively writing\neach node as a function of the upstream noise terms, we separate the intrinsic\ninformation added by each node from the one obtained from its ancestors. To\ninterpret the intrinsic information as a {\\it causal} contribution, we consider\n`structure-preserving interventions' that randomize each node in a way that\nmimics the usual dependence on the parents and does not perturb the observed\njoint distribution. To get a measure that is invariant with respect to\nrelabelling nodes we use Shapley based symmetrization and show that it reduces\nin the linear case to simple ANOVA after resolving the target node into noise\nvariables. We describe our contribution analysis for variance and entropy, but\ncontributions for other target metrics can be defined analogously. The code is\navailable in the package gcm of the open source library DoWhy.","updated":1709904783000,"published":1593632048000,"authors":["Dominik Janzing","Patrick Bl\u00f6baum","Atalanti A. Mastakouri","Philipp M. Faller","Lenon Minorics","Kailash Budhathoki"],"comments":"to appear at AISTATS 2024","categories":["cs.AI","cs.IT","math.IT","stat.ML"],"primary_category":"cs.AI","doi":null,"journal_ref":null,"peer_reviewed":true,"reader_id":"rid1","human_jargon_term":"target node","definition_text":"In the context of the given abstract, a \"target node\" refers to the specific part or element in a network (such as in a diagram showing a series of events or actions) that the study aims to analyze or understand how it is influenced by other parts or elements within the same network.","model":"gpt4_abstract","Accuracy":"accurate","Ranking":0,"Notes":""},"26":{"arxiv_id":"2007.00714v4","url":"http:\/\/arxiv.org\/abs\/2007.00714v4","title":"Quantifying intrinsic causal contributions via structure preserving\n  interventions","summary":"We propose a notion of causal influence that describes the `intrinsic' part\nof the contribution of a node on a target node in a DAG. By recursively writing\neach node as a function of the upstream noise terms, we separate the intrinsic\ninformation added by each node from the one obtained from its ancestors. To\ninterpret the intrinsic information as a {\\it causal} contribution, we consider\n`structure-preserving interventions' that randomize each node in a way that\nmimics the usual dependence on the parents and does not perturb the observed\njoint distribution. To get a measure that is invariant with respect to\nrelabelling nodes we use Shapley based symmetrization and show that it reduces\nin the linear case to simple ANOVA after resolving the target node into noise\nvariables. We describe our contribution analysis for variance and entropy, but\ncontributions for other target metrics can be defined analogously. The code is\navailable in the package gcm of the open source library DoWhy.","updated":1709904783000,"published":1593632048000,"authors":["Dominik Janzing","Patrick Bl\u00f6baum","Atalanti A. Mastakouri","Philipp M. Faller","Lenon Minorics","Kailash Budhathoki"],"comments":"to appear at AISTATS 2024","categories":["cs.AI","cs.IT","math.IT","stat.ML"],"primary_category":"cs.AI","doi":null,"journal_ref":null,"peer_reviewed":true,"reader_id":"rid1","human_jargon_term":"upstream noise terms","definition_text":"Upstream noise terms refer to random disturbances or variations that affect a specific part of a system before influencing other parts or outcomes in a chain of events or processes. These are essentially the initial random inputs that propagate through a system and impact its behavior or results.","model":"gpt4_abstract","Accuracy":"accurate","Ranking":2,"Notes":""},"27":{"arxiv_id":"2311.02760v2","url":"http:\/\/arxiv.org\/abs\/2311.02760v2","title":"Causal Question Answering with Reinforcement Learning","summary":"Causal questions inquire about causal relationships between different events\nor phenomena. They are important for a variety of use cases, including virtual\nassistants and search engines. However, many current approaches to causal\nquestion answering cannot provide explanations or evidence for their answers.\nHence, in this paper, we aim to answer causal questions with a causality graph,\na large-scale dataset of causal relations between noun phrases along with the\nrelations' provenance data. Inspired by recent, successful applications of\nreinforcement learning to knowledge graph tasks, such as link prediction and\nfact-checking, we explore the application of reinforcement learning on a\ncausality graph for causal question answering. We introduce an\nActor-Critic-based agent which learns to search through the graph to answer\ncausal questions. We bootstrap the agent with a supervised learning procedure\nto deal with large action spaces and sparse rewards. Our evaluation shows that\nthe agent successfully prunes the search space to answer binary causal\nquestions by visiting less than 30 nodes per question compared to over 3,000\nnodes by a naive breadth-first search. Our ablation study indicates that our\nsupervised learning strategy provides a strong foundation upon which our\nreinforcement learning agent improves. The paths returned by our agent explain\nthe mechanisms by which a cause produces an effect. Moreover, for each edge on\na path, our causality graph provides its original source allowing for easy\nverification of paths.","updated":1711357067000,"published":1699216398000,"authors":["Lukas Bl\u00fcbaum","Stefan Heindorf"],"comments":"Accepted at WWW 2024","categories":["cs.AI","cs.LG"],"primary_category":"cs.AI","doi":"10.1145\/3589334.3645610","journal_ref":null,"peer_reviewed":true,"reader_id":"rid1","human_jargon_term":"ablation study","definition_text":"An ablation study is a research method used to determine the impact of various parts of a system by systematically removing or modifying them and observing the effect of these changes. This helps researchers understand which components are critical for the system's performance.","model":"gpt4_abstract","Accuracy":"accurate","Ranking":1,"Notes":""},"28":{"arxiv_id":"2311.02760v2","url":"http:\/\/arxiv.org\/abs\/2311.02760v2","title":"Causal Question Answering with Reinforcement Learning","summary":"Causal questions inquire about causal relationships between different events\nor phenomena. They are important for a variety of use cases, including virtual\nassistants and search engines. However, many current approaches to causal\nquestion answering cannot provide explanations or evidence for their answers.\nHence, in this paper, we aim to answer causal questions with a causality graph,\na large-scale dataset of causal relations between noun phrases along with the\nrelations' provenance data. Inspired by recent, successful applications of\nreinforcement learning to knowledge graph tasks, such as link prediction and\nfact-checking, we explore the application of reinforcement learning on a\ncausality graph for causal question answering. We introduce an\nActor-Critic-based agent which learns to search through the graph to answer\ncausal questions. We bootstrap the agent with a supervised learning procedure\nto deal with large action spaces and sparse rewards. Our evaluation shows that\nthe agent successfully prunes the search space to answer binary causal\nquestions by visiting less than 30 nodes per question compared to over 3,000\nnodes by a naive breadth-first search. Our ablation study indicates that our\nsupervised learning strategy provides a strong foundation upon which our\nreinforcement learning agent improves. The paths returned by our agent explain\nthe mechanisms by which a cause produces an effect. Moreover, for each edge on\na path, our causality graph provides its original source allowing for easy\nverification of paths.","updated":1711357067000,"published":1699216398000,"authors":["Lukas Bl\u00fcbaum","Stefan Heindorf"],"comments":"Accepted at WWW 2024","categories":["cs.AI","cs.LG"],"primary_category":"cs.AI","doi":"10.1145\/3589334.3645610","journal_ref":null,"peer_reviewed":true,"reader_id":"rid1","human_jargon_term":"causality graph","definition_text":"A causality graph is a visual representation that maps out and shows the relationships between different events or phenomena, indicating how one event can cause another. This can help in understanding and tracing the origin and impact of different causes and effects.","model":"gpt4_abstract","Accuracy":"accurate","Ranking":1,"Notes":""},"29":{"arxiv_id":"2311.02760v2","url":"http:\/\/arxiv.org\/abs\/2311.02760v2","title":"Causal Question Answering with Reinforcement Learning","summary":"Causal questions inquire about causal relationships between different events\nor phenomena. They are important for a variety of use cases, including virtual\nassistants and search engines. However, many current approaches to causal\nquestion answering cannot provide explanations or evidence for their answers.\nHence, in this paper, we aim to answer causal questions with a causality graph,\na large-scale dataset of causal relations between noun phrases along with the\nrelations' provenance data. Inspired by recent, successful applications of\nreinforcement learning to knowledge graph tasks, such as link prediction and\nfact-checking, we explore the application of reinforcement learning on a\ncausality graph for causal question answering. We introduce an\nActor-Critic-based agent which learns to search through the graph to answer\ncausal questions. We bootstrap the agent with a supervised learning procedure\nto deal with large action spaces and sparse rewards. Our evaluation shows that\nthe agent successfully prunes the search space to answer binary causal\nquestions by visiting less than 30 nodes per question compared to over 3,000\nnodes by a naive breadth-first search. Our ablation study indicates that our\nsupervised learning strategy provides a strong foundation upon which our\nreinforcement learning agent improves. The paths returned by our agent explain\nthe mechanisms by which a cause produces an effect. Moreover, for each edge on\na path, our causality graph provides its original source allowing for easy\nverification of paths.","updated":1711357067000,"published":1699216398000,"authors":["Lukas Bl\u00fcbaum","Stefan Heindorf"],"comments":"Accepted at WWW 2024","categories":["cs.AI","cs.LG"],"primary_category":"cs.AI","doi":"10.1145\/3589334.3645610","journal_ref":null,"peer_reviewed":true,"reader_id":"rid1","human_jargon_term":"knowledge graph tasks","definition_text":"Knowledge graph tasks involve using a structured network of interconnected data, where entities (such as people, places, and things) and their interrelationships are represented as nodes and edges, respectively. These tasks might include searching for specific information, determining relationships between concepts, or verifying facts by exploring how data points are linked within the graph.","model":"gpt4_abstract","Accuracy":"accurate","Ranking":1,"Notes":""},"30":{"arxiv_id":"2311.02760v2","url":"http:\/\/arxiv.org\/abs\/2311.02760v2","title":"Causal Question Answering with Reinforcement Learning","summary":"Causal questions inquire about causal relationships between different events\nor phenomena. They are important for a variety of use cases, including virtual\nassistants and search engines. However, many current approaches to causal\nquestion answering cannot provide explanations or evidence for their answers.\nHence, in this paper, we aim to answer causal questions with a causality graph,\na large-scale dataset of causal relations between noun phrases along with the\nrelations' provenance data. Inspired by recent, successful applications of\nreinforcement learning to knowledge graph tasks, such as link prediction and\nfact-checking, we explore the application of reinforcement learning on a\ncausality graph for causal question answering. We introduce an\nActor-Critic-based agent which learns to search through the graph to answer\ncausal questions. We bootstrap the agent with a supervised learning procedure\nto deal with large action spaces and sparse rewards. Our evaluation shows that\nthe agent successfully prunes the search space to answer binary causal\nquestions by visiting less than 30 nodes per question compared to over 3,000\nnodes by a naive breadth-first search. Our ablation study indicates that our\nsupervised learning strategy provides a strong foundation upon which our\nreinforcement learning agent improves. The paths returned by our agent explain\nthe mechanisms by which a cause produces an effect. Moreover, for each edge on\na path, our causality graph provides its original source allowing for easy\nverification of paths.","updated":1711357067000,"published":1699216398000,"authors":["Lukas Bl\u00fcbaum","Stefan Heindorf"],"comments":"Accepted at WWW 2024","categories":["cs.AI","cs.LG"],"primary_category":"cs.AI","doi":"10.1145\/3589334.3645610","journal_ref":null,"peer_reviewed":true,"reader_id":"rid1","human_jargon_term":"link prediction","definition_text":"Link prediction is a method used in network science to estimate whether a connection or relationship between two entities in a network, like people in a social network or pages on a website, might exist even if it's not currently observed. It helps in forecasting which new interactions or associations are likely to occur in the future.","model":"gpt4_abstract","Accuracy":"accurate","Ranking":1,"Notes":""},"31":{"arxiv_id":"2311.02760v2","url":"http:\/\/arxiv.org\/abs\/2311.02760v2","title":"Causal Question Answering with Reinforcement Learning","summary":"Causal questions inquire about causal relationships between different events\nor phenomena. They are important for a variety of use cases, including virtual\nassistants and search engines. However, many current approaches to causal\nquestion answering cannot provide explanations or evidence for their answers.\nHence, in this paper, we aim to answer causal questions with a causality graph,\na large-scale dataset of causal relations between noun phrases along with the\nrelations' provenance data. Inspired by recent, successful applications of\nreinforcement learning to knowledge graph tasks, such as link prediction and\nfact-checking, we explore the application of reinforcement learning on a\ncausality graph for causal question answering. We introduce an\nActor-Critic-based agent which learns to search through the graph to answer\ncausal questions. We bootstrap the agent with a supervised learning procedure\nto deal with large action spaces and sparse rewards. Our evaluation shows that\nthe agent successfully prunes the search space to answer binary causal\nquestions by visiting less than 30 nodes per question compared to over 3,000\nnodes by a naive breadth-first search. Our ablation study indicates that our\nsupervised learning strategy provides a strong foundation upon which our\nreinforcement learning agent improves. The paths returned by our agent explain\nthe mechanisms by which a cause produces an effect. Moreover, for each edge on\na path, our causality graph provides its original source allowing for easy\nverification of paths.","updated":1711357067000,"published":1699216398000,"authors":["Lukas Bl\u00fcbaum","Stefan Heindorf"],"comments":"Accepted at WWW 2024","categories":["cs.AI","cs.LG"],"primary_category":"cs.AI","doi":"10.1145\/3589334.3645610","journal_ref":null,"peer_reviewed":true,"reader_id":"rid1","human_jargon_term":"provenance data","definition_text":"Provenance data refers to the information that explains the origin or source of other data, helping to understand where it comes from and how it was generated or collected. This type of data is important for verifying the accuracy and reliability of the information.","model":"gpt4_abstract","Accuracy":"accurate","Ranking":0,"Notes":""},"32":{"arxiv_id":"2311.02760v2","url":"http:\/\/arxiv.org\/abs\/2311.02760v2","title":"Causal Question Answering with Reinforcement Learning","summary":"Causal questions inquire about causal relationships between different events\nor phenomena. They are important for a variety of use cases, including virtual\nassistants and search engines. However, many current approaches to causal\nquestion answering cannot provide explanations or evidence for their answers.\nHence, in this paper, we aim to answer causal questions with a causality graph,\na large-scale dataset of causal relations between noun phrases along with the\nrelations' provenance data. Inspired by recent, successful applications of\nreinforcement learning to knowledge graph tasks, such as link prediction and\nfact-checking, we explore the application of reinforcement learning on a\ncausality graph for causal question answering. We introduce an\nActor-Critic-based agent which learns to search through the graph to answer\ncausal questions. We bootstrap the agent with a supervised learning procedure\nto deal with large action spaces and sparse rewards. Our evaluation shows that\nthe agent successfully prunes the search space to answer binary causal\nquestions by visiting less than 30 nodes per question compared to over 3,000\nnodes by a naive breadth-first search. Our ablation study indicates that our\nsupervised learning strategy provides a strong foundation upon which our\nreinforcement learning agent improves. The paths returned by our agent explain\nthe mechanisms by which a cause produces an effect. Moreover, for each edge on\na path, our causality graph provides its original source allowing for easy\nverification of paths.","updated":1711357067000,"published":1699216398000,"authors":["Lukas Bl\u00fcbaum","Stefan Heindorf"],"comments":"Accepted at WWW 2024","categories":["cs.AI","cs.LG"],"primary_category":"cs.AI","doi":"10.1145\/3589334.3645610","journal_ref":null,"peer_reviewed":true,"reader_id":"rid1","human_jargon_term":"reinforcement learning","definition_text":"Reinforcement learning is a type of artificial intelligence where a computer program learns to make decisions by trying different actions and seeing which ones produce the most favorable outcomes, much like how a person learns from trial and error. This method focuses on maximizing the rewards it receives from these actions over time, enabling it to adapt and optimize its behavior.","model":"gpt4_abstract","Accuracy":"accurate","Ranking":0,"Notes":""},"33":{"arxiv_id":"2311.02760v2","url":"http:\/\/arxiv.org\/abs\/2311.02760v2","title":"Causal Question Answering with Reinforcement Learning","summary":"Causal questions inquire about causal relationships between different events\nor phenomena. They are important for a variety of use cases, including virtual\nassistants and search engines. However, many current approaches to causal\nquestion answering cannot provide explanations or evidence for their answers.\nHence, in this paper, we aim to answer causal questions with a causality graph,\na large-scale dataset of causal relations between noun phrases along with the\nrelations' provenance data. Inspired by recent, successful applications of\nreinforcement learning to knowledge graph tasks, such as link prediction and\nfact-checking, we explore the application of reinforcement learning on a\ncausality graph for causal question answering. We introduce an\nActor-Critic-based agent which learns to search through the graph to answer\ncausal questions. We bootstrap the agent with a supervised learning procedure\nto deal with large action spaces and sparse rewards. Our evaluation shows that\nthe agent successfully prunes the search space to answer binary causal\nquestions by visiting less than 30 nodes per question compared to over 3,000\nnodes by a naive breadth-first search. Our ablation study indicates that our\nsupervised learning strategy provides a strong foundation upon which our\nreinforcement learning agent improves. The paths returned by our agent explain\nthe mechanisms by which a cause produces an effect. Moreover, for each edge on\na path, our causality graph provides its original source allowing for easy\nverification of paths.","updated":1711357067000,"published":1699216398000,"authors":["Lukas Bl\u00fcbaum","Stefan Heindorf"],"comments":"Accepted at WWW 2024","categories":["cs.AI","cs.LG"],"primary_category":"cs.AI","doi":"10.1145\/3589334.3645610","journal_ref":null,"peer_reviewed":true,"reader_id":"rid1","human_jargon_term":"supervised learning procedure","definition_text":"A supervised learning procedure involves training a computer model using data that already includes the correct answers, or outcomes. This method teaches the model to recognize patterns or make decisions based on examples where the input data and the desired result are both known.","model":"gpt4_abstract","Accuracy":"accurate","Ranking":0,"Notes":""},"34":{"arxiv_id":"2403.17358v1","url":"http:\/\/arxiv.org\/abs\/2403.17358v1","title":"Addressing Myopic Constrained POMDP Planning with Recursive Dual Ascent","summary":"Lagrangian-guided Monte Carlo tree search with global dual ascent has been\napplied to solve large constrained partially observable Markov decision\nprocesses (CPOMDPs) online. In this work, we demonstrate that these global dual\nparameters can lead to myopic action selection during exploration, ultimately\nleading to suboptimal decision making. To address this, we introduce\nhistory-dependent dual variables that guide local action selection and are\noptimized with recursive dual ascent. We empirically compare the performance of\nour approach on a motivating toy example and two large CPOMDPs, demonstrating\nimproved exploration, and ultimately, safer outcomes.","updated":1711424793000,"published":1711424793000,"authors":["Paula Stocco","Suhas Chundi","Arec Jamgochian","Mykel J. Kochenderfer"],"comments":"Accepted to the 2024 International Conference on Automated Planning\n  and Scheduling (ICAPS)","categories":["cs.AI"],"primary_category":"cs.AI","doi":null,"journal_ref":null,"peer_reviewed":true,"reader_id":"rid1","human_jargon_term":"Lagrangian-guided Monte Carlo tree search","definition_text":"\"Lagrangian-guided Monte Carlo tree search\" is a computational technique used in decision-making processes that involve uncertainty and complex constraints. It combines theories from physics (Lagrangian mechanics) and computer science (Monte Carlo tree search) to efficiently explore and select the best actions in scenarios where numerous possibilities exist and external limitations must be considered.","model":"gpt4_abstract","Accuracy":"accurate","Ranking":1,"Notes":""},"35":{"arxiv_id":"2403.17358v1","url":"http:\/\/arxiv.org\/abs\/2403.17358v1","title":"Addressing Myopic Constrained POMDP Planning with Recursive Dual Ascent","summary":"Lagrangian-guided Monte Carlo tree search with global dual ascent has been\napplied to solve large constrained partially observable Markov decision\nprocesses (CPOMDPs) online. In this work, we demonstrate that these global dual\nparameters can lead to myopic action selection during exploration, ultimately\nleading to suboptimal decision making. To address this, we introduce\nhistory-dependent dual variables that guide local action selection and are\noptimized with recursive dual ascent. We empirically compare the performance of\nour approach on a motivating toy example and two large CPOMDPs, demonstrating\nimproved exploration, and ultimately, safer outcomes.","updated":1711424793000,"published":1711424793000,"authors":["Paula Stocco","Suhas Chundi","Arec Jamgochian","Mykel J. Kochenderfer"],"comments":"Accepted to the 2024 International Conference on Automated Planning\n  and Scheduling (ICAPS)","categories":["cs.AI"],"primary_category":"cs.AI","doi":null,"journal_ref":null,"peer_reviewed":true,"reader_id":"rid1","human_jargon_term":"Markov decision\nprocesses","definition_text":"Markov decision processes are mathematical models used to make a sequence of decisions in situations where outcomes are partly random and partly under the control of a decision maker. These models help in studying decision-making in scenarios where the present choice could affect future outcomes.","model":"gpt4_abstract","Accuracy":"accurate","Ranking":0,"Notes":""},"36":{"arxiv_id":"2403.17358v1","url":"http:\/\/arxiv.org\/abs\/2403.17358v1","title":"Addressing Myopic Constrained POMDP Planning with Recursive Dual Ascent","summary":"Lagrangian-guided Monte Carlo tree search with global dual ascent has been\napplied to solve large constrained partially observable Markov decision\nprocesses (CPOMDPs) online. In this work, we demonstrate that these global dual\nparameters can lead to myopic action selection during exploration, ultimately\nleading to suboptimal decision making. To address this, we introduce\nhistory-dependent dual variables that guide local action selection and are\noptimized with recursive dual ascent. We empirically compare the performance of\nour approach on a motivating toy example and two large CPOMDPs, demonstrating\nimproved exploration, and ultimately, safer outcomes.","updated":1711424793000,"published":1711424793000,"authors":["Paula Stocco","Suhas Chundi","Arec Jamgochian","Mykel J. Kochenderfer"],"comments":"Accepted to the 2024 International Conference on Automated Planning\n  and Scheduling (ICAPS)","categories":["cs.AI"],"primary_category":"cs.AI","doi":null,"journal_ref":null,"peer_reviewed":true,"reader_id":"rid1","human_jargon_term":"global dual ascent","definition_text":"Global dual ascent is a method used in optimization where the overall problem is broken into smaller parts and each part is solved individually to improve the overall solution step by step. This method is often employed to find the best outcome under certain constraints, improving results gradually by adjusting global parameters that affect the entire system.","model":"gpt4_abstract","Accuracy":"accurate","Ranking":0,"Notes":""},"37":{"arxiv_id":"2403.17358v1","url":"http:\/\/arxiv.org\/abs\/2403.17358v1","title":"Addressing Myopic Constrained POMDP Planning with Recursive Dual Ascent","summary":"Lagrangian-guided Monte Carlo tree search with global dual ascent has been\napplied to solve large constrained partially observable Markov decision\nprocesses (CPOMDPs) online. In this work, we demonstrate that these global dual\nparameters can lead to myopic action selection during exploration, ultimately\nleading to suboptimal decision making. To address this, we introduce\nhistory-dependent dual variables that guide local action selection and are\noptimized with recursive dual ascent. We empirically compare the performance of\nour approach on a motivating toy example and two large CPOMDPs, demonstrating\nimproved exploration, and ultimately, safer outcomes.","updated":1711424793000,"published":1711424793000,"authors":["Paula Stocco","Suhas Chundi","Arec Jamgochian","Mykel J. Kochenderfer"],"comments":"Accepted to the 2024 International Conference on Automated Planning\n  and Scheduling (ICAPS)","categories":["cs.AI"],"primary_category":"cs.AI","doi":null,"journal_ref":null,"peer_reviewed":true,"reader_id":"rid1","human_jargon_term":"myopic action selection","definition_text":"Myopic action selection refers to making decisions based solely on immediate benefits without considering long-term consequences. This approach can lead to choices that seem good in the short term but are suboptimal or detrimental over time.","model":"gpt4_abstract","Accuracy":"accurate","Ranking":0,"Notes":""},"38":{"arxiv_id":"2403.04124v1","url":"http:\/\/arxiv.org\/abs\/2403.04124v1","title":"Privacy-preserving Fine-tuning of Large Language Models through Flatness","summary":"The privacy concerns associated with the use of Large Language Models (LLMs)\nhave grown recently with the development of LLMs such as ChatGPT. Differential\nPrivacy (DP) techniques are explored in existing work to mitigate their privacy\nrisks at the cost of generalization degradation. Our paper reveals that the\nflatness of DP-trained models' loss landscape plays an essential role in the\ntrade-off between their privacy and generalization. We further propose a\nholistic framework to enforce appropriate weight flatness, which substantially\nimproves model generalization with competitive privacy preservation. It\ninnovates from three coarse-to-grained levels, including perturbation-aware\nmin-max optimization on model weights within a layer, flatness-guided sparse\nprefix-tuning on weights across layers, and weight knowledge distillation\nbetween DP \\& non-DP weights copies. Comprehensive experiments of both\nblack-box and white-box scenarios are conducted to demonstrate the\neffectiveness of our proposal in enhancing generalization and maintaining DP\ncharacteristics. For instance, on text classification dataset QNLI, DP-Flat\nachieves similar performance with non-private full fine-tuning but with DP\nguarantee under privacy budget $\\epsilon=3$, and even better performance given\nhigher privacy budgets. Codes are provided in the supplement.","updated":1709772251000,"published":1709772251000,"authors":["Tiejin Chen","Longchao Da","Huixue Zhou","Pingzhi Li","Kaixiong Zhou","Tianlong Chen","Hua Wei"],"comments":"Accepted to ICLR 2024 SeT LLM Workshop","categories":["cs.AI","I.2"],"primary_category":"cs.AI","doi":null,"journal_ref":null,"peer_reviewed":true,"reader_id":"rid1","human_jargon_term":"Differential Privacy","definition_text":"Differential Privacy (DP) is a technique used to protect an individual's privacy when sharing information in data analysis. It ensures that the results of queries or analyses remain essentially the same whether an individual's data is included or not, thus preventing the disclosure of private information.","model":"gpt4_abstract","Accuracy":"accurate","Ranking":0,"Notes":""},"39":{"arxiv_id":"2403.04124v1","url":"http:\/\/arxiv.org\/abs\/2403.04124v1","title":"Privacy-preserving Fine-tuning of Large Language Models through Flatness","summary":"The privacy concerns associated with the use of Large Language Models (LLMs)\nhave grown recently with the development of LLMs such as ChatGPT. Differential\nPrivacy (DP) techniques are explored in existing work to mitigate their privacy\nrisks at the cost of generalization degradation. Our paper reveals that the\nflatness of DP-trained models' loss landscape plays an essential role in the\ntrade-off between their privacy and generalization. We further propose a\nholistic framework to enforce appropriate weight flatness, which substantially\nimproves model generalization with competitive privacy preservation. It\ninnovates from three coarse-to-grained levels, including perturbation-aware\nmin-max optimization on model weights within a layer, flatness-guided sparse\nprefix-tuning on weights across layers, and weight knowledge distillation\nbetween DP \\& non-DP weights copies. Comprehensive experiments of both\nblack-box and white-box scenarios are conducted to demonstrate the\neffectiveness of our proposal in enhancing generalization and maintaining DP\ncharacteristics. For instance, on text classification dataset QNLI, DP-Flat\nachieves similar performance with non-private full fine-tuning but with DP\nguarantee under privacy budget $\\epsilon=3$, and even better performance given\nhigher privacy budgets. Codes are provided in the supplement.","updated":1709772251000,"published":1709772251000,"authors":["Tiejin Chen","Longchao Da","Huixue Zhou","Pingzhi Li","Kaixiong Zhou","Tianlong Chen","Hua Wei"],"comments":"Accepted to ICLR 2024 SeT LLM Workshop","categories":["cs.AI","I.2"],"primary_category":"cs.AI","doi":null,"journal_ref":null,"peer_reviewed":true,"reader_id":"rid1","human_jargon_term":"QNLI","definition_text":"QNLI stands for Question-answering Natural Language Inference, which is a type of dataset used to train and test artificial intelligence models on their ability to understand and process human language by determining whether a given answer logically follows from a question.","model":"gpt4_abstract","Accuracy":"accurate","Ranking":1,"Notes":""},"40":{"arxiv_id":"2403.04124v1","url":"http:\/\/arxiv.org\/abs\/2403.04124v1","title":"Privacy-preserving Fine-tuning of Large Language Models through Flatness","summary":"The privacy concerns associated with the use of Large Language Models (LLMs)\nhave grown recently with the development of LLMs such as ChatGPT. Differential\nPrivacy (DP) techniques are explored in existing work to mitigate their privacy\nrisks at the cost of generalization degradation. Our paper reveals that the\nflatness of DP-trained models' loss landscape plays an essential role in the\ntrade-off between their privacy and generalization. We further propose a\nholistic framework to enforce appropriate weight flatness, which substantially\nimproves model generalization with competitive privacy preservation. It\ninnovates from three coarse-to-grained levels, including perturbation-aware\nmin-max optimization on model weights within a layer, flatness-guided sparse\nprefix-tuning on weights across layers, and weight knowledge distillation\nbetween DP \\& non-DP weights copies. Comprehensive experiments of both\nblack-box and white-box scenarios are conducted to demonstrate the\neffectiveness of our proposal in enhancing generalization and maintaining DP\ncharacteristics. For instance, on text classification dataset QNLI, DP-Flat\nachieves similar performance with non-private full fine-tuning but with DP\nguarantee under privacy budget $\\epsilon=3$, and even better performance given\nhigher privacy budgets. Codes are provided in the supplement.","updated":1709772251000,"published":1709772251000,"authors":["Tiejin Chen","Longchao Da","Huixue Zhou","Pingzhi Li","Kaixiong Zhou","Tianlong Chen","Hua Wei"],"comments":"Accepted to ICLR 2024 SeT LLM Workshop","categories":["cs.AI","I.2"],"primary_category":"cs.AI","doi":null,"journal_ref":null,"peer_reviewed":true,"reader_id":"rid1","human_jargon_term":"black-box and white-box scenarios","definition_text":"In black-box scenarios, the inner workings of a system are not known to the tester, who only sees the inputs and outputs and must evaluate the system based on this limited visibility. Conversely, in white-box scenarios, the tester has full visibility into the system's internal workings, including access to the code, structures, and algorithms, allowing a more thorough evaluation.","model":"gpt4_abstract","Accuracy":"accurate","Ranking":1,"Notes":""},"41":{"arxiv_id":"2403.04124v1","url":"http:\/\/arxiv.org\/abs\/2403.04124v1","title":"Privacy-preserving Fine-tuning of Large Language Models through Flatness","summary":"The privacy concerns associated with the use of Large Language Models (LLMs)\nhave grown recently with the development of LLMs such as ChatGPT. Differential\nPrivacy (DP) techniques are explored in existing work to mitigate their privacy\nrisks at the cost of generalization degradation. Our paper reveals that the\nflatness of DP-trained models' loss landscape plays an essential role in the\ntrade-off between their privacy and generalization. We further propose a\nholistic framework to enforce appropriate weight flatness, which substantially\nimproves model generalization with competitive privacy preservation. It\ninnovates from three coarse-to-grained levels, including perturbation-aware\nmin-max optimization on model weights within a layer, flatness-guided sparse\nprefix-tuning on weights across layers, and weight knowledge distillation\nbetween DP \\& non-DP weights copies. Comprehensive experiments of both\nblack-box and white-box scenarios are conducted to demonstrate the\neffectiveness of our proposal in enhancing generalization and maintaining DP\ncharacteristics. For instance, on text classification dataset QNLI, DP-Flat\nachieves similar performance with non-private full fine-tuning but with DP\nguarantee under privacy budget $\\epsilon=3$, and even better performance given\nhigher privacy budgets. Codes are provided in the supplement.","updated":1709772251000,"published":1709772251000,"authors":["Tiejin Chen","Longchao Da","Huixue Zhou","Pingzhi Li","Kaixiong Zhou","Tianlong Chen","Hua Wei"],"comments":"Accepted to ICLR 2024 SeT LLM Workshop","categories":["cs.AI","I.2"],"primary_category":"cs.AI","doi":null,"journal_ref":null,"peer_reviewed":true,"reader_id":"rid1","human_jargon_term":"coarse-to-grained","definition_text":"The term \"coarse-to-grained\" refers to a methodological approach that starts with broad, generalized strategies (coarse) and progresses towards more detailed, specific strategies (grained) to address a problem or improve a process. This approach is useful in tackling complex issues by handling them at different levels of detail.","model":"gpt4_abstract","Accuracy":"accurate","Ranking":1,"Notes":""},"42":{"arxiv_id":"2403.04124v1","url":"http:\/\/arxiv.org\/abs\/2403.04124v1","title":"Privacy-preserving Fine-tuning of Large Language Models through Flatness","summary":"The privacy concerns associated with the use of Large Language Models (LLMs)\nhave grown recently with the development of LLMs such as ChatGPT. Differential\nPrivacy (DP) techniques are explored in existing work to mitigate their privacy\nrisks at the cost of generalization degradation. Our paper reveals that the\nflatness of DP-trained models' loss landscape plays an essential role in the\ntrade-off between their privacy and generalization. We further propose a\nholistic framework to enforce appropriate weight flatness, which substantially\nimproves model generalization with competitive privacy preservation. It\ninnovates from three coarse-to-grained levels, including perturbation-aware\nmin-max optimization on model weights within a layer, flatness-guided sparse\nprefix-tuning on weights across layers, and weight knowledge distillation\nbetween DP \\& non-DP weights copies. Comprehensive experiments of both\nblack-box and white-box scenarios are conducted to demonstrate the\neffectiveness of our proposal in enhancing generalization and maintaining DP\ncharacteristics. For instance, on text classification dataset QNLI, DP-Flat\nachieves similar performance with non-private full fine-tuning but with DP\nguarantee under privacy budget $\\epsilon=3$, and even better performance given\nhigher privacy budgets. Codes are provided in the supplement.","updated":1709772251000,"published":1709772251000,"authors":["Tiejin Chen","Longchao Da","Huixue Zhou","Pingzhi Li","Kaixiong Zhou","Tianlong Chen","Hua Wei"],"comments":"Accepted to ICLR 2024 SeT LLM Workshop","categories":["cs.AI","I.2"],"primary_category":"cs.AI","doi":null,"journal_ref":null,"peer_reviewed":true,"reader_id":"rid1","human_jargon_term":"flatness","definition_text":"In the context of machine learning models like the one described, \"flatness\" refers to the characteristic of the model's loss landscape where smaller or smoother variations in model parameters (like weights) occur, leading to more stable and reliable predictions even when slight changes are made to these parameters. This can help in achieving better generalization, meaning the model performs well not just on the data it was trained on, but also on new, unseen data.","model":"gpt4_abstract","Accuracy":"accurate","Ranking":1,"Notes":""},"43":{"arxiv_id":"2403.04124v1","url":"http:\/\/arxiv.org\/abs\/2403.04124v1","title":"Privacy-preserving Fine-tuning of Large Language Models through Flatness","summary":"The privacy concerns associated with the use of Large Language Models (LLMs)\nhave grown recently with the development of LLMs such as ChatGPT. Differential\nPrivacy (DP) techniques are explored in existing work to mitigate their privacy\nrisks at the cost of generalization degradation. Our paper reveals that the\nflatness of DP-trained models' loss landscape plays an essential role in the\ntrade-off between their privacy and generalization. We further propose a\nholistic framework to enforce appropriate weight flatness, which substantially\nimproves model generalization with competitive privacy preservation. It\ninnovates from three coarse-to-grained levels, including perturbation-aware\nmin-max optimization on model weights within a layer, flatness-guided sparse\nprefix-tuning on weights across layers, and weight knowledge distillation\nbetween DP \\& non-DP weights copies. Comprehensive experiments of both\nblack-box and white-box scenarios are conducted to demonstrate the\neffectiveness of our proposal in enhancing generalization and maintaining DP\ncharacteristics. For instance, on text classification dataset QNLI, DP-Flat\nachieves similar performance with non-private full fine-tuning but with DP\nguarantee under privacy budget $\\epsilon=3$, and even better performance given\nhigher privacy budgets. Codes are provided in the supplement.","updated":1709772251000,"published":1709772251000,"authors":["Tiejin Chen","Longchao Da","Huixue Zhou","Pingzhi Li","Kaixiong Zhou","Tianlong Chen","Hua Wei"],"comments":"Accepted to ICLR 2024 SeT LLM Workshop","categories":["cs.AI","I.2"],"primary_category":"cs.AI","doi":null,"journal_ref":null,"peer_reviewed":true,"reader_id":"rid1","human_jargon_term":"generalization degradation","definition_text":"Generalization degradation refers to the decline in a model's ability to perform well on new, unseen data compared to how it performs on its training data. This usually happens when optimizing for certain features, like privacy in the case of using differential privacy, which then affects the model's overall effectiveness on tasks it wasn't specifically trained on.","model":"gpt4_abstract","Accuracy":"accurate","Ranking":2,"Notes":""},"44":{"arxiv_id":"2403.04124v1","url":"http:\/\/arxiv.org\/abs\/2403.04124v1","title":"Privacy-preserving Fine-tuning of Large Language Models through Flatness","summary":"The privacy concerns associated with the use of Large Language Models (LLMs)\nhave grown recently with the development of LLMs such as ChatGPT. Differential\nPrivacy (DP) techniques are explored in existing work to mitigate their privacy\nrisks at the cost of generalization degradation. Our paper reveals that the\nflatness of DP-trained models' loss landscape plays an essential role in the\ntrade-off between their privacy and generalization. We further propose a\nholistic framework to enforce appropriate weight flatness, which substantially\nimproves model generalization with competitive privacy preservation. It\ninnovates from three coarse-to-grained levels, including perturbation-aware\nmin-max optimization on model weights within a layer, flatness-guided sparse\nprefix-tuning on weights across layers, and weight knowledge distillation\nbetween DP \\& non-DP weights copies. Comprehensive experiments of both\nblack-box and white-box scenarios are conducted to demonstrate the\neffectiveness of our proposal in enhancing generalization and maintaining DP\ncharacteristics. For instance, on text classification dataset QNLI, DP-Flat\nachieves similar performance with non-private full fine-tuning but with DP\nguarantee under privacy budget $\\epsilon=3$, and even better performance given\nhigher privacy budgets. Codes are provided in the supplement.","updated":1709772251000,"published":1709772251000,"authors":["Tiejin Chen","Longchao Da","Huixue Zhou","Pingzhi Li","Kaixiong Zhou","Tianlong Chen","Hua Wei"],"comments":"Accepted to ICLR 2024 SeT LLM Workshop","categories":["cs.AI","I.2"],"primary_category":"cs.AI","doi":null,"journal_ref":null,"peer_reviewed":true,"reader_id":"rid1","human_jargon_term":"min-max optimization","definition_text":"Min-max optimization is a strategy used in mathematics and computer science where the goal is to minimize the possible maximum losses or risks in a given scenario. Essentially, it involves adjusting variables to find the best result that has the least worst outcome, balancing between competing interests or objectives.","model":"gpt4_abstract","Accuracy":"accurate","Ranking":0,"Notes":""},"45":{"arxiv_id":"2403.04124v1","url":"http:\/\/arxiv.org\/abs\/2403.04124v1","title":"Privacy-preserving Fine-tuning of Large Language Models through Flatness","summary":"The privacy concerns associated with the use of Large Language Models (LLMs)\nhave grown recently with the development of LLMs such as ChatGPT. Differential\nPrivacy (DP) techniques are explored in existing work to mitigate their privacy\nrisks at the cost of generalization degradation. Our paper reveals that the\nflatness of DP-trained models' loss landscape plays an essential role in the\ntrade-off between their privacy and generalization. We further propose a\nholistic framework to enforce appropriate weight flatness, which substantially\nimproves model generalization with competitive privacy preservation. It\ninnovates from three coarse-to-grained levels, including perturbation-aware\nmin-max optimization on model weights within a layer, flatness-guided sparse\nprefix-tuning on weights across layers, and weight knowledge distillation\nbetween DP \\& non-DP weights copies. Comprehensive experiments of both\nblack-box and white-box scenarios are conducted to demonstrate the\neffectiveness of our proposal in enhancing generalization and maintaining DP\ncharacteristics. For instance, on text classification dataset QNLI, DP-Flat\nachieves similar performance with non-private full fine-tuning but with DP\nguarantee under privacy budget $\\epsilon=3$, and even better performance given\nhigher privacy budgets. Codes are provided in the supplement.","updated":1709772251000,"published":1709772251000,"authors":["Tiejin Chen","Longchao Da","Huixue Zhou","Pingzhi Li","Kaixiong Zhou","Tianlong Chen","Hua Wei"],"comments":"Accepted to ICLR 2024 SeT LLM Workshop","categories":["cs.AI","I.2"],"primary_category":"cs.AI","doi":null,"journal_ref":null,"peer_reviewed":true,"reader_id":"rid1","human_jargon_term":"perturbation-aware","definition_text":"The term \"perturbation-aware\" refers to the characteristic of a system or model that has been designed to recognize and respond to changes or disturbances, known as perturbations, within its environment or internal structure. This awareness allows the system to adjust accordingly to maintain its effectiveness or accuracy.","model":"gpt4_abstract","Accuracy":"accurate","Ranking":0,"Notes":""},"46":{"arxiv_id":"2403.04124v1","url":"http:\/\/arxiv.org\/abs\/2403.04124v1","title":"Privacy-preserving Fine-tuning of Large Language Models through Flatness","summary":"The privacy concerns associated with the use of Large Language Models (LLMs)\nhave grown recently with the development of LLMs such as ChatGPT. Differential\nPrivacy (DP) techniques are explored in existing work to mitigate their privacy\nrisks at the cost of generalization degradation. Our paper reveals that the\nflatness of DP-trained models' loss landscape plays an essential role in the\ntrade-off between their privacy and generalization. We further propose a\nholistic framework to enforce appropriate weight flatness, which substantially\nimproves model generalization with competitive privacy preservation. It\ninnovates from three coarse-to-grained levels, including perturbation-aware\nmin-max optimization on model weights within a layer, flatness-guided sparse\nprefix-tuning on weights across layers, and weight knowledge distillation\nbetween DP \\& non-DP weights copies. Comprehensive experiments of both\nblack-box and white-box scenarios are conducted to demonstrate the\neffectiveness of our proposal in enhancing generalization and maintaining DP\ncharacteristics. For instance, on text classification dataset QNLI, DP-Flat\nachieves similar performance with non-private full fine-tuning but with DP\nguarantee under privacy budget $\\epsilon=3$, and even better performance given\nhigher privacy budgets. Codes are provided in the supplement.","updated":1709772251000,"published":1709772251000,"authors":["Tiejin Chen","Longchao Da","Huixue Zhou","Pingzhi Li","Kaixiong Zhou","Tianlong Chen","Hua Wei"],"comments":"Accepted to ICLR 2024 SeT LLM Workshop","categories":["cs.AI","I.2"],"primary_category":"cs.AI","doi":null,"journal_ref":null,"peer_reviewed":true,"reader_id":"rid1","human_jargon_term":"prefix-tuning","definition_text":"Prefix-tuning is a technique where small adjustments are made to a section of a model's parameters at the beginning of the model (the \"prefix\") to refine its performance without altering the entire model. This approach balances enhancing the model's capabilities while maintaining efficiency.","model":"gpt4_abstract","Accuracy":"accurate","Ranking":0,"Notes":""},"47":{"arxiv_id":"2403.04124v1","url":"http:\/\/arxiv.org\/abs\/2403.04124v1","title":"Privacy-preserving Fine-tuning of Large Language Models through Flatness","summary":"The privacy concerns associated with the use of Large Language Models (LLMs)\nhave grown recently with the development of LLMs such as ChatGPT. Differential\nPrivacy (DP) techniques are explored in existing work to mitigate their privacy\nrisks at the cost of generalization degradation. Our paper reveals that the\nflatness of DP-trained models' loss landscape plays an essential role in the\ntrade-off between their privacy and generalization. We further propose a\nholistic framework to enforce appropriate weight flatness, which substantially\nimproves model generalization with competitive privacy preservation. It\ninnovates from three coarse-to-grained levels, including perturbation-aware\nmin-max optimization on model weights within a layer, flatness-guided sparse\nprefix-tuning on weights across layers, and weight knowledge distillation\nbetween DP \\& non-DP weights copies. Comprehensive experiments of both\nblack-box and white-box scenarios are conducted to demonstrate the\neffectiveness of our proposal in enhancing generalization and maintaining DP\ncharacteristics. For instance, on text classification dataset QNLI, DP-Flat\nachieves similar performance with non-private full fine-tuning but with DP\nguarantee under privacy budget $\\epsilon=3$, and even better performance given\nhigher privacy budgets. Codes are provided in the supplement.","updated":1709772251000,"published":1709772251000,"authors":["Tiejin Chen","Longchao Da","Huixue Zhou","Pingzhi Li","Kaixiong Zhou","Tianlong Chen","Hua Wei"],"comments":"Accepted to ICLR 2024 SeT LLM Workshop","categories":["cs.AI","I.2"],"primary_category":"cs.AI","doi":null,"journal_ref":null,"peer_reviewed":true,"reader_id":"rid1","human_jargon_term":"weight knowledge distillation","definition_text":"Weight knowledge distillation is a technique where the information or knowledge from one set of model parameters (weights) is transferred to another, often making the receiving model perform better or more efficiently. This process can help improve privacy-preserving models by allowing them to learn from more complex models without compromising privacy.","model":"gpt4_abstract","Accuracy":"accurate","Ranking":2,"Notes":""},"48":{"arxiv_id":"2402.07398v2","url":"http:\/\/arxiv.org\/abs\/2402.07398v2","title":"VisLingInstruct: Elevating Zero-Shot Learning in Multi-Modal Language\n  Models with Autonomous Instruction Optimization","summary":"This paper presents VisLingInstruct, a novel approach to advancing\nMulti-Modal Language Models (MMLMs) in zero-shot learning. Current MMLMs show\nimpressive zero-shot abilities in multi-modal tasks, but their performance\ndepends heavily on the quality of instructions. VisLingInstruct tackles this by\nautonomously evaluating and optimizing instructional texts through In-Context\nLearning, improving the synergy between visual perception and linguistic\nexpression in MMLMs. Alongside this instructional advancement, we have also\noptimized the visual feature extraction modules in MMLMs, further augmenting\ntheir responsiveness to textual cues. Our comprehensive experiments on MMLMs,\nbased on FlanT5 and Vicuna, show that VisLingInstruct significantly improves\nzero-shot performance in visual multi-modal tasks. Notably, it achieves a 13.1%\nand 9% increase in accuracy over the prior state-of-the-art on the TextVQA and\nHatefulMemes datasets.","updated":1710426614000,"published":1707711196000,"authors":["Dongsheng Zhu","Xunzhu Tang","Weidong Han","Jinghui Lu","Yukun Zhao","Guoliang Xing","Junfeng Wang","Dawei Yin"],"comments":"Accepted to NAACL2024 main conference","categories":["cs.AI"],"primary_category":"cs.AI","doi":null,"journal_ref":null,"peer_reviewed":true,"reader_id":"rid1","human_jargon_term":"FlanT5","definition_text":"FlanT5 is a model developed for processing and understanding language, which helps computers better understand and generate human-like text based on the information they are given. This model is particularly used in scenarios where the computer needs to handle new tasks it hasn't explicitly been trained for, by using general instructions provided in natural language.","model":"gpt4_abstract","Accuracy":"accurate","Ranking":1,"Notes":""},"49":{"arxiv_id":"2402.07398v2","url":"http:\/\/arxiv.org\/abs\/2402.07398v2","title":"VisLingInstruct: Elevating Zero-Shot Learning in Multi-Modal Language\n  Models with Autonomous Instruction Optimization","summary":"This paper presents VisLingInstruct, a novel approach to advancing\nMulti-Modal Language Models (MMLMs) in zero-shot learning. Current MMLMs show\nimpressive zero-shot abilities in multi-modal tasks, but their performance\ndepends heavily on the quality of instructions. VisLingInstruct tackles this by\nautonomously evaluating and optimizing instructional texts through In-Context\nLearning, improving the synergy between visual perception and linguistic\nexpression in MMLMs. Alongside this instructional advancement, we have also\noptimized the visual feature extraction modules in MMLMs, further augmenting\ntheir responsiveness to textual cues. Our comprehensive experiments on MMLMs,\nbased on FlanT5 and Vicuna, show that VisLingInstruct significantly improves\nzero-shot performance in visual multi-modal tasks. Notably, it achieves a 13.1%\nand 9% increase in accuracy over the prior state-of-the-art on the TextVQA and\nHatefulMemes datasets.","updated":1710426614000,"published":1707711196000,"authors":["Dongsheng Zhu","Xunzhu Tang","Weidong Han","Jinghui Lu","Yukun Zhao","Guoliang Xing","Junfeng Wang","Dawei Yin"],"comments":"Accepted to NAACL2024 main conference","categories":["cs.AI"],"primary_category":"cs.AI","doi":null,"journal_ref":null,"peer_reviewed":true,"reader_id":"rid1","human_jargon_term":"In-Context Learning","definition_text":"In-Context Learning is a method used by some advanced computer models where the system learns to make decisions or perform tasks based on examples and information provided directly within the context of its current task, rather than from a pre-trained set of data. This approach helps the model adapt to new or varying situations without needing separate training for each new task.","model":"gpt4_abstract","Accuracy":"accurate","Ranking":1,"Notes":""},"50":{"arxiv_id":"2402.07398v2","url":"http:\/\/arxiv.org\/abs\/2402.07398v2","title":"VisLingInstruct: Elevating Zero-Shot Learning in Multi-Modal Language\n  Models with Autonomous Instruction Optimization","summary":"This paper presents VisLingInstruct, a novel approach to advancing\nMulti-Modal Language Models (MMLMs) in zero-shot learning. Current MMLMs show\nimpressive zero-shot abilities in multi-modal tasks, but their performance\ndepends heavily on the quality of instructions. VisLingInstruct tackles this by\nautonomously evaluating and optimizing instructional texts through In-Context\nLearning, improving the synergy between visual perception and linguistic\nexpression in MMLMs. Alongside this instructional advancement, we have also\noptimized the visual feature extraction modules in MMLMs, further augmenting\ntheir responsiveness to textual cues. Our comprehensive experiments on MMLMs,\nbased on FlanT5 and Vicuna, show that VisLingInstruct significantly improves\nzero-shot performance in visual multi-modal tasks. Notably, it achieves a 13.1%\nand 9% increase in accuracy over the prior state-of-the-art on the TextVQA and\nHatefulMemes datasets.","updated":1710426614000,"published":1707711196000,"authors":["Dongsheng Zhu","Xunzhu Tang","Weidong Han","Jinghui Lu","Yukun Zhao","Guoliang Xing","Junfeng Wang","Dawei Yin"],"comments":"Accepted to NAACL2024 main conference","categories":["cs.AI"],"primary_category":"cs.AI","doi":null,"journal_ref":null,"peer_reviewed":true,"reader_id":"rid1","human_jargon_term":"Multi-Modal Language Models","definition_text":"Multi-Modal Language Models are advanced computer systems that process and understand information from different forms, such as text and images, to perform tasks that involve both seeing and reading. These models integrate and interpret visual and verbal information to enhance their understanding and responsiveness to various inputs.","model":"gpt4_abstract","Accuracy":"accurate","Ranking":0,"Notes":""},"51":{"arxiv_id":"2402.07398v2","url":"http:\/\/arxiv.org\/abs\/2402.07398v2","title":"VisLingInstruct: Elevating Zero-Shot Learning in Multi-Modal Language\n  Models with Autonomous Instruction Optimization","summary":"This paper presents VisLingInstruct, a novel approach to advancing\nMulti-Modal Language Models (MMLMs) in zero-shot learning. Current MMLMs show\nimpressive zero-shot abilities in multi-modal tasks, but their performance\ndepends heavily on the quality of instructions. VisLingInstruct tackles this by\nautonomously evaluating and optimizing instructional texts through In-Context\nLearning, improving the synergy between visual perception and linguistic\nexpression in MMLMs. Alongside this instructional advancement, we have also\noptimized the visual feature extraction modules in MMLMs, further augmenting\ntheir responsiveness to textual cues. Our comprehensive experiments on MMLMs,\nbased on FlanT5 and Vicuna, show that VisLingInstruct significantly improves\nzero-shot performance in visual multi-modal tasks. Notably, it achieves a 13.1%\nand 9% increase in accuracy over the prior state-of-the-art on the TextVQA and\nHatefulMemes datasets.","updated":1710426614000,"published":1707711196000,"authors":["Dongsheng Zhu","Xunzhu Tang","Weidong Han","Jinghui Lu","Yukun Zhao","Guoliang Xing","Junfeng Wang","Dawei Yin"],"comments":"Accepted to NAACL2024 main conference","categories":["cs.AI"],"primary_category":"cs.AI","doi":null,"journal_ref":null,"peer_reviewed":true,"reader_id":"rid1","human_jargon_term":"TextVQA and HatefulMemes datasets","definition_text":"The TextVQA dataset is used to evaluate how well artificial intelligence models can understand and answer questions about text in images. The HatefulMemes dataset is used to test the ability of these models to detect and understand hateful content within memes, combining images and text.","model":"gpt4_abstract","Accuracy":"accurate","Ranking":0,"Notes":""},"52":{"arxiv_id":"2402.07398v2","url":"http:\/\/arxiv.org\/abs\/2402.07398v2","title":"VisLingInstruct: Elevating Zero-Shot Learning in Multi-Modal Language\n  Models with Autonomous Instruction Optimization","summary":"This paper presents VisLingInstruct, a novel approach to advancing\nMulti-Modal Language Models (MMLMs) in zero-shot learning. Current MMLMs show\nimpressive zero-shot abilities in multi-modal tasks, but their performance\ndepends heavily on the quality of instructions. VisLingInstruct tackles this by\nautonomously evaluating and optimizing instructional texts through In-Context\nLearning, improving the synergy between visual perception and linguistic\nexpression in MMLMs. Alongside this instructional advancement, we have also\noptimized the visual feature extraction modules in MMLMs, further augmenting\ntheir responsiveness to textual cues. Our comprehensive experiments on MMLMs,\nbased on FlanT5 and Vicuna, show that VisLingInstruct significantly improves\nzero-shot performance in visual multi-modal tasks. Notably, it achieves a 13.1%\nand 9% increase in accuracy over the prior state-of-the-art on the TextVQA and\nHatefulMemes datasets.","updated":1710426614000,"published":1707711196000,"authors":["Dongsheng Zhu","Xunzhu Tang","Weidong Han","Jinghui Lu","Yukun Zhao","Guoliang Xing","Junfeng Wang","Dawei Yin"],"comments":"Accepted to NAACL2024 main conference","categories":["cs.AI"],"primary_category":"cs.AI","doi":null,"journal_ref":null,"peer_reviewed":true,"reader_id":"rid1","human_jargon_term":"Vicuna","definition_text":"Vicuna in the given context refers to one of the Multi-Modal Language Models (MMLMs) that the paper utilized to conduct experiments and measure improvements in zero-shot learning tasks involving both visual and textual data.","model":"gpt4_abstract","Accuracy":"accurate","Ranking":1,"Notes":""},"53":{"arxiv_id":"2402.07398v2","url":"http:\/\/arxiv.org\/abs\/2402.07398v2","title":"VisLingInstruct: Elevating Zero-Shot Learning in Multi-Modal Language\n  Models with Autonomous Instruction Optimization","summary":"This paper presents VisLingInstruct, a novel approach to advancing\nMulti-Modal Language Models (MMLMs) in zero-shot learning. Current MMLMs show\nimpressive zero-shot abilities in multi-modal tasks, but their performance\ndepends heavily on the quality of instructions. VisLingInstruct tackles this by\nautonomously evaluating and optimizing instructional texts through In-Context\nLearning, improving the synergy between visual perception and linguistic\nexpression in MMLMs. Alongside this instructional advancement, we have also\noptimized the visual feature extraction modules in MMLMs, further augmenting\ntheir responsiveness to textual cues. Our comprehensive experiments on MMLMs,\nbased on FlanT5 and Vicuna, show that VisLingInstruct significantly improves\nzero-shot performance in visual multi-modal tasks. Notably, it achieves a 13.1%\nand 9% increase in accuracy over the prior state-of-the-art on the TextVQA and\nHatefulMemes datasets.","updated":1710426614000,"published":1707711196000,"authors":["Dongsheng Zhu","Xunzhu Tang","Weidong Han","Jinghui Lu","Yukun Zhao","Guoliang Xing","Junfeng Wang","Dawei Yin"],"comments":"Accepted to NAACL2024 main conference","categories":["cs.AI"],"primary_category":"cs.AI","doi":null,"journal_ref":null,"peer_reviewed":true,"reader_id":"rid1","human_jargon_term":"linguistic\nexpression","definition_text":"Linguistic expression refers to the way language is used to convey ideas, information, or feelings. It encompasses vocabulary, grammar, and the structure of sentences used in communication.","model":"gpt4_abstract","Accuracy":"accurate","Ranking":0,"Notes":""},"54":{"arxiv_id":"2402.07398v2","url":"http:\/\/arxiv.org\/abs\/2402.07398v2","title":"VisLingInstruct: Elevating Zero-Shot Learning in Multi-Modal Language\n  Models with Autonomous Instruction Optimization","summary":"This paper presents VisLingInstruct, a novel approach to advancing\nMulti-Modal Language Models (MMLMs) in zero-shot learning. Current MMLMs show\nimpressive zero-shot abilities in multi-modal tasks, but their performance\ndepends heavily on the quality of instructions. VisLingInstruct tackles this by\nautonomously evaluating and optimizing instructional texts through In-Context\nLearning, improving the synergy between visual perception and linguistic\nexpression in MMLMs. Alongside this instructional advancement, we have also\noptimized the visual feature extraction modules in MMLMs, further augmenting\ntheir responsiveness to textual cues. Our comprehensive experiments on MMLMs,\nbased on FlanT5 and Vicuna, show that VisLingInstruct significantly improves\nzero-shot performance in visual multi-modal tasks. Notably, it achieves a 13.1%\nand 9% increase in accuracy over the prior state-of-the-art on the TextVQA and\nHatefulMemes datasets.","updated":1710426614000,"published":1707711196000,"authors":["Dongsheng Zhu","Xunzhu Tang","Weidong Han","Jinghui Lu","Yukun Zhao","Guoliang Xing","Junfeng Wang","Dawei Yin"],"comments":"Accepted to NAACL2024 main conference","categories":["cs.AI"],"primary_category":"cs.AI","doi":null,"journal_ref":null,"peer_reviewed":true,"reader_id":"rid1","human_jargon_term":"multi-modal","definition_text":"\"Multi-modal\" refers to the combination and integration of different types of data or information, such as text, images, and sound, to enhance the processing and interpretation capabilities of a system or model. In the context of technology and artificial intelligence, it means using these various modes together to improve the performance and accuracy of tasks that involve complex data.","model":"gpt4_abstract","Accuracy":"accurate","Ranking":2,"Notes":""},"55":{"arxiv_id":"2402.07398v2","url":"http:\/\/arxiv.org\/abs\/2402.07398v2","title":"VisLingInstruct: Elevating Zero-Shot Learning in Multi-Modal Language\n  Models with Autonomous Instruction Optimization","summary":"This paper presents VisLingInstruct, a novel approach to advancing\nMulti-Modal Language Models (MMLMs) in zero-shot learning. Current MMLMs show\nimpressive zero-shot abilities in multi-modal tasks, but their performance\ndepends heavily on the quality of instructions. VisLingInstruct tackles this by\nautonomously evaluating and optimizing instructional texts through In-Context\nLearning, improving the synergy between visual perception and linguistic\nexpression in MMLMs. Alongside this instructional advancement, we have also\noptimized the visual feature extraction modules in MMLMs, further augmenting\ntheir responsiveness to textual cues. Our comprehensive experiments on MMLMs,\nbased on FlanT5 and Vicuna, show that VisLingInstruct significantly improves\nzero-shot performance in visual multi-modal tasks. Notably, it achieves a 13.1%\nand 9% increase in accuracy over the prior state-of-the-art on the TextVQA and\nHatefulMemes datasets.","updated":1710426614000,"published":1707711196000,"authors":["Dongsheng Zhu","Xunzhu Tang","Weidong Han","Jinghui Lu","Yukun Zhao","Guoliang Xing","Junfeng Wang","Dawei Yin"],"comments":"Accepted to NAACL2024 main conference","categories":["cs.AI"],"primary_category":"cs.AI","doi":null,"journal_ref":null,"peer_reviewed":true,"reader_id":"rid1","human_jargon_term":"visual perception","definition_text":"Visual perception refers to the ability of the brain to interpret and make sense of what the eyes see, essentially how we understand and perceive visual information from our environment.","model":"gpt4_abstract","Accuracy":"accurate","Ranking":0,"Notes":""},"56":{"arxiv_id":"2402.07398v2","url":"http:\/\/arxiv.org\/abs\/2402.07398v2","title":"VisLingInstruct: Elevating Zero-Shot Learning in Multi-Modal Language\n  Models with Autonomous Instruction Optimization","summary":"This paper presents VisLingInstruct, a novel approach to advancing\nMulti-Modal Language Models (MMLMs) in zero-shot learning. Current MMLMs show\nimpressive zero-shot abilities in multi-modal tasks, but their performance\ndepends heavily on the quality of instructions. VisLingInstruct tackles this by\nautonomously evaluating and optimizing instructional texts through In-Context\nLearning, improving the synergy between visual perception and linguistic\nexpression in MMLMs. Alongside this instructional advancement, we have also\noptimized the visual feature extraction modules in MMLMs, further augmenting\ntheir responsiveness to textual cues. Our comprehensive experiments on MMLMs,\nbased on FlanT5 and Vicuna, show that VisLingInstruct significantly improves\nzero-shot performance in visual multi-modal tasks. Notably, it achieves a 13.1%\nand 9% increase in accuracy over the prior state-of-the-art on the TextVQA and\nHatefulMemes datasets.","updated":1710426614000,"published":1707711196000,"authors":["Dongsheng Zhu","Xunzhu Tang","Weidong Han","Jinghui Lu","Yukun Zhao","Guoliang Xing","Junfeng Wang","Dawei Yin"],"comments":"Accepted to NAACL2024 main conference","categories":["cs.AI"],"primary_category":"cs.AI","doi":null,"journal_ref":null,"peer_reviewed":true,"reader_id":"rid1","human_jargon_term":"zero-shot abilities","definition_text":"Zero-shot abilities refer to a model's capability to correctly perform tasks it has not specifically been trained to do, using only its general understanding and any relevant instructions provided at the time of the task. This means the model can handle new challenges without needing prior exposure to similar situations.","model":"gpt4_abstract","Accuracy":"accurate","Ranking":0,"Notes":""},"57":{"arxiv_id":"2402.07398v2","url":"http:\/\/arxiv.org\/abs\/2402.07398v2","title":"VisLingInstruct: Elevating Zero-Shot Learning in Multi-Modal Language\n  Models with Autonomous Instruction Optimization","summary":"This paper presents VisLingInstruct, a novel approach to advancing\nMulti-Modal Language Models (MMLMs) in zero-shot learning. Current MMLMs show\nimpressive zero-shot abilities in multi-modal tasks, but their performance\ndepends heavily on the quality of instructions. VisLingInstruct tackles this by\nautonomously evaluating and optimizing instructional texts through In-Context\nLearning, improving the synergy between visual perception and linguistic\nexpression in MMLMs. Alongside this instructional advancement, we have also\noptimized the visual feature extraction modules in MMLMs, further augmenting\ntheir responsiveness to textual cues. Our comprehensive experiments on MMLMs,\nbased on FlanT5 and Vicuna, show that VisLingInstruct significantly improves\nzero-shot performance in visual multi-modal tasks. Notably, it achieves a 13.1%\nand 9% increase in accuracy over the prior state-of-the-art on the TextVQA and\nHatefulMemes datasets.","updated":1710426614000,"published":1707711196000,"authors":["Dongsheng Zhu","Xunzhu Tang","Weidong Han","Jinghui Lu","Yukun Zhao","Guoliang Xing","Junfeng Wang","Dawei Yin"],"comments":"Accepted to NAACL2024 main conference","categories":["cs.AI"],"primary_category":"cs.AI","doi":null,"journal_ref":null,"peer_reviewed":true,"reader_id":"rid1","human_jargon_term":"zero-shot learning","definition_text":"Zero-shot learning is a type of artificial intelligence that allows a model to correctly handle tasks it has never specifically seen or been trained on during its development. This capability enables the model to apply what it has learned from previous data to new, unseen scenarios without additional instruction.","model":"gpt4_abstract","Accuracy":"accurate","Ranking":0,"Notes":""},"58":{"arxiv_id":"2309.03685v2","url":"http:\/\/arxiv.org\/abs\/2309.03685v2","title":"PyGraft: Configurable Generation of Synthetic Schemas and Knowledge\n  Graphs at Your Fingertips","summary":"Knowledge graphs (KGs) have emerged as a prominent data representation and\nmanagement paradigm. Being usually underpinned by a schema (e.g., an ontology),\nKGs capture not only factual information but also contextual knowledge. In some\ntasks, a few KGs established themselves as standard benchmarks. However, recent\nworks outline that relying on a limited collection of datasets is not\nsufficient to assess the generalization capability of an approach. In some\ndata-sensitive fields such as education or medicine, access to public datasets\nis even more limited. To remedy the aforementioned issues, we release PyGraft,\na Python-based tool that generates highly customized, domain-agnostic schemas\nand KGs. The synthesized schemas encompass various RDFS and OWL constructs,\nwhile the synthesized KGs emulate the characteristics and scale of real-world\nKGs. Logical consistency of the generated resources is ultimately ensured by\nrunning a description logic (DL) reasoner. By providing a way of generating\nboth a schema and KG in a single pipeline, PyGraft's aim is to empower the\ngeneration of a more diverse array of KGs for benchmarking novel approaches in\nareas such as graph-based machine learning (ML), or more generally KG\nprocessing. In graph-based ML in particular, this should foster a more holistic\nevaluation of model performance and generalization capability, thereby going\nbeyond the limited collection of available benchmarks. PyGraft is available at:\nhttps:\/\/github.com\/nicolas-hbt\/pygraft.","updated":1709675803000,"published":1694091609000,"authors":["Nicolas Hubert","Pierre Monnin","Mathieu d'Aquin","Davy Monticolo","Armelle Brun"],"comments":"Accepted in ESWC 2024","categories":["cs.AI","cs.SE"],"primary_category":"cs.AI","doi":null,"journal_ref":null,"peer_reviewed":true,"reader_id":"rid1","human_jargon_term":"Knowledge graphs","definition_text":"Knowledge graphs are tools used to store and manage complex sets of data by mapping out how different pieces of information are related to each other. They help in visualizing connections and relationships between facts and concepts, making it easier to understand and use the stored information effectively.","model":"gpt4_abstract","Accuracy":"accurate","Ranking":0,"Notes":""},"59":{"arxiv_id":"2309.03685v2","url":"http:\/\/arxiv.org\/abs\/2309.03685v2","title":"PyGraft: Configurable Generation of Synthetic Schemas and Knowledge\n  Graphs at Your Fingertips","summary":"Knowledge graphs (KGs) have emerged as a prominent data representation and\nmanagement paradigm. Being usually underpinned by a schema (e.g., an ontology),\nKGs capture not only factual information but also contextual knowledge. In some\ntasks, a few KGs established themselves as standard benchmarks. However, recent\nworks outline that relying on a limited collection of datasets is not\nsufficient to assess the generalization capability of an approach. In some\ndata-sensitive fields such as education or medicine, access to public datasets\nis even more limited. To remedy the aforementioned issues, we release PyGraft,\na Python-based tool that generates highly customized, domain-agnostic schemas\nand KGs. The synthesized schemas encompass various RDFS and OWL constructs,\nwhile the synthesized KGs emulate the characteristics and scale of real-world\nKGs. Logical consistency of the generated resources is ultimately ensured by\nrunning a description logic (DL) reasoner. By providing a way of generating\nboth a schema and KG in a single pipeline, PyGraft's aim is to empower the\ngeneration of a more diverse array of KGs for benchmarking novel approaches in\nareas such as graph-based machine learning (ML), or more generally KG\nprocessing. In graph-based ML in particular, this should foster a more holistic\nevaluation of model performance and generalization capability, thereby going\nbeyond the limited collection of available benchmarks. PyGraft is available at:\nhttps:\/\/github.com\/nicolas-hbt\/pygraft.","updated":1709675803000,"published":1694091609000,"authors":["Nicolas Hubert","Pierre Monnin","Mathieu d'Aquin","Davy Monticolo","Armelle Brun"],"comments":"Accepted in ESWC 2024","categories":["cs.AI","cs.SE"],"primary_category":"cs.AI","doi":null,"journal_ref":null,"peer_reviewed":true,"reader_id":"rid1","human_jargon_term":"PyGraft","definition_text":"PyGraft is a software tool designed to create customizable and domain-independent knowledge graphs and schemas, which are structured models to organize and categorize information. It helps overcome limitations of data availability in certain fields by allowing users to generate varied and realistic datasets that can be used for testing and enhancing different data processing and machine learning applications.","model":"gpt4_abstract","Accuracy":"accurate","Ranking":0,"Notes":""},"60":{"arxiv_id":"2309.03685v2","url":"http:\/\/arxiv.org\/abs\/2309.03685v2","title":"PyGraft: Configurable Generation of Synthetic Schemas and Knowledge\n  Graphs at Your Fingertips","summary":"Knowledge graphs (KGs) have emerged as a prominent data representation and\nmanagement paradigm. Being usually underpinned by a schema (e.g., an ontology),\nKGs capture not only factual information but also contextual knowledge. In some\ntasks, a few KGs established themselves as standard benchmarks. However, recent\nworks outline that relying on a limited collection of datasets is not\nsufficient to assess the generalization capability of an approach. In some\ndata-sensitive fields such as education or medicine, access to public datasets\nis even more limited. To remedy the aforementioned issues, we release PyGraft,\na Python-based tool that generates highly customized, domain-agnostic schemas\nand KGs. The synthesized schemas encompass various RDFS and OWL constructs,\nwhile the synthesized KGs emulate the characteristics and scale of real-world\nKGs. Logical consistency of the generated resources is ultimately ensured by\nrunning a description logic (DL) reasoner. By providing a way of generating\nboth a schema and KG in a single pipeline, PyGraft's aim is to empower the\ngeneration of a more diverse array of KGs for benchmarking novel approaches in\nareas such as graph-based machine learning (ML), or more generally KG\nprocessing. In graph-based ML in particular, this should foster a more holistic\nevaluation of model performance and generalization capability, thereby going\nbeyond the limited collection of available benchmarks. PyGraft is available at:\nhttps:\/\/github.com\/nicolas-hbt\/pygraft.","updated":1709675803000,"published":1694091609000,"authors":["Nicolas Hubert","Pierre Monnin","Mathieu d'Aquin","Davy Monticolo","Armelle Brun"],"comments":"Accepted in ESWC 2024","categories":["cs.AI","cs.SE"],"primary_category":"cs.AI","doi":null,"journal_ref":null,"peer_reviewed":true,"reader_id":"rid1","human_jargon_term":"RDFS and OWL constructs","definition_text":"RDFS (Resource Description Framework Schema) and OWL (Web Ontology Language) constructs are tools used in creating frameworks to categorize and define the relationships between different data elements on the web. These constructs help in organizing information in a way that it can be easily understood and used by computers to perform more complex tasks, such as searching for specific information or making connections between different pieces of data.","model":"gpt4_abstract","Accuracy":"accurate","Ranking":0,"Notes":""},"61":{"arxiv_id":"2309.03685v2","url":"http:\/\/arxiv.org\/abs\/2309.03685v2","title":"PyGraft: Configurable Generation of Synthetic Schemas and Knowledge\n  Graphs at Your Fingertips","summary":"Knowledge graphs (KGs) have emerged as a prominent data representation and\nmanagement paradigm. Being usually underpinned by a schema (e.g., an ontology),\nKGs capture not only factual information but also contextual knowledge. In some\ntasks, a few KGs established themselves as standard benchmarks. However, recent\nworks outline that relying on a limited collection of datasets is not\nsufficient to assess the generalization capability of an approach. In some\ndata-sensitive fields such as education or medicine, access to public datasets\nis even more limited. To remedy the aforementioned issues, we release PyGraft,\na Python-based tool that generates highly customized, domain-agnostic schemas\nand KGs. The synthesized schemas encompass various RDFS and OWL constructs,\nwhile the synthesized KGs emulate the characteristics and scale of real-world\nKGs. Logical consistency of the generated resources is ultimately ensured by\nrunning a description logic (DL) reasoner. By providing a way of generating\nboth a schema and KG in a single pipeline, PyGraft's aim is to empower the\ngeneration of a more diverse array of KGs for benchmarking novel approaches in\nareas such as graph-based machine learning (ML), or more generally KG\nprocessing. In graph-based ML in particular, this should foster a more holistic\nevaluation of model performance and generalization capability, thereby going\nbeyond the limited collection of available benchmarks. PyGraft is available at:\nhttps:\/\/github.com\/nicolas-hbt\/pygraft.","updated":1709675803000,"published":1694091609000,"authors":["Nicolas Hubert","Pierre Monnin","Mathieu d'Aquin","Davy Monticolo","Armelle Brun"],"comments":"Accepted in ESWC 2024","categories":["cs.AI","cs.SE"],"primary_category":"cs.AI","doi":null,"journal_ref":null,"peer_reviewed":true,"reader_id":"rid1","human_jargon_term":"description logic (DL) reasoner","definition_text":"A description logic (DL) reasoner is a software tool used to check and infer logical relationships and properties within a dataset, ensuring that the data follows specific rules and is logically consistent. It helps in maintaining the accuracy and integrity of the information in systems like knowledge graphs by automatically figuring out what is true based on the given data and rules.","model":"gpt4_abstract","Accuracy":"accurate","Ranking":0,"Notes":""},"62":{"arxiv_id":"2309.03685v2","url":"http:\/\/arxiv.org\/abs\/2309.03685v2","title":"PyGraft: Configurable Generation of Synthetic Schemas and Knowledge\n  Graphs at Your Fingertips","summary":"Knowledge graphs (KGs) have emerged as a prominent data representation and\nmanagement paradigm. Being usually underpinned by a schema (e.g., an ontology),\nKGs capture not only factual information but also contextual knowledge. In some\ntasks, a few KGs established themselves as standard benchmarks. However, recent\nworks outline that relying on a limited collection of datasets is not\nsufficient to assess the generalization capability of an approach. In some\ndata-sensitive fields such as education or medicine, access to public datasets\nis even more limited. To remedy the aforementioned issues, we release PyGraft,\na Python-based tool that generates highly customized, domain-agnostic schemas\nand KGs. The synthesized schemas encompass various RDFS and OWL constructs,\nwhile the synthesized KGs emulate the characteristics and scale of real-world\nKGs. Logical consistency of the generated resources is ultimately ensured by\nrunning a description logic (DL) reasoner. By providing a way of generating\nboth a schema and KG in a single pipeline, PyGraft's aim is to empower the\ngeneration of a more diverse array of KGs for benchmarking novel approaches in\nareas such as graph-based machine learning (ML), or more generally KG\nprocessing. In graph-based ML in particular, this should foster a more holistic\nevaluation of model performance and generalization capability, thereby going\nbeyond the limited collection of available benchmarks. PyGraft is available at:\nhttps:\/\/github.com\/nicolas-hbt\/pygraft.","updated":1709675803000,"published":1694091609000,"authors":["Nicolas Hubert","Pierre Monnin","Mathieu d'Aquin","Davy Monticolo","Armelle Brun"],"comments":"Accepted in ESWC 2024","categories":["cs.AI","cs.SE"],"primary_category":"cs.AI","doi":null,"journal_ref":null,"peer_reviewed":true,"reader_id":"rid1","human_jargon_term":"domain-agnostic","definition_text":"The term \"domain-agnostic\" refers to a technology or tool that is designed to be used across different areas of study or types of data without needing to be specialized for any particular one. This means it can be applied universally, regardless of the field or subject matter it is used for.","model":"gpt4_abstract","Accuracy":"accurate","Ranking":0,"Notes":""},"63":{"arxiv_id":"2309.03685v2","url":"http:\/\/arxiv.org\/abs\/2309.03685v2","title":"PyGraft: Configurable Generation of Synthetic Schemas and Knowledge\n  Graphs at Your Fingertips","summary":"Knowledge graphs (KGs) have emerged as a prominent data representation and\nmanagement paradigm. Being usually underpinned by a schema (e.g., an ontology),\nKGs capture not only factual information but also contextual knowledge. In some\ntasks, a few KGs established themselves as standard benchmarks. However, recent\nworks outline that relying on a limited collection of datasets is not\nsufficient to assess the generalization capability of an approach. In some\ndata-sensitive fields such as education or medicine, access to public datasets\nis even more limited. To remedy the aforementioned issues, we release PyGraft,\na Python-based tool that generates highly customized, domain-agnostic schemas\nand KGs. The synthesized schemas encompass various RDFS and OWL constructs,\nwhile the synthesized KGs emulate the characteristics and scale of real-world\nKGs. Logical consistency of the generated resources is ultimately ensured by\nrunning a description logic (DL) reasoner. By providing a way of generating\nboth a schema and KG in a single pipeline, PyGraft's aim is to empower the\ngeneration of a more diverse array of KGs for benchmarking novel approaches in\nareas such as graph-based machine learning (ML), or more generally KG\nprocessing. In graph-based ML in particular, this should foster a more holistic\nevaluation of model performance and generalization capability, thereby going\nbeyond the limited collection of available benchmarks. PyGraft is available at:\nhttps:\/\/github.com\/nicolas-hbt\/pygraft.","updated":1709675803000,"published":1694091609000,"authors":["Nicolas Hubert","Pierre Monnin","Mathieu d'Aquin","Davy Monticolo","Armelle Brun"],"comments":"Accepted in ESWC 2024","categories":["cs.AI","cs.SE"],"primary_category":"cs.AI","doi":null,"journal_ref":null,"peer_reviewed":true,"reader_id":"rid1","human_jargon_term":"schema","definition_text":"A schema, in the context of knowledge graphs, refers to a structured framework or blueprint that defines how data is organized and how different pieces of information relate to each other. It acts like a template to guide the construction and interpretation of data within the knowledge graph.","model":"gpt4_abstract","Accuracy":"accurate","Ranking":2,"Notes":""},"64":{"arxiv_id":"2301.13755v3","url":"http:\/\/arxiv.org\/abs\/2301.13755v3","title":"Retrosynthetic Planning with Dual Value Networks","summary":"Retrosynthesis, which aims to find a route to synthesize a target molecule\nfrom commercially available starting materials, is a critical task in drug\ndiscovery and materials design. Recently, the combination of ML-based\nsingle-step reaction predictors with multi-step planners has led to promising\nresults. However, the single-step predictors are mostly trained offline to\noptimize the single-step accuracy, without considering complete routes. Here,\nwe leverage reinforcement learning (RL) to improve the single-step predictor,\nby using a tree-shaped MDP to optimize complete routes. Specifically, we\npropose a novel online training algorithm, called Planning with Dual Value\nNetworks (PDVN), which alternates between the planning phase and updating\nphase. In PDVN, we construct two separate value networks to predict the\nsynthesizability and cost of molecules, respectively. To maintain the\nsingle-step accuracy, we design a two-branch network structure for the\nsingle-step predictor. On the widely-used USPTO dataset, our PDVN algorithm\nimproves the search success rate of existing multi-step planners (e.g.,\nincreasing the success rate from 85.79% to 98.95% for Retro*, and reducing the\nnumber of model calls by half while solving 99.47% molecules for RetroGraph).\nAdditionally, PDVN helps find shorter synthesis routes (e.g., reducing the\naverage route length from 5.76 to 4.83 for Retro*, and from 5.63 to 4.78 for\nRetroGraph). Our code is available at \\url{https:\/\/github.com\/DiXue98\/PDVN}.","updated":1709475801000,"published":1675183433000,"authors":["Guoqing Liu","Di Xue","Shufang Xie","Yingce Xia","Austin Tripp","Krzysztof Maziarz","Marwin Segler","Tao Qin","Zongzhang Zhang","Tie-Yan Liu"],"comments":"Accepted to ICML 2023","categories":["cs.AI","cs.LG"],"primary_category":"cs.AI","doi":null,"journal_ref":null,"peer_reviewed":true,"reader_id":"rid1","human_jargon_term":"Planning with Dual Value Networks","definition_text":"Planning with Dual Value Networks (PDVN) is a method used in computer science to improve how machines plan multiple steps in chemical synthesis. It uses two different systems (value networks) to evaluate both the feasibility and cost of each step, helping to find more efficient and possible ways to create a chemical compound.","model":"gpt4_abstract","Accuracy":"accurate","Ranking":2,"Notes":""},"65":{"arxiv_id":"2301.13755v3","url":"http:\/\/arxiv.org\/abs\/2301.13755v3","title":"Retrosynthetic Planning with Dual Value Networks","summary":"Retrosynthesis, which aims to find a route to synthesize a target molecule\nfrom commercially available starting materials, is a critical task in drug\ndiscovery and materials design. Recently, the combination of ML-based\nsingle-step reaction predictors with multi-step planners has led to promising\nresults. However, the single-step predictors are mostly trained offline to\noptimize the single-step accuracy, without considering complete routes. Here,\nwe leverage reinforcement learning (RL) to improve the single-step predictor,\nby using a tree-shaped MDP to optimize complete routes. Specifically, we\npropose a novel online training algorithm, called Planning with Dual Value\nNetworks (PDVN), which alternates between the planning phase and updating\nphase. In PDVN, we construct two separate value networks to predict the\nsynthesizability and cost of molecules, respectively. To maintain the\nsingle-step accuracy, we design a two-branch network structure for the\nsingle-step predictor. On the widely-used USPTO dataset, our PDVN algorithm\nimproves the search success rate of existing multi-step planners (e.g.,\nincreasing the success rate from 85.79% to 98.95% for Retro*, and reducing the\nnumber of model calls by half while solving 99.47% molecules for RetroGraph).\nAdditionally, PDVN helps find shorter synthesis routes (e.g., reducing the\naverage route length from 5.76 to 4.83 for Retro*, and from 5.63 to 4.78 for\nRetroGraph). Our code is available at \\url{https:\/\/github.com\/DiXue98\/PDVN}.","updated":1709475801000,"published":1675183433000,"authors":["Guoqing Liu","Di Xue","Shufang Xie","Yingce Xia","Austin Tripp","Krzysztof Maziarz","Marwin Segler","Tao Qin","Zongzhang Zhang","Tie-Yan Liu"],"comments":"Accepted to ICML 2023","categories":["cs.AI","cs.LG"],"primary_category":"cs.AI","doi":null,"journal_ref":null,"peer_reviewed":true,"reader_id":"rid1","human_jargon_term":"Retro*","definition_text":"Retro* is a type of multi-step planner used in computational chemistry to devise pathways for synthesizing complex molecules, starting from simpler, commercially available substances. It is part of computer algorithms that assist chemists in drug development and materials science by finding efficient routes for chemical synthesis.","model":"gpt4_abstract","Accuracy":"accurate","Ranking":1,"Notes":""},"66":{"arxiv_id":"2301.13755v3","url":"http:\/\/arxiv.org\/abs\/2301.13755v3","title":"Retrosynthetic Planning with Dual Value Networks","summary":"Retrosynthesis, which aims to find a route to synthesize a target molecule\nfrom commercially available starting materials, is a critical task in drug\ndiscovery and materials design. Recently, the combination of ML-based\nsingle-step reaction predictors with multi-step planners has led to promising\nresults. However, the single-step predictors are mostly trained offline to\noptimize the single-step accuracy, without considering complete routes. Here,\nwe leverage reinforcement learning (RL) to improve the single-step predictor,\nby using a tree-shaped MDP to optimize complete routes. Specifically, we\npropose a novel online training algorithm, called Planning with Dual Value\nNetworks (PDVN), which alternates between the planning phase and updating\nphase. In PDVN, we construct two separate value networks to predict the\nsynthesizability and cost of molecules, respectively. To maintain the\nsingle-step accuracy, we design a two-branch network structure for the\nsingle-step predictor. On the widely-used USPTO dataset, our PDVN algorithm\nimproves the search success rate of existing multi-step planners (e.g.,\nincreasing the success rate from 85.79% to 98.95% for Retro*, and reducing the\nnumber of model calls by half while solving 99.47% molecules for RetroGraph).\nAdditionally, PDVN helps find shorter synthesis routes (e.g., reducing the\naverage route length from 5.76 to 4.83 for Retro*, and from 5.63 to 4.78 for\nRetroGraph). Our code is available at \\url{https:\/\/github.com\/DiXue98\/PDVN}.","updated":1709475801000,"published":1675183433000,"authors":["Guoqing Liu","Di Xue","Shufang Xie","Yingce Xia","Austin Tripp","Krzysztof Maziarz","Marwin Segler","Tao Qin","Zongzhang Zhang","Tie-Yan Liu"],"comments":"Accepted to ICML 2023","categories":["cs.AI","cs.LG"],"primary_category":"cs.AI","doi":null,"journal_ref":null,"peer_reviewed":true,"reader_id":"rid1","human_jargon_term":"RetroGraph","definition_text":"RetroGraph is a type of computer algorithm used to plan multiple steps in the chemical synthesis of molecules, particularly useful in developing new drugs or materials by suggesting efficient sequences of chemical reactions starting from simpler, available substances.","model":"gpt4_abstract","Accuracy":"accurate","Ranking":2,"Notes":""},"67":{"arxiv_id":"2301.13755v3","url":"http:\/\/arxiv.org\/abs\/2301.13755v3","title":"Retrosynthetic Planning with Dual Value Networks","summary":"Retrosynthesis, which aims to find a route to synthesize a target molecule\nfrom commercially available starting materials, is a critical task in drug\ndiscovery and materials design. Recently, the combination of ML-based\nsingle-step reaction predictors with multi-step planners has led to promising\nresults. However, the single-step predictors are mostly trained offline to\noptimize the single-step accuracy, without considering complete routes. Here,\nwe leverage reinforcement learning (RL) to improve the single-step predictor,\nby using a tree-shaped MDP to optimize complete routes. Specifically, we\npropose a novel online training algorithm, called Planning with Dual Value\nNetworks (PDVN), which alternates between the planning phase and updating\nphase. In PDVN, we construct two separate value networks to predict the\nsynthesizability and cost of molecules, respectively. To maintain the\nsingle-step accuracy, we design a two-branch network structure for the\nsingle-step predictor. On the widely-used USPTO dataset, our PDVN algorithm\nimproves the search success rate of existing multi-step planners (e.g.,\nincreasing the success rate from 85.79% to 98.95% for Retro*, and reducing the\nnumber of model calls by half while solving 99.47% molecules for RetroGraph).\nAdditionally, PDVN helps find shorter synthesis routes (e.g., reducing the\naverage route length from 5.76 to 4.83 for Retro*, and from 5.63 to 4.78 for\nRetroGraph). Our code is available at \\url{https:\/\/github.com\/DiXue98\/PDVN}.","updated":1709475801000,"published":1675183433000,"authors":["Guoqing Liu","Di Xue","Shufang Xie","Yingce Xia","Austin Tripp","Krzysztof Maziarz","Marwin Segler","Tao Qin","Zongzhang Zhang","Tie-Yan Liu"],"comments":"Accepted to ICML 2023","categories":["cs.AI","cs.LG"],"primary_category":"cs.AI","doi":null,"journal_ref":null,"peer_reviewed":true,"reader_id":"rid1","human_jargon_term":"Retrosynthesis","definition_text":"Retrosynthesis is a method used by chemists to plan the creation of complex molecules by breaking them down into simpler, more readily available starting materials. This approach helps in figuring out a step-by-step process to synthesize a target molecule, starting from basic compounds.","model":"gpt4_abstract","Accuracy":"accurate","Ranking":1,"Notes":""},"68":{"arxiv_id":"2301.13755v3","url":"http:\/\/arxiv.org\/abs\/2301.13755v3","title":"Retrosynthetic Planning with Dual Value Networks","summary":"Retrosynthesis, which aims to find a route to synthesize a target molecule\nfrom commercially available starting materials, is a critical task in drug\ndiscovery and materials design. Recently, the combination of ML-based\nsingle-step reaction predictors with multi-step planners has led to promising\nresults. However, the single-step predictors are mostly trained offline to\noptimize the single-step accuracy, without considering complete routes. Here,\nwe leverage reinforcement learning (RL) to improve the single-step predictor,\nby using a tree-shaped MDP to optimize complete routes. Specifically, we\npropose a novel online training algorithm, called Planning with Dual Value\nNetworks (PDVN), which alternates between the planning phase and updating\nphase. In PDVN, we construct two separate value networks to predict the\nsynthesizability and cost of molecules, respectively. To maintain the\nsingle-step accuracy, we design a two-branch network structure for the\nsingle-step predictor. On the widely-used USPTO dataset, our PDVN algorithm\nimproves the search success rate of existing multi-step planners (e.g.,\nincreasing the success rate from 85.79% to 98.95% for Retro*, and reducing the\nnumber of model calls by half while solving 99.47% molecules for RetroGraph).\nAdditionally, PDVN helps find shorter synthesis routes (e.g., reducing the\naverage route length from 5.76 to 4.83 for Retro*, and from 5.63 to 4.78 for\nRetroGraph). Our code is available at \\url{https:\/\/github.com\/DiXue98\/PDVN}.","updated":1709475801000,"published":1675183433000,"authors":["Guoqing Liu","Di Xue","Shufang Xie","Yingce Xia","Austin Tripp","Krzysztof Maziarz","Marwin Segler","Tao Qin","Zongzhang Zhang","Tie-Yan Liu"],"comments":"Accepted to ICML 2023","categories":["cs.AI","cs.LG"],"primary_category":"cs.AI","doi":null,"journal_ref":null,"peer_reviewed":true,"reader_id":"rid1","human_jargon_term":"USPTO dataset","definition_text":"The USPTO dataset refers to a collection of data that includes various chemical reactions, which is used to train and evaluate machine learning models for predicting chemical synthesis processes. This dataset is derived from the United States Patent and Trademark Office, which holds numerous patents, including those related to chemical compounds and their synthesis methods.","model":"gpt4_abstract","Accuracy":"accurate","Ranking":2,"Notes":""},"69":{"arxiv_id":"2301.13755v3","url":"http:\/\/arxiv.org\/abs\/2301.13755v3","title":"Retrosynthetic Planning with Dual Value Networks","summary":"Retrosynthesis, which aims to find a route to synthesize a target molecule\nfrom commercially available starting materials, is a critical task in drug\ndiscovery and materials design. Recently, the combination of ML-based\nsingle-step reaction predictors with multi-step planners has led to promising\nresults. However, the single-step predictors are mostly trained offline to\noptimize the single-step accuracy, without considering complete routes. Here,\nwe leverage reinforcement learning (RL) to improve the single-step predictor,\nby using a tree-shaped MDP to optimize complete routes. Specifically, we\npropose a novel online training algorithm, called Planning with Dual Value\nNetworks (PDVN), which alternates between the planning phase and updating\nphase. In PDVN, we construct two separate value networks to predict the\nsynthesizability and cost of molecules, respectively. To maintain the\nsingle-step accuracy, we design a two-branch network structure for the\nsingle-step predictor. On the widely-used USPTO dataset, our PDVN algorithm\nimproves the search success rate of existing multi-step planners (e.g.,\nincreasing the success rate from 85.79% to 98.95% for Retro*, and reducing the\nnumber of model calls by half while solving 99.47% molecules for RetroGraph).\nAdditionally, PDVN helps find shorter synthesis routes (e.g., reducing the\naverage route length from 5.76 to 4.83 for Retro*, and from 5.63 to 4.78 for\nRetroGraph). Our code is available at \\url{https:\/\/github.com\/DiXue98\/PDVN}.","updated":1709475801000,"published":1675183433000,"authors":["Guoqing Liu","Di Xue","Shufang Xie","Yingce Xia","Austin Tripp","Krzysztof Maziarz","Marwin Segler","Tao Qin","Zongzhang Zhang","Tie-Yan Liu"],"comments":"Accepted to ICML 2023","categories":["cs.AI","cs.LG"],"primary_category":"cs.AI","doi":null,"journal_ref":null,"peer_reviewed":true,"reader_id":"rid1","human_jargon_term":"multi-step planners","definition_text":"Multi-step planners are tools used in scientific research to design and sequence a series of reactions that convert simple starting materials into more complex target molecules, enabling efficient synthesis planning over multiple steps. These planners help researchers determine the best pathway to create a desired molecule, considering factors like the feasibility and cost of each reaction in the sequence.","model":"gpt4_abstract","Accuracy":"accurate","Ranking":0,"Notes":""},"70":{"arxiv_id":"2301.13755v3","url":"http:\/\/arxiv.org\/abs\/2301.13755v3","title":"Retrosynthetic Planning with Dual Value Networks","summary":"Retrosynthesis, which aims to find a route to synthesize a target molecule\nfrom commercially available starting materials, is a critical task in drug\ndiscovery and materials design. Recently, the combination of ML-based\nsingle-step reaction predictors with multi-step planners has led to promising\nresults. However, the single-step predictors are mostly trained offline to\noptimize the single-step accuracy, without considering complete routes. Here,\nwe leverage reinforcement learning (RL) to improve the single-step predictor,\nby using a tree-shaped MDP to optimize complete routes. Specifically, we\npropose a novel online training algorithm, called Planning with Dual Value\nNetworks (PDVN), which alternates between the planning phase and updating\nphase. In PDVN, we construct two separate value networks to predict the\nsynthesizability and cost of molecules, respectively. To maintain the\nsingle-step accuracy, we design a two-branch network structure for the\nsingle-step predictor. On the widely-used USPTO dataset, our PDVN algorithm\nimproves the search success rate of existing multi-step planners (e.g.,\nincreasing the success rate from 85.79% to 98.95% for Retro*, and reducing the\nnumber of model calls by half while solving 99.47% molecules for RetroGraph).\nAdditionally, PDVN helps find shorter synthesis routes (e.g., reducing the\naverage route length from 5.76 to 4.83 for Retro*, and from 5.63 to 4.78 for\nRetroGraph). Our code is available at \\url{https:\/\/github.com\/DiXue98\/PDVN}.","updated":1709475801000,"published":1675183433000,"authors":["Guoqing Liu","Di Xue","Shufang Xie","Yingce Xia","Austin Tripp","Krzysztof Maziarz","Marwin Segler","Tao Qin","Zongzhang Zhang","Tie-Yan Liu"],"comments":"Accepted to ICML 2023","categories":["cs.AI","cs.LG"],"primary_category":"cs.AI","doi":null,"journal_ref":null,"peer_reviewed":true,"reader_id":"rid1","human_jargon_term":"single-step accuracy","definition_text":"Single-step accuracy refers to how well a model can predict the outcome of a single reaction in the process of turning simpler chemicals into a complex target molecule. It measures the model's ability to correctly choose the right chemical reaction at each individual step without considering the entire sequence of reactions leading to the final product.","model":"gpt4_abstract","Accuracy":"accurate","Ranking":0,"Notes":""},"71":{"arxiv_id":"2301.13755v3","url":"http:\/\/arxiv.org\/abs\/2301.13755v3","title":"Retrosynthetic Planning with Dual Value Networks","summary":"Retrosynthesis, which aims to find a route to synthesize a target molecule\nfrom commercially available starting materials, is a critical task in drug\ndiscovery and materials design. Recently, the combination of ML-based\nsingle-step reaction predictors with multi-step planners has led to promising\nresults. However, the single-step predictors are mostly trained offline to\noptimize the single-step accuracy, without considering complete routes. Here,\nwe leverage reinforcement learning (RL) to improve the single-step predictor,\nby using a tree-shaped MDP to optimize complete routes. Specifically, we\npropose a novel online training algorithm, called Planning with Dual Value\nNetworks (PDVN), which alternates between the planning phase and updating\nphase. In PDVN, we construct two separate value networks to predict the\nsynthesizability and cost of molecules, respectively. To maintain the\nsingle-step accuracy, we design a two-branch network structure for the\nsingle-step predictor. On the widely-used USPTO dataset, our PDVN algorithm\nimproves the search success rate of existing multi-step planners (e.g.,\nincreasing the success rate from 85.79% to 98.95% for Retro*, and reducing the\nnumber of model calls by half while solving 99.47% molecules for RetroGraph).\nAdditionally, PDVN helps find shorter synthesis routes (e.g., reducing the\naverage route length from 5.76 to 4.83 for Retro*, and from 5.63 to 4.78 for\nRetroGraph). Our code is available at \\url{https:\/\/github.com\/DiXue98\/PDVN}.","updated":1709475801000,"published":1675183433000,"authors":["Guoqing Liu","Di Xue","Shufang Xie","Yingce Xia","Austin Tripp","Krzysztof Maziarz","Marwin Segler","Tao Qin","Zongzhang Zhang","Tie-Yan Liu"],"comments":"Accepted to ICML 2023","categories":["cs.AI","cs.LG"],"primary_category":"cs.AI","doi":null,"journal_ref":null,"peer_reviewed":true,"reader_id":"rid1","human_jargon_term":"single-step predictor","definition_text":"A single-step predictor in the context of chemical synthesis is a tool used to identify the best chemical reaction for turning one specific molecule into another in just one step. This type of predictor uses machine learning to evaluate potential reactions quickly and choose the most effective one for each step in creating a larger sequence needed to produce a target molecule.","model":"gpt4_abstract","Accuracy":"accurate","Ranking":2,"Notes":""},"72":{"arxiv_id":"2301.13755v3","url":"http:\/\/arxiv.org\/abs\/2301.13755v3","title":"Retrosynthetic Planning with Dual Value Networks","summary":"Retrosynthesis, which aims to find a route to synthesize a target molecule\nfrom commercially available starting materials, is a critical task in drug\ndiscovery and materials design. Recently, the combination of ML-based\nsingle-step reaction predictors with multi-step planners has led to promising\nresults. However, the single-step predictors are mostly trained offline to\noptimize the single-step accuracy, without considering complete routes. Here,\nwe leverage reinforcement learning (RL) to improve the single-step predictor,\nby using a tree-shaped MDP to optimize complete routes. Specifically, we\npropose a novel online training algorithm, called Planning with Dual Value\nNetworks (PDVN), which alternates between the planning phase and updating\nphase. In PDVN, we construct two separate value networks to predict the\nsynthesizability and cost of molecules, respectively. To maintain the\nsingle-step accuracy, we design a two-branch network structure for the\nsingle-step predictor. On the widely-used USPTO dataset, our PDVN algorithm\nimproves the search success rate of existing multi-step planners (e.g.,\nincreasing the success rate from 85.79% to 98.95% for Retro*, and reducing the\nnumber of model calls by half while solving 99.47% molecules for RetroGraph).\nAdditionally, PDVN helps find shorter synthesis routes (e.g., reducing the\naverage route length from 5.76 to 4.83 for Retro*, and from 5.63 to 4.78 for\nRetroGraph). Our code is available at \\url{https:\/\/github.com\/DiXue98\/PDVN}.","updated":1709475801000,"published":1675183433000,"authors":["Guoqing Liu","Di Xue","Shufang Xie","Yingce Xia","Austin Tripp","Krzysztof Maziarz","Marwin Segler","Tao Qin","Zongzhang Zhang","Tie-Yan Liu"],"comments":"Accepted to ICML 2023","categories":["cs.AI","cs.LG"],"primary_category":"cs.AI","doi":null,"journal_ref":null,"peer_reviewed":true,"reader_id":"rid1","human_jargon_term":"single-step reaction predictors","definition_text":"Single-step reaction predictors are tools used in chemistry to forecast the outcome of an individual chemical reaction, such as determining what product would result from combining certain reactants. These predictors help chemists understand and plan specific steps within a larger chemical synthesis process.","model":"gpt4_abstract","Accuracy":"accurate","Ranking":1,"Notes":""},"73":{"arxiv_id":"2301.13755v3","url":"http:\/\/arxiv.org\/abs\/2301.13755v3","title":"Retrosynthetic Planning with Dual Value Networks","summary":"Retrosynthesis, which aims to find a route to synthesize a target molecule\nfrom commercially available starting materials, is a critical task in drug\ndiscovery and materials design. Recently, the combination of ML-based\nsingle-step reaction predictors with multi-step planners has led to promising\nresults. However, the single-step predictors are mostly trained offline to\noptimize the single-step accuracy, without considering complete routes. Here,\nwe leverage reinforcement learning (RL) to improve the single-step predictor,\nby using a tree-shaped MDP to optimize complete routes. Specifically, we\npropose a novel online training algorithm, called Planning with Dual Value\nNetworks (PDVN), which alternates between the planning phase and updating\nphase. In PDVN, we construct two separate value networks to predict the\nsynthesizability and cost of molecules, respectively. To maintain the\nsingle-step accuracy, we design a two-branch network structure for the\nsingle-step predictor. On the widely-used USPTO dataset, our PDVN algorithm\nimproves the search success rate of existing multi-step planners (e.g.,\nincreasing the success rate from 85.79% to 98.95% for Retro*, and reducing the\nnumber of model calls by half while solving 99.47% molecules for RetroGraph).\nAdditionally, PDVN helps find shorter synthesis routes (e.g., reducing the\naverage route length from 5.76 to 4.83 for Retro*, and from 5.63 to 4.78 for\nRetroGraph). Our code is available at \\url{https:\/\/github.com\/DiXue98\/PDVN}.","updated":1709475801000,"published":1675183433000,"authors":["Guoqing Liu","Di Xue","Shufang Xie","Yingce Xia","Austin Tripp","Krzysztof Maziarz","Marwin Segler","Tao Qin","Zongzhang Zhang","Tie-Yan Liu"],"comments":"Accepted to ICML 2023","categories":["cs.AI","cs.LG"],"primary_category":"cs.AI","doi":null,"journal_ref":null,"peer_reviewed":true,"reader_id":"rid1","human_jargon_term":"tree-shaped MDP","definition_text":"A tree-shaped MDP (Markov Decision Process) is a framework used in decision-making models where choices branch out like a tree from one decision to the next. Each branch represents a possible decision or outcome, helping to systematically explore different sequences of decisions to achieve the best possible result in planning or solving a problem.","model":"gpt4_abstract","Accuracy":"accurate","Ranking":2,"Notes":""},"74":{"arxiv_id":"2312.14106v2","url":"http:\/\/arxiv.org\/abs\/2312.14106v2","title":"Learning Human-like Representations to Enable Learning Human Values","summary":"How can we build AI systems that are aligned with human values to avoid\ncausing harm or violating societal standards for acceptable behavior? We argue\nthat representational alignment between humans and AI agents facilitates value\nalignment. Making AI systems learn human-like representations of the world has\nmany known benefits, including improving generalization, robustness to domain\nshifts, and few-shot learning performance. We propose that this kind of\nrepresentational alignment between machine learning (ML) models and humans can\nalso support value alignment, allowing ML systems to conform to human values\nand societal norms. We focus on ethics as one aspect of value alignment and\ntrain ML agents using a variety of methods in a multi-armed bandit setting,\nwhere rewards reflect the moral acceptability of the chosen action. We use a\nsynthetic experiment to demonstrate that agents' representational alignment\nwith the environment bounds their learning performance. We then repeat this\nprocedure in a realistic setting, using textual action descriptions and\nsimilarity judgments collected from humans and a variety of language models, to\nshow that the results generalize and are model-agnostic when grounded in an\nethically relevant context.","updated":1710293875000,"published":1703183493000,"authors":["Andrea Wynn","Ilia Sucholutsky","Thomas L. Griffiths"],"comments":"Paper accepted in Human-Centric Representation Learning workshop at\n  AAAI 2024 (https:\/\/hcrl-workshop.github.io\/2024\/)","categories":["cs.AI","cs.LG"],"primary_category":"cs.AI","doi":null,"journal_ref":null,"peer_reviewed":true,"reader_id":"rid1","human_jargon_term":"ML agents","definition_text":"ML agents refer to computer systems or software that are designed to learn from data and make decisions or predictions based on that data, essentially learning to perform tasks or make assessments without being explicitly programmed for every situation. Their behavior can improve over time as they learn from new information and experiences.","model":"gpt4_abstract","Accuracy":"accurate","Ranking":0,"Notes":""},"75":{"arxiv_id":"2312.14106v2","url":"http:\/\/arxiv.org\/abs\/2312.14106v2","title":"Learning Human-like Representations to Enable Learning Human Values","summary":"How can we build AI systems that are aligned with human values to avoid\ncausing harm or violating societal standards for acceptable behavior? We argue\nthat representational alignment between humans and AI agents facilitates value\nalignment. Making AI systems learn human-like representations of the world has\nmany known benefits, including improving generalization, robustness to domain\nshifts, and few-shot learning performance. We propose that this kind of\nrepresentational alignment between machine learning (ML) models and humans can\nalso support value alignment, allowing ML systems to conform to human values\nand societal norms. We focus on ethics as one aspect of value alignment and\ntrain ML agents using a variety of methods in a multi-armed bandit setting,\nwhere rewards reflect the moral acceptability of the chosen action. We use a\nsynthetic experiment to demonstrate that agents' representational alignment\nwith the environment bounds their learning performance. We then repeat this\nprocedure in a realistic setting, using textual action descriptions and\nsimilarity judgments collected from humans and a variety of language models, to\nshow that the results generalize and are model-agnostic when grounded in an\nethically relevant context.","updated":1710293875000,"published":1703183493000,"authors":["Andrea Wynn","Ilia Sucholutsky","Thomas L. Griffiths"],"comments":"Paper accepted in Human-Centric Representation Learning workshop at\n  AAAI 2024 (https:\/\/hcrl-workshop.github.io\/2024\/)","categories":["cs.AI","cs.LG"],"primary_category":"cs.AI","doi":null,"journal_ref":null,"peer_reviewed":true,"reader_id":"rid1","human_jargon_term":"multi-armed bandit setting","definition_text":"A multi-armed bandit setting is a scenario used in experiments where a machine or AI has multiple options (like slot machines, or \"one-armed bandits\" in a casino), and it must choose the best option based on the rewards it receives after each choice. The goal is for the machine to learn which option gives the best outcome through repeated trials.","model":"gpt4_abstract","Accuracy":"accurate","Ranking":0,"Notes":""},"76":{"arxiv_id":"2312.00812v4","url":"http:\/\/arxiv.org\/abs\/2312.00812v4","title":"Empowering Autonomous Driving with Large Language Models: A Safety\n  Perspective","summary":"Autonomous Driving (AD) encounters significant safety hurdles in long-tail\nunforeseen driving scenarios, largely stemming from the non-interpretability\nand poor generalization of the deep neural networks within the AD system,\nparticularly in out-of-distribution and uncertain data. To this end, this paper\nexplores the integration of Large Language Models (LLMs) into AD systems,\nleveraging their robust common-sense knowledge and reasoning abilities. The\nproposed methodologies employ LLMs as intelligent decision-makers in behavioral\nplanning, augmented with a safety verifier shield for contextual safety\nlearning, for enhancing driving performance and safety. We present two key\nstudies in a simulated environment: an adaptive LLM-conditioned Model\nPredictive Control (MPC) and an LLM-enabled interactive behavior planning\nscheme with a state machine. Demonstrating superior performance and safety\nmetrics compared to state-of-the-art approaches, our approach shows the\npromising potential for using LLMs for autonomous vehicles.","updated":1711128541000,"published":1701141189000,"authors":["Yixuan Wang","Ruochen Jiao","Sinong Simon Zhan","Chengtian Lang","Chao Huang","Zhaoran Wang","Zhuoran Yang","Qi Zhu"],"comments":"Accepted to LLMAgent workshop @ICLR2024","categories":["cs.AI","cs.LG","cs.SY","eess.SY"],"primary_category":"cs.AI","doi":null,"journal_ref":null,"peer_reviewed":true,"reader_id":"rid1","human_jargon_term":"LLM-conditioned Model\nPredictive Control","definition_text":"LLM-conditioned Model Predictive Control (MPC) refers to a method where a large language model (LLM) is used to enhance traditional model predictive control systems in autonomous vehicles. This approach allows the system to make better decisions by incorporating advanced reasoning and understanding, improving the vehicle's performance and safety in unpredictable situations.","model":"gpt4_abstract","Accuracy":"accurate","Ranking":0,"Notes":"started marking -1 here"},"77":{"arxiv_id":"2312.00812v4","url":"http:\/\/arxiv.org\/abs\/2312.00812v4","title":"Empowering Autonomous Driving with Large Language Models: A Safety\n  Perspective","summary":"Autonomous Driving (AD) encounters significant safety hurdles in long-tail\nunforeseen driving scenarios, largely stemming from the non-interpretability\nand poor generalization of the deep neural networks within the AD system,\nparticularly in out-of-distribution and uncertain data. To this end, this paper\nexplores the integration of Large Language Models (LLMs) into AD systems,\nleveraging their robust common-sense knowledge and reasoning abilities. The\nproposed methodologies employ LLMs as intelligent decision-makers in behavioral\nplanning, augmented with a safety verifier shield for contextual safety\nlearning, for enhancing driving performance and safety. We present two key\nstudies in a simulated environment: an adaptive LLM-conditioned Model\nPredictive Control (MPC) and an LLM-enabled interactive behavior planning\nscheme with a state machine. Demonstrating superior performance and safety\nmetrics compared to state-of-the-art approaches, our approach shows the\npromising potential for using LLMs for autonomous vehicles.","updated":1711128541000,"published":1701141189000,"authors":["Yixuan Wang","Ruochen Jiao","Sinong Simon Zhan","Chengtian Lang","Chao Huang","Zhaoran Wang","Zhuoran Yang","Qi Zhu"],"comments":"Accepted to LLMAgent workshop @ICLR2024","categories":["cs.AI","cs.LG","cs.SY","eess.SY"],"primary_category":"cs.AI","doi":null,"journal_ref":null,"peer_reviewed":true,"reader_id":"rid1","human_jargon_term":"LLM-enabled interactive behavior planning scheme","definition_text":"An LLM-enabled interactive behavior planning scheme refers to a method in which large language models (LLMs) are used to help autonomous vehicles make decisions about how to behave or react in different driving situations. This approach allows the vehicle to interact and plan its actions more like a human would, based on the common sense and reasoning abilities of the language models.","model":"gpt4_abstract","Accuracy":"accurate","Ranking":1,"Notes":""},"78":{"arxiv_id":"2312.00812v4","url":"http:\/\/arxiv.org\/abs\/2312.00812v4","title":"Empowering Autonomous Driving with Large Language Models: A Safety\n  Perspective","summary":"Autonomous Driving (AD) encounters significant safety hurdles in long-tail\nunforeseen driving scenarios, largely stemming from the non-interpretability\nand poor generalization of the deep neural networks within the AD system,\nparticularly in out-of-distribution and uncertain data. To this end, this paper\nexplores the integration of Large Language Models (LLMs) into AD systems,\nleveraging their robust common-sense knowledge and reasoning abilities. The\nproposed methodologies employ LLMs as intelligent decision-makers in behavioral\nplanning, augmented with a safety verifier shield for contextual safety\nlearning, for enhancing driving performance and safety. We present two key\nstudies in a simulated environment: an adaptive LLM-conditioned Model\nPredictive Control (MPC) and an LLM-enabled interactive behavior planning\nscheme with a state machine. Demonstrating superior performance and safety\nmetrics compared to state-of-the-art approaches, our approach shows the\npromising potential for using LLMs for autonomous vehicles.","updated":1711128541000,"published":1701141189000,"authors":["Yixuan Wang","Ruochen Jiao","Sinong Simon Zhan","Chengtian Lang","Chao Huang","Zhaoran Wang","Zhuoran Yang","Qi Zhu"],"comments":"Accepted to LLMAgent workshop @ICLR2024","categories":["cs.AI","cs.LG","cs.SY","eess.SY"],"primary_category":"cs.AI","doi":null,"journal_ref":null,"peer_reviewed":true,"reader_id":"rid1","human_jargon_term":"behavioral\nplanning","definition_text":"Behavioral planning in the context of autonomous driving refers to the process where the system decides the actions of a vehicle, such as when to turn, speed up, or slow down, based on current traffic conditions and road rules. This involves predicting and reacting to the behavior of other drivers and obstacles to ensure safe and efficient driving.","model":"gpt4_abstract","Accuracy":"accurate","Ranking":2,"Notes":""},"79":{"arxiv_id":"2312.00812v4","url":"http:\/\/arxiv.org\/abs\/2312.00812v4","title":"Empowering Autonomous Driving with Large Language Models: A Safety\n  Perspective","summary":"Autonomous Driving (AD) encounters significant safety hurdles in long-tail\nunforeseen driving scenarios, largely stemming from the non-interpretability\nand poor generalization of the deep neural networks within the AD system,\nparticularly in out-of-distribution and uncertain data. To this end, this paper\nexplores the integration of Large Language Models (LLMs) into AD systems,\nleveraging their robust common-sense knowledge and reasoning abilities. The\nproposed methodologies employ LLMs as intelligent decision-makers in behavioral\nplanning, augmented with a safety verifier shield for contextual safety\nlearning, for enhancing driving performance and safety. We present two key\nstudies in a simulated environment: an adaptive LLM-conditioned Model\nPredictive Control (MPC) and an LLM-enabled interactive behavior planning\nscheme with a state machine. Demonstrating superior performance and safety\nmetrics compared to state-of-the-art approaches, our approach shows the\npromising potential for using LLMs for autonomous vehicles.","updated":1711128541000,"published":1701141189000,"authors":["Yixuan Wang","Ruochen Jiao","Sinong Simon Zhan","Chengtian Lang","Chao Huang","Zhaoran Wang","Zhuoran Yang","Qi Zhu"],"comments":"Accepted to LLMAgent workshop @ICLR2024","categories":["cs.AI","cs.LG","cs.SY","eess.SY"],"primary_category":"cs.AI","doi":null,"journal_ref":null,"peer_reviewed":true,"reader_id":"rid1","human_jargon_term":"deep neural networks","definition_text":"Deep neural networks are a type of artificial intelligence that mimic the way the human brain works, allowing computers to recognize patterns and solve problems by learning from large amounts of data. They are made up of layers of interconnected nodes or \"neurons\" that process information to make decisions or predictions.","model":"gpt4_abstract","Accuracy":"accurate","Ranking":0,"Notes":""},"80":{"arxiv_id":"2312.00812v4","url":"http:\/\/arxiv.org\/abs\/2312.00812v4","title":"Empowering Autonomous Driving with Large Language Models: A Safety\n  Perspective","summary":"Autonomous Driving (AD) encounters significant safety hurdles in long-tail\nunforeseen driving scenarios, largely stemming from the non-interpretability\nand poor generalization of the deep neural networks within the AD system,\nparticularly in out-of-distribution and uncertain data. To this end, this paper\nexplores the integration of Large Language Models (LLMs) into AD systems,\nleveraging their robust common-sense knowledge and reasoning abilities. The\nproposed methodologies employ LLMs as intelligent decision-makers in behavioral\nplanning, augmented with a safety verifier shield for contextual safety\nlearning, for enhancing driving performance and safety. We present two key\nstudies in a simulated environment: an adaptive LLM-conditioned Model\nPredictive Control (MPC) and an LLM-enabled interactive behavior planning\nscheme with a state machine. Demonstrating superior performance and safety\nmetrics compared to state-of-the-art approaches, our approach shows the\npromising potential for using LLMs for autonomous vehicles.","updated":1711128541000,"published":1701141189000,"authors":["Yixuan Wang","Ruochen Jiao","Sinong Simon Zhan","Chengtian Lang","Chao Huang","Zhaoran Wang","Zhuoran Yang","Qi Zhu"],"comments":"Accepted to LLMAgent workshop @ICLR2024","categories":["cs.AI","cs.LG","cs.SY","eess.SY"],"primary_category":"cs.AI","doi":null,"journal_ref":null,"peer_reviewed":true,"reader_id":"rid1","human_jargon_term":"generalization","definition_text":"Generalization in this context refers to the ability of a computer system, such as those used in autonomous driving, to correctly interpret and react to new, previously unseen situations based on the knowledge it has learned from past experiences. It means the system can apply what it has learned to new and different situations effectively.","model":"gpt4_abstract","Accuracy":"accurate","Ranking":1,"Notes":""},"81":{"arxiv_id":"2312.00812v4","url":"http:\/\/arxiv.org\/abs\/2312.00812v4","title":"Empowering Autonomous Driving with Large Language Models: A Safety\n  Perspective","summary":"Autonomous Driving (AD) encounters significant safety hurdles in long-tail\nunforeseen driving scenarios, largely stemming from the non-interpretability\nand poor generalization of the deep neural networks within the AD system,\nparticularly in out-of-distribution and uncertain data. To this end, this paper\nexplores the integration of Large Language Models (LLMs) into AD systems,\nleveraging their robust common-sense knowledge and reasoning abilities. The\nproposed methodologies employ LLMs as intelligent decision-makers in behavioral\nplanning, augmented with a safety verifier shield for contextual safety\nlearning, for enhancing driving performance and safety. We present two key\nstudies in a simulated environment: an adaptive LLM-conditioned Model\nPredictive Control (MPC) and an LLM-enabled interactive behavior planning\nscheme with a state machine. Demonstrating superior performance and safety\nmetrics compared to state-of-the-art approaches, our approach shows the\npromising potential for using LLMs for autonomous vehicles.","updated":1711128541000,"published":1701141189000,"authors":["Yixuan Wang","Ruochen Jiao","Sinong Simon Zhan","Chengtian Lang","Chao Huang","Zhaoran Wang","Zhuoran Yang","Qi Zhu"],"comments":"Accepted to LLMAgent workshop @ICLR2024","categories":["cs.AI","cs.LG","cs.SY","eess.SY"],"primary_category":"cs.AI","doi":null,"journal_ref":null,"peer_reviewed":true,"reader_id":"rid1","human_jargon_term":"non-interpretability","definition_text":"Non-interpretability refers to the difficulty of understanding or explaining how a system, like a deep neural network, makes decisions or arrives at its conclusions. This term highlights a challenge where it's hard to trace or articulate the reasoning behind the system's outputs.","model":"gpt4_abstract","Accuracy":"accurate","Ranking":0,"Notes":""},"82":{"arxiv_id":"2312.00812v4","url":"http:\/\/arxiv.org\/abs\/2312.00812v4","title":"Empowering Autonomous Driving with Large Language Models: A Safety\n  Perspective","summary":"Autonomous Driving (AD) encounters significant safety hurdles in long-tail\nunforeseen driving scenarios, largely stemming from the non-interpretability\nand poor generalization of the deep neural networks within the AD system,\nparticularly in out-of-distribution and uncertain data. To this end, this paper\nexplores the integration of Large Language Models (LLMs) into AD systems,\nleveraging their robust common-sense knowledge and reasoning abilities. The\nproposed methodologies employ LLMs as intelligent decision-makers in behavioral\nplanning, augmented with a safety verifier shield for contextual safety\nlearning, for enhancing driving performance and safety. We present two key\nstudies in a simulated environment: an adaptive LLM-conditioned Model\nPredictive Control (MPC) and an LLM-enabled interactive behavior planning\nscheme with a state machine. Demonstrating superior performance and safety\nmetrics compared to state-of-the-art approaches, our approach shows the\npromising potential for using LLMs for autonomous vehicles.","updated":1711128541000,"published":1701141189000,"authors":["Yixuan Wang","Ruochen Jiao","Sinong Simon Zhan","Chengtian Lang","Chao Huang","Zhaoran Wang","Zhuoran Yang","Qi Zhu"],"comments":"Accepted to LLMAgent workshop @ICLR2024","categories":["cs.AI","cs.LG","cs.SY","eess.SY"],"primary_category":"cs.AI","doi":null,"journal_ref":null,"peer_reviewed":true,"reader_id":"rid1","human_jargon_term":"out-of-distribution","definition_text":"Out-of-distribution refers to data that a model encounters which differs significantly from the data it was trained on. This unexpected data can make it difficult for the model to make accurate predictions or decisions because it hasn't learned patterns that account for these new, unfamiliar situations.","model":"gpt4_abstract","Accuracy":"accurate","Ranking":0,"Notes":""},"83":{"arxiv_id":"2312.00812v4","url":"http:\/\/arxiv.org\/abs\/2312.00812v4","title":"Empowering Autonomous Driving with Large Language Models: A Safety\n  Perspective","summary":"Autonomous Driving (AD) encounters significant safety hurdles in long-tail\nunforeseen driving scenarios, largely stemming from the non-interpretability\nand poor generalization of the deep neural networks within the AD system,\nparticularly in out-of-distribution and uncertain data. To this end, this paper\nexplores the integration of Large Language Models (LLMs) into AD systems,\nleveraging their robust common-sense knowledge and reasoning abilities. The\nproposed methodologies employ LLMs as intelligent decision-makers in behavioral\nplanning, augmented with a safety verifier shield for contextual safety\nlearning, for enhancing driving performance and safety. We present two key\nstudies in a simulated environment: an adaptive LLM-conditioned Model\nPredictive Control (MPC) and an LLM-enabled interactive behavior planning\nscheme with a state machine. Demonstrating superior performance and safety\nmetrics compared to state-of-the-art approaches, our approach shows the\npromising potential for using LLMs for autonomous vehicles.","updated":1711128541000,"published":1701141189000,"authors":["Yixuan Wang","Ruochen Jiao","Sinong Simon Zhan","Chengtian Lang","Chao Huang","Zhaoran Wang","Zhuoran Yang","Qi Zhu"],"comments":"Accepted to LLMAgent workshop @ICLR2024","categories":["cs.AI","cs.LG","cs.SY","eess.SY"],"primary_category":"cs.AI","doi":null,"journal_ref":null,"peer_reviewed":true,"reader_id":"rid1","human_jargon_term":"uncertain data","definition_text":"Uncertain data refers to information that may be incomplete, imprecise, or subject to change, which makes it difficult to rely on when making decisions or predictions. This type of data can arise from various sources, such as sensors that do not always provide accurate readings or situations where information is constantly updating.","model":"gpt4_abstract","Accuracy":"accurate","Ranking":1,"Notes":""},"84":{"arxiv_id":"2403.04732v2","url":"http:\/\/arxiv.org\/abs\/2403.04732v2","title":"How Far Are We from Intelligent Visual Deductive Reasoning?","summary":"Vision-Language Models (VLMs) such as GPT-4V have recently demonstrated\nincredible strides on diverse vision language tasks. We dig into vision-based\ndeductive reasoning, a more sophisticated but less explored realm, and find\npreviously unexposed blindspots in the current SOTA VLMs. Specifically, we\nleverage Raven's Progressive Matrices (RPMs), to assess VLMs' abilities to\nperform multi-hop relational and deductive reasoning relying solely on visual\nclues. We perform comprehensive evaluations of several popular VLMs employing\nstandard strategies such as in-context learning, self-consistency, and\nChain-of-thoughts (CoT) on three diverse datasets, including the Mensa IQ test,\nIntelligenceTest, and RAVEN. The results reveal that despite the impressive\ncapabilities of LLMs in text-based reasoning, we are still far from achieving\ncomparable proficiency in visual deductive reasoning. We found that certain\nstandard strategies that are effective when applied to LLMs do not seamlessly\ntranslate to the challenges presented by visual reasoning tasks. Moreover, a\ndetailed analysis reveals that VLMs struggle to solve these tasks mainly\nbecause they are unable to perceive and comprehend multiple, confounding\nabstract patterns in RPM examples.","updated":1709880428000,"published":1709836554000,"authors":["Yizhe Zhang","He Bai","Ruixiang Zhang","Jiatao Gu","Shuangfei Zhai","Josh Susskind","Navdeep Jaitly"],"comments":"ICLR 2024 AGI workshop. https:\/\/github.com\/apple\/ml-rpm-bench","categories":["cs.AI","cs.CL","cs.CV"],"primary_category":"cs.AI","doi":null,"journal_ref":null,"peer_reviewed":true,"reader_id":"rid1","human_jargon_term":"Chain-of-thoughts","definition_text":"Chain-of-thoughts (CoT) is a strategy used in artificial intelligence where the system processes information by detailing its reasoning steps one after another, similar to how a human might explain their thought process step-by-step when solving a problem. This approach helps the system to better handle complex tasks by breaking them down into understandable parts.","model":"gpt4_abstract","Accuracy":"accurate","Ranking":0,"Notes":""},"85":{"arxiv_id":"2403.04732v2","url":"http:\/\/arxiv.org\/abs\/2403.04732v2","title":"How Far Are We from Intelligent Visual Deductive Reasoning?","summary":"Vision-Language Models (VLMs) such as GPT-4V have recently demonstrated\nincredible strides on diverse vision language tasks. We dig into vision-based\ndeductive reasoning, a more sophisticated but less explored realm, and find\npreviously unexposed blindspots in the current SOTA VLMs. Specifically, we\nleverage Raven's Progressive Matrices (RPMs), to assess VLMs' abilities to\nperform multi-hop relational and deductive reasoning relying solely on visual\nclues. We perform comprehensive evaluations of several popular VLMs employing\nstandard strategies such as in-context learning, self-consistency, and\nChain-of-thoughts (CoT) on three diverse datasets, including the Mensa IQ test,\nIntelligenceTest, and RAVEN. The results reveal that despite the impressive\ncapabilities of LLMs in text-based reasoning, we are still far from achieving\ncomparable proficiency in visual deductive reasoning. We found that certain\nstandard strategies that are effective when applied to LLMs do not seamlessly\ntranslate to the challenges presented by visual reasoning tasks. Moreover, a\ndetailed analysis reveals that VLMs struggle to solve these tasks mainly\nbecause they are unable to perceive and comprehend multiple, confounding\nabstract patterns in RPM examples.","updated":1709880428000,"published":1709836554000,"authors":["Yizhe Zhang","He Bai","Ruixiang Zhang","Jiatao Gu","Shuangfei Zhai","Josh Susskind","Navdeep Jaitly"],"comments":"ICLR 2024 AGI workshop. https:\/\/github.com\/apple\/ml-rpm-bench","categories":["cs.AI","cs.CL","cs.CV"],"primary_category":"cs.AI","doi":null,"journal_ref":null,"peer_reviewed":true,"reader_id":"rid1","human_jargon_term":"IntelligenceTest","definition_text":"IntelligenceTest refers to a set of standardized questions and tasks designed to assess a person's intellectual capabilities, such as problem-solving skills, reasoning ability, and understanding of complex concepts. These tests are curated to measure various cognitive functions in a quantifiable way.","model":"gpt4_abstract","Accuracy":"accurate","Ranking":0,"Notes":""},"86":{"arxiv_id":"2403.04732v2","url":"http:\/\/arxiv.org\/abs\/2403.04732v2","title":"How Far Are We from Intelligent Visual Deductive Reasoning?","summary":"Vision-Language Models (VLMs) such as GPT-4V have recently demonstrated\nincredible strides on diverse vision language tasks. We dig into vision-based\ndeductive reasoning, a more sophisticated but less explored realm, and find\npreviously unexposed blindspots in the current SOTA VLMs. Specifically, we\nleverage Raven's Progressive Matrices (RPMs), to assess VLMs' abilities to\nperform multi-hop relational and deductive reasoning relying solely on visual\nclues. We perform comprehensive evaluations of several popular VLMs employing\nstandard strategies such as in-context learning, self-consistency, and\nChain-of-thoughts (CoT) on three diverse datasets, including the Mensa IQ test,\nIntelligenceTest, and RAVEN. The results reveal that despite the impressive\ncapabilities of LLMs in text-based reasoning, we are still far from achieving\ncomparable proficiency in visual deductive reasoning. We found that certain\nstandard strategies that are effective when applied to LLMs do not seamlessly\ntranslate to the challenges presented by visual reasoning tasks. Moreover, a\ndetailed analysis reveals that VLMs struggle to solve these tasks mainly\nbecause they are unable to perceive and comprehend multiple, confounding\nabstract patterns in RPM examples.","updated":1709880428000,"published":1709836554000,"authors":["Yizhe Zhang","He Bai","Ruixiang Zhang","Jiatao Gu","Shuangfei Zhai","Josh Susskind","Navdeep Jaitly"],"comments":"ICLR 2024 AGI workshop. https:\/\/github.com\/apple\/ml-rpm-bench","categories":["cs.AI","cs.CL","cs.CV"],"primary_category":"cs.AI","doi":null,"journal_ref":null,"peer_reviewed":true,"reader_id":"rid1","human_jargon_term":"Mensa IQ test","definition_text":"The Mensa IQ test is a standardized test used to measure intelligence and cognitive abilities, and it is often used by the organization Mensa to determine eligibility for membership, which requires scoring in the top 2% of the population on the test.","model":"gpt4_abstract","Accuracy":"accurate","Ranking":0,"Notes":""},"87":{"arxiv_id":"2403.04732v2","url":"http:\/\/arxiv.org\/abs\/2403.04732v2","title":"How Far Are We from Intelligent Visual Deductive Reasoning?","summary":"Vision-Language Models (VLMs) such as GPT-4V have recently demonstrated\nincredible strides on diverse vision language tasks. We dig into vision-based\ndeductive reasoning, a more sophisticated but less explored realm, and find\npreviously unexposed blindspots in the current SOTA VLMs. Specifically, we\nleverage Raven's Progressive Matrices (RPMs), to assess VLMs' abilities to\nperform multi-hop relational and deductive reasoning relying solely on visual\nclues. We perform comprehensive evaluations of several popular VLMs employing\nstandard strategies such as in-context learning, self-consistency, and\nChain-of-thoughts (CoT) on three diverse datasets, including the Mensa IQ test,\nIntelligenceTest, and RAVEN. The results reveal that despite the impressive\ncapabilities of LLMs in text-based reasoning, we are still far from achieving\ncomparable proficiency in visual deductive reasoning. We found that certain\nstandard strategies that are effective when applied to LLMs do not seamlessly\ntranslate to the challenges presented by visual reasoning tasks. Moreover, a\ndetailed analysis reveals that VLMs struggle to solve these tasks mainly\nbecause they are unable to perceive and comprehend multiple, confounding\nabstract patterns in RPM examples.","updated":1709880428000,"published":1709836554000,"authors":["Yizhe Zhang","He Bai","Ruixiang Zhang","Jiatao Gu","Shuangfei Zhai","Josh Susskind","Navdeep Jaitly"],"comments":"ICLR 2024 AGI workshop. https:\/\/github.com\/apple\/ml-rpm-bench","categories":["cs.AI","cs.CL","cs.CV"],"primary_category":"cs.AI","doi":null,"journal_ref":null,"peer_reviewed":true,"reader_id":"rid1","human_jargon_term":"RAVEN","definition_text":"RAVEN is a dataset used to assess the ability of models to handle complex visual reasoning tasks; it consists of challenges where one must identify the missing piece in a sequence of abstract patterns following certain rules.","model":"gpt4_abstract","Accuracy":"accurate","Ranking":0,"Notes":""},"88":{"arxiv_id":"2403.04732v2","url":"http:\/\/arxiv.org\/abs\/2403.04732v2","title":"How Far Are We from Intelligent Visual Deductive Reasoning?","summary":"Vision-Language Models (VLMs) such as GPT-4V have recently demonstrated\nincredible strides on diverse vision language tasks. We dig into vision-based\ndeductive reasoning, a more sophisticated but less explored realm, and find\npreviously unexposed blindspots in the current SOTA VLMs. Specifically, we\nleverage Raven's Progressive Matrices (RPMs), to assess VLMs' abilities to\nperform multi-hop relational and deductive reasoning relying solely on visual\nclues. We perform comprehensive evaluations of several popular VLMs employing\nstandard strategies such as in-context learning, self-consistency, and\nChain-of-thoughts (CoT) on three diverse datasets, including the Mensa IQ test,\nIntelligenceTest, and RAVEN. The results reveal that despite the impressive\ncapabilities of LLMs in text-based reasoning, we are still far from achieving\ncomparable proficiency in visual deductive reasoning. We found that certain\nstandard strategies that are effective when applied to LLMs do not seamlessly\ntranslate to the challenges presented by visual reasoning tasks. Moreover, a\ndetailed analysis reveals that VLMs struggle to solve these tasks mainly\nbecause they are unable to perceive and comprehend multiple, confounding\nabstract patterns in RPM examples.","updated":1709880428000,"published":1709836554000,"authors":["Yizhe Zhang","He Bai","Ruixiang Zhang","Jiatao Gu","Shuangfei Zhai","Josh Susskind","Navdeep Jaitly"],"comments":"ICLR 2024 AGI workshop. https:\/\/github.com\/apple\/ml-rpm-bench","categories":["cs.AI","cs.CL","cs.CV"],"primary_category":"cs.AI","doi":null,"journal_ref":null,"peer_reviewed":true,"reader_id":"rid1","human_jargon_term":"Raven's Progressive Matrices","definition_text":"Raven's Progressive Matrices (RPMs) are a type of intelligence test that consists of visual puzzles. In these tests, participants are shown a matrix of images with one image missing, and they must select the correct image to complete the pattern from a set of options.","model":"gpt4_abstract","Accuracy":"accurate","Ranking":0,"Notes":""},"89":{"arxiv_id":"2403.04732v2","url":"http:\/\/arxiv.org\/abs\/2403.04732v2","title":"How Far Are We from Intelligent Visual Deductive Reasoning?","summary":"Vision-Language Models (VLMs) such as GPT-4V have recently demonstrated\nincredible strides on diverse vision language tasks. We dig into vision-based\ndeductive reasoning, a more sophisticated but less explored realm, and find\npreviously unexposed blindspots in the current SOTA VLMs. Specifically, we\nleverage Raven's Progressive Matrices (RPMs), to assess VLMs' abilities to\nperform multi-hop relational and deductive reasoning relying solely on visual\nclues. We perform comprehensive evaluations of several popular VLMs employing\nstandard strategies such as in-context learning, self-consistency, and\nChain-of-thoughts (CoT) on three diverse datasets, including the Mensa IQ test,\nIntelligenceTest, and RAVEN. The results reveal that despite the impressive\ncapabilities of LLMs in text-based reasoning, we are still far from achieving\ncomparable proficiency in visual deductive reasoning. We found that certain\nstandard strategies that are effective when applied to LLMs do not seamlessly\ntranslate to the challenges presented by visual reasoning tasks. Moreover, a\ndetailed analysis reveals that VLMs struggle to solve these tasks mainly\nbecause they are unable to perceive and comprehend multiple, confounding\nabstract patterns in RPM examples.","updated":1709880428000,"published":1709836554000,"authors":["Yizhe Zhang","He Bai","Ruixiang Zhang","Jiatao Gu","Shuangfei Zhai","Josh Susskind","Navdeep Jaitly"],"comments":"ICLR 2024 AGI workshop. https:\/\/github.com\/apple\/ml-rpm-bench","categories":["cs.AI","cs.CL","cs.CV"],"primary_category":"cs.AI","doi":null,"journal_ref":null,"peer_reviewed":true,"reader_id":"rid1","human_jargon_term":"SOTA VLM","definition_text":"SOTA VLM refers to the most advanced or cutting-edge Vision-Language Models currently available. These models are designed to understand and process both visual images and language, allowing them to perform tasks that involve interpreting what they see and responding or acting based on that information.","model":"gpt4_abstract","Accuracy":"accurate","Ranking":2,"Notes":""},"90":{"arxiv_id":"2403.04732v2","url":"http:\/\/arxiv.org\/abs\/2403.04732v2","title":"How Far Are We from Intelligent Visual Deductive Reasoning?","summary":"Vision-Language Models (VLMs) such as GPT-4V have recently demonstrated\nincredible strides on diverse vision language tasks. We dig into vision-based\ndeductive reasoning, a more sophisticated but less explored realm, and find\npreviously unexposed blindspots in the current SOTA VLMs. Specifically, we\nleverage Raven's Progressive Matrices (RPMs), to assess VLMs' abilities to\nperform multi-hop relational and deductive reasoning relying solely on visual\nclues. We perform comprehensive evaluations of several popular VLMs employing\nstandard strategies such as in-context learning, self-consistency, and\nChain-of-thoughts (CoT) on three diverse datasets, including the Mensa IQ test,\nIntelligenceTest, and RAVEN. The results reveal that despite the impressive\ncapabilities of LLMs in text-based reasoning, we are still far from achieving\ncomparable proficiency in visual deductive reasoning. We found that certain\nstandard strategies that are effective when applied to LLMs do not seamlessly\ntranslate to the challenges presented by visual reasoning tasks. Moreover, a\ndetailed analysis reveals that VLMs struggle to solve these tasks mainly\nbecause they are unable to perceive and comprehend multiple, confounding\nabstract patterns in RPM examples.","updated":1709880428000,"published":1709836554000,"authors":["Yizhe Zhang","He Bai","Ruixiang Zhang","Jiatao Gu","Shuangfei Zhai","Josh Susskind","Navdeep Jaitly"],"comments":"ICLR 2024 AGI workshop. https:\/\/github.com\/apple\/ml-rpm-bench","categories":["cs.AI","cs.CL","cs.CV"],"primary_category":"cs.AI","doi":null,"journal_ref":null,"peer_reviewed":true,"reader_id":"rid1","human_jargon_term":"Vision-Language Models","definition_text":"Vision-Language Models (VLMs) are advanced computer programs that can understand and interpret both visual data, such as images and videos, and textual data, such as words and sentences. These models are trained to analyze and make sense of combinations of visual and language inputs, enabling them to perform tasks that involve both seeing and reading.","model":"gpt4_abstract","Accuracy":"accurate","Ranking":0,"Notes":""},"91":{"arxiv_id":"2403.04732v2","url":"http:\/\/arxiv.org\/abs\/2403.04732v2","title":"How Far Are We from Intelligent Visual Deductive Reasoning?","summary":"Vision-Language Models (VLMs) such as GPT-4V have recently demonstrated\nincredible strides on diverse vision language tasks. We dig into vision-based\ndeductive reasoning, a more sophisticated but less explored realm, and find\npreviously unexposed blindspots in the current SOTA VLMs. Specifically, we\nleverage Raven's Progressive Matrices (RPMs), to assess VLMs' abilities to\nperform multi-hop relational and deductive reasoning relying solely on visual\nclues. We perform comprehensive evaluations of several popular VLMs employing\nstandard strategies such as in-context learning, self-consistency, and\nChain-of-thoughts (CoT) on three diverse datasets, including the Mensa IQ test,\nIntelligenceTest, and RAVEN. The results reveal that despite the impressive\ncapabilities of LLMs in text-based reasoning, we are still far from achieving\ncomparable proficiency in visual deductive reasoning. We found that certain\nstandard strategies that are effective when applied to LLMs do not seamlessly\ntranslate to the challenges presented by visual reasoning tasks. Moreover, a\ndetailed analysis reveals that VLMs struggle to solve these tasks mainly\nbecause they are unable to perceive and comprehend multiple, confounding\nabstract patterns in RPM examples.","updated":1709880428000,"published":1709836554000,"authors":["Yizhe Zhang","He Bai","Ruixiang Zhang","Jiatao Gu","Shuangfei Zhai","Josh Susskind","Navdeep Jaitly"],"comments":"ICLR 2024 AGI workshop. https:\/\/github.com\/apple\/ml-rpm-bench","categories":["cs.AI","cs.CL","cs.CV"],"primary_category":"cs.AI","doi":null,"journal_ref":null,"peer_reviewed":true,"reader_id":"rid1","human_jargon_term":"multi-hop","definition_text":"Multi-hop reasoning involves making several intermediate logical steps or connections to arrive at a final conclusion or answer. This process requires piecing together information gathered from different sources or aspects to solve complex problems.","model":"gpt4_abstract","Accuracy":"accurate","Ranking":1,"Notes":""},"92":{"arxiv_id":"2403.04732v2","url":"http:\/\/arxiv.org\/abs\/2403.04732v2","title":"How Far Are We from Intelligent Visual Deductive Reasoning?","summary":"Vision-Language Models (VLMs) such as GPT-4V have recently demonstrated\nincredible strides on diverse vision language tasks. We dig into vision-based\ndeductive reasoning, a more sophisticated but less explored realm, and find\npreviously unexposed blindspots in the current SOTA VLMs. Specifically, we\nleverage Raven's Progressive Matrices (RPMs), to assess VLMs' abilities to\nperform multi-hop relational and deductive reasoning relying solely on visual\nclues. We perform comprehensive evaluations of several popular VLMs employing\nstandard strategies such as in-context learning, self-consistency, and\nChain-of-thoughts (CoT) on three diverse datasets, including the Mensa IQ test,\nIntelligenceTest, and RAVEN. The results reveal that despite the impressive\ncapabilities of LLMs in text-based reasoning, we are still far from achieving\ncomparable proficiency in visual deductive reasoning. We found that certain\nstandard strategies that are effective when applied to LLMs do not seamlessly\ntranslate to the challenges presented by visual reasoning tasks. Moreover, a\ndetailed analysis reveals that VLMs struggle to solve these tasks mainly\nbecause they are unable to perceive and comprehend multiple, confounding\nabstract patterns in RPM examples.","updated":1709880428000,"published":1709836554000,"authors":["Yizhe Zhang","He Bai","Ruixiang Zhang","Jiatao Gu","Shuangfei Zhai","Josh Susskind","Navdeep Jaitly"],"comments":"ICLR 2024 AGI workshop. https:\/\/github.com\/apple\/ml-rpm-bench","categories":["cs.AI","cs.CL","cs.CV"],"primary_category":"cs.AI","doi":null,"journal_ref":null,"peer_reviewed":true,"reader_id":"rid1","human_jargon_term":"vision language","definition_text":"Vision language refers to the field of technology focused on developing systems capable of understanding and processing both visual data (like images or videos) and textual or spoken language simultaneously. This enables computers to interact with, interpret, and respond to visual and textual content in ways similar to human perception and communication.","model":"gpt4_abstract","Accuracy":"accurate","Ranking":1,"Notes":""},"93":{"arxiv_id":"2307.03067v2","url":"http:\/\/arxiv.org\/abs\/2307.03067v2","title":"DeepOnto: A Python Package for Ontology Engineering with Deep Learning","summary":"Integrating deep learning techniques, particularly language models (LMs),\nwith knowledge representation techniques like ontologies has raised widespread\nattention, urging the need of a platform that supports both paradigms. Although\npackages such as OWL API and Jena offer robust support for basic ontology\nprocessing features, they lack the capability to transform various types of\ninformation within ontologies into formats suitable for downstream deep\nlearning-based applications. Moreover, widely-used ontology APIs are primarily\nJava-based while deep learning frameworks like PyTorch and Tensorflow are\nmainly for Python programming. To address the needs, we present DeepOnto, a\nPython package designed for ontology engineering with deep learning. The\npackage encompasses a core ontology processing module founded on the\nwidely-recognised and reliable OWL API, encapsulating its fundamental features\nin a more \"Pythonic\" manner and extending its capabilities to incorporate other\nessential components including reasoning, verbalisation, normalisation,\ntaxonomy, projection, and more. Building on this module, DeepOnto offers a\nsuite of tools, resources, and algorithms that support various ontology\nengineering tasks, such as ontology alignment and completion, by harnessing\ndeep learning methods, primarily pre-trained LMs. In this paper, we also\ndemonstrate the practical utility of DeepOnto through two use-cases: the\nDigital Health Coaching in Samsung Research UK and the Bio-ML track of the\nOntology Alignment Evaluation Initiative (OAEI).","updated":1709950662000,"published":1688657702000,"authors":["Yuan He","Jiaoyan Chen","Hang Dong","Ian Horrocks","Carlo Allocca","Taehun Kim","Brahmananda Sapkota"],"comments":"Accepted by the Semantic Web Journal","categories":["cs.AI","cs.CL","cs.LG","cs.LO"],"primary_category":"cs.AI","doi":null,"journal_ref":null,"peer_reviewed":true,"reader_id":"rid1","human_jargon_term":"DeepOnto","definition_text":"DeepOnto is a software tool designed to help merge the capabilities of ontology engineering (the way information is categorized and related in a field like biology or computer science) with advanced AI methods, such as deep learning, to enhance how data is processed and utilized in these systems. It translates complex structural data into a format usable by AI, facilitating tasks like aligning and completing knowledge databases.","model":"gpt4_abstract","Accuracy":"accurate","Ranking":0,"Notes":""},"94":{"arxiv_id":"2307.03067v2","url":"http:\/\/arxiv.org\/abs\/2307.03067v2","title":"DeepOnto: A Python Package for Ontology Engineering with Deep Learning","summary":"Integrating deep learning techniques, particularly language models (LMs),\nwith knowledge representation techniques like ontologies has raised widespread\nattention, urging the need of a platform that supports both paradigms. Although\npackages such as OWL API and Jena offer robust support for basic ontology\nprocessing features, they lack the capability to transform various types of\ninformation within ontologies into formats suitable for downstream deep\nlearning-based applications. Moreover, widely-used ontology APIs are primarily\nJava-based while deep learning frameworks like PyTorch and Tensorflow are\nmainly for Python programming. To address the needs, we present DeepOnto, a\nPython package designed for ontology engineering with deep learning. The\npackage encompasses a core ontology processing module founded on the\nwidely-recognised and reliable OWL API, encapsulating its fundamental features\nin a more \"Pythonic\" manner and extending its capabilities to incorporate other\nessential components including reasoning, verbalisation, normalisation,\ntaxonomy, projection, and more. Building on this module, DeepOnto offers a\nsuite of tools, resources, and algorithms that support various ontology\nengineering tasks, such as ontology alignment and completion, by harnessing\ndeep learning methods, primarily pre-trained LMs. In this paper, we also\ndemonstrate the practical utility of DeepOnto through two use-cases: the\nDigital Health Coaching in Samsung Research UK and the Bio-ML track of the\nOntology Alignment Evaluation Initiative (OAEI).","updated":1709950662000,"published":1688657702000,"authors":["Yuan He","Jiaoyan Chen","Hang Dong","Ian Horrocks","Carlo Allocca","Taehun Kim","Brahmananda Sapkota"],"comments":"Accepted by the Semantic Web Journal","categories":["cs.AI","cs.CL","cs.LG","cs.LO"],"primary_category":"cs.AI","doi":null,"journal_ref":null,"peer_reviewed":true,"reader_id":"rid1","human_jargon_term":"Jena","definition_text":"Jena is a software package that helps users manage and process ontologies, which are structured frameworks for organizing information. It provides tools to develop applications that handle structured data in a way that makes it understandable and usable by computers.","model":"gpt4_abstract","Accuracy":"accurate","Ranking":0,"Notes":""},"95":{"arxiv_id":"2307.03067v2","url":"http:\/\/arxiv.org\/abs\/2307.03067v2","title":"DeepOnto: A Python Package for Ontology Engineering with Deep Learning","summary":"Integrating deep learning techniques, particularly language models (LMs),\nwith knowledge representation techniques like ontologies has raised widespread\nattention, urging the need of a platform that supports both paradigms. Although\npackages such as OWL API and Jena offer robust support for basic ontology\nprocessing features, they lack the capability to transform various types of\ninformation within ontologies into formats suitable for downstream deep\nlearning-based applications. Moreover, widely-used ontology APIs are primarily\nJava-based while deep learning frameworks like PyTorch and Tensorflow are\nmainly for Python programming. To address the needs, we present DeepOnto, a\nPython package designed for ontology engineering with deep learning. The\npackage encompasses a core ontology processing module founded on the\nwidely-recognised and reliable OWL API, encapsulating its fundamental features\nin a more \"Pythonic\" manner and extending its capabilities to incorporate other\nessential components including reasoning, verbalisation, normalisation,\ntaxonomy, projection, and more. Building on this module, DeepOnto offers a\nsuite of tools, resources, and algorithms that support various ontology\nengineering tasks, such as ontology alignment and completion, by harnessing\ndeep learning methods, primarily pre-trained LMs. In this paper, we also\ndemonstrate the practical utility of DeepOnto through two use-cases: the\nDigital Health Coaching in Samsung Research UK and the Bio-ML track of the\nOntology Alignment Evaluation Initiative (OAEI).","updated":1709950662000,"published":1688657702000,"authors":["Yuan He","Jiaoyan Chen","Hang Dong","Ian Horrocks","Carlo Allocca","Taehun Kim","Brahmananda Sapkota"],"comments":"Accepted by the Semantic Web Journal","categories":["cs.AI","cs.CL","cs.LG","cs.LO"],"primary_category":"cs.AI","doi":null,"journal_ref":null,"peer_reviewed":true,"reader_id":"rid1","human_jargon_term":"OWL API","definition_text":"The OWL API is a software interface designed to help programmers create, manipulate, and manage ontologies (structured frameworks of knowledge) coded in the OWL language, which is a format used for organizing complex information so that computers can process it. Essentially, it provides a set of tools that make it easier to interact with and utilize this type of data in software applications.","model":"gpt4_abstract","Accuracy":"accurate","Ranking":0,"Notes":""},"96":{"arxiv_id":"2307.03067v2","url":"http:\/\/arxiv.org\/abs\/2307.03067v2","title":"DeepOnto: A Python Package for Ontology Engineering with Deep Learning","summary":"Integrating deep learning techniques, particularly language models (LMs),\nwith knowledge representation techniques like ontologies has raised widespread\nattention, urging the need of a platform that supports both paradigms. Although\npackages such as OWL API and Jena offer robust support for basic ontology\nprocessing features, they lack the capability to transform various types of\ninformation within ontologies into formats suitable for downstream deep\nlearning-based applications. Moreover, widely-used ontology APIs are primarily\nJava-based while deep learning frameworks like PyTorch and Tensorflow are\nmainly for Python programming. To address the needs, we present DeepOnto, a\nPython package designed for ontology engineering with deep learning. The\npackage encompasses a core ontology processing module founded on the\nwidely-recognised and reliable OWL API, encapsulating its fundamental features\nin a more \"Pythonic\" manner and extending its capabilities to incorporate other\nessential components including reasoning, verbalisation, normalisation,\ntaxonomy, projection, and more. Building on this module, DeepOnto offers a\nsuite of tools, resources, and algorithms that support various ontology\nengineering tasks, such as ontology alignment and completion, by harnessing\ndeep learning methods, primarily pre-trained LMs. In this paper, we also\ndemonstrate the practical utility of DeepOnto through two use-cases: the\nDigital Health Coaching in Samsung Research UK and the Bio-ML track of the\nOntology Alignment Evaluation Initiative (OAEI).","updated":1709950662000,"published":1688657702000,"authors":["Yuan He","Jiaoyan Chen","Hang Dong","Ian Horrocks","Carlo Allocca","Taehun Kim","Brahmananda Sapkota"],"comments":"Accepted by the Semantic Web Journal","categories":["cs.AI","cs.CL","cs.LG","cs.LO"],"primary_category":"cs.AI","doi":null,"journal_ref":null,"peer_reviewed":true,"reader_id":"rid1","human_jargon_term":"PyTorch","definition_text":"PyTorch is a programming tool used primarily for artificial intelligence projects, particularly in developing and training deep learning models, which are systems designed to mimic human learning and thought processes. It is favored for its flexibility and ease of use, particularly in research and development environments.","model":"gpt4_abstract","Accuracy":"accurate","Ranking":1,"Notes":""},"97":{"arxiv_id":"2307.03067v2","url":"http:\/\/arxiv.org\/abs\/2307.03067v2","title":"DeepOnto: A Python Package for Ontology Engineering with Deep Learning","summary":"Integrating deep learning techniques, particularly language models (LMs),\nwith knowledge representation techniques like ontologies has raised widespread\nattention, urging the need of a platform that supports both paradigms. Although\npackages such as OWL API and Jena offer robust support for basic ontology\nprocessing features, they lack the capability to transform various types of\ninformation within ontologies into formats suitable for downstream deep\nlearning-based applications. Moreover, widely-used ontology APIs are primarily\nJava-based while deep learning frameworks like PyTorch and Tensorflow are\nmainly for Python programming. To address the needs, we present DeepOnto, a\nPython package designed for ontology engineering with deep learning. The\npackage encompasses a core ontology processing module founded on the\nwidely-recognised and reliable OWL API, encapsulating its fundamental features\nin a more \"Pythonic\" manner and extending its capabilities to incorporate other\nessential components including reasoning, verbalisation, normalisation,\ntaxonomy, projection, and more. Building on this module, DeepOnto offers a\nsuite of tools, resources, and algorithms that support various ontology\nengineering tasks, such as ontology alignment and completion, by harnessing\ndeep learning methods, primarily pre-trained LMs. In this paper, we also\ndemonstrate the practical utility of DeepOnto through two use-cases: the\nDigital Health Coaching in Samsung Research UK and the Bio-ML track of the\nOntology Alignment Evaluation Initiative (OAEI).","updated":1709950662000,"published":1688657702000,"authors":["Yuan He","Jiaoyan Chen","Hang Dong","Ian Horrocks","Carlo Allocca","Taehun Kim","Brahmananda Sapkota"],"comments":"Accepted by the Semantic Web Journal","categories":["cs.AI","cs.CL","cs.LG","cs.LO"],"primary_category":"cs.AI","doi":null,"journal_ref":null,"peer_reviewed":true,"reader_id":"rid1","human_jargon_term":"Tensorflow","definition_text":"Tensorflow is a software tool commonly used in artificial intelligence for creating models that can process and understand data in ways similar to human learning and reasoning. It is particularly popular for tasks that involve recognizing patterns or making decisions based on large amounts of data.","model":"gpt4_abstract","Accuracy":"accurate","Ranking":1,"Notes":""},"98":{"arxiv_id":"2307.03067v2","url":"http:\/\/arxiv.org\/abs\/2307.03067v2","title":"DeepOnto: A Python Package for Ontology Engineering with Deep Learning","summary":"Integrating deep learning techniques, particularly language models (LMs),\nwith knowledge representation techniques like ontologies has raised widespread\nattention, urging the need of a platform that supports both paradigms. Although\npackages such as OWL API and Jena offer robust support for basic ontology\nprocessing features, they lack the capability to transform various types of\ninformation within ontologies into formats suitable for downstream deep\nlearning-based applications. Moreover, widely-used ontology APIs are primarily\nJava-based while deep learning frameworks like PyTorch and Tensorflow are\nmainly for Python programming. To address the needs, we present DeepOnto, a\nPython package designed for ontology engineering with deep learning. The\npackage encompasses a core ontology processing module founded on the\nwidely-recognised and reliable OWL API, encapsulating its fundamental features\nin a more \"Pythonic\" manner and extending its capabilities to incorporate other\nessential components including reasoning, verbalisation, normalisation,\ntaxonomy, projection, and more. Building on this module, DeepOnto offers a\nsuite of tools, resources, and algorithms that support various ontology\nengineering tasks, such as ontology alignment and completion, by harnessing\ndeep learning methods, primarily pre-trained LMs. In this paper, we also\ndemonstrate the practical utility of DeepOnto through two use-cases: the\nDigital Health Coaching in Samsung Research UK and the Bio-ML track of the\nOntology Alignment Evaluation Initiative (OAEI).","updated":1709950662000,"published":1688657702000,"authors":["Yuan He","Jiaoyan Chen","Hang Dong","Ian Horrocks","Carlo Allocca","Taehun Kim","Brahmananda Sapkota"],"comments":"Accepted by the Semantic Web Journal","categories":["cs.AI","cs.CL","cs.LG","cs.LO"],"primary_category":"cs.AI","doi":null,"journal_ref":null,"peer_reviewed":true,"reader_id":"rid1","human_jargon_term":"downstream deep\nlearning-based applications","definition_text":"Downstream deep learning-based applications refer to processes or systems that utilize the output from deep learning models to perform specific tasks, such as making predictions or analyzing data, after the initial learning phase has been completed. Essentially, these are practical uses of the trained models to achieve or automate various functions and tasks in real-world scenarios.","model":"gpt4_abstract","Accuracy":"accurate","Ranking":0,"Notes":""},"99":{"arxiv_id":"2307.03067v2","url":"http:\/\/arxiv.org\/abs\/2307.03067v2","title":"DeepOnto: A Python Package for Ontology Engineering with Deep Learning","summary":"Integrating deep learning techniques, particularly language models (LMs),\nwith knowledge representation techniques like ontologies has raised widespread\nattention, urging the need of a platform that supports both paradigms. Although\npackages such as OWL API and Jena offer robust support for basic ontology\nprocessing features, they lack the capability to transform various types of\ninformation within ontologies into formats suitable for downstream deep\nlearning-based applications. Moreover, widely-used ontology APIs are primarily\nJava-based while deep learning frameworks like PyTorch and Tensorflow are\nmainly for Python programming. To address the needs, we present DeepOnto, a\nPython package designed for ontology engineering with deep learning. The\npackage encompasses a core ontology processing module founded on the\nwidely-recognised and reliable OWL API, encapsulating its fundamental features\nin a more \"Pythonic\" manner and extending its capabilities to incorporate other\nessential components including reasoning, verbalisation, normalisation,\ntaxonomy, projection, and more. Building on this module, DeepOnto offers a\nsuite of tools, resources, and algorithms that support various ontology\nengineering tasks, such as ontology alignment and completion, by harnessing\ndeep learning methods, primarily pre-trained LMs. In this paper, we also\ndemonstrate the practical utility of DeepOnto through two use-cases: the\nDigital Health Coaching in Samsung Research UK and the Bio-ML track of the\nOntology Alignment Evaluation Initiative (OAEI).","updated":1709950662000,"published":1688657702000,"authors":["Yuan He","Jiaoyan Chen","Hang Dong","Ian Horrocks","Carlo Allocca","Taehun Kim","Brahmananda Sapkota"],"comments":"Accepted by the Semantic Web Journal","categories":["cs.AI","cs.CL","cs.LG","cs.LO"],"primary_category":"cs.AI","doi":null,"journal_ref":null,"peer_reviewed":true,"reader_id":"rid1","human_jargon_term":"normalisation","definition_text":"Normalisation, in the context of ontology engineering, refers to the process of standardizing and organizing data within an ontology so that it follows a consistent format and structure. This makes the data easier to use and integrate with other systems, particularly for tasks involving deep learning applications.","model":"gpt4_abstract","Accuracy":"accurate","Ranking":1,"Notes":""},"100":{"arxiv_id":"2307.03067v2","url":"http:\/\/arxiv.org\/abs\/2307.03067v2","title":"DeepOnto: A Python Package for Ontology Engineering with Deep Learning","summary":"Integrating deep learning techniques, particularly language models (LMs),\nwith knowledge representation techniques like ontologies has raised widespread\nattention, urging the need of a platform that supports both paradigms. Although\npackages such as OWL API and Jena offer robust support for basic ontology\nprocessing features, they lack the capability to transform various types of\ninformation within ontologies into formats suitable for downstream deep\nlearning-based applications. Moreover, widely-used ontology APIs are primarily\nJava-based while deep learning frameworks like PyTorch and Tensorflow are\nmainly for Python programming. To address the needs, we present DeepOnto, a\nPython package designed for ontology engineering with deep learning. The\npackage encompasses a core ontology processing module founded on the\nwidely-recognised and reliable OWL API, encapsulating its fundamental features\nin a more \"Pythonic\" manner and extending its capabilities to incorporate other\nessential components including reasoning, verbalisation, normalisation,\ntaxonomy, projection, and more. Building on this module, DeepOnto offers a\nsuite of tools, resources, and algorithms that support various ontology\nengineering tasks, such as ontology alignment and completion, by harnessing\ndeep learning methods, primarily pre-trained LMs. In this paper, we also\ndemonstrate the practical utility of DeepOnto through two use-cases: the\nDigital Health Coaching in Samsung Research UK and the Bio-ML track of the\nOntology Alignment Evaluation Initiative (OAEI).","updated":1709950662000,"published":1688657702000,"authors":["Yuan He","Jiaoyan Chen","Hang Dong","Ian Horrocks","Carlo Allocca","Taehun Kim","Brahmananda Sapkota"],"comments":"Accepted by the Semantic Web Journal","categories":["cs.AI","cs.CL","cs.LG","cs.LO"],"primary_category":"cs.AI","doi":null,"journal_ref":null,"peer_reviewed":true,"reader_id":"rid1","human_jargon_term":"ontologies","definition_text":"Ontologies in this context are structured frameworks for organizing information, which define categories and the relationships between them, helping to make data more understandable and usable by humans and computer programs. They are used to categorize and integrate various types of knowledge systematically.","model":"gpt4_abstract","Accuracy":"accurate","Ranking":1,"Notes":""},"101":{"arxiv_id":"2307.03067v2","url":"http:\/\/arxiv.org\/abs\/2307.03067v2","title":"DeepOnto: A Python Package for Ontology Engineering with Deep Learning","summary":"Integrating deep learning techniques, particularly language models (LMs),\nwith knowledge representation techniques like ontologies has raised widespread\nattention, urging the need of a platform that supports both paradigms. Although\npackages such as OWL API and Jena offer robust support for basic ontology\nprocessing features, they lack the capability to transform various types of\ninformation within ontologies into formats suitable for downstream deep\nlearning-based applications. Moreover, widely-used ontology APIs are primarily\nJava-based while deep learning frameworks like PyTorch and Tensorflow are\nmainly for Python programming. To address the needs, we present DeepOnto, a\nPython package designed for ontology engineering with deep learning. The\npackage encompasses a core ontology processing module founded on the\nwidely-recognised and reliable OWL API, encapsulating its fundamental features\nin a more \"Pythonic\" manner and extending its capabilities to incorporate other\nessential components including reasoning, verbalisation, normalisation,\ntaxonomy, projection, and more. Building on this module, DeepOnto offers a\nsuite of tools, resources, and algorithms that support various ontology\nengineering tasks, such as ontology alignment and completion, by harnessing\ndeep learning methods, primarily pre-trained LMs. In this paper, we also\ndemonstrate the practical utility of DeepOnto through two use-cases: the\nDigital Health Coaching in Samsung Research UK and the Bio-ML track of the\nOntology Alignment Evaluation Initiative (OAEI).","updated":1709950662000,"published":1688657702000,"authors":["Yuan He","Jiaoyan Chen","Hang Dong","Ian Horrocks","Carlo Allocca","Taehun Kim","Brahmananda Sapkota"],"comments":"Accepted by the Semantic Web Journal","categories":["cs.AI","cs.CL","cs.LG","cs.LO"],"primary_category":"cs.AI","doi":null,"journal_ref":null,"peer_reviewed":true,"reader_id":"rid1","human_jargon_term":"ontology\nprocessing features","definition_text":"Ontology processing features refer to the tools and methods used in handling and manipulating ontologies, which are structured frameworks for organizing information. These features allow for activities like adding, removing, or altering the information within an ontology to ensure it accurately represents the knowledge in a specific domain.","model":"gpt4_abstract","Accuracy":"accurate","Ranking":1,"Notes":""},"102":{"arxiv_id":"2307.03067v2","url":"http:\/\/arxiv.org\/abs\/2307.03067v2","title":"DeepOnto: A Python Package for Ontology Engineering with Deep Learning","summary":"Integrating deep learning techniques, particularly language models (LMs),\nwith knowledge representation techniques like ontologies has raised widespread\nattention, urging the need of a platform that supports both paradigms. Although\npackages such as OWL API and Jena offer robust support for basic ontology\nprocessing features, they lack the capability to transform various types of\ninformation within ontologies into formats suitable for downstream deep\nlearning-based applications. Moreover, widely-used ontology APIs are primarily\nJava-based while deep learning frameworks like PyTorch and Tensorflow are\nmainly for Python programming. To address the needs, we present DeepOnto, a\nPython package designed for ontology engineering with deep learning. The\npackage encompasses a core ontology processing module founded on the\nwidely-recognised and reliable OWL API, encapsulating its fundamental features\nin a more \"Pythonic\" manner and extending its capabilities to incorporate other\nessential components including reasoning, verbalisation, normalisation,\ntaxonomy, projection, and more. Building on this module, DeepOnto offers a\nsuite of tools, resources, and algorithms that support various ontology\nengineering tasks, such as ontology alignment and completion, by harnessing\ndeep learning methods, primarily pre-trained LMs. In this paper, we also\ndemonstrate the practical utility of DeepOnto through two use-cases: the\nDigital Health Coaching in Samsung Research UK and the Bio-ML track of the\nOntology Alignment Evaluation Initiative (OAEI).","updated":1709950662000,"published":1688657702000,"authors":["Yuan He","Jiaoyan Chen","Hang Dong","Ian Horrocks","Carlo Allocca","Taehun Kim","Brahmananda Sapkota"],"comments":"Accepted by the Semantic Web Journal","categories":["cs.AI","cs.CL","cs.LG","cs.LO"],"primary_category":"cs.AI","doi":null,"journal_ref":null,"peer_reviewed":true,"reader_id":"rid1","human_jargon_term":"ontology API","definition_text":"An ontology API is a tool that allows software developers to interact with and manipulate sets of knowledge, which are organized in a structured way, resembling a digital library of concepts and their relationships. This makes it easier to work with complex information systems and to integrate various data sources cohesively.","model":"gpt4_abstract","Accuracy":"accurate","Ranking":1,"Notes":""},"103":{"arxiv_id":"2307.03067v2","url":"http:\/\/arxiv.org\/abs\/2307.03067v2","title":"DeepOnto: A Python Package for Ontology Engineering with Deep Learning","summary":"Integrating deep learning techniques, particularly language models (LMs),\nwith knowledge representation techniques like ontologies has raised widespread\nattention, urging the need of a platform that supports both paradigms. Although\npackages such as OWL API and Jena offer robust support for basic ontology\nprocessing features, they lack the capability to transform various types of\ninformation within ontologies into formats suitable for downstream deep\nlearning-based applications. Moreover, widely-used ontology APIs are primarily\nJava-based while deep learning frameworks like PyTorch and Tensorflow are\nmainly for Python programming. To address the needs, we present DeepOnto, a\nPython package designed for ontology engineering with deep learning. The\npackage encompasses a core ontology processing module founded on the\nwidely-recognised and reliable OWL API, encapsulating its fundamental features\nin a more \"Pythonic\" manner and extending its capabilities to incorporate other\nessential components including reasoning, verbalisation, normalisation,\ntaxonomy, projection, and more. Building on this module, DeepOnto offers a\nsuite of tools, resources, and algorithms that support various ontology\nengineering tasks, such as ontology alignment and completion, by harnessing\ndeep learning methods, primarily pre-trained LMs. In this paper, we also\ndemonstrate the practical utility of DeepOnto through two use-cases: the\nDigital Health Coaching in Samsung Research UK and the Bio-ML track of the\nOntology Alignment Evaluation Initiative (OAEI).","updated":1709950662000,"published":1688657702000,"authors":["Yuan He","Jiaoyan Chen","Hang Dong","Ian Horrocks","Carlo Allocca","Taehun Kim","Brahmananda Sapkota"],"comments":"Accepted by the Semantic Web Journal","categories":["cs.AI","cs.CL","cs.LG","cs.LO"],"primary_category":"cs.AI","doi":null,"journal_ref":null,"peer_reviewed":true,"reader_id":"rid1","human_jargon_term":"projection","definition_text":"In the context described, \"projection\" in terms of ontology engineering likely refers to the process of transforming or mapping specific parts or aspects of an ontology (a structured set of terms and concepts representing a domain of knowledge) into a different format or structure that is more suitable for specific tasks or analyses, especially for use in deep learning applications.","model":"gpt4_abstract","Accuracy":"accurate","Ranking":1,"Notes":""},"104":{"arxiv_id":"2307.03067v2","url":"http:\/\/arxiv.org\/abs\/2307.03067v2","title":"DeepOnto: A Python Package for Ontology Engineering with Deep Learning","summary":"Integrating deep learning techniques, particularly language models (LMs),\nwith knowledge representation techniques like ontologies has raised widespread\nattention, urging the need of a platform that supports both paradigms. Although\npackages such as OWL API and Jena offer robust support for basic ontology\nprocessing features, they lack the capability to transform various types of\ninformation within ontologies into formats suitable for downstream deep\nlearning-based applications. Moreover, widely-used ontology APIs are primarily\nJava-based while deep learning frameworks like PyTorch and Tensorflow are\nmainly for Python programming. To address the needs, we present DeepOnto, a\nPython package designed for ontology engineering with deep learning. The\npackage encompasses a core ontology processing module founded on the\nwidely-recognised and reliable OWL API, encapsulating its fundamental features\nin a more \"Pythonic\" manner and extending its capabilities to incorporate other\nessential components including reasoning, verbalisation, normalisation,\ntaxonomy, projection, and more. Building on this module, DeepOnto offers a\nsuite of tools, resources, and algorithms that support various ontology\nengineering tasks, such as ontology alignment and completion, by harnessing\ndeep learning methods, primarily pre-trained LMs. In this paper, we also\ndemonstrate the practical utility of DeepOnto through two use-cases: the\nDigital Health Coaching in Samsung Research UK and the Bio-ML track of the\nOntology Alignment Evaluation Initiative (OAEI).","updated":1709950662000,"published":1688657702000,"authors":["Yuan He","Jiaoyan Chen","Hang Dong","Ian Horrocks","Carlo Allocca","Taehun Kim","Brahmananda Sapkota"],"comments":"Accepted by the Semantic Web Journal","categories":["cs.AI","cs.CL","cs.LG","cs.LO"],"primary_category":"cs.AI","doi":null,"journal_ref":null,"peer_reviewed":true,"reader_id":"rid1","human_jargon_term":"taxonomy","definition_text":"Taxonomy in this context refers to the method of organizing and categorizing information or data into a structured format, such as classifying different elements based on their characteristics and relationships within a hierarchical system. This helps in understanding and managing large sets of data more effectively.","model":"gpt4_abstract","Accuracy":"accurate","Ranking":1,"Notes":""},"105":{"arxiv_id":"2307.03067v2","url":"http:\/\/arxiv.org\/abs\/2307.03067v2","title":"DeepOnto: A Python Package for Ontology Engineering with Deep Learning","summary":"Integrating deep learning techniques, particularly language models (LMs),\nwith knowledge representation techniques like ontologies has raised widespread\nattention, urging the need of a platform that supports both paradigms. Although\npackages such as OWL API and Jena offer robust support for basic ontology\nprocessing features, they lack the capability to transform various types of\ninformation within ontologies into formats suitable for downstream deep\nlearning-based applications. Moreover, widely-used ontology APIs are primarily\nJava-based while deep learning frameworks like PyTorch and Tensorflow are\nmainly for Python programming. To address the needs, we present DeepOnto, a\nPython package designed for ontology engineering with deep learning. The\npackage encompasses a core ontology processing module founded on the\nwidely-recognised and reliable OWL API, encapsulating its fundamental features\nin a more \"Pythonic\" manner and extending its capabilities to incorporate other\nessential components including reasoning, verbalisation, normalisation,\ntaxonomy, projection, and more. Building on this module, DeepOnto offers a\nsuite of tools, resources, and algorithms that support various ontology\nengineering tasks, such as ontology alignment and completion, by harnessing\ndeep learning methods, primarily pre-trained LMs. In this paper, we also\ndemonstrate the practical utility of DeepOnto through two use-cases: the\nDigital Health Coaching in Samsung Research UK and the Bio-ML track of the\nOntology Alignment Evaluation Initiative (OAEI).","updated":1709950662000,"published":1688657702000,"authors":["Yuan He","Jiaoyan Chen","Hang Dong","Ian Horrocks","Carlo Allocca","Taehun Kim","Brahmananda Sapkota"],"comments":"Accepted by the Semantic Web Journal","categories":["cs.AI","cs.CL","cs.LG","cs.LO"],"primary_category":"cs.AI","doi":null,"journal_ref":null,"peer_reviewed":true,"reader_id":"rid1","human_jargon_term":"verbalisation","definition_text":"Verbalisation in the context of ontology engineering refers to the process of converting the structured content of an ontology\u2014such as its classes, relationships, and properties\u2014into human-readable text. This makes it easier for people to understand the complex data and relationships represented in the ontology.","model":"gpt4_abstract","Accuracy":"accurate","Ranking":2,"Notes":""},"106":{"arxiv_id":"2403.17873v1","url":"http:\/\/arxiv.org\/abs\/2403.17873v1","title":"Addressing Social Misattributions of Large Language Models: An\n  HCXAI-based Approach","summary":"Human-centered explainable AI (HCXAI) advocates for the integration of social\naspects into AI explanations. Central to the HCXAI discourse is the Social\nTransparency (ST) framework, which aims to make the socio-organizational\ncontext of AI systems accessible to their users. In this work, we suggest\nextending the ST framework to address the risks of social misattributions in\nLarge Language Models (LLMs), particularly in sensitive areas like mental\nhealth. In fact LLMs, which are remarkably capable of simulating roles and\npersonas, may lead to mismatches between designers' intentions and users'\nperceptions of social attributes, risking to promote emotional manipulation and\ndangerous behaviors, cases of epistemic injustice, and unwarranted trust. To\naddress these issues, we propose enhancing the ST framework with a fifth\n'W-question' to clarify the specific social attributions assigned to LLMs by\nits designers and users. This addition aims to bridge the gap between LLM\ncapabilities and user perceptions, promoting the ethically responsible\ndevelopment and use of LLM-based technology.","updated":1711472562000,"published":1711472562000,"authors":["Andrea Ferrario","Alberto Termine","Alessandro Facchini"],"comments":"Extended version of the manuscript accepted for the ACM CHI Workshop\n  on Human-Centered Explainable AI 2024 (HCXAI24)","categories":["cs.AI"],"primary_category":"cs.AI","doi":null,"journal_ref":null,"peer_reviewed":true,"reader_id":"rid1","human_jargon_term":"Human-centered explainable AI","definition_text":"Human-centered explainable AI (HCXAI) is a type of artificial intelligence that focuses on being understandable to humans, incorporating human perspectives and needs into its design to ensure that the AI's decisions and processes can be easily explained and understood by its users.","model":"gpt4_abstract","Accuracy":"accurate","Ranking":1,"Notes":""},"107":{"arxiv_id":"2403.17873v1","url":"http:\/\/arxiv.org\/abs\/2403.17873v1","title":"Addressing Social Misattributions of Large Language Models: An\n  HCXAI-based Approach","summary":"Human-centered explainable AI (HCXAI) advocates for the integration of social\naspects into AI explanations. Central to the HCXAI discourse is the Social\nTransparency (ST) framework, which aims to make the socio-organizational\ncontext of AI systems accessible to their users. In this work, we suggest\nextending the ST framework to address the risks of social misattributions in\nLarge Language Models (LLMs), particularly in sensitive areas like mental\nhealth. In fact LLMs, which are remarkably capable of simulating roles and\npersonas, may lead to mismatches between designers' intentions and users'\nperceptions of social attributes, risking to promote emotional manipulation and\ndangerous behaviors, cases of epistemic injustice, and unwarranted trust. To\naddress these issues, we propose enhancing the ST framework with a fifth\n'W-question' to clarify the specific social attributions assigned to LLMs by\nits designers and users. This addition aims to bridge the gap between LLM\ncapabilities and user perceptions, promoting the ethically responsible\ndevelopment and use of LLM-based technology.","updated":1711472562000,"published":1711472562000,"authors":["Andrea Ferrario","Alberto Termine","Alessandro Facchini"],"comments":"Extended version of the manuscript accepted for the ACM CHI Workshop\n  on Human-Centered Explainable AI 2024 (HCXAI24)","categories":["cs.AI"],"primary_category":"cs.AI","doi":null,"journal_ref":null,"peer_reviewed":true,"reader_id":"rid1","human_jargon_term":"Social\nTransparency (ST) framework","definition_text":"The Social Transparency (ST) framework is designed to help users understand the social and organizational contexts affecting AI systems, ensuring that the influences and decisions behind AI technologies are clear and comprehensible to those who use them.","model":"gpt4_abstract","Accuracy":"accurate","Ranking":0,"Notes":""},"108":{"arxiv_id":"2403.17873v1","url":"http:\/\/arxiv.org\/abs\/2403.17873v1","title":"Addressing Social Misattributions of Large Language Models: An\n  HCXAI-based Approach","summary":"Human-centered explainable AI (HCXAI) advocates for the integration of social\naspects into AI explanations. Central to the HCXAI discourse is the Social\nTransparency (ST) framework, which aims to make the socio-organizational\ncontext of AI systems accessible to their users. In this work, we suggest\nextending the ST framework to address the risks of social misattributions in\nLarge Language Models (LLMs), particularly in sensitive areas like mental\nhealth. In fact LLMs, which are remarkably capable of simulating roles and\npersonas, may lead to mismatches between designers' intentions and users'\nperceptions of social attributes, risking to promote emotional manipulation and\ndangerous behaviors, cases of epistemic injustice, and unwarranted trust. To\naddress these issues, we propose enhancing the ST framework with a fifth\n'W-question' to clarify the specific social attributions assigned to LLMs by\nits designers and users. This addition aims to bridge the gap between LLM\ncapabilities and user perceptions, promoting the ethically responsible\ndevelopment and use of LLM-based technology.","updated":1711472562000,"published":1711472562000,"authors":["Andrea Ferrario","Alberto Termine","Alessandro Facchini"],"comments":"Extended version of the manuscript accepted for the ACM CHI Workshop\n  on Human-Centered Explainable AI 2024 (HCXAI24)","categories":["cs.AI"],"primary_category":"cs.AI","doi":null,"journal_ref":null,"peer_reviewed":true,"reader_id":"rid1","human_jargon_term":"epistemic injustice","definition_text":"Epistemic injustice occurs when someone is unfairly deprived of their ability to participate in the sharing and creation of knowledge, often due to prejudice or misperceptions related to their social identity or group affiliation. This type of injustice can happen when people's contributions to knowledge or their competence are dismissed or undervalued because of bias.","model":"gpt4_abstract","Accuracy":"accurate","Ranking":0,"Notes":""},"109":{"arxiv_id":"2403.17873v1","url":"http:\/\/arxiv.org\/abs\/2403.17873v1","title":"Addressing Social Misattributions of Large Language Models: An\n  HCXAI-based Approach","summary":"Human-centered explainable AI (HCXAI) advocates for the integration of social\naspects into AI explanations. Central to the HCXAI discourse is the Social\nTransparency (ST) framework, which aims to make the socio-organizational\ncontext of AI systems accessible to their users. In this work, we suggest\nextending the ST framework to address the risks of social misattributions in\nLarge Language Models (LLMs), particularly in sensitive areas like mental\nhealth. In fact LLMs, which are remarkably capable of simulating roles and\npersonas, may lead to mismatches between designers' intentions and users'\nperceptions of social attributes, risking to promote emotional manipulation and\ndangerous behaviors, cases of epistemic injustice, and unwarranted trust. To\naddress these issues, we propose enhancing the ST framework with a fifth\n'W-question' to clarify the specific social attributions assigned to LLMs by\nits designers and users. This addition aims to bridge the gap between LLM\ncapabilities and user perceptions, promoting the ethically responsible\ndevelopment and use of LLM-based technology.","updated":1711472562000,"published":1711472562000,"authors":["Andrea Ferrario","Alberto Termine","Alessandro Facchini"],"comments":"Extended version of the manuscript accepted for the ACM CHI Workshop\n  on Human-Centered Explainable AI 2024 (HCXAI24)","categories":["cs.AI"],"primary_category":"cs.AI","doi":null,"journal_ref":null,"peer_reviewed":true,"reader_id":"rid1","human_jargon_term":"social misattributions","definition_text":"Social misattributions refer to situations where people mistakenly assign social characteristics or intentions to large language models (computer programs designed to understand and generate human language), leading to misunderstandings about what the models are really designed to do or represent. This can occur, for example, when a user wrongly assumes that a model has human emotions or biases, impacting how they interact with and respond to the technology.","model":"gpt4_abstract","Accuracy":"accurate","Ranking":0,"Notes":""},"110":{"arxiv_id":"2403.15875v1","url":"http:\/\/arxiv.org\/abs\/2403.15875v1","title":"LAMPER: LanguAge Model and Prompt EngineeRing for zero-shot time series\n  classification","summary":"This study constructs the LanguAge Model with Prompt EngineeRing (LAMPER)\nframework, designed to systematically evaluate the adaptability of pre-trained\nlanguage models (PLMs) in accommodating diverse prompts and their integration\nin zero-shot time series (TS) classification. We deploy LAMPER in experimental\nassessments using 128 univariate TS datasets sourced from the UCR archive. Our\nfindings indicate that the feature representation capacity of LAMPER is\ninfluenced by the maximum input token threshold imposed by PLMs.","updated":1711209157000,"published":1711209157000,"authors":["Zhicheng Du","Zhaotian Xie","Yan Tong","Peiwu Qin"],"comments":"Accepted as tiny paper in ICLR 2024","categories":["cs.AI","cs.CL"],"primary_category":"cs.AI","doi":null,"journal_ref":null,"peer_reviewed":true,"reader_id":"rid1","human_jargon_term":"LanguAge Model with Prompt EngineeRing","definition_text":"The LanguAge Model with Prompt EngineeRing (LAMPER) is a framework that helps to test and improve how well artificial intelligence language models can understand and respond to various instructions or questions automatically, without human input, even in complex tasks like classifying patterns in data.","model":"gpt4_abstract","Accuracy":"accurate","Ranking":1,"Notes":""},"111":{"arxiv_id":"2403.15875v1","url":"http:\/\/arxiv.org\/abs\/2403.15875v1","title":"LAMPER: LanguAge Model and Prompt EngineeRing for zero-shot time series\n  classification","summary":"This study constructs the LanguAge Model with Prompt EngineeRing (LAMPER)\nframework, designed to systematically evaluate the adaptability of pre-trained\nlanguage models (PLMs) in accommodating diverse prompts and their integration\nin zero-shot time series (TS) classification. We deploy LAMPER in experimental\nassessments using 128 univariate TS datasets sourced from the UCR archive. Our\nfindings indicate that the feature representation capacity of LAMPER is\ninfluenced by the maximum input token threshold imposed by PLMs.","updated":1711209157000,"published":1711209157000,"authors":["Zhicheng Du","Zhaotian Xie","Yan Tong","Peiwu Qin"],"comments":"Accepted as tiny paper in ICLR 2024","categories":["cs.AI","cs.CL"],"primary_category":"cs.AI","doi":null,"journal_ref":null,"peer_reviewed":true,"reader_id":"rid1","human_jargon_term":"UCR archive","definition_text":"The UCR archive is a collection of 128 different datasets specifically focused on univariate time series, which are used in scientific research to assess and develop methods for analyzing and classifying data that changes over time.","model":"gpt4_abstract","Accuracy":"accurate","Ranking":2,"Notes":""},"112":{"arxiv_id":"2403.15875v1","url":"http:\/\/arxiv.org\/abs\/2403.15875v1","title":"LAMPER: LanguAge Model and Prompt EngineeRing for zero-shot time series\n  classification","summary":"This study constructs the LanguAge Model with Prompt EngineeRing (LAMPER)\nframework, designed to systematically evaluate the adaptability of pre-trained\nlanguage models (PLMs) in accommodating diverse prompts and their integration\nin zero-shot time series (TS) classification. We deploy LAMPER in experimental\nassessments using 128 univariate TS datasets sourced from the UCR archive. Our\nfindings indicate that the feature representation capacity of LAMPER is\ninfluenced by the maximum input token threshold imposed by PLMs.","updated":1711209157000,"published":1711209157000,"authors":["Zhicheng Du","Zhaotian Xie","Yan Tong","Peiwu Qin"],"comments":"Accepted as tiny paper in ICLR 2024","categories":["cs.AI","cs.CL"],"primary_category":"cs.AI","doi":null,"journal_ref":null,"peer_reviewed":true,"reader_id":"rid1","human_jargon_term":"maximum input token threshold","definition_text":"The maximum input token threshold refers to the upper limit on the number of pieces of information, or 'tokens', that a language model can process at one time. This limitation affects how much data the model can consider when making its predictions or analyses.","model":"gpt4_abstract","Accuracy":"accurate","Ranking":0,"Notes":""},"113":{"arxiv_id":"2403.15875v1","url":"http:\/\/arxiv.org\/abs\/2403.15875v1","title":"LAMPER: LanguAge Model and Prompt EngineeRing for zero-shot time series\n  classification","summary":"This study constructs the LanguAge Model with Prompt EngineeRing (LAMPER)\nframework, designed to systematically evaluate the adaptability of pre-trained\nlanguage models (PLMs) in accommodating diverse prompts and their integration\nin zero-shot time series (TS) classification. We deploy LAMPER in experimental\nassessments using 128 univariate TS datasets sourced from the UCR archive. Our\nfindings indicate that the feature representation capacity of LAMPER is\ninfluenced by the maximum input token threshold imposed by PLMs.","updated":1711209157000,"published":1711209157000,"authors":["Zhicheng Du","Zhaotian Xie","Yan Tong","Peiwu Qin"],"comments":"Accepted as tiny paper in ICLR 2024","categories":["cs.AI","cs.CL"],"primary_category":"cs.AI","doi":null,"journal_ref":null,"peer_reviewed":true,"reader_id":"rid1","human_jargon_term":"pre-trained language models","definition_text":"Pre-trained language models (PLMs) are advanced software systems that have already been trained on large amounts of text data, which allows them to understand and generate human-like text. This prior training enables them to perform a variety of language-based tasks even before they are customized or further trained for specific applications.","model":"gpt4_abstract","Accuracy":"accurate","Ranking":0,"Notes":""},"114":{"arxiv_id":"2403.15875v1","url":"http:\/\/arxiv.org\/abs\/2403.15875v1","title":"LAMPER: LanguAge Model and Prompt EngineeRing for zero-shot time series\n  classification","summary":"This study constructs the LanguAge Model with Prompt EngineeRing (LAMPER)\nframework, designed to systematically evaluate the adaptability of pre-trained\nlanguage models (PLMs) in accommodating diverse prompts and their integration\nin zero-shot time series (TS) classification. We deploy LAMPER in experimental\nassessments using 128 univariate TS datasets sourced from the UCR archive. Our\nfindings indicate that the feature representation capacity of LAMPER is\ninfluenced by the maximum input token threshold imposed by PLMs.","updated":1711209157000,"published":1711209157000,"authors":["Zhicheng Du","Zhaotian Xie","Yan Tong","Peiwu Qin"],"comments":"Accepted as tiny paper in ICLR 2024","categories":["cs.AI","cs.CL"],"primary_category":"cs.AI","doi":null,"journal_ref":null,"peer_reviewed":true,"reader_id":"rid1","human_jargon_term":"univariate TS datasets","definition_text":"Univariate TS datasets refer to collections of data where each dataset consists of sequences of measurements of the same variable taken at continuous, regular intervals. For example, measuring the temperature every hour throughout the day would generate a univariate time series dataset of temperature readings.","model":"gpt4_abstract","Accuracy":"accurate","Ranking":1,"Notes":""},"115":{"arxiv_id":"2403.15875v1","url":"http:\/\/arxiv.org\/abs\/2403.15875v1","title":"LAMPER: LanguAge Model and Prompt EngineeRing for zero-shot time series\n  classification","summary":"This study constructs the LanguAge Model with Prompt EngineeRing (LAMPER)\nframework, designed to systematically evaluate the adaptability of pre-trained\nlanguage models (PLMs) in accommodating diverse prompts and their integration\nin zero-shot time series (TS) classification. We deploy LAMPER in experimental\nassessments using 128 univariate TS datasets sourced from the UCR archive. Our\nfindings indicate that the feature representation capacity of LAMPER is\ninfluenced by the maximum input token threshold imposed by PLMs.","updated":1711209157000,"published":1711209157000,"authors":["Zhicheng Du","Zhaotian Xie","Yan Tong","Peiwu Qin"],"comments":"Accepted as tiny paper in ICLR 2024","categories":["cs.AI","cs.CL"],"primary_category":"cs.AI","doi":null,"journal_ref":null,"peer_reviewed":true,"reader_id":"rid1","human_jargon_term":"zero-shot time series (TS) classification","definition_text":"Zero-shot time series classification is a method where a model can identify and categorize sequences of data it has never seen before, based on learning from different but related tasks. This allows the model to apply its knowledge to new situations without needing additional training on those specific tasks.","model":"gpt4_abstract","Accuracy":"accurate","Ranking":1,"Notes":""},"116":{"arxiv_id":"2403.16508v1","url":"http:\/\/arxiv.org\/abs\/2403.16508v1","title":"Return to Tradition: Learning Reliable Heuristics with Classical Machine\n  Learning","summary":"Current approaches for learning for planning have yet to achieve competitive\nperformance against classical planners in several domains, and have poor\noverall performance. In this work, we construct novel graph representations of\nlifted planning tasks and use the WL algorithm to generate features from them.\nThese features are used with classical machine learning methods which have up\nto 2 orders of magnitude fewer parameters and train up to 3 orders of magnitude\nfaster than the state-of-the-art deep learning for planning models. Our novel\napproach, WL-GOOSE, reliably learns heuristics from scratch and outperforms the\n$h^{\\text{FF}}$ heuristic in a fair competition setting. It also outperforms or\nties with LAMA on 4 out of 10 domains on coverage and 7 out of 10 domains on\nplan quality. WL-GOOSE is the first learning for planning model which achieves\nthese feats. Furthermore, we study the connections between our novel WL feature\ngeneration method, previous theoretically flavoured learning architectures, and\nDescription Logic Features for planning.","updated":1711352872000,"published":1711352872000,"authors":["Dillon Z. Chen","Felipe Trevizan","Sylvie Thi\u00e9baux"],"comments":"Extended version of ICAPS 2024 paper","categories":["cs.AI"],"primary_category":"cs.AI","doi":null,"journal_ref":null,"peer_reviewed":true,"reader_id":"rid1","human_jargon_term":"Description Logic Features","definition_text":"Description Logic Features refer to specific characteristics or properties used in planning problems that are derived from Description Logic, a type of formal knowledge representation system in computer science. These features help to enhance the decision-making process by structuring and utilizing the underlying logical properties of the entities and their relationships within the planning task.","model":"gpt4_abstract","Accuracy":"accurate","Ranking":2,"Notes":""},"117":{"arxiv_id":"2403.16508v1","url":"http:\/\/arxiv.org\/abs\/2403.16508v1","title":"Return to Tradition: Learning Reliable Heuristics with Classical Machine\n  Learning","summary":"Current approaches for learning for planning have yet to achieve competitive\nperformance against classical planners in several domains, and have poor\noverall performance. In this work, we construct novel graph representations of\nlifted planning tasks and use the WL algorithm to generate features from them.\nThese features are used with classical machine learning methods which have up\nto 2 orders of magnitude fewer parameters and train up to 3 orders of magnitude\nfaster than the state-of-the-art deep learning for planning models. Our novel\napproach, WL-GOOSE, reliably learns heuristics from scratch and outperforms the\n$h^{\\text{FF}}$ heuristic in a fair competition setting. It also outperforms or\nties with LAMA on 4 out of 10 domains on coverage and 7 out of 10 domains on\nplan quality. WL-GOOSE is the first learning for planning model which achieves\nthese feats. Furthermore, we study the connections between our novel WL feature\ngeneration method, previous theoretically flavoured learning architectures, and\nDescription Logic Features for planning.","updated":1711352872000,"published":1711352872000,"authors":["Dillon Z. Chen","Felipe Trevizan","Sylvie Thi\u00e9baux"],"comments":"Extended version of ICAPS 2024 paper","categories":["cs.AI"],"primary_category":"cs.AI","doi":null,"journal_ref":null,"peer_reviewed":true,"reader_id":"rid1","human_jargon_term":"LAMA","definition_text":"LAMA is a well-regarded, award-winning system used in the field of automated planning, which is specifically designed to optimize the process of creating sequences of actions to achieve specific goals efficiently. In practice, it helps determine the best course of actions in complex situations where planning is essential.","model":"gpt4_abstract","Accuracy":"accurate","Ranking":2,"Notes":""},"118":{"arxiv_id":"2403.16508v1","url":"http:\/\/arxiv.org\/abs\/2403.16508v1","title":"Return to Tradition: Learning Reliable Heuristics with Classical Machine\n  Learning","summary":"Current approaches for learning for planning have yet to achieve competitive\nperformance against classical planners in several domains, and have poor\noverall performance. In this work, we construct novel graph representations of\nlifted planning tasks and use the WL algorithm to generate features from them.\nThese features are used with classical machine learning methods which have up\nto 2 orders of magnitude fewer parameters and train up to 3 orders of magnitude\nfaster than the state-of-the-art deep learning for planning models. Our novel\napproach, WL-GOOSE, reliably learns heuristics from scratch and outperforms the\n$h^{\\text{FF}}$ heuristic in a fair competition setting. It also outperforms or\nties with LAMA on 4 out of 10 domains on coverage and 7 out of 10 domains on\nplan quality. WL-GOOSE is the first learning for planning model which achieves\nthese feats. Furthermore, we study the connections between our novel WL feature\ngeneration method, previous theoretically flavoured learning architectures, and\nDescription Logic Features for planning.","updated":1711352872000,"published":1711352872000,"authors":["Dillon Z. Chen","Felipe Trevizan","Sylvie Thi\u00e9baux"],"comments":"Extended version of ICAPS 2024 paper","categories":["cs.AI"],"primary_category":"cs.AI","doi":null,"journal_ref":null,"peer_reviewed":true,"reader_id":"rid1","human_jargon_term":"WL algorithm","definition_text":"The WL algorithm, short for Weisfeiler-Lehman algorithm, is a method used to generate features from graphs by assessing their structure. This process helps in identifying and differentiating between various graph forms, which is useful for tasks that involve the analysis or classification of networks or connections within data.","model":"gpt4_abstract","Accuracy":"accurate","Ranking":2,"Notes":""},"119":{"arxiv_id":"2403.16508v1","url":"http:\/\/arxiv.org\/abs\/2403.16508v1","title":"Return to Tradition: Learning Reliable Heuristics with Classical Machine\n  Learning","summary":"Current approaches for learning for planning have yet to achieve competitive\nperformance against classical planners in several domains, and have poor\noverall performance. In this work, we construct novel graph representations of\nlifted planning tasks and use the WL algorithm to generate features from them.\nThese features are used with classical machine learning methods which have up\nto 2 orders of magnitude fewer parameters and train up to 3 orders of magnitude\nfaster than the state-of-the-art deep learning for planning models. Our novel\napproach, WL-GOOSE, reliably learns heuristics from scratch and outperforms the\n$h^{\\text{FF}}$ heuristic in a fair competition setting. It also outperforms or\nties with LAMA on 4 out of 10 domains on coverage and 7 out of 10 domains on\nplan quality. WL-GOOSE is the first learning for planning model which achieves\nthese feats. Furthermore, we study the connections between our novel WL feature\ngeneration method, previous theoretically flavoured learning architectures, and\nDescription Logic Features for planning.","updated":1711352872000,"published":1711352872000,"authors":["Dillon Z. Chen","Felipe Trevizan","Sylvie Thi\u00e9baux"],"comments":"Extended version of ICAPS 2024 paper","categories":["cs.AI"],"primary_category":"cs.AI","doi":null,"journal_ref":null,"peer_reviewed":true,"reader_id":"rid1","human_jargon_term":"WL-GOOSE","definition_text":"WL-GOOSE is a novel method developed to enhance the process of creating and optimizing plans or strategies (known as \"planning\") by using unique graph structures and an efficient algorithm to extract useful features. These features are then applied to improve the decision-making tasks in planning, making it faster and more effective compared to traditional methods.","model":"gpt4_abstract","Accuracy":"accurate","Ranking":0,"Notes":""},"120":{"arxiv_id":"2403.16508v1","url":"http:\/\/arxiv.org\/abs\/2403.16508v1","title":"Return to Tradition: Learning Reliable Heuristics with Classical Machine\n  Learning","summary":"Current approaches for learning for planning have yet to achieve competitive\nperformance against classical planners in several domains, and have poor\noverall performance. In this work, we construct novel graph representations of\nlifted planning tasks and use the WL algorithm to generate features from them.\nThese features are used with classical machine learning methods which have up\nto 2 orders of magnitude fewer parameters and train up to 3 orders of magnitude\nfaster than the state-of-the-art deep learning for planning models. Our novel\napproach, WL-GOOSE, reliably learns heuristics from scratch and outperforms the\n$h^{\\text{FF}}$ heuristic in a fair competition setting. It also outperforms or\nties with LAMA on 4 out of 10 domains on coverage and 7 out of 10 domains on\nplan quality. WL-GOOSE is the first learning for planning model which achieves\nthese feats. Furthermore, we study the connections between our novel WL feature\ngeneration method, previous theoretically flavoured learning architectures, and\nDescription Logic Features for planning.","updated":1711352872000,"published":1711352872000,"authors":["Dillon Z. Chen","Felipe Trevizan","Sylvie Thi\u00e9baux"],"comments":"Extended version of ICAPS 2024 paper","categories":["cs.AI"],"primary_category":"cs.AI","doi":null,"journal_ref":null,"peer_reviewed":true,"reader_id":"rid1","human_jargon_term":"classical planners","definition_text":"Classical planners are tools used in artificial intelligence that help design sequences of actions to achieve a specific goal, typically based on predefined rules and logic. They are used to systematically organize and execute steps necessary to accomplish tasks in various computational environments.","model":"gpt4_abstract","Accuracy":"accurate","Ranking":1,"Notes":""},"121":{"arxiv_id":"2403.16508v1","url":"http:\/\/arxiv.org\/abs\/2403.16508v1","title":"Return to Tradition: Learning Reliable Heuristics with Classical Machine\n  Learning","summary":"Current approaches for learning for planning have yet to achieve competitive\nperformance against classical planners in several domains, and have poor\noverall performance. In this work, we construct novel graph representations of\nlifted planning tasks and use the WL algorithm to generate features from them.\nThese features are used with classical machine learning methods which have up\nto 2 orders of magnitude fewer parameters and train up to 3 orders of magnitude\nfaster than the state-of-the-art deep learning for planning models. Our novel\napproach, WL-GOOSE, reliably learns heuristics from scratch and outperforms the\n$h^{\\text{FF}}$ heuristic in a fair competition setting. It also outperforms or\nties with LAMA on 4 out of 10 domains on coverage and 7 out of 10 domains on\nplan quality. WL-GOOSE is the first learning for planning model which achieves\nthese feats. Furthermore, we study the connections between our novel WL feature\ngeneration method, previous theoretically flavoured learning architectures, and\nDescription Logic Features for planning.","updated":1711352872000,"published":1711352872000,"authors":["Dillon Z. Chen","Felipe Trevizan","Sylvie Thi\u00e9baux"],"comments":"Extended version of ICAPS 2024 paper","categories":["cs.AI"],"primary_category":"cs.AI","doi":null,"journal_ref":null,"peer_reviewed":true,"reader_id":"rid1","human_jargon_term":"flavoured learning architectures","definition_text":"Flavoured learning architectures in this context refer to variations or adaptations of traditional machine learning frameworks that incorporate specific theoretical insights or concepts. These adaptations are designed to enhance the learning process, potentially making it more suited to particular types of tasks or data.","model":"gpt4_abstract","Accuracy":"accurate","Ranking":0,"Notes":""},"122":{"arxiv_id":"2403.16508v1","url":"http:\/\/arxiv.org\/abs\/2403.16508v1","title":"Return to Tradition: Learning Reliable Heuristics with Classical Machine\n  Learning","summary":"Current approaches for learning for planning have yet to achieve competitive\nperformance against classical planners in several domains, and have poor\noverall performance. In this work, we construct novel graph representations of\nlifted planning tasks and use the WL algorithm to generate features from them.\nThese features are used with classical machine learning methods which have up\nto 2 orders of magnitude fewer parameters and train up to 3 orders of magnitude\nfaster than the state-of-the-art deep learning for planning models. Our novel\napproach, WL-GOOSE, reliably learns heuristics from scratch and outperforms the\n$h^{\\text{FF}}$ heuristic in a fair competition setting. It also outperforms or\nties with LAMA on 4 out of 10 domains on coverage and 7 out of 10 domains on\nplan quality. WL-GOOSE is the first learning for planning model which achieves\nthese feats. Furthermore, we study the connections between our novel WL feature\ngeneration method, previous theoretically flavoured learning architectures, and\nDescription Logic Features for planning.","updated":1711352872000,"published":1711352872000,"authors":["Dillon Z. Chen","Felipe Trevizan","Sylvie Thi\u00e9baux"],"comments":"Extended version of ICAPS 2024 paper","categories":["cs.AI"],"primary_category":"cs.AI","doi":null,"journal_ref":null,"peer_reviewed":true,"reader_id":"rid1","human_jargon_term":"graph representations","definition_text":"Graph representations are a way of organizing data where elements (such as objects, ideas, or points) are depicted as nodes (or points), and the relationships or connections between these elements are shown as edges (or lines). This visual framework helps to analyze and understand complex networks by displaying how each element interacts with others.","model":"gpt4_abstract","Accuracy":"accurate","Ranking":1,"Notes":""},"123":{"arxiv_id":"2403.16508v1","url":"http:\/\/arxiv.org\/abs\/2403.16508v1","title":"Return to Tradition: Learning Reliable Heuristics with Classical Machine\n  Learning","summary":"Current approaches for learning for planning have yet to achieve competitive\nperformance against classical planners in several domains, and have poor\noverall performance. In this work, we construct novel graph representations of\nlifted planning tasks and use the WL algorithm to generate features from them.\nThese features are used with classical machine learning methods which have up\nto 2 orders of magnitude fewer parameters and train up to 3 orders of magnitude\nfaster than the state-of-the-art deep learning for planning models. Our novel\napproach, WL-GOOSE, reliably learns heuristics from scratch and outperforms the\n$h^{\\text{FF}}$ heuristic in a fair competition setting. It also outperforms or\nties with LAMA on 4 out of 10 domains on coverage and 7 out of 10 domains on\nplan quality. WL-GOOSE is the first learning for planning model which achieves\nthese feats. Furthermore, we study the connections between our novel WL feature\ngeneration method, previous theoretically flavoured learning architectures, and\nDescription Logic Features for planning.","updated":1711352872000,"published":1711352872000,"authors":["Dillon Z. Chen","Felipe Trevizan","Sylvie Thi\u00e9baux"],"comments":"Extended version of ICAPS 2024 paper","categories":["cs.AI"],"primary_category":"cs.AI","doi":null,"journal_ref":null,"peer_reviewed":true,"reader_id":"rid1","human_jargon_term":"magnitude","definition_text":"In science and mathematics, \"magnitude\" generally refers to the size or extent of something, often expressed as a power of ten. It quantitatively measures the importance, size, or impact of an object or phenomenon relative to a standard or typical example. For instance, when something is said to have \"2 orders of magnitude fewer parameters,\" it means it has 100 times fewer parameters than another standard or comparison group, since each order of magnitude represents a tenfold change.","model":"gpt4_abstract","Accuracy":"accurate","Ranking":1,"Notes":""},"124":{"arxiv_id":"2403.16289v1","url":"http:\/\/arxiv.org\/abs\/2403.16289v1","title":"Engineering Safety Requirements for Autonomous Driving with Large\n  Language Models","summary":"Changes and updates in the requirement artifacts, which can be frequent in\nthe automotive domain, are a challenge for SafetyOps. Large Language Models\n(LLMs), with their impressive natural language understanding and generating\ncapabilities, can play a key role in automatically refining and decomposing\nrequirements after each update. In this study, we propose a prototype of a\npipeline of prompts and LLMs that receives an item definition and outputs\nsolutions in the form of safety requirements. This pipeline also performs a\nreview of the requirement dataset and identifies redundant or contradictory\nrequirements. We first identified the necessary characteristics for performing\nHARA and then defined tests to assess an LLM's capability in meeting these\ncriteria. We used design science with multiple iterations and let experts from\ndifferent companies evaluate each cycle quantitatively and qualitatively.\nFinally, the prototype was implemented at a case company and the responsible\nteam evaluated its efficiency.","updated":1711312851000,"published":1711312851000,"authors":["Ali Nouri","Beatriz Cabrero-Daniel","Fredrik T\u00f6rner","H\u0227kan Sivencrona","Christian Berger"],"comments":"Accepted in 32nd IEEE International Requirements Engineering 2024\n  conference, Iceland","categories":["cs.AI"],"primary_category":"cs.AI","doi":null,"journal_ref":null,"peer_reviewed":true,"reader_id":"rid1","human_jargon_term":"HARA","definition_text":"HARA, or Hazard Analysis and Risk Assessment, is a process used to identify and evaluate risks associated with potential safety hazards in order to prioritize and manage them effectively. This is especially important in industries like automotive, where ensuring safety is critical.","model":"gpt4_abstract","Accuracy":"accurate","Ranking":0,"Notes":""},"125":{"arxiv_id":"2403.16289v1","url":"http:\/\/arxiv.org\/abs\/2403.16289v1","title":"Engineering Safety Requirements for Autonomous Driving with Large\n  Language Models","summary":"Changes and updates in the requirement artifacts, which can be frequent in\nthe automotive domain, are a challenge for SafetyOps. Large Language Models\n(LLMs), with their impressive natural language understanding and generating\ncapabilities, can play a key role in automatically refining and decomposing\nrequirements after each update. In this study, we propose a prototype of a\npipeline of prompts and LLMs that receives an item definition and outputs\nsolutions in the form of safety requirements. This pipeline also performs a\nreview of the requirement dataset and identifies redundant or contradictory\nrequirements. We first identified the necessary characteristics for performing\nHARA and then defined tests to assess an LLM's capability in meeting these\ncriteria. We used design science with multiple iterations and let experts from\ndifferent companies evaluate each cycle quantitatively and qualitatively.\nFinally, the prototype was implemented at a case company and the responsible\nteam evaluated its efficiency.","updated":1711312851000,"published":1711312851000,"authors":["Ali Nouri","Beatriz Cabrero-Daniel","Fredrik T\u00f6rner","H\u0227kan Sivencrona","Christian Berger"],"comments":"Accepted in 32nd IEEE International Requirements Engineering 2024\n  conference, Iceland","categories":["cs.AI"],"primary_category":"cs.AI","doi":null,"journal_ref":null,"peer_reviewed":true,"reader_id":"rid1","human_jargon_term":"SafetyOps","definition_text":"SafetyOps refers to the practices and processes involved in maintaining and ensuring the safety of operations within a particular domain, such Behavioral as the automotive industry. It focuses on managing changes and updates to safety requirements and protocols to prevent hazards and ensure continuous safe operation.","model":"gpt4_abstract","Accuracy":"accurate","Ranking":0,"Notes":""},"126":{"arxiv_id":"2403.17419v1","url":"http:\/\/arxiv.org\/abs\/2403.17419v1","title":"AI Safety: Necessary, but insufficient and possibly problematic","summary":"This article critically examines the recent hype around AI safety. We first\nstart with noting the nature of the AI safety hype as being dominated by\ngovernments and corporations, and contrast it with other avenues within AI\nresearch on advancing social good. We consider what 'AI safety' actually means,\nand outline the dominant concepts that the digital footprint of AI safety\naligns with. We posit that AI safety has a nuanced and uneasy relationship with\ntransparency and other allied notions associated with societal good, indicating\nthat it is an insufficient notion if the goal is that of societal good in a\nbroad sense. We note that the AI safety debate has already influenced some\nregulatory efforts in AI, perhaps in not so desirable directions. We also share\nour concerns on how AI safety may normalize AI that advances structural harm\nthrough providing exploitative and harmful AI with a veneer of safety.","updated":1711433922000,"published":1711433922000,"authors":["Deepak P"],"comments":"AI & Soc (2024)","categories":["cs.AI","cs.CY"],"primary_category":"cs.AI","doi":"10.1007\/s00146-024-01899-y","journal_ref":null,"peer_reviewed":true,"reader_id":"rid1","human_jargon_term":"AI safety","definition_text":"AI safety refers to the field of study and practice aimed at ensuring that artificial intelligence systems operate in a way that is secure and does not cause harm to humans or society. It involves developing guidelines and frameworks to control AI behaviors and make sure that AI technology supports, rather than undermines, societal well-being.","model":"gpt4_abstract","Accuracy":"accurate","Ranking":0,"Notes":""},"127":{"arxiv_id":"2403.17419v1","url":"http:\/\/arxiv.org\/abs\/2403.17419v1","title":"AI Safety: Necessary, but insufficient and possibly problematic","summary":"This article critically examines the recent hype around AI safety. We first\nstart with noting the nature of the AI safety hype as being dominated by\ngovernments and corporations, and contrast it with other avenues within AI\nresearch on advancing social good. We consider what 'AI safety' actually means,\nand outline the dominant concepts that the digital footprint of AI safety\naligns with. We posit that AI safety has a nuanced and uneasy relationship with\ntransparency and other allied notions associated with societal good, indicating\nthat it is an insufficient notion if the goal is that of societal good in a\nbroad sense. We note that the AI safety debate has already influenced some\nregulatory efforts in AI, perhaps in not so desirable directions. We also share\nour concerns on how AI safety may normalize AI that advances structural harm\nthrough providing exploitative and harmful AI with a veneer of safety.","updated":1711433922000,"published":1711433922000,"authors":["Deepak P"],"comments":"AI & Soc (2024)","categories":["cs.AI","cs.CY"],"primary_category":"cs.AI","doi":"10.1007\/s00146-024-01899-y","journal_ref":null,"peer_reviewed":true,"reader_id":"rid1","human_jargon_term":"veneer","definition_text":"A veneer refers to a surface appearance or decoration that is attractive, but can be misleading because it covers up the true nature or quality of what's underneath.","model":"gpt4_abstract","Accuracy":"accurate","Ranking":1,"Notes":""},"128":{"arxiv_id":"2402.01786v2","url":"http:\/\/arxiv.org\/abs\/2402.01786v2","title":"COA-GPT: Generative Pre-trained Transformers for Accelerated Course of\n  Action Development in Military Operations","summary":"The development of Courses of Action (COAs) in military operations is\ntraditionally a time-consuming and intricate process. Addressing this\nchallenge, this study introduces COA-GPT, a novel algorithm employing Large\nLanguage Models (LLMs) for rapid and efficient generation of valid COAs.\nCOA-GPT incorporates military doctrine and domain expertise to LLMs through\nin-context learning, allowing commanders to input mission information - in both\ntext and image formats - and receive strategically aligned COAs for review and\napproval. Uniquely, COA-GPT not only accelerates COA development, producing\ninitial COAs within seconds, but also facilitates real-time refinement based on\ncommander feedback. This work evaluates COA-GPT in a military-relevant scenario\nwithin a militarized version of the StarCraft II game, comparing its\nperformance against state-of-the-art reinforcement learning algorithms. Our\nresults demonstrate COA-GPT's superiority in generating strategically sound\nCOAs more swiftly, with added benefits of enhanced adaptability and alignment\nwith commander intentions. COA-GPT's capability to rapidly adapt and update\nCOAs during missions presents a transformative potential for military planning,\nparticularly in addressing planning discrepancies and capitalizing on emergent\nwindows of opportunities.","updated":1711639362000,"published":1706824269000,"authors":["Vinicius G. Goecks","Nicholas Waytowich"],"comments":"Accepted at the NATO Science and Technology Organization Symposium\n  (ICMCIS) organized by the Information Systems Technology (IST) Panel,\n  IST-205-RSY - the ICMCIS, held in Koblenz, Germany, 23-24 April 2024","categories":["cs.AI","cs.CL","cs.HC","cs.LG","I.2.6; I.2.7; J.7"],"primary_category":"cs.AI","doi":null,"journal_ref":null,"peer_reviewed":true,"reader_id":"rid1","human_jargon_term":"COA-GPT","definition_text":"COA-GPT is a highly advanced computer program designed to quickly and effectively create military strategies, or \"Courses of Action,\" by integrating existing military rules and expert knowledge into its calculations. It uses cutting-edge artificial intelligence to produce these strategies, allowing military commanders to make decisions faster by providing instant strategic suggestions and adjusting them based on the commanders' feedback.","model":"gpt4_abstract","Accuracy":"accurate","Ranking":2,"Notes":""},"129":{"arxiv_id":"2402.01786v2","url":"http:\/\/arxiv.org\/abs\/2402.01786v2","title":"COA-GPT: Generative Pre-trained Transformers for Accelerated Course of\n  Action Development in Military Operations","summary":"The development of Courses of Action (COAs) in military operations is\ntraditionally a time-consuming and intricate process. Addressing this\nchallenge, this study introduces COA-GPT, a novel algorithm employing Large\nLanguage Models (LLMs) for rapid and efficient generation of valid COAs.\nCOA-GPT incorporates military doctrine and domain expertise to LLMs through\nin-context learning, allowing commanders to input mission information - in both\ntext and image formats - and receive strategically aligned COAs for review and\napproval. Uniquely, COA-GPT not only accelerates COA development, producing\ninitial COAs within seconds, but also facilitates real-time refinement based on\ncommander feedback. This work evaluates COA-GPT in a military-relevant scenario\nwithin a militarized version of the StarCraft II game, comparing its\nperformance against state-of-the-art reinforcement learning algorithms. Our\nresults demonstrate COA-GPT's superiority in generating strategically sound\nCOAs more swiftly, with added benefits of enhanced adaptability and alignment\nwith commander intentions. COA-GPT's capability to rapidly adapt and update\nCOAs during missions presents a transformative potential for military planning,\nparticularly in addressing planning discrepancies and capitalizing on emergent\nwindows of opportunities.","updated":1711639362000,"published":1706824269000,"authors":["Vinicius G. Goecks","Nicholas Waytowich"],"comments":"Accepted at the NATO Science and Technology Organization Symposium\n  (ICMCIS) organized by the Information Systems Technology (IST) Panel,\n  IST-205-RSY - the ICMCIS, held in Koblenz, Germany, 23-24 April 2024","categories":["cs.AI","cs.CL","cs.HC","cs.LG","I.2.6; I.2.7; J.7"],"primary_category":"cs.AI","doi":null,"journal_ref":null,"peer_reviewed":true,"reader_id":"rid1","human_jargon_term":"Courses of Action","definition_text":"Courses of Action (COAs) are planned sequences of activities or strategies that military commanders can implement to achieve specific objectives during operations. They outline different approaches that can be taken to handle a situation, considering the available resources and constraints.","model":"gpt4_abstract","Accuracy":"accurate","Ranking":2,"Notes":""},"130":{"arxiv_id":"2402.01786v2","url":"http:\/\/arxiv.org\/abs\/2402.01786v2","title":"COA-GPT: Generative Pre-trained Transformers for Accelerated Course of\n  Action Development in Military Operations","summary":"The development of Courses of Action (COAs) in military operations is\ntraditionally a time-consuming and intricate process. Addressing this\nchallenge, this study introduces COA-GPT, a novel algorithm employing Large\nLanguage Models (LLMs) for rapid and efficient generation of valid COAs.\nCOA-GPT incorporates military doctrine and domain expertise to LLMs through\nin-context learning, allowing commanders to input mission information - in both\ntext and image formats - and receive strategically aligned COAs for review and\napproval. Uniquely, COA-GPT not only accelerates COA development, producing\ninitial COAs within seconds, but also facilitates real-time refinement based on\ncommander feedback. This work evaluates COA-GPT in a military-relevant scenario\nwithin a militarized version of the StarCraft II game, comparing its\nperformance against state-of-the-art reinforcement learning algorithms. Our\nresults demonstrate COA-GPT's superiority in generating strategically sound\nCOAs more swiftly, with added benefits of enhanced adaptability and alignment\nwith commander intentions. COA-GPT's capability to rapidly adapt and update\nCOAs during missions presents a transformative potential for military planning,\nparticularly in addressing planning discrepancies and capitalizing on emergent\nwindows of opportunities.","updated":1711639362000,"published":1706824269000,"authors":["Vinicius G. Goecks","Nicholas Waytowich"],"comments":"Accepted at the NATO Science and Technology Organization Symposium\n  (ICMCIS) organized by the Information Systems Technology (IST) Panel,\n  IST-205-RSY - the ICMCIS, held in Koblenz, Germany, 23-24 April 2024","categories":["cs.AI","cs.CL","cs.HC","cs.LG","I.2.6; I.2.7; J.7"],"primary_category":"cs.AI","doi":null,"journal_ref":null,"peer_reviewed":true,"reader_id":"rid1","human_jargon_term":"commander feedback","definition_text":"Commander feedback refers to the responses and directives provided by a military leader after reviewing strategic plans or actions, such as proposed military operations. This feedback is used to refine and improve these plans to better align with the mission's objectives and the commander's intent.","model":"gpt4_abstract","Accuracy":"accurate","Ranking":0,"Notes":""},"131":{"arxiv_id":"2403.10112v1","url":"http:\/\/arxiv.org\/abs\/2403.10112v1","title":"Single- and Multi-Agent Private Active Sensing: A Deep Neuroevolution\n  Approach","summary":"In this paper, we focus on one centralized and one decentralized problem of\nactive hypothesis testing in the presence of an eavesdropper. For the\ncentralized problem including a single legitimate agent, we present a new\nframework based on NeuroEvolution (NE), whereas, for the decentralized problem,\nwe develop a novel NE-based method for solving collaborative multi-agent tasks,\nwhich interestingly maintains all computational benefits of single-agent NE.\nThe superiority of the proposed EAHT approaches over conventional active\nhypothesis testing policies, as well as learning-based methods, is validated\nthrough numerical investigations in an example use case of anomaly detection\nover wireless sensor networks.","updated":1710492956000,"published":1710492956000,"authors":["George Stamatelis","Angelos-Nikolaos Kanatas","Ioannis Asprogerakas","George C. Alexandropoulos"],"comments":"7 pages, 5 figures, accepted at IEEE ICC 2024 (to be presented)","categories":["cs.AI","cs.CR","cs.MA","cs.NE"],"primary_category":"cs.AI","doi":null,"journal_ref":null,"peer_reviewed":true,"reader_id":"rid1","human_jargon_term":"NeuroEvolution","definition_text":"NeuroEvolution is a type of artificial intelligence technique that designs and optimizes neural networks, which are algorithms modeled after the human brain, using evolutionary algorithms that simulate the process of natural evolution. This method allows the networks to adapt and improve over time automatically, making decisions based on trial and error, much like how nature selects the fittest organisms for survival.","model":"gpt4_abstract","Accuracy":"accurate","Ranking":-1,"Notes":""},"132":{"arxiv_id":"2403.10112v1","url":"http:\/\/arxiv.org\/abs\/2403.10112v1","title":"Single- and Multi-Agent Private Active Sensing: A Deep Neuroevolution\n  Approach","summary":"In this paper, we focus on one centralized and one decentralized problem of\nactive hypothesis testing in the presence of an eavesdropper. For the\ncentralized problem including a single legitimate agent, we present a new\nframework based on NeuroEvolution (NE), whereas, for the decentralized problem,\nwe develop a novel NE-based method for solving collaborative multi-agent tasks,\nwhich interestingly maintains all computational benefits of single-agent NE.\nThe superiority of the proposed EAHT approaches over conventional active\nhypothesis testing policies, as well as learning-based methods, is validated\nthrough numerical investigations in an example use case of anomaly detection\nover wireless sensor networks.","updated":1710492956000,"published":1710492956000,"authors":["George Stamatelis","Angelos-Nikolaos Kanatas","Ioannis Asprogerakas","George C. Alexandropoulos"],"comments":"7 pages, 5 figures, accepted at IEEE ICC 2024 (to be presented)","categories":["cs.AI","cs.CR","cs.MA","cs.NE"],"primary_category":"cs.AI","doi":null,"journal_ref":null,"peer_reviewed":true,"reader_id":"rid1","human_jargon_term":"centralized and one decentralized problem","definition_text":"In the scenario described, a \"centralized problem\" involves a situation where a single entity or agent is responsible for making decisions or solving a problem on its own. Conversely, a \"decentralized problem\" refers to a situation where multiple agents collaborate or work independently to address a problem, rather than being directed by a central authority.","model":"gpt4_abstract","Accuracy":"accurate","Ranking":0,"Notes":""},"133":{"arxiv_id":"2403.10112v1","url":"http:\/\/arxiv.org\/abs\/2403.10112v1","title":"Single- and Multi-Agent Private Active Sensing: A Deep Neuroevolution\n  Approach","summary":"In this paper, we focus on one centralized and one decentralized problem of\nactive hypothesis testing in the presence of an eavesdropper. For the\ncentralized problem including a single legitimate agent, we present a new\nframework based on NeuroEvolution (NE), whereas, for the decentralized problem,\nwe develop a novel NE-based method for solving collaborative multi-agent tasks,\nwhich interestingly maintains all computational benefits of single-agent NE.\nThe superiority of the proposed EAHT approaches over conventional active\nhypothesis testing policies, as well as learning-based methods, is validated\nthrough numerical investigations in an example use case of anomaly detection\nover wireless sensor networks.","updated":1710492956000,"published":1710492956000,"authors":["George Stamatelis","Angelos-Nikolaos Kanatas","Ioannis Asprogerakas","George C. Alexandropoulos"],"comments":"7 pages, 5 figures, accepted at IEEE ICC 2024 (to be presented)","categories":["cs.AI","cs.CR","cs.MA","cs.NE"],"primary_category":"cs.AI","doi":null,"journal_ref":null,"peer_reviewed":true,"reader_id":"rid1","human_jargon_term":"multi-agent tasks","definition_text":"Multi-agent tasks involve multiple agents, which can be software programs or robots, working together to achieve a common goal or complete a specific job. Each agent may have different capabilities or responsibilities, but they collaborate to efficiently solve complex problems that are difficult for an individual agent to handle alone.","model":"gpt4_abstract","Accuracy":"accurate","Ranking":0,"Notes":""},"134":{"arxiv_id":"2403.10112v1","url":"http:\/\/arxiv.org\/abs\/2403.10112v1","title":"Single- and Multi-Agent Private Active Sensing: A Deep Neuroevolution\n  Approach","summary":"In this paper, we focus on one centralized and one decentralized problem of\nactive hypothesis testing in the presence of an eavesdropper. For the\ncentralized problem including a single legitimate agent, we present a new\nframework based on NeuroEvolution (NE), whereas, for the decentralized problem,\nwe develop a novel NE-based method for solving collaborative multi-agent tasks,\nwhich interestingly maintains all computational benefits of single-agent NE.\nThe superiority of the proposed EAHT approaches over conventional active\nhypothesis testing policies, as well as learning-based methods, is validated\nthrough numerical investigations in an example use case of anomaly detection\nover wireless sensor networks.","updated":1710492956000,"published":1710492956000,"authors":["George Stamatelis","Angelos-Nikolaos Kanatas","Ioannis Asprogerakas","George C. Alexandropoulos"],"comments":"7 pages, 5 figures, accepted at IEEE ICC 2024 (to be presented)","categories":["cs.AI","cs.CR","cs.MA","cs.NE"],"primary_category":"cs.AI","doi":null,"journal_ref":null,"peer_reviewed":true,"reader_id":"rid1","human_jargon_term":"single legitimate agent","definition_text":"A \"single legitimate agent\" refers to one authorized individual or system involved in a task or operation, often working within a network or framework designed to test or monitor hypotheses or scenarios without communications or interference from others not authorized or involved.","model":"gpt4_abstract","Accuracy":"accurate","Ranking":0,"Notes":""},"135":{"arxiv_id":"2403.10112v1","url":"http:\/\/arxiv.org\/abs\/2403.10112v1","title":"Single- and Multi-Agent Private Active Sensing: A Deep Neuroevolution\n  Approach","summary":"In this paper, we focus on one centralized and one decentralized problem of\nactive hypothesis testing in the presence of an eavesdropper. For the\ncentralized problem including a single legitimate agent, we present a new\nframework based on NeuroEvolution (NE), whereas, for the decentralized problem,\nwe develop a novel NE-based method for solving collaborative multi-agent tasks,\nwhich interestingly maintains all computational benefits of single-agent NE.\nThe superiority of the proposed EAHT approaches over conventional active\nhypothesis testing policies, as well as learning-based methods, is validated\nthrough numerical investigations in an example use case of anomaly detection\nover wireless sensor networks.","updated":1710492956000,"published":1710492956000,"authors":["George Stamatelis","Angelos-Nikolaos Kanatas","Ioannis Asprogerakas","George C. Alexandropoulos"],"comments":"7 pages, 5 figures, accepted at IEEE ICC 2024 (to be presented)","categories":["cs.AI","cs.CR","cs.MA","cs.NE"],"primary_category":"cs.AI","doi":null,"journal_ref":null,"peer_reviewed":true,"reader_id":"rid1","human_jargon_term":"wireless sensor networks","definition_text":"Wireless sensor networks consist of a group of small devices equipped with sensors that can communicate wirelessly and collect data from their surroundings. These networks are typically used to monitor and gather information from various environments, such as temperature or movement, without needing physical connections.","model":"gpt4_abstract","Accuracy":"accurate","Ranking":0,"Notes":""},"136":{"arxiv_id":"2403.07131v1","url":"http:\/\/arxiv.org\/abs\/2403.07131v1","title":"Bigraph Matching Weighted with Learnt Incentive Function for Multi-Robot\n  Task Allocation","summary":"Most real-world Multi-Robot Task Allocation (MRTA) problems require fast and\nefficient decision-making, which is often achieved using heuristics-aided\nmethods such as genetic algorithms, auction-based methods, and bipartite graph\nmatching methods. These methods often assume a form that lends better\nexplainability compared to an end-to-end (learnt) neural network based policy\nfor MRTA. However, deriving suitable heuristics can be tedious, risky and in\nsome cases impractical if problems are too complex. This raises the question:\ncan these heuristics be learned? To this end, this paper particularly develops\na Graph Reinforcement Learning (GRL) framework to learn the heuristics or\nincentives for a bipartite graph matching approach to MRTA. Specifically a\nCapsule Attention policy model is used to learn how to weight task\/robot\npairings (edges) in the bipartite graph that connects the set of tasks to the\nset of robots. The original capsule attention network architecture is\nfundamentally modified by adding encoding of robots' state graph, and two\nMultihead Attention based decoders whose output are used to construct a\nLogNormal distribution matrix from which positive bigraph weights can be drawn.\nThe performance of this new bigraph matching approach augmented with a\nGRL-derived incentive is found to be at par with the original bigraph matching\napproach that used expert-specified heuristics, with the former offering\nnotable robustness benefits. During training, the learned incentive policy is\nfound to get initially closer to the expert-specified incentive and then\nslightly deviate from its trend.","updated":1710186908000,"published":1710186908000,"authors":["Steve Paul","Nathan Maurer","Souma Chowdhury"],"comments":"This paper was accepted for presentation in proceedings of IEEE\n  International Conference on Robotics and Automation 2024","categories":["cs.AI","cs.MA"],"primary_category":"cs.AI","doi":null,"journal_ref":null,"peer_reviewed":true,"reader_id":"rid1","human_jargon_term":"Capsule Attention policy model","definition_text":"The Capsule Attention policy model is a type of computer algorithm used to selectively focus on certain parts of data, enabling a system to effectively learn and make decisions by prioritizing important information. In the context of allocating tasks to robots, this model helps determine the best task for each robot by weighing different task and robot combinations.","model":"gpt4_abstract","Accuracy":"accurate","Ranking":2,"Notes":""},"137":{"arxiv_id":"2403.07131v1","url":"http:\/\/arxiv.org\/abs\/2403.07131v1","title":"Bigraph Matching Weighted with Learnt Incentive Function for Multi-Robot\n  Task Allocation","summary":"Most real-world Multi-Robot Task Allocation (MRTA) problems require fast and\nefficient decision-making, which is often achieved using heuristics-aided\nmethods such as genetic algorithms, auction-based methods, and bipartite graph\nmatching methods. These methods often assume a form that lends better\nexplainability compared to an end-to-end (learnt) neural network based policy\nfor MRTA. However, deriving suitable heuristics can be tedious, risky and in\nsome cases impractical if problems are too complex. This raises the question:\ncan these heuristics be learned? To this end, this paper particularly develops\na Graph Reinforcement Learning (GRL) framework to learn the heuristics or\nincentives for a bipartite graph matching approach to MRTA. Specifically a\nCapsule Attention policy model is used to learn how to weight task\/robot\npairings (edges) in the bipartite graph that connects the set of tasks to the\nset of robots. The original capsule attention network architecture is\nfundamentally modified by adding encoding of robots' state graph, and two\nMultihead Attention based decoders whose output are used to construct a\nLogNormal distribution matrix from which positive bigraph weights can be drawn.\nThe performance of this new bigraph matching approach augmented with a\nGRL-derived incentive is found to be at par with the original bigraph matching\napproach that used expert-specified heuristics, with the former offering\nnotable robustness benefits. During training, the learned incentive policy is\nfound to get initially closer to the expert-specified incentive and then\nslightly deviate from its trend.","updated":1710186908000,"published":1710186908000,"authors":["Steve Paul","Nathan Maurer","Souma Chowdhury"],"comments":"This paper was accepted for presentation in proceedings of IEEE\n  International Conference on Robotics and Automation 2024","categories":["cs.AI","cs.MA"],"primary_category":"cs.AI","doi":null,"journal_ref":null,"peer_reviewed":true,"reader_id":"rid1","human_jargon_term":"GRL-derived incentive","definition_text":"A GRL-derived incentive refers to a method where an AI system uses a technique called Graph Reinforcement Learning to determine the best way to distribute tasks among multiple robots. This approach learns the most effective motivations or rewards to guide the decision-making process, rather than using predefined rules set by humans.","model":"gpt4_abstract","Accuracy":"accurate","Ranking":1,"Notes":""},"138":{"arxiv_id":"2403.07131v1","url":"http:\/\/arxiv.org\/abs\/2403.07131v1","title":"Bigraph Matching Weighted with Learnt Incentive Function for Multi-Robot\n  Task Allocation","summary":"Most real-world Multi-Robot Task Allocation (MRTA) problems require fast and\nefficient decision-making, which is often achieved using heuristics-aided\nmethods such as genetic algorithms, auction-based methods, and bipartite graph\nmatching methods. These methods often assume a form that lends better\nexplainability compared to an end-to-end (learnt) neural network based policy\nfor MRTA. However, deriving suitable heuristics can be tedious, risky and in\nsome cases impractical if problems are too complex. This raises the question:\ncan these heuristics be learned? To this end, this paper particularly develops\na Graph Reinforcement Learning (GRL) framework to learn the heuristics or\nincentives for a bipartite graph matching approach to MRTA. Specifically a\nCapsule Attention policy model is used to learn how to weight task\/robot\npairings (edges) in the bipartite graph that connects the set of tasks to the\nset of robots. The original capsule attention network architecture is\nfundamentally modified by adding encoding of robots' state graph, and two\nMultihead Attention based decoders whose output are used to construct a\nLogNormal distribution matrix from which positive bigraph weights can be drawn.\nThe performance of this new bigraph matching approach augmented with a\nGRL-derived incentive is found to be at par with the original bigraph matching\napproach that used expert-specified heuristics, with the former offering\nnotable robustness benefits. During training, the learned incentive policy is\nfound to get initially closer to the expert-specified incentive and then\nslightly deviate from its trend.","updated":1710186908000,"published":1710186908000,"authors":["Steve Paul","Nathan Maurer","Souma Chowdhury"],"comments":"This paper was accepted for presentation in proceedings of IEEE\n  International Conference on Robotics and Automation 2024","categories":["cs.AI","cs.MA"],"primary_category":"cs.AI","doi":null,"journal_ref":null,"peer_reviewed":true,"reader_id":"rid1","human_jargon_term":"Graph Reinforcement Learning (GRL) framework","definition_text":"The Graph Reinforcement Learning (GRL) framework is a method used in computer science where a system learns how to make decisions by using a network structure, called a graph, to understand how different elements are connected. This system improves its decision-making skills over time by continuously learning from its experiences, much like how humans learn from their past actions.","model":"gpt4_abstract","Accuracy":"accurate","Ranking":0,"Notes":""},"139":{"arxiv_id":"2403.07131v1","url":"http:\/\/arxiv.org\/abs\/2403.07131v1","title":"Bigraph Matching Weighted with Learnt Incentive Function for Multi-Robot\n  Task Allocation","summary":"Most real-world Multi-Robot Task Allocation (MRTA) problems require fast and\nefficient decision-making, which is often achieved using heuristics-aided\nmethods such as genetic algorithms, auction-based methods, and bipartite graph\nmatching methods. These methods often assume a form that lends better\nexplainability compared to an end-to-end (learnt) neural network based policy\nfor MRTA. However, deriving suitable heuristics can be tedious, risky and in\nsome cases impractical if problems are too complex. This raises the question:\ncan these heuristics be learned? To this end, this paper particularly develops\na Graph Reinforcement Learning (GRL) framework to learn the heuristics or\nincentives for a bipartite graph matching approach to MRTA. Specifically a\nCapsule Attention policy model is used to learn how to weight task\/robot\npairings (edges) in the bipartite graph that connects the set of tasks to the\nset of robots. The original capsule attention network architecture is\nfundamentally modified by adding encoding of robots' state graph, and two\nMultihead Attention based decoders whose output are used to construct a\nLogNormal distribution matrix from which positive bigraph weights can be drawn.\nThe performance of this new bigraph matching approach augmented with a\nGRL-derived incentive is found to be at par with the original bigraph matching\napproach that used expert-specified heuristics, with the former offering\nnotable robustness benefits. During training, the learned incentive policy is\nfound to get initially closer to the expert-specified incentive and then\nslightly deviate from its trend.","updated":1710186908000,"published":1710186908000,"authors":["Steve Paul","Nathan Maurer","Souma Chowdhury"],"comments":"This paper was accepted for presentation in proceedings of IEEE\n  International Conference on Robotics and Automation 2024","categories":["cs.AI","cs.MA"],"primary_category":"cs.AI","doi":null,"journal_ref":null,"peer_reviewed":true,"reader_id":"rid1","human_jargon_term":"LogNormal distribution matrix","definition_text":"A LogNormal distribution matrix represents data where the logarithm of the values follows a normal distribution. In simpler terms, it is a structured set of data where each number, when transformed by taking its logarithm, resembles a bell-shaped curve, commonly used to model values that can't be negative.","model":"gpt4_abstract","Accuracy":"accurate","Ranking":-1,"Notes":""},"140":{"arxiv_id":"2403.07131v1","url":"http:\/\/arxiv.org\/abs\/2403.07131v1","title":"Bigraph Matching Weighted with Learnt Incentive Function for Multi-Robot\n  Task Allocation","summary":"Most real-world Multi-Robot Task Allocation (MRTA) problems require fast and\nefficient decision-making, which is often achieved using heuristics-aided\nmethods such as genetic algorithms, auction-based methods, and bipartite graph\nmatching methods. These methods often assume a form that lends better\nexplainability compared to an end-to-end (learnt) neural network based policy\nfor MRTA. However, deriving suitable heuristics can be tedious, risky and in\nsome cases impractical if problems are too complex. This raises the question:\ncan these heuristics be learned? To this end, this paper particularly develops\na Graph Reinforcement Learning (GRL) framework to learn the heuristics or\nincentives for a bipartite graph matching approach to MRTA. Specifically a\nCapsule Attention policy model is used to learn how to weight task\/robot\npairings (edges) in the bipartite graph that connects the set of tasks to the\nset of robots. The original capsule attention network architecture is\nfundamentally modified by adding encoding of robots' state graph, and two\nMultihead Attention based decoders whose output are used to construct a\nLogNormal distribution matrix from which positive bigraph weights can be drawn.\nThe performance of this new bigraph matching approach augmented with a\nGRL-derived incentive is found to be at par with the original bigraph matching\napproach that used expert-specified heuristics, with the former offering\nnotable robustness benefits. During training, the learned incentive policy is\nfound to get initially closer to the expert-specified incentive and then\nslightly deviate from its trend.","updated":1710186908000,"published":1710186908000,"authors":["Steve Paul","Nathan Maurer","Souma Chowdhury"],"comments":"This paper was accepted for presentation in proceedings of IEEE\n  International Conference on Robotics and Automation 2024","categories":["cs.AI","cs.MA"],"primary_category":"cs.AI","doi":null,"journal_ref":null,"peer_reviewed":true,"reader_id":"rid1","human_jargon_term":"Multi-Robot Task Allocation","definition_text":"Multi-Robot Task Allocation (MRTA) refers to the process of efficiently assigning various tasks to different robots in a way that optimizes how the group as a whole completes these tasks. This involves deciding which robot will perform each task based on factors such as task requirements and robot capabilities.","model":"gpt4_abstract","Accuracy":"accurate","Ranking":0,"Notes":""},"141":{"arxiv_id":"2403.07131v1","url":"http:\/\/arxiv.org\/abs\/2403.07131v1","title":"Bigraph Matching Weighted with Learnt Incentive Function for Multi-Robot\n  Task Allocation","summary":"Most real-world Multi-Robot Task Allocation (MRTA) problems require fast and\nefficient decision-making, which is often achieved using heuristics-aided\nmethods such as genetic algorithms, auction-based methods, and bipartite graph\nmatching methods. These methods often assume a form that lends better\nexplainability compared to an end-to-end (learnt) neural network based policy\nfor MRTA. However, deriving suitable heuristics can be tedious, risky and in\nsome cases impractical if problems are too complex. This raises the question:\ncan these heuristics be learned? To this end, this paper particularly develops\na Graph Reinforcement Learning (GRL) framework to learn the heuristics or\nincentives for a bipartite graph matching approach to MRTA. Specifically a\nCapsule Attention policy model is used to learn how to weight task\/robot\npairings (edges) in the bipartite graph that connects the set of tasks to the\nset of robots. The original capsule attention network architecture is\nfundamentally modified by adding encoding of robots' state graph, and two\nMultihead Attention based decoders whose output are used to construct a\nLogNormal distribution matrix from which positive bigraph weights can be drawn.\nThe performance of this new bigraph matching approach augmented with a\nGRL-derived incentive is found to be at par with the original bigraph matching\napproach that used expert-specified heuristics, with the former offering\nnotable robustness benefits. During training, the learned incentive policy is\nfound to get initially closer to the expert-specified incentive and then\nslightly deviate from its trend.","updated":1710186908000,"published":1710186908000,"authors":["Steve Paul","Nathan Maurer","Souma Chowdhury"],"comments":"This paper was accepted for presentation in proceedings of IEEE\n  International Conference on Robotics and Automation 2024","categories":["cs.AI","cs.MA"],"primary_category":"cs.AI","doi":null,"journal_ref":null,"peer_reviewed":true,"reader_id":"rid1","human_jargon_term":"Multihead Attention based decoders","definition_text":"Multihead Attention based decoders are components in a computational model that allow the system to focus on different parts of input data simultaneously to better understand the relationships and importance of these parts. By doing so, they help in generating more accurate and relevant outputs based on the input they receive.","model":"gpt4_abstract","Accuracy":"accurate","Ranking":0,"Notes":""},"142":{"arxiv_id":"2403.07131v1","url":"http:\/\/arxiv.org\/abs\/2403.07131v1","title":"Bigraph Matching Weighted with Learnt Incentive Function for Multi-Robot\n  Task Allocation","summary":"Most real-world Multi-Robot Task Allocation (MRTA) problems require fast and\nefficient decision-making, which is often achieved using heuristics-aided\nmethods such as genetic algorithms, auction-based methods, and bipartite graph\nmatching methods. These methods often assume a form that lends better\nexplainability compared to an end-to-end (learnt) neural network based policy\nfor MRTA. However, deriving suitable heuristics can be tedious, risky and in\nsome cases impractical if problems are too complex. This raises the question:\ncan these heuristics be learned? To this end, this paper particularly develops\na Graph Reinforcement Learning (GRL) framework to learn the heuristics or\nincentives for a bipartite graph matching approach to MRTA. Specifically a\nCapsule Attention policy model is used to learn how to weight task\/robot\npairings (edges) in the bipartite graph that connects the set of tasks to the\nset of robots. The original capsule attention network architecture is\nfundamentally modified by adding encoding of robots' state graph, and two\nMultihead Attention based decoders whose output are used to construct a\nLogNormal distribution matrix from which positive bigraph weights can be drawn.\nThe performance of this new bigraph matching approach augmented with a\nGRL-derived incentive is found to be at par with the original bigraph matching\napproach that used expert-specified heuristics, with the former offering\nnotable robustness benefits. During training, the learned incentive policy is\nfound to get initially closer to the expert-specified incentive and then\nslightly deviate from its trend.","updated":1710186908000,"published":1710186908000,"authors":["Steve Paul","Nathan Maurer","Souma Chowdhury"],"comments":"This paper was accepted for presentation in proceedings of IEEE\n  International Conference on Robotics and Automation 2024","categories":["cs.AI","cs.MA"],"primary_category":"cs.AI","doi":null,"journal_ref":null,"peer_reviewed":true,"reader_id":"rid1","human_jargon_term":"auction-based methods","definition_text":"Auction-based methods are a way to assign tasks to robots by having the robots \"bid\" for the tasks they want or are best suited to complete, similar to bidders in a traditional auction competing for an item. The task is then assigned to the robot with the best bid, often considering factors like the robot's suitability or efficiency for the task.","model":"gpt4_abstract","Accuracy":"accurate","Ranking":2,"Notes":""},"143":{"arxiv_id":"2403.07131v1","url":"http:\/\/arxiv.org\/abs\/2403.07131v1","title":"Bigraph Matching Weighted with Learnt Incentive Function for Multi-Robot\n  Task Allocation","summary":"Most real-world Multi-Robot Task Allocation (MRTA) problems require fast and\nefficient decision-making, which is often achieved using heuristics-aided\nmethods such as genetic algorithms, auction-based methods, and bipartite graph\nmatching methods. These methods often assume a form that lends better\nexplainability compared to an end-to-end (learnt) neural network based policy\nfor MRTA. However, deriving suitable heuristics can be tedious, risky and in\nsome cases impractical if problems are too complex. This raises the question:\ncan these heuristics be learned? To this end, this paper particularly develops\na Graph Reinforcement Learning (GRL) framework to learn the heuristics or\nincentives for a bipartite graph matching approach to MRTA. Specifically a\nCapsule Attention policy model is used to learn how to weight task\/robot\npairings (edges) in the bipartite graph that connects the set of tasks to the\nset of robots. The original capsule attention network architecture is\nfundamentally modified by adding encoding of robots' state graph, and two\nMultihead Attention based decoders whose output are used to construct a\nLogNormal distribution matrix from which positive bigraph weights can be drawn.\nThe performance of this new bigraph matching approach augmented with a\nGRL-derived incentive is found to be at par with the original bigraph matching\napproach that used expert-specified heuristics, with the former offering\nnotable robustness benefits. During training, the learned incentive policy is\nfound to get initially closer to the expert-specified incentive and then\nslightly deviate from its trend.","updated":1710186908000,"published":1710186908000,"authors":["Steve Paul","Nathan Maurer","Souma Chowdhury"],"comments":"This paper was accepted for presentation in proceedings of IEEE\n  International Conference on Robotics and Automation 2024","categories":["cs.AI","cs.MA"],"primary_category":"cs.AI","doi":null,"journal_ref":null,"peer_reviewed":true,"reader_id":"rid1","human_jargon_term":"bipartite graph matching approach","definition_text":"A bipartite graph matching approach is a method used to pair two different types of entities (such as tasks and robots) by connecting them in a graph where each connection, or edge, represents a potential pairing. This method helps in deciding the best way to assign each task to a robot so that the overall effectiveness or efficiency is maximized.","model":"gpt4_abstract","Accuracy":"accurate","Ranking":1,"Notes":""},"144":{"arxiv_id":"2403.07131v1","url":"http:\/\/arxiv.org\/abs\/2403.07131v1","title":"Bigraph Matching Weighted with Learnt Incentive Function for Multi-Robot\n  Task Allocation","summary":"Most real-world Multi-Robot Task Allocation (MRTA) problems require fast and\nefficient decision-making, which is often achieved using heuristics-aided\nmethods such as genetic algorithms, auction-based methods, and bipartite graph\nmatching methods. These methods often assume a form that lends better\nexplainability compared to an end-to-end (learnt) neural network based policy\nfor MRTA. However, deriving suitable heuristics can be tedious, risky and in\nsome cases impractical if problems are too complex. This raises the question:\ncan these heuristics be learned? To this end, this paper particularly develops\na Graph Reinforcement Learning (GRL) framework to learn the heuristics or\nincentives for a bipartite graph matching approach to MRTA. Specifically a\nCapsule Attention policy model is used to learn how to weight task\/robot\npairings (edges) in the bipartite graph that connects the set of tasks to the\nset of robots. The original capsule attention network architecture is\nfundamentally modified by adding encoding of robots' state graph, and two\nMultihead Attention based decoders whose output are used to construct a\nLogNormal distribution matrix from which positive bigraph weights can be drawn.\nThe performance of this new bigraph matching approach augmented with a\nGRL-derived incentive is found to be at par with the original bigraph matching\napproach that used expert-specified heuristics, with the former offering\nnotable robustness benefits. During training, the learned incentive policy is\nfound to get initially closer to the expert-specified incentive and then\nslightly deviate from its trend.","updated":1710186908000,"published":1710186908000,"authors":["Steve Paul","Nathan Maurer","Souma Chowdhury"],"comments":"This paper was accepted for presentation in proceedings of IEEE\n  International Conference on Robotics and Automation 2024","categories":["cs.AI","cs.MA"],"primary_category":"cs.AI","doi":null,"journal_ref":null,"peer_reviewed":true,"reader_id":"rid1","human_jargon_term":"bipartite graph matching methods","definition_text":"Bipartite graph matching methods are an approach used to pair two different types of entities (such as tasks and robots) by connecting them in a graph where each connection, or edge, links one entity from each type. This method helps to determine the best way to pair these entities based on certain criteria or rules.","model":"gpt4_abstract","Accuracy":"accurate","Ranking":2,"Notes":""},"145":{"arxiv_id":"2403.07131v1","url":"http:\/\/arxiv.org\/abs\/2403.07131v1","title":"Bigraph Matching Weighted with Learnt Incentive Function for Multi-Robot\n  Task Allocation","summary":"Most real-world Multi-Robot Task Allocation (MRTA) problems require fast and\nefficient decision-making, which is often achieved using heuristics-aided\nmethods such as genetic algorithms, auction-based methods, and bipartite graph\nmatching methods. These methods often assume a form that lends better\nexplainability compared to an end-to-end (learnt) neural network based policy\nfor MRTA. However, deriving suitable heuristics can be tedious, risky and in\nsome cases impractical if problems are too complex. This raises the question:\ncan these heuristics be learned? To this end, this paper particularly develops\na Graph Reinforcement Learning (GRL) framework to learn the heuristics or\nincentives for a bipartite graph matching approach to MRTA. Specifically a\nCapsule Attention policy model is used to learn how to weight task\/robot\npairings (edges) in the bipartite graph that connects the set of tasks to the\nset of robots. The original capsule attention network architecture is\nfundamentally modified by adding encoding of robots' state graph, and two\nMultihead Attention based decoders whose output are used to construct a\nLogNormal distribution matrix from which positive bigraph weights can be drawn.\nThe performance of this new bigraph matching approach augmented with a\nGRL-derived incentive is found to be at par with the original bigraph matching\napproach that used expert-specified heuristics, with the former offering\nnotable robustness benefits. During training, the learned incentive policy is\nfound to get initially closer to the expert-specified incentive and then\nslightly deviate from its trend.","updated":1710186908000,"published":1710186908000,"authors":["Steve Paul","Nathan Maurer","Souma Chowdhury"],"comments":"This paper was accepted for presentation in proceedings of IEEE\n  International Conference on Robotics and Automation 2024","categories":["cs.AI","cs.MA"],"primary_category":"cs.AI","doi":null,"journal_ref":null,"peer_reviewed":true,"reader_id":"rid1","human_jargon_term":"expert-specified heuristics","definition_text":"Expert-specified heuristics are rules or guidelines developed by specialists based on their knowledge and experience to help solve complex problems more quickly and effectively. These heuristics are used to guide decision-making processes, particularly in scenarios involving complicated calculations or where quick judgments are necessary.","model":"gpt4_abstract","Accuracy":"accurate","Ranking":0,"Notes":""},"146":{"arxiv_id":"2403.07131v1","url":"http:\/\/arxiv.org\/abs\/2403.07131v1","title":"Bigraph Matching Weighted with Learnt Incentive Function for Multi-Robot\n  Task Allocation","summary":"Most real-world Multi-Robot Task Allocation (MRTA) problems require fast and\nefficient decision-making, which is often achieved using heuristics-aided\nmethods such as genetic algorithms, auction-based methods, and bipartite graph\nmatching methods. These methods often assume a form that lends better\nexplainability compared to an end-to-end (learnt) neural network based policy\nfor MRTA. However, deriving suitable heuristics can be tedious, risky and in\nsome cases impractical if problems are too complex. This raises the question:\ncan these heuristics be learned? To this end, this paper particularly develops\na Graph Reinforcement Learning (GRL) framework to learn the heuristics or\nincentives for a bipartite graph matching approach to MRTA. Specifically a\nCapsule Attention policy model is used to learn how to weight task\/robot\npairings (edges) in the bipartite graph that connects the set of tasks to the\nset of robots. The original capsule attention network architecture is\nfundamentally modified by adding encoding of robots' state graph, and two\nMultihead Attention based decoders whose output are used to construct a\nLogNormal distribution matrix from which positive bigraph weights can be drawn.\nThe performance of this new bigraph matching approach augmented with a\nGRL-derived incentive is found to be at par with the original bigraph matching\napproach that used expert-specified heuristics, with the former offering\nnotable robustness benefits. During training, the learned incentive policy is\nfound to get initially closer to the expert-specified incentive and then\nslightly deviate from its trend.","updated":1710186908000,"published":1710186908000,"authors":["Steve Paul","Nathan Maurer","Souma Chowdhury"],"comments":"This paper was accepted for presentation in proceedings of IEEE\n  International Conference on Robotics and Automation 2024","categories":["cs.AI","cs.MA"],"primary_category":"cs.AI","doi":null,"journal_ref":null,"peer_reviewed":true,"reader_id":"rid1","human_jargon_term":"genetic algorithms","definition_text":"Genetic algorithms are a type of computer algorithm inspired by the process of natural selection, where solutions to problems evolve over time through processes resembling biological evolution, such as selection, crossover, and mutation. These algorithms repeatedly modify a population of individual solutions to produce new generations of solutions, aiming to find the best or most optimal solution to a problem.","model":"gpt4_abstract","Accuracy":"accurate","Ranking":0,"Notes":""},"147":{"arxiv_id":"2403.07131v1","url":"http:\/\/arxiv.org\/abs\/2403.07131v1","title":"Bigraph Matching Weighted with Learnt Incentive Function for Multi-Robot\n  Task Allocation","summary":"Most real-world Multi-Robot Task Allocation (MRTA) problems require fast and\nefficient decision-making, which is often achieved using heuristics-aided\nmethods such as genetic algorithms, auction-based methods, and bipartite graph\nmatching methods. These methods often assume a form that lends better\nexplainability compared to an end-to-end (learnt) neural network based policy\nfor MRTA. However, deriving suitable heuristics can be tedious, risky and in\nsome cases impractical if problems are too complex. This raises the question:\ncan these heuristics be learned? To this end, this paper particularly develops\na Graph Reinforcement Learning (GRL) framework to learn the heuristics or\nincentives for a bipartite graph matching approach to MRTA. Specifically a\nCapsule Attention policy model is used to learn how to weight task\/robot\npairings (edges) in the bipartite graph that connects the set of tasks to the\nset of robots. The original capsule attention network architecture is\nfundamentally modified by adding encoding of robots' state graph, and two\nMultihead Attention based decoders whose output are used to construct a\nLogNormal distribution matrix from which positive bigraph weights can be drawn.\nThe performance of this new bigraph matching approach augmented with a\nGRL-derived incentive is found to be at par with the original bigraph matching\napproach that used expert-specified heuristics, with the former offering\nnotable robustness benefits. During training, the learned incentive policy is\nfound to get initially closer to the expert-specified incentive and then\nslightly deviate from its trend.","updated":1710186908000,"published":1710186908000,"authors":["Steve Paul","Nathan Maurer","Souma Chowdhury"],"comments":"This paper was accepted for presentation in proceedings of IEEE\n  International Conference on Robotics and Automation 2024","categories":["cs.AI","cs.MA"],"primary_category":"cs.AI","doi":null,"journal_ref":null,"peer_reviewed":true,"reader_id":"rid1","human_jargon_term":"heuristics-aided\nmethods","definition_text":"Heuristics-aided methods are approaches that use simple rules or shortcuts to speed up problem-solving and decision-making processes. These methods help in handling complex problems more efficiently by approximating solutions rather than calculating exact answers, making them useful in situations where quick responses are necessary.","model":"gpt4_abstract","Accuracy":"accurate","Ranking":1,"Notes":""},"148":{"arxiv_id":"2403.07131v1","url":"http:\/\/arxiv.org\/abs\/2403.07131v1","title":"Bigraph Matching Weighted with Learnt Incentive Function for Multi-Robot\n  Task Allocation","summary":"Most real-world Multi-Robot Task Allocation (MRTA) problems require fast and\nefficient decision-making, which is often achieved using heuristics-aided\nmethods such as genetic algorithms, auction-based methods, and bipartite graph\nmatching methods. These methods often assume a form that lends better\nexplainability compared to an end-to-end (learnt) neural network based policy\nfor MRTA. However, deriving suitable heuristics can be tedious, risky and in\nsome cases impractical if problems are too complex. This raises the question:\ncan these heuristics be learned? To this end, this paper particularly develops\na Graph Reinforcement Learning (GRL) framework to learn the heuristics or\nincentives for a bipartite graph matching approach to MRTA. Specifically a\nCapsule Attention policy model is used to learn how to weight task\/robot\npairings (edges) in the bipartite graph that connects the set of tasks to the\nset of robots. The original capsule attention network architecture is\nfundamentally modified by adding encoding of robots' state graph, and two\nMultihead Attention based decoders whose output are used to construct a\nLogNormal distribution matrix from which positive bigraph weights can be drawn.\nThe performance of this new bigraph matching approach augmented with a\nGRL-derived incentive is found to be at par with the original bigraph matching\napproach that used expert-specified heuristics, with the former offering\nnotable robustness benefits. During training, the learned incentive policy is\nfound to get initially closer to the expert-specified incentive and then\nslightly deviate from its trend.","updated":1710186908000,"published":1710186908000,"authors":["Steve Paul","Nathan Maurer","Souma Chowdhury"],"comments":"This paper was accepted for presentation in proceedings of IEEE\n  International Conference on Robotics and Automation 2024","categories":["cs.AI","cs.MA"],"primary_category":"cs.AI","doi":null,"journal_ref":null,"peer_reviewed":true,"reader_id":"rid1","human_jargon_term":"neural network based policy","definition_text":"A neural network based policy refers to a set of rules or decision-making guidelines created using a system that mimics the human brain, which processes information and learns from it to optimize tasks or solve problems. This type of policy utilizes complex algorithms to analyze and react according to the data it is trained on, enabling it to make intelligent decisions almost automatically.","model":"gpt4_abstract","Accuracy":"accurate","Ranking":1,"Notes":""},"149":{"arxiv_id":"2403.07131v1","url":"http:\/\/arxiv.org\/abs\/2403.07131v1","title":"Bigraph Matching Weighted with Learnt Incentive Function for Multi-Robot\n  Task Allocation","summary":"Most real-world Multi-Robot Task Allocation (MRTA) problems require fast and\nefficient decision-making, which is often achieved using heuristics-aided\nmethods such as genetic algorithms, auction-based methods, and bipartite graph\nmatching methods. These methods often assume a form that lends better\nexplainability compared to an end-to-end (learnt) neural network based policy\nfor MRTA. However, deriving suitable heuristics can be tedious, risky and in\nsome cases impractical if problems are too complex. This raises the question:\ncan these heuristics be learned? To this end, this paper particularly develops\na Graph Reinforcement Learning (GRL) framework to learn the heuristics or\nincentives for a bipartite graph matching approach to MRTA. Specifically a\nCapsule Attention policy model is used to learn how to weight task\/robot\npairings (edges) in the bipartite graph that connects the set of tasks to the\nset of robots. The original capsule attention network architecture is\nfundamentally modified by adding encoding of robots' state graph, and two\nMultihead Attention based decoders whose output are used to construct a\nLogNormal distribution matrix from which positive bigraph weights can be drawn.\nThe performance of this new bigraph matching approach augmented with a\nGRL-derived incentive is found to be at par with the original bigraph matching\napproach that used expert-specified heuristics, with the former offering\nnotable robustness benefits. During training, the learned incentive policy is\nfound to get initially closer to the expert-specified incentive and then\nslightly deviate from its trend.","updated":1710186908000,"published":1710186908000,"authors":["Steve Paul","Nathan Maurer","Souma Chowdhury"],"comments":"This paper was accepted for presentation in proceedings of IEEE\n  International Conference on Robotics and Automation 2024","categories":["cs.AI","cs.MA"],"primary_category":"cs.AI","doi":null,"journal_ref":null,"peer_reviewed":true,"reader_id":"rid1","human_jargon_term":"original capsule attention network architecture","definition_text":"The original capsule attention network architecture is a design in computer models that helps determine how important various parts of data are relative to each other by processing them in small groups called \"capsules.\" This structure helps the model to focus on the most relevant information when making decisions or predictions.","model":"gpt4_abstract","Accuracy":"accurate","Ranking":1,"Notes":""},"150":{"arxiv_id":"2403.07131v1","url":"http:\/\/arxiv.org\/abs\/2403.07131v1","title":"Bigraph Matching Weighted with Learnt Incentive Function for Multi-Robot\n  Task Allocation","summary":"Most real-world Multi-Robot Task Allocation (MRTA) problems require fast and\nefficient decision-making, which is often achieved using heuristics-aided\nmethods such as genetic algorithms, auction-based methods, and bipartite graph\nmatching methods. These methods often assume a form that lends better\nexplainability compared to an end-to-end (learnt) neural network based policy\nfor MRTA. However, deriving suitable heuristics can be tedious, risky and in\nsome cases impractical if problems are too complex. This raises the question:\ncan these heuristics be learned? To this end, this paper particularly develops\na Graph Reinforcement Learning (GRL) framework to learn the heuristics or\nincentives for a bipartite graph matching approach to MRTA. Specifically a\nCapsule Attention policy model is used to learn how to weight task\/robot\npairings (edges) in the bipartite graph that connects the set of tasks to the\nset of robots. The original capsule attention network architecture is\nfundamentally modified by adding encoding of robots' state graph, and two\nMultihead Attention based decoders whose output are used to construct a\nLogNormal distribution matrix from which positive bigraph weights can be drawn.\nThe performance of this new bigraph matching approach augmented with a\nGRL-derived incentive is found to be at par with the original bigraph matching\napproach that used expert-specified heuristics, with the former offering\nnotable robustness benefits. During training, the learned incentive policy is\nfound to get initially closer to the expert-specified incentive and then\nslightly deviate from its trend.","updated":1710186908000,"published":1710186908000,"authors":["Steve Paul","Nathan Maurer","Souma Chowdhury"],"comments":"This paper was accepted for presentation in proceedings of IEEE\n  International Conference on Robotics and Automation 2024","categories":["cs.AI","cs.MA"],"primary_category":"cs.AI","doi":null,"journal_ref":null,"peer_reviewed":true,"reader_id":"rid1","human_jargon_term":"positive bigraph weights","definition_text":"Positive bigraph weights are numerical values assigned to the connections (edges) between tasks and robots in a graph structure, where these values are positive, indicating the strength or preference for linking specific tasks to specific robots. These weights help in deciding the most effective task assignment in multi-robot systems.","model":"gpt4_abstract","Accuracy":"accurate","Ranking":0,"Notes":""},"151":{"arxiv_id":"2403.05112v1","url":"http:\/\/arxiv.org\/abs\/2403.05112v1","title":"RLPeri: Accelerating Visual Perimetry Test with Reinforcement Learning\n  and Convolutional Feature Extraction","summary":"Visual perimetry is an important eye examination that helps detect vision\nproblems caused by ocular or neurological conditions. During the test, a\npatient's gaze is fixed at a specific location while light stimuli of varying\nintensities are presented in central and peripheral vision. Based on the\npatient's responses to the stimuli, the visual field mapping and sensitivity\nare determined. However, maintaining high levels of concentration throughout\nthe test can be challenging for patients, leading to increased examination\ntimes and decreased accuracy.\n  In this work, we present RLPeri, a reinforcement learning-based approach to\noptimize visual perimetry testing. By determining the optimal sequence of\nlocations and initial stimulus values, we aim to reduce the examination time\nwithout compromising accuracy. Additionally, we incorporate reward shaping\ntechniques to further improve the testing performance. To monitor the patient's\nresponses over time during testing, we represent the test's state as a pair of\n3D matrices. We apply two different convolutional kernels to extract spatial\nfeatures across locations as well as features across different stimulus values\nfor each location. Through experiments, we demonstrate that our approach\nresults in a 10-20% reduction in examination time while maintaining the\naccuracy as compared to state-of-the-art methods. With the presented approach,\nwe aim to make visual perimetry testing more efficient and patient-friendly,\nwhile still providing accurate results.","updated":1709882383000,"published":1709882383000,"authors":["Tanvi Verma","Linh Le Dinh","Nicholas Tan","Xinxing Xu","Chingyu Cheng","Yong Liu"],"comments":"Published at AAAI-24","categories":["cs.AI"],"primary_category":"cs.AI","doi":null,"journal_ref":"The 38th Annual AAAI Conference on Artificial Intelligence, 2024","peer_reviewed":true,"reader_id":"rid1","human_jargon_term":"RLPeri","definition_text":"RLPeri is a tool developed using reinforcement learning techniques to optimize the process of visual perimetry testing, which is used to assess a person's visual field. It aims to make these eye exams quicker and more accurate by determining the best order and intensity of visual cues to present during the test.","model":"gpt4_abstract","Accuracy":"accurate","Ranking":1,"Notes":""},"152":{"arxiv_id":"2403.05112v1","url":"http:\/\/arxiv.org\/abs\/2403.05112v1","title":"RLPeri: Accelerating Visual Perimetry Test with Reinforcement Learning\n  and Convolutional Feature Extraction","summary":"Visual perimetry is an important eye examination that helps detect vision\nproblems caused by ocular or neurological conditions. During the test, a\npatient's gaze is fixed at a specific location while light stimuli of varying\nintensities are presented in central and peripheral vision. Based on the\npatient's responses to the stimuli, the visual field mapping and sensitivity\nare determined. However, maintaining high levels of concentration throughout\nthe test can be challenging for patients, leading to increased examination\ntimes and decreased accuracy.\n  In this work, we present RLPeri, a reinforcement learning-based approach to\noptimize visual perimetry testing. By determining the optimal sequence of\nlocations and initial stimulus values, we aim to reduce the examination time\nwithout compromising accuracy. Additionally, we incorporate reward shaping\ntechniques to further improve the testing performance. To monitor the patient's\nresponses over time during testing, we represent the test's state as a pair of\n3D matrices. We apply two different convolutional kernels to extract spatial\nfeatures across locations as well as features across different stimulus values\nfor each location. Through experiments, we demonstrate that our approach\nresults in a 10-20% reduction in examination time while maintaining the\naccuracy as compared to state-of-the-art methods. With the presented approach,\nwe aim to make visual perimetry testing more efficient and patient-friendly,\nwhile still providing accurate results.","updated":1709882383000,"published":1709882383000,"authors":["Tanvi Verma","Linh Le Dinh","Nicholas Tan","Xinxing Xu","Chingyu Cheng","Yong Liu"],"comments":"Published at AAAI-24","categories":["cs.AI"],"primary_category":"cs.AI","doi":null,"journal_ref":"The 38th Annual AAAI Conference on Artificial Intelligence, 2024","peer_reviewed":true,"reader_id":"rid1","human_jargon_term":"Visual perimetry","definition_text":"Visual perimetry is a type of eye test that measures a person's field of vision, particularly the range and sensitivity of their sight, by having them respond to light signals that appear at different places and intensities while they look straight ahead. This test helps identify vision issues stemming from eye or brain problems.","model":"gpt4_abstract","Accuracy":"accurate","Ranking":0,"Notes":""},"153":{"arxiv_id":"2403.05112v1","url":"http:\/\/arxiv.org\/abs\/2403.05112v1","title":"RLPeri: Accelerating Visual Perimetry Test with Reinforcement Learning\n  and Convolutional Feature Extraction","summary":"Visual perimetry is an important eye examination that helps detect vision\nproblems caused by ocular or neurological conditions. During the test, a\npatient's gaze is fixed at a specific location while light stimuli of varying\nintensities are presented in central and peripheral vision. Based on the\npatient's responses to the stimuli, the visual field mapping and sensitivity\nare determined. However, maintaining high levels of concentration throughout\nthe test can be challenging for patients, leading to increased examination\ntimes and decreased accuracy.\n  In this work, we present RLPeri, a reinforcement learning-based approach to\noptimize visual perimetry testing. By determining the optimal sequence of\nlocations and initial stimulus values, we aim to reduce the examination time\nwithout compromising accuracy. Additionally, we incorporate reward shaping\ntechniques to further improve the testing performance. To monitor the patient's\nresponses over time during testing, we represent the test's state as a pair of\n3D matrices. We apply two different convolutional kernels to extract spatial\nfeatures across locations as well as features across different stimulus values\nfor each location. Through experiments, we demonstrate that our approach\nresults in a 10-20% reduction in examination time while maintaining the\naccuracy as compared to state-of-the-art methods. With the presented approach,\nwe aim to make visual perimetry testing more efficient and patient-friendly,\nwhile still providing accurate results.","updated":1709882383000,"published":1709882383000,"authors":["Tanvi Verma","Linh Le Dinh","Nicholas Tan","Xinxing Xu","Chingyu Cheng","Yong Liu"],"comments":"Published at AAAI-24","categories":["cs.AI"],"primary_category":"cs.AI","doi":null,"journal_ref":"The 38th Annual AAAI Conference on Artificial Intelligence, 2024","peer_reviewed":true,"reader_id":"rid1","human_jargon_term":"convolutional kernels","definition_text":"Convolutional kernels are small matrices used in image processing that slide over an image to transform its appearance by detecting specific features like edges or textures, which helps in analyzing the image more effectively. In the context of the visual perimetry test, these kernels help to analyze and interpret various aspects of the visual stimuli presented during the test.","model":"gpt4_abstract","Accuracy":"accurate","Ranking":0,"Notes":""},"154":{"arxiv_id":"2403.05112v1","url":"http:\/\/arxiv.org\/abs\/2403.05112v1","title":"RLPeri: Accelerating Visual Perimetry Test with Reinforcement Learning\n  and Convolutional Feature Extraction","summary":"Visual perimetry is an important eye examination that helps detect vision\nproblems caused by ocular or neurological conditions. During the test, a\npatient's gaze is fixed at a specific location while light stimuli of varying\nintensities are presented in central and peripheral vision. Based on the\npatient's responses to the stimuli, the visual field mapping and sensitivity\nare determined. However, maintaining high levels of concentration throughout\nthe test can be challenging for patients, leading to increased examination\ntimes and decreased accuracy.\n  In this work, we present RLPeri, a reinforcement learning-based approach to\noptimize visual perimetry testing. By determining the optimal sequence of\nlocations and initial stimulus values, we aim to reduce the examination time\nwithout compromising accuracy. Additionally, we incorporate reward shaping\ntechniques to further improve the testing performance. To monitor the patient's\nresponses over time during testing, we represent the test's state as a pair of\n3D matrices. We apply two different convolutional kernels to extract spatial\nfeatures across locations as well as features across different stimulus values\nfor each location. Through experiments, we demonstrate that our approach\nresults in a 10-20% reduction in examination time while maintaining the\naccuracy as compared to state-of-the-art methods. With the presented approach,\nwe aim to make visual perimetry testing more efficient and patient-friendly,\nwhile still providing accurate results.","updated":1709882383000,"published":1709882383000,"authors":["Tanvi Verma","Linh Le Dinh","Nicholas Tan","Xinxing Xu","Chingyu Cheng","Yong Liu"],"comments":"Published at AAAI-24","categories":["cs.AI"],"primary_category":"cs.AI","doi":null,"journal_ref":"The 38th Annual AAAI Conference on Artificial Intelligence, 2024","peer_reviewed":true,"reader_id":"rid1","human_jargon_term":"ocular or neurological conditions","definition_text":"Ocular or neurological conditions refer to health issues that affect either the eyes or the nervous system, respectively. These conditions can influence how well someone can see or process visual information, which visual perimetry tests aim to assess.","model":"gpt4_abstract","Accuracy":"accurate","Ranking":0,"Notes":""},"155":{"arxiv_id":"2403.05112v1","url":"http:\/\/arxiv.org\/abs\/2403.05112v1","title":"RLPeri: Accelerating Visual Perimetry Test with Reinforcement Learning\n  and Convolutional Feature Extraction","summary":"Visual perimetry is an important eye examination that helps detect vision\nproblems caused by ocular or neurological conditions. During the test, a\npatient's gaze is fixed at a specific location while light stimuli of varying\nintensities are presented in central and peripheral vision. Based on the\npatient's responses to the stimuli, the visual field mapping and sensitivity\nare determined. However, maintaining high levels of concentration throughout\nthe test can be challenging for patients, leading to increased examination\ntimes and decreased accuracy.\n  In this work, we present RLPeri, a reinforcement learning-based approach to\noptimize visual perimetry testing. By determining the optimal sequence of\nlocations and initial stimulus values, we aim to reduce the examination time\nwithout compromising accuracy. Additionally, we incorporate reward shaping\ntechniques to further improve the testing performance. To monitor the patient's\nresponses over time during testing, we represent the test's state as a pair of\n3D matrices. We apply two different convolutional kernels to extract spatial\nfeatures across locations as well as features across different stimulus values\nfor each location. Through experiments, we demonstrate that our approach\nresults in a 10-20% reduction in examination time while maintaining the\naccuracy as compared to state-of-the-art methods. With the presented approach,\nwe aim to make visual perimetry testing more efficient and patient-friendly,\nwhile still providing accurate results.","updated":1709882383000,"published":1709882383000,"authors":["Tanvi Verma","Linh Le Dinh","Nicholas Tan","Xinxing Xu","Chingyu Cheng","Yong Liu"],"comments":"Published at AAAI-24","categories":["cs.AI"],"primary_category":"cs.AI","doi":null,"journal_ref":"The 38th Annual AAAI Conference on Artificial Intelligence, 2024","peer_reviewed":true,"reader_id":"rid1","human_jargon_term":"spatial features","definition_text":"Spatial features refer to characteristics or patterns within a space that can be observed and quantified, such as the layout, arrangement, and distribution of elements within a visual field or an image. These features help in understanding the structure and organization of the space or image being analyzed.","model":"gpt4_abstract","Accuracy":"accurate","Ranking":0,"Notes":""},"156":{"arxiv_id":"2403.00431v1","url":"http:\/\/arxiv.org\/abs\/2403.00431v1","title":"Robotic Process Automation as a Driver for Sustainable Innovation and\n  Entrepreneurship","summary":"Technological innovation plays a crucial role in driving economic growth and\ndevelopment. In this study, we investigate the extent to which technological\ninnovation contributes to a more sustainable future and fosters\nentrepreneurship. To examine this, we focus on robotic process automation (RPA)\nhighly relevant technology. We conducted a comprehensive analysis by examining\nthe usage of RPA and its impact on environmental, social, and governance (ESG)\nfactors. Our research involved gathering data from the 300 largest companies in\nterms of market capitalization. We assessed whether these companies used RPA\nand obtained their corresponding ESG ratings. To investigate the relationship\nbetween RPA and ESG, we employed a contingency table analysis, which involved\ncategorizing the data based on ESG ratings. We further used Pearson's\nChi-square Test of Independence to assess the impact of RPA on ESG. Our\nfindings revealed a statistically significant association between RPA and ESG\nratings, indicating their interconnection. The calculated value for Pearson's\nChi-square Test of Independence was 6.54, with a corresponding p-value of\n0.0381. This indicates that at a significance level of five percent, the RPA\nand ESG variables depend on each other. These results suggest that RPA,\nrepresentative of modern technologies, likely influences the achievement of a\nsustainable future and the promotion of entrepreneurship. In conclusion, our\nstudy provides empirical evidence supporting the notion that technological\ninnovations such as RPA have the potential to positively shape sustainability\nefforts and entrepreneurial endeavours.","updated":1709289168000,"published":1709289168000,"authors":["Petr Prucha"],"comments":"XB-CON International Conference 2023, Zelezna Ruda, Czechia","categories":["cs.CY"],"primary_category":"cs.CY","doi":null,"journal_ref":null,"peer_reviewed":true,"reader_id":"rid1","human_jargon_term":"Pearson's Chi-square Test of Independence","definition_text":"The Pearson's Chi-square Test of Independence is a statistical tool used to determine whether there is a significant association between two categorical variables. It helps to see if changes in one variable are related to changes in another, or if they are independent of each other.","model":"gpt4_abstract","Accuracy":"accurate","Ranking":0,"Notes":""},"157":{"arxiv_id":"2403.00431v1","url":"http:\/\/arxiv.org\/abs\/2403.00431v1","title":"Robotic Process Automation as a Driver for Sustainable Innovation and\n  Entrepreneurship","summary":"Technological innovation plays a crucial role in driving economic growth and\ndevelopment. In this study, we investigate the extent to which technological\ninnovation contributes to a more sustainable future and fosters\nentrepreneurship. To examine this, we focus on robotic process automation (RPA)\nhighly relevant technology. We conducted a comprehensive analysis by examining\nthe usage of RPA and its impact on environmental, social, and governance (ESG)\nfactors. Our research involved gathering data from the 300 largest companies in\nterms of market capitalization. We assessed whether these companies used RPA\nand obtained their corresponding ESG ratings. To investigate the relationship\nbetween RPA and ESG, we employed a contingency table analysis, which involved\ncategorizing the data based on ESG ratings. We further used Pearson's\nChi-square Test of Independence to assess the impact of RPA on ESG. Our\nfindings revealed a statistically significant association between RPA and ESG\nratings, indicating their interconnection. The calculated value for Pearson's\nChi-square Test of Independence was 6.54, with a corresponding p-value of\n0.0381. This indicates that at a significance level of five percent, the RPA\nand ESG variables depend on each other. These results suggest that RPA,\nrepresentative of modern technologies, likely influences the achievement of a\nsustainable future and the promotion of entrepreneurship. In conclusion, our\nstudy provides empirical evidence supporting the notion that technological\ninnovations such as RPA have the potential to positively shape sustainability\nefforts and entrepreneurial endeavours.","updated":1709289168000,"published":1709289168000,"authors":["Petr Prucha"],"comments":"XB-CON International Conference 2023, Zelezna Ruda, Czechia","categories":["cs.CY"],"primary_category":"cs.CY","doi":null,"journal_ref":null,"peer_reviewed":true,"reader_id":"rid1","human_jargon_term":"robotic process automation (RPA)","definition_text":"Robotic process automation (RPA) is a technology that uses software robots to automate repetitive and routine tasks that are typically done by humans. This allows businesses to streamline operations, reduce errors, and save time.","model":"gpt4_abstract","Accuracy":"accurate","Ranking":0,"Notes":""},"158":{"arxiv_id":"2403.11952v1","url":"http:\/\/arxiv.org\/abs\/2403.11952v1","title":"Exploring Estonia's Open Government Data Development as a Journey\n  towards Excellence: Unveiling the Progress of Local Governments in Open Data\n  Provision","summary":"Estonia has a global reputation of a digital state or e-country. However,\ndespite the success in digital governance, the country has faced challenges in\nthe realm of Open Government Data (OGD) area, with significant advancements in\nits OGD ecosystem, as reflected in various open data rankings from 2020 and\nonwards, in the recent years being recognized among trend-setters. This paper\naims to explore the evolution and positioning of Estonia's OGD development,\nencompassing national and local levels, through an integrated analysis of\nvarious indices, primary data from the Estonian OGD portal, and a thorough\nliterature review. The research shows that Estonia has made progress in the\nnational level open data ecosystem, primarily due to improvements in the OGD\nportal usability and legislation amendments. However, the local level is not as\ndeveloped, with local governments lagging behind in OGD provision. The\nliterature review highlights the lack of previous research focusing on Estonian\nand European local open data, emphasizing the need for future studies to\nexplore the barriers and enablers of municipal OGD. This study contributes to a\nnuanced understanding of Estonia's dynamic journey in the OGD landscape,\nshedding light on both achievements and areas warranting further attention for\nestablishing a sustainable open data ecosystem.","updated":1710780605000,"published":1710780605000,"authors":["Katrin Rajam\u00e4e-Soosaar","Anastasija Nikiforova"],"comments":"This paper has been accepted for publication in Proceedings of the\n  25th Annual International Conference on Digital Government Research and this\n  is a pre-print version of the manuscript. It is posted here for your personal\n  use. Not for redistribution","categories":["cs.CY","cs.CE","cs.DB","cs.SE","cs.SI"],"primary_category":"cs.CY","doi":null,"journal_ref":null,"peer_reviewed":true,"reader_id":"rid1","human_jargon_term":"Open Government Data (OGD)","definition_text":"Open Government Data (OGD) refers to the practice of government agencies making various datasets available to the public in a way that is easily accessible and usable, with the intention of increasing transparency, improving governance, and encouraging civic engagement and innovation.","model":"gpt4_abstract","Accuracy":"accurate","Ranking":0,"Notes":""},"159":{"arxiv_id":"2403.08451v1","url":"http:\/\/arxiv.org\/abs\/2403.08451v1","title":"An Integrated Usability Framework for Evaluating Open Government Data\n  Portals: Comparative Analysis of EU and GCC Countries","summary":"This study explores the critical role of open government data (OGD) portals\nin fostering transparency and collaboration between diverse stakeholders.\nRecognizing the challenges of usability, communication with diverse\npopulations, and strategic value creation, this paper develops an integrated\nframework for evaluating OGD portal effectiveness that accommodates user\ndiversity (regardless of their data literacy and language), evaluates\ncollaboration and participation, and the ability of users to explore and\nunderstand the data provided through them. The framework is validated by\napplying it to 33 national portals across European Union and Gulf Cooperation\nCouncil (GCC) countries, as a result of which we rank OGD portals, identify\nsome good practices that lower-performing portals can learn from, and common\nshortcomings. Notably, the study unveils the competitive and innovative nature\nof GCC OGD portals, pinpointing specific improvement areas such as multilingual\nsupport and data understandability. The findings underscore the growing trend\nof exposing data quality metrics and advocate for enhanced two-way\ncommunication channels between users and portal representatives. Overall, the\nstudy contributes to accelerating the development of user-friendly,\ncollaborative, and sustainable OGD portals while addressing gaps identified in\nprevious research.","updated":1710331602000,"published":1710331602000,"authors":["Fillip Molodtsov","Anastasija Nikiforova"],"comments":"This paper has been accepted for publication in Proceedings of the\n  25th Annual International Conference on Digital Government Research and this\n  is a preprint version of the manuscript","categories":["cs.CY","cs.SE"],"primary_category":"cs.CY","doi":null,"journal_ref":null,"peer_reviewed":true,"reader_id":"rid1","human_jargon_term":"European Union and Gulf Cooperation Council (GCC) countries","definition_text":"The European Union (EU) refers to a political and economic union of several European countries that have agreed to have standardized laws and policies to facilitate trade and cooperation among them. The Gulf Cooperation Council (GCC) is a regional intergovernmental political and economic union consisting of Arab states around the Persian Gulf, including countries like Saudi Arabia, Kuwait, the UAE, Qatar, Bahrain, and Oman.","model":"gpt4_abstract","Accuracy":"accurate","Ranking":1,"Notes":""},"160":{"arxiv_id":"2403.08451v1","url":"http:\/\/arxiv.org\/abs\/2403.08451v1","title":"An Integrated Usability Framework for Evaluating Open Government Data\n  Portals: Comparative Analysis of EU and GCC Countries","summary":"This study explores the critical role of open government data (OGD) portals\nin fostering transparency and collaboration between diverse stakeholders.\nRecognizing the challenges of usability, communication with diverse\npopulations, and strategic value creation, this paper develops an integrated\nframework for evaluating OGD portal effectiveness that accommodates user\ndiversity (regardless of their data literacy and language), evaluates\ncollaboration and participation, and the ability of users to explore and\nunderstand the data provided through them. The framework is validated by\napplying it to 33 national portals across European Union and Gulf Cooperation\nCouncil (GCC) countries, as a result of which we rank OGD portals, identify\nsome good practices that lower-performing portals can learn from, and common\nshortcomings. Notably, the study unveils the competitive and innovative nature\nof GCC OGD portals, pinpointing specific improvement areas such as multilingual\nsupport and data understandability. The findings underscore the growing trend\nof exposing data quality metrics and advocate for enhanced two-way\ncommunication channels between users and portal representatives. Overall, the\nstudy contributes to accelerating the development of user-friendly,\ncollaborative, and sustainable OGD portals while addressing gaps identified in\nprevious research.","updated":1710331602000,"published":1710331602000,"authors":["Fillip Molodtsov","Anastasija Nikiforova"],"comments":"This paper has been accepted for publication in Proceedings of the\n  25th Annual International Conference on Digital Government Research and this\n  is a preprint version of the manuscript","categories":["cs.CY","cs.SE"],"primary_category":"cs.CY","doi":null,"journal_ref":null,"peer_reviewed":true,"reader_id":"rid1","human_jargon_term":"open government data (OGD)","definition_text":"Open government data (OGD) refers to the practice of government agencies making data freely available to the public in a way that is easy for people to access and use. This type of data is often shared through online platforms or portals and is intended to increase transparency, improve public services, and encourage collaboration between the government and its citizens.","model":"gpt4_abstract","Accuracy":"accurate","Ranking":0,"Notes":""},"161":{"arxiv_id":"2403.14686v1","url":"http:\/\/arxiv.org\/abs\/2403.14686v1","title":"Evaluating Pedagogical Incentives in Undergraduate Computing: A Mixed\n  Methods Approach Using Learning Analytics","summary":"In the context of higher education's evolving dynamics post-COVID-19, this\npaper assesses the impact of new pedagogical incentives implemented in a\nfirst-year undergraduate computing module at University College London. We\nemploy a mixed methods approach, combining learning analytics with qualitative\ndata, to evaluate the effectiveness of these incentives on increasing student\nengagement.\n  A longitudinal overview of resource interactions is mapped through Bayesian\nnetwork analysis of Moodle activity logs from 204 students. This analysis\nidentifies early resource engagement as a predictive indicator of continued\nengagement while also suggesting that the new incentives disproportionately\nbenefit highly engaged students. Focus group discussions complement this\nanalysis, providing insights into student perceptions of the pedagogical\nchanges and the module design. These qualitative findings underscore the\nchallenge of sustaining engagement through the new incentives and highlight the\nimportance of communication in blended learning environments.\n  Our paper introduces an interpretable and actionable model for student\nengagement, which integrates objective, data-driven analysis with students'\nperspectives. This model provides educators with a tool to evaluate and improve\ninstructional strategies. By demonstrating the effectiveness of our mixed\nmethods approach in capturing the intricacies of student behaviour in digital\nlearning environments, we underscore the model's potential to improve online\npedagogical practices across diverse educational settings.","updated":1710347978000,"published":1710347978000,"authors":["Laura J. Johnston","Takoua Jendoubi"],"comments":"5 pages, 1 figure. Accepted by IEEE Global Engineering Education\n  Conference 2024","categories":["cs.CY"],"primary_category":"cs.CY","doi":null,"journal_ref":null,"peer_reviewed":true,"reader_id":"rid1","human_jargon_term":"Bayesian network analysis","definition_text":"Bayesian network analysis is a statistical method that uses a network of interconnected nodes, representing different variables, to model and analyze the relationships and dependencies among these variables. This approach helps in predicting outcomes based on the connections and influence of various factors within the network.","model":"gpt4_abstract","Accuracy":"accurate","Ranking":0,"Notes":""},"162":{"arxiv_id":"2403.14686v1","url":"http:\/\/arxiv.org\/abs\/2403.14686v1","title":"Evaluating Pedagogical Incentives in Undergraduate Computing: A Mixed\n  Methods Approach Using Learning Analytics","summary":"In the context of higher education's evolving dynamics post-COVID-19, this\npaper assesses the impact of new pedagogical incentives implemented in a\nfirst-year undergraduate computing module at University College London. We\nemploy a mixed methods approach, combining learning analytics with qualitative\ndata, to evaluate the effectiveness of these incentives on increasing student\nengagement.\n  A longitudinal overview of resource interactions is mapped through Bayesian\nnetwork analysis of Moodle activity logs from 204 students. This analysis\nidentifies early resource engagement as a predictive indicator of continued\nengagement while also suggesting that the new incentives disproportionately\nbenefit highly engaged students. Focus group discussions complement this\nanalysis, providing insights into student perceptions of the pedagogical\nchanges and the module design. These qualitative findings underscore the\nchallenge of sustaining engagement through the new incentives and highlight the\nimportance of communication in blended learning environments.\n  Our paper introduces an interpretable and actionable model for student\nengagement, which integrates objective, data-driven analysis with students'\nperspectives. This model provides educators with a tool to evaluate and improve\ninstructional strategies. By demonstrating the effectiveness of our mixed\nmethods approach in capturing the intricacies of student behaviour in digital\nlearning environments, we underscore the model's potential to improve online\npedagogical practices across diverse educational settings.","updated":1710347978000,"published":1710347978000,"authors":["Laura J. Johnston","Takoua Jendoubi"],"comments":"5 pages, 1 figure. Accepted by IEEE Global Engineering Education\n  Conference 2024","categories":["cs.CY"],"primary_category":"cs.CY","doi":null,"journal_ref":null,"peer_reviewed":true,"reader_id":"rid1","human_jargon_term":"Moodle activity logs","definition_text":"Moodle activity logs are records of user actions, such as accessing resources or submitting assignments, within Moodle, an online platform used by educational institutions to manage course content and facilitate learning. These logs help track how students interact with different elements of their courses.","model":"gpt4_abstract","Accuracy":"accurate","Ranking":0,"Notes":""},"163":{"arxiv_id":"2403.14686v1","url":"http:\/\/arxiv.org\/abs\/2403.14686v1","title":"Evaluating Pedagogical Incentives in Undergraduate Computing: A Mixed\n  Methods Approach Using Learning Analytics","summary":"In the context of higher education's evolving dynamics post-COVID-19, this\npaper assesses the impact of new pedagogical incentives implemented in a\nfirst-year undergraduate computing module at University College London. We\nemploy a mixed methods approach, combining learning analytics with qualitative\ndata, to evaluate the effectiveness of these incentives on increasing student\nengagement.\n  A longitudinal overview of resource interactions is mapped through Bayesian\nnetwork analysis of Moodle activity logs from 204 students. This analysis\nidentifies early resource engagement as a predictive indicator of continued\nengagement while also suggesting that the new incentives disproportionately\nbenefit highly engaged students. Focus group discussions complement this\nanalysis, providing insights into student perceptions of the pedagogical\nchanges and the module design. These qualitative findings underscore the\nchallenge of sustaining engagement through the new incentives and highlight the\nimportance of communication in blended learning environments.\n  Our paper introduces an interpretable and actionable model for student\nengagement, which integrates objective, data-driven analysis with students'\nperspectives. This model provides educators with a tool to evaluate and improve\ninstructional strategies. By demonstrating the effectiveness of our mixed\nmethods approach in capturing the intricacies of student behaviour in digital\nlearning environments, we underscore the model's potential to improve online\npedagogical practices across diverse educational settings.","updated":1710347978000,"published":1710347978000,"authors":["Laura J. Johnston","Takoua Jendoubi"],"comments":"5 pages, 1 figure. Accepted by IEEE Global Engineering Education\n  Conference 2024","categories":["cs.CY"],"primary_category":"cs.CY","doi":null,"journal_ref":null,"peer_reviewed":true,"reader_id":"rid1","human_jargon_term":"pedagogical","definition_text":"Pedagogical refers to the methods and practices of teaching and education. It involves the strategies and techniques used by teachers to facilitate learning and improve student engagement and understanding.","model":"gpt4_abstract","Accuracy":"accurate","Ranking":0,"Notes":""},"164":{"arxiv_id":"2403.07082v1","url":"http:\/\/arxiv.org\/abs\/2403.07082v1","title":"Exploring the Impact of ChatGPT on Student Interactions in\n  Computer-Supported Collaborative Learning","summary":"The growing popularity of generative AI, particularly ChatGPT, has sparked\nboth enthusiasm and caution among practitioners and researchers in education.\nTo effectively harness the full potential of ChatGPT in educational contexts,\nit is crucial to analyze its impact and suitability for different educational\npurposes. This paper takes an initial step in exploring the applicability of\nChatGPT in a computer-supported collaborative learning (CSCL) environment.\nUsing statistical analysis, we validate the shifts in student interactions\nduring an asynchronous group brainstorming session by introducing ChatGPT as an\ninstantaneous question-answering agent.","updated":1710181098000,"published":1710181098000,"authors":["Han Kyul Kim","Shriniwas Nayak","Aleyeh Roknaldin","Xiaoci Zhang","Marlon Twyman","Stephen Lu"],"comments":"AAAI2024 Workshop on AI for Education (AI4ED)","categories":["cs.CY"],"primary_category":"cs.CY","doi":null,"journal_ref":null,"peer_reviewed":true,"reader_id":"rid1","human_jargon_term":"(CSCL) environment","definition_text":"A computer-supported collaborative learning (CSCL) environment is a setting where technology is used to help groups of students work together and learn from each either through shared activities and discussions, often facilitated by digital tools and platforms.","model":"gpt4_abstract","Accuracy":"accurate","Ranking":0,"Notes":""},"165":{"arxiv_id":"2403.07082v1","url":"http:\/\/arxiv.org\/abs\/2403.07082v1","title":"Exploring the Impact of ChatGPT on Student Interactions in\n  Computer-Supported Collaborative Learning","summary":"The growing popularity of generative AI, particularly ChatGPT, has sparked\nboth enthusiasm and caution among practitioners and researchers in education.\nTo effectively harness the full potential of ChatGPT in educational contexts,\nit is crucial to analyze its impact and suitability for different educational\npurposes. This paper takes an initial step in exploring the applicability of\nChatGPT in a computer-supported collaborative learning (CSCL) environment.\nUsing statistical analysis, we validate the shifts in student interactions\nduring an asynchronous group brainstorming session by introducing ChatGPT as an\ninstantaneous question-answering agent.","updated":1710181098000,"published":1710181098000,"authors":["Han Kyul Kim","Shriniwas Nayak","Aleyeh Roknaldin","Xiaoci Zhang","Marlon Twyman","Stephen Lu"],"comments":"AAAI2024 Workshop on AI for Education (AI4ED)","categories":["cs.CY"],"primary_category":"cs.CY","doi":null,"journal_ref":null,"peer_reviewed":true,"reader_id":"rid1","human_jargon_term":"asynchronous group brainstorming session","definition_text":"An asynchronous group brainstorming session is a collaborative activity where participants contribute their ideas and thoughts at different times rather than interacting simultaneously. This allows each participant to reflect and respond when it is most convenient for them, rather than needing everyone to be available at the same time.","model":"gpt4_abstract","Accuracy":"accurate","Ranking":0,"Notes":""},"166":{"arxiv_id":"2401.09210v2","url":"http:\/\/arxiv.org\/abs\/2401.09210v2","title":"Narratives of Collective Action in YouTube's Discourse on Veganism","summary":"Narratives can be powerful tools for inspiring action on pressing societal\nissues such as climate change. While social science theories offer frameworks\nfor understanding the narratives that arise within collective movements, these\nare rarely applied to the vast data available from social media platforms,\nwhich play a significant role in shaping public opinion and mobilizing\ncollective action. This gap in the empirical evaluation of online narratives\nlimits our understanding of their relationship with public response. In this\nstudy, we focus on plant-based diets as a form of pro-environmental action and\nemploy natural language processing to operationalize a theoretical framework of\nmoral narratives specific to the vegan movement. We apply this framework to\nnarratives found in YouTube videos promoting environmental initiatives such as\nVeganuary, Meatless March, and No Meat May. Our analysis reveals that several\nnarrative types, as defined by the theory, are empirically present in the data.\nTo identify narratives with the potential to elicit positive public engagement,\nwe used text processing to estimate the proportion of comments supporting\ncollective action across narrative types. Video narratives advocating social\nfight, whether through protest or through efforts to convert others to the\ncause, are associated with a stronger sense of collective action in the\nrespective comments. These narrative types also demonstrate increased semantic\ncoherence and alignment between the message and public response, markers\ntypically associated with successful collective action. Our work offers new\ninsights into the complex factors that influence the emergence of collective\naction, thereby informing the development of effective communication strategies\nwithin social movements.","updated":1711625999000,"published":1705499076000,"authors":["Arianna Pera","Luca Maria Aiello"],"comments":"15 pages, 7 figures, 7 tables. Accepted at ICWSM 2024","categories":["cs.CY","physics.soc-ph"],"primary_category":"cs.CY","doi":null,"journal_ref":null,"peer_reviewed":true,"reader_id":"rid1","human_jargon_term":"semantic\ncoherence","definition_text":"Semantic coherence refers to the extent to which ideas in a text logically connect and make sense together, forming a clear and consistent message. It ensures that the text flows smoothly and its various parts contribute to an overall understanding or theme.","model":"gpt4_abstract","Accuracy":"accurate","Ranking":2,"Notes":""},"167":{"arxiv_id":"2310.06155v3","url":"http:\/\/arxiv.org\/abs\/2310.06155v3","title":"CoQuest: Exploring Research Question Co-Creation with an LLM-based Agent","summary":"Developing novel research questions (RQs) often requires extensive literature\nreviews, especially in interdisciplinary fields. To support RQ development\nthrough human-AI co-creation, we leveraged Large Language Models (LLMs) to\nbuild an LLM-based agent system named CoQuest. We conducted an experiment with\n20 HCI researchers to examine the impact of two interaction designs:\nbreadth-first and depth-first RQ generation. The findings revealed that\nparticipants perceived the breadth-first approach as more creative and\ntrustworthy upon task completion. Conversely, during the task, participants\nconsidered the depth-first generated RQs as more creative. Additionally, we\ndiscovered that AI processing delays allowed users to reflect on multiple RQs\nsimultaneously, leading to a higher quantity of generated RQs and an enhanced\nsense of control. Our work makes both theoretical and practical contributions\nby proposing and evaluating a mental model for human-AI co-creation of RQs. We\nalso address potential ethical issues, such as biases and over-reliance on AI,\nadvocating for using the system to improve human research creativity rather\nthan automating scientific inquiry.","updated":1710967383000,"published":1696885527000,"authors":["Yiren Liu","Si Chen","Haocong Cheng","Mengxia Yu","Xiao Ran","Andrew Mo","Yiliu Tang","Yun Huang"],"comments":"Accepted to SIGCHI 2024","categories":["cs.HC","cs.CE"],"primary_category":"cs.HC","doi":null,"journal_ref":null,"peer_reviewed":true,"reader_id":"rid1","human_jargon_term":"breadth-first and depth-first RQ generation","definition_text":"Breadth-first and depth-first RQ generation are two methods used in developing research questions. In the breadth-first approach, a wide range of questions are explored broadly before narrowing down to specifics, whereas in depth-first, the focus starts deep on a limited set of questions before expanding to others.","model":"gpt4_abstract","Accuracy":"accurate","Ranking":0,"Notes":""},"168":{"arxiv_id":"2310.06155v3","url":"http:\/\/arxiv.org\/abs\/2310.06155v3","title":"CoQuest: Exploring Research Question Co-Creation with an LLM-based Agent","summary":"Developing novel research questions (RQs) often requires extensive literature\nreviews, especially in interdisciplinary fields. To support RQ development\nthrough human-AI co-creation, we leveraged Large Language Models (LLMs) to\nbuild an LLM-based agent system named CoQuest. We conducted an experiment with\n20 HCI researchers to examine the impact of two interaction designs:\nbreadth-first and depth-first RQ generation. The findings revealed that\nparticipants perceived the breadth-first approach as more creative and\ntrustworthy upon task completion. Conversely, during the task, participants\nconsidered the depth-first generated RQs as more creative. Additionally, we\ndiscovered that AI processing delays allowed users to reflect on multiple RQs\nsimultaneously, leading to a higher quantity of generated RQs and an enhanced\nsense of control. Our work makes both theoretical and practical contributions\nby proposing and evaluating a mental model for human-AI co-creation of RQs. We\nalso address potential ethical issues, such as biases and over-reliance on AI,\nadvocating for using the system to improve human research creativity rather\nthan automating scientific inquiry.","updated":1710967383000,"published":1696885527000,"authors":["Yiren Liu","Si Chen","Haocong Cheng","Mengxia Yu","Xiao Ran","Andrew Mo","Yiliu Tang","Yun Huang"],"comments":"Accepted to SIGCHI 2024","categories":["cs.HC","cs.CE"],"primary_category":"cs.HC","doi":null,"journal_ref":null,"peer_reviewed":true,"reader_id":"rid1","human_jargon_term":"research questions","definition_text":"Research questions are specific queries that researchers aim to answer through their investigations and studies. These questions guide the focus and direction of the research, helping to clarify what the researcher intends to examine or discover.","model":"gpt4_abstract","Accuracy":"accurate","Ranking":0,"Notes":""},"169":{"arxiv_id":"2403.01783v1","url":"http:\/\/arxiv.org\/abs\/2403.01783v1","title":"Towards A Diffractive Analysis of Prompt-Based Generative AI","summary":"Recent developments in prompt-based generative AI has given rise to discourse\nsurrounding the perceived ethical concerns, economic implications, and\nconsequences for the future of cultural production. As generative imagery\nbecomes pervasive in mainstream society, dominated primarily by emerging\nindustry leaders, we encourage that the role of the CHI community be one of\ninquiry; to investigate the numerous ways in which generative AI has the\npotential to, and already is, augmenting human creativity. In this paper, we\nconducted a diffractive analysis exploring the potential role of prompt-based\ninterfaces in artists' creative practice. Over a two week period, seven visual\nartists were given access to a personalised instance of Stable Diffusion,\nfine-tuned on a dataset of their work. In the following diffractive analysis,\nwe identified two dominant modes adopted by participants, AI for ideation, and\nAI for production. We furthermore present a number of ethical design\nconsiderations for the future development of generative AI interfaces.","updated":1709537029000,"published":1709537029000,"authors":["Nina Rajcic","Maria Teresa Llano","Jon McCormack"],"comments":"Preprint of paper accepted for CHI 2024","categories":["cs.HC","J.5; H.1.2; H.5"],"primary_category":"cs.HC","doi":"10.1145\/3613904.3641971","journal_ref":null,"peer_reviewed":true,"reader_id":"rid1","human_jargon_term":"Stable Diffusion","definition_text":"Stable Diffusion is a type of generative AI technology that assists artists in creating images by using their input, or \"prompts,\" to generate new visual content that reflects the artist's own style. This tool uses a customized AI model, which has been trained specifically with a dataset of the artist\u2019s previous artwork to ensure the new creations are aligned with their unique artistic voice.","model":"gpt4_abstract","Accuracy":"accurate","Ranking":2,"Notes":""},"170":{"arxiv_id":"2403.01783v1","url":"http:\/\/arxiv.org\/abs\/2403.01783v1","title":"Towards A Diffractive Analysis of Prompt-Based Generative AI","summary":"Recent developments in prompt-based generative AI has given rise to discourse\nsurrounding the perceived ethical concerns, economic implications, and\nconsequences for the future of cultural production. As generative imagery\nbecomes pervasive in mainstream society, dominated primarily by emerging\nindustry leaders, we encourage that the role of the CHI community be one of\ninquiry; to investigate the numerous ways in which generative AI has the\npotential to, and already is, augmenting human creativity. In this paper, we\nconducted a diffractive analysis exploring the potential role of prompt-based\ninterfaces in artists' creative practice. Over a two week period, seven visual\nartists were given access to a personalised instance of Stable Diffusion,\nfine-tuned on a dataset of their work. In the following diffractive analysis,\nwe identified two dominant modes adopted by participants, AI for ideation, and\nAI for production. We furthermore present a number of ethical design\nconsiderations for the future development of generative AI interfaces.","updated":1709537029000,"published":1709537029000,"authors":["Nina Rajcic","Maria Teresa Llano","Jon McCormack"],"comments":"Preprint of paper accepted for CHI 2024","categories":["cs.HC","J.5; H.1.2; H.5"],"primary_category":"cs.HC","doi":"10.1145\/3613904.3641971","journal_ref":null,"peer_reviewed":true,"reader_id":"rid1","human_jargon_term":"diffractive analysis","definition_text":"Diffractive analysis is a research method used to explore and understand how different ideas or elements interact and influence each other, often revealing new insights or perspectives. In the context of the study described, it was used to examine how artists integrate and interact with AI technology in their creative process.","model":"gpt4_abstract","Accuracy":"accurate","Ranking":1,"Notes":""},"171":{"arxiv_id":"2403.01783v1","url":"http:\/\/arxiv.org\/abs\/2403.01783v1","title":"Towards A Diffractive Analysis of Prompt-Based Generative AI","summary":"Recent developments in prompt-based generative AI has given rise to discourse\nsurrounding the perceived ethical concerns, economic implications, and\nconsequences for the future of cultural production. As generative imagery\nbecomes pervasive in mainstream society, dominated primarily by emerging\nindustry leaders, we encourage that the role of the CHI community be one of\ninquiry; to investigate the numerous ways in which generative AI has the\npotential to, and already is, augmenting human creativity. In this paper, we\nconducted a diffractive analysis exploring the potential role of prompt-based\ninterfaces in artists' creative practice. Over a two week period, seven visual\nartists were given access to a personalised instance of Stable Diffusion,\nfine-tuned on a dataset of their work. In the following diffractive analysis,\nwe identified two dominant modes adopted by participants, AI for ideation, and\nAI for production. We furthermore present a number of ethical design\nconsiderations for the future development of generative AI interfaces.","updated":1709537029000,"published":1709537029000,"authors":["Nina Rajcic","Maria Teresa Llano","Jon McCormack"],"comments":"Preprint of paper accepted for CHI 2024","categories":["cs.HC","J.5; H.1.2; H.5"],"primary_category":"cs.HC","doi":"10.1145\/3613904.3641971","journal_ref":null,"peer_reviewed":true,"reader_id":"rid1","human_jargon_term":"ideation","definition_text":"Ideation is the process of generating a broad set of ideas and concepts without concern for practical limitations. It often serves as the initial, creative phase in problem-solving where the goal is to explore as many possibilities as possible.","model":"gpt4_abstract","Accuracy":"accurate","Ranking":0,"Notes":""},"172":{"arxiv_id":"2403.08940v1","url":"http:\/\/arxiv.org\/abs\/2403.08940v1","title":"A Virtual Environment for Collaborative Inspection in Additive\n  Manufacturing","summary":"Additive manufacturing (AM) techniques have been used to enhance the design\nand fabrication of complex components for various applications in the medical,\naerospace, energy, and consumer products industries. A defining feature for\nmany AM parts is the complex internal geometry enabled by the printing process.\nHowever, inspecting these internal structures requires volumetric imaging,\ni.e., X-ray CT, leading to the well-known challenge of visualizing complex 3D\ngeometries using 2D desktop interfaces. Furthermore, existing tools are limited\nto single-user systems making it difficult to jointly discuss or share findings\nwith a larger team, i.e., the designers, manufacturing experts, and evaluation\nteam. In this work, we present a collaborative virtual reality (VR) for the\nexploration and inspection of AM parts. Geographically separated experts can\nvirtually inspect and jointly discuss data. It also supports VR and non-VR\nusers, who can be spectators in the VR environment. Various features for data\nexploration and inspection are developed and enhanced via real-time\nsynchronization. We followed usability and interface verification guidelines\nusing Nielsen's heuristics approach. Furthermore, we conducted exploratory and\nsemi-structured interviews with domain experts to collect qualitative feedback.\nResults reveal potential benefits, applicability, and current limitations. The\nproposed collaborative VR environment provides a new basis and opens new\nresearch directions for virtual inspection and team collaboration in AM\nsettings.","updated":1710360976000,"published":1710360976000,"authors":["Vuthea Chheang","Brian Thomas Weston","Robert William Cerda","Brian Au","Brian Giera","Peer-Timo Bremer","Haichao Miao"],"comments":"Conditionally Accepted - CHI LBW 2024","categories":["cs.HC","cs.DC"],"primary_category":"cs.HC","doi":null,"journal_ref":null,"peer_reviewed":true,"reader_id":"rid1","human_jargon_term":"Additive manufacturing","definition_text":"Additive manufacturing is a process of creating three-dimensional objects by adding material layer by layer, allowing for intricate designs and complex internal structures that might be difficult to achieve with traditional manufacturing methods. This technique is widely used in industries such as aerospace, medical, and consumer products to produce everything from small parts to larger, customized items.","model":"gpt4_abstract","Accuracy":"accurate","Ranking":0,"Notes":""},"173":{"arxiv_id":"2403.08940v1","url":"http:\/\/arxiv.org\/abs\/2403.08940v1","title":"A Virtual Environment for Collaborative Inspection in Additive\n  Manufacturing","summary":"Additive manufacturing (AM) techniques have been used to enhance the design\nand fabrication of complex components for various applications in the medical,\naerospace, energy, and consumer products industries. A defining feature for\nmany AM parts is the complex internal geometry enabled by the printing process.\nHowever, inspecting these internal structures requires volumetric imaging,\ni.e., X-ray CT, leading to the well-known challenge of visualizing complex 3D\ngeometries using 2D desktop interfaces. Furthermore, existing tools are limited\nto single-user systems making it difficult to jointly discuss or share findings\nwith a larger team, i.e., the designers, manufacturing experts, and evaluation\nteam. In this work, we present a collaborative virtual reality (VR) for the\nexploration and inspection of AM parts. Geographically separated experts can\nvirtually inspect and jointly discuss data. It also supports VR and non-VR\nusers, who can be spectators in the VR environment. Various features for data\nexploration and inspection are developed and enhanced via real-time\nsynchronization. We followed usability and interface verification guidelines\nusing Nielsen's heuristics approach. Furthermore, we conducted exploratory and\nsemi-structured interviews with domain experts to collect qualitative feedback.\nResults reveal potential benefits, applicability, and current limitations. The\nproposed collaborative VR environment provides a new basis and opens new\nresearch directions for virtual inspection and team collaboration in AM\nsettings.","updated":1710360976000,"published":1710360976000,"authors":["Vuthea Chheang","Brian Thomas Weston","Robert William Cerda","Brian Au","Brian Giera","Peer-Timo Bremer","Haichao Miao"],"comments":"Conditionally Accepted - CHI LBW 2024","categories":["cs.HC","cs.DC"],"primary_category":"cs.HC","doi":null,"journal_ref":null,"peer_reviewed":true,"reader_id":"rid1","human_jargon_term":"Nielsen's heuristics approach","definition_text":"Nielsen's heuristics approach refers to a set of guidelines developed by usability expert Jakob Nielsen to evaluate the user-friendliness and functionality of user interfaces. These guidelines help designers identify problems and improve the ease of use and overall experience of a system.","model":"gpt4_abstract","Accuracy":"accurate","Ranking":2,"Notes":""},"174":{"arxiv_id":"2403.08940v1","url":"http:\/\/arxiv.org\/abs\/2403.08940v1","title":"A Virtual Environment for Collaborative Inspection in Additive\n  Manufacturing","summary":"Additive manufacturing (AM) techniques have been used to enhance the design\nand fabrication of complex components for various applications in the medical,\naerospace, energy, and consumer products industries. A defining feature for\nmany AM parts is the complex internal geometry enabled by the printing process.\nHowever, inspecting these internal structures requires volumetric imaging,\ni.e., X-ray CT, leading to the well-known challenge of visualizing complex 3D\ngeometries using 2D desktop interfaces. Furthermore, existing tools are limited\nto single-user systems making it difficult to jointly discuss or share findings\nwith a larger team, i.e., the designers, manufacturing experts, and evaluation\nteam. In this work, we present a collaborative virtual reality (VR) for the\nexploration and inspection of AM parts. Geographically separated experts can\nvirtually inspect and jointly discuss data. It also supports VR and non-VR\nusers, who can be spectators in the VR environment. Various features for data\nexploration and inspection are developed and enhanced via real-time\nsynchronization. We followed usability and interface verification guidelines\nusing Nielsen's heuristics approach. Furthermore, we conducted exploratory and\nsemi-structured interviews with domain experts to collect qualitative feedback.\nResults reveal potential benefits, applicability, and current limitations. The\nproposed collaborative VR environment provides a new basis and opens new\nresearch directions for virtual inspection and team collaboration in AM\nsettings.","updated":1710360976000,"published":1710360976000,"authors":["Vuthea Chheang","Brian Thomas Weston","Robert William Cerda","Brian Au","Brian Giera","Peer-Timo Bremer","Haichao Miao"],"comments":"Conditionally Accepted - CHI LBW 2024","categories":["cs.HC","cs.DC"],"primary_category":"cs.HC","doi":null,"journal_ref":null,"peer_reviewed":true,"reader_id":"rid1","human_jargon_term":"collaborative virtual reality","definition_text":"Collaborative virtual reality (VR) refers to a technology that allows multiple users, possibly located in different geographic areas, to enter and interact within a digital environment as if they were together in the same physical space. This shared virtual space enables them to work together, discuss, and explore data or objects in real-time, despite being physically apart.","model":"gpt4_abstract","Accuracy":"accurate","Ranking":0,"Notes":""},"175":{"arxiv_id":"2403.08940v1","url":"http:\/\/arxiv.org\/abs\/2403.08940v1","title":"A Virtual Environment for Collaborative Inspection in Additive\n  Manufacturing","summary":"Additive manufacturing (AM) techniques have been used to enhance the design\nand fabrication of complex components for various applications in the medical,\naerospace, energy, and consumer products industries. A defining feature for\nmany AM parts is the complex internal geometry enabled by the printing process.\nHowever, inspecting these internal structures requires volumetric imaging,\ni.e., X-ray CT, leading to the well-known challenge of visualizing complex 3D\ngeometries using 2D desktop interfaces. Furthermore, existing tools are limited\nto single-user systems making it difficult to jointly discuss or share findings\nwith a larger team, i.e., the designers, manufacturing experts, and evaluation\nteam. In this work, we present a collaborative virtual reality (VR) for the\nexploration and inspection of AM parts. Geographically separated experts can\nvirtually inspect and jointly discuss data. It also supports VR and non-VR\nusers, who can be spectators in the VR environment. Various features for data\nexploration and inspection are developed and enhanced via real-time\nsynchronization. We followed usability and interface verification guidelines\nusing Nielsen's heuristics approach. Furthermore, we conducted exploratory and\nsemi-structured interviews with domain experts to collect qualitative feedback.\nResults reveal potential benefits, applicability, and current limitations. The\nproposed collaborative VR environment provides a new basis and opens new\nresearch directions for virtual inspection and team collaboration in AM\nsettings.","updated":1710360976000,"published":1710360976000,"authors":["Vuthea Chheang","Brian Thomas Weston","Robert William Cerda","Brian Au","Brian Giera","Peer-Timo Bremer","Haichao Miao"],"comments":"Conditionally Accepted - CHI LBW 2024","categories":["cs.HC","cs.DC"],"primary_category":"cs.HC","doi":null,"journal_ref":null,"peer_reviewed":true,"reader_id":"rid1","human_jargon_term":"volumetric imaging","definition_text":"Volumetric imaging is a type of 3D imaging technology used to create detailed internal views of objects by capturing information about the volume inside them. Commonly, methods like X-ray CT scans are used in this process to see inside complex structures without cutting them open.","model":"gpt4_abstract","Accuracy":"accurate","Ranking":2,"Notes":""},"176":{"arxiv_id":"2403.10851v1","url":"http:\/\/arxiv.org\/abs\/2403.10851v1","title":"GustosonicSense: Towards understanding the design of playful gustosonic\n  eating experiences","summary":"The pleasure that often comes with eating can be further enhanced with\nintelligent technology, as the field of human-food interaction suggests.\nHowever, knowledge on how to design such pleasure-supporting eating systems is\nlimited. To begin filling this knowledge gap, we designed \"GustosonicSense\", a\nnovel gustosonic eating system that utilizes wireless earbuds for sensing\ndifferent eating and drinking actions with a machine learning algorithm and\ntrigger playful sounds as a way to facilitate pleasurable eating experiences.\nWe present the findings from our design and a study that revealed how we can\nsupport the \"stimulation\", \"hedonism\", and \"reflexivity\" for playful human-food\ninteractions. Ultimately, with our work, we aim to support interaction\ndesigners in facilitating playful experiences with food.","updated":1710576669000,"published":1710576669000,"authors":["Yan Wang","Humphrey O. Obie","Zhuying Li","Flora D. Salim","John Grundy","Florian 'Floyd' Mueller"],"comments":"To appear at CHI'24: The ACM Conference on Human Factors in Computing\n  Systems (CHI), Honolulu, Hawaii, 2024","categories":["cs.HC","cs.MM"],"primary_category":"cs.HC","doi":null,"journal_ref":null,"peer_reviewed":true,"reader_id":"rid1","human_jargon_term":"GustosonicSense","definition_text":"GustosonicSense is a technology developed to enhance the eating experience by using wireless earbuds that detect your eating and drinking actions. This device then uses this information to play fun sounds, making the act of eating more enjoyable and interactive.","model":"gpt4_abstract","Accuracy":"accurate","Ranking":0,"Notes":""},"177":{"arxiv_id":"2403.10851v1","url":"http:\/\/arxiv.org\/abs\/2403.10851v1","title":"GustosonicSense: Towards understanding the design of playful gustosonic\n  eating experiences","summary":"The pleasure that often comes with eating can be further enhanced with\nintelligent technology, as the field of human-food interaction suggests.\nHowever, knowledge on how to design such pleasure-supporting eating systems is\nlimited. To begin filling this knowledge gap, we designed \"GustosonicSense\", a\nnovel gustosonic eating system that utilizes wireless earbuds for sensing\ndifferent eating and drinking actions with a machine learning algorithm and\ntrigger playful sounds as a way to facilitate pleasurable eating experiences.\nWe present the findings from our design and a study that revealed how we can\nsupport the \"stimulation\", \"hedonism\", and \"reflexivity\" for playful human-food\ninteractions. Ultimately, with our work, we aim to support interaction\ndesigners in facilitating playful experiences with food.","updated":1710576669000,"published":1710576669000,"authors":["Yan Wang","Humphrey O. Obie","Zhuying Li","Flora D. Salim","John Grundy","Florian 'Floyd' Mueller"],"comments":"To appear at CHI'24: The ACM Conference on Human Factors in Computing\n  Systems (CHI), Honolulu, Hawaii, 2024","categories":["cs.HC","cs.MM"],"primary_category":"cs.HC","doi":null,"journal_ref":null,"peer_reviewed":true,"reader_id":"rid1","human_jargon_term":"hedonism","definition_text":"Hedonism is the belief or philosophy that pleasure or happiness is the primary or most important goal in life, and that individuals should strive to maximize their own pleasure and enjoyment. In the context of food, it refers to the enjoyment and satisfaction derived from eating.","model":"gpt4_abstract","Accuracy":"accurate","Ranking":0,"Notes":""},"178":{"arxiv_id":"2403.10851v1","url":"http:\/\/arxiv.org\/abs\/2403.10851v1","title":"GustosonicSense: Towards understanding the design of playful gustosonic\n  eating experiences","summary":"The pleasure that often comes with eating can be further enhanced with\nintelligent technology, as the field of human-food interaction suggests.\nHowever, knowledge on how to design such pleasure-supporting eating systems is\nlimited. To begin filling this knowledge gap, we designed \"GustosonicSense\", a\nnovel gustosonic eating system that utilizes wireless earbuds for sensing\ndifferent eating and drinking actions with a machine learning algorithm and\ntrigger playful sounds as a way to facilitate pleasurable eating experiences.\nWe present the findings from our design and a study that revealed how we can\nsupport the \"stimulation\", \"hedonism\", and \"reflexivity\" for playful human-food\ninteractions. Ultimately, with our work, we aim to support interaction\ndesigners in facilitating playful experiences with food.","updated":1710576669000,"published":1710576669000,"authors":["Yan Wang","Humphrey O. Obie","Zhuying Li","Flora D. Salim","John Grundy","Florian 'Floyd' Mueller"],"comments":"To appear at CHI'24: The ACM Conference on Human Factors in Computing\n  Systems (CHI), Honolulu, Hawaii, 2024","categories":["cs.HC","cs.MM"],"primary_category":"cs.HC","doi":null,"journal_ref":null,"peer_reviewed":true,"reader_id":"rid1","human_jargon_term":"reflexivity","definition_text":"Reflexivity in this context refers to the ability of individuals to reflect on their own experiences and behaviors, particularly while interacting with food, enabling them to be more conscious and thoughtful about their eating habits and the enjoyment derived from them.","model":"gpt4_abstract","Accuracy":"accurate","Ranking":1,"Notes":""},"179":{"arxiv_id":"2403.04760v1","url":"http:\/\/arxiv.org\/abs\/2403.04760v1","title":"iScore: Visual Analytics for Interpreting How Language Models\n  Automatically Score Summaries","summary":"The recent explosion in popularity of large language models (LLMs) has\ninspired learning engineers to incorporate them into adaptive educational tools\nthat automatically score summary writing. Understanding and evaluating LLMs is\nvital before deploying them in critical learning environments, yet their\nunprecedented size and expanding number of parameters inhibits transparency and\nimpedes trust when they underperform. Through a collaborative user-centered\ndesign process with several learning engineers building and deploying summary\nscoring LLMs, we characterized fundamental design challenges and goals around\ninterpreting their models, including aggregating large text inputs, tracking\nscore provenance, and scaling LLM interpretability methods. To address their\nconcerns, we developed iScore, an interactive visual analytics tool for\nlearning engineers to upload, score, and compare multiple summaries\nsimultaneously. Tightly integrated views allow users to iteratively revise the\nlanguage in summaries, track changes in the resulting LLM scores, and visualize\nmodel weights at multiple levels of abstraction. To validate our approach, we\ndeployed iScore with three learning engineers over the course of a month. We\npresent a case study where interacting with iScore led a learning engineer to\nimprove their LLM's score accuracy by three percentage points. Finally, we\nconducted qualitative interviews with the learning engineers that revealed how\niScore enabled them to understand, evaluate, and build trust in their LLMs\nduring deployment.","updated":1709837799000,"published":1709837799000,"authors":["Adam Coscia","Langdon Holmes","Wesley Morris","Joon Suh Choi","Scott Crossley","Alex Endert"],"comments":"Accepted to IUI 2024. 16 pages, 5 figures, 1 table. For a demo video,\n  see https:\/\/youtu.be\/EYJX-_fQPf0 . For a live demo, visit\n  https:\/\/adamcoscia.com\/papers\/iscore\/demo\/ . The source code is available at\n  https:\/\/github.com\/AdamCoscia\/iScore","categories":["cs.HC","cs.AI","cs.CY","cs.LG"],"primary_category":"cs.HC","doi":"10.1145\/3640543.3645142","journal_ref":null,"peer_reviewed":true,"reader_id":"rid1","human_jargon_term":"iScore","definition_text":"iScore is an interactive tool designed to help learning engineers upload, analyze, and compare summaries assessed by language models, enabling them to see how changes in the text affect the scoring and visualize various aspects of the model's decision-making process. This visual analytics tool aids in understanding, evaluating, and improving the accuracy and reliability of these language models.","model":"gpt4_abstract","Accuracy":"accurate","Ranking":2,"Notes":""},"180":{"arxiv_id":"2403.04760v1","url":"http:\/\/arxiv.org\/abs\/2403.04760v1","title":"iScore: Visual Analytics for Interpreting How Language Models\n  Automatically Score Summaries","summary":"The recent explosion in popularity of large language models (LLMs) has\ninspired learning engineers to incorporate them into adaptive educational tools\nthat automatically score summary writing. Understanding and evaluating LLMs is\nvital before deploying them in critical learning environments, yet their\nunprecedented size and expanding number of parameters inhibits transparency and\nimpedes trust when they underperform. Through a collaborative user-centered\ndesign process with several learning engineers building and deploying summary\nscoring LLMs, we characterized fundamental design challenges and goals around\ninterpreting their models, including aggregating large text inputs, tracking\nscore provenance, and scaling LLM interpretability methods. To address their\nconcerns, we developed iScore, an interactive visual analytics tool for\nlearning engineers to upload, score, and compare multiple summaries\nsimultaneously. Tightly integrated views allow users to iteratively revise the\nlanguage in summaries, track changes in the resulting LLM scores, and visualize\nmodel weights at multiple levels of abstraction. To validate our approach, we\ndeployed iScore with three learning engineers over the course of a month. We\npresent a case study where interacting with iScore led a learning engineer to\nimprove their LLM's score accuracy by three percentage points. Finally, we\nconducted qualitative interviews with the learning engineers that revealed how\niScore enabled them to understand, evaluate, and build trust in their LLMs\nduring deployment.","updated":1709837799000,"published":1709837799000,"authors":["Adam Coscia","Langdon Holmes","Wesley Morris","Joon Suh Choi","Scott Crossley","Alex Endert"],"comments":"Accepted to IUI 2024. 16 pages, 5 figures, 1 table. For a demo video,\n  see https:\/\/youtu.be\/EYJX-_fQPf0 . For a live demo, visit\n  https:\/\/adamcoscia.com\/papers\/iscore\/demo\/ . The source code is available at\n  https:\/\/github.com\/AdamCoscia\/iScore","categories":["cs.HC","cs.AI","cs.CY","cs.LG"],"primary_category":"cs.HC","doi":"10.1145\/3640543.3645142","journal_ref":null,"peer_reviewed":true,"reader_id":"rid1","human_jargon_term":"score provenance","definition_text":"Score provenance refers to the ability to track and understand the origin of the scores given by the language models to various text summaries, including details about how and why a particular score was assigned.","model":"gpt4_abstract","Accuracy":"accurate","Ranking":1,"Notes":""},"181":{"arxiv_id":"2403.09308v1","url":"http:\/\/arxiv.org\/abs\/2403.09308v1","title":"Enabling Waypoint Generation for Collaborative Robots using LLMs and\n  Mixed Reality","summary":"Programming a robotic is a complex task, as it demands the user to have a\ngood command of specific programming languages and awareness of the robot's\nphysical constraints. We propose a framework that simplifies robot deployment\nby allowing direct communication using natural language. It uses large language\nmodels (LLM) for prompt processing, workspace understanding, and waypoint\ngeneration. It also employs Augmented Reality (AR) to provide visual feedback\nof the planned outcome. We showcase the effectiveness of our framework with a\nsimple pick-and-place task, which we implement on a real robot. Moreover, we\npresent an early concept of expressive robot behavior and skill generation that\ncan be used to communicate with the user and learn new skills (e.g., object\ngrasping).","updated":1710417547000,"published":1710417547000,"authors":["Cathy Mengying Fang","Krzysztof Zieli\u0144ski","Pattie Maes","Joe Paradiso","Bruce Blumberg","Mikkel Baun Kj\u00e6rgaard"],"comments":"Submitted to VLMNM 2024 - Workshop, ICRA 2024. This work has been\n  submitted to the IEEE for possible publication. Copyright may be transferred\n  without notice, after which this version may no longer be accessible","categories":["cs.HC","cs.RO"],"primary_category":"cs.HC","doi":null,"journal_ref":null,"peer_reviewed":true,"reader_id":"rid1","human_jargon_term":"pick-and-place task","definition_text":"A pick-and-place task refers to a job where a robot is programmed to pick up an object from one location and place it in another specified location, similar to how a person might move items from one spot to another on a table. This common robotic activity is used to demonstrate and test the effectiveness of robotic programming and operation systems.","model":"gpt4_abstract","Accuracy":"accurate","Ranking":2,"Notes":""},"182":{"arxiv_id":"2403.09308v1","url":"http:\/\/arxiv.org\/abs\/2403.09308v1","title":"Enabling Waypoint Generation for Collaborative Robots using LLMs and\n  Mixed Reality","summary":"Programming a robotic is a complex task, as it demands the user to have a\ngood command of specific programming languages and awareness of the robot's\nphysical constraints. We propose a framework that simplifies robot deployment\nby allowing direct communication using natural language. It uses large language\nmodels (LLM) for prompt processing, workspace understanding, and waypoint\ngeneration. It also employs Augmented Reality (AR) to provide visual feedback\nof the planned outcome. We showcase the effectiveness of our framework with a\nsimple pick-and-place task, which we implement on a real robot. Moreover, we\npresent an early concept of expressive robot behavior and skill generation that\ncan be used to communicate with the user and learn new skills (e.g., object\ngrasping).","updated":1710417547000,"published":1710417547000,"authors":["Cathy Mengying Fang","Krzysztof Zieli\u0144ski","Pattie Maes","Joe Paradiso","Bruce Blumberg","Mikkel Baun Kj\u00e6rgaard"],"comments":"Submitted to VLMNM 2024 - Workshop, ICRA 2024. This work has been\n  submitted to the IEEE for possible publication. Copyright may be transferred\n  without notice, after which this version may no longer be accessible","categories":["cs.HC","cs.RO"],"primary_category":"cs.HC","doi":null,"journal_ref":null,"peer_reviewed":true,"reader_id":"rid1","human_jargon_term":"waypoint generation","definition_text":"Waypoint generation involves creating specific points or locations that a robot must reach or pass through as it moves to complete a task. This helps guide the robot's movement in a structured way to achieve its objectives efficiently.","model":"gpt4_abstract","Accuracy":"accurate","Ranking":0,"Notes":""},"183":{"arxiv_id":"2403.09308v1","url":"http:\/\/arxiv.org\/abs\/2403.09308v1","title":"Enabling Waypoint Generation for Collaborative Robots using LLMs and\n  Mixed Reality","summary":"Programming a robotic is a complex task, as it demands the user to have a\ngood command of specific programming languages and awareness of the robot's\nphysical constraints. We propose a framework that simplifies robot deployment\nby allowing direct communication using natural language. It uses large language\nmodels (LLM) for prompt processing, workspace understanding, and waypoint\ngeneration. It also employs Augmented Reality (AR) to provide visual feedback\nof the planned outcome. We showcase the effectiveness of our framework with a\nsimple pick-and-place task, which we implement on a real robot. Moreover, we\npresent an early concept of expressive robot behavior and skill generation that\ncan be used to communicate with the user and learn new skills (e.g., object\ngrasping).","updated":1710417547000,"published":1710417547000,"authors":["Cathy Mengying Fang","Krzysztof Zieli\u0144ski","Pattie Maes","Joe Paradiso","Bruce Blumberg","Mikkel Baun Kj\u00e6rgaard"],"comments":"Submitted to VLMNM 2024 - Workshop, ICRA 2024. This work has been\n  submitted to the IEEE for possible publication. Copyright may be transferred\n  without notice, after which this version may no longer be accessible","categories":["cs.HC","cs.RO"],"primary_category":"cs.HC","doi":null,"journal_ref":null,"peer_reviewed":true,"reader_id":"rid1","human_jargon_term":"workspace understanding","definition_text":"Workspace understanding in this context refers to the robot's ability to recognize and interpret the space around it where it operates. This helps the robot determine where objects are located and how it can interact with them during tasks.","model":"gpt4_abstract","Accuracy":"accurate","Ranking":0,"Notes":""},"184":{"arxiv_id":"2403.02928v1","url":"http:\/\/arxiv.org\/abs\/2403.02928v1","title":"User-Driven Adaptation: Tailoring Autonomous Driving Systems with\n  Dynamic Preferences","summary":"In the realm of autonomous vehicles, dynamic user preferences are critical\nyet challenging to accommodate. Existing methods often misrepresent these\npreferences, either by overlooking their dynamism or overburdening users as\nhumans often find it challenging to express their objectives mathematically.\nThe previously introduced framework, which interprets dynamic preferences as\ninherent uncertainty and includes a ``human-on-the-loop'' mechanism enabling\nusers to give feedback when dissatisfied with system behaviors, addresses this\ngap. In this study, we further enhance the approach with a user study of 20\nparticipants, focusing on aligning system behavior with user expectations\nthrough feedback-driven adaptation. The findings affirm the approach's ability\nto effectively merge algorithm-driven adjustments with user complaints, leading\nto improved participants' subjective satisfaction in autonomous systems.","updated":1709642694000,"published":1709642694000,"authors":["Mingyue Zhang","Jialong Li","Nianyu Li","Eunsuk Kang","Kenji Tei"],"comments":"accepted by CHI LBW 2024","categories":["cs.HC","cs.SE"],"primary_category":"cs.HC","doi":null,"journal_ref":null,"peer_reviewed":true,"reader_id":"rid1","human_jargon_term":"dynamism","definition_text":"Dynamism refers to the quality of being constantly changing or active. In the context of user preferences, it means that what users want or expect can vary frequently over time.","model":"gpt4_abstract","Accuracy":"accurate","Ranking":0,"Notes":""},"185":{"arxiv_id":"2403.02928v1","url":"http:\/\/arxiv.org\/abs\/2403.02928v1","title":"User-Driven Adaptation: Tailoring Autonomous Driving Systems with\n  Dynamic Preferences","summary":"In the realm of autonomous vehicles, dynamic user preferences are critical\nyet challenging to accommodate. Existing methods often misrepresent these\npreferences, either by overlooking their dynamism or overburdening users as\nhumans often find it challenging to express their objectives mathematically.\nThe previously introduced framework, which interprets dynamic preferences as\ninherent uncertainty and includes a ``human-on-the-loop'' mechanism enabling\nusers to give feedback when dissatisfied with system behaviors, addresses this\ngap. In this study, we further enhance the approach with a user study of 20\nparticipants, focusing on aligning system behavior with user expectations\nthrough feedback-driven adaptation. The findings affirm the approach's ability\nto effectively merge algorithm-driven adjustments with user complaints, leading\nto improved participants' subjective satisfaction in autonomous systems.","updated":1709642694000,"published":1709642694000,"authors":["Mingyue Zhang","Jialong Li","Nianyu Li","Eunsuk Kang","Kenji Tei"],"comments":"accepted by CHI LBW 2024","categories":["cs.HC","cs.SE"],"primary_category":"cs.HC","doi":null,"journal_ref":null,"peer_reviewed":true,"reader_id":"rid1","human_jargon_term":"human-on-the-loop","definition_text":"The term \"human-on-the-loop\" refers to a system design where humans are involved by monitoring and providing feedback on automated or autonomous systems, but are not directly controlling every action. This allows the human to intervene and make adjustments only when necessary, enhancing the system\u2019s performance or correcting errors, without being overwhelmed by the need to manage continuous operation.","model":"gpt4_abstract","Accuracy":"accurate","Ranking":0,"Notes":""},"186":{"arxiv_id":"2403.07997v1","url":"http:\/\/arxiv.org\/abs\/2403.07997v1","title":"Fast-Forward Reality: Authoring Error-Free Context-Aware Policies with\n  Real-Time Unit Tests in Extended Reality","summary":"Advances in ubiquitous computing have enabled end-user authoring of\ncontext-aware policies (CAPs) that control smart devices based on specific\ncontexts of the user and environment. However, authoring CAPs accurately and\navoiding run-time errors is challenging for end-users as it is difficult to\nforesee CAP behaviors under complex real-world conditions. We propose\nFast-Forward Reality, an Extended Reality (XR) based authoring workflow that\nenables end-users to iteratively author and refine CAPs by validating their\nbehaviors via simulated unit test cases. We develop a computational approach to\nautomatically generate test cases based on the authored CAP and the user's\ncontext history. Our system delivers each test case with immersive\nvisualizations in XR, facilitating users to verify the CAP behavior and\nidentify necessary refinements. We evaluated Fast-Forward Reality in a user\nstudy (N=12). Our authoring and validation process improved the accuracy of\nCAPs and the users provided positive feedback on the system usability.","updated":1710266738000,"published":1710266738000,"authors":["Xun Qian","Tianyi Wang","Xuhai Xu","Tanya R Jonker","Kashyap Todi"],"comments":"17 pages, 7 figures, ACM CHI 2024 Full Paper","categories":["cs.HC","H.5.2"],"primary_category":"cs.HC","doi":"10.1145\/3613904.3642158","journal_ref":null,"peer_reviewed":true,"reader_id":"rid1","human_jargon_term":"Extended Reality","definition_text":"Extended Reality (XR) refers to all real-and-virtual combined environments and human-machine interactions generated by computer technology and wearables. It includes the spectrum of augmented reality (AR), virtual reality (VR), and mixed reality (MR) technologies.","model":"gpt4_abstract","Accuracy":"accurate","Ranking":1,"Notes":""},"187":{"arxiv_id":"2403.07997v1","url":"http:\/\/arxiv.org\/abs\/2403.07997v1","title":"Fast-Forward Reality: Authoring Error-Free Context-Aware Policies with\n  Real-Time Unit Tests in Extended Reality","summary":"Advances in ubiquitous computing have enabled end-user authoring of\ncontext-aware policies (CAPs) that control smart devices based on specific\ncontexts of the user and environment. However, authoring CAPs accurately and\navoiding run-time errors is challenging for end-users as it is difficult to\nforesee CAP behaviors under complex real-world conditions. We propose\nFast-Forward Reality, an Extended Reality (XR) based authoring workflow that\nenables end-users to iteratively author and refine CAPs by validating their\nbehaviors via simulated unit test cases. We develop a computational approach to\nautomatically generate test cases based on the authored CAP and the user's\ncontext history. Our system delivers each test case with immersive\nvisualizations in XR, facilitating users to verify the CAP behavior and\nidentify necessary refinements. We evaluated Fast-Forward Reality in a user\nstudy (N=12). Our authoring and validation process improved the accuracy of\nCAPs and the users provided positive feedback on the system usability.","updated":1710266738000,"published":1710266738000,"authors":["Xun Qian","Tianyi Wang","Xuhai Xu","Tanya R Jonker","Kashyap Todi"],"comments":"17 pages, 7 figures, ACM CHI 2024 Full Paper","categories":["cs.HC","H.5.2"],"primary_category":"cs.HC","doi":"10.1145\/3613904.3642158","journal_ref":null,"peer_reviewed":true,"reader_id":"rid1","human_jargon_term":"Fast-Forward Reality","definition_text":"Fast-Forward Reality is an Extended Reality (XR) based system designed to help users create and improve rules for controlling smart devices by letting them simulate and test these rules in a virtual environment before applying them in the real world. This allows users to see how the rules would work and make necessary adjustments, ensuring the devices behave as intended.","model":"gpt4_abstract","Accuracy":"accurate","Ranking":1,"Notes":""},"188":{"arxiv_id":"2403.07997v1","url":"http:\/\/arxiv.org\/abs\/2403.07997v1","title":"Fast-Forward Reality: Authoring Error-Free Context-Aware Policies with\n  Real-Time Unit Tests in Extended Reality","summary":"Advances in ubiquitous computing have enabled end-user authoring of\ncontext-aware policies (CAPs) that control smart devices based on specific\ncontexts of the user and environment. However, authoring CAPs accurately and\navoiding run-time errors is challenging for end-users as it is difficult to\nforesee CAP behaviors under complex real-world conditions. We propose\nFast-Forward Reality, an Extended Reality (XR) based authoring workflow that\nenables end-users to iteratively author and refine CAPs by validating their\nbehaviors via simulated unit test cases. We develop a computational approach to\nautomatically generate test cases based on the authored CAP and the user's\ncontext history. Our system delivers each test case with immersive\nvisualizations in XR, facilitating users to verify the CAP behavior and\nidentify necessary refinements. We evaluated Fast-Forward Reality in a user\nstudy (N=12). Our authoring and validation process improved the accuracy of\nCAPs and the users provided positive feedback on the system usability.","updated":1710266738000,"published":1710266738000,"authors":["Xun Qian","Tianyi Wang","Xuhai Xu","Tanya R Jonker","Kashyap Todi"],"comments":"17 pages, 7 figures, ACM CHI 2024 Full Paper","categories":["cs.HC","H.5.2"],"primary_category":"cs.HC","doi":"10.1145\/3613904.3642158","journal_ref":null,"peer_reviewed":true,"reader_id":"rid1","human_jargon_term":"context-aware policies","definition_text":"Context-aware policies (CAPs) are rules or guidelines used by smart devices that change their behavior based of specific situations involving the user and the surrounding environment. For example, a context-aware policy could automatically adjust the lighting and temperature in a room based on the time of day, the weather outside, and the presence of people in the room.","model":"gpt4_abstract","Accuracy":"accurate","Ranking":0,"Notes":""},"189":{"arxiv_id":"2403.06267v1","url":"http:\/\/arxiv.org\/abs\/2403.06267v1","title":"FARPLS: A Feature-Augmented Robot Trajectory Preference Labeling System\n  to Assist Human Labelers' Preference Elicitation","summary":"Preference-based learning aims to align robot task objectives with human\nvalues. One of the most common methods to infer human preferences is by\npairwise comparisons of robot task trajectories. Traditional comparison-based\npreference labeling systems seldom support labelers to digest and identify\ncritical differences between complex trajectories recorded in videos. Our\nformative study (N = 12) suggests that individuals may overlook non-salient\ntask features and establish biased preference criteria during their preference\nelicitation process because of partial observations. In addition, they may\nexperience mental fatigue when given many pairs to compare, causing their label\nquality to deteriorate. To mitigate these issues, we propose FARPLS, a\nFeature-Augmented Robot trajectory Preference Labeling System. FARPLS\nhighlights potential outliers in a wide variety of task features that matter to\nhumans and extracts the corresponding video keyframes for easy review and\ncomparison. It also dynamically adjusts the labeling order according to users'\nfamiliarities, difficulties of the trajectory pair, and level of disagreements.\nAt the same time, the system monitors labelers' consistency and provides\nfeedback on labeling progress to keep labelers engaged. A between-subjects\nstudy (N = 42, 105 pairs of robot pick-and-place trajectories per person) shows\nthat FARPLS can help users establish preference criteria more easily and notice\nmore relevant details in the presented trajectories than the conventional\ninterface. FARPLS also improves labeling consistency and engagement, mitigating\nchallenges in preference elicitation without raising cognitive loads\nsignificantly","updated":1710090440000,"published":1710090440000,"authors":["Hanfang Lyu","Yuanchen Bai","Xin Liang","Ujaan Das","Chuhan Shi","Leiliang Gong","Yingchi Li","Mingfei Sun","Ming Ge","Xiaojuan Ma"],"comments":"Accepted to ACM Conference on Intelligent User Interfaces (IUI) 2024,\n  March 18-21, 2024, Greenville, SC, USA","categories":["cs.HC","cs.AI"],"primary_category":"cs.HC","doi":"10.1145\/3640543.3645145","journal_ref":null,"peer_reviewed":true,"reader_id":"rid1","human_jargon_term":"FARPLS","definition_text":"FARPLS, or Feature-Augmented Robot trajectory Preference Labeling System, is a tool designed to help users more effectively review and compare robot task trajectories by highlighting key differences and important features. This system also organizes the review process by prioritizing videos based on the user's familiarity with the tasks and the difficulty level, enhancing consistency and engagement in labeling preferences without significantly increasing the mental effort required.","model":"gpt4_abstract","Accuracy":"accurate","Ranking":1,"Notes":""},"190":{"arxiv_id":"2403.06267v1","url":"http:\/\/arxiv.org\/abs\/2403.06267v1","title":"FARPLS: A Feature-Augmented Robot Trajectory Preference Labeling System\n  to Assist Human Labelers' Preference Elicitation","summary":"Preference-based learning aims to align robot task objectives with human\nvalues. One of the most common methods to infer human preferences is by\npairwise comparisons of robot task trajectories. Traditional comparison-based\npreference labeling systems seldom support labelers to digest and identify\ncritical differences between complex trajectories recorded in videos. Our\nformative study (N = 12) suggests that individuals may overlook non-salient\ntask features and establish biased preference criteria during their preference\nelicitation process because of partial observations. In addition, they may\nexperience mental fatigue when given many pairs to compare, causing their label\nquality to deteriorate. To mitigate these issues, we propose FARPLS, a\nFeature-Augmented Robot trajectory Preference Labeling System. FARPLS\nhighlights potential outliers in a wide variety of task features that matter to\nhumans and extracts the corresponding video keyframes for easy review and\ncomparison. It also dynamically adjusts the labeling order according to users'\nfamiliarities, difficulties of the trajectory pair, and level of disagreements.\nAt the same time, the system monitors labelers' consistency and provides\nfeedback on labeling progress to keep labelers engaged. A between-subjects\nstudy (N = 42, 105 pairs of robot pick-and-place trajectories per person) shows\nthat FARPLS can help users establish preference criteria more easily and notice\nmore relevant details in the presented trajectories than the conventional\ninterface. FARPLS also improves labeling consistency and engagement, mitigating\nchallenges in preference elicitation without raising cognitive loads\nsignificantly","updated":1710090440000,"published":1710090440000,"authors":["Hanfang Lyu","Yuanchen Bai","Xin Liang","Ujaan Das","Chuhan Shi","Leiliang Gong","Yingchi Li","Mingfei Sun","Ming Ge","Xiaojuan Ma"],"comments":"Accepted to ACM Conference on Intelligent User Interfaces (IUI) 2024,\n  March 18-21, 2024, Greenville, SC, USA","categories":["cs.HC","cs.AI"],"primary_category":"cs.HC","doi":"10.1145\/3640543.3645145","journal_ref":null,"peer_reviewed":true,"reader_id":"rid1","human_jargon_term":"Preference-based learning","definition_text":"Preference-based learning is a method used in robotics and artificial intelligence where systems learn to make decisions based on human preferences. This approach involves the system receiving input on which choices humans prefer in certain situations, thereby aligning the machine's actions with human values and expectations.","model":"gpt4_abstract","Accuracy":"accurate","Ranking":0,"Notes":""},"191":{"arxiv_id":"2403.06267v1","url":"http:\/\/arxiv.org\/abs\/2403.06267v1","title":"FARPLS: A Feature-Augmented Robot Trajectory Preference Labeling System\n  to Assist Human Labelers' Preference Elicitation","summary":"Preference-based learning aims to align robot task objectives with human\nvalues. One of the most common methods to infer human preferences is by\npairwise comparisons of robot task trajectories. Traditional comparison-based\npreference labeling systems seldom support labelers to digest and identify\ncritical differences between complex trajectories recorded in videos. Our\nformative study (N = 12) suggests that individuals may overlook non-salient\ntask features and establish biased preference criteria during their preference\nelicitation process because of partial observations. In addition, they may\nexperience mental fatigue when given many pairs to compare, causing their label\nquality to deteriorate. To mitigate these issues, we propose FARPLS, a\nFeature-Augmented Robot trajectory Preference Labeling System. FARPLS\nhighlights potential outliers in a wide variety of task features that matter to\nhumans and extracts the corresponding video keyframes for easy review and\ncomparison. It also dynamically adjusts the labeling order according to users'\nfamiliarities, difficulties of the trajectory pair, and level of disagreements.\nAt the same time, the system monitors labelers' consistency and provides\nfeedback on labeling progress to keep labelers engaged. A between-subjects\nstudy (N = 42, 105 pairs of robot pick-and-place trajectories per person) shows\nthat FARPLS can help users establish preference criteria more easily and notice\nmore relevant details in the presented trajectories than the conventional\ninterface. FARPLS also improves labeling consistency and engagement, mitigating\nchallenges in preference elicitation without raising cognitive loads\nsignificantly","updated":1710090440000,"published":1710090440000,"authors":["Hanfang Lyu","Yuanchen Bai","Xin Liang","Ujaan Das","Chuhan Shi","Leiliang Gong","Yingchi Li","Mingfei Sun","Ming Ge","Xiaojuan Ma"],"comments":"Accepted to ACM Conference on Intelligent User Interfaces (IUI) 2024,\n  March 18-21, 2024, Greenville, SC, USA","categories":["cs.HC","cs.AI"],"primary_category":"cs.HC","doi":"10.1145\/3640543.3645145","journal_ref":null,"peer_reviewed":true,"reader_id":"rid1","human_jargon_term":"cognitive loads","definition_text":"Cognitive load refers to the amount of mental effort and resources required to process information and perform tasks. In simpler terms, it's how much brain power you need to use to think about or do something.","model":"gpt4_abstract","Accuracy":"accurate","Ranking":0,"Notes":""},"192":{"arxiv_id":"2403.06267v1","url":"http:\/\/arxiv.org\/abs\/2403.06267v1","title":"FARPLS: A Feature-Augmented Robot Trajectory Preference Labeling System\n  to Assist Human Labelers' Preference Elicitation","summary":"Preference-based learning aims to align robot task objectives with human\nvalues. One of the most common methods to infer human preferences is by\npairwise comparisons of robot task trajectories. Traditional comparison-based\npreference labeling systems seldom support labelers to digest and identify\ncritical differences between complex trajectories recorded in videos. Our\nformative study (N = 12) suggests that individuals may overlook non-salient\ntask features and establish biased preference criteria during their preference\nelicitation process because of partial observations. In addition, they may\nexperience mental fatigue when given many pairs to compare, causing their label\nquality to deteriorate. To mitigate these issues, we propose FARPLS, a\nFeature-Augmented Robot trajectory Preference Labeling System. FARPLS\nhighlights potential outliers in a wide variety of task features that matter to\nhumans and extracts the corresponding video keyframes for easy review and\ncomparison. It also dynamically adjusts the labeling order according to users'\nfamiliarities, difficulties of the trajectory pair, and level of disagreements.\nAt the same time, the system monitors labelers' consistency and provides\nfeedback on labeling progress to keep labelers engaged. A between-subjects\nstudy (N = 42, 105 pairs of robot pick-and-place trajectories per person) shows\nthat FARPLS can help users establish preference criteria more easily and notice\nmore relevant details in the presented trajectories than the conventional\ninterface. FARPLS also improves labeling consistency and engagement, mitigating\nchallenges in preference elicitation without raising cognitive loads\nsignificantly","updated":1710090440000,"published":1710090440000,"authors":["Hanfang Lyu","Yuanchen Bai","Xin Liang","Ujaan Das","Chuhan Shi","Leiliang Gong","Yingchi Li","Mingfei Sun","Ming Ge","Xiaojuan Ma"],"comments":"Accepted to ACM Conference on Intelligent User Interfaces (IUI) 2024,\n  March 18-21, 2024, Greenville, SC, USA","categories":["cs.HC","cs.AI"],"primary_category":"cs.HC","doi":"10.1145\/3640543.3645145","journal_ref":null,"peer_reviewed":true,"reader_id":"rid1","human_jargon_term":"non-salient","definition_text":"The term \"non-salient\" refers to features or aspects that are not prominent or easily noticeable. In the context described, this would mean parts of a task or details that do not stand out or catch the observer's attention quickly, potentially being overlooked during evaluation or comparison.","model":"gpt4_abstract","Accuracy":"accurate","Ranking":0,"Notes":""},"193":{"arxiv_id":"2403.06267v1","url":"http:\/\/arxiv.org\/abs\/2403.06267v1","title":"FARPLS: A Feature-Augmented Robot Trajectory Preference Labeling System\n  to Assist Human Labelers' Preference Elicitation","summary":"Preference-based learning aims to align robot task objectives with human\nvalues. One of the most common methods to infer human preferences is by\npairwise comparisons of robot task trajectories. Traditional comparison-based\npreference labeling systems seldom support labelers to digest and identify\ncritical differences between complex trajectories recorded in videos. Our\nformative study (N = 12) suggests that individuals may overlook non-salient\ntask features and establish biased preference criteria during their preference\nelicitation process because of partial observations. In addition, they may\nexperience mental fatigue when given many pairs to compare, causing their label\nquality to deteriorate. To mitigate these issues, we propose FARPLS, a\nFeature-Augmented Robot trajectory Preference Labeling System. FARPLS\nhighlights potential outliers in a wide variety of task features that matter to\nhumans and extracts the corresponding video keyframes for easy review and\ncomparison. It also dynamically adjusts the labeling order according to users'\nfamiliarities, difficulties of the trajectory pair, and level of disagreements.\nAt the same time, the system monitors labelers' consistency and provides\nfeedback on labeling progress to keep labelers engaged. A between-subjects\nstudy (N = 42, 105 pairs of robot pick-and-place trajectories per person) shows\nthat FARPLS can help users establish preference criteria more easily and notice\nmore relevant details in the presented trajectories than the conventional\ninterface. FARPLS also improves labeling consistency and engagement, mitigating\nchallenges in preference elicitation without raising cognitive loads\nsignificantly","updated":1710090440000,"published":1710090440000,"authors":["Hanfang Lyu","Yuanchen Bai","Xin Liang","Ujaan Das","Chuhan Shi","Leiliang Gong","Yingchi Li","Mingfei Sun","Ming Ge","Xiaojuan Ma"],"comments":"Accepted to ACM Conference on Intelligent User Interfaces (IUI) 2024,\n  March 18-21, 2024, Greenville, SC, USA","categories":["cs.HC","cs.AI"],"primary_category":"cs.HC","doi":"10.1145\/3640543.3645145","journal_ref":null,"peer_reviewed":true,"reader_id":"rid1","human_jargon_term":"trajectory pair","definition_text":"A trajectory pair refers to two sequences of movements or paths taken by a robot as it completes a task, which are compared against each other to determine which one aligns better with human preferences or performs the task more effectively. This comparison helps in understanding and enhancing how robots execute tasks based on human judgment.","model":"gpt4_abstract","Accuracy":"accurate","Ranking":1,"Notes":""},"194":{"arxiv_id":"2403.06823v2","url":"http:\/\/arxiv.org\/abs\/2403.06823v2","title":"Transparent AI Disclosure Obligations: Who, What, When, Where, Why, How","summary":"Advances in Generative Artificial Intelligence (AI) are resulting in\nAI-generated media output that is (nearly) indistinguishable from human-created\ncontent. This can drastically impact users and the media sector, especially\ngiven global risks of misinformation. While the currently discussed European AI\nAct aims at addressing these risks through Article 52's AI transparency\nobligations, its interpretation and implications remain unclear. In this early\nwork, we adopt a participatory AI approach to derive key questions based on\nArticle 52's disclosure obligations. We ran two workshops with researchers,\ndesigners, and engineers across disciplines (N=16), where participants\ndeconstructed Article 52's relevant clauses using the 5W1H framework. We\ncontribute a set of 149 questions clustered into five themes and 18 sub-themes.\nWe believe these can not only help inform future legal developments and\ninterpretations of Article 52, but also provide a starting point for\nHuman-Computer Interaction research to (re-)examine disclosure transparency\nfrom a human-centered AI lens.","updated":1710319233000,"published":1710171636000,"authors":["Abdallah El Ali","Karthikeya Puttur Venkatraj","Sophie Morosoli","Laurens Naudts","Natali Helberger","Pablo Cesar"],"comments":"Accepted to CHI 2024 Late-Breaking Work","categories":["cs.HC","cs.CY","H.5.m"],"primary_category":"cs.HC","doi":"10.1145\/3613905.3650750","journal_ref":null,"peer_reviewed":true,"reader_id":"rid1","human_jargon_term":"5W1H framework","definition_text":"The 5W1H framework is a methodical approach used to explore and understand problems or topics by asking six basic questions: Who, What, When, Where, Why, and How. This technique helps in breaking down and organizing information to make the analysis more comprehensive and effective.","model":"gpt4_abstract","Accuracy":"accurate","Ranking":0,"Notes":""},"195":{"arxiv_id":"2403.06823v2","url":"http:\/\/arxiv.org\/abs\/2403.06823v2","title":"Transparent AI Disclosure Obligations: Who, What, When, Where, Why, How","summary":"Advances in Generative Artificial Intelligence (AI) are resulting in\nAI-generated media output that is (nearly) indistinguishable from human-created\ncontent. This can drastically impact users and the media sector, especially\ngiven global risks of misinformation. While the currently discussed European AI\nAct aims at addressing these risks through Article 52's AI transparency\nobligations, its interpretation and implications remain unclear. In this early\nwork, we adopt a participatory AI approach to derive key questions based on\nArticle 52's disclosure obligations. We ran two workshops with researchers,\ndesigners, and engineers across disciplines (N=16), where participants\ndeconstructed Article 52's relevant clauses using the 5W1H framework. We\ncontribute a set of 149 questions clustered into five themes and 18 sub-themes.\nWe believe these can not only help inform future legal developments and\ninterpretations of Article 52, but also provide a starting point for\nHuman-Computer Interaction research to (re-)examine disclosure transparency\nfrom a human-centered AI lens.","updated":1710319233000,"published":1710171636000,"authors":["Abdallah El Ali","Karthikeya Puttur Venkatraj","Sophie Morosoli","Laurens Naudts","Natali Helberger","Pablo Cesar"],"comments":"Accepted to CHI 2024 Late-Breaking Work","categories":["cs.HC","cs.CY","H.5.m"],"primary_category":"cs.HC","doi":"10.1145\/3613905.3650750","journal_ref":null,"peer_reviewed":true,"reader_id":"rid1","human_jargon_term":"European AI Act","definition_text":"The European AI Act is a proposed set of regulations by the European Union aimed at managing the risks and impacts of Artificial Intelligence technologies across all member countries to ensure AI is used safely and transparently.","model":"gpt4_abstract","Accuracy":"accurate","Ranking":0,"Notes":""},"196":{"arxiv_id":"2402.09494v2","url":"http:\/\/arxiv.org\/abs\/2402.09494v2","title":"Can AI and humans genuinely communicate?","summary":"Can AI and humans genuinely communicate? In this article, after giving some\nbackground and motivating my proposal (sections 1 to 3), I explore a way to\nanswer this question that I call the \"mental-behavioral methodology\" (sections\n4 and 5). This methodology follows the following three steps: First, spell out\nwhat mental capacities are sufficient for human communication (as opposed to\ncommunication more generally). Second, spell out the experimental paradigms\nrequired to test whether a behavior exhibits these capacities. Third, apply or\nadapt these paradigms to test whether an AI displays the relevant behaviors. If\nthe first two steps are successfully completed, and if the AI passes the tests\nwith human-like results, this constitutes evidence that this AI and humans can\ngenuinely communicate. This mental-behavioral methodology has the advantage\nthat we don't need to understand the workings of black-box algorithms, such as\nstandard deep neural networks. This is comparable to the fact that we don't\nneed to understand how human brains work to know that humans can genuinely\ncommunicate. This methodology also has its disadvantages and I will discuss\nsome of them (section 6).","updated":1711384364000,"published":1707915640000,"authors":["Constant Bonard"],"comments":"March 2024 preprint","categories":["cs.HC","cs.AI"],"primary_category":"cs.HC","doi":null,"journal_ref":null,"peer_reviewed":true,"reader_id":"rid1","human_jargon_term":"mental-behavioral methodology","definition_text":"The mental-behavioral methodology is a three-step approach used to determine if artificial intelligence (AI) can truly communicate like humans. It involves defining the necessary mental abilities for human communication, designing experiments to test these abilities, and then applying these tests to AI to see if it behaves in a human-like way.","model":"gpt4_abstract","Accuracy":"accurate","Ranking":0,"Notes":""},"197":{"arxiv_id":"2403.06431v1","url":"http:\/\/arxiv.org\/abs\/2403.06431v1","title":"From Fitting Participation to Forging Relationships: The Art of\n  Participatory ML","summary":"Participatory machine learning (ML) encourages the inclusion of end users and\npeople affected by ML systems in design and development processes. We\ninterviewed 18 participation brokers -- individuals who facilitate such\ninclusion and transform the products of participants' labour into inputs for an\nML artefact or system -- across a range of organisational settings and project\nlocations. Our findings demonstrate the inherent challenges of integrating\nmessy contextual information generated through participation with the\nstructured data formats required by ML workflows and the uneven power dynamics\nin project contexts. We advocate for evolution in the role of brokers to more\nequitably balance value generated in Participatory ML projects for design and\ndevelopment teams with value created for participants. To move beyond `fitting'\nparticipation to existing processes and empower participants to envision\nalternative futures through ML, brokers must become educators and advocates for\nend users, while attending to frustration and dissent from indirect\nstakeholders.","updated":1710132274000,"published":1710132274000,"authors":["Ned Cooper","Alex Zafiroglu"],"comments":"To appear in Proceedings of the 2024 CHI Conference on Human Factors\n  in Computing Systems (CHI '24)","categories":["cs.HC","cs.CY"],"primary_category":"cs.HC","doi":null,"journal_ref":null,"peer_reviewed":true,"reader_id":"rid1","human_jargon_term":"Participatory machine learning","definition_text":"Participatory machine learning is an approach where not only the developers but also the users and people impacted by machine learning systems actively contribute ideas and inputs throughout the process of designing and developing the technology. This collaboration aims to ensure the technology works well for everyone it affects by incorporating their perspectives and needs.","model":"gpt4_abstract","Accuracy":"accurate","Ranking":0,"Notes":""},"198":{"arxiv_id":"2403.06034v1","url":"http:\/\/arxiv.org\/abs\/2403.06034v1","title":"Content Moderation Justice and Fairness on Social Media: Comparisons\n  Across Different Contexts and Platforms","summary":"Social media users may perceive moderation decisions by the platform\ndifferently, which can lead to frustration and dropout. This study investigates\nusers' perceived justice and fairness of online moderation decisions when they\nare exposed to various illegal versus legal scenarios, retributive versus\nrestorative moderation strategies, and user-moderated versus commercially\nmoderated platforms. We conduct an online experiment on 200 American social\nmedia users of Reddit and Twitter. Results show that retributive moderation\ndelivers higher justice and fairness for commercially moderated than for\nuser-moderated platforms in illegal violations; restorative moderation delivers\nhigher fairness for legal violations than illegal ones. We discuss the\nopportunities for platform policymaking to improve moderation system design.","updated":1710024606000,"published":1710024606000,"authors":["Jie Cai","Aashka Patel","Azadeh Naderi","Donghee Yvette Wohn"],"comments":"Accepted by CHI LBW 2024","categories":["cs.HC","cs.CY"],"primary_category":"cs.HC","doi":"10.1145\/3613905.3650882","journal_ref":null,"peer_reviewed":true,"reader_id":"rid1","human_jargon_term":"retributive versus restorative moderation strategies","definition_text":"Retributive moderation strategies involve penalizing users for their misbehavior, typically by banning or suspending them, emphasizing punishment for the wrongdoing. In contrast, restorative moderation strategies focus on resolving conflicts and mending relationships, involving actions like encouraging apologies or discussions between users to address and resolve issues.","model":"gpt4_abstract","Accuracy":"accurate","Ranking":2,"Notes":""},"199":{"arxiv_id":"2403.06651v1","url":"http:\/\/arxiv.org\/abs\/2403.06651v1","title":"SoniWeight Shoes: Investigating Effects and Personalization of a\n  Wearable Sound Device for Altering Body Perception and Behavior","summary":"Changes in body perception influence behavior and emotion and can be induced\nthrough multisensory feedback. Auditory feedback to one's actions can trigger\nsuch alterations; however, it is unclear which individual factors modulate\nthese effects. We employ and evaluate SoniWeight Shoes, a wearable device based\non literature for altering one's weight perception through manipulated footstep\nsounds. In a healthy population sample across a spectrum of individuals (n=84)\nwith varying degrees of eating disorder symptomatology, physical activity\nlevels, body concerns, and mental imagery capacities, we explore the effects of\nthree sound conditions (low-frequency, high-frequency and control) on extensive\nbody perception measures (demographic, behavioral, physiological,\npsychological, and subjective). Analyses revealed an impact of individual\ndifferences in each of these dimensions. Besides replicating previous findings,\nwe reveal and highlight the role of individual differences in body perception,\noffering avenues for personalized sonification strategies. Datasets, technical\nrefinements, and novel body map quantification tools are provided.","updated":1710159374000,"published":1710159374000,"authors":["A. D'Adamo","M. Roel-Lesur","L. Turmo-Vidal","M. M. Dehshibi","D. De La Prida","J. R. Diaz-Duran","L. A. Azpicueta-Ruiz","A. V\u00e4ljam\u00e4e","A. Tajadura-Jim\u00e9nez"],"comments":"Conditionally Accepted in CHI '24 Conference","categories":["cs.HC"],"primary_category":"cs.HC","doi":"10.1145\/3613904.3642651","journal_ref":null,"peer_reviewed":true,"reader_id":"rid1","human_jargon_term":"SoniWeight Shoes","definition_text":"SoniWeight Shoes are wearable devices designed to change a person's perception of their body weight by altering the sounds their footsteps make. These shoes use different sound frequencies to potentially influence how heavy or light someone feels.","model":"gpt4_abstract","Accuracy":"accurate","Ranking":2,"Notes":""},"200":{"arxiv_id":"2403.06651v1","url":"http:\/\/arxiv.org\/abs\/2403.06651v1","title":"SoniWeight Shoes: Investigating Effects and Personalization of a\n  Wearable Sound Device for Altering Body Perception and Behavior","summary":"Changes in body perception influence behavior and emotion and can be induced\nthrough multisensory feedback. Auditory feedback to one's actions can trigger\nsuch alterations; however, it is unclear which individual factors modulate\nthese effects. We employ and evaluate SoniWeight Shoes, a wearable device based\non literature for altering one's weight perception through manipulated footstep\nsounds. In a healthy population sample across a spectrum of individuals (n=84)\nwith varying degrees of eating disorder symptomatology, physical activity\nlevels, body concerns, and mental imagery capacities, we explore the effects of\nthree sound conditions (low-frequency, high-frequency and control) on extensive\nbody perception measures (demographic, behavioral, physiological,\npsychological, and subjective). Analyses revealed an impact of individual\ndifferences in each of these dimensions. Besides replicating previous findings,\nwe reveal and highlight the role of individual differences in body perception,\noffering avenues for personalized sonification strategies. Datasets, technical\nrefinements, and novel body map quantification tools are provided.","updated":1710159374000,"published":1710159374000,"authors":["A. D'Adamo","M. Roel-Lesur","L. Turmo-Vidal","M. M. Dehshibi","D. De La Prida","J. R. Diaz-Duran","L. A. Azpicueta-Ruiz","A. V\u00e4ljam\u00e4e","A. Tajadura-Jim\u00e9nez"],"comments":"Conditionally Accepted in CHI '24 Conference","categories":["cs.HC"],"primary_category":"cs.HC","doi":"10.1145\/3613904.3642651","journal_ref":null,"peer_reviewed":true,"reader_id":"rid1","human_jargon_term":"multisensory feedback","definition_text":"Multisensory feedback refers to the process where input from various senses (like sight, touch, hearing) is combined to influence one's perception or behavior. For example, seeing a visual and hearing a corresponding sound simultaneously can alter what and how one perceives an event or environment.","model":"gpt4_abstract","Accuracy":"accurate","Ranking":0,"Notes":""},"201":{"arxiv_id":"2403.08041v1","url":"http:\/\/arxiv.org\/abs\/2403.08041v1","title":"What would Plato say? Concepts and notions from Greek philosophy applied\n  to gamification mechanics for a meaningful and ethical gamification","summary":"Gamification, the integration of game mechanics in non-game settings, has\nbecome increasingly prevalent in various digital platforms; however, its\nethical and societal impacts are often overlooked. This paper delves into how\nPlatonic and Aristotelian philosophies can provide a critical framework for\nunderstanding and evaluating the ethical dimensions of gamification. Plato's\nallegory of the cave and theory of forms are used to analyse the perception of\nreality in gamified environments, questioning their authenticity and the value\nof virtual achievements, while Aristotle's virtue ethics, with its emphasis on\nmoderation, virtue, and eudaimonia (true and full happiness), can help assess\nhow gamification influences user behaviour and ethical decision-making. The\npaper critically examines various gamification elements, such as the hero's\njourney, altruistic actions, badge levels, and user autonomy, through these\nphilosophical lenses, and addresses the ethical responsibilities of\ngamification designers, advocating for a balanced approach that prioritizes\nuser well-being and ethical development over commercial interests. By bridging\nancient philosophical insights with modern digital culture, this research\ncontributes to a deeper understanding of the ethical implications of\ngamification, emphasizing the need for responsible and virtuous design in\ndigital applications.","updated":1710271513000,"published":1710271513000,"authors":["Kostas Karpouzis"],"comments":"Accepted for presentation at GamiFIN 2024","categories":["cs.HC"],"primary_category":"cs.HC","doi":null,"journal_ref":null,"peer_reviewed":true,"reader_id":"rid1","human_jargon_term":"Gamification","definition_text":"Gamification refers to the practice of applying elements typically found in games, such as scoring points, competing with others, and earning rewards, to non-game environments like apps and websites to increase engagement or motivate specific behaviors.","model":"gpt4_abstract","Accuracy":"accurate","Ranking":0,"Notes":""},"202":{"arxiv_id":"2403.08041v1","url":"http:\/\/arxiv.org\/abs\/2403.08041v1","title":"What would Plato say? Concepts and notions from Greek philosophy applied\n  to gamification mechanics for a meaningful and ethical gamification","summary":"Gamification, the integration of game mechanics in non-game settings, has\nbecome increasingly prevalent in various digital platforms; however, its\nethical and societal impacts are often overlooked. This paper delves into how\nPlatonic and Aristotelian philosophies can provide a critical framework for\nunderstanding and evaluating the ethical dimensions of gamification. Plato's\nallegory of the cave and theory of forms are used to analyse the perception of\nreality in gamified environments, questioning their authenticity and the value\nof virtual achievements, while Aristotle's virtue ethics, with its emphasis on\nmoderation, virtue, and eudaimonia (true and full happiness), can help assess\nhow gamification influences user behaviour and ethical decision-making. The\npaper critically examines various gamification elements, such as the hero's\njourney, altruistic actions, badge levels, and user autonomy, through these\nphilosophical lenses, and addresses the ethical responsibilities of\ngamification designers, advocating for a balanced approach that prioritizes\nuser well-being and ethical development over commercial interests. By bridging\nancient philosophical insights with modern digital culture, this research\ncontributes to a deeper understanding of the ethical implications of\ngamification, emphasizing the need for responsible and virtuous design in\ndigital applications.","updated":1710271513000,"published":1710271513000,"authors":["Kostas Karpouzis"],"comments":"Accepted for presentation at GamiFIN 2024","categories":["cs.HC"],"primary_category":"cs.HC","doi":null,"journal_ref":null,"peer_reviewed":true,"reader_id":"rid1","human_jargon_term":"Platonic and Aristotelian philosophies","definition_text":"Platonic and Aristotelian philosophies refer to the teachings of the ancient Greek philosophers Plato and Aristotle, respectively. Plato's philosophy often explores ideals and perfect forms, whereas Aristotle's teachings focus on practical ethics, the pursuit of virtue, and achieving happiness through living a balanced life.","model":"gpt4_abstract","Accuracy":"accurate","Ranking":2,"Notes":""},"203":{"arxiv_id":"2403.08041v1","url":"http:\/\/arxiv.org\/abs\/2403.08041v1","title":"What would Plato say? Concepts and notions from Greek philosophy applied\n  to gamification mechanics for a meaningful and ethical gamification","summary":"Gamification, the integration of game mechanics in non-game settings, has\nbecome increasingly prevalent in various digital platforms; however, its\nethical and societal impacts are often overlooked. This paper delves into how\nPlatonic and Aristotelian philosophies can provide a critical framework for\nunderstanding and evaluating the ethical dimensions of gamification. Plato's\nallegory of the cave and theory of forms are used to analyse the perception of\nreality in gamified environments, questioning their authenticity and the value\nof virtual achievements, while Aristotle's virtue ethics, with its emphasis on\nmoderation, virtue, and eudaimonia (true and full happiness), can help assess\nhow gamification influences user behaviour and ethical decision-making. The\npaper critically examines various gamification elements, such as the hero's\njourney, altruistic actions, badge levels, and user autonomy, through these\nphilosophical lenses, and addresses the ethical responsibilities of\ngamification designers, advocating for a balanced approach that prioritizes\nuser well-being and ethical development over commercial interests. By bridging\nancient philosophical insights with modern digital culture, this research\ncontributes to a deeper understanding of the ethical implications of\ngamification, emphasizing the need for responsible and virtuous design in\ndigital applications.","updated":1710271513000,"published":1710271513000,"authors":["Kostas Karpouzis"],"comments":"Accepted for presentation at GamiFIN 2024","categories":["cs.HC"],"primary_category":"cs.HC","doi":null,"journal_ref":null,"peer_reviewed":true,"reader_id":"rid1","human_jargon_term":"altruistic actions","definition_text":"Altruistic actions refer to behaviors motivated by a genuine desire to help others, without seeking any personal gain or benefit from those actions. In the context of gamification, this might involve players performing tasks that directly benefit other players or contribute positively to the community within the game.","model":"gpt4_abstract","Accuracy":"accurate","Ranking":1,"Notes":""},"204":{"arxiv_id":"2403.08041v1","url":"http:\/\/arxiv.org\/abs\/2403.08041v1","title":"What would Plato say? Concepts and notions from Greek philosophy applied\n  to gamification mechanics for a meaningful and ethical gamification","summary":"Gamification, the integration of game mechanics in non-game settings, has\nbecome increasingly prevalent in various digital platforms; however, its\nethical and societal impacts are often overlooked. This paper delves into how\nPlatonic and Aristotelian philosophies can provide a critical framework for\nunderstanding and evaluating the ethical dimensions of gamification. Plato's\nallegory of the cave and theory of forms are used to analyse the perception of\nreality in gamified environments, questioning their authenticity and the value\nof virtual achievements, while Aristotle's virtue ethics, with its emphasis on\nmoderation, virtue, and eudaimonia (true and full happiness), can help assess\nhow gamification influences user behaviour and ethical decision-making. The\npaper critically examines various gamification elements, such as the hero's\njourney, altruistic actions, badge levels, and user autonomy, through these\nphilosophical lenses, and addresses the ethical responsibilities of\ngamification designers, advocating for a balanced approach that prioritizes\nuser well-being and ethical development over commercial interests. By bridging\nancient philosophical insights with modern digital culture, this research\ncontributes to a deeper understanding of the ethical implications of\ngamification, emphasizing the need for responsible and virtuous design in\ndigital applications.","updated":1710271513000,"published":1710271513000,"authors":["Kostas Karpouzis"],"comments":"Accepted for presentation at GamiFIN 2024","categories":["cs.HC"],"primary_category":"cs.HC","doi":null,"journal_ref":null,"peer_reviewed":true,"reader_id":"rid1","human_jargon_term":"eudaimonia","definition_text":"Eudaimonia is a term from ancient Greek philosophy that refers to the highest state of human happiness and fulfillment, often linked with living a life of virtue and achieving one's true potential.","model":"gpt4_abstract","Accuracy":"accurate","Ranking":2,"Notes":""},"205":{"arxiv_id":"2403.08041v1","url":"http:\/\/arxiv.org\/abs\/2403.08041v1","title":"What would Plato say? Concepts and notions from Greek philosophy applied\n  to gamification mechanics for a meaningful and ethical gamification","summary":"Gamification, the integration of game mechanics in non-game settings, has\nbecome increasingly prevalent in various digital platforms; however, its\nethical and societal impacts are often overlooked. This paper delves into how\nPlatonic and Aristotelian philosophies can provide a critical framework for\nunderstanding and evaluating the ethical dimensions of gamification. Plato's\nallegory of the cave and theory of forms are used to analyse the perception of\nreality in gamified environments, questioning their authenticity and the value\nof virtual achievements, while Aristotle's virtue ethics, with its emphasis on\nmoderation, virtue, and eudaimonia (true and full happiness), can help assess\nhow gamification influences user behaviour and ethical decision-making. The\npaper critically examines various gamification elements, such as the hero's\njourney, altruistic actions, badge levels, and user autonomy, through these\nphilosophical lenses, and addresses the ethical responsibilities of\ngamification designers, advocating for a balanced approach that prioritizes\nuser well-being and ethical development over commercial interests. By bridging\nancient philosophical insights with modern digital culture, this research\ncontributes to a deeper understanding of the ethical implications of\ngamification, emphasizing the need for responsible and virtuous design in\ndigital applications.","updated":1710271513000,"published":1710271513000,"authors":["Kostas Karpouzis"],"comments":"Accepted for presentation at GamiFIN 2024","categories":["cs.HC"],"primary_category":"cs.HC","doi":null,"journal_ref":null,"peer_reviewed":true,"reader_id":"rid1","human_jargon_term":"moderation","definition_text":"Moderation refers to the practice of avoiding extremes, instead aiming for a balanced or middle-ground approach in actions and decisions. It involves regulating behavior or activities to not exceed limits deemed reasonable or healthy.","model":"gpt4_abstract","Accuracy":"accurate","Ranking":1,"Notes":""},"206":{"arxiv_id":"2403.12344v1","url":"http:\/\/arxiv.org\/abs\/2403.12344v1","title":"Human Factors in Space Exploration: Opportunities for International and\n  Interdisciplinary Collaboration","summary":"As humanity pushes the boundaries of space exploration, human factors\nresearch becomes more important. Human factors encompass a broad spectrum of\npsychological, physiological, and ergonomic factors that affect human\nperformance, well-being, and safety in the unique and challenging space\nenvironment. This panel explores the multifaceted field of human factors in\nspace exploration and highlights the opportunities that lie in fostering\ninternational and interdisciplinary cooperation. This exploration delves into\nthe current state of research on human factors in space missions, addressing\nthe physiological and psychological challenges astronauts face during long\nspace flights. It emphasizes the importance of interdisciplinary collaboration,\ncombining knowledge from fields such as psychology, medicine, engineering, and\ndesign to address the complex interaction of factors affecting human\nperformance and adaptation to the space environment","updated":1710811635000,"published":1710811635000,"authors":["Wies\u0142aw Kope\u0107","Grzegorz Pochwatko","Monika Kornacka","Wiktor Stawski","Maciej Grzeszczuk","Kinga Skorupska","Barbara Karpowicz","Rafa\u0142 Mas\u0142yk","Pavlo Zinevych","Stanis\u0142aw Knapi\u0144ski","Steven Barnes","Cezary Biele"],"comments":"13 pages including bibliography, 4 figures. To be published by\n  Springer as MIDI 2023 Conference proceedings","categories":["cs.HC"],"primary_category":"cs.HC","doi":null,"journal_ref":null,"peer_reviewed":true,"reader_id":"rid1","human_jargon_term":"ergonomic","definition_text":"Ergonomic refers to the design and arrangement of things people use so that the users interact with these things in the safest, most comfortable, and efficient way possible.","model":"gpt4_abstract","Accuracy":"accurate","Ranking":2,"Notes":""},"207":{"arxiv_id":"2403.19436v1","url":"http:\/\/arxiv.org\/abs\/2403.19436v1","title":"\"At the end of the day, I am accountable\": Gig Workers' Self-Tracking\n  for Multi-Dimensional Accountability Management","summary":"Tracking is inherent in and central to the gig economy. Platforms track gig\nworkers' performance through metrics such as acceptance rate and punctuality,\nwhile gig workers themselves engage in self-tracking. Although prior research\nhas extensively examined how gig platforms track workers through metrics --\nwith some studies briefly acknowledging the phenomenon of self-tracking among\nworkers -- there is a dearth of studies that explore how and why gig workers\ntrack themselves. To address this, we conducted 25 semi-structured interviews,\nrevealing how gig workers self-tracking to manage accountabilities to\nthemselves and external entities across three identities: the holistic self,\nthe entrepreneurial self, and the platformized self. We connect our findings to\nneoliberalism, through which we contextualize gig workers' self-accountability\nand the invisible labor of self-tracking. We further discuss how self-tracking\nmitigates information and power asymmetries in gig work and offer design\nimplications to support gig workers' multi-dimensional self-tracking.","updated":1711634670000,"published":1711634670000,"authors":["Rie Helene Hernandez","Qiurong Song","Yubo Kou","Xinning Gui"],"comments":"Accepted to CHI 2024","categories":["cs.HC"],"primary_category":"cs.HC","doi":null,"journal_ref":null,"peer_reviewed":true,"reader_id":"rid1","human_jargon_term":"dearthneoliberalism","definition_text":"The term \"dearth\" refers to a scarcity or lack of something. When the abstract mentions a \"dearth of studies,\" it indicates that there are very few studies or insufficient research on the topic being discussed. \"Neoliberalism\" is an economic and political ideology that emphasizes the importance of free-market capitalism, minimal government intervention in the economy, and individual self-reliance.","model":"gpt4_abstract","Accuracy":"accurate","Ranking":1,"Notes":""},"208":{"arxiv_id":"2403.19436v1","url":"http:\/\/arxiv.org\/abs\/2403.19436v1","title":"\"At the end of the day, I am accountable\": Gig Workers' Self-Tracking\n  for Multi-Dimensional Accountability Management","summary":"Tracking is inherent in and central to the gig economy. Platforms track gig\nworkers' performance through metrics such as acceptance rate and punctuality,\nwhile gig workers themselves engage in self-tracking. Although prior research\nhas extensively examined how gig platforms track workers through metrics --\nwith some studies briefly acknowledging the phenomenon of self-tracking among\nworkers -- there is a dearth of studies that explore how and why gig workers\ntrack themselves. To address this, we conducted 25 semi-structured interviews,\nrevealing how gig workers self-tracking to manage accountabilities to\nthemselves and external entities across three identities: the holistic self,\nthe entrepreneurial self, and the platformized self. We connect our findings to\nneoliberalism, through which we contextualize gig workers' self-accountability\nand the invisible labor of self-tracking. We further discuss how self-tracking\nmitigates information and power asymmetries in gig work and offer design\nimplications to support gig workers' multi-dimensional self-tracking.","updated":1711634670000,"published":1711634670000,"authors":["Rie Helene Hernandez","Qiurong Song","Yubo Kou","Xinning Gui"],"comments":"Accepted to CHI 2024","categories":["cs.HC"],"primary_category":"cs.HC","doi":null,"journal_ref":null,"peer_reviewed":true,"reader_id":"rid1","human_jargon_term":"gig economy","definition_text":"The gig economy refers to a labor market characterized by the prevalence of short-term contracts or freelance work, as opposed to permanent jobs, where workers often use apps or platforms to find quick, individual gigs such as driving for ride-sharing services or performing tasks for online freelance marketplaces. This setup allows people to work flexible hours, choosing when and where they complete tasks, often across multiple jobs or projects.","model":"gpt4_abstract","Accuracy":"accurate","Ranking":0,"Notes":""},"209":{"arxiv_id":"2401.10838v2","url":"http:\/\/arxiv.org\/abs\/2401.10838v2","title":"Rambler: Supporting Writing With Speech via LLM-Assisted Gist\n  Manipulation","summary":"Dictation enables efficient text input on mobile devices. However, writing\nwith speech can produce disfluent, wordy, and incoherent text and thus requires\nheavy post-processing. This paper presents Rambler, an LLM-powered graphical\nuser interface that supports gist-level manipulation of dictated text with two\nmain sets of functions: gist extraction and macro revision. Gist extraction\ngenerates keywords and summaries as anchors to support the review and\ninteraction with spoken text. LLM-assisted macro revisions allow users to\nrespeak, split, merge and transform dictated text without specifying precise\nediting locations. Together they pave the way for interactive dictation and\nrevision that help close gaps between spontaneous spoken words and\nwell-structured writing. In a comparative study with 12 participants performing\nverbal composition tasks, Rambler outperformed the baseline of a speech-to-text\neditor + ChatGPT, as it better facilitates iterative revisions with enhanced\nuser control over the content while supporting surprisingly diverse user\nstrategies.","updated":1709865965000,"published":1705685996000,"authors":["Susan Lin","Jeremy Warner","J. D. Zamfirescu-Pereira","Matthew G. Lee","Sauhard Jain","Michael Xuelin Huang","Piyawat Lertvittayakumjorn","Shanqing Cai","Shumin Zhai","Bj\u00f6rn Hartmann","Can Liu"],"comments":"To appear at ACM CHI 2024","categories":["cs.HC"],"primary_category":"cs.HC","doi":"10.1145\/3613904.3642217","journal_ref":null,"peer_reviewed":true,"reader_id":"rid1","human_jargon_term":"Rambler","definition_text":"Rambler is a graphical user interface designed for editing dictated text, which helps users easily make broad changes such as extracting key points, summarizing, and reorganizing spoken text to improve its clarity and coherence.","model":"gpt4_abstract","Accuracy":"accurate","Ranking":-1,"Notes":""},"210":{"arxiv_id":"2401.10838v2","url":"http:\/\/arxiv.org\/abs\/2401.10838v2","title":"Rambler: Supporting Writing With Speech via LLM-Assisted Gist\n  Manipulation","summary":"Dictation enables efficient text input on mobile devices. However, writing\nwith speech can produce disfluent, wordy, and incoherent text and thus requires\nheavy post-processing. This paper presents Rambler, an LLM-powered graphical\nuser interface that supports gist-level manipulation of dictated text with two\nmain sets of functions: gist extraction and macro revision. Gist extraction\ngenerates keywords and summaries as anchors to support the review and\ninteraction with spoken text. LLM-assisted macro revisions allow users to\nrespeak, split, merge and transform dictated text without specifying precise\nediting locations. Together they pave the way for interactive dictation and\nrevision that help close gaps between spontaneous spoken words and\nwell-structured writing. In a comparative study with 12 participants performing\nverbal composition tasks, Rambler outperformed the baseline of a speech-to-text\neditor + ChatGPT, as it better facilitates iterative revisions with enhanced\nuser control over the content while supporting surprisingly diverse user\nstrategies.","updated":1709865965000,"published":1705685996000,"authors":["Susan Lin","Jeremy Warner","J. D. Zamfirescu-Pereira","Matthew G. Lee","Sauhard Jain","Michael Xuelin Huang","Piyawat Lertvittayakumjorn","Shanqing Cai","Shumin Zhai","Bj\u00f6rn Hartmann","Can Liu"],"comments":"To appear at ACM CHI 2024","categories":["cs.HC"],"primary_category":"cs.HC","doi":"10.1145\/3613904.3642217","journal_ref":null,"peer_reviewed":true,"reader_id":"rid1","human_jargon_term":"gist extraction and macro revision","definition_text":"Gist extraction refers to the process of identifying and extracting the main points or keywords from spoken text to make reviewing and editing easier. Macro revision involves making larger changes to the text, such as restructuring or combining sentences, to improve clarity and coherence without the need to pinpoint specific locations for edits.","model":"gpt4_abstract","Accuracy":"accurate","Ranking":0,"Notes":""},"211":{"arxiv_id":"2401.10838v2","url":"http:\/\/arxiv.org\/abs\/2401.10838v2","title":"Rambler: Supporting Writing With Speech via LLM-Assisted Gist\n  Manipulation","summary":"Dictation enables efficient text input on mobile devices. However, writing\nwith speech can produce disfluent, wordy, and incoherent text and thus requires\nheavy post-processing. This paper presents Rambler, an LLM-powered graphical\nuser interface that supports gist-level manipulation of dictated text with two\nmain sets of functions: gist extraction and macro revision. Gist extraction\ngenerates keywords and summaries as anchors to support the review and\ninteraction with spoken text. LLM-assisted macro revisions allow users to\nrespeak, split, merge and transform dictated text without specifying precise\nediting locations. Together they pave the way for interactive dictation and\nrevision that help close gaps between spontaneous spoken words and\nwell-structured writing. In a comparative study with 12 participants performing\nverbal composition tasks, Rambler outperformed the baseline of a speech-to-text\neditor + ChatGPT, as it better facilitates iterative revisions with enhanced\nuser control over the content while supporting surprisingly diverse user\nstrategies.","updated":1709865965000,"published":1705685996000,"authors":["Susan Lin","Jeremy Warner","J. D. Zamfirescu-Pereira","Matthew G. Lee","Sauhard Jain","Michael Xuelin Huang","Piyawat Lertvittayakumjorn","Shanqing Cai","Shumin Zhai","Bj\u00f6rn Hartmann","Can Liu"],"comments":"To appear at ACM CHI 2024","categories":["cs.HC"],"primary_category":"cs.HC","doi":"10.1145\/3613904.3642217","journal_ref":null,"peer_reviewed":true,"reader_id":"rid1","human_jargon_term":"gist-level manipulation","definition_text":"Gist-level manipulation refers to the process of editing and refining a text by focusing on its main ideas or core messages, rather than adjusting each word or phrase individually. This enables users to modify the overall content and structure of their text efficiently, ensuring it conveys the intended meaning more clearly.","model":"gpt4_abstract","Accuracy":"accurate","Ranking":0,"Notes":""},"212":{"arxiv_id":"2403.16018v1","url":"http:\/\/arxiv.org\/abs\/2403.16018v1","title":"Understanding the Impact of Referent Design on Scale Perception in\n  Immersive Data Visualization","summary":"Referents are often used to enhance scale perception in immersive\nvisualizations. Common referent designs include the considerations of referent\nlayout (side-by-side vs. in-situ) and referent size (small vs. medium vs.\nlarge). This paper introduces a controlled user study to assess how different\nreferent designs affect the efficiency and accuracy of scale perception across\ndifferent data scales, on the performance of the size-matching task in the\nvirtual environment. Our results reveal that in-situ layouts significantly\nenhance accuracy and confidence across various data scales, particularly with\nlarge referents. Linear regression analyses further confirm that in-situ\nlayouts exhibit greater resilience to changes in data scale. For tasks\nrequiring efficiency, medium-sized referents emerge as the preferred choice.\nBased on these findings, we offer design guidelines for selecting referent\nlayouts and sizes in immersive visualizations.","updated":1711258709000,"published":1711258709000,"authors":["Yihan Hou","Hao Cui","Rongrong Chen","Wei Zeng"],"comments":"7 pages, 6 figures, Accepted to Extended Abstracts of the CHI\n  Conference on Human Factors in Computing Systems (CHI EA '24)","categories":["cs.HC"],"primary_category":"cs.HC","doi":"10.1145\/3613905.3650783","journal_ref":null,"peer_reviewed":true,"reader_id":"rid1","human_jargon_term":"Referents","definition_text":"Referents in the context of immersive visualizations are objects or elements used as comparison standards to help people better understand the size or scale of the data they are viewing. These referents can be placed next to each other or directly within the data presentation and come in various sizes to improve a viewer's perception and judgment of the data displayed.","model":"gpt4_abstract","Accuracy":"accurate","Ranking":0,"Notes":""},"213":{"arxiv_id":"2403.16018v1","url":"http:\/\/arxiv.org\/abs\/2403.16018v1","title":"Understanding the Impact of Referent Design on Scale Perception in\n  Immersive Data Visualization","summary":"Referents are often used to enhance scale perception in immersive\nvisualizations. Common referent designs include the considerations of referent\nlayout (side-by-side vs. in-situ) and referent size (small vs. medium vs.\nlarge). This paper introduces a controlled user study to assess how different\nreferent designs affect the efficiency and accuracy of scale perception across\ndifferent data scales, on the performance of the size-matching task in the\nvirtual environment. Our results reveal that in-situ layouts significantly\nenhance accuracy and confidence across various data scales, particularly with\nlarge referents. Linear regression analyses further confirm that in-situ\nlayouts exhibit greater resilience to changes in data scale. For tasks\nrequiring efficiency, medium-sized referents emerge as the preferred choice.\nBased on these findings, we offer design guidelines for selecting referent\nlayouts and sizes in immersive visualizations.","updated":1711258709000,"published":1711258709000,"authors":["Yihan Hou","Hao Cui","Rongrong Chen","Wei Zeng"],"comments":"7 pages, 6 figures, Accepted to Extended Abstracts of the CHI\n  Conference on Human Factors in Computing Systems (CHI EA '24)","categories":["cs.HC"],"primary_category":"cs.HC","doi":"10.1145\/3613905.3650783","journal_ref":null,"peer_reviewed":true,"reader_id":"rid1","human_jargon_term":"in-situ","definition_text":"The term \"in-situ\" refers to arranging objects or elements within their natural or original context, directly in the environment where they are normally found or used. In the context of virtual environments, this means placing reference objects directly within the scene being viewed, as opposed to positioning them separately or off to the side.","model":"gpt4_abstract","Accuracy":"accurate","Ranking":1,"Notes":""},"214":{"arxiv_id":"2403.16018v1","url":"http:\/\/arxiv.org\/abs\/2403.16018v1","title":"Understanding the Impact of Referent Design on Scale Perception in\n  Immersive Data Visualization","summary":"Referents are often used to enhance scale perception in immersive\nvisualizations. Common referent designs include the considerations of referent\nlayout (side-by-side vs. in-situ) and referent size (small vs. medium vs.\nlarge). This paper introduces a controlled user study to assess how different\nreferent designs affect the efficiency and accuracy of scale perception across\ndifferent data scales, on the performance of the size-matching task in the\nvirtual environment. Our results reveal that in-situ layouts significantly\nenhance accuracy and confidence across various data scales, particularly with\nlarge referents. Linear regression analyses further confirm that in-situ\nlayouts exhibit greater resilience to changes in data scale. For tasks\nrequiring efficiency, medium-sized referents emerge as the preferred choice.\nBased on these findings, we offer design guidelines for selecting referent\nlayouts and sizes in immersive visualizations.","updated":1711258709000,"published":1711258709000,"authors":["Yihan Hou","Hao Cui","Rongrong Chen","Wei Zeng"],"comments":"7 pages, 6 figures, Accepted to Extended Abstracts of the CHI\n  Conference on Human Factors in Computing Systems (CHI EA '24)","categories":["cs.HC"],"primary_category":"cs.HC","doi":"10.1145\/3613905.3650783","journal_ref":null,"peer_reviewed":true,"reader_id":"rid1","human_jargon_term":"side-by-side","definition_text":"The term \"side-by-side\" refers to arranging objects or elements next to each other, usually in the same line of sight, so that they can be easily compared or assessed simultaneously.","model":"gpt4_abstract","Accuracy":"accurate","Ranking":0,"Notes":""},"215":{"arxiv_id":"2403.03822v1","url":"http:\/\/arxiv.org\/abs\/2403.03822v1","title":"HoLens: A Visual Analytics Design for Higher-order Movement Modeling and\n  Visualization","summary":"Higher-order patterns reveal sequential multistep state transitions, which\nare usually superior to origin-destination analysis, which depicts only\nfirst-order geospatial movement patterns. Conventional methods for higher-order\nmovement modeling first construct a directed acyclic graph (DAG) of movements,\nthen extract higher-order patterns from the DAG. However, DAG-based methods\nheavily rely on the identification of movement keypoints that are challenging\nfor sparse movements and fail to consider the temporal variants that are\ncritical for movements in urban environments. To overcome the limitations, we\npropose HoLens, a novel approach for modeling and visualizing higher-order\nmovement patterns in the context of an urban environment. HoLens mainly makes\ntwofold contributions: first, we design an auto-adaptive movement aggregation\nalgorithm that self-organizes movements hierarchically by considering spatial\nproximity, contextual information, and temporal variability; second, we develop\nan interactive visual analytics interface consisting of well-established\nvisualization techniques, including the H-Flow for visualizing the higher-order\npatterns on the map and the higher-order state sequence chart for representing\nthe higher-order state transitions. Two real-world case studies manifest that\nthe method can adaptively aggregate the data and exhibit the process of how to\nexplore the higher-order patterns by HoLens. We also demonstrate our approach's\nfeasibility, usability, and effectiveness through an expert interview with\nthree domain experts.","updated":1709741331000,"published":1709741331000,"authors":["Zezheng Feng","Fang Zhu","Hongjun Wang","Jianing Hao","ShuangHua Yang","Wei Zeng","Huamin Qu"],"comments":"20 pages, 18 figures, is accepted by computational visual media\n  journal","categories":["cs.HC"],"primary_category":"cs.HC","doi":null,"journal_ref":null,"peer_reviewed":true,"reader_id":"rid1","human_jargon_term":"H-Flow","definition_text":"The H-Flow in the context of the scientific abstract refers to a visualization technique used to display higher-order movement patterns on a map. It helps in visually representing complex movement sequences and transitions, making it easier to understand and analyze patterns in urban environments.","model":"gpt4_abstract","Accuracy":"accurate","Ranking":1,"Notes":""},"216":{"arxiv_id":"2403.03822v1","url":"http:\/\/arxiv.org\/abs\/2403.03822v1","title":"HoLens: A Visual Analytics Design for Higher-order Movement Modeling and\n  Visualization","summary":"Higher-order patterns reveal sequential multistep state transitions, which\nare usually superior to origin-destination analysis, which depicts only\nfirst-order geospatial movement patterns. Conventional methods for higher-order\nmovement modeling first construct a directed acyclic graph (DAG) of movements,\nthen extract higher-order patterns from the DAG. However, DAG-based methods\nheavily rely on the identification of movement keypoints that are challenging\nfor sparse movements and fail to consider the temporal variants that are\ncritical for movements in urban environments. To overcome the limitations, we\npropose HoLens, a novel approach for modeling and visualizing higher-order\nmovement patterns in the context of an urban environment. HoLens mainly makes\ntwofold contributions: first, we design an auto-adaptive movement aggregation\nalgorithm that self-organizes movements hierarchically by considering spatial\nproximity, contextual information, and temporal variability; second, we develop\nan interactive visual analytics interface consisting of well-established\nvisualization techniques, including the H-Flow for visualizing the higher-order\npatterns on the map and the higher-order state sequence chart for representing\nthe higher-order state transitions. Two real-world case studies manifest that\nthe method can adaptively aggregate the data and exhibit the process of how to\nexplore the higher-order patterns by HoLens. We also demonstrate our approach's\nfeasibility, usability, and effectiveness through an expert interview with\nthree domain experts.","updated":1709741331000,"published":1709741331000,"authors":["Zezheng Feng","Fang Zhu","Hongjun Wang","Jianing Hao","ShuangHua Yang","Wei Zeng","Huamin Qu"],"comments":"20 pages, 18 figures, is accepted by computational visual media\n  journal","categories":["cs.HC"],"primary_category":"cs.HC","doi":null,"journal_ref":null,"peer_reviewed":true,"reader_id":"rid1","human_jargon_term":"HoLens","definition_text":"HoLens is a new tool designed to analyze and display complex patterns of movement in city environments. It organizes movement data based on location closeness, relevant surrounding information, and time changes, and uses visual tools to show these patterns and their development over time.","model":"gpt4_abstract","Accuracy":"accurate","Ranking":1,"Notes":""},"217":{"arxiv_id":"2403.03822v1","url":"http:\/\/arxiv.org\/abs\/2403.03822v1","title":"HoLens: A Visual Analytics Design for Higher-order Movement Modeling and\n  Visualization","summary":"Higher-order patterns reveal sequential multistep state transitions, which\nare usually superior to origin-destination analysis, which depicts only\nfirst-order geospatial movement patterns. Conventional methods for higher-order\nmovement modeling first construct a directed acyclic graph (DAG) of movements,\nthen extract higher-order patterns from the DAG. However, DAG-based methods\nheavily rely on the identification of movement keypoints that are challenging\nfor sparse movements and fail to consider the temporal variants that are\ncritical for movements in urban environments. To overcome the limitations, we\npropose HoLens, a novel approach for modeling and visualizing higher-order\nmovement patterns in the context of an urban environment. HoLens mainly makes\ntwofold contributions: first, we design an auto-adaptive movement aggregation\nalgorithm that self-organizes movements hierarchically by considering spatial\nproximity, contextual information, and temporal variability; second, we develop\nan interactive visual analytics interface consisting of well-established\nvisualization techniques, including the H-Flow for visualizing the higher-order\npatterns on the map and the higher-order state sequence chart for representing\nthe higher-order state transitions. Two real-world case studies manifest that\nthe method can adaptively aggregate the data and exhibit the process of how to\nexplore the higher-order patterns by HoLens. We also demonstrate our approach's\nfeasibility, usability, and effectiveness through an expert interview with\nthree domain experts.","updated":1709741331000,"published":1709741331000,"authors":["Zezheng Feng","Fang Zhu","Hongjun Wang","Jianing Hao","ShuangHua Yang","Wei Zeng","Huamin Qu"],"comments":"20 pages, 18 figures, is accepted by computational visual media\n  journal","categories":["cs.HC"],"primary_category":"cs.HC","doi":null,"journal_ref":null,"peer_reviewed":true,"reader_id":"rid1","human_jargon_term":"directed acyclic graph","definition_text":"A directed acyclic graph (DAG) is a type of diagram or chart where points, called nodes, are connected with arrows, called edges, that point in a specific direction, and it is set up in a way that avoids any loops\u2014meaning you cannot start at one node and return to it by following the directional arrows. This structure helps in representing processes or sequences where certain steps must precedently occur before others.","model":"gpt4_abstract","Accuracy":"accurate","Ranking":0,"Notes":""},"218":{"arxiv_id":"2403.03822v1","url":"http:\/\/arxiv.org\/abs\/2403.03822v1","title":"HoLens: A Visual Analytics Design for Higher-order Movement Modeling and\n  Visualization","summary":"Higher-order patterns reveal sequential multistep state transitions, which\nare usually superior to origin-destination analysis, which depicts only\nfirst-order geospatial movement patterns. Conventional methods for higher-order\nmovement modeling first construct a directed acyclic graph (DAG) of movements,\nthen extract higher-order patterns from the DAG. However, DAG-based methods\nheavily rely on the identification of movement keypoints that are challenging\nfor sparse movements and fail to consider the temporal variants that are\ncritical for movements in urban environments. To overcome the limitations, we\npropose HoLens, a novel approach for modeling and visualizing higher-order\nmovement patterns in the context of an urban environment. HoLens mainly makes\ntwofold contributions: first, we design an auto-adaptive movement aggregation\nalgorithm that self-organizes movements hierarchically by considering spatial\nproximity, contextual information, and temporal variability; second, we develop\nan interactive visual analytics interface consisting of well-established\nvisualization techniques, including the H-Flow for visualizing the higher-order\npatterns on the map and the higher-order state sequence chart for representing\nthe higher-order state transitions. Two real-world case studies manifest that\nthe method can adaptively aggregate the data and exhibit the process of how to\nexplore the higher-order patterns by HoLens. We also demonstrate our approach's\nfeasibility, usability, and effectiveness through an expert interview with\nthree domain experts.","updated":1709741331000,"published":1709741331000,"authors":["Zezheng Feng","Fang Zhu","Hongjun Wang","Jianing Hao","ShuangHua Yang","Wei Zeng","Huamin Qu"],"comments":"20 pages, 18 figures, is accepted by computational visual media\n  journal","categories":["cs.HC"],"primary_category":"cs.HC","doi":null,"journal_ref":null,"peer_reviewed":true,"reader_id":"rid1","human_jargon_term":"first-order geospatial movement patterns","definition_text":"First-order geospatial movement patterns refer to the simple analysis of movements from one location to another without considering any intermediate steps or complex interactions between routes and locations involved. These patterns just track direct movement from a start point to an endpoint.","model":"gpt4_abstract","Accuracy":"accurate","Ranking":0,"Notes":""},"219":{"arxiv_id":"2403.03822v1","url":"http:\/\/arxiv.org\/abs\/2403.03822v1","title":"HoLens: A Visual Analytics Design for Higher-order Movement Modeling and\n  Visualization","summary":"Higher-order patterns reveal sequential multistep state transitions, which\nare usually superior to origin-destination analysis, which depicts only\nfirst-order geospatial movement patterns. Conventional methods for higher-order\nmovement modeling first construct a directed acyclic graph (DAG) of movements,\nthen extract higher-order patterns from the DAG. However, DAG-based methods\nheavily rely on the identification of movement keypoints that are challenging\nfor sparse movements and fail to consider the temporal variants that are\ncritical for movements in urban environments. To overcome the limitations, we\npropose HoLens, a novel approach for modeling and visualizing higher-order\nmovement patterns in the context of an urban environment. HoLens mainly makes\ntwofold contributions: first, we design an auto-adaptive movement aggregation\nalgorithm that self-organizes movements hierarchically by considering spatial\nproximity, contextual information, and temporal variability; second, we develop\nan interactive visual analytics interface consisting of well-established\nvisualization techniques, including the H-Flow for visualizing the higher-order\npatterns on the map and the higher-order state sequence chart for representing\nthe higher-order state transitions. Two real-world case studies manifest that\nthe method can adaptively aggregate the data and exhibit the process of how to\nexplore the higher-order patterns by HoLens. We also demonstrate our approach's\nfeasibility, usability, and effectiveness through an expert interview with\nthree domain experts.","updated":1709741331000,"published":1709741331000,"authors":["Zezheng Feng","Fang Zhu","Hongjun Wang","Jianing Hao","ShuangHua Yang","Wei Zeng","Huamin Qu"],"comments":"20 pages, 18 figures, is accepted by computational visual media\n  journal","categories":["cs.HC"],"primary_category":"cs.HC","doi":null,"journal_ref":null,"peer_reviewed":true,"reader_id":"rid1","human_jargon_term":"origin-destination analysis","definition_text":"Origin-destination analysis is a method used to study the movement between a starting point (origin) and an ending point (destination) without examining the details of the path or patterns of movement between these points.","model":"gpt4_abstract","Accuracy":"accurate","Ranking":2,"Notes":""},"220":{"arxiv_id":"2403.03822v1","url":"http:\/\/arxiv.org\/abs\/2403.03822v1","title":"HoLens: A Visual Analytics Design for Higher-order Movement Modeling and\n  Visualization","summary":"Higher-order patterns reveal sequential multistep state transitions, which\nare usually superior to origin-destination analysis, which depicts only\nfirst-order geospatial movement patterns. Conventional methods for higher-order\nmovement modeling first construct a directed acyclic graph (DAG) of movements,\nthen extract higher-order patterns from the DAG. However, DAG-based methods\nheavily rely on the identification of movement keypoints that are challenging\nfor sparse movements and fail to consider the temporal variants that are\ncritical for movements in urban environments. To overcome the limitations, we\npropose HoLens, a novel approach for modeling and visualizing higher-order\nmovement patterns in the context of an urban environment. HoLens mainly makes\ntwofold contributions: first, we design an auto-adaptive movement aggregation\nalgorithm that self-organizes movements hierarchically by considering spatial\nproximity, contextual information, and temporal variability; second, we develop\nan interactive visual analytics interface consisting of well-established\nvisualization techniques, including the H-Flow for visualizing the higher-order\npatterns on the map and the higher-order state sequence chart for representing\nthe higher-order state transitions. Two real-world case studies manifest that\nthe method can adaptively aggregate the data and exhibit the process of how to\nexplore the higher-order patterns by HoLens. We also demonstrate our approach's\nfeasibility, usability, and effectiveness through an expert interview with\nthree domain experts.","updated":1709741331000,"published":1709741331000,"authors":["Zezheng Feng","Fang Zhu","Hongjun Wang","Jianing Hao","ShuangHua Yang","Wei Zeng","Huamin Qu"],"comments":"20 pages, 18 figures, is accepted by computational visual media\n  journal","categories":["cs.HC"],"primary_category":"cs.HC","doi":null,"journal_ref":null,"peer_reviewed":true,"reader_id":"rid1","human_jargon_term":"sequential multistep state transitions","definition_text":"Sequential multistep state transitions refer to processes where something progresses through multiple distinct stages or conditions in a specific order. For example, it\u2019s like following a series of steps in a recipe where each step must be completed before moving on to the next to achieve the final dish.","model":"gpt4_abstract","Accuracy":"accurate","Ranking":2,"Notes":""},"221":{"arxiv_id":"2403.03822v1","url":"http:\/\/arxiv.org\/abs\/2403.03822v1","title":"HoLens: A Visual Analytics Design for Higher-order Movement Modeling and\n  Visualization","summary":"Higher-order patterns reveal sequential multistep state transitions, which\nare usually superior to origin-destination analysis, which depicts only\nfirst-order geospatial movement patterns. Conventional methods for higher-order\nmovement modeling first construct a directed acyclic graph (DAG) of movements,\nthen extract higher-order patterns from the DAG. However, DAG-based methods\nheavily rely on the identification of movement keypoints that are challenging\nfor sparse movements and fail to consider the temporal variants that are\ncritical for movements in urban environments. To overcome the limitations, we\npropose HoLens, a novel approach for modeling and visualizing higher-order\nmovement patterns in the context of an urban environment. HoLens mainly makes\ntwofold contributions: first, we design an auto-adaptive movement aggregation\nalgorithm that self-organizes movements hierarchically by considering spatial\nproximity, contextual information, and temporal variability; second, we develop\nan interactive visual analytics interface consisting of well-established\nvisualization techniques, including the H-Flow for visualizing the higher-order\npatterns on the map and the higher-order state sequence chart for representing\nthe higher-order state transitions. Two real-world case studies manifest that\nthe method can adaptively aggregate the data and exhibit the process of how to\nexplore the higher-order patterns by HoLens. We also demonstrate our approach's\nfeasibility, usability, and effectiveness through an expert interview with\nthree domain experts.","updated":1709741331000,"published":1709741331000,"authors":["Zezheng Feng","Fang Zhu","Hongjun Wang","Jianing Hao","ShuangHua Yang","Wei Zeng","Huamin Qu"],"comments":"20 pages, 18 figures, is accepted by computational visual media\n  journal","categories":["cs.HC"],"primary_category":"cs.HC","doi":null,"journal_ref":null,"peer_reviewed":true,"reader_id":"rid1","human_jargon_term":"sparse movements","definition_text":"Sparse movements refer to situations where there are relatively few instances of movement or activity occurring within a certain area or period, making it difficult to detect and analyze patterns due to the limited data available.","model":"gpt4_abstract","Accuracy":"accurate","Ranking":0,"Notes":""},"222":{"arxiv_id":"2403.03822v1","url":"http:\/\/arxiv.org\/abs\/2403.03822v1","title":"HoLens: A Visual Analytics Design for Higher-order Movement Modeling and\n  Visualization","summary":"Higher-order patterns reveal sequential multistep state transitions, which\nare usually superior to origin-destination analysis, which depicts only\nfirst-order geospatial movement patterns. Conventional methods for higher-order\nmovement modeling first construct a directed acyclic graph (DAG) of movements,\nthen extract higher-order patterns from the DAG. However, DAG-based methods\nheavily rely on the identification of movement keypoints that are challenging\nfor sparse movements and fail to consider the temporal variants that are\ncritical for movements in urban environments. To overcome the limitations, we\npropose HoLens, a novel approach for modeling and visualizing higher-order\nmovement patterns in the context of an urban environment. HoLens mainly makes\ntwofold contributions: first, we design an auto-adaptive movement aggregation\nalgorithm that self-organizes movements hierarchically by considering spatial\nproximity, contextual information, and temporal variability; second, we develop\nan interactive visual analytics interface consisting of well-established\nvisualization techniques, including the H-Flow for visualizing the higher-order\npatterns on the map and the higher-order state sequence chart for representing\nthe higher-order state transitions. Two real-world case studies manifest that\nthe method can adaptively aggregate the data and exhibit the process of how to\nexplore the higher-order patterns by HoLens. We also demonstrate our approach's\nfeasibility, usability, and effectiveness through an expert interview with\nthree domain experts.","updated":1709741331000,"published":1709741331000,"authors":["Zezheng Feng","Fang Zhu","Hongjun Wang","Jianing Hao","ShuangHua Yang","Wei Zeng","Huamin Qu"],"comments":"20 pages, 18 figures, is accepted by computational visual media\n  journal","categories":["cs.HC"],"primary_category":"cs.HC","doi":null,"journal_ref":null,"peer_reviewed":true,"reader_id":"rid1","human_jargon_term":"temporal variability","definition_text":"Temporal variability refers to changes in a pattern or phenomenon over time. In the context of urban movements, this could relate to how people's traveling behaviors change throughout different times of the day, days of the week, or seasons.","model":"gpt4_abstract","Accuracy":"accurate","Ranking":1,"Notes":""},"223":{"arxiv_id":"2403.03822v1","url":"http:\/\/arxiv.org\/abs\/2403.03822v1","title":"HoLens: A Visual Analytics Design for Higher-order Movement Modeling and\n  Visualization","summary":"Higher-order patterns reveal sequential multistep state transitions, which\nare usually superior to origin-destination analysis, which depicts only\nfirst-order geospatial movement patterns. Conventional methods for higher-order\nmovement modeling first construct a directed acyclic graph (DAG) of movements,\nthen extract higher-order patterns from the DAG. However, DAG-based methods\nheavily rely on the identification of movement keypoints that are challenging\nfor sparse movements and fail to consider the temporal variants that are\ncritical for movements in urban environments. To overcome the limitations, we\npropose HoLens, a novel approach for modeling and visualizing higher-order\nmovement patterns in the context of an urban environment. HoLens mainly makes\ntwofold contributions: first, we design an auto-adaptive movement aggregation\nalgorithm that self-organizes movements hierarchically by considering spatial\nproximity, contextual information, and temporal variability; second, we develop\nan interactive visual analytics interface consisting of well-established\nvisualization techniques, including the H-Flow for visualizing the higher-order\npatterns on the map and the higher-order state sequence chart for representing\nthe higher-order state transitions. Two real-world case studies manifest that\nthe method can adaptively aggregate the data and exhibit the process of how to\nexplore the higher-order patterns by HoLens. We also demonstrate our approach's\nfeasibility, usability, and effectiveness through an expert interview with\nthree domain experts.","updated":1709741331000,"published":1709741331000,"authors":["Zezheng Feng","Fang Zhu","Hongjun Wang","Jianing Hao","ShuangHua Yang","Wei Zeng","Huamin Qu"],"comments":"20 pages, 18 figures, is accepted by computational visual media\n  journal","categories":["cs.HC"],"primary_category":"cs.HC","doi":null,"journal_ref":null,"peer_reviewed":true,"reader_id":"rid1","human_jargon_term":"temporal variants","definition_text":"\"Temporal variants\" refer to changes or differences that occur over time. In the context of analyzing movement patterns, this term highlights how factors related to time can affect how movements are observed and understood, such as variations in traffic flow at different times of day.","model":"gpt4_abstract","Accuracy":"accurate","Ranking":1,"Notes":""},"224":{"arxiv_id":"2403.08057v1","url":"http:\/\/arxiv.org\/abs\/2403.08057v1","title":"MineXR: Mining Personalized Extended Reality Interfaces","summary":"Extended Reality (XR) interfaces offer engaging user experiences, but their\neffective design requires a nuanced understanding of user behavior and\npreferences. This knowledge is challenging to obtain without the widespread\nadoption of XR devices. We introduce MineXR, a design mining workflow and data\nanalysis platform for collecting and analyzing personalized XR user interaction\nand experience data. MineXR enables elicitation of personalized interfaces from\nparticipants of a data collection: for any particular context, participants\ncreate interface elements using application screenshots from their own\nsmartphone, place them in the environment, and simultaneously preview the\nresulting XR layout on a headset. Using MineXR, we contribute a dataset of\npersonalized XR interfaces collected from 31 participants, consisting of 695 XR\nwidgets created from 178 unique applications. We provide insights for XR widget\nfunctionalities, categories, clusters, UI element types, and placement. Our\nopen-source tools and data support researchers and designers in developing\nfuture XR interfaces.","updated":1710273914000,"published":1710273914000,"authors":["Hyunsung Cho","Yukang Yan","Kashyap Todi","Mark Parent","Missie Smith","Tanya R. Jonker","Hrvoje Benko","David Lindlbauer"],"comments":"17 pages, 18 figures, Proceedings of the 2024 CHI Conference on Human\n  Factors in Computing Systems","categories":["cs.HC","H.5.2"],"primary_category":"cs.HC","doi":"10.1145\/3613904.3642394","journal_ref":null,"peer_reviewed":true,"reader_id":"rid1","human_jargon_term":"Extended Reality","definition_text":"Extended Reality (XR) is a term that encompasses all types of technologies that combine real and virtual environments, including virtual reality (VR), augmented reality (AR), and mixed reality (MR). These technologies create immersive digital experiences that can mimic real-world or imaginary settings.","model":"gpt4_abstract","Accuracy":"accurate","Ranking":2,"Notes":""},"225":{"arxiv_id":"2403.08057v1","url":"http:\/\/arxiv.org\/abs\/2403.08057v1","title":"MineXR: Mining Personalized Extended Reality Interfaces","summary":"Extended Reality (XR) interfaces offer engaging user experiences, but their\neffective design requires a nuanced understanding of user behavior and\npreferences. This knowledge is challenging to obtain without the widespread\nadoption of XR devices. We introduce MineXR, a design mining workflow and data\nanalysis platform for collecting and analyzing personalized XR user interaction\nand experience data. MineXR enables elicitation of personalized interfaces from\nparticipants of a data collection: for any particular context, participants\ncreate interface elements using application screenshots from their own\nsmartphone, place them in the environment, and simultaneously preview the\nresulting XR layout on a headset. Using MineXR, we contribute a dataset of\npersonalized XR interfaces collected from 31 participants, consisting of 695 XR\nwidgets created from 178 unique applications. We provide insights for XR widget\nfunctionalities, categories, clusters, UI element types, and placement. Our\nopen-source tools and data support researchers and designers in developing\nfuture XR interfaces.","updated":1710273914000,"published":1710273914000,"authors":["Hyunsung Cho","Yukang Yan","Kashyap Todi","Mark Parent","Missie Smith","Tanya R. Jonker","Hrvoje Benko","David Lindlbauer"],"comments":"17 pages, 18 figures, Proceedings of the 2024 CHI Conference on Human\n  Factors in Computing Systems","categories":["cs.HC","H.5.2"],"primary_category":"cs.HC","doi":"10.1145\/3613904.3642394","journal_ref":null,"peer_reviewed":true,"reader_id":"rid1","human_jargon_term":"MineXR","definition_text":"MineXR is a tool designed to collect and analyze data on how people interact with and customize their Extended Reality (XR) environments. It allows participants to design their own XR interfaces using elements from their smartphones, which helps researchers and designers understand user preferences and improve the design of XR technology.","model":"gpt4_abstract","Accuracy":"accurate","Ranking":0,"Notes":""},"226":{"arxiv_id":"2403.12730v1","url":"http:\/\/arxiv.org\/abs\/2403.12730v1","title":"What Does Evaluation of Explainable Artificial Intelligence Actually\n  Tell Us? A Case for Compositional and Contextual Validation of XAI Building\n  Blocks","summary":"Despite significant progress, evaluation of explainable artificial\nintelligence remains elusive and challenging. In this paper we propose a\nfine-grained validation framework that is not overly reliant on any one facet\nof these sociotechnical systems, and that recognises their inherent modular\nstructure: technical building blocks, user-facing explanatory artefacts and\nsocial communication protocols. While we concur that user studies are\ninvaluable in assessing the quality and effectiveness of explanation\npresentation and delivery strategies from the explainees' perspective in a\nparticular deployment context, the underlying explanation generation mechanisms\nrequire a separate, predominantly algorithmic validation strategy that accounts\nfor the technical and human-centred desiderata of their (numerical) outputs.\nSuch a comprehensive sociotechnical utility-based evaluation framework could\nallow to systematically reason about the properties and downstream influence of\ndifferent building blocks from which explainable artificial intelligence\nsystems are composed -- accounting for a diverse range of their engineering and\nsocial aspects -- in view of the anticipated use case.","updated":1710855934000,"published":1710855934000,"authors":["Kacper Sokol","Julia E. Vogt"],"comments":"Published in Extended Abstracts of the 2024 CHI Conference on Human\n  Factors in Computing Systems (CHI EA '24)","categories":["cs.HC","cs.AI"],"primary_category":"cs.HC","doi":"10.1145\/3613905.3651047","journal_ref":null,"peer_reviewed":true,"reader_id":"rid1","human_jargon_term":"sociotechnical systems","definition_text":"Sociotechnical systems refer to complex systems that involve both social aspects (such as people, organizations, and communities) and technical components (like technology and software). These systems consider the interaction between people and technology to ensure that technology supports human needs in a balanced and effective manner.","model":"gpt4_abstract","Accuracy":"accurate","Ranking":2,"Notes":""},"227":{"arxiv_id":"2403.01697v1","url":"http:\/\/arxiv.org\/abs\/2403.01697v1","title":"Dismantling Gender Blindness in Online Discussion of a Crime\/Gender\n  Dichotomy","summary":"Contemporary feminists utilize social media for activism, while backlashes\ncome along. The gender-related discourses are often diminished when addressing\npublic events regarding sexism and gender inequality on social media platforms.\nThe dichotomized debate around the Tangshan beating incident in China\nepitomized how criminal interpretations of gender-related violence became a\nbacklash against feminist expressions. By analyzing posts on Weibo using mixed\nmethods, we describe the emerging discursive patterns around crime and gender,\nuncovering the inherent gender-blind sexism that refutes feminist discourses on\nthe social platform. We also highlight the critical restrictions facing\ngrassroots feminist activism in Chinese cyberspace and propose implications for\nthe design and research related to digital feminist activism.","updated":1709522274000,"published":1709522274000,"authors":["Yigang Qin","Weilun Duan","Qunfang Wu","Zhicong Lu"],"comments":"31 pages, 3 figures, Accepted for publication in Proceedings of the\n  ACM on Human-Computer Interaction (CSCW 2024)","categories":["cs.HC"],"primary_category":"cs.HC","doi":null,"journal_ref":null,"peer_reviewed":true,"reader_id":"rid1","human_jargon_term":"Tangshan beating incident","definition_text":"The Tangshan beating incident refers to a high-profile event in China where a violent assault on women was captured on video and widely shared on social media, sparking national and international discussions about gender violence and the safety of women. This incident became central to debates around the effectiveness of feminist activism and the societal responses to gender-related violence in the digital age.","model":"gpt4_abstract","Accuracy":"accurate","Ranking":0,"Notes":""},"228":{"arxiv_id":"2403.01697v1","url":"http:\/\/arxiv.org\/abs\/2403.01697v1","title":"Dismantling Gender Blindness in Online Discussion of a Crime\/Gender\n  Dichotomy","summary":"Contemporary feminists utilize social media for activism, while backlashes\ncome along. The gender-related discourses are often diminished when addressing\npublic events regarding sexism and gender inequality on social media platforms.\nThe dichotomized debate around the Tangshan beating incident in China\nepitomized how criminal interpretations of gender-related violence became a\nbacklash against feminist expressions. By analyzing posts on Weibo using mixed\nmethods, we describe the emerging discursive patterns around crime and gender,\nuncovering the inherent gender-blind sexism that refutes feminist discourses on\nthe social platform. We also highlight the critical restrictions facing\ngrassroots feminist activism in Chinese cyberspace and propose implications for\nthe design and research related to digital feminist activism.","updated":1709522274000,"published":1709522274000,"authors":["Yigang Qin","Weilun Duan","Qunfang Wu","Zhicong Lu"],"comments":"31 pages, 3 figures, Accepted for publication in Proceedings of the\n  ACM on Human-Computer Interaction (CSCW 2024)","categories":["cs.HC"],"primary_category":"cs.HC","doi":null,"journal_ref":null,"peer_reviewed":true,"reader_id":"rid1","human_jargon_term":"Weibo","definition_text":"Weibo is a popular social media platform in China that allows users to post content, follow other users, and engage in communications much like Twitter.","model":"gpt4_abstract","Accuracy":"accurate","Ranking":0,"Notes":""},"229":{"arxiv_id":"2403.01697v1","url":"http:\/\/arxiv.org\/abs\/2403.01697v1","title":"Dismantling Gender Blindness in Online Discussion of a Crime\/Gender\n  Dichotomy","summary":"Contemporary feminists utilize social media for activism, while backlashes\ncome along. The gender-related discourses are often diminished when addressing\npublic events regarding sexism and gender inequality on social media platforms.\nThe dichotomized debate around the Tangshan beating incident in China\nepitomized how criminal interpretations of gender-related violence became a\nbacklash against feminist expressions. By analyzing posts on Weibo using mixed\nmethods, we describe the emerging discursive patterns around crime and gender,\nuncovering the inherent gender-blind sexism that refutes feminist discourses on\nthe social platform. We also highlight the critical restrictions facing\ngrassroots feminist activism in Chinese cyberspace and propose implications for\nthe design and research related to digital feminist activism.","updated":1709522274000,"published":1709522274000,"authors":["Yigang Qin","Weilun Duan","Qunfang Wu","Zhicong Lu"],"comments":"31 pages, 3 figures, Accepted for publication in Proceedings of the\n  ACM on Human-Computer Interaction (CSCW 2024)","categories":["cs.HC"],"primary_category":"cs.HC","doi":null,"journal_ref":null,"peer_reviewed":true,"reader_id":"rid1","human_jargon_term":"grassroots feminist activism","definition_text":"Grassroots feminist activism refers to efforts initiated and carried out by ordinary individuals or local communities aimed at promoting gender equality and addressing issues of sexism and discrimination from the ground up, rather than being driven by top-level organizations or governments. This type of activism often utilizes local resources and is highly reliant on community involvement to effect change.","model":"gpt4_abstract","Accuracy":"accurate","Ranking":1,"Notes":""},"230":{"arxiv_id":"2403.01055v1","url":"http:\/\/arxiv.org\/abs\/2403.01055v1","title":"Towards Full Authorship with AI: Supporting Revision with AI-Generated\n  Views","summary":"Large language models (LLMs) are shaping a new user interface (UI) paradigm\nin writing tools by enabling users to generate text through prompts. This\nparadigm shifts some creative control from the user to the system, thereby\ndiminishing the user's authorship and autonomy in the writing process. To\nrestore autonomy, we introduce Textfocals, a UI prototype designed to\ninvestigate a human-centered approach that emphasizes the user's role in\nwriting. Textfocals supports the writing process by providing LLM-generated\nsummaries, questions, and advice (i.e., LLM views) in a sidebar of a text\neditor, encouraging reflection and self-driven revision in writing without\ndirect text generation. Textfocals' UI affordances, including contextually\nadaptive views and scaffolding for prompt selection and customization, offer a\nnovel way to interact with LLMs where users maintain full authorship of their\nwriting. A formative user study with Textfocals showed promising evidence that\nthis approach might help users develop underdeveloped ideas, cater to the\nrhetorical audience, and clarify their writing. However, the study also showed\ninteraction design challenges related to document navigation and scoping,\nprompt engineering, and context management. Our work highlights the breadth of\nthe design space of writing support interfaces powered by generative AI that\nmaintain authorship integrity.","updated":1709341895000,"published":1709341895000,"authors":["Jiho Kim","Ray C. Flanagan","Noelle E. Haviland","ZeAi Sun","Souad N. Yakubu","Edom A. Maru","Kenneth C. Arnold"],"comments":"15 pages, 2 figures; Accepted to 5th Workshop on Human-AI Co-Creation\n  with Generative Models (HAI-GEN) at ACM IUI 2024","categories":["cs.HC","cs.AI","cs.CY","H.5.2; I.7.1; I.2.7"],"primary_category":"cs.HC","doi":null,"journal_ref":null,"peer_reviewed":true,"reader_id":"rid1","human_jargon_term":"Textfocals","definition_text":"Textfocals is a user interface prototype designed to help writers by providing AI-generated summaries, questions, and advice in a sidebar within a text editor. This tool aims to support writers by encouraging them to reflect and revise their work independently, while keeping them in control of the writing process and maintaining their original authorship.","model":"gpt4_abstract","Accuracy":"accurate","Ranking":2,"Notes":""},"231":{"arxiv_id":"2305.11927v2","url":"http:\/\/arxiv.org\/abs\/2305.11927v2","title":"Evaluating how interactive visualizations can assist in finding samples\n  where and how computer vision models make mistakes","summary":"Creating Computer Vision (CV) models remains a complex practice, despite\ntheir ubiquity. Access to data, the requirement for ML expertise, and model\nopacity are just a few points of complexity that limit the ability of end-users\nto build, inspect, and improve these models. Interactive ML perspectives have\nhelped address some of these issues by considering a teacher in the loop where\nplanning, teaching, and evaluating tasks take place. We present and evaluate\ntwo interactive visualizations in the context of Sprite, a system for creating\nCV classification and detection models for images originating from videos. We\nstudy how these visualizations help Sprite's users identify (evaluate) and\nselect (plan) images where a model is struggling and can lead to improved\nperformance, compared to a baseline condition where users used a query\nlanguage. We found that users who had used the visualizations found more images\nacross a wider set of potential types of model errors.","updated":1710526996000,"published":1684507380000,"authors":["Hayeong Song","Gonzalo Ramos","Peter Bodik"],"comments":"Hayeong Song, Gonzalo Ramos, and Peter Bodik. \"Evaluating how\n  interactive visualizations can assist in finding samples where and how\n  computer vision models make mistakes\" 2024 IEEE Pacific Visualization\n  Symposium (PacificVis). Ieee, 2024","categories":["cs.HC","cs.CV","cs.LG"],"primary_category":"cs.HC","doi":null,"journal_ref":null,"peer_reviewed":true,"reader_id":"rid1","human_jargon_term":"Sprite","definition_text":"Sprite is a system designed to assist users in creating computer vision models that classify and detect objects within images taken from videos. It incorporates interactive visualizations that aid users in selecting and evaluating problematic images to enhance model performance.","model":"gpt4_abstract","Accuracy":"accurate","Ranking":0,"Notes":""},"232":{"arxiv_id":"2403.00632v1","url":"http:\/\/arxiv.org\/abs\/2403.00632v1","title":"Metamorpheus: Interactive, Affective, and Creative Dream Narration\n  Through Metaphorical Visual Storytelling","summary":"Human emotions are essentially molded by lived experiences, from which we\nconstruct personalised meaning. The engagement in such meaning-making process\nhas been practiced as an intervention in various psychotherapies to promote\nwellness. Nevertheless, to support recollecting and recounting lived\nexperiences in everyday life remains under explored in HCI. It also remains\nunknown how technologies such as generative AI models can facilitate the\nmeaning making process, and ultimately support affective mindfulness. In this\npaper we present Metamorpheus, an affective interface that engages users in a\ncreative visual storytelling of emotional experiences during dreams.\nMetamorpheus arranges the storyline based on a dream's emotional arc, and\nprovokes self-reflection through the creation of metaphorical images and text\ndepictions. The system provides metaphor suggestions, and generates visual\nmetaphors and text depictions using generative AI models, while users can apply\ngenerations to recolour and re-arrange the interface to be visually affective.\nOur experience-centred evaluation manifests that, by interacting with\nMetamorpheus, users can recall their dreams in vivid detail, through which they\nrelive and reflect upon their experiences in a meaningful way.","updated":1709309372000,"published":1709309372000,"authors":["Qian Wan","Xin Feng","Yining Bei","Zhiqi Gao","Zhicong Lu"],"comments":"Accepted by CHI 2024","categories":["cs.HC","cs.AI","cs.CL","cs.CY"],"primary_category":"cs.HC","doi":null,"journal_ref":null,"peer_reviewed":true,"reader_id":"rid1","human_jargon_term":"Metamorpheus","definition_text":"Metamorpheus is an interactive tool that helps users explore and reflect on their emotional experiences through dreams by creating visual and textual metaphors. It uses AI to suggest and generate these metaphors, allowing users to adjust the visuals and text to deepen their understanding and reflection of their feelings.","model":"gpt4_abstract","Accuracy":"accurate","Ranking":1,"Notes":""}}