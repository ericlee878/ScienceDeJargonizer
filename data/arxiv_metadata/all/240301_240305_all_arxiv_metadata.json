{
    "0710.3901": {
        "title": "A recursive linear time modular decomposition algorithm via LexBFS",
        "authors": [
            "Derek Corneil",
            "Michel Habib",
            "Christophe Paul",
            "Marc Tedder"
        ],
        "comments": "An EA of this work appeared in ICALP'08. The arXiv v2 contains an appendix with some sketches of proofs. To date, complete proofs can only be found in the PhD of M. Tedder and spread over several chapters. This is the first self-contained version. To ease the understanding, the noveI presentation enlights the combinatorial objects involved in the algorithm, which still relies on the same ideas",
        "subjects": "Discrete Mathematics (cs.DM)",
        "abstract": "A module of a graph G is a set of vertices that have the same set of neighbours outside. Modules of a graphs form a so-called partitive family and thereby can be represented by a unique tree MD(G), called the modular decomposition tree. Motivated by the central role of modules in numerous algorithmic graph theory questions, the problem of efficiently computing MD(G) has been investigated since the early 70's. To date the best algorithms run in linear time but are all rather complicated. By combining previous algorithmic paradigms developed for the problem, we are able to present a simpler linear-time that relies on very simple data-structures, namely slice decomposition and sequences of rooted ordered trees.\n    ",
        "primary_category": "cs.DM",
        "categories": [],
        "submitted_date": "21 Oct 2007",
        "last_revised_date": " "
    },
    "1505.02681": {
        "title": "Socio-Spatial Group Queries for Impromptu Activity Planning",
        "authors": [
            "Chih-Ya Shen",
            "De-Nian Yang",
            "Liang-Hao Huang",
            "Wang-Chien Lee",
            "Ming-Syan Chen"
        ],
        "comments": " ",
        "subjects": "Data Structures and Algorithms (cs.DS)",
        "abstract": "The development and integration of social networking services and smartphones have made it easy for individuals to organize impromptu social activities anywhere and anytime. Main challenges arising in organizing impromptu activities are mostly due to the requirements of making timely invitations in accordance with the potential activity locations, corresponding to the locations of and the relationship among the candidate attendees. Various combinations of candidate attendees and activity locations create a large solution space. Thus, in this paper, we propose Multiple Rally-Point Social Spatial Group Query (MRGQ), to select an appropriate activity location for a group of nearby attendees with tight social relationships. Although MRGQ is NP-hard, the number of attendees in practice is usually small enough such that an optimal solution can be found efficiently. Therefore, we first propose an Integer Linear Programming optimization model for MRGQ. We then design an efficient algorithm, called MAGS, which employs effective search space exploration and pruning strategies to reduce the running time for finding the optimal solution. We also propose to further optimize efficiency by indexing the potential activity locations. A user study demonstrates the strength of using MAGS over manual coordination in terms of both solution quality and efficiency. Experimental results on real datasets show that our algorithms can process MRGQ efficiently and significantly outperform other baseline algorithms, including one based on the commercial parallel optimizer IBM CPLEX.\n    ",
        "primary_category": "cs.DS",
        "categories": [
            "cs.DB"
        ],
        "submitted_date": "11 May 2015",
        "last_revised_date": " "
    },
    "1607.06444": {
        "title": "The Complexity of Drawing Graphs on Few Lines and Few Planes",
        "authors": [
            "Steven Chaplick",
            "Krzysztof Fleszar",
            "Fabian Lipp",
            "Alexander Ravsky",
            "Oleg Verbitsky",
            "Alexander Wolff"
        ],
        "comments": "A preliminary version appeared in Proc. WADS 2017",
        "subjects": "Computational Complexity (cs.CC)",
        "abstract": "It is well known that any graph admits a crossing-free straight-line drawing in $\\mathbb{R}^3$ and that any planar graph admits the same even in $\\mathbb{R}^2$. For a graph $G$ and $d \\in \\{2,3\\}$, let $\\rho^1_d(G)$ denote the smallest number of lines in $\\mathbb{R}^d$ whose union contains a crossing-free straight-line drawing of $G$. For $d=2$, $G$ must be planar. Similarly, let $\\rho^2_3(G)$ denote the smallest number of planes in $\\mathbb{R}^3$ whose union contains a crossing-free straight-line drawing of $G$.\nWe investigate the complexity of computing these three parameters and obtain the following hardness and algorithmic results.\n- For $d\\in\\{2,3\\}$, we prove that deciding whether $\\rho^1_d(G)\\le k$ for a given graph $G$ and integer $k$ is ${\\exists\\mathbb{R}}$-complete.\n- Since $\\mathrm{NP}\\subseteq{\\exists\\mathbb{R}}$, deciding $\\rho^1_d(G)\\le k$ is NP-hard for $d\\in\\{2,3\\}$. On the positive side, we show that the problem is fixed-parameter tractable with respect to $k$.\n- Since ${\\exists\\mathbb{R}}\\subseteq\\mathrm{PSPACE}$, both $\\rho^1_2(G)$ and $\\rho^1_3(G)$ are computable in polynomial space. On the negative side, we show that drawings that are optimal with respect to $\\rho^1_2$ or $\\rho^1_3$ sometimes require irrational coordinates.\n- We prove that deciding whether $\\rho^2_3(G)\\le k$ is NP-hard for any fixed $k \\ge 2$. Hence, the problem is not fixed-parameter tractable with respect to $k$ unless $\\mathrm{P}=\\mathrm{NP}$.\n    ",
        "primary_category": "cs.CC",
        "categories": [
            "cs.CG"
        ],
        "submitted_date": "21 Jul 2016",
        "last_revised_date": " "
    },
    "1710.01837": {
        "title": "Postquantum Br\u00e8gman relative entropies",
        "authors": [
            "Ryszard Pawe\u0142 Kostecki"
        ],
        "comments": "v3: paper rewritten from scratch; parts of v2 about categories and resource monoids are moved to arXiv:2103.07810, while models based on Orlicz spaces are moved to an upcoming paper; v4: further improvements; a proof of H\u00f6lder continuity of nonassociative Mazur map, and a discussion of $L_p$ spaces over order unit spaces have been added; v5: a new section with noncommutative Orlicz spaces",
        "subjects": "Mathematical Physics (math-ph)",
        "abstract": "We develop a new approach to construction of Br\u00e8gman relative entropies over nonreflexive Banach spaces, based on nonlinear mappings into reflexive Banach spaces. We apply it to derive few families of Br\u00e8gman relative entropies over several radially compact base normed spaces in spectral duality. In particular, we prove generalised pythagorean theorem and norm-to-norm continuity of the corresponding entropic projections for a family induced on preduals of any W$^*$-algebras and of semifinite JBW-algebras using Mazur maps into corresponding noncommutative and nonassociative $L_p$ spaces. We also prove generalised pythagorean theorem for a family induced using Kaczmarz maps into Orlicz spaces over semifinite W$^*$-algebras, and for a family over generalised spin factors. Additionally, we establish Lipschitz--H\u00f6lder continuity of the nonassociative Mazur map on positive parts of unit balls, characterise several geometric properties of the Morse-Transue-Nakano-Luxemburg norm on noncommutative Orlicz spaces, and introduce a new family of $L_p$ spaces over order unit spaces.\n    ",
        "primary_category": "math-ph",
        "categories": [
            "cs.IT"
        ],
        "submitted_date": "5 Oct 2017",
        "last_revised_date": " "
    },
    "1803.06488": {
        "title": "An extended type system with lambda-typed lambda-expressions (extended version)",
        "authors": [
            "Matthias Weber"
        ],
        "comments": "246 pages",
        "subjects": "Logic in Computer Science (cs.LO)",
        "abstract": "We present the type system $\\mathtt{d}$, an extended type system with lambda-typed lambda-expressions. It is related to type systems originating from the Automath project. $\\mathtt{d}$ extends existing lambda-typed systems by an existential abstraction operator as well as propositional operators. $\\beta$-reduction is extended to also normalize negated expressions using a subset of the laws of classical negation, hence $\\mathtt{d}$ is normalizing both proofs and formulas which are handled uniformly as functional expressions. $\\mathtt{d}$ is using a reflexive typing axiom for a constant $\\tau$ to which no function can be typed. Some properties are shown including confluence, subject reduction, uniqueness of types, strong normalization, and consistency. We illustrate how, when using $\\mathtt{d}$, due to its limited logical strength additional axioms must be added both for negation and for the mathematical structures whose deductions are to be formalized. Several appendices deal with extensions and variations of the proposed system.\n    ",
        "primary_category": "cs.LO",
        "categories": [],
        "submitted_date": "17 Mar 2018",
        "last_revised_date": " "
    },
    "1804.02973": {
        "title": "The Schulze Method of Voting",
        "authors": [
            "Markus Schulze"
        ],
        "comments": " ",
        "subjects": "Computer Science and Game Theory (cs.GT)",
        "abstract": "We propose a new single-winner election method (\"Schulze method\") and prove that it satisfies many academic criteria (e.g. monotonicity, reversal symmetry, resolvability, independence of clones, Condorcet criterion, k-consistency, polynomial runtime). We then generalize this method to proportional representation by the single transferable vote (\"Schulze STV\") and to methods to calculate a proportional ranking (\"Schulze proportional ranking\"). Furthermore, we propose a generalization of the Condorcet criterion to multi-winner elections. This paper contains a large number of examples to illustrate the proposed methods.\n    ",
        "primary_category": "cs.GT",
        "categories": [],
        "submitted_date": "15 Mar 2018",
        "last_revised_date": " "
    },
    "1805.04770": {
        "title": "Born Again Neural Networks",
        "authors": [
            "Tommaso Furlanello",
            "Zachary C. Lipton",
            "Michael Tschannen",
            "Laurent Itti",
            "Anima Anandkumar"
        ],
        "comments": "Published @ICML 2018",
        "subjects": "Machine Learning (stat.ML)",
        "abstract": "Knowledge Distillation (KD) consists of transferring \u00e2\u20ac\u0153knowledge\u00e2\u20ac\u009d from one machine learning model (the teacher) to another (the student). Commonly, the teacher is a high-capacity model with formidable performance, while the student is more compact. By transferring knowledge, one hopes to benefit from the student\u00e2\u20ac\u2122s compactness, without sacrificing too much performance. We study KD from a new perspective: rather than compressing models, we train students parameterized identically to their teachers. Surprisingly, these Born-Again Networks (BANs), outperform their teachers significantly, both on computer vision and language modeling tasks. Our experiments with BANs based on DenseNets demonstrate state-of-the-art performance on the CIFAR-10 (3.5%) and CIFAR-100 (15.5%) datasets, by validation error. Additional experiments explore two distillation objectives: (i) Confidence-Weighted by Teacher Max (CWTM) and (ii) Dark Knowledge with Permuted Predictions (DKPP). Both methods elucidate the essential components of KD, demonstrating the effect of the teacher outputs on both predicted and non-predicted classes.\n    ",
        "primary_category": "stat.ML",
        "categories": [
            "cs.AI",
            "cs.LG"
        ],
        "submitted_date": "12 May 2018",
        "last_revised_date": " "
    },
    "1806.05451": {
        "title": "The committee machine: Computational to statistical gaps in learning a two-layers neural network",
        "authors": [
            "Benjamin Aubin",
            "Antoine Maillard",
            "Jean Barbier",
            "Florent Krzakala",
            "Nicolas Macris",
            "Lenka Zdeborov\u00e1"
        ],
        "comments": "18 pages + supplementary material, 3 figures. (v2: update to match the published version ; v3: clarification of the caption of Fig. 3)",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Heuristic tools from statistical physics have been used in the past to locate the phase transitions and compute the optimal learning and generalization errors in the teacher-student scenario in multi-layer neural networks. In this contribution, we provide a rigorous justification of these approaches for a two-layers neural network model called the committee machine. We also introduce a version of the approximate message passing (AMP) algorithm for the committee machine that allows to perform optimal learning in polynomial time for a large set of parameters. We find that there are regimes in which a low generalization error is information-theoretically achievable while the AMP algorithm fails to deliver it, strongly suggesting that no efficient algorithm exists for those cases, and unveiling a large computational gap.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cond-mat.dis-nn",
            "cond-mat.stat-mech",
            "physics.comp-ph",
            "stat.ML"
        ],
        "submitted_date": "14 Jun 2018",
        "last_revised_date": " "
    },
    "1907.01743": {
        "title": "Deep Attentive Features for Prostate Segmentation in 3D Transrectal Ultrasound",
        "authors": [
            "Yi Wang",
            "Haoran Dou",
            "Xiaowei Hu",
            "Lei Zhu",
            "Xin Yang",
            "Ming Xu",
            "Jing Qin",
            "Pheng-Ann Heng",
            "Tianfu Wang",
            "Dong Ni"
        ],
        "comments": "11 pages, 10 figures, 2 tables. Accepted by IEEE transactions on Medical Imaging",
        "subjects": "Image and Video Processing (eess.IV)",
        "abstract": "Automatic prostate segmentation in transrectal ultrasound (TRUS) images is of essential importance for image-guided prostate interventions and treatment planning. However, developing such automatic solutions remains very challenging due to the missing/ambiguous boundary and inhomogeneous intensity distribution of the prostate in TRUS, as well as the large variability in prostate shapes. This paper develops a novel 3D deep neural network equipped with attention modules for better prostate segmentation in TRUS by fully exploiting the complementary information encoded in different layers of the convolutional neural network (CNN). Our attention module utilizes the attention mechanism to selectively leverage the multilevel features integrated from different layers to refine the features at each individual layer, suppressing the non-prostate noise at shallow layers of the CNN and increasing more prostate details into features at deep layers. Experimental results on challenging 3D TRUS volumes show that our method attains satisfactory segmentation performance. The proposed attention mechanism is a general strategy to aggregate multi-level deep features and has the potential to be used for other medical image segmentation tasks. The code is publicly available at this https URL.\n    ",
        "primary_category": "eess.IV",
        "categories": [
            "cs.AI",
            "cs.CV",
            "cs.LG"
        ],
        "submitted_date": "3 Jul 2019",
        "last_revised_date": " "
    },
    "1907.02677": {
        "title": "Interpretable Feature Learning in Multivariate Big Data Analysis for Network Monitoring",
        "authors": [
            "Jos\u00e9 Camacho",
            "Katarzyna Wasielewska",
            "Rasmus Bro",
            "David Kotz"
        ],
        "comments": " ",
        "subjects": "Networking and Internet Architecture (cs.NI)",
        "abstract": "There is an increasing interest in the development of new data-driven models useful to assess the performance of communication networks. For many applications, like network monitoring and troubleshooting, a data model is of little use if it cannot be interpreted by a human operator. In this paper, we present an extension of the Multivariate Big Data Analysis (MBDA) methodology, a recently proposed interpretable data analysis tool. In this extension, we propose a solution to the automatic derivation of features, a cornerstone step for the application of MBDA when the amount of data is massive. The resulting network monitoring approach allows us to detect and diagnose disparate network anomalies, with a data-analysis workflow that combines the advantages of interpretable and interactive models with the power of parallel processing. We apply the extended MBDA to two case studies: UGR'16, a benchmark flow-based real-traffic dataset for anomaly detection, and Dartmouth'18, the longest and largest Wi-Fi trace known to date.\n    ",
        "primary_category": "cs.NI",
        "categories": [
            "cs.LG",
            "stat.ML"
        ],
        "submitted_date": "5 Jul 2019",
        "last_revised_date": " "
    },
    "1909.12077": {
        "title": "Symplectic ODE-Net: Learning Hamiltonian Dynamics with Control",
        "authors": [
            "Yaofeng Desmond Zhong",
            "Biswadip Dey",
            "Amit Chakraborty"
        ],
        "comments": "Published as a Conference Paper at ICLR 2020",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "In this paper, we introduce Symplectic ODE-Net (SymODEN), a deep learning framework which can infer the dynamics of a physical system, given by an ordinary differential equation (ODE), from observed state trajectories. To achieve better generalization with fewer training samples, SymODEN incorporates appropriate inductive bias by designing the associated computation graph in a physics-informed manner. In particular, we enforce Hamiltonian dynamics with control to learn the underlying dynamics in a transparent way, which can then be leveraged to draw insight about relevant physical aspects of the system, such as mass and potential energy. In addition, we propose a parametrization which can enforce this Hamiltonian formalism even when the generalized coordinate data is embedded in a high-dimensional space or we can only access velocity data instead of generalized momentum. This framework, by offering interpretable, physically-consistent models for physical systems, opens up new possibilities for synthesizing model-based control strategies.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "eess.SY",
            "physics.comp-ph",
            "stat.ML"
        ],
        "submitted_date": "26 Sep 2019",
        "last_revised_date": " "
    },
    "1910.04331": {
        "title": "Agent with Warm Start and Active Termination for Plane Localization in 3D Ultrasound",
        "authors": [
            "Haoran Dou",
            "Xin Yang",
            "Jikuan Qian",
            "Wufeng Xue",
            "Hao Qin",
            "Xu Wang",
            "Lequan Yu",
            "Shujun Wang",
            "Yi Xiong",
            "Pheng-Ann Heng",
            "Dong Ni"
        ],
        "comments": "9 pages, 5 figures, 1 table. Accepted by MICCAI 2019 (oral)",
        "subjects": "Image and Video Processing (eess.IV)",
        "abstract": "Standard plane localization is crucial for ultrasound (US) diagnosis. In prenatal US, dozens of standard planes are manually acquired with a 2D probe. It is time-consuming and operator-dependent. In comparison, 3D US containing multiple standard planes in one shot has the inherent advantages of less user-dependency and more efficiency. However, manual plane localization in US volume is challenging due to the huge search space and large fetal posture variation. In this study, we propose a novel reinforcement learning (RL) framework to automatically localize fetal brain standard planes in 3D US. Our contribution is two-fold. First, we equip the RL framework with a landmark-aware alignment module to provide warm start and strong spatial bounds for the agent actions, thus ensuring its effectiveness. Second, instead of passively and empirically terminating the agent inference, we propose a recurrent neural network based strategy for active termination of the agent's interaction procedure. This improves both the accuracy and efficiency of the localization system. Extensively validated on our in-house large dataset, our approach achieves the accuracy of 3.4mm/9.6\u00b0 and 2.7mm/9.1\u00b0 for the transcerebellar and transthalamic plane localization, respectively. Ourproposed RL framework is general and has the potential to improve the efficiency and standardization of US scanning.\n    ",
        "primary_category": "eess.IV",
        "categories": [
            "cs.CV",
            "cs.LG"
        ],
        "submitted_date": "10 Oct 2019",
        "last_revised_date": " "
    },
    "1910.04935": {
        "title": "FetusMap: Fetal Pose Estimation in 3D Ultrasound",
        "authors": [
            "Xin Yang",
            "Wenlong Shi",
            "Haoran Dou",
            "Jikuan Qian",
            "Yi Wang",
            "Wufeng Xue",
            "Shengli Li",
            "Dong Ni",
            "Pheng-Ann Heng"
        ],
        "comments": "9 pages, 6 figures, 2 tables. Accepted by MICCAI 2019",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "The 3D ultrasound (US) entrance inspires a multitude of automated prenatal examinations. However, studies about the structuralized description of the whole fetus in 3D US are still rare. In this paper, we propose to estimate the 3D pose of fetus in US volumes to facilitate its quantitative analyses in global and local scales. Given the great challenges in 3D US, including the high volume dimension, poor image quality, symmetric ambiguity in anatomical structures and large variations of fetal pose, our contribution is three-fold. (i) This is the first work about 3D pose estimation of fetus in the literature. We aim to extract the skeleton of whole fetus and assign different segments/joints with correct torso/limb labels. (ii) We propose a self-supervised learning (SSL) framework to finetune the deep network to form visually plausible pose predictions. Specifically, we leverage the landmark-based registration to effectively encode case-adaptive anatomical priors and generate evolving label proxy for supervision. (iii) To enable our 3D network perceive better contextual cues with higher resolution input under limited computing resource, we further adopt the gradient check-pointing (GCP) strategy to save GPU memory and improve the prediction. Extensively validated on a large 3D US dataset, our method tackles varying fetal poses and achieves promising results. 3D pose estimation of fetus has potentials in serving as a map to provide navigation for many advanced studies.\n    ",
        "primary_category": "cs.CV",
        "categories": [
            "cs.LG",
            "eess.IV"
        ],
        "submitted_date": "11 Oct 2019",
        "last_revised_date": " "
    },
    "1911.08756": {
        "title": "Classification with Costly Features in Hierarchical Deep Sets",
        "authors": [
            "Jarom\u00edr Janisch",
            "Tom\u00e1\u0161 Pevn\u00fd",
            "Viliam Lis\u00fd"
        ],
        "comments": "formerly Hierarchical Multiple-Instance Data Classification with Costly Features; RL4RealLife @ ICML2021; code available at this https URL",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Classification with Costly Features (CwCF) is a classification problem that includes the cost of features in the optimization criteria. Individually for each sample, its features are sequentially acquired to maximize accuracy while minimizing the acquired features' cost. However, existing approaches can only process data that can be expressed as vectors of fixed length. In real life, the data often possesses rich and complex structure, which can be more precisely described with formats such as XML or JSON. The data is hierarchical and often contains nested lists of objects. In this work, we extend an existing deep reinforcement learning-based algorithm with hierarchical deep sets and hierarchical softmax, so that it can directly process this data. The extended method has greater control over which features it can acquire and, in experiments with seven datasets, we show that this leads to superior performance. To showcase the real usage of the new method, we apply it to a real-life problem of classifying malicious web domains, using an online service.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.AI",
            "stat.ML"
        ],
        "submitted_date": "20 Nov 2019",
        "last_revised_date": " "
    },
    "1912.01243": {
        "title": "On irreversible spread of influence in edge-weighted graphs",
        "authors": [
            "Manouchehr Zaker"
        ],
        "comments": " ",
        "subjects": "Discrete Mathematics (cs.DM)",
        "abstract": "Various kinds of spread of influence occur in real world social and virtual networks. These phenomena are formulated by activation processes and irreversible dynamic monopolies in combinatorial graphs representing the topology of the networks. In most cases the nature of influence is weighted and the spread of influence depends on the weight of edges. The ordinary formulation and results for dynamic monopolies do not work for such models. In this paper we present a graph theoretical analysis for spread of weighted influence and mention a real world example realizing the activation model with weighted influence. Then we obtain some extremal bounds and algorithmic results for activation process and dynamic monopolies in directed and undirected graphs with weighted edges.\n    ",
        "primary_category": "cs.DM",
        "categories": [
            "math.CO"
        ],
        "submitted_date": "3 Dec 2019",
        "last_revised_date": " "
    },
    "2002.12438": {
        "title": "Almost Public Quantum Coins",
        "authors": [
            "Amit Behera",
            "Or Sattath"
        ],
        "comments": " ",
        "subjects": "Quantum Physics (quant-ph)",
        "abstract": "In a quantum money scheme, a bank can issue money that users cannot counterfeit. Similar to bills of paper money, most quantum money schemes assign a unique serial number to each money state, thus potentially compromising the privacy of the users of quantum money. However in a quantum coins scheme, just like the traditional currency coin scheme, all the money states are exact copies of each other, providing a better level of privacy for the users. A quantum money scheme can be private, i.e., only the bank can verify the money states, or public, meaning anyone can verify. In this work, we propose a way to lift any private quantum coin scheme -- which is known to exist based on the existence of one-way functions, due to Ji, Liu, and Song (CRYPTO'18) -- to a scheme that closely resembles a public quantum coin scheme. Verification of a new coin is done by comparing it to the coins the user already possesses, by using a projector on to the symmetric subspace. No public coin scheme was known prior to this work. It is also the first construction that is very close to a public quantum money scheme and is provably secure based on standard assumptions. Finally, the lifting technique, when instantiated with the private quantum coins scheme~\\cite{MS10}, gives rise to the first construction that is close to an inefficient unconditionally secure public quantum money scheme.\n    ",
        "primary_category": "quant-ph",
        "categories": [
            "cs.CR"
        ],
        "submitted_date": "27 Feb 2020",
        "last_revised_date": " "
    },
    "2003.09038": {
        "title": "Byzantine-Resilient Distributed Optimization of Multi-Dimensional Functions",
        "authors": [
            "Kananart Kuwaranancharoen",
            "Lei Xin",
            "Shreyas Sundaram"
        ],
        "comments": "10 pages, 1 figure; Proceedings of the 2020 American Control Conference, 1-3 July 2020, Denver, CO, USA",
        "subjects": "Optimization and Control (math.OC)",
        "abstract": "The problem of distributed optimization requires a group of agents to reach agreement on a parameter that minimizes the average of their local cost functions using information received from their neighbors. While there are a variety of distributed optimization algorithms that can solve this problem, they are typically vulnerable to malicious (or ``Byzantine'') agents that do not follow the algorithm. Recent attempts to address this issue focus on single dimensional functions, or provide analysis under certain assumptions on the statistical properties of the functions at the agents. In this paper, we propose a resilient distributed optimization algorithm for multi-dimensional convex functions. Our scheme involves two filtering steps at each iteration of the algorithm: (1) distance-based and (2) component-wise removal of extreme states. We show that this algorithm can mitigate the impact of up to $F$ Byzantine agents in the neighborhood of each regular node, without knowing the identities of the Byzantine agents in advance. In particular, we show that if the network topology satisfies certain conditions, all of the regular states are guaranteed to asymptotically converge to a bounded region that contains the global minimizer.\n    ",
        "primary_category": "math.OC",
        "categories": [
            "cs.MA"
        ],
        "submitted_date": "19 Mar 2020",
        "last_revised_date": " "
    },
    "2005.07423": {
        "title": "Phase Transition of a Non-Linear Opinion Dynamics with Noisy Interactions",
        "authors": [
            "Francesco d'Amore",
            "Andrea Clementi",
            "Emanuele Natale"
        ],
        "comments": " ",
        "subjects": "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "abstract": "In several real \\emph{Multi-Agent Systems} (MAS), it has been observed that only weaker forms of\\emph{metastable consensus} are achieved, in which a large majority of agents agree on some  opinion  while other opinions continue to be supported  by  a (small) minority of agents. In this work, we take a step towards the investigation of metastable consensus for complex (non-linear) \\emph{opinion dynamics} by considering the famous \\undecided dynamics in the binary setting, which is known to reach consensus exponentially faster than the \\voter dynamics.   We propose a simple form of uniform noise in which each message can change to another one with probability $p$ and we prove that the persistence of a \\emph{metastable consensus} undergoes a \\emph{phase transition} for $p=\\frac 16$. In detail, below this threshold, we prove the system  reaches with high probability a metastable regime where  a large majority of agents keeps supporting the same opinion  for polynomial time. Moreover, this opinion turns out to be the initial majority opinion, whenever the initial bias is slightly larger than its standard deviation.On the contrary, above the threshold, we show that the information about the initial majority opinion is  \"lost\" within  logarithmic time even when the initial bias is maximum.Interestingly, using a simple coupling argument, we show the equivalence between our noisy model above and the model where a subset of agents behave in a \\emph{stubborn} way.\n    ",
        "primary_category": "cs.DC",
        "categories": [
            "cs.CC",
            "cs.SI",
            "math.PR"
        ],
        "submitted_date": "15 May 2020",
        "last_revised_date": " "
    },
    "2006.10628": {
        "title": "Offline detection of change-points in the mean for stationary graph signals",
        "authors": [
            "Alejandro de la Concha",
            "Nicolas Vayatis",
            "Argyris Kalogeratos"
        ],
        "comments": "16 pages, 2 figures, 1 table, 1 annex. 9 pages of main text",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "This paper addresses the problem of segmenting a stream of graph signals: we aim to detect changes in the mean of a multivariate signal defined over the nodes of a known graph. We propose an offline method that relies on the concept of graph signal stationarity and allows the convenient translation of the problem from the original vertex domain to the spectral domain (Graph Fourier Transform), where it is much easier to solve. Although the obtained spectral representation is sparse in real applications, to the best of our knowledge this property has not been sufficiently exploited in the existing related literature. Our change-point detection method adopts a model selection approach that takes into account the sparsity of the spectral representation and determines automatically the number of change-points. Our detector comes with a proof of a non-asymptotic oracle inequality. Numerical experiments demonstrate the performance of the proposed method.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "stat.AP",
            "stat.ML"
        ],
        "submitted_date": "18 Jun 2020",
        "last_revised_date": " "
    },
    "2007.12315": {
        "title": "Bayesian Robust Optimization for Imitation Learning",
        "authors": [
            "Daniel S. Brown",
            "Scott Niekum",
            "Marek Petrik"
        ],
        "comments": "In proceedings NeurIPS 2020",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "One of the main challenges in imitation learning is determining what action an agent should take when outside the state distribution of the demonstrations. Inverse reinforcement learning (IRL) can enable generalization to new states by learning a parameterized reward function, but these approaches still face uncertainty over the true reward function and corresponding optimal policy. Existing safe imitation learning approaches based on IRL deal with this uncertainty using a maxmin framework that optimizes a policy under the assumption of an adversarial reward function, whereas risk-neutral IRL approaches either optimize a policy for the mean or MAP reward function. While completely ignoring risk can lead to overly aggressive and unsafe policies, optimizing in a fully adversarial sense is also problematic as it can lead to overly conservative policies that perform poorly in practice. To provide a bridge between these two extremes, we propose Bayesian Robust Optimization for Imitation Learning (BROIL). BROIL leverages Bayesian reward function inference and a user specific risk tolerance to efficiently optimize a robust policy that balances expected return and conditional value at risk. Our empirical results show that BROIL provides a natural way to interpolate between return-maximizing and risk-minimizing behaviors and outperforms existing risk-sensitive and risk-neutral inverse reinforcement learning algorithms. Code is available at this https URL.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "stat.ML"
        ],
        "submitted_date": "24 Jul 2020",
        "last_revised_date": " "
    },
    "2007.14384": {
        "title": "Noise-Induced Barren Plateaus in Variational Quantum Algorithms",
        "authors": [
            "Samson Wang",
            "Enrico Fontana",
            "M. Cerezo",
            "Kunal Sharma",
            "Akira Sone",
            "Lukasz Cincio",
            "Patrick J. Coles"
        ],
        "comments": "12+15 pages, 6+1 figures",
        "subjects": "Quantum Physics (quant-ph)",
        "abstract": "Variational Quantum Algorithms (VQAs) may be a path to quantum advantage on Noisy Intermediate-Scale Quantum (NISQ) computers. A natural question is whether noise on NISQ devices places fundamental limitations on VQA performance. We rigorously prove a serious limitation for noisy VQAs, in that the noise causes the training landscape to have a barren plateau (i.e., vanishing gradient). Specifically, for the local Pauli noise considered, we prove that the gradient vanishes exponentially in the number of qubits $n$ if the depth of the ansatz grows linearly with $n$. These noise-induced barren plateaus (NIBPs) are conceptually different from noise-free barren plateaus, which are linked to random parameter initialization. Our result is formulated for a generic ansatz that includes as special cases the Quantum Alternating Operator Ansatz and the Unitary Coupled Cluster Ansatz, among others. For the former, our numerical heuristics demonstrate the NIBP phenomenon for a realistic hardware noise model.\n    ",
        "primary_category": "quant-ph",
        "categories": [
            "cs.LG"
        ],
        "submitted_date": "28 Jul 2020",
        "last_revised_date": " "
    },
    "2010.15738": {
        "title": "The Agile Coach Role: Coaching for Agile Performance Impact",
        "authors": [
            "Viktoria Stray",
            "Anastasiia Tkalich",
            "Nils Brede Moe"
        ],
        "comments": "10 pages",
        "subjects": "Software Engineering (cs.SE)",
        "abstract": "It is increasingly common to introduce agile coaches to help gain speed and advantage in agile companies. Following the success of Spotify, the role of the agile coach has branched out in terms of tasks and responsibilities, but little research has been conducted to examine how this role is practiced. This paper examines the role of the agile coach through 19 semistructured interviews with agile coaches from ten different companies. We describe the role in terms of the tasks the coach has in agile projects, valuable traits, skills, tools, and the enablers of agile coaching. Our findings indicate that agile coaches perform at the team and organizational levels. They affect effort, strategies, knowledge, and skills of the agile teams. The most essential traits of an agile coach are being emphatic, people-oriented, able to listen, diplomatic, and persistent. We suggest empirically based advice for agile coaching, for example companies giving their agile coaches the authority to implement the required organizational changes within and outside the teams.\n    ",
        "primary_category": "cs.SE",
        "categories": [],
        "submitted_date": "29 Oct 2020",
        "last_revised_date": " "
    },
    "2011.06702": {
        "title": "Neural Network Training Techniques Regularize Optimization Trajectory: An Empirical Study",
        "authors": [
            "Cheng Chen",
            "Junjie Yang",
            "Yi Zhou"
        ],
        "comments": "9 pages, 16 figures, this paper has been accepted as a short paper by the conference of IEEE-bigdata-2020",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Modern deep neural network (DNN) trainings utilize various training techniques, e.g., nonlinear activation functions, batch normalization, skip-connections, etc. Despite their effectiveness, it is still mysterious how they help accelerate DNN trainings in practice. In this paper, we provide an empirical study of the regularization effect of these training techniques on DNN optimization. Specifically, we find that the optimization trajectories of successful DNN trainings consistently obey a certain regularity principle that regularizes the model update direction to be aligned with the trajectory direction. Theoretically, we show that such a regularity principle leads to a convergence guarantee in nonconvex optimization and the convergence rate depends on a regularization parameter. Empirically, we find that DNN trainings that apply the training techniques achieve a fast convergence and obey the regularity principle with a large regularization parameter, implying that the model updates are well aligned with the trajectory. On the other hand, DNN trainings without the training techniques have slow convergence and obey the regularity principle with a small regularization parameter, implying that the model updates are not well aligned with the trajectory. Therefore, different training techniques regularize the model update direction via the regularity principle to facilitate the convergence.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "math.OC"
        ],
        "submitted_date": "13 Nov 2020",
        "last_revised_date": " "
    },
    "2011.07295": {
        "title": "A new vertex coloring heuristic and corresponding chromatic number",
        "authors": [
            "Manouchehr Zaker"
        ],
        "comments": " ",
        "subjects": "Discrete Mathematics (cs.DM)",
        "abstract": "One method to obtain a proper vertex coloring of graphs using a reasonable number of colors is to start from any arbitrary proper coloring and then repeat some local re-coloring techniques to reduce the number of color classes. The Grundy (First-Fit) coloring and color-dominating colorings of graphs are two well-known such techniques. The color-dominating colorings are also known and commonly referred as {\\rm b}-colorings. But these two topics have been studied separately in graph theory. We introduce a new coloring procedure which combines the strategies of these two techniques and satisfies an additional property. We first prove that the vertices of every graph $G$ can be effectively colored using color classes say $C_1, \\ldots, C_k$ such that $(i)$ for any two colors $i$ and $j$ with $1\\leq i< j \\leq k$, any vertex of color $j$ is adjacent to a vertex of color $i$, $(ii)$ there exists a set $\\{u_1, \\ldots, u_k\\}$ of vertices of $G$ such that $u_j\\in C_j$ for any $j\\in \\{1, \\ldots, k\\}$ and $u_k$ is adjacent to $u_j$ for each $1\\leq j \\leq k$ with $j\\not= k$, and $(iii)$ for each $i$ and $j$ with $i\\not= j$, the vertex $u_j$ has a neighbor in $C_i$. This provides a new vertex coloring heuristic which improves both Grundy and color-dominating colorings. Denote by $z(G)$ the maximum number of colors used in any proper vertex coloring satisfying the above properties. The $z(G)$ quantifies the worst-case behavior of the heuristic. We prove the existence of $\\{G_n\\}_{n\\geq 1}$ such that $\\min \\{\\Gamma(G_n), b(G_n)\\} \\rightarrow \\infty$ but $z(G_n)\\leq 3$ for each $n$. For each positive integer $t$ we construct a family of finitely many colored graphs ${\\mathcal{D}}_t$ satisfying the property that if $z(G)\\geq t$ for a graph $G$ then $G$ contains an element from ${\\mathcal{D}}_t$ as a colored subgraph. This provides an algorithmic method for proving numeric upper bounds for $z(G)$.\n    ",
        "primary_category": "cs.DM",
        "categories": [
            "math.CO"
        ],
        "submitted_date": "14 Nov 2020",
        "last_revised_date": " "
    },
    "2101.12700": {
        "title": "Reservoir Computing with Magnetic Thin Films",
        "authors": [
            "Matthew Dale",
            "David Griffin",
            "Richard F. L. Evans",
            "Sarah Jenkins",
            "Simon O'Keefe",
            "Angelika Sebald",
            "Susan Stepney",
            "Fernando Torre",
            "Martin Trefzer"
        ],
        "comments": "30 pages, 10 figures, updated and clarified",
        "subjects": "Emerging Technologies (cs.ET)",
        "abstract": "Advances in artificial intelligence are driven by technologies inspired by the brain, but these technologies are orders of magnitude less powerful and energy efficient than biological systems. Inspired by the nonlinear dynamics of neural networks, new unconventional computing hardware has emerged with the potential to exploit natural phenomena and gain efficiency, in a similar manner to biological systems. Physical reservoir computing demonstrates this with a variety of unconventional systems, from optical-based to memristive systems. Reservoir computers provide a nonlinear projection of the task input into a high-dimensional feature space by exploiting the system's internal dynamics. A trained readout layer then combines features to perform tasks, such as pattern recognition and time-series analysis. Despite progress, achieving state-of-the-art performance without external signal processing to the reservoir remains challenging. Here we perform an initial exploration of three magnetic materials in thin-film geometries via microscale simulation. Our results reveal that basic spin properties of magnetic films generate the required nonlinear dynamics and memory to solve machine learning tasks (although there would be practical challenges in exploiting these particular materials in physical implementations). The method of exploration can be applied to other materials, so this work opens up the possibility of testing different materials, from relatively simple (alloys) to significantly complex (antiferromagnetic reservoirs).\n    ",
        "primary_category": "cs.ET",
        "categories": [
            "cond-mat.mtrl-sci",
            "cs.AR",
            "cs.LG",
            "cs.NE"
        ],
        "submitted_date": "29 Jan 2021",
        "last_revised_date": " "
    },
    "2102.06202": {
        "title": "Private Prediction Sets",
        "authors": [
            "Anastasios N. Angelopoulos",
            "Stephen Bates",
            "Tijana Zrnic",
            "Michael I. Jordan"
        ],
        "comments": "Code available at this https URL",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "In real-world settings involving consequential decision-making, the deployment of machine learning systems generally requires both reliable uncertainty quantification and protection of individuals' privacy. We present a framework that treats these two desiderata jointly. Our framework is based on conformal prediction, a methodology that augments predictive models to return prediction sets that provide uncertainty quantification -- they provably cover the true response with a user-specified probability, such as 90%. One might hope that when used with privately-trained models, conformal prediction would yield privacy guarantees for the resulting prediction sets; unfortunately, this is not the case. To remedy this key problem, we develop a method that takes any pre-trained predictive model and outputs differentially private prediction sets. Our method follows the general approach of split conformal prediction; we use holdout data to calibrate the size of the prediction sets but preserve privacy by using a privatized quantile subroutine. This subroutine compensates for the noise introduced to preserve privacy in order to guarantee correct coverage. We evaluate the method on large-scale computer vision datasets.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.AI",
            "cs.CR",
            "stat.ME",
            "stat.ML"
        ],
        "submitted_date": "11 Feb 2021",
        "last_revised_date": " "
    },
    "2103.08413": {
        "title": "Megha: Decentralized Global Fair Scheduling for Federated Clusters",
        "authors": [
            "Meghana Thiyyakat",
            "Subramaniam Kalambur",
            "Dinkar Sitaram"
        ],
        "comments": "10 pages, 12 figures, conference paper",
        "subjects": "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "abstract": "Increasing scale and heterogeneity in data centers have led to the development of federated clusters such as KubeFed, Hydra, and Pigeon, that federate individual data center clusters. In our work, we introduce Megha, a novel decentralized resource management framework for such federated clusters. Megha employs flexible logical partitioning of clusters to distribute its scheduling load, ensuring that the requirements of the workload are satisfied with very low scheduling overheads. It uses a distributed global scheduler that does not rely on a centralized data store but, instead, works with eventual consistency, unlike other schedulers that use a tiered architecture or rely on centralized databases. Our experiments with Megha show that it can schedule tasks taking into account fairness and placement constraints with low resource allocation times - in the order of tens of milliseconds.\n    ",
        "primary_category": "cs.DC",
        "categories": [],
        "submitted_date": "15 Mar 2021",
        "last_revised_date": " "
    },
    "2103.12468": {
        "title": "Approximately Counting Answers to Conjunctive Queries with Disequalities and Negations",
        "authors": [
            "Jacob Focke",
            "Leslie Ann Goldberg",
            "Marc Roth",
            "Stanislav \u017divn\u00fd"
        ],
        "comments": "An extended abstract of this work appeared in the proceedings of PODS22. 30 pages, 1 figure",
        "subjects": "Discrete Mathematics (cs.DM)",
        "abstract": "We study the complexity of approximating the number of answers to a small query $\\varphi$ in a large database $\\mathcal{D}$. We establish an exhaustive classification into tractable and intractable cases if $\\varphi$ is a conjunctive query with disequalities and negations:\n$\\bullet$ If there is a constant bound on the arity of $\\varphi$, and if the randomised Exponential Time Hypothesis (rETH) holds, then the problem has a fixed-parameter tractable approximation scheme (FPTRAS) if and only if the treewidth of $\\varphi$ is bounded.\n$\\bullet$ If the arity is unbounded and we allow disequalities only, then the problem has an FPTRAS if and only if the adaptive width of $\\varphi$ (a width measure strictly more general than treewidth) is bounded; the lower bound relies on the rETH as well.\nAdditionally we show that our results cannot be strengthened to achieve a fully polynomial randomised approximation scheme (FPRAS): We observe that, unless $\\mathrm{NP} =\\mathrm{RP}$, there is no FPRAS even if the treewidth (and the adaptive width) is $1$. However, if there are neither disequalities nor negations, we prove the existence of an FPRAS for queries of bounded fractional hypertreewidth, strictly generalising the recently established FPRAS for conjunctive queries with bounded hypertreewidth due to Arenas, Croquevielle, Jayaram and Riveros (STOC 2021).\n    ",
        "primary_category": "cs.DM",
        "categories": [
            "cs.CC",
            "cs.DB"
        ],
        "submitted_date": "23 Mar 2021",
        "last_revised_date": " "
    },
    "2103.16031": {
        "title": "Certifiably-Robust Federated Adversarial Learning via Randomized Smoothing",
        "authors": [
            "Cheng Chen",
            "Bhavya Kailkhura",
            "Ryan Goldhahn",
            "Yi Zhou"
        ],
        "comments": "9 pages, 12 figures",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Federated learning is an emerging data-private distributed learning framework, which, however, is vulnerable to adversarial attacks. Although several heuristic defenses are proposed to enhance the robustness of federated learning, they do not provide certifiable robustness guarantees. In this paper, we incorporate randomized smoothing techniques into federated adversarial training to enable data-private distributed learning with certifiable robustness to test-time adversarial perturbations. Our experiments show that such an advanced federated adversarial learning framework can deliver models as robust as those trained by the centralized training. Further, this enables provably-robust classifiers to $\\ell_2$-bounded adversarial perturbations in a distributed setup. We also show that one-point gradient estimation based training approach is $2-3\\times$ faster than popular stochastic estimator based approach without any noticeable certified robustness differences.\n    ",
        "primary_category": "cs.LG",
        "categories": [],
        "submitted_date": "30 Mar 2021",
        "last_revised_date": " "
    },
    "2105.05377": {
        "title": "Identity Concealment Games: How I Learned to Stop Revealing and Love the Coincidences",
        "authors": [
            "Mustafa O. Karabag",
            "Melkior Ornik",
            "Ufuk Topcu"
        ],
        "comments": " ",
        "subjects": "Computer Science and Game Theory (cs.GT)",
        "abstract": "In an adversarial environment, a hostile player performing a task may behave like a non-hostile one in order not to reveal its identity to an opponent. To model such a scenario, we define identity concealment games: zero-sum stochastic reachability games with a zero-sum objective of identity concealment. To measure the identity concealment of the player, we introduce the notion of an average player. The average player's policy represents the expected behavior of a non-hostile player. We show that there exists an equilibrium policy pair for every identity concealment game and give the optimality equations to synthesize an equilibrium policy pair. If the player's opponent follows a non-equilibrium policy, the player can hide its identity better. For this reason, we study how the hostile player may learn the opponent's policy. Since learning via exploration policies would quickly reveal the hostile player's identity to the opponent, we consider the problem of learning a near-optimal policy for the hostile player using the game runs collected under the average player's policy. Consequently, we propose an algorithm that provably learns a near-optimal policy and give an upper bound on the number of sample runs to be collected.\n    ",
        "primary_category": "cs.GT",
        "categories": [
            "cs.MA",
            "math.OC"
        ],
        "submitted_date": "12 May 2021",
        "last_revised_date": " "
    },
    "2105.13937": {
        "title": "Polygonal Unadjusted Langevin Algorithms: Creating stable and efficient adaptive algorithms for neural networks",
        "authors": [
            "Dong-Young Lim",
            "Sotirios Sabanis"
        ],
        "comments": " ",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "We present a new class of Langevin based algorithms, which overcomes many of the known shortcomings of popular adaptive optimizers that are currently used for the fine tuning of deep learning models. Its underpinning theory relies on recent advances of Euler's polygonal approximations for stochastic differential equations (SDEs) with monotone coefficients. As a result, it inherits the stability properties of tamed algorithms, while it addresses other known issues, e.g. vanishing gradients in neural networks. In particular, we provide a nonasymptotic analysis and full theoretical guarantees for the convergence properties of an algorithm of this novel class, which we named TH$\\varepsilon$O POULA (or, simply, TheoPouLa). Finally, several experiments are presented with different types of deep learning models, which show the superior performance of TheoPouLa over many popular adaptive optimization algorithms.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "math.OC",
            "math.PR",
            "stat.ML"
        ],
        "submitted_date": "28 May 2021",
        "last_revised_date": " "
    },
    "2106.01768": {
        "title": "Homeostasis: Design and Implementation of a Self-Stabilizing Compiler",
        "authors": [
            "Aman Nougrahiya",
            "V. Krishna Nandivada"
        ],
        "comments": "Accepted for publication in ACM TOPLAS. 58 pages, 36 figures. Patent granted in India. US Patent published. For associated code, see this https URL",
        "subjects": "Programming Languages (cs.PL)",
        "abstract": "Mainstream compilers perform a multitude of analyses and optimizations on the given input program. Each analysis (such as points-to analysis) may generate a program-abstraction (such as points-to graph). Each optimization is typically composed of multiple alternating phases of inspection of such program-abstractions and transformations of the program. Upon transformation of a program, the program-abstractions generated by various analyses may become inconsistent with the modified program. Consequently, the correctness of the downstream inspection (and consequent transformation) phases cannot be ensured until the relevant program-abstractions are stabilized; that is, the program-abstractions are either invalidated or made consistent with the modified program. In general, the existing compiler frameworks do not perform automated stabilization of the program-abstractions and instead leave it to the compiler pass writers to deal with the complex task of identifying the relevant program-abstractions to be stabilized, the points where the stabilization is to be performed, and the exact procedure of stabilization. In this paper, we address these challenges by providing the design and implementation of a novel compiler-design framework called Homeostasis. Homeostasis automatically captures all the program changes performed by each transformation phase, and later, triggers the required stabilization using the captured information, if needed. We also provide a formal description of Homeostasis and a correctness proof thereof. To assess the feasibility of using Homeostasis in compilers of parallel programs, we have implemented our proposed idea in IMOP, a compiler framework for OpenMP C programs. We present an evaluation which demonstrates that Homeostasis is efficient and easy to use.\n    ",
        "primary_category": "cs.PL",
        "categories": [],
        "submitted_date": "3 Jun 2021",
        "last_revised_date": " "
    },
    "2106.08060": {
        "title": "Privacy Assessment of Federated Learning using Private Personalized Layers",
        "authors": [
            "Th\u00e9o Jourdan",
            "Antoine Boutet",
            "Carole Frindel"
        ],
        "comments": " ",
        "subjects": "Cryptography and Security (cs.CR)",
        "abstract": "Federated Learning (FL) is a collaborative scheme to train a learning model across multiple participants without sharing data. While FL is a clear step forward towards enforcing users' privacy, different inference attacks have been developed. In this paper, we quantify the utility and privacy trade-off of a FL scheme using private personalized layers. While this scheme has been proposed as local adaptation to improve the accuracy of the model through local personalization, it has also the advantage to minimize the information about the model exchanged with the server. However, the privacy of such a scheme has never been quantified. Our evaluations using motion sensor dataset show that personalized layers speed up the convergence of the model and slightly improve the accuracy for all users compared to a standard FL scheme while better preventing both attribute and membership inferences compared to a FL scheme using local differential privacy.\n    ",
        "primary_category": "cs.CR",
        "categories": [
            "cs.AI",
            "cs.LG"
        ],
        "submitted_date": "15 Jun 2021",
        "last_revised_date": " "
    },
    "2106.10479": {
        "title": "Practical Transferability Estimation for Image Classification Tasks",
        "authors": [
            "Yang Tan",
            "Yang Li",
            "Shao-Lun Huang"
        ],
        "comments": "This paper is not the latest version. Please refer to Transferability-Guided Cross-Domain Cross-Task Transfer Learning (IEEE TNNLS'24) for more details.this https URL",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Transferability estimation is an essential problem in transfer learning to predict how good the performance is when transferring a source model (or source task) to a target task. Recent analytical transferability metrics have been widely used for source model selection and multi-task learning. A major challenge is how to make transfereability estimation robust under the cross-domain cross-task settings. The recently proposed OTCE score solves this problem by considering both domain and task differences, with the help of transfer experiences on auxiliary tasks, which causes an efficiency overhead. In this work, we propose a practical transferability metric called JC-NCE score that dramatically improves the robustness of the task difference estimation in OTCE, thus removing the need for auxiliary tasks. Specifically, we build the joint correspondences between source and target data via solving an optimal transport problem with a ground cost considering both the sample distance and label distance, and then compute the transferability score as the negative conditional entropy of the matched labels. Extensive validations under the intra-dataset and inter-dataset transfer settings demonstrate that our JC-NCE score outperforms the auxiliary-task free version of OTCE for 7% and 12%, respectively, and is also more robust than other existing transferability metrics on average.\n    ",
        "primary_category": "cs.CV",
        "categories": [
            "cs.AI",
            "cs.LG"
        ],
        "submitted_date": "19 Jun 2021",
        "last_revised_date": " "
    },
    "2106.11886": {
        "title": "The Separation of $\\mathcal{NP}$ and $\\mathcal{PSPACE}$",
        "authors": [
            "Tianrong Lin"
        ],
        "comments": "[v22] minor revision; 20 pages, 1 figure; arXiv admin note: text overlap with arXiv:2110.06211",
        "subjects": "Computational Complexity (cs.CC)",
        "abstract": "There is a important and interesting open question in computational complexity on the relation between the complexity classes $\\mathcal{NP}$ and $\\mathcal{PSPACE}$. It is a widespread belief that $\\mathcal{NP}\\neq \\mathcal{PSPACE}$. In this paper, we confirm this conjecture by showing that there is a language $L_d$ accepted by no polynomial-time nondeterministic Turing machines but accepted by a nondeterministic Turing machine running within space $O(n^k)$ for all $k\\in\\mathbb{N}_1$, by virtue of the premise of \\[\\text{NTIME}[S(n)]\\subseteq\\text{DSPACE}[S(n)],\\] and then by diagonalization against all polynomial-time nondeterministic Turing machines via a universal nondeterministic Turing machine $M_0$ running in space $O(n^k)$ for all $k\\in\\mathbb{N}_1$. We further show that $L_d\\in \\mathcal{PSPACE}$, which leads to the conclusion \\[\\mathcal{NP}\\subsetneqq\\mathcal{PSPACE}.\\] Our approach is based on standard diagonalization similar to \\cite{Lin21a,Lin21b} with some new refinement.\n    ",
        "primary_category": "cs.CC",
        "categories": [],
        "submitted_date": "22 Jun 2021",
        "last_revised_date": " "
    },
    "2106.14969": {
        "title": "Hop-Constrained Metric Embeddings and their Applications",
        "authors": [
            "Arnold Filtser"
        ],
        "comments": " ",
        "subjects": "Data Structures and Algorithms (cs.DS)",
        "abstract": "In network design problems, such as compact routing, the goal is to route packets between nodes using the (approximated) shortest paths. A desirable property of these routes is a small number of hops, which makes them more reliable, and reduces the transmission costs. Following the overwhelming success of stochastic tree embeddings for algorithmic design, Haeupler, Hershkowitz, and Zuzic (STOC'21) studied hop-constrained Ramsey-type metric embeddings into trees. Specifically, embedding $f:G(V,E)\\rightarrow T$ has Ramsey hop-distortion $(t,M,\\beta,h)$ (here $t,\\beta,h\\ge1$ and $M\\subseteq V$) if $\\forall u,v\\in M$, $d_G^{(\\beta\\cdot h)}(u,v)\\le d_T(u,v)\\le t\\cdot d_G^{(h)}(u,v)$. $t$ is called the distortion, $\\beta$ is called the hop-stretch, and $d_G^{(h)}(u,v)$ denotes the minimum weight of a $u-v$ path with at most $h$ hops. Haeupler {\\em et al.} constructed embedding where $M$ contains $1-\\epsilon$ fraction of the vertices and $\\beta=t=O(\\frac{\\log^2 n}{\\epsilon})$. They used their embedding to obtain multiple bicriteria approximation algorithms for hop-constrained network design problems.\nIn this paper, we first improve the Ramsey-type embedding to obtain parameters $t=\\beta=\\frac{\\tilde{O}(\\log n)}{\\epsilon}$, and generalize it to arbitrary distortion parameter $t$ (in the cost of reducing the size of $M$). This embedding immediately implies polynomial improvements for all the approximation algorithms from Haeupler {\\em et al.}. Further, we construct hop-constrained clan embeddings (where each vertex has multiple copies), and use them to construct bicriteria approximation algorithms for the group Steiner tree problem, matching the state of the art of the non constrained version. Finally, we use our embedding results to construct hop constrained distance oracles, distance labeling, and most prominently, the first hop constrained compact routing scheme with provable guarantees.\n    ",
        "primary_category": "cs.DS",
        "categories": [
            "cs.DM"
        ],
        "submitted_date": "28 Jun 2021",
        "last_revised_date": " "
    },
    "2107.01815": {
        "title": "A Formal Semantics of the GraalVM Intermediate Representation",
        "authors": [
            "Brae J. Webb",
            "Mark Utting",
            "Ian J. Hayes"
        ],
        "comments": "16 pages, 8 figures, to be published to ATVA 2021",
        "subjects": "Logic in Computer Science (cs.LO)",
        "abstract": "The optimization phase of a compiler is responsible for transforming an intermediate representation (IR) of a program into a more efficient form. Modern optimizers, such as that used in the GraalVM compiler, use an IR consisting of a sophisticated graph data structure that combines data flow and control flow into the one structure. As part of a wider project on the verification of optimization passes of GraalVM, this paper describes a semantics for its IR within Isabelle/HOL. The semantics consists of a big-step operational semantics for data nodes (which are represented in a graph-based static single assignment (SSA) form) and a small-step operational semantics for handling control flow including heap-based reads and writes, exceptions, and method calls. We have proved a suite of canonicalization optimizations and conditional elimination optimizations with respect to the semantics.\n    ",
        "primary_category": "cs.LO",
        "categories": [
            "cs.PL"
        ],
        "submitted_date": "5 Jul 2021",
        "last_revised_date": " "
    },
    "2107.02270": {
        "title": "Accessible Color Sequences for Data Visualization",
        "authors": [
            "Matthew A. Petroff"
        ],
        "comments": "26 pages, 4 figures, 4 tables; comments welcome",
        "subjects": "Graphics (cs.GR)",
        "abstract": "Color sequences, ordered sets of colors for data visualization, that balance aesthetics with accessibility considerations are presented. In order to model aesthetic preference, data were collected with an online survey, and the results were used to train a machine-learning model. To ensure accessibility, this model was combined with minimum-perceptual-distance constraints, including for simulated color-vision deficiencies, as well as with minimum-lightness-distance constraints for grayscale printing, maximum-lightness constraints for maintaining contrast with a white background, and scores from a color-saliency model for ease of use of the colors in verbal and written descriptions. Optimal color sequences containing six, eight, and ten colors were generated using the data-driven aesthetic-preference model and accessibility constraints. Due to the balance of aesthetics and accessibility considerations, the resulting color sequences can serve as reasonable defaults in data-plotting codes, e.g., for use in scatter plots and line plots.\n    ",
        "primary_category": "cs.GR",
        "categories": [],
        "submitted_date": "5 Jul 2021",
        "last_revised_date": " "
    },
    "2107.02743": {
        "title": "Submodular Order Functions and Assortment Optimization",
        "authors": [
            "Rajan Udwani"
        ],
        "comments": "To appear in Management Science",
        "subjects": "Optimization and Control (math.OC)",
        "abstract": "We define a new class of set functions that in addition to being monotone and subadditive, also admit a very limited form of submodularity defined over a permutation of the ground set. We refer to this permutation as a submodular order. This class of functions includes monotone submodular functions as a sub-family. We give fast algorithms with strong approximation guarantees for maximizing submodular order functions under a variety of constraints and show a nearly tight upper bound on the highest approximation guarantee achievable by algorithms with polynomial query complexity. Applying this new notion to the problem of constrained assortment optimization in fundamental choice models, we obtain new algorithms that are both faster and have stronger approximation guarantees (in some cases, first algorithm with constant factor guarantee). We also show an intriguing connection to the maximization of monotone submodular functions in the streaming model, where we recover best known approximation guarantees as a corollary of our results.\n    ",
        "primary_category": "math.OC",
        "categories": [
            "cs.DS"
        ],
        "submitted_date": "6 Jul 2021",
        "last_revised_date": " "
    },
    "2107.04252": {
        "title": "A Tight Max-Flow Min-Cut Duality Theorem for Non-Linear Multicommodity Flows",
        "authors": [
            "Matthew Broussard",
            "Bala Krishnamoorthy"
        ],
        "comments": "Minor revisions; to appear in the Journal of Combinatorial Optimization",
        "subjects": "Data Structures and Algorithms (cs.DS)",
        "abstract": "The Max-Flow Min-Cut theorem is the classical duality result for the Max-Flow problem, which considers flow of a single commodity. We study a multiple commodity generalization of Max-Flow in which flows are composed of real-valued k-vectors through networks with arc capacities formed by regions in \\R^k. Given the absence of a clear notion of ordering in the multicommodity case, we define the generalized max flow as the feasible region of all flow values.\nWe define a collection of concepts and operations on flows and cuts in the multicommodity setting. We study the mutual capacity of a set of cuts, defined as the set of flows that can pass through all cuts in the set. We present a method to calculate the mutual capacity of pairs of cuts, and then generalize the same to a method of calculation for arbitrary sets of cuts. We show that the mutual capacity is exactly the set of feasible flows in the network, and hence is equal to the max flow. Furthermore, we present a simple class of the multicommodity max flow problem where computations using this tight duality result could run significantly faster than default brute force computations.\nWe also study more tractable special cases of the multicommodity max flow problem where the objective is to transport a maximum real or integer multiple of a given vector through the network. We devise an augmenting cycle search algorithm that reduces the optimization problem to one with m constraints in at most \\R^{(m-n+1)k} space from one that requires mn constraints in \\R^{mk} space for a network with n nodes and m edges. We present efficient algorithms that compute eps-approximations to both the ratio and the integer ratio maximum flow problems.\n    ",
        "primary_category": "cs.DS",
        "categories": [
            "math.AT"
        ],
        "submitted_date": "9 Jul 2021",
        "last_revised_date": " "
    },
    "2107.04771": {
        "title": "Similar Cases Recommendation using Legal Knowledge Graphs",
        "authors": [
            "Jaspreet Singh Dhani",
            "Ruchika Bhatt",
            "Balaji Ganesan",
            "Parikshet Sirohi",
            "Vasudha Bhatnagar"
        ],
        "comments": "10 pages. 6 figures. 3rd Symposium on Artificial Intelligence and Law. SAIL 2023",
        "subjects": "Artificial Intelligence (cs.AI)",
        "abstract": "A legal knowledge graph constructed from court cases, judgments, laws and other legal documents can enable a number of applications like question answering, document similarity, and search. While the use of knowledge graphs for distant supervision in NLP tasks is well researched, using knowledge graphs for applications like case similarity presents challenges. In this work, we describe our solution for predicting similar cases in Indian court judgements. We present our results and also discuss the impact of large language models on this task.\n    ",
        "primary_category": "cs.AI",
        "categories": [],
        "submitted_date": "10 Jul 2021",
        "last_revised_date": " "
    },
    "2107.06570": {
        "title": "QoS-Aware Scheduling in New Radio Using Deep Reinforcement Learning",
        "authors": [
            "Jakob Stigenberg",
            "Vidit Saxena",
            "Soma Tayamon",
            "Euhanna Ghadimi"
        ],
        "comments": " ",
        "subjects": "Networking and Internet Architecture (cs.NI)",
        "abstract": "Fifth-generation (5G) New Radio (NR) cellular networks support a wide range of new services, many of which require an application-specific quality of service (QoS), e.g. in terms of a guaranteed minimum bit-rate or a maximum tolerable delay. Therefore, scheduling multiple parallel data flows, each serving a unique application instance, is bound to become an even more challenging task compared to the previous generations. Leveraging recent advances in deep reinforcement learning, in this paper, we propose a QoS-Aware Deep Reinforcement learning Agent (QADRA) scheduler for NR networks. In contrast to state-of-the-art scheduling heuristics, the QADRA scheduler explicitly optimizes for the QoS satisfaction rate while simultaneously maximizing the network performance. Moreover, we train our algorithm end-to-end on these objectives. We evaluate QADRA in a full scale, near-product, system level NR simulator and demonstrate a significant boost in network performance. In our particular evaluation scenario, the QADRA scheduler improves network throughput by 30% while simultaneously maintaining the QoS satisfaction rate of VoIP users served by the network, compared to state-of-the-art baselines.\n    ",
        "primary_category": "cs.NI",
        "categories": [
            "cs.AI",
            "eess.SY"
        ],
        "submitted_date": "14 Jul 2021",
        "last_revised_date": " "
    },
    "2107.11977": {
        "title": "Strategyproof Facility Location in Perturbation Stable Instances",
        "authors": [
            "Dimitris Fotakis",
            "Panagiotis Patsilinakos"
        ],
        "comments": " ",
        "subjects": "Computer Science and Game Theory (cs.GT)",
        "abstract": "We consider $k$-Facility Location games, where $n$ strategic agents report their locations on the real line, and a mechanism maps them to $k\\ge 2$ facilities. Each agent seeks to minimize her distance to the nearest facility. We are interested in (deterministic or randomized) strategyproof mechanisms without payments that achieve a reasonable approximation ratio to the optimal social cost of the agents. To circumvent the inapproximability of $k$-Facility Location by deterministic strategyproof mechanisms, we restrict our attention to perturbation stable instances. An instance of $k$-Facility Location on the line is $\\gamma$-perturbation stable (or simply, $\\gamma$-stable), for some $\\gamma\\ge 1$, if the optimal agent clustering is not affected by moving any subset of consecutive agent locations closer to each other by a factor at most $\\gamma$. We show that the optimal solution is strategyproof in $(2+\\sqrt{3})$-stable instances whose optimal solution does not include any singleton clusters, and that allocating the facility to the agent next to the rightmost one in each optimal cluster (or to the unique agent, for singleton clusters) is strategyproof and $(n-2)/2$-approximate for $5$-stable instances (even if their optimal solution includes singleton clusters). On the negative side, we show that for any $k\\ge 3$ and any $\\delta > 0$, there is no deterministic anonymous mechanism that achieves a bounded approximation ratio and is strategyproof in $(\\sqrt{2}-\\delta)$-stable instances. We also prove that allocating the facility to a random agent of each optimal cluster is strategyproof and $2$-approximate in $5$-stable instances. To the best of our knowledge, this is the first time that the existence of deterministic (resp. randomized) strategyproof mechanisms with a bounded (resp. constant) approximation ratio is shown for a large and natural class of $k$-Facility Location instances.\n    ",
        "primary_category": "cs.GT",
        "categories": [],
        "submitted_date": "26 Jul 2021",
        "last_revised_date": " "
    },
    "2107.14297": {
        "title": "Mobilkit: A Python Toolkit for Urban Resilience and Disaster Risk Management Analytics using High Frequency Human Mobility Data",
        "authors": [
            "Enrico Ubaldi",
            "Takahiro Yabe",
            "Nicholas K. W. Jones",
            "Maham Faisal Khan",
            "Satish V. Ukkusuri",
            "Riccardo Di Clemente",
            "Emanuele Strano"
        ],
        "comments": "3 pages, 1 figure, KDD KDD Workshop on Data-driven Humanitarian Mapping, 27th ACM SIGKDD Conference",
        "subjects": "Computers and Society (cs.CY)",
        "abstract": "Increasingly available high-frequency location datasets derived from smartphones provide unprecedented insight into trajectories of human mobility. These datasets can play a significant and growing role in informing preparedness and response to natural disasters. However, limited tools exist to enable rapid analytics using mobility data, and tend not to be tailored specifically for disaster risk management. We present an open-source, Python-based toolkit designed to conduct replicable and scalable post-disaster analytics using GPS location data. Privacy, system capabilities, and potential expansions of \\textit{Mobilkit} are discussed.\n    ",
        "primary_category": "cs.CY",
        "categories": [
            "cs.SI",
            "physics.soc-ph"
        ],
        "submitted_date": "29 Jul 2021",
        "last_revised_date": " "
    },
    "2108.04567": {
        "title": "Robust and Dexterous Dual-arm Tele-Cooperation using Adaptable Impedance Control",
        "authors": [
            "Keyhan Kouhkiloui Babarahmati",
            "Mohammadreza Kasaei",
            "Carlo Tiseo",
            "Michael Mistry",
            "Sethu Vijayakumar"
        ],
        "comments": " ",
        "subjects": "Robotics (cs.RO)",
        "abstract": "In recent years, the need for robots to transition from isolated industrial tasks to shared environments, including human-robot collaboration and teleoperation, has become increasingly evident. Building on the foundation of Fractal Impedance Control (FIC) introduced in our previous work, this paper presents a novel extension to dual-arm tele-cooperation, leveraging the non-linear stiffness and passivity of FIC to adapt to diverse cooperative scenarios. Unlike traditional impedance controllers, our approach ensures stability without relying on energy tanks, as demonstrated in our prior research. In this paper, we further extend the FIC framework to bimanual operations, allowing for stable and smooth switching between different dynamic tasks without gain tuning. We also introduce a telemanipulation architecture that offers higher transparency and dexterity, addressing the challenges of signal latency and low-bandwidth communication. Through extensive experiments, we validate the robustness of our method and the results confirm the advantages of the FIC approach over traditional impedance controllers, showcasing its potential for applications in planetary exploration and other scenarios requiring dexterous telemanipulation. This paper's contributions include the seamless integration of FIC into multi-arm systems, the ability to perform robust interactions in highly variable environments, and the provision of a comprehensive comparison with competing approaches, thereby significantly enhancing the robustness and adaptability of robotic systems.\n    ",
        "primary_category": "cs.RO",
        "categories": [],
        "submitted_date": "10 Aug 2021",
        "last_revised_date": " "
    },
    "2109.09307": {
        "title": "Assisted Learning for Organizations with Limited Imbalanced Data",
        "authors": [
            "Cheng Chen",
            "Jiaying Zhou",
            "Jie Ding",
            "Yi Zhou"
        ],
        "comments": "Published in Transactions on Machine Learning Research (TMLR) (05/2023)",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "In the era of big data, many big organizations are integrating machine learning into their work pipelines to facilitate data analysis. However, the performance of their trained models is often restricted by limited and imbalanced data available to them. In this work, we develop an assisted learning framework for assisting organizations to improve their learning performance. The organizations have sufficient computation resources but are subject to stringent data-sharing and collaboration policies. Their limited imbalanced data often cause biased inference and sub-optimal decision-making. In assisted learning, an organizational learner purchases assistance service from an external service provider and aims to enhance its model performance within only a few assistance rounds. We develop effective stochastic training algorithms for both assisted deep learning and assisted reinforcement learning. Different from existing distributed algorithms that need to frequently transmit gradients or models, our framework allows the learner to only occasionally share information with the service provider, but still obtain a model that achieves near-oracle performance as if all the data were centralized.\n    ",
        "primary_category": "cs.LG",
        "categories": [],
        "submitted_date": "20 Sep 2021",
        "last_revised_date": " "
    },
    "2109.12550": {
        "title": "MixNN: Protection of Federated Learning Against Inference Attacks by Mixing Neural Network Layers",
        "authors": [
            "Antoine Boutet",
            "Thomas Lebrun",
            "Jan Aalmoes",
            "Adrien Baud"
        ],
        "comments": " ",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Machine Learning (ML) has emerged as a core technology to provide learning models to perform complex tasks. Boosted by Machine Learning as a Service (MLaaS), the number of applications relying on ML capabilities is ever increasing. However, ML models are the source of different privacy violations through passive or active attacks from different entities. In this paper, we present MixNN a proxy-based privacy-preserving system for federated learning to protect the privacy of participants against a curious or malicious aggregation server trying to infer sensitive attributes. MixNN receives the model updates from participants and mixes layers between participants before sending the mixed updates to the aggregation server. This mixing strategy drastically reduces privacy without any trade-off with utility. Indeed, mixing the updates of the model has no impact on the result of the aggregation of the updates computed by the server. We experimentally evaluate MixNN and design a new attribute inference attack, Sim, exploiting the privacy vulnerability of SGD algorithm to quantify privacy leakage in different settings (i.e., the aggregation server can conduct a passive or an active attack). We show that MixNN significantly limits the attribute inference compared to a baseline using noisy gradient (well known to damage the utility) while keeping the same level of utility as classic federated learning.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.CR"
        ],
        "submitted_date": "26 Sep 2021",
        "last_revised_date": " "
    },
    "2109.12586": {
        "title": "Optimal Simulation of Quantum Measurements via the Likelihood POVMs",
        "authors": [
            "Arun Padakandla"
        ],
        "comments": " ",
        "subjects": "Quantum Physics (quant-ph)",
        "abstract": "By developing a new framework of likelihood POVMs, analysis techniques and a new proof of the quantum covering lemma, we address the simulation of separable quantum measurement over bipartite states. In addition to a new one shot inner bound that naturally generalizes to the asymptotic case, we demonstrate the power, generality and universality of the developed techniques in the most general distributed measurement scenario by recovering all current known inner bounds. In addition to the above results, this framework is appealing in being the most natural and simple POVM simulation protocol.\n    ",
        "primary_category": "quant-ph",
        "categories": [
            "cs.IT"
        ],
        "submitted_date": "26 Sep 2021",
        "last_revised_date": " "
    },
    "2109.15242": {
        "title": "Transferability Estimation for Semantic Segmentation Task",
        "authors": [
            "Yang Tan",
            "Yang Li",
            "Shao-Lun Huang"
        ],
        "comments": "This paper is not the latest version. Please refer to Efficient Prediction of Model Transferability in Semantic Segmentation Tasks (ICIP'23) for more details. this https URL",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Transferability estimation is a fundamental problem in transfer learning to predict how good the performance is when transferring a source model (or source task) to a target task. With the guidance of transferability score, we can efficiently select the highly transferable source models without performing the real transfer in practice. Recent analytical transferability metrics are mainly designed for image classification problem, and currently there is no specific investigation for the transferability estimation of semantic segmentation task, which is an essential problem in autonomous driving, medical image analysis, etc. Consequently, we further extend the recent analytical transferability metric OTCE (Optimal Transport based Conditional Entropy) score to the semantic segmentation task. The challenge in applying the OTCE score is the high dimensional segmentation output, which is difficult to find the optimal coupling between so many pixels under an acceptable computation cost. Thus we propose to randomly sample N pixels for computing OTCE score and take the expectation over K repetitions as the final transferability score. Experimental evaluation on Cityscapes, BDD100K and GTA5 datasets demonstrates that the OTCE score highly correlates with the transfer performance.\n    ",
        "primary_category": "cs.CV",
        "categories": [],
        "submitted_date": "30 Sep 2021",
        "last_revised_date": " "
    },
    "2110.06211": {
        "title": "Diagonalization of Polynomial-Time Deterministic Turing Machines via Nondeterministic Turing Machines",
        "authors": [
            "Tianrong Lin"
        ],
        "comments": "[v27] final (but not publication) version; remark 4.1 strengthened; 47 pages, 2 figures; arXiv admin note: text overlap with arXiv:2110.05942, arXiv:2112.03677",
        "subjects": "Computational Complexity (cs.CC)",
        "abstract": "The diagonalization technique was invented by Georg Cantor to show that there are more real numbers than algebraic numbers and is very important in theoretical computer science. In this work, we enumerate all of the polynomial-time deterministic Turing machines and diagonalize against all of them by a universal nondeterministic Turing machine. As a result, we obtain that there is a language $L_d$ not accepted by any polynomial-time deterministic Turing machines but accepted by a nondeterministic Turing machine running within time $O(n^k)$ for any $k\\in\\mathbb{N}_1$. Based on these, we further show that $L_d\\in\\mathcal{NP}$ . That is, we present a proof that $\\mathcal{P}$ and $\\mathcal{NP}$ differ. Meanwhile, we show that there exists a language $L_s$ in $\\mathcal{P}$ but the machine accepting it also runs within time $O(n^k)$ for all $k\\in\\mathbb{N}_1$. Lastly, we show that if $\\mathcal{P}^O=\\mathcal{NP}^O$ and on some rational base assumptions then the set $P^O$ of all polynomial-time deterministic oracle Turing machines with oracle $O$ is not enumerable, thus demonstrating that diagonalization technique (via a universal nondeterministic oracle Turing machine) will generally not apply to the relativized versions of the $\\mathcal{P}$ versus $\\mathcal{NP}$ problem.\n    ",
        "primary_category": "cs.CC",
        "categories": [
            "cs.FL"
        ],
        "submitted_date": "12 Oct 2021",
        "last_revised_date": " "
    },
    "2110.07450": {
        "title": "Bugs in our Pockets: The Risks of Client-Side Scanning",
        "authors": [
            "Hal Abelson",
            "Ross Anderson",
            "Steven M. Bellovin",
            "Josh Benaloh",
            "Matt Blaze",
            "Jon Callas",
            "Whitfield Diffie",
            "Susan Landau",
            "Peter G. Neumann",
            "Ronald L. Rivest",
            "Jeffrey I. Schiller",
            "Bruce Schneier",
            "Vanessa Teague",
            "Carmela Troncoso"
        ],
        "comments": "46 pages, 3 figures",
        "subjects": "Cryptography and Security (cs.CR)",
        "abstract": "Our increasing reliance on digital technology for personal, economic, and government affairs has made it essential to secure the communications and devices of private citizens, businesses, and governments. This has led to pervasive use of cryptography across society. Despite its evident advantages, law enforcement and national security agencies have argued that the spread of cryptography has hindered access to evidence and intelligence. Some in industry and government now advocate a new technology to access targeted data: client-side scanning (CSS). Instead of weakening encryption or providing law enforcement with backdoor keys to decrypt communications, CSS would enable on-device analysis of data in the clear. If targeted information were detected, its existence and, potentially, its source, would be revealed to the agencies; otherwise, little or no information would leave the client device. Its proponents claim that CSS is a solution to the encryption versus public safety debate: it offers privacy -- in the sense of unimpeded end-to-end encryption -- and the ability to successfully investigate serious crime. In this report, we argue that CSS neither guarantees efficacious crime prevention nor prevents surveillance. Indeed, the effect is the opposite. CSS by its nature creates serious security and privacy risks for all society while the assistance it can provide for law enforcement is at best problematic. There are multiple ways in which client-side scanning can fail, can be evaded, and can be abused.\n    ",
        "primary_category": "cs.CR",
        "categories": [
            "cs.CY"
        ],
        "submitted_date": "14 Oct 2021",
        "last_revised_date": " "
    },
    "2110.11385": {
        "title": "Self-Initiated Open World Learning for Autonomous AI Agents",
        "authors": [
            "Bing Liu",
            "Eric Robertson",
            "Scott Grigsby",
            "Sahisnu Mazumder"
        ],
        "comments": "Published in AAAI 2022 Spring Symposium Series",
        "subjects": "Artificial Intelligence (cs.AI)",
        "abstract": "As more and more AI agents are used in practice, it is time to think about how to make these agents fully autonomous so that they can learn by themselves in a self-motivated and self-supervised manner rather than being retrained periodically on the initiation of human engineers using expanded training data. As the real-world is an open environment with unknowns or novelties, detecting novelties or unknowns, characterizing them, accommodating or adapting to them, gathering ground-truth training data, and incrementally learning the unknowns/novelties are critical to making the agent more and more knowledgeable and powerful over time. The key challenge is how to automate the process so that it is carried out on the agent's own initiative and through its own interactions with humans and the environment. Since an AI agent usually has a performance task, characterizing each novelty becomes critical and necessary so that the agent can formulate an appropriate response to adapt its behavior to accommodate the novelty and to learn from it to improve the agent's adaptation capability and task performance. The process goes continually without termination. This paper proposes a theoretic framework for this learning paradigm to promote the research of building Self-initiated Open world Learning (SOL) agents. An example SOL agent is also described.\n    ",
        "primary_category": "cs.AI",
        "categories": [
            "cs.HC",
            "cs.LG"
        ],
        "submitted_date": "21 Oct 2021",
        "last_revised_date": " "
    },
    "2111.13384": {
        "title": "EOLANG and $\u03c6$-calculus",
        "authors": [
            "Yegor Bugayenko"
        ],
        "comments": " ",
        "subjects": "Programming Languages (cs.PL)",
        "abstract": "Object-oriented programming (OOP) is one of the most popular paradigms used for building software systems. However, despite its industrial and academic popularity, OOP is still missing a formal apparatus similar to $\\lambda$-calculus, which functional programming is based on. There were a number of attempts to formalize OOP, but none of them managed to cover all the features available in modern OO programming languages, such as C++ or Java. We have made yet another attempt and created $\\varphi$-calculus. We also created EOLANG (also called EO), an experimental programming language based on $\\varphi$-calculus.\n    ",
        "primary_category": "cs.PL",
        "categories": [],
        "submitted_date": "26 Nov 2021",
        "last_revised_date": " "
    },
    "2111.13919": {
        "title": "More relations between $\u03bb$-labeling and Hamiltonian paths with emphasis on line graph of bipartite multigraphs",
        "authors": [
            "Manouchehr Zaker"
        ],
        "comments": "20 pages, 7 figures, accepted paper",
        "subjects": "Combinatorics (math.CO)",
        "abstract": "This paper deals with the $\\lambda$-labeling and $L(2,1)$-coloring of simple graphs. A $\\lambda$-labeling of a graph $G$ is any labeling of the vertices of $G$ with different labels such that any two adjacent vertices receive labels which differ at least two. Also an $L(2,1)$-coloring of $G$ is any labeling of the vertices of $G$ such that any two adjacent vertices receive labels which differ at least two and any two vertices with distance two receive distinct labels. Assume that a partial $\\lambda$-labeling $f$ is given in a graph $G$. A general question is whether $f$ can be extended to a $\\lambda$-labeling of $G$. We show that the extension is feasible if and only if a Hamiltonian path consistent with some distance constraints exists in the complement of $G$. Then we consider line graph of bipartite multigraphs and determine the minimum number of labels in $L(2,1)$-coloring and $\\lambda$-labeling of these graphs. In fact we obtain easily computable formulas for the path covering number and the maximum path of the complement of these graphs. We obtain a polynomial time algorithm which generates all Hamiltonian paths in the related graphs. A special case is the Cartesian product graph $K_n\\Box K_n$ and the generation of $\\lambda$-squares.\n    ",
        "primary_category": "math.CO",
        "categories": [
            "cs.DM"
        ],
        "submitted_date": "27 Nov 2021",
        "last_revised_date": " "
    },
    "2111.15478": {
        "title": "A new near-linear time algorithm for k-nearest neighbor search using a compressed cover tree",
        "authors": [
            "Yury Elkin",
            "Vitaliy Kurlin"
        ],
        "comments": "Accepted to ICML 2023",
        "subjects": "Computational Geometry (cs.CG)",
        "abstract": "Given a reference set $R$ of $n$ points and a query set $Q$ of $m$ points in a metric space, this paper studies an important problem of finding $k$-nearest neighbors of every point $q \\in Q$ in the set $R$ in a near-linear time. In the paper at ICML 2006, Beygelzimer, Kakade, and Langford introduced a cover tree on $R$ and attempted to prove that this tree can be built in $O(n\\log n)$ time while the nearest neighbor search can be done in $O(n\\log m)$ time with a hidden dimensionality factor. This paper fills a substantial gap in the past proofs of time complexity by defining a simpler compressed cover tree on the reference set $R$. The first new algorithm constructs a compressed cover tree in $O(n \\log n)$ time. The second new algorithm finds all $k$-nearest neighbors of all points from $Q$ using a compressed cover tree in time $O(m(k+\\log n)\\log k)$ with a hidden dimensionality factor depending on point distributions of the given sets $R,Q$ but not on their sizes.\n    ",
        "primary_category": "cs.CG",
        "categories": [
            "cs.DS"
        ],
        "submitted_date": "30 Nov 2021",
        "last_revised_date": " "
    },
    "2112.01799": {
        "title": "Global Context with Discrete Diffusion in Vector Quantised Modelling for Image Generation",
        "authors": [
            "Minghui Hu",
            "Yujie Wang",
            "Tat-Jen Cham",
            "Jianfei Yang",
            "P.N.Suganthan"
        ],
        "comments": " ",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "The integration of Vector Quantised Variational AutoEncoder (VQ-VAE) with autoregressive models as generation part has yielded high-quality results on image generation. However, the autoregressive models will strictly follow the progressive scanning order during the sampling phase. This leads the existing VQ series models to hardly escape the trap of lacking global information. Denoising Diffusion Probabilistic Models (DDPM) in the continuous domain have shown a capability to capture the global context, while generating high-quality images. In the discrete state space, some works have demonstrated the potential to perform text generation and low resolution image generation. We show that with the help of a content-rich discrete visual codebook from VQ-VAE, the discrete diffusion model can also generate high fidelity images with global context, which compensates for the deficiency of the classical autoregressive model along pixel space. Meanwhile, the integration of the discrete VAE with the diffusion model resolves the drawback of conventional autoregressive models being oversized, and the diffusion model which demands excessive time in the sampling process when generating images. It is found that the quality of the generated images is heavily dependent on the discrete visual codebook. Extensive experiments demonstrate that the proposed Vector Quantised Discrete Diffusion Model (VQ-DDM) is able to achieve comparable performance to top-tier methods with low complexity. It also demonstrates outstanding advantages over other vectors quantised with autoregressive models in terms of image inpainting tasks without additional training.\n    ",
        "primary_category": "cs.CV",
        "categories": [
            "cs.LG"
        ],
        "submitted_date": "3 Dec 2021",
        "last_revised_date": " "
    },
    "2112.03543": {
        "title": "Phase Transition of the 3-Majority Dynamics with Uniform Communication Noise",
        "authors": [
            "Francesco d'Amore",
            "Isabella Ziccardi"
        ],
        "comments": " ",
        "subjects": "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "abstract": "Communication noise is a common feature in several real-world scenarios where systems of agents need to communicate in order to pursue some collective task. In particular, many biologically inspired systems that try to achieve agreements on some opinion must implement resilient dynamics that are not strongly affected by noisy communications. In this work, we study the popular 3-Majority dynamics, an opinion dynamics which has been proved to be an efficient protocol for the majority consensus problem, in which we introduce a simple feature of uniform communication noise, following (d'Amore et al. 2020). We prove that in the fully connected communication network of n agents and in the binary opinion case, the process induced by the 3-Majority dynamics exhibits a phase transition. For a noise probability $p < 1/3$, the dynamics reaches in logarithmic time an almost-consensus metastable phase which lasts for a polynomial number of rounds with high probability. Furthermore, departing from previous analyses, we further characterize this phase by showing that there exists an attractive equilibrium value $s_{\\text{eq}} \\in [n]$ for the bias of the system, i.e. the difference between the majority community size and the minority one. Moreover, the agreement opinion turns out to be the initial majority one if the bias towards it is of magnitude $\\Omega(\\sqrt{n\\log n})$ in the initial configuration. If, instead, $p > 1/3$, no form of consensus is possible, and any information regarding the initial majority opinion is lost in logarithmic time with high probability. Despite more communications per-round are allowed, the 3-Majority dynamics surprisingly turns out to be less resilient to noise than the Undecided-State dynamics (d'Amore et al. 2020), whose noise threshold value is $p = 1/2$.\n    ",
        "primary_category": "cs.DC",
        "categories": [
            "cs.CC",
            "cs.SI",
            "math.PR"
        ],
        "submitted_date": "7 Dec 2021",
        "last_revised_date": " "
    },
    "2112.04539": {
        "title": "Prompt-based Zero-shot Relation Extraction with Semantic Knowledge Augmentation",
        "authors": [
            "Jiaying Gong",
            "Hoda Eldardiry"
        ],
        "comments": "14 pages, 5 figures",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "In relation triplet extraction (RTE), recognizing unseen relations for which there are no training instances is a challenging task. Efforts have been made to recognize unseen relations based on question-answering models or relation descriptions. However, these approaches miss the semantic information about connections between seen and unseen relations. In this paper, We propose a prompt-based model with semantic knowledge augmentation (ZS-SKA) to recognize unseen relations under the zero-shot setting. We present a new word-level analogy-based sentence translation rule and generate augmented instances with unseen relations from instances with seen relations using that new rule. We design prompts with weighted virtual label construction based on an external knowledge graph to integrate semantic knowledge information learned from seen relations. Instead of using the actual label sets in the prompt template, we construct weighted virtual label words. We learn the representations of both seen and unseen relations with augmented instances and prompts. We then calculate the distance between the generated representations using prototypical networks to predict unseen relations. Extensive experiments conducted on three public datasets FewRel, Wiki-ZSL, and NYT, show that ZS-SKA outperforms other methods under zero-shot setting. Results also demonstrate the effectiveness and robustness of ZS-SKA.\n    ",
        "primary_category": "cs.CL",
        "categories": [],
        "submitted_date": "8 Dec 2021",
        "last_revised_date": " "
    },
    "2112.05478": {
        "title": "Critical configurations for three projective views",
        "authors": [
            "Martin Br\u00e5telund"
        ],
        "comments": "40 pages, 9 figures. This is a companion paper to arXiv:2112.05074. Accepted manuscript published in Mathematica Scandinavica",
        "subjects": "Algebraic Geometry (math.AG)",
        "abstract": "The problem of structure from motion is concerned with recovering the 3-dimensional structure of an object from a set of 2-dimensional images taken by unknown cameras. Generally, all information can be uniquely recovered if enough images and point correspondences are provided, yet there are certain cases where unique recovery is impossible; these are called critical configurations. We use an algebraic approach to study the critical configurations for three projective cameras. We show that all critical configurations lie on the intersection of quadric surfaces, and classify exactly which intersections constitute a critical configuration.\n    ",
        "primary_category": "math.AG",
        "categories": [
            "cs.CV"
        ],
        "submitted_date": "10 Dec 2021",
        "last_revised_date": " "
    },
    "2112.06242": {
        "title": "Formulating Event-based Image Reconstruction as a Linear Inverse Problem with Deep Regularization using Optical Flow",
        "authors": [
            "Zelin Zhang",
            "Anthony Yezzi",
            "Guillermo Gallego"
        ],
        "comments": "22 pages, 26 figures, 5 tables, 6 animations when clicked on",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Event cameras are novel bio-inspired sensors that measure per-pixel brightness differences asynchronously. Recovering brightness from events is appealing since the reconstructed images inherit the high dynamic range (HDR) and high-speed properties of events; hence they can be used in many robotic vision applications and to generate slow-motion HDR videos. However, state-of-the-art methods tackle this problem by training an event-to-image Recurrent Neural Network (RNN), which lacks explainability and is difficult to tune. In this work we show, for the first time, how tackling the combined problem of motion and brightness estimation leads us to formulate event-based image reconstruction as a linear inverse problem that can be solved without training an image reconstruction RNN. Instead, classical and learning-based regularizers are used to solve the problem and remove artifacts from the reconstructed images. The experiments show that the proposed approach generates images with visual quality on par with state-of-the-art methods despite only using data from a short time interval. State-of-the-art results are achieved using an image denoising Convolutional Neural Network (CNN) as the regularization function. The proposed regularized formulation and solvers have a unifying character because they can be applied also to reconstruct brightness from the second derivative. Additionally, the formulation is attractive because it can be naturally combined with super-resolution, motion-segmentation and color demosaicing. Code is available at this https URL\n",
        "primary_category": "cs.CV",
        "categories": [
            "cs.LG",
            "cs.RO"
        ],
        "submitted_date": "12 Dec 2021",
        "last_revised_date": " "
    },
    "2201.11967": {
        "title": "Pseudo-Differential Neural Operator: Generalized Fourier Neural Operator for Learning Solution Operators of Partial Differential Equations",
        "authors": [
            "Jin Young Shin",
            "Jae Yong Lee",
            "Hyung Ju Hwang"
        ],
        "comments": "23 pages, 13 figures",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Learning the mapping between two function spaces has garnered considerable research attention. However, learning the solution operator of partial differential equations (PDEs) remains a challenge in scientific computing. Fourier neural operator (FNO) was recently proposed to learn solution operators, and it achieved an excellent performance. In this study, we propose a novel \\textit{pseudo-differential integral operator} (PDIO) to analyze and generalize the Fourier integral operator in FNO. PDIO is inspired by a pseudo-differential operator, which is a generalized differential operator characterized by a certain symbol. We parameterize this symbol using a neural network and demonstrate that the neural network-based symbol is contained in a smooth symbol class. Subsequently, we verify that the PDIO is a bounded linear operator, and thus is continuous in the Sobolev space. We combine the PDIO with the neural operator to develop a \\textit{pseudo-differential neural operator} (PDNO) and learn the nonlinear solution operator of PDEs. We experimentally validate the effectiveness of the proposed model by utilizing Darcy flow and the Navier-Stokes equation. The obtained results indicate that the proposed PDNO outperforms the existing neural operator approaches in most experiments.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "math.NA"
        ],
        "submitted_date": "28 Jan 2022",
        "last_revised_date": " "
    },
    "2202.06834": {
        "title": "Memory-Efficient Sequential Pattern Mining with Hybrid Tries",
        "authors": [
            "Amin Hosseininasab",
            "Willem-Jan van Hoeve",
            "Andre A. Cire"
        ],
        "comments": " ",
        "subjects": "Databases (cs.DB)",
        "abstract": "As modern data sets continue to grow exponentially in size, the demand for efficient mining algorithms capable of handling such large data sets becomes increasingly imperative. This paper develops a memory-efficient approach for Sequential Pattern Mining (SPM), a fundamental topic in knowledge discovery that faces a well-known memory bottleneck for large data sets. Our methodology involves a novel hybrid trie data structure that exploits recurring patterns to compactly store the data set in memory; and a corresponding mining algorithm designed to effectively extract patterns from this compact representation. Numerical results on real-life test instances show an average improvement of 88% in memory consumption and 41% in computation time for small to medium-sized data sets compared to the state of the art. Furthermore, our algorithm stands out as the only capable SPM approach for large data sets within 256GB of system memory.\n    ",
        "primary_category": "cs.DB",
        "categories": [
            "cs.AI",
            "cs.DS",
            "cs.LG"
        ],
        "submitted_date": "6 Feb 2022",
        "last_revised_date": " "
    },
    "2202.08370": {
        "title": "CAREER: A Foundation Model for Labor Sequence Data",
        "authors": [
            "Keyon Vafa",
            "Emil Palikot",
            "Tianyu Du",
            "Ayush Kanodia",
            "Susan Athey",
            "David M. Blei"
        ],
        "comments": " ",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Labor economists regularly analyze employment data by fitting predictive models to small, carefully constructed longitudinal survey datasets. Although machine learning methods offer promise for such problems, these survey datasets are too small to take advantage of them. In recent years large datasets of online resumes have also become available, providing data about the career trajectories of millions of individuals. However, standard econometric models cannot take advantage of their scale or incorporate them into the analysis of survey data. To this end we develop CAREER, a foundation model for job sequences. CAREER is first fit to large, passively-collected resume data and then fine-tuned to smaller, better-curated datasets for economic inferences. We fit CAREER to a dataset of 24 million job sequences from resumes, and adjust it on small longitudinal survey datasets. We find that CAREER forms accurate predictions of job sequences, outperforming econometric baselines on three widely-used economics datasets. We further find that CAREER can be used to form good predictions of other downstream variables. For example, incorporating CAREER into a wage model provides better predictions than the econometric models currently in use.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "econ.EM"
        ],
        "submitted_date": "16 Feb 2022",
        "last_revised_date": " "
    },
    "2202.09210": {
        "title": "Hedonic Diversity Games: A Complexity Picture with More than Two Colors",
        "authors": [
            "Robert Ganian",
            "Thekla Hamm",
            "Du\u0161an Knop",
            "\u0160imon Schierreich",
            "Ond\u0159ej Such\u00fd"
        ],
        "comments": "A preliminary version appeared in AAAI '22",
        "subjects": "Computer Science and Game Theory (cs.GT)",
        "abstract": "Hedonic diversity games are a variant of the classical Hedonic games designed to better model a variety of questions concerning diversity and fairness. Previous works mainly targeted the case with two diversity classes (represented as colors in the model) and provided some initial complexity-theoretic and existential results concerning Nash and individually stable outcomes. Here, we design new algorithms accompanied with lower bounds which provide a complete parameterized-complexity picture for computing Nash and individually stable outcomes with respect to the most natural parameterizations of the problem. Crucially, our results hold for general Hedonic diversity games where the number of colors is not necessarily restricted to two, and show that -- apart from two trivial cases -- a necessary condition for tractability in this setting is that the number of colors is bounded by the parameter. Moreover, for the special case of two colors we resolve an open question asked in previous work (Boehmer and Elkind, AAAI 2020).\n    ",
        "primary_category": "cs.GT",
        "categories": [],
        "submitted_date": "18 Feb 2022",
        "last_revised_date": " "
    },
    "2202.09393": {
        "title": "Information Decomposition Diagrams Applied beyond Shannon Entropy: A Generalization of Hu's Theorem",
        "authors": [
            "Leon Lang",
            "Pierre Baudot",
            "Rick Quax",
            "Patrick Forr\u00e9"
        ],
        "comments": "58 pages, 5 figures",
        "subjects": "Information Theory (cs.IT)",
        "abstract": "In information theory, one major goal is to find useful functions that summarize the amount of information contained in the interaction of several random variables. Specifically, one can ask how the classical Shannon entropy, mutual information, and higher interaction information relate to each other. This is answered by Hu's theorem, which is widely known in the form of information diagrams: it relates shapes in a Venn diagram to information functions, thus establishing a bridge from set theory to information theory. In this work, we view random variables together with the joint operation as a monoid that acts by conditioning on information functions, and entropy as a function satisfying the chain rule of information. This abstract viewpoint allows to prove a generalization of Hu's theorem. It applies to Shannon and Tsallis entropy, (Tsallis) Kullback-Leibler Divergence, cross-entropy, Kolmogorov complexity, submodular information functions, and the generalization error in machine learning. Our result implies for Chaitin's Kolmogorov complexity that the interaction complexities of all degrees are in expectation close to Shannon interaction information. For well-behaved probability distributions on increasing sequence lengths, this shows that the per-bit expected interaction complexity and information asymptotically coincide, thus showing a strong bridge between algorithmic and classical information theory.\n    ",
        "primary_category": "cs.IT",
        "categories": [],
        "submitted_date": "18 Feb 2022",
        "last_revised_date": " "
    },
    "2202.10062": {
        "title": "USCORE: An Effective Approach to Fully Unsupervised Evaluation Metrics for Machine Translation",
        "authors": [
            "Jonas Belouadi",
            "Steffen Eger"
        ],
        "comments": "Accepted at EACL 2023 (main track)",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "The vast majority of evaluation metrics for machine translation are supervised, i.e., (i) are trained on human scores, (ii) assume the existence of reference translations, or (iii) leverage parallel data. This hinders their applicability to cases where such supervision signals are not available. In this work, we develop fully unsupervised evaluation metrics. To do so, we leverage similarities and synergies between evaluation metric induction, parallel corpus mining, and MT systems. In particular, we use an unsupervised evaluation metric to mine pseudo-parallel data, which we use to remap deficient underlying vector spaces (in an iterative manner) and to induce an unsupervised MT system, which then provides pseudo-references as an additional component in the metric. Finally, we also induce unsupervised multilingual sentence embeddings from pseudo-parallel data. We show that our fully unsupervised metrics are effective, i.e., they beat supervised competitors on 4 out of our 5 evaluation datasets. We make our code publicly available.\n    ",
        "primary_category": "cs.CL",
        "categories": [],
        "submitted_date": "21 Feb 2022",
        "last_revised_date": " "
    },
    "2203.01360": {
        "title": "Neural Galerkin Schemes with Active Learning for High-Dimensional Evolution Equations",
        "authors": [
            "Joan Bruna",
            "Benjamin Peherstorfer",
            "Eric Vanden-Eijnden"
        ],
        "comments": " ",
        "subjects": "Numerical Analysis (math.NA)",
        "abstract": "Deep neural networks have been shown to provide accurate function approximations in high dimensions. However, fitting network parameters requires informative training data that are often challenging to collect in science and engineering applications. This work proposes Neural Galerkin schemes based on deep learning that generate training data with active learning for numerically solving high-dimensional partial differential equations. Neural Galerkin schemes build on the Dirac-Frenkel variational principle to train networks by minimizing the residual sequentially over time, which enables adaptively collecting new training data in a self-informed manner that is guided by the dynamics described by the partial differential equations. This is in contrast to other machine learning methods that aim to fit network parameters globally in time without taking into account training data acquisition. Our finding is that the active form of gathering training data of the proposed Neural Galerkin schemes is key for numerically realizing the expressive power of networks in high dimensions. Numerical experiments demonstrate that Neural Galerkin schemes have the potential to enable simulating phenomena and processes with many variables for which traditional and other deep-learning-based solvers fail, especially when features of the solutions evolve locally such as in high-dimensional wave propagation problems and interacting particle systems described by Fokker-Planck and kinetic equations.\n    ",
        "primary_category": "math.NA",
        "categories": [
            "cs.LG",
            "stat.ML"
        ],
        "submitted_date": "2 Mar 2022",
        "last_revised_date": " "
    },
    "2203.05888": {
        "title": "Moser-Tardos Algorithm with small number of random bits",
        "authors": [
            "Endre Cs\u00f3ka",
            "\u0141ukasz Grabowski",
            "Andr\u00e1s M\u00e1th\u00e9",
            "Oleg Pikhurko",
            "Konstantinos Tyros"
        ],
        "comments": "31 pages; minor corrections and changes; note that the required bound on the failure probabilities in Theorems 2.5 and 3.28 is slightly stronger than in Version 1",
        "subjects": "Combinatorics (math.CO)",
        "abstract": "We study a variant of the parallel Moser-Tardos Algorithm. We prove that if we restrict attention to a class of problems whose dependency graphs have subexponential growth, then the expected total number of random bits used by the algorithm is constant; in particular, it is independent from the number of variables. This is achieved by using the same random bits to resample variables which are far enough in the dependency graph.\nThere are two corollaries. First, we obtain a deterministic algorithm for finding a satisfying assignment, which for any class of problems as in the previous paragraph runs in time O(n), where n is the number of variables. Second, we present a Borel version of the Lov\u00e1sz Local Lemma.\n    ",
        "primary_category": "math.CO",
        "categories": [
            "cs.DC",
            "cs.DS",
            "math.LO"
        ],
        "submitted_date": "11 Mar 2022",
        "last_revised_date": " "
    },
    "2203.08964": {
        "title": "Point-Unet: A Context-aware Point-based Neural Network for Volumetric Segmentation",
        "authors": [
            "Ngoc-Vuong Ho",
            "Tan Nguyen",
            "Gia-Han Diep",
            "Ngan Le",
            "Binh-Son Hua"
        ],
        "comments": "Accepted in MICCAI 2021",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Medical image analysis using deep learning has recently been prevalent, showing great performance for various downstream tasks including medical image segmentation and its sibling, volumetric image segmentation. Particularly, a typical volumetric segmentation network strongly relies on a voxel grid representation which treats volumetric data as a stack of individual voxel `slices', which allows learning to segment a voxel grid to be as straightforward as extending existing image-based segmentation networks to the 3D domain. However, using a voxel grid representation requires a large memory footprint, expensive test-time and limiting the scalability of the solutions. In this paper, we propose Point-Unet, a novel method that incorporates the efficiency of deep learning with 3D point clouds into volumetric segmentation. Our key idea is to first predict the regions of interest in the volume by learning an attentional probability map, which is then used for sampling the volume into a sparse point cloud that is subsequently segmented using a point-based neural network. We have conducted the experiments on the medical volumetric segmentation task with both a small-scale dataset Pancreas and large-scale datasets BraTS18, BraTS19, and BraTS20 challenges. A comprehensive benchmark on different metrics has shown that our context-aware Point-Unet robustly outperforms the SOTA voxel-based networks at both accuracies, memory usage during training, and time consumption during testing. Our code is available at this https URL.\n    ",
        "primary_category": "cs.CV",
        "categories": [],
        "submitted_date": "16 Mar 2022",
        "last_revised_date": " "
    },
    "2203.16464": {
        "title": "Towards Interpretable Deep Reinforcement Learning Models via Inverse Reinforcement Learning",
        "authors": [
            "Sean Xie",
            "Soroush Vosoughi",
            "Saeed Hassanpour"
        ],
        "comments": "Paper accepted to ICPR 2022",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Artificial intelligence, particularly through recent advancements in deep learning, has achieved exceptional performances in many tasks in fields such as natural language processing and computer vision. In addition to desirable evaluation metrics, a high level of interpretability is often required for these models to be reliably utilized. Therefore, explanations that offer insight into the process by which a model maps its inputs onto its outputs are much sought-after. Unfortunately, the current black box nature of machine learning models is still an unresolved issue and this very nature prevents researchers from learning and providing explicative descriptions for a model's behavior and final predictions. In this work, we propose a novel framework utilizing Adversarial Inverse Reinforcement Learning that can provide global explanations for decisions made by a Reinforcement Learning model and capture intuitive tendencies that the model follows by summarizing the model's decision-making process.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "30 Mar 2022",
        "last_revised_date": " "
    },
    "2204.00961": {
        "title": "Enhancing Digital Health Services: A Machine Learning Approach to Personalized Exercise Goal Setting",
        "authors": [
            "Ji Fang",
            "Vincent CS Lee",
            "Hao Ji",
            "Haiyan Wang"
        ],
        "comments": " ",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "The utilization of digital health has increased recently, and these services provide extensive guidance to encourage users to exercise frequently by setting daily exercise goals to promote a healthy lifestyle. These comprehensive guides evolved from the consideration of various personalized behavioral factors. Nevertheless, existing approaches frequently neglect the users dynamic behavior and the changing in their health conditions. This study aims to fill this gap by developing a machine learning algorithm that dynamically updates auto-suggestion exercise goals using retrospective data and realistic behavior trajectory. We conducted a methodological study by designing a deep reinforcement learning algorithm to evaluate exercise performance, considering fitness-fatigue effects. The deep reinforcement learning algorithm combines deep learning techniques to analyse time series data and infer user exercise behavior. In addition, we use the asynchronous advantage actor-critic algorithm for reinforcement learning to determine the optimal exercise intensity through exploration and exploitation. The personalized exercise data and biometric data used in this study were collected from publicly available datasets, encompassing walking, sports logs, and running. In our study, we conducted The statistical analyses/inferential tests to compare the effectiveness of machine learning approach in exercise goal setting across different exercise goal setting strategies.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "math.OC"
        ],
        "submitted_date": "3 Apr 2022",
        "last_revised_date": " "
    },
    "2204.01612": {
        "title": "Neural Estimation of the Rate-Distortion Function With Applications to Operational Source Coding",
        "authors": [
            "Eric Lei",
            "Hamed Hassani",
            "Shirin Saeedi Bidokhti"
        ],
        "comments": " ",
        "subjects": "Information Theory (cs.IT)",
        "abstract": "A fundamental question in designing lossy data compression schemes is how well one can do in comparison with the rate-distortion function, which describes the known theoretical limits of lossy compression. Motivated by the empirical success of deep neural network (DNN) compressors on large, real-world data, we investigate methods to estimate the rate-distortion function on such data, which would allow comparison of DNN compressors with optimality. While one could use the empirical distribution of the data and apply the Blahut-Arimoto algorithm, this approach presents several computational challenges and inaccuracies when the datasets are large and high-dimensional, such as the case of modern image datasets. Instead, we re-formulate the rate-distortion objective, and solve the resulting functional optimization problem using neural networks. We apply the resulting rate-distortion estimator, called NERD, on popular image datasets, and provide evidence that NERD can accurately estimate the rate-distortion function. Using our estimate, we show that the rate-distortion achievable by DNN compressors are within several bits of the rate-distortion function for real-world datasets. Additionally, NERD provides access to the rate-distortion achieving channel, as well as samples from its output marginal. Therefore, using recent results in reverse channel coding, we describe how NERD can be used to construct an operational one-shot lossy compression scheme with guarantees on the achievable rate and distortion. Experimental results demonstrate competitive performance with DNN compressors.\n    ",
        "primary_category": "cs.IT",
        "categories": [
            "cs.LG",
            "stat.ML"
        ],
        "submitted_date": "4 Apr 2022",
        "last_revised_date": " "
    },
    "2204.04377": {
        "title": "Robotic Surgery Remote Mentoring via AR with 3D Scene Streaming and Hand Interaction",
        "authors": [
            "Yonghao Long",
            "Chengkun Li",
            "Qi Dou"
        ],
        "comments": " ",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "With the growing popularity of robotic surgery, education becomes increasingly important and urgently needed for the sake of patient safety. However, experienced surgeons have limited accessibility due to their busy clinical schedule or working in a distant city, thus can hardly provide sufficient education resources for novices. Remote mentoring, as an effective way, can help solve this problem, but traditional methods are limited to plain text, audio, or 2D video, which are not intuitive nor vivid. Augmented reality (AR), a thriving technique being widely used for various education scenarios, is promising to offer new possibilities of visual experience and interactive teaching. In this paper, we propose a novel AR-based robotic surgery remote mentoring system with efficient 3D scene visualization and natural 3D hand interaction. Using a head-mounted display (i.e., HoloLens), the mentor can remotely monitor the procedure streamed from the trainee's operation side. The mentor can also provide feedback directly with hand gestures, which is in-turn transmitted to the trainee and viewed in surgical console as guidance. We comprehensively validate the system on both real surgery stereo videos and ex-vivo scenarios of common robotic training tasks (i.e., peg-transfer and suturing). Promising results are demonstrated regarding the fidelity of streamed scene visualization, the accuracy of feedback with hand interaction, and the low-latency of each component in the entire remote mentoring system. This work showcases the feasibility of leveraging AR technology for reliable, flexible and low-cost solutions to robotic surgical education, and holds great potential for clinical applications.\n    ",
        "primary_category": "cs.CV",
        "categories": [],
        "submitted_date": "9 Apr 2022",
        "last_revised_date": " "
    },
    "2204.04476": {
        "title": "High-dimensional Asymptotics of Langevin Dynamics in Spiked Matrix Models",
        "authors": [
            "Tengyuan Liang",
            "Subhabrata Sen",
            "Pragya Sur"
        ],
        "comments": "26 pages",
        "subjects": "Statistics Theory (math.ST)",
        "abstract": "We study Langevin dynamics for recovering the planted signal in the spiked matrix model. We provide a \"path-wise\" characterization of the overlap between the output of the Langevin algorithm and the planted signal. This overlap is characterized in terms of a self-consistent system of integro-differential equations, usually referred to as the Crisanti-Horner-Sommers-Cugliandolo-Kurchan (CHSCK) equations in the spin glass literature. As a second contribution, we derive an explicit formula for the limiting overlap in terms of the signal-to-noise ratio and the injected noise in the diffusion. This uncovers a sharp phase transition -- in one regime, the limiting overlap is strictly positive, while in the other, the injected noise overcomes the signal, and the limiting overlap is zero.\n    ",
        "primary_category": "math.ST",
        "categories": [
            "cs.LG",
            "math.PR",
            "stat.ML"
        ],
        "submitted_date": "9 Apr 2022",
        "last_revised_date": " "
    },
    "2204.05798": {
        "title": "Multi-View Hypercomplex Learning for Breast Cancer Screening",
        "authors": [
            "Eleonora Lopez",
            "Eleonora Grassucci",
            "Martina Valleriani",
            "Danilo Comminiello"
        ],
        "comments": "This paper has been submitted to IEEE Transactions on Pattern Analysis and Machine Intelligence",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Traditionally, deep learning methods for breast cancer classification perform a single-view analysis. However, radiologists simultaneously analyze all four views that compose a mammography exam, owing to the correlations contained in mammography views, which present crucial information for identifying tumors. In light of this, some studies have started to propose multi-view methods. Nevertheless, in such existing architectures, mammogram views are processed as independent images by separate convolutional branches, thus losing correlations among them. To overcome such limitations, in this paper, we propose a methodological approach for multi-view breast cancer classification based on parameterized hypercomplex neural networks. Thanks to hypercomplex algebra properties, our networks are able to model, and thus leverage, existing correlations between the different views that comprise a mammogram, thus mimicking the reading process performed by clinicians. This happens because hypercomplex networks capture both global properties, as standard neural models, as well as local relations, i.e., inter-view correlations, which real-valued networks fail at modeling. We define architectures designed to process two-view exams, namely PHResNets, and four-view exams, i.e., PHYSEnet and PHYBOnet. Through an extensive experimental evaluation conducted with publicly available datasets, we demonstrate that our proposed models clearly outperform real-valued counterparts and state-of-the-art methods, proving that breast cancer classification benefits from the proposed multi-view architectures. We also assess the method generalizability beyond mammogram analysis by considering different benchmarks, as well as a finer-scaled task such as segmentation. Full code and pretrained models for complete reproducibility of our experiments are freely available at this https URL.\n    ",
        "primary_category": "cs.CV",
        "categories": [
            "cs.AI",
            "cs.LG"
        ],
        "submitted_date": "12 Apr 2022",
        "last_revised_date": " "
    },
    "2204.07640": {
        "title": "Event-aided Direct Sparse Odometry",
        "authors": [
            "Javier Hidalgo-Carri\u00f3",
            "Guillermo Gallego",
            "Davide Scaramuzza"
        ],
        "comments": "16 pages, 14 Figures, Page: this https URL",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "We introduce EDS, a direct monocular visual odometry using events and frames. Our algorithm leverages the event generation model to track the camera motion in the blind time between frames. The method formulates a direct probabilistic approach of observed brightness increments. Per-pixel brightness increments are predicted using a sparse number of selected 3D points and are compared to the events via the brightness increment error to estimate camera motion. The method recovers a semi-dense 3D map using photometric bundle adjustment. EDS is the first method to perform 6-DOF VO using events and frames with a direct approach. By design, it overcomes the problem of changing appearance in indirect methods. We also show that, for a target error performance, EDS can work at lower frame rates than state-of-the-art frame-based VO solutions. This opens the door to low-power motion-tracking applications where frames are sparingly triggered \"on demand\" and our method tracks the motion in between. We release code and datasets to the public.\n    ",
        "primary_category": "cs.CV",
        "categories": [],
        "submitted_date": "15 Apr 2022",
        "last_revised_date": " "
    },
    "2205.02160": {
        "title": "Making SGD Parameter-Free",
        "authors": [
            "Yair Carmon",
            "Oliver Hinder"
        ],
        "comments": " ",
        "subjects": "Optimization and Control (math.OC)",
        "abstract": "We develop an algorithm for parameter-free stochastic convex optimization (SCO) whose rate of convergence is only a double-logarithmic factor larger than the optimal rate for the corresponding known-parameter setting. In contrast, the best previously known rates for parameter-free SCO are based on online parameter-free regret bounds, which contain unavoidable excess logarithmic terms compared to their known-parameter counterparts. Our algorithm is conceptually simple, has high-probability guarantees, and is also partially adaptive to unknown gradient norms, smoothness, and strong convexity. At the heart of our results is a novel parameter-free certificate for SGD step size choice, and a time-uniform concentration result that assumes no a-priori bounds on SGD iterates.\n    ",
        "primary_category": "math.OC",
        "categories": [
            "cs.LG",
            "stat.ML"
        ],
        "submitted_date": "4 May 2022",
        "last_revised_date": " "
    },
    "2205.11029": {
        "title": "META-GUI: Towards Multi-modal Conversational Agents on Mobile GUI",
        "authors": [
            "Liangtai Sun",
            "Xingyu Chen",
            "Lu Chen",
            "Tianle Dai",
            "Zichen Zhu",
            "Kai Yu"
        ],
        "comments": "14 pages, 10 figures",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "Task-oriented dialogue (TOD) systems have been widely used by mobile phone intelligent assistants to accomplish tasks such as calendar scheduling or hotel reservation. Current TOD systems usually focus on multi-turn text/speech interaction, then they would call back-end APIs designed for TODs to perform the task. However, this API-based architecture greatly limits the information-searching capability of intelligent assistants and may even lead to task failure if TOD-specific APIs are not available or the task is too complicated to be executed by the provided APIs. In this paper, we propose a new TOD architecture: GUI-based task-oriented dialogue system (GUI-TOD). A GUI-TOD system can directly perform GUI operations on real APPs and execute tasks without invoking TOD-specific backend APIs. Furthermore, we release META-GUI, a dataset for training a Multi-modal convErsaTional Agent on mobile GUI. We also propose a multi-model action prediction and response model, which show promising results on META-GUI. The dataset, codes and leaderboard are publicly available.\n    ",
        "primary_category": "cs.CL",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "23 May 2022",
        "last_revised_date": " "
    },
    "2205.14845": {
        "title": "QFaaS: A Serverless Function-as-a-Service Framework for Quantum Computing",
        "authors": [
            "Hoa T. Nguyen",
            "Muhammad Usman",
            "Rajkumar Buyya"
        ],
        "comments": "35 pages, 15 figures",
        "subjects": "Quantum Physics (quant-ph)",
        "abstract": "Recent breakthroughs in quantum hardware are creating opportunities for its use in many applications. However, quantum software engineering is still in its infancy with many challenges, especially dealing with the diversity of quantum programming languages and hardware platforms. To alleviate these challenges, we propose QFaaS, a novel Quantum Function-as-a-Service framework, which leverages the advantages of the serverless model and the state-of-the-art software engineering approaches to advance practical quantum computing. Our framework provides essential components of a quantum serverless platform to simplify the software development and adapt to the quantum cloud computing paradigm, such as combining hybrid quantum-classical computation, containerizing functions, and integrating DevOps features. We design QFaaS as a unified quantum computing framework by supporting well-known quantum languages and software development kits (Qiskit, Q#, Cirq, and Braket), executing the quantum tasks on multiple simulators and quantum cloud providers (IBM Quantum and Amazon Braket). This paper proposes architectural design, principal components, the life cycle of hybrid quantum-classical function, operation workflow, and implementation of QFaaS. We present two practical use cases and perform the evaluations on quantum computers and simulators to demonstrate our framework's ability to ease the burden on traditional engineers to expedite the ongoing quantum software transition.\n    ",
        "primary_category": "quant-ph",
        "categories": [
            "cs.DC",
            "cs.ET"
        ],
        "submitted_date": "30 May 2022",
        "last_revised_date": " "
    },
    "2206.00224": {
        "title": "Accelerated first-order methods for a class of semidefinite programs",
        "authors": [
            "Alex L. Wang",
            "Fatma Kilinc-Karzan"
        ],
        "comments": " ",
        "subjects": "Optimization and Control (math.OC)",
        "abstract": "This paper introduces a new storage-optimal first-order method (FOM), CertSDP, for solving a special class of semidefinite programs (SDPs) to high accuracy. The class of SDPs that we consider, the exact QMP-like SDPs, is characterized by low-rank solutions, a priori knowledge of the restriction of the SDP solution to a small subspace, and standard regularity assumptions such as strict complementarity. Crucially, we show how to use a certificate of strict complementarity to construct a low-dimensional strongly convex minimax problem whose optimizer coincides with a factorization of the SDP optimizer. From an algorithmic standpoint, we show how to construct the necessary certificate and how to solve the minimax problem efficiently. We accompany our theoretical results with preliminary numerical experiments suggesting that CertSDP significantly outperforms current state-of-the-art methods on large sparse exact QMP-like SDPs.\n    ",
        "primary_category": "math.OC",
        "categories": [
            "cs.DS"
        ],
        "submitted_date": "1 Jun 2022",
        "last_revised_date": " "
    },
    "2206.03010": {
        "title": "MS-RNN: A Flexible Multi-Scale Framework for Spatiotemporal Predictive Learning",
        "authors": [
            "Zhifeng Ma",
            "Hao Zhang",
            "Jie Liu"
        ],
        "comments": " ",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Spatiotemporal predictive learning, which predicts future frames through historical prior knowledge with the aid of deep learning, is widely used in many fields. Previous work essentially improves the model performance by widening or deepening the network, but it also brings surging memory overhead, which seriously hinders the development and application of this technology. In order to improve the performance without increasing memory consumption, we focus on scale, which is another dimension to improve model performance but with low memory requirement. The effectiveness has been widely demonstrated in many CNN-based tasks such as image classification and semantic segmentation, but it has not been fully explored in recent RNN models. In this paper, learning from the benefit of multi-scale, we propose a general framework named Multi-Scale RNN (MS-RNN) to boost recent RNN models for spatiotemporal predictive learning. We verify the MS-RNN framework by thorough theoretical analyses and exhaustive experiments, where the theory focuses on memory reduction and performance improvement while the experiments employ eight RNN models (ConvLSTM, TrajGRU, PredRNN, PredRNN++, MIM, MotionRNN, PredRNN-V2, and PrecipLSTM) and four datasets (Moving MNIST, TaxiBJ, KTH, and Germany). The results show the efficiency that RNN models incorporating our framework have much lower memory cost but better performance than before. Our code is released at \\url{this https URL}.\n    ",
        "primary_category": "cs.CV",
        "categories": [],
        "submitted_date": "7 Jun 2022",
        "last_revised_date": " "
    },
    "2206.03776": {
        "title": "High-Throughput Secure Multiparty Computation with an Honest Majority in Various Network Settings",
        "authors": [
            "Christopher Harth-Kitzerow",
            "Georg Carcle"
        ],
        "comments": " ",
        "subjects": "Cryptography and Security (cs.CR)",
        "abstract": "In this work, we present novel protocols over rings for semi-honest secure three-party computation (3-PC) and malicious four-party computation (4-PC) with one corruption. Compared to state-of-the-art protocols in the same setting, our protocols require fewer low-latency and high-bandwidth links between the parties to achieve high throughput. Our protocols also reduce the computational complexity by requiring up to 50 percent fewer basic instructions per gate. Further, our protocols achieve the currently best-known communication complexity (3, resp. 5 elements per multiplication gate) with an optional preprocessing phase to reduce the communication complexity of the online phase to 2 (resp. 3) elements per multiplication gate. In homogeneous network settings, i.e. all links between the parties share similar network bandwidth and latency, our protocols achieve up to two times higher throughput than state-of-the-art protocols. In heterogeneous network settings, i.e. all links between the parties share different network bandwidth and latency, our protocols achieve even larger performance improvements. We implemented our protocols and multiple other state-of-the-art protocols (Replicated 3-PC, Astra, Fantastic Four, Tetrad) in a novel open-source C++ framework optimized for achieving high throughput. Five out of six implemented 3-PC and 4-PC protocols achieve more than one billion 32-bit multiplication or more than 32 billion AND gates per second using our implementation in a 25 Gbit/s LAN environment. This is the highest throughput achieved in 3-PC and 4-PC so far and between two and three orders of magnitude higher than the throughput MP-SPDZ achieves in the same settings.\n    ",
        "primary_category": "cs.CR",
        "categories": [],
        "submitted_date": "8 Jun 2022",
        "last_revised_date": " "
    },
    "2206.09256": {
        "title": "Multistream Gaze Estimation with Anatomical Eye Region Isolation by Synthetic to Real Transfer Learning",
        "authors": [
            "Zunayed Mahmud",
            "Paul Hungler",
            "Ali Etemad"
        ],
        "comments": "15 pages, 7 figures, 14 tables. This work has been accepted to the IEEE Transactions on Artificial Intelligence $\u00a9$ 2024 IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "We propose a novel neural pipeline, MSGazeNet, that learns gaze representations by taking advantage of the eye anatomy information through a multistream framework. Our proposed solution comprises two components, first a network for isolating anatomical eye regions, and a second network for multistream gaze estimation. The eye region isolation is performed with a U-Net style network which we train using a synthetic dataset that contains eye region masks for the visible eyeball and the iris region. The synthetic dataset used in this stage is procured using the UnityEyes simulator, and consists of 80,000 eye images. Successive to training, the eye region isolation network is then transferred to the real domain for generating masks for the real-world eye images. In order to successfully make the transfer, we exploit domain randomization in the training process, which allows for the synthetic images to benefit from a larger variance with the help of augmentations that resemble artifacts. The generated eye region masks along with the raw eye images are then used together as a multistream input to our gaze estimation network, which consists of wide residual blocks. The output embeddings from these encoders are fused in the channel dimension before feeding into the gaze regression layers. We evaluate our framework on three gaze estimation datasets and achieve strong performances. Our method surpasses the state-of-the-art by 7.57% and 1.85% on two datasets, and obtains competitive results on the other. We also study the robustness of our method with respect to the noise in the data and demonstrate that our model is less sensitive to noisy data. Lastly, we perform a variety of experiments including ablation studies to evaluate the contribution of different components and design choices in our solution.\n    ",
        "primary_category": "cs.CV",
        "categories": [
            "cs.LG"
        ],
        "submitted_date": "18 Jun 2022",
        "last_revised_date": " "
    },
    "2206.10485": {
        "title": "Tight bounds for the learning of homotopy \u00e0 la Niyogi, Smale, and Weinberger for subsets of Euclidean spaces and of Riemannian manifolds",
        "authors": [
            "Dominique Attali",
            "Hana Dal Poz Kou\u0159imsk\u00e1",
            "Christopher Fillmore",
            "Ishika Ghosh",
            "Andr\u00e9 Lieutier",
            "Elizabeth Stephenson",
            "Mathijs Wintraecken"
        ],
        "comments": "75 pages, 29 figures",
        "subjects": "Computational Geometry (cs.CG)",
        "abstract": "In this article we extend and strengthen the seminal work by Niyogi, Smale, and Weinberger on the learning of the homotopy type from a sample of an underlying space. In their work, Niyogi, Smale, and Weinberger studied samples of $C^2$ manifolds with positive reach embedded in $\\mathbb{R}^d$. We extend their results in the following ways: In the first part of our paper we consider both manifolds of positive reach -- a more general setting than $C^2$ manifolds -- and sets of positive reach embedded in $\\mathbb{R}^d$. The sample $P$ of such a set $\\mathcal{S}$ does not have to lie directly on it. Instead, we assume that the two one-sided Hausdorff distances -- $\\varepsilon$ and $\\delta$ -- between $P$ and $\\mathcal{S}$ are bounded. We provide explicit bounds in terms of $\\varepsilon$ and $ \\delta$, that guarantee that there exists a parameter $r$ such that the union of balls of radius $r$ centred at the sample $P$ deformation-retracts to $\\mathcal{S}$.\nIn the second part of our paper we study homotopy learning in a significantly more general setting -- we investigate sets of positive reach and submanifolds of positive reach embedded in a \\emph{Riemannian manifold with bounded sectional curvature}. To this end we introduce a new version of the reach in the Riemannian setting inspired by the cut locus. Yet again, we provide tight bounds on $\\varepsilon$ and $\\delta$ for both cases (submanifolds as well as sets of positive reach), exhibiting the tightness by an explicit construction.\n    ",
        "primary_category": "cs.CG",
        "categories": [
            "math.AT"
        ],
        "submitted_date": "21 Jun 2022",
        "last_revised_date": " "
    },
    "2206.12733": {
        "title": "SiMa: Effective and Efficient Matching Across Data Silos Using Graph Neural Networks",
        "authors": [
            "Christos Koutras",
            "Rihan Hai",
            "Kyriakos Psarakis",
            "Marios Fragkoulis",
            "Asterios Katsifodimos"
        ],
        "comments": " ",
        "subjects": "Databases (cs.DB)",
        "abstract": "How can we leverage existing column relationships within silos, to predict similar ones across silos? Can we do this efficiently and effectively? Existing matching approaches do not exploit prior knowledge, relying on prohibitively expensive similarity computations. In this paper we present the first technique for matching columns across data silos, called SiMa, which leverages Graph Neural Networks (GNNs) to learn from existing column relationships within data silos, and dataset-specific profiles. The main novelty of SiMa is its ability to be trained incrementally on column relationships within each silo individually, without requiring the consolidation of all datasets in a single place. Our experiments show that SiMa is more effective than the - otherwise inapplicable to the setting of silos - state-of-the-art matching methods, while requiring orders of magnitude less computational resources. Moreover, we demonstrate that SiMa considerably outperforms other state-of-the-art column representation learning methods.\n    ",
        "primary_category": "cs.DB",
        "categories": [],
        "submitted_date": "25 Jun 2022",
        "last_revised_date": " "
    },
    "2207.00288": {
        "title": "Distributed Influence-Augmented Local Simulators for Parallel MARL in Large Networked Systems",
        "authors": [
            "Miguel Suau",
            "Jinke He",
            "Mustafa Mert \u00c7elikok",
            "Matthijs T. J. Spaan",
            "Frans A. Oliehoek"
        ],
        "comments": " ",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Due to its high sample complexity, simulation is, as of today, critical for the successful application of reinforcement learning. Many real-world problems, however, exhibit overly complex dynamics, which makes their full-scale simulation computationally slow. In this paper, we show how to decompose large networked systems of many agents into multiple local components such that we can build separate simulators that run independently and in parallel. To monitor the influence that the different local components exert on one another, each of these simulators is equipped with a learned model that is periodically trained on real trajectories. Our empirical results reveal that distributing the simulation among different processes not only makes it possible to train large multi-agent systems in just a few hours but also helps mitigate the negative effects of simultaneous learning.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.MA"
        ],
        "submitted_date": "1 Jul 2022",
        "last_revised_date": " "
    },
    "2207.01227": {
        "title": "Cybersecurity: Past, Present and Future",
        "authors": [
            "Shahid Alam"
        ],
        "comments": "Author's copy of the book published under ISBN: 978-620-4-74421-6",
        "subjects": "Cryptography and Security (cs.CR)",
        "abstract": "The digital transformation has created a new digital space known as cyberspace. This new cyberspace has improved the workings of businesses, organizations, governments, society as a whole, and day to day life of an individual. With these improvements come new challenges, and one of the main challenges is security. The security of the new cyberspace is called cybersecurity. Cyberspace has created new technologies and environments such as cloud computing, smart devices, IoTs, and several others. To keep pace with these advancements in cyber technologies there is a need to expand research and develop new cybersecurity methods and tools to secure these domains and environments. This book is an effort to introduce the reader to the field of cybersecurity, highlight current issues and challenges, and provide future directions to mitigate or resolve them. The main specializations of cybersecurity covered in this book are software security, hardware security, the evolution of malware, biometrics, cyber intelligence, and cyber forensics. We must learn from the past, evolve our present and improve the future. Based on this objective, the book covers the past, present, and future of these main specializations of cybersecurity. The book also examines the upcoming areas of research in cyber intelligence, such as hybrid augmented and explainable artificial intelligence (AI). Human and AI collaboration can significantly increase the performance of a cybersecurity system. Interpreting and explaining machine learning models, i.e., explainable AI is an emerging field of study and has a lot of potentials to improve the role of AI in cybersecurity.\n    ",
        "primary_category": "cs.CR",
        "categories": [],
        "submitted_date": "4 Jul 2022",
        "last_revised_date": " "
    },
    "2207.03512": {
        "title": "The effect of smooth parametrizations on nonconvex optimization landscapes",
        "authors": [
            "Eitan Levin",
            "Joe Kileel",
            "Nicolas Boumal"
        ],
        "comments": " ",
        "subjects": "Optimization and Control (math.OC)",
        "abstract": "We develop new tools to study landscapes in nonconvex optimization. Given one optimization problem, we pair it with another by smoothly parametrizing the domain. This is either for practical purposes (e.g., to use smooth optimization algorithms with good guarantees) or for theoretical purposes (e.g., to reveal that the landscape satisfies a strict saddle property). In both cases, the central question is: how do the landscapes of the two problems relate? More precisely: how do desirable points such as local minima and critical points in one problem relate to those in the other problem? A key finding in this paper is that these relations are often determined by the parametrization itself, and are almost entirely independent of the cost function. Accordingly, we introduce a general framework to study parametrizations by their effect on landscapes. The framework enables us to obtain new guarantees for an array of problems, some of which were previously treated on a case-by-case basis in the literature. Applications include: optimizing low-rank matrices and tensors through factorizations; solving semidefinite programs via the Burer-Monteiro approach; training neural networks by optimizing their weights and biases; and quotienting out symmetries.\n    ",
        "primary_category": "math.OC",
        "categories": [
            "math.NA"
        ],
        "submitted_date": "7 Jul 2022",
        "last_revised_date": " "
    },
    "2207.04007": {
        "title": "Event Collapse in Contrast Maximization Frameworks",
        "authors": [
            "Shintaro Shiba",
            "Yoshimitsu Aoki",
            "Guillermo Gallego"
        ],
        "comments": "19 pages, 8 figures, 3 tables",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Contrast maximization (CMax) is a framework that provides state-of-the-art results on several event-based computer vision tasks, such as ego-motion or optical flow estimation. However, it may suffer from a problem called event collapse, which is an undesired solution where events are warped into too few pixels. As prior works have largely ignored the issue or proposed workarounds, it is imperative to analyze this phenomenon in detail. Our work demonstrates event collapse in its simplest form and proposes collapse metrics by using first principles of space-time deformation based on differential geometry and physics. We experimentally show on publicly available datasets that the proposed metrics mitigate event collapse and do not harm well-posed warps. To the best of our knowledge, regularizers based on the proposed metrics are the only effective solution against event collapse in the experimental settings considered, compared with other methods. We hope that this work inspires further research to tackle more complex warp models.\n    ",
        "primary_category": "cs.CV",
        "categories": [
            "cs.RO",
            "math.DG"
        ],
        "submitted_date": "8 Jul 2022",
        "last_revised_date": " "
    },
    "2207.04779": {
        "title": "Mathematical Proof Between Generations",
        "authors": [
            "Jonas Bayer",
            "Christoph Benzm\u00fcller",
            "Kevin Buzzard",
            "Marco David",
            "Leslie Lamport",
            "Yuri Matiyasevich",
            "Lawrence Paulson",
            "Dierk Schleicher",
            "Benedikt Stock",
            "Efim Zelmanov"
        ],
        "comments": "17 pages, 1 figure",
        "subjects": "History and Overview (math.HO)",
        "abstract": "A proof is one of the most important concepts of mathematics. However, there is a striking difference between how a proof is defined in theory and how it is used in practice. This puts the unique status of mathematics as exact science into peril. Now may be the time to reconcile theory and practice, i.e. precision and intuition, through the advent of computer proof assistants. For the most time this has been a topic for experts in specialized communities. However, mathematical proofs have become increasingly sophisticated, stretching the boundaries of what is humanly comprehensible, so that leading mathematicians have asked for formal verification of their proofs. At the same time, major theorems in mathematics have recently been computer-verified by people from outside of these communities, even by beginning students. This article investigates the gap between the different definitions of a proof and possibilities to build bridges. It is written as a polemic or a collage by different members of the communities in mathematics and computer science at different stages of their careers, challenging well-known preconceptions and exploring new perspectives.\n    ",
        "primary_category": "math.HO",
        "categories": [
            "cs.LO"
        ],
        "submitted_date": "8 Jul 2022",
        "last_revised_date": " "
    },
    "2207.05510": {
        "title": "Transferability-Guided Cross-Domain Cross-Task Transfer Learning",
        "authors": [
            "Yang Tan",
            "Enming Zhang",
            "Yang Li",
            "Shao-Lun Huang",
            "Xiao-Ping Zhang"
        ],
        "comments": "This work is accepted by IEEE TNNLS. Please see the official version this https URL may be transferred without notice, after which this version may no longer be accessible",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "We propose two novel transferability metrics F-OTCE (Fast Optimal Transport based Conditional Entropy) and JC-OTCE (Joint Correspondence OTCE) to evaluate how much the source model (task) can benefit the learning of the target task and to learn more transferable representations for cross-domain cross-task transfer learning. Unlike the existing metric that requires evaluating the empirical transferability on auxiliary tasks, our metrics are auxiliary-free such that they can be computed much more efficiently. Specifically, F-OTCE estimates transferability by first solving an Optimal Transport (OT) problem between source and target distributions, and then uses the optimal coupling to compute the Negative Conditional Entropy between source and target labels. It can also serve as a loss function to maximize the transferability of the source model before finetuning on the target task. Meanwhile, JC-OTCE improves the transferability robustness of F-OTCE by including label distances in the OT problem, though it may incur additional computation cost. Extensive experiments demonstrate that F-OTCE and JC-OTCE outperform state-of-the-art auxiliary-free metrics by 18.85% and 28.88%, respectively in correlation coefficient with the ground-truth transfer accuracy. By eliminating the training cost of auxiliary tasks, the two metrics reduces the total computation time of the previous method from 43 minutes to 9.32s and 10.78s, respectively, for a pair of tasks. When used as a loss function, F-OTCE shows consistent improvements on the transfer accuracy of the source model in few-shot classification experiments, with up to 4.41% accuracy gain.\n    ",
        "primary_category": "cs.CV",
        "categories": [
            "cs.AI",
            "cs.LG"
        ],
        "submitted_date": "12 Jul 2022",
        "last_revised_date": " "
    },
    "2207.05564": {
        "title": "The expected sum of edge lengths in planar linearizations of trees. Theory and applications",
        "authors": [
            "Llu\u00eds Alemany-Puig",
            "Ramon Ferrer-i-Cancho"
        ],
        "comments": "New version updated",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "Dependency trees have proven to be a very successful model to represent the syntactic structure of sentences of human languages. In these structures, vertices are words and edges connect syntactically-dependent words. The tendency of these dependencies to be short has been demonstrated using random baselines for the sum of the lengths of the edges or its variants. A ubiquitous baseline is the expected sum in projective orderings (wherein edges do not cross and the root word of the sentence is not covered by any edge), that can be computed in time $O(n)$. Here we focus on a weaker formal constraint, namely planarity. In the theoretical domain, we present a characterization of planarity that, given a sentence, yields either the number of planar permutations or an efficient algorithm to generate uniformly random planar permutations of the words. We also show the relationship between the expected sum in planar arrangements and the expected sum in projective arrangements. In the domain of applications, we derive a $O(n)$-time algorithm to calculate the expected value of the sum of edge lengths. We also apply this research to a parallel corpus and find that the gap between actual dependency distance and the random baseline reduces as the strength of the formal constraint on dependency structures increases, suggesting that formal constraints absorb part of the dependency distance minimization effect. Our research paves the way for replicating past research on dependency distance minimization using random planar linearizations as random baseline.\n    ",
        "primary_category": "cs.CL",
        "categories": [],
        "submitted_date": "12 Jul 2022",
        "last_revised_date": " "
    },
    "2207.05868": {
        "title": "Approximation algorithms for job scheduling with block-type conflict graphs",
        "authors": [
            "Hanna Furma\u0144czyk",
            "Tytus Pikies",
            "Inka Soko\u0142owska",
            "Krzysztof Turowski"
        ],
        "comments": "48 pages, 6 figures, 9 algorithms",
        "subjects": "Discrete Mathematics (cs.DM)",
        "abstract": "The problem of scheduling jobs on parallel machines (identical, uniform, or unrelated), under incompatibility relation modeled as a block graph, under the makespan optimality criterion, is considered in this paper. No two jobs that are in the relation (equivalently in the same block) may be scheduled on the same machine in this model.\nThe presented model stems from a well-established line of research combining scheduling theory with methods relevant to graph coloring. Recently, cluster graphs and their extensions like block graphs were given additional attention. We complement hardness results provided by other researchers for block graphs by providing approximation algorithms. In particular, we provide a $2$-approximation algorithm for $P|G = block\\ graph|C_{max}$ and a PTAS for the case when the jobs are unit time in addition. In the case of uniform machines, we analyze two cases. The first one is when the number of blocks is bounded, i.e. $Q|G = k-block\\ graph|C_{max}$. For this case, we provide a PTAS, improving upon results presented by D. Page and R. Solis-Oba. The improvement is two-fold: we allow richer graph structure, and we allow the number of machine speeds to be part of the input. Due to strong NP-hardness of $Q|G = 2-clique\\ graph|C_{max}$, the result establishes the approximation status of $Q|G = k-block\\ graph|C_{max}$. The PTAS might be of independent interest because the problem is tightly related to the NUMERICAL k-DIMENSIONAL MATCHING WITH TARGET SUMS problem. The second case that we analyze is when the number of blocks is arbitrary, but the number of cut-vertices is bounded and jobs are of unit time. In this case, we present an exact algorithm. In addition, we present an FPTAS for graphs with bounded treewidth and a bounded number of unrelated machines.\n    ",
        "primary_category": "cs.DM",
        "categories": [],
        "submitted_date": "12 Jul 2022",
        "last_revised_date": " "
    },
    "2207.06492": {
        "title": "Approximate Nash Equilibrium Learning for n-Player Markov Games in Dynamic Pricing",
        "authors": [
            "Larkin Liu"
        ],
        "comments": " ",
        "subjects": "Computer Science and Game Theory (cs.GT)",
        "abstract": "We investigate Nash equilibrium learning in a competitive Markov Game (MG) environment, where multiple agents compete, and multiple Nash equilibria can exist. In particular, for an oligopolistic dynamic pricing environment, exact Nash equilibria are difficult to obtain due to the curse-of-dimensionality. We develop a new model-free method to find approximate Nash equilibria. Gradient-free black box optimization is then applied to estimate $\\epsilon$, the maximum reward advantage of an agent unilaterally deviating from any joint policy, and to also estimate the $\\epsilon$-minimizing policy for any given state. The policy-$\\epsilon$ correspondence and the state to $\\epsilon$-minimizing policy are represented by neural networks, the latter being the Nash Policy Net. During batch update, we perform Nash Q learning on the system, by adjusting the action probabilities using the Nash Policy Net. We demonstrate that an approximate Nash equilibrium can be learned, particularly in the dynamic pricing domain where exact solutions are often intractable.\n    ",
        "primary_category": "cs.GT",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "13 Jul 2022",
        "last_revised_date": " "
    },
    "2207.07827": {
        "title": "CLMFormer: Mitigating Data Redundancy to Revitalize Transformer-based Long-Term Time Series Forecasting System",
        "authors": [
            "Mingjie Li",
            "Rui Liu",
            "Guangsi Shi",
            "Mingfei Han",
            "Changling Li",
            "Lina Yao",
            "Xiaojun Chang",
            "Ling Chen"
        ],
        "comments": "Tech report",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Long-term time-series forecasting (LTSF) plays a crucial role in various practical applications. Transformer and its variants have become the de facto backbone for LTSF, offering exceptional capabilities in processing long sequence data. However, existing Transformer-based models, such as Fedformer and Informer, often achieve their best performances on validation sets after just a few epochs, indicating potential underutilization of the Transformer's capacity. One of the reasons that contribute to this overfitting is data redundancy arising from the rolling forecasting settings in the data augmentation process, particularly evident in longer sequences with highly similar adjacent data. In this paper, we propose a novel approach to address this issue by employing curriculum learning and introducing a memory-driven decoder. Specifically, we progressively introduce Bernoulli noise to the training samples, which effectively breaks the high similarity between adjacent data points. To further enhance forecasting accuracy, we introduce a memory-driven decoder. This component enables the model to capture seasonal tendencies and dependencies in the time-series data and leverages temporal relationships to facilitate the forecasting process. The experimental results on six real-life LTSF benchmarks demonstrate that our approach can be seamlessly plugged into varying Transformer-based models, with our approach enhancing the LTSF performances of various Transformer-based models by maximally 30%.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.CV"
        ],
        "submitted_date": "16 Jul 2022",
        "last_revised_date": " "
    },
    "2207.09286": {
        "title": "Exploring the Online Micro-targeting Practices of Small, Medium, and Large Businesses",
        "authors": [
            "Salim Chouaki",
            "Islem Bouzenia",
            "Oana Goga",
            "Beatrice Roussillon"
        ],
        "comments": " ",
        "subjects": "Computers and Society (cs.CY)",
        "abstract": "Facebook and other advertising platforms exploit users data for marketing purposes by allowing advertisers to select specific users and target them (the practice is being called micro-targeting). However, advertisers such as Cambridge Analytica have maliciously used these targeting features to manipulate users in the context of elections. The European Commission plans to restrict or ban some targeting functionalities in the new European Democracy Action Plan act to protect users from such harms. The difficulty is that we do not know the economic impact of these restrictions on regular advertisers. In this paper, to inform the debate, we take a first step by understanding who is advertising on Facebook and how they use the targeting functionalities. For this, we asked 890 U.S. users to install a monitoring tool on their browsers to collect the ads they receive on Facebook and information about how these ads were targeted. By matching advertisers on Facebook with their LinkedIn profiles, we could see that 71% of advertisers are small and medium-sized businesses with 200 employees or less, and they are responsible for 61% of ads and 57% of ad impressions. Regarding micro-targeting, we found that only 32% of small and medium-sized businesses and 30% of large-sized businesses micro-target at least one of their ads. These results should not be interpreted as micro-targeting not being useful as a marketing strategy, but rather that advertisers prefer to outsource the micro-targeting task to ad platforms. Indeed, Facebook is employing optimization algorithms that exploit user data to decide which users should see what ads; which means ad platforms are performing an algorithmic-driven micro-targeting. Hence, when setting restrictions, legislators should take into account both the traditional advertiser-driven micro-targeting as well as algorithmic-driven micro-targeting performed by ad platforms.\n    ",
        "primary_category": "cs.CY",
        "categories": [],
        "submitted_date": "19 Jul 2022",
        "last_revised_date": " "
    },
    "2207.10022": {
        "title": "Secrets of Event-Based Optical Flow",
        "authors": [
            "Shintaro Shiba",
            "Yoshimitsu Aoki",
            "Guillermo Gallego"
        ],
        "comments": "23 pages, 11 figures, 7 tables, this https URL",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Event cameras respond to scene dynamics and offer advantages to estimate motion. Following recent image-based deep-learning achievements, optical flow estimation methods for event cameras have rushed to combine those image-based methods with event data. However, it requires several adaptations (data conversion, loss function, etc.) as they have very different properties. We develop a principled method to extend the Contrast Maximization framework to estimate optical flow from events alone. We investigate key elements: how to design the objective function to prevent overfitting, how to warp events to deal better with occlusions, and how to improve convergence with multi-scale raw events. With these key elements, our method ranks first among unsupervised methods on the MVSEC benchmark, and is competitive on the DSEC benchmark. Moreover, our method allows us to expose the issues of the ground truth flow in those benchmarks, and produces remarkable results when it is transferred to unsupervised learning settings. Our code is available at this https URL\n",
        "primary_category": "cs.CV",
        "categories": [
            "cs.RO"
        ],
        "submitted_date": "20 Jul 2022",
        "last_revised_date": " "
    },
    "2207.12993": {
        "title": "On the Stability of Electromechanical Switching Devices",
        "authors": [
            "Edgar Ramirez-Laboreo",
            "Carlos Sagues",
            "Eduardo Moya-Lasheras",
            "Eloy Serrano-Seco"
        ],
        "comments": "11 pages, 11 figures. Revised version submitted for consideration to the IEEE/ASME Transactions on Mechatronics after first round of peer review",
        "subjects": "Systems and Control (eess.SY)",
        "abstract": "Electromagnetic relays and solenoid actuators are commonly used for their bistable behavior, which allows for switching between two states in electrical, pneumatic, or hydraulic circuits, among other applications. Although there has been extensive research on modeling, estimation, and control of these electromechanical systems, a gap remains in the analysis area. This paper addresses this gap by presenting an equilibrium and stability analysis to gain deeper insight into their bistability. This analysis leverages a hybrid dynamical model to obtain analytical expressions that relate the physical parameters to the switching conditions. These expressions are useful, e.g., for fundamental understanding, quick analyses, or design optimization. The results are discussed in depth and potential practical applications are explored. Finally, the analysis is validated with experimental results from a real device.\n    ",
        "primary_category": "eess.SY",
        "categories": [],
        "submitted_date": "26 Jul 2022",
        "last_revised_date": " "
    },
    "2208.00463": {
        "title": "Mismatching-Aware Unsupervised Translation Quality Estimation For Low-Resource Languages",
        "authors": [
            "Fatemeh Azadi",
            "Heshaam Faili",
            "Mohammad Javad Dousti"
        ],
        "comments": "Submitted to Language Resources and Evaluation",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "Translation Quality Estimation (QE) is the task of predicting the quality of machine translation (MT) output without any reference. This task has gained increasing attention as an important component in the practical applications of MT. In this paper, we first propose XLMRScore, which is a cross-lingual counterpart of BERTScore computed via the XLM-RoBERTa (XLMR) model. This metric can be used as a simple unsupervised QE method, nevertheless facing two issues: firstly, the untranslated tokens leading to unexpectedly high translation scores, and secondly, the issue of mismatching errors between source and hypothesis tokens when applying the greedy matching in XLMRScore. To mitigate these issues, we suggest replacing untranslated words with the unknown token and the cross-lingual alignment of the pre-trained model to represent aligned words closer to each other, respectively. We evaluate the proposed method on four low-resource language pairs of the WMT21 QE shared task, as well as a new English$\\rightarrow$Persian (En-Fa) test dataset introduced in this paper. Experiments show that our method could get comparable results with the supervised baseline for two zero-shot scenarios, i.e., with less than 0.01 difference in Pearson correlation, while outperforming unsupervised rivals in all the low-resource language pairs for above 8%, on average.\n    ",
        "primary_category": "cs.CL",
        "categories": [],
        "submitted_date": "31 Jul 2022",
        "last_revised_date": " "
    },
    "2208.05424": {
        "title": "Hard-Constrained Deep Learning for Climate Downscaling",
        "authors": [
            "Paula Harder",
            "Alex Hernandez-Garcia",
            "Venkatesh Ramesh",
            "Qidong Yang",
            "Prasanna Sattigeri",
            "Daniela Szwarcman",
            "Campbell Watson",
            "David Rolnick"
        ],
        "comments": " ",
        "subjects": "Atmospheric and Oceanic Physics (physics.ao-ph)",
        "abstract": "The availability of reliable, high-resolution climate and weather data is important to inform long-term decisions on climate adaptation and mitigation and to guide rapid responses to extreme events. Forecasting models are limited by computational costs and, therefore, often generate coarse-resolution predictions. Statistical downscaling, including super-resolution methods from deep learning, can provide an efficient method of upsampling low-resolution data. However, despite achieving visually compelling results in some cases, such models frequently violate conservation laws when predicting physical variables. In order to conserve physical quantities, here we introduce methods that guarantee statistical constraints are satisfied by a deep learning downscaling model, while also improving their performance according to traditional metrics. We compare different constraining approaches and demonstrate their applicability across different neural architectures as well as a variety of climate and weather data sets. Besides enabling faster and more accurate climate predictions through downscaling, we also show that our novel methodologies can improve super-resolution for satellite data and natural images data sets.\n    ",
        "primary_category": "physics.ao-ph",
        "categories": [
            "cs.LG"
        ],
        "submitted_date": "8 Aug 2022",
        "last_revised_date": " "
    },
    "2208.09500": {
        "title": "Causality-Inspired Taxonomy for Explainable Artificial Intelligence",
        "authors": [
            "Pedro C. Neto",
            "Tiago Gon\u00e7alves",
            "Jo\u00e3o Ribeiro Pinto",
            "Wilson Silva",
            "Ana F. Sequeira",
            "Arun Ross",
            "Jaime S. Cardoso"
        ],
        "comments": " ",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "As two sides of the same coin, causality and explainable artificial intelligence (xAI) were initially proposed and developed with different goals. However, the latter can only be complete when seen through the lens of the causality framework. As such, we propose a novel causality-inspired framework for xAI that creates an environment for the development of xAI approaches. To show its applicability, biometrics was used as case study. For this, we have analysed 81 research papers on a myriad of biometric modalities and different tasks. We have categorised each of these methods according to our novel xAI Ladder and discussed the future directions of the field.\n    ",
        "primary_category": "cs.CV",
        "categories": [],
        "submitted_date": "19 Aug 2022",
        "last_revised_date": " "
    },
    "2208.10824": {
        "title": "Improved rates for a space-time FOSLS of parabolic PDEs",
        "authors": [
            "Gregor Gantner",
            "Rob Stevenson"
        ],
        "comments": " ",
        "subjects": "Numerical Analysis (math.NA)",
        "abstract": "We consider the first-order system space-time formulation of the heat equation introduced in [Bochev, Gunzburger, Springer, New York (2009)], and analyzed in [F\u00fchrer, Karkulik, Comput. Math. Appl. 92 (2021)] and [Gantner, Stevenson, ESAIM Math. Model. Numer. Anal.} 55 (2021)], with solution components $(u_1,{\\bf u}_2)=(u,-\\nabla_{\\bf x} u)$. The corresponding operator is boundedly invertible between a Hilbert space $U$ and a Cartesian product of $L_2$-type spaces, which facilitates easy first-order system least-squares (FOSLS) discretizations. Besides $L_2$-norms of $\\nabla_{\\bf x} u_1$ and ${\\bf u}_2$, the (graph) norm of $U$ contains the $L_2$-norm of $\\partial_t u_1 +{\\rm div}_{\\bf x} {\\bf u}_2$. When applying standard finite elements w.r.t. simplicial partitions of the space-time cylinder, estimates of the approximation error w.r.t. the latter norm require higher-order smoothness of ${\\bf u}_2$. In experiments for both uniform and adaptively refined partitions, this manifested itself in disappointingly low convergence rates for non-smooth solutions $u$.\nIn this paper, we construct finite element spaces w.r.t. prismatic partitions. They come with a quasi-interpolant that satisfies a near commuting diagram in the sense that, apart from some harmless term, the aforementioned error depends exclusively on the smoothness of $\\partial_t u_1 +{\\rm div}_{\\bf x} {\\bf u}_2$, i.e., of the forcing term $f=(\\partial_t-\\Delta_x)u$. Numerical results show significantly improved convergence rates.\n    ",
        "primary_category": "math.NA",
        "categories": [],
        "submitted_date": "23 Aug 2022",
        "last_revised_date": " "
    },
    "2209.00945": {
        "title": "IMG2IMU: Translating Knowledge from Large-Scale Images to IMU Sensing Applications",
        "authors": [
            "Hyungjun Yoon",
            "Hyeongheon Cha",
            "Hoang C. Nguyen",
            "Taesik Gong",
            "Sung-Ju Lee"
        ],
        "comments": "12 pages",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Pre-training representations acquired via self-supervised learning could achieve high accuracy on even tasks with small training data. Unlike in vision and natural language processing domains, pre-training for IMU-based applications is challenging, as there are few public datasets with sufficient size and diversity to learn generalizable representations. To overcome this problem, we propose IMG2IMU that adapts pre-trained representation from large-scale images to diverse IMU sensing tasks. We convert the sensor data into visually interpretable spectrograms for the model to utilize the knowledge gained from vision. We further present a sensor-aware pre-training method for images that enables models to acquire particularly impactful knowledge for IMU sensing applications. This involves using contrastive learning on our augmentation set customized for the properties of sensor data. Our evaluation with four different IMU sensing tasks shows that IMG2IMU outperforms the baselines pre-trained on sensor data by an average of 9.6%p F1-score, illustrating that vision knowledge can be usefully incorporated into IMU sensing applications where only limited training data is available.\n    ",
        "primary_category": "cs.LG",
        "categories": [],
        "submitted_date": "2 Sep 2022",
        "last_revised_date": " "
    },
    "2209.01183": {
        "title": "Indoor Positioning in 5G-Advanced: Challenges and Solution towards Centimeter-level Accuracy with Carrier Phase Enhancements",
        "authors": [
            "Jakub Nikonowicz",
            "Aamir Mahmood",
            "Muhammad Ikram Ashraf",
            "Emil Bj\u00f6rnson",
            "Mikael Gidlund"
        ],
        "comments": "5 figures, 1 table, accepted for publication in IEEE Wireless Communications Magazine",
        "subjects": "Information Theory (cs.IT)",
        "abstract": "After robust connectivity, precise positioning is evolving into an innovative component of 5G service offerings for industrial use-cases and verticals with challenging indoor radio environments. In this direction, the 3GPP Rel-16 standard has been a tipping point in specifying critical innovations, followed by enhancements in Rel-17 and Rel-18. In this article, we elaborate on the 5G positioning framework, measurements, and procedures before shifting the focus mainly to recently identified carrier-phase (CP) measurements in Rel-18 as a complementary measure for time- and angular-based positioning methods. We discuss the associated challenges and potential solutions for exploiting CP, including integer ambiguity, multipath sensitivity, and signaling aspects. Furthermore, we study how phase-continuous reference signaling can counter noisy phase measurements using realistic simulations to achieve centimeter-level accuracy in indoor factory (InF) scenarios.\n    ",
        "primary_category": "cs.IT",
        "categories": [],
        "submitted_date": "2 Sep 2022",
        "last_revised_date": " "
    },
    "2209.01970": {
        "title": "FIRED: a fine-grained robust performance diagnosis framework for cloud applications",
        "authors": [
            "Ruyue Xin",
            "Hongyun Liu",
            "Peng Chen",
            "Paola Grosso",
            "Zhiming Zhao"
        ],
        "comments": " ",
        "subjects": "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "abstract": "To run a cloud application with the required service quality, operators have to continuously monitor the cloud application's run-time status, detect potential performance anomalies, and diagnose the root causes of anomalies. However, existing models of performance anomaly detection often suffer from low re-usability and robustness due to the diversity of system-level metrics being monitored and the lack of high-quality labeled monitoring data for anomalies. Moreover, the current coarse-grained analysis models make it difficult to locate system-level root causes of the application performance anomalies for effective adaptation decisions. We provide a FIne-grained Robust pErformance Diagnosis (FIRED) framework to tackle those challenges. The framework offers an ensemble of several well-selected base models for anomaly detection using a deep neural network, which adopts weakly-supervised learning considering fewer labels exist in reality. The framework also employs a real-time fine-grained analysis model to locate dependent system metrics of the anomaly. Our experiments show that the framework can achieve the best detection accuracy and algorithm robustness, and it can predict anomalies in four minutes with F1 score higher than 0.8. In addition, the framework can accurately localize the first root causes, and with an average accuracy higher than 0.7 of locating first four root causes.\n    ",
        "primary_category": "cs.DC",
        "categories": [],
        "submitted_date": "5 Sep 2022",
        "last_revised_date": " "
    },
    "2209.02166": {
        "title": "To Compute or not to Compute? Adaptive Smart Sensing in Resource-Constrained Edge Computing",
        "authors": [
            "Luca Ballotta",
            "Giovanni Peserico",
            "Francesco Zanini",
            "Paolo Dini"
        ],
        "comments": "16 pages, 17 figures; submitted to IEEE TNSE; final accepted version",
        "subjects": "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "abstract": "We consider a network of smart sensors for an edge computing application that sample a time-varying signal and send updates to a base station for remote global monitoring. Sensors are equipped with sensing and compute, and can either send raw data or process them on-board before transmission. Limited hardware resources at the edge generate a fundamental latency-accuracy trade-off: raw measurements are inaccurate but timely, whereas accurate processed updates are available after processing delay. Hence, one needs to decide when sensors should transmit raw measurements or rely on local processing to maximize network monitoring performance. To tackle this sensing design problem, we model an estimation-theoretic optimization framework that embeds both computation and communication latency, and propose a Reinforcement Learning-based approach that dynamically allocates computational resources at each sensor. Effectiveness of our proposed approach is validated through numerical experiments motivated by smart sensing for the Internet of Drones and self-driving vehicles. In particular, we show that, under constrained computation at the base station, monitoring performance can be further improved by an online sensor selection.\n    ",
        "primary_category": "cs.DC",
        "categories": [
            "cs.AI",
            "cs.RO"
        ],
        "submitted_date": "5 Sep 2022",
        "last_revised_date": " "
    },
    "2209.03602": {
        "title": "Template-based Program Synthesis using Stellens\u00e4tze",
        "authors": [
            "Amir Kafshdar Goharshady",
            "S. Hitarth",
            "Fatemeh Mohammadi",
            "Harshit J Motwani"
        ],
        "comments": " ",
        "subjects": "Programming Languages (cs.PL)",
        "abstract": "Template-based synthesis, also known as sketching, is a localized approach to program synthesis in which the programmer provides not only a specification, but also a high-level ``sketch'' of the program. The sketch is basically a partial program that models the general intuition of the programmer, while leaving the low-level details as unimplemented ``holes''. The role of the synthesis engine is then to fill in these holes such that the completed program satisfies the desired specification. In this work, we focus on template-based synthesis of polynomial imperative programs with real variables, i.e.~imperative programs in which all expressions appearing in assignments, conditions and guards are polynomials over program variables. While this problem can be solved in a sound and complete manner by a reduction to the first-order theory of the reals, the resulting formulas will contain a quantifier alternation and are extremely hard for modern SMT solvers, even when considering toy programs with a handful of lines. Moreover, the classical algorithms for quantifier elimination are notoriously unscalable and not at all applicable to this use-case.\nIn contrast, our main contribution is an algorithm, based on several well-known theorems in polyhedral and real algebraic geometry, namely Putinar's Positivstellensatz, the Real Nullstellensatz, Handelman's Theorem and Farkas' Lemma, which sidesteps the quantifier elimination difficulty and reduces the problem directly to Quadratic Programming (QP). Alternatively, one can view our algorithm as an efficient way of eliminating quantifiers in the particular formulas that appear in the synthesis problem. The resulting QP instances can then be handled quite easily by SMT solvers. Notably, our reduction to QP is sound and semi-complete, i.e.~it is complete if polynomials of a sufficiently high degree are used in the templates...\n    ",
        "primary_category": "cs.PL",
        "categories": [],
        "submitted_date": "8 Sep 2022",
        "last_revised_date": " "
    },
    "2209.04244": {
        "title": "Window Expressions for Stream Data Processing",
        "authors": [
            "M. Praveen",
            "S. Hitarth"
        ],
        "comments": " ",
        "subjects": "Formal Languages and Automata Theory (cs.FL)",
        "abstract": "Traditional ways of storing and querying data do not work well in scenarios where data is being generated continuously and quick decisions need to be taken. For example, in hospital intensive care units, signals from multiple devices need to be monitored and the occurrence of any anomaly should raise alarms immediately. A typical design would take the average from a window of say 10 seconds (time-based) or 10 successive (count-based) readings and look for sudden deviations. Existing stream processing systems either restrict the windows to time or count-based windows or let users define customized windows in imperative programming languages. These are subject to the implementers' interpretation of what is desired and hard to understand for others. We introduce a formalism for specifying windows based on Monadic Second Order logic. It offers several advantages over ad-hoc definitions written in imperative languages. We demonstrate four such advantages. First, we illustrate how practical streaming data queries can be easily written with precise semantics. Second, we can get different but expressively equivalent formalisms for defining windows. We use one of them (regular expressions) to design an end-user-friendly language for defining windows. Third, we use another expressively equivalent formalism (automata) to design a processor that automatically generates windows according to specifications. The fourth advantage we demonstrate is more sophisticated. Some window definitions have the problem of too many windows overlapping with each other, overwhelming the processing engine. This is handled in different ways by different engines, but all the options are about what to do when this happens at runtime. We study this as a static analysis question and prove that it is undecidable to check whether such a scenario can ever arise for a given window definition. We identify a decidable fragment...\n    ",
        "primary_category": "cs.FL",
        "categories": [],
        "submitted_date": "9 Sep 2022",
        "last_revised_date": " "
    },
    "2209.06356": {
        "title": "Using Forwards-Backwards Models to Approximate MDP Homomorphisms",
        "authors": [
            "Augustine N. Mavor-Parker",
            "Matthew J. Sargent",
            "Christian Pehle",
            "Andrea Banino",
            "Lewis D. Griffin",
            "Caswell Barry"
        ],
        "comments": "Previously Presented at the Multi-disciplinary Conference on Reinforcement Learning and Decision Making (RLDM) 2022",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Reinforcement learning agents must painstakingly learn through trial and error what sets of state-action pairs are value equivalent -- requiring an often prohibitively large amount of environment experience. MDP homomorphisms have been proposed that reduce the MDP of an environment to an abstract MDP, enabling better sample efficiency. Consequently, impressive improvements have been achieved when a suitable homomorphism can be constructed a priori -- usually by exploiting a practitioner's knowledge of environment symmetries. We propose a novel approach to constructing homomorphisms in discrete action spaces, which uses a learnt model of environment dynamics to infer which state-action pairs lead to the same state -- which can reduce the size of the state-action space by a factor as large as the cardinality of the original action space. In MinAtar, we report an almost 4x improvement over a value-based off-policy baseline in the low sample limit, when averaging over all games and optimizers.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "14 Sep 2022",
        "last_revised_date": " "
    },
    "2209.06852": {
        "title": "A Model Drift Detection and Adaptation Framework for 5G Core Networks",
        "authors": [
            "Dimitrios Michael Manias",
            "Ali Chouman",
            "Abdallah Shami"
        ],
        "comments": "Accepted: IEEE MeditCom 2022",
        "subjects": "Networking and Internet Architecture (cs.NI)",
        "abstract": "The advent of Fifth Generation (5G) and beyond 5G networks (5G+) has revolutionized the way network operators consider the management and orchestration of their networks. With an increased focus on intelligence and automation through core network functions such as the NWDAF, service providers are tasked with integrating machine learning models and artificial intelligence systems into their existing network operation practices. Due to the dynamic nature of next-generation networks and their supported use cases and applications, model drift is a serious concern, which can deteriorate the performance of intelligent models deployed throughout the network. The work presented in this paper introduces a model drift detection and adaptation module for 5G core networks. Using a functional prototype of a 5G core network, a drift in user behaviour is emulated, and the proposed framework is deployed and tested. The results of this work demonstrate the ability of the drift detection module to accurately characterize a drifted concept as well as the ability of the drift adaptation module to begin the necessary remediation efforts to restore system performance.\n    ",
        "primary_category": "cs.NI",
        "categories": [
            "cs.LG"
        ],
        "submitted_date": "8 Aug 2022",
        "last_revised_date": " "
    },
    "2209.10428": {
        "title": "An NWDAF Approach to 5G Core Network Signaling Traffic: Analysis and Characterization",
        "authors": [
            "Dimitrios Michael Manias",
            "Ali Chouman",
            "Abdallah Shami"
        ],
        "comments": "Accepted in IEEE GlobeCom 2022",
        "subjects": "Networking and Internet Architecture (cs.NI)",
        "abstract": "Data-driven approaches and paradigms have become promising solutions to efficient network performances through optimization. These approaches focus on state-of-the-art machine learning techniques that can address the needs of 5G networks and the networks of tomorrow, such as proactive load balancing. In contrast to model-based approaches, data-driven approaches do not need accurate models to tackle the target problem, and their associated architectures provide a flexibility of available system parameters that improve the feasibility of learning-based algorithms in mobile wireless networks. The work presented in this paper focuses on demonstrating a working system prototype of the 5G Core (5GC) network and the Network Data Analytics Function (NWDAF) used to bring the benefits of data-driven techniques to fruition. Analyses of the network-generated data explore core intra-network interactions through unsupervised learning, clustering, and evaluate these results as insights for future opportunities and works.\n    ",
        "primary_category": "cs.NI",
        "categories": [
            "cs.LG"
        ],
        "submitted_date": "21 Sep 2022",
        "last_revised_date": " "
    },
    "2209.12044": {
        "title": "Characterising memory in infinite games",
        "authors": [
            "Antonio Casares",
            "Pierre Ohlmann"
        ],
        "comments": "52 pages, 21 figures",
        "subjects": "Formal Languages and Automata Theory (cs.FL)",
        "abstract": "This paper is concerned with games of infinite duration played over potentially infinite graphs. Recently, Ohlmann (LICS 2022) presented a characterisation of objectives admitting optimal positional strategies, by means of universal graphs: an objective is positional if and only if it admits well-ordered monotone universal graphs. We extend Ohlmann's characterisation to encompass (finite or infinite) memory upper bounds.\nWe prove that objectives admitting optimal strategies with $\\varepsilon$-memory less than $m$ (a memory that cannot be updated when reading an $\\varepsilon$-edge) are exactly those which admit well-founded monotone universal graphs whose antichains have size bounded by $m$. We also give a characterisation of chromatic memory by means of appropriate universal structures. Our results apply to finite as well as infinite memory bounds (for instance, to objectives with finite but unbounded memory, or with countable memory strategies).\nWe illustrate the applicability of our framework by carrying out a few case studies, we provide examples witnessing limitations of our approach, and we discuss general closure properties which follow from our results.\n    ",
        "primary_category": "cs.FL",
        "categories": [
            "cs.LO"
        ],
        "submitted_date": "24 Sep 2022",
        "last_revised_date": " "
    },
    "2209.13099": {
        "title": "Bayesian Mechanism Design for Blockchain Transaction Fee Allocation",
        "authors": [
            "Xi Chen",
            "David Simchi-Levi",
            "Zishuo Zhao",
            "Yuan Zhou"
        ],
        "comments": "63 pages, CESC 2022",
        "subjects": "Computer Science and Game Theory (cs.GT)",
        "abstract": "In blockchain systems, the design of transaction fee mechanisms is essential for stability and satisfaction for both miners and users. A recent work has proven the impossibility of collusion-proof mechanisms that achieve both non-zero miner revenue and Dominating-Strategy-Incentive-Compatible (DSIC) for users. However, a positive miner revenue is important in practice to motivate miners. To address this challenge, we consider a Bayesian game setting and relax the DSIC requirement for users to Bayesian-Nash-Incentive-Compatibility (BNIC). In particular, we propose an auxiliary mechanism method that makes connections between BNIC and DSIC mechanisms. With the auxiliary mechanism method, we design a transaction fee mechanism (TFM) based on the multinomial logit (MNL) choice model, and prove that the TFM has both BNIC and collusion-proof properties with an asymptotic constant-factor approximation of optimal miner revenue for i.i.d. bounded valuations. Our result breaks the zero-revenue barrier while preserving truthfulness and collusion-proof properties.\n    ",
        "primary_category": "cs.GT",
        "categories": [],
        "submitted_date": "27 Sep 2022",
        "last_revised_date": " "
    },
    "2209.13865": {
        "title": "Zero-Shot 3D Drug Design by Sketching and Generating",
        "authors": [
            "Siyu Long",
            "Yi Zhou",
            "Xinyu Dai",
            "Hao Zhou"
        ],
        "comments": "NeurIPS 2022 camera-ready",
        "subjects": "Computational Engineering, Finance, and Science (cs.CE)",
        "abstract": "Drug design is a crucial step in the drug discovery cycle. Recently, various deep learning-based methods design drugs by generating novel molecules from scratch, avoiding traversing large-scale drug libraries. However, they depend on scarce experimental data or time-consuming docking simulation, leading to overfitting issues with limited training data and slow generation speed. In this study, we propose the zero-shot drug design method DESERT (Drug dEsign by SkEtching and geneRaTing). Specifically, DESERT splits the design process into two stages: sketching and generating, and bridges them with the molecular shape. The two-stage fashion enables our method to utilize the large-scale molecular database to reduce the need for experimental data and docking simulation. Experiments show that DESERT achieves a new state-of-the-art at a fast speed.\n    ",
        "primary_category": "cs.CE",
        "categories": [
            "q-bio.BM"
        ],
        "submitted_date": "28 Sep 2022",
        "last_revised_date": " "
    },
    "2210.01282": {
        "title": "Structural Estimation of Markov Decision Processes in High-Dimensional State Space with Finite-Time Guarantees",
        "authors": [
            "Siliang Zeng",
            "Mingyi Hong",
            "Alfredo Garcia"
        ],
        "comments": "This conference version of this paper refers to \"Maximum-Likelihood Inverse Reinforcement Learning with Finite-Time Guarantees\" in NeurIPS 2022",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "We consider the task of estimating a structural model of dynamic decisions by a human agent based upon the observable history of implemented actions and visited states. This problem has an inherent nested structure: in the inner problem, an optimal policy for a given reward function is identified while in the outer problem, a measure of fit is maximized. Several approaches have been proposed to alleviate the computational burden of this nested-loop structure, but these methods still suffer from high complexity when the state space is either discrete with large cardinality or continuous in high dimensions. Other approaches in the inverse reinforcement learning (IRL) literature emphasize policy estimation at the expense of reduced reward estimation accuracy. In this paper we propose a single-loop estimation algorithm with finite time guarantees that is equipped to deal with high-dimensional state spaces without compromising reward estimation accuracy. In the proposed algorithm, each policy improvement step is followed by a stochastic gradient step for likelihood maximization. We show that the proposed algorithm converges to a stationary solution with a finite-time guarantee. Further, if the reward is parameterized linearly, we show that the algorithm approximates the maximum likelihood estimator sublinearly. Finally, by using robotics control problems in MuJoCo and their transfer settings, we show that the proposed algorithm achieves superior performance compared with other IRL and imitation learning benchmarks.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.AI",
            "econ.EM",
            "stat.ML"
        ],
        "submitted_date": "4 Oct 2022",
        "last_revised_date": " "
    },
    "2210.01598": {
        "title": "On the hull and interval numbers of oriented graphs",
        "authors": [
            "J. Araujo",
            "A. K. Maia",
            "P. P. Medeiros",
            "L. Penso"
        ],
        "comments": " ",
        "subjects": "Combinatorics (math.CO)",
        "abstract": "In this work, for a given oriented graph $D$, we study its interval and hull numbers, respectively, in the oriented geodetic, P3 and P3* convexities. This last one, we believe to be formally defined and first studied in this paper, although its undirected version is well-known in the literature.\nConcerning bounds, for a strongly oriented graph D, and the oriented geodetic convexity, we prove that $ohng(D)\\leq m(D)-n(D)+2$ and that there is at least one such that $ohng(D) = m(D)-n(D)$. We also determine exact values for the hull numbers in these three convexities for tournaments, which imply polynomial-time algorithms to compute them. These results allow us to deduce polynomial-time algorithms to compute $ohnp(D)$ when the underlying graph of $D$ is split or cobipartite.\nMoreover, we provide a meta-theorem by proving that if deciding whether $oing(D)\\leq k$ or $ohng(D)\\leq k$ is NP-hard or W[i]-hard parameterized by $k$, for some $i\\in\\mathbb{Z_+^*}$, then the same holds even if the underlying graph of $D$ is bipartite. Next, we prove that deciding whether $ohnp(D)\\leq k$ or $ohnps(D)\\leq k$ is W[2]-hard parameterized by $k$, even if $D$ is acyclic and its underlying graph is bipartite; that deciding whether $ohng(D)\\leq k$ is W[2]-hard parameterized by $k$, even if $D$ is acyclic; that deciding whether $oinp(D)\\leq k$ or $oinps(D)\\leq k$ is NP-complete, even if $D$ has no directed cycles and the underlying graph of $D$ is a chordal bipartite graph; and that deciding whether $oinp(D)\\leq k$ or $oinps(D)\\leq k$ is W[2]-hard parameterized by $k$, even if the underlying graph of $D$ is split.\nFinally, also argue that the interval and hull numbers in the oriented P3 and P3* convexities can be computed in cubic time for graphs of bounded clique-width by using Courcelle's theorem.\n    ",
        "primary_category": "math.CO",
        "categories": [
            "cs.CC",
            "cs.DM"
        ],
        "submitted_date": "4 Oct 2022",
        "last_revised_date": " "
    },
    "2210.01607": {
        "title": "A Generative Shape Compositional Framework to Synthesise Populations of Virtual Chimaeras",
        "authors": [
            "Haoran Dou",
            "Seppo Virtanen",
            "Nishant Ravikumar",
            "Alejandro F. Frangi"
        ],
        "comments": "15 pages, 4 figures, 4 tables. Accepted by IEEE Transactions on Neural Networks and Learning Systems",
        "subjects": "Image and Video Processing (eess.IV)",
        "abstract": "Generating virtual populations of anatomy that capture sufficient variability while remaining plausible is essential for conducting in-silico trials of medical devices. However, not all anatomical shapes of interest are always available for each individual in a population. Hence, missing/partially-overlapping anatomical information is often available across individuals in a population. We introduce a generative shape model for complex anatomical structures, learnable from datasets of unpaired datasets. The proposed generative model can synthesise complete whole complex shape assemblies coined virtual chimaeras, as opposed to natural human chimaeras. We applied this framework to build virtual chimaeras from databases of whole-heart shape assemblies that each contribute samples for heart substructures. Specifically, we propose a generative shape compositional framework which comprises two components - a part-aware generative shape model which captures the variability in shape observed for each structure of interest in the training population; and a spatial composition network which assembles/composes the structures synthesised by the former into multi-part shape assemblies (viz. virtual chimaeras). We also propose a novel self supervised learning scheme that enables the spatial composition network to be trained with partially overlapping data and weak labels. We trained and validated our approach using shapes of cardiac structures derived from cardiac magnetic resonance images available in the UK Biobank. Our approach significantly outperforms a PCA-based shape model (trained with complete data) in terms of generalisability and specificity. This demonstrates the superiority of the proposed approach as the synthesised cardiac virtual populations are more plausible and capture a greater degree of variability in shape than those generated by the PCA-based shape model.\n    ",
        "primary_category": "eess.IV",
        "categories": [
            "cs.CV",
            "cs.LG"
        ],
        "submitted_date": "4 Oct 2022",
        "last_revised_date": " "
    },
    "2210.02419": {
        "title": "Boundary-Aware Uncertainty for Feature Attribution Explainers",
        "authors": [
            "Davin Hill",
            "Aria Masoomi",
            "Max Torop",
            "Sandesh Ghimire",
            "Jennifer Dy"
        ],
        "comments": "Proceedings of the 27th International Conference on Artificial Intelligence and Statistics (AISTATS) 2024",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Post-hoc explanation methods have become a critical tool for understanding black-box classifiers in high-stakes applications. However, high-performing classifiers are often highly nonlinear and can exhibit complex behavior around the decision boundary, leading to brittle or misleading local explanations. Therefore there is an impending need to quantify the uncertainty of such explanation methods in order to understand when explanations are trustworthy. In this work we propose the Gaussian Process Explanation UnCertainty (GPEC) framework, which generates a unified uncertainty estimate combining decision boundary-aware uncertainty with explanation function approximation uncertainty. We introduce a novel geodesic-based kernel, which captures the complexity of the target black-box decision boundary. We show theoretically that the proposed kernel similarity increases with decision boundary complexity. The proposed framework is highly flexible; it can be used with any black-box classifier and feature attribution method. Empirical results on multiple tabular and image datasets show that the GPEC uncertainty estimate improves understanding of explanations as compared to existing methods.\n    ",
        "primary_category": "cs.LG",
        "categories": [],
        "submitted_date": "5 Oct 2022",
        "last_revised_date": " "
    },
    "2210.04870": {
        "title": "SMiLE: Schema-augmented Multi-level Contrastive Learning for Knowledge Graph Link Prediction",
        "authors": [
            "Miao Peng",
            "Ben Liu",
            "Qianqian Xie",
            "Wenjie Xu",
            "Hua Wang",
            "Min Peng"
        ],
        "comments": "Findings of EMNLP 2022",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "Link prediction is the task of inferring missing links between entities in knowledge graphs. Embedding-based methods have shown effectiveness in addressing this problem by modeling relational patterns in triples. However, the link prediction task often requires contextual information in entity neighborhoods, while most existing embedding-based methods fail to capture it. Additionally, little attention is paid to the diversity of entity representations in different contexts, which often leads to false prediction results. In this situation, we consider that the schema of knowledge graph contains the specific contextual information, and it is beneficial for preserving the consistency of entities across contexts. In this paper, we propose a novel Schema-augmented Multi-level contrastive LEarning framework (SMiLE) to conduct knowledge graph link prediction. Specifically, we first exploit network schema as the prior constraint to sample negatives and pre-train our model by employing a multi-level contrastive learning method to yield both prior schema and contextual information. Then we fine-tune our model under the supervision of individual triples to learn subtler representations for link prediction. Extensive experimental results on four knowledge graph datasets with thorough analysis of each component demonstrate the effectiveness of our proposed framework against state-of-the-art baselines. The implementation of SMiLE is available at this https URL.\n    ",
        "primary_category": "cs.CL",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "10 Oct 2022",
        "last_revised_date": " "
    },
    "2210.07161": {
        "title": "A Logic of \"Black Box\" Classifier Systems",
        "authors": [
            "Xinghan Liu",
            "Emiliano Lorini"
        ],
        "comments": "17 pages",
        "subjects": "Logic in Computer Science (cs.LO)",
        "abstract": "Binary classifiers are traditionally studied by propositional logic (PL). PL can only represent them as white boxes, under the assumption that the underlying Boolean function is fully known. Binary classifiers used in practical applications and trained by machine learning are however opaque. They are usually described as black boxes. In this paper, we provide a product modal logic called PLC (Product modal Logic for binary input Classifier) in which the notion of \"black box\" is interpreted as the uncertainty over a set of classifiers. We give results about axiomatics and complexity of satisfiability checking for our logic. Moreover, we present a dynamic extension in which the process of acquiring new information about the actual classifier can be represented.\n    ",
        "primary_category": "cs.LO",
        "categories": [],
        "submitted_date": "13 Oct 2022",
        "last_revised_date": " "
    },
    "2210.08854": {
        "title": "Inexpensive polynomial-degree-robust equilibrated flux a posteriori estimates for isogeometric analysis",
        "authors": [
            "Gregor Gantner",
            "Martin Vohral\u00edk"
        ],
        "comments": " ",
        "subjects": "Numerical Analysis (math.NA)",
        "abstract": "We consider isogeometric discretizations of the Poisson model problem, focusing on high polynomial degrees and strong hierarchical refinements. We derive a posteriori error estimates by equilibrated fluxes, i.e., vector-valued mapped piecewise polynomials lying in the $\\boldsymbol{H}({\\rm div})$ space which appropriately approximate the desired divergence constraint. Our estimates are constant-free in the leading term, locally efficient, and robust with respect to the polynomial degree. They are also robust with respect to the number of hanging nodes arising in adaptive mesh refinement employing hierarchical B-splines. Two partitions of unity are designed, one with larger supports corresponding to the mapped splines, and one with small supports corresponding to mapped piecewise multilinear finite element hat basis functions. The equilibration is only performed on the small supports, avoiding the higher computational price of equilibration on the large supports or even the solution of a global system. Thus, the derived estimates are also as inexpensive as possible. An abstract framework for such a setting is developed, whose application to a specific situation only requests a verification of a few clearly identified assumptions. Numerical experiments illustrate the theoretical developments.\n    ",
        "primary_category": "math.NA",
        "categories": [],
        "submitted_date": "17 Oct 2022",
        "last_revised_date": " "
    },
    "2210.12090": {
        "title": "AutoPrognosis 2.0: Democratizing Diagnostic and Prognostic Modeling in Healthcare with Automated Machine Learning",
        "authors": [
            "Fergus Imrie",
            "Bogdan Cebere",
            "Eoin F. McKinney",
            "Mihaela van der Schaar"
        ],
        "comments": " ",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Diagnostic and prognostic models are increasingly important in medicine and inform many clinical decisions. Recently, machine learning approaches have shown improvement over conventional modeling techniques by better capturing complex interactions between patient covariates in a data-driven manner. However, the use of machine learning introduces a number of technical and practical challenges that have thus far restricted widespread adoption of such techniques in clinical settings. To address these challenges and empower healthcare professionals, we present a machine learning framework, AutoPrognosis 2.0, to develop diagnostic and prognostic models. AutoPrognosis leverages state-of-the-art advances in automated machine learning to develop optimized machine learning pipelines, incorporates model explainability tools, and enables deployment of clinical demonstrators, without requiring significant technical expertise. Our framework eliminates the major technical obstacles to predictive modeling with machine learning that currently impede clinical adoption. To demonstrate AutoPrognosis 2.0, we provide an illustrative application where we construct a prognostic risk score for diabetes using the UK Biobank, a prospective study of 502,467 individuals. The models produced by our automated framework achieve greater discrimination for diabetes than expert clinical risk scores. Our risk score has been implemented as a web-based decision support tool and can be publicly accessed by patients and clinicians worldwide. In addition, AutoPrognosis 2.0 is provided as an open-source python package. By open-sourcing our framework as a tool for the community, clinicians and other medical practitioners will be able to readily develop new risk scores, personalized diagnostics, and prognostics using modern machine learning techniques.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "21 Oct 2022",
        "last_revised_date": " "
    },
    "2210.14484": {
        "title": "Imputation of missing values in multi-view data",
        "authors": [
            "Wouter van Loon",
            "Marjolein Fokkema",
            "Frank de Vos",
            "Marisa Koini",
            "Reinhold Schmidt",
            "Mark de Rooij"
        ],
        "comments": "48 pages, 15 figures. Major revisions",
        "subjects": "Machine Learning (stat.ML)",
        "abstract": "Data for which a set of objects is described by multiple distinct feature sets (called views) is known as multi-view data. When missing values occur in multi-view data, all features in a view are likely to be missing simultaneously. This leads to very large quantities of missing data which, especially when combined with high-dimensionality, makes the application of conditional imputation methods computationally infeasible. We introduce a new imputation method based on the existing stacked penalized logistic regression (StaPLR) algorithm for multi-view learning. It performs imputation in a dimension-reduced space to address computational challenges inherent to the multi-view context. We compare the performance of the new imputation method with several existing imputation algorithms in simulated data sets. The results show that the new imputation method leads to competitive results at a much lower computational cost, and makes the use of advanced imputation algorithms such as missForest and predictive mean matching possible in settings where they would otherwise be computationally infeasible.\n    ",
        "primary_category": "stat.ML",
        "categories": [
            "cs.LG",
            "stat.ME"
        ],
        "submitted_date": "26 Oct 2022",
        "last_revised_date": " "
    },
    "2210.15073": {
        "title": "Hierarchical quantum circuit representations for neural architecture search",
        "authors": [
            "Matt Lourens",
            "Ilya Sinayskiy",
            "Daniel K. Park",
            "Carsten Blank",
            "Francesco Petruccione"
        ],
        "comments": "22 pages, 13 figures",
        "subjects": "Quantum Physics (quant-ph)",
        "abstract": "Machine learning with hierarchical quantum circuits, usually referred to as Quantum Convolutional Neural Networks (QCNNs), is a promising prospect for near-term quantum computing. The QCNN is a circuit model inspired by the architecture of Convolutional Neural Networks (CNNs). CNNs are successful because they do not need manual feature design and can learn high-level features from raw data. Neural Architecture Search (NAS) builds on this success by learning network architecture and achieves state-of-the-art performance. However, applying NAS to QCNNs presents unique challenges due to the lack of a well-defined search space. In this work, we propose a novel framework for representing QCNN architectures using techniques from NAS, which enables search space design and architecture search. Using this framework, we generate a family of popular QCNNs, those resembling reverse binary trees. We then evaluate this family of models on a music genre classification dataset, GTZAN, to justify the importance of circuit architecture. Furthermore, we employ a genetic algorithm to perform Quantum Phase Recognition (QPR) as an example of architecture search with our representation. This work provides a way to improve model performance without increasing complexity and to jump around the cost landscape to avoid barren plateaus. Finally, we implement the framework as an open-source Python package to enable dynamic QCNN creation and facilitate QCNN search space design for NAS.\n    ",
        "primary_category": "quant-ph",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "26 Oct 2022",
        "last_revised_date": " "
    },
    "2210.16662": {
        "title": "Global Optimization of Energy Efficiency in IRS-Aided Communication Systems via Robust IRS-Element Activation",
        "authors": [
            "Christos N. Efrem",
            "Ioannis Krikidis"
        ],
        "comments": "8 pages, 3 figures",
        "subjects": "Signal Processing (eess.SP)",
        "abstract": "In this paper, we study an intelligent reflecting surface (IRS) assisted communication system with single-antenna transmitter and receiver, under imperfect channel state information (CSI). More specifically, we deal with the robust selection of binary (on/off) states of the IRS elements in order to maximize the worst-case energy efficiency (EE), given a bounded CSI uncertainty, while satisfying a minimum signal-to-noise ratio (SNR). The IRS phase shifts are adjusted so as to maximize the ideal SNR (i.e., without CSI error), based only on the estimated channels. First, we derive a closed-form expression of the worst-case SNR, and then formulate the robust (discrete) optimization problem. Moreover, we design and analyze a dynamic programming (DP) algorithm that is theoretically guaranteed to achieve the global maximum with polynomial complexity $O(L \\log L)$, where $L$ is the number of IRS elements. Finally, numerical simulations confirm the theoretical results. In particular, the proposed algorithm shows identical performance with the exhaustive search, and significantly outperforms a baseline scheme, namely, the activation of all IRS elements.\n    ",
        "primary_category": "eess.SP",
        "categories": [
            "cs.IT"
        ],
        "submitted_date": "29 Oct 2022",
        "last_revised_date": " "
    },
    "2211.00103": {
        "title": "Towards Human Cognition Level-based Experiment Design for Counterfactual Explanations (XAI)",
        "authors": [
            "Muhammad Suffian",
            "Muhammad Yaseen Khan",
            "Alessandro Bogliolo"
        ],
        "comments": "5 pages, 2 figures",
        "subjects": "Artificial Intelligence (cs.AI)",
        "abstract": "Explainable Artificial Intelligence (XAI) has recently gained a swell of interest, as many Artificial Intelligence (AI) practitioners and developers are compelled to rationalize how such AI-based systems work. Decades back, most XAI systems were developed as knowledge-based or expert systems. These systems assumed reasoning for the technical description of an explanation, with little regard for the user's cognitive capabilities. The emphasis of XAI research appears to have turned to a more pragmatic explanation approach for better understanding. An extensive area where cognitive science research may substantially influence XAI advancements is evaluating user knowledge and feedback, which are essential for XAI system evaluation. To this end, we propose a framework to experiment with generating and evaluating the explanations on the grounds of different cognitive levels of understanding. In this regard, we adopt Bloom's taxonomy, a widely accepted model for assessing the user's cognitive capability. We utilize the counterfactual explanations as an explanation-providing medium encompassed with user feedback to validate the levels of understanding about the explanation at each cognitive level and improvise the explanation generation methods accordingly.\n    ",
        "primary_category": "cs.AI",
        "categories": [
            "cs.HC"
        ],
        "submitted_date": "31 Oct 2022",
        "last_revised_date": " "
    },
    "2211.00617": {
        "title": "Convergence of policy gradient methods for finite-horizon exploratory linear-quadratic control problems",
        "authors": [
            "Michael Giegrich",
            "Christoph Reisinger",
            "Yufei Zhang"
        ],
        "comments": "To be published in SIAM Journal on Control and Optimization",
        "subjects": "Optimization and Control (math.OC)",
        "abstract": "We study the global linear convergence of policy gradient (PG) methods for finite-horizon continuous-time exploratory linear-quadratic control (LQC) problems. The setting includes stochastic LQC problems with indefinite costs and allows additional entropy regularisers in the objective. We consider a continuous-time Gaussian policy whose mean is linear in the state variable and whose covariance is state-independent. Contrary to discrete-time problems, the cost is noncoercive in the policy and not all descent directions lead to bounded iterates. We propose geometry-aware gradient descents for the mean and covariance of the policy using the Fisher geometry and the Bures-Wasserstein geometry, respectively. The policy iterates are shown to satisfy an a-priori bound, and converge globally to the optimal policy with a linear rate. We further propose a novel PG method with discrete-time policies. The algorithm leverages the continuous-time analysis, and achieves a robust linear convergence across different action frequencies. A numerical experiment confirms the convergence and robustness of the proposed algorithm.\n    ",
        "primary_category": "math.OC",
        "categories": [
            "cs.LG"
        ],
        "submitted_date": "1 Nov 2022",
        "last_revised_date": " "
    },
    "2211.01412": {
        "title": "CAMANet: Class Activation Map Guided Attention Network for Radiology Report Generation",
        "authors": [
            "Jun Wang",
            "Abhir Bhalerao",
            "Terry Yin",
            "Simon See",
            "Yulan He"
        ],
        "comments": "Accepted to IEEE Journal of Biomedical and Health Informatics (IJBHI). 13 pages, 8 figures",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Radiology report generation (RRG) has gained increasing research attention because of its huge potential to mitigate medical resource shortages and aid the process of disease decision making by radiologists. Recent advancements in RRG are largely driven by improving a model's capabilities in encoding single-modal feature representations, while few studies explicitly explore the cross-modal alignment between image regions and words. Radiologists typically focus first on abnormal image regions before composing the corresponding text descriptions, thus cross-modal alignment is of great importance to learn a RRG model which is aware of abnormalities in the image. Motivated by this, we propose a Class Activation Map guided Attention Network (CAMANet) which explicitly promotes crossmodal alignment by employing aggregated class activation maps to supervise cross-modal attention learning, and simultaneously enrich the discriminative information. CAMANet contains three complementary modules: a Visual Discriminative Map Generation module to generate the importance/contribution of each visual token; Visual Discriminative Map Assisted Encoder to learn the discriminative representation and enrich the discriminative information; and a Visual Textual Attention Consistency module to ensure the attention consistency between the visual and textual tokens, to achieve the cross-modal alignment. Experimental results demonstrate that CAMANet outperforms previous SOTA methods on two commonly used RRG benchmarks.\n    ",
        "primary_category": "cs.CV",
        "categories": [],
        "submitted_date": "2 Nov 2022",
        "last_revised_date": " "
    },
    "2211.02507": {
        "title": "Dilations and information flow axioms in categorical probability",
        "authors": [
            "Tobias Fritz",
            "Tom\u00e1\u0161 Gonda",
            "Nicholas Gauguin Houghton-Larsen",
            "Antonio Lorenzin",
            "Paolo Perrone",
            "Dario Stein"
        ],
        "comments": "42 pages",
        "subjects": "Category Theory (math.CT)",
        "abstract": "We study the positivity and causality axioms for Markov categories as properties of dilations and information flow in Markov categories, and in variations thereof for arbitrary semicartesian monoidal categories. These help us show that being a positive Markov category is merely an additional property of a symmetric monoidal category (rather than extra structure). We also characterize the positivity of representable Markov categories and prove that causality implies positivity, but not conversely. Finally, we note that positivity fails for quasi-Borel spaces and interpret this failure as a privacy property of probabilistic name generation.\n    ",
        "primary_category": "math.CT",
        "categories": [
            "cs.IT",
            "cs.LO",
            "math.PR"
        ],
        "submitted_date": "4 Nov 2022",
        "last_revised_date": " "
    },
    "2211.05269": {
        "title": "Generative Adversarial Networks for Weakly Supervised Generation and Evaluation of Brain Tumor Segmentations on MR Images",
        "authors": [
            "Jay J. Yoo",
            "Khashayar Namdar",
            "Matthias W. Wagner",
            "Liana Nobre",
            "Uri Tabori",
            "Cynthia Hawkins",
            "Birgit B. Ertl-Wagner",
            "Farzad Khalvati"
        ],
        "comments": " ",
        "subjects": "Image and Video Processing (eess.IV)",
        "abstract": "Segmentation of regions of interest (ROIs) for identifying abnormalities is a leading problem in medical imaging. Using machine learning for this problem generally requires manually annotated ground-truth segmentations, demanding extensive time and resources from radiologists. This work presents a weakly supervised approach that utilizes binary image-level labels, which are much simpler to acquire, to effectively segment anomalies in 2D magnetic resonance images without ground truth annotations. We train a generative adversarial network (GAN) that converts cancerous images to healthy variants, which are used along with localization seeds as priors to generate improved weakly supervised segmentations. The non-cancerous variants can also be used to evaluate the segmentations in a weakly supervised fashion, which allows for the most effective segmentations to be identified and then applied to downstream clinical classification tasks. On the Multimodal Brain Tumor Segmentation (BraTS) 2020 dataset, our proposed method generates and identifies segmentations that achieve test Dice coefficients of 83.91%. Using these segmentations for pathology classification results with a test AUC of 93.32% which is comparable to the test AUC of 95.80% achieved when using true segmentations.\n    ",
        "primary_category": "eess.IV",
        "categories": [
            "cs.CV"
        ],
        "submitted_date": "10 Nov 2022",
        "last_revised_date": " "
    },
    "2211.05764": {
        "title": "DC-Check: A Data-Centric AI checklist to guide the development of reliable machine learning systems",
        "authors": [
            "Nabeel Seedat",
            "Fergus Imrie",
            "Mihaela van der Schaar"
        ],
        "comments": "Main paper: 11 pages, supplementary & case studies follow",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "While there have been a number of remarkable breakthroughs in machine learning (ML), much of the focus has been placed on model development. However, to truly realize the potential of machine learning in real-world settings, additional aspects must be considered across the ML pipeline. Data-centric AI is emerging as a unifying paradigm that could enable such reliable end-to-end pipelines. However, this remains a nascent area with no standardized framework to guide practitioners to the necessary data-centric considerations or to communicate the design of data-centric driven ML systems. To address this gap, we propose DC-Check, an actionable checklist-style framework to elicit data-centric considerations at different stages of the ML pipeline: Data, Training, Testing, and Deployment. This data-centric lens on development aims to promote thoughtfulness and transparency prior to system development. Additionally, we highlight specific data-centric AI challenges and research opportunities. DC-Check is aimed at both practitioners and researchers to guide day-to-day development. As such, to easily engage with and use DC-Check and associated resources, we provide a DC-Check companion website (this https URL). The website will also serve as an updated resource as methods and tooling evolve over time.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.AI",
            "cs.CY",
            "cs.SE",
            "stat.ML"
        ],
        "submitted_date": "9 Nov 2022",
        "last_revised_date": " "
    },
    "2211.07160": {
        "title": "FedTracker: Furnishing Ownership Verification and Traceability for Federated Learning Model",
        "authors": [
            "Shuo Shao",
            "Wenyuan Yang",
            "Hanlin Gu",
            "Zhan Qin",
            "Lixin Fan",
            "Qiang Yang",
            "Kui Ren"
        ],
        "comments": " ",
        "subjects": "Cryptography and Security (cs.CR)",
        "abstract": "Federated learning (FL) is a distributed machine learning paradigm allowing multiple clients to collaboratively train a global model without sharing their local data. However, FL entails exposing the model to various participants. This poses a risk of unauthorized model distribution or resale by the malicious client, compromising the intellectual property rights of the FL group. To deter such misbehavior, it is essential to establish a mechanism for verifying the ownership of the model and as well tracing its origin to the leaker among the FL participants. In this paper, we present FedTracker, the first FL model protection framework that provides both ownership verification and traceability. FedTracker adopts a bi-level protection scheme consisting of global watermark mechanism and local fingerprint mechanism. The former authenticates the ownership of the global model, while the latter identifies which client the model is derived from. FedTracker leverages Continual Learning (CL) principles to embed the watermark in a way that preserves the utility of the FL model on both primitive task and watermark task. FedTracker also devises a novel metric to better discriminate different fingerprints. Experimental results show FedTracker is effective in ownership verification, traceability, and maintains good fidelity and robustness against various watermark removal attacks.\n    ",
        "primary_category": "cs.CR",
        "categories": [
            "cs.AI",
            "cs.LG"
        ],
        "submitted_date": "14 Nov 2022",
        "last_revised_date": " "
    },
    "2211.07303": {
        "title": "Adaptive Federated Minimax Optimization with Lower Complexities",
        "authors": [
            "Feihu Huang",
            "Xinrui Wang",
            "Junyi Li",
            "Songcan Chen"
        ],
        "comments": "To appear in AISTATS 2024",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Federated learning is a popular distributed and privacy-preserving learning paradigm in machine learning. Recently, some federated learning algorithms have been proposed to solve the distributed minimax problems. However, these federated minimax algorithms still suffer from high gradient or communication complexity. Meanwhile, few algorithm focuses on using adaptive learning rate to accelerate these algorithms. To fill this gap, in the paper, we study a class of nonconvex minimax optimization, and propose an efficient adaptive federated minimax optimization algorithm (i.e., AdaFGDA) to solve these distributed minimax problems. Specifically, our AdaFGDA builds on the momentum-based variance reduced and local-SGD techniques, and it can flexibly incorporate various adaptive learning rates by using the unified adaptive matrices. Theoretically, we provide a solid convergence analysis framework for our AdaFGDA algorithm under non-i.i.d. setting. Moreover, we prove our AdaFGDA algorithm obtains a lower gradient (i.e., stochastic first-order oracle, SFO) complexity of $\\tilde{O}(\\epsilon^{-3})$ with lower communication complexity of $\\tilde{O}(\\epsilon^{-2})$ in finding $\\epsilon$-stationary point of the nonconvex minimax problems. Experimentally, we conduct some experiments on the deep AUC maximization and robust neural network training tasks to verify efficiency of our algorithms.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "math.OC"
        ],
        "submitted_date": "14 Nov 2022",
        "last_revised_date": " "
    },
    "2211.08229": {
        "title": "CorruptEncoder: Data Poisoning based Backdoor Attacks to Contrastive Learning",
        "authors": [
            "Jinghuai Zhang",
            "Hongbin Liu",
            "Jinyuan Jia",
            "Neil Zhenqiang Gong"
        ],
        "comments": "CVPR 2024",
        "subjects": "Cryptography and Security (cs.CR)",
        "abstract": "Contrastive learning (CL) pre-trains general-purpose encoders using an unlabeled pre-training dataset, which consists of images or image-text pairs. CL is vulnerable to data poisoning based backdoor attacks (DPBAs), in which an attacker injects poisoned inputs into the pre-training dataset so the encoder is backdoored. However, existing DPBAs achieve limited effectiveness. In this work, we take the first step to analyze the limitations of existing backdoor attacks and propose new DPBAs called CorruptEncoder to CL. CorruptEncoder introduces a new attack strategy to create poisoned inputs and uses a theory-guided method to maximize attack effectiveness. Our experiments show that CorruptEncoder substantially outperforms existing DPBAs. In particular, CorruptEncoder is the first DPBA that achieves more than 90% attack success rates with only a few (3) reference images and a small poisoning ratio 0.5%. Moreover, we also propose a defense, called localized cropping, to defend against DPBAs. Our results show that our defense can reduce the effectiveness of DPBAs, but it sacrifices the utility of the encoder, highlighting the need for new defenses.\n    ",
        "primary_category": "cs.CR",
        "categories": [
            "cs.CV",
            "cs.LG"
        ],
        "submitted_date": "15 Nov 2022",
        "last_revised_date": " "
    },
    "2211.14298": {
        "title": "PIP: Positional-encoding Image Prior",
        "authors": [
            "Nimrod Shabtay",
            "Eli Schwartz",
            "Raja Giryes"
        ],
        "comments": " ",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "In Deep Image Prior (DIP), a Convolutional Neural Network (CNN) is fitted to map a latent space to a degraded (e.g. noisy) image but in the process learns to reconstruct the clean image. This phenomenon is attributed to CNN's internal image-prior. We revisit the DIP framework, examining it from the perspective of a neural implicit representation. Motivated by this perspective, we replace the random or learned latent with Fourier-Features (Positional Encoding). We show that thanks to the Fourier features properties, we can replace the convolution layers with simple pixel-level MLPs. We name this scheme ``Positional Encoding Image Prior\" (PIP) and exhibit that it performs very similarly to DIP on various image-reconstruction tasks with much less parameters required. Additionally, we demonstrate that PIP can be easily extended to videos, where 3D-DIP struggles and suffers from instability. Code and additional examples for all tasks, including videos, are available on the project page this https URL\n",
        "primary_category": "cs.CV",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "25 Nov 2022",
        "last_revised_date": " "
    },
    "2211.16943": {
        "title": "Predicting Properties of Quantum Systems with Conditional Generative Models",
        "authors": [
            "Haoxiang Wang",
            "Maurice Weber",
            "Josh Izaac",
            "Cedric Yen-Yu Lin"
        ],
        "comments": "10 pages, 14 figures, 5 pages appendix. Open-source code is available at this https URL",
        "subjects": "Quantum Physics (quant-ph)",
        "abstract": "Machine learning has emerged recently as a powerful tool for predicting properties of quantum many-body systems. For many ground states of gapped Hamiltonians, generative models can learn from measurements of a single quantum state to reconstruct the state accurately enough to predict local observables. Alternatively, classification and regression models can predict local observables by learning from measurements on different but related states. In this work, we combine the benefits of both approaches and propose the use of conditional generative models to simultaneously represent a family of states, learning shared structures of different quantum states from measurements. The trained model enables us to predict arbitrary local properties of ground states, even for states not included in the training data, without necessitating further training for new observables. We first numerically validate our approach on 2D random Heisenberg models using simulations of up to 45 qubits. Furthermore, we conduct quantum simulations on a neutral-atom quantum computer and demonstrate that our method can accurately predict the quantum phases of square lattices of 13$\\times$13 Rydberg atoms.\n    ",
        "primary_category": "quant-ph",
        "categories": [
            "cs.LG"
        ],
        "submitted_date": "30 Nov 2022",
        "last_revised_date": " "
    },
    "2212.00322": {
        "title": "Hijack Vertical Federated Learning Models As One Party",
        "authors": [
            "Pengyu Qiu",
            "Xuhong Zhang",
            "Shouling Ji",
            "Changjiang Li",
            "Yuwen Pu",
            "Xing Yang",
            "Ting Wang"
        ],
        "comments": "this https URL",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Vertical federated learning (VFL) is an emerging paradigm that enables collaborators to build machine learning models together in a distributed fashion. In general, these parties have a group of users in common but own different features. Existing VFL frameworks use cryptographic techniques to provide data privacy and security guarantees, leading to a line of works studying computing efficiency and fast implementation. However, the security of VFL's model remains underexplored.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.AI",
            "cs.CR"
        ],
        "submitted_date": "1 Dec 2022",
        "last_revised_date": " "
    },
    "2212.00386": {
        "title": "Automated Coronary Arteries Labeling Via Geometric Deep Learning",
        "authors": [
            "Yadan Li",
            "Mohammad Ali Armin",
            "Simon Denman",
            "David Ahmedt-Aristizabal"
        ],
        "comments": " ",
        "subjects": "Image and Video Processing (eess.IV)",
        "abstract": "Automatic labelling of anatomical structures, such as coronary arteries, is critical for diagnosis, yet existing (non-deep learning) methods are limited by a reliance on prior topological knowledge of the expected tree-like structures. As the structure such vascular systems is often difficult to conceptualize, graph-based representations have become popular due to their ability to capture the geometric and topological properties of the morphology in an orientation-independent and abstract manner. However, graph-based learning for automated labeling of tree-like anatomical structures has received limited attention in the literature. The majority of prior studies have limitations in the entity graph construction, are dependent on topological structures, and have limited accuracy due to the anatomical variability between subjects. In this paper, we propose an intuitive graph representation method, well suited to use with 3D coordinate data obtained from angiography scans. We subsequently seek to analyze subject-specific graphs using geometric deep learning. The proposed models leverage expert annotated labels from 141 patients to learn representations of each coronary segment, while capturing the effects of anatomical variability within the training data. We investigate different variants of so-called message passing neural networks. Through extensive evaluations, our pipeline achieves a promising weighted F1-score of 0.805 for labeling coronary artery (13 classes) for a five-fold cross-validation. Considering the ability of graph models in dealing with irregular data, and their scalability for data segmentation, this work highlights the potential of such methods to provide quantitative evidence to support the decisions of medical experts.\n    ",
        "primary_category": "eess.IV",
        "categories": [
            "cs.CV",
            "q-bio.TO"
        ],
        "submitted_date": "1 Dec 2022",
        "last_revised_date": " "
    },
    "2212.03827": {
        "title": "Discovering Latent Knowledge in Language Models Without Supervision",
        "authors": [
            "Collin Burns",
            "Haotian Ye",
            "Dan Klein",
            "Jacob Steinhardt"
        ],
        "comments": "ICLR 2023",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "Existing techniques for training language models can be misaligned with the truth: if we train models with imitation learning, they may reproduce errors that humans make; if we train them to generate text that humans rate highly, they may output errors that human evaluators can't detect. We propose circumventing this issue by directly finding latent knowledge inside the internal activations of a language model in a purely unsupervised way. Specifically, we introduce a method for accurately answering yes-no questions given only unlabeled model activations. It works by finding a direction in activation space that satisfies logical consistency properties, such as that a statement and its negation have opposite truth values. We show that despite using no supervision and no model outputs, our method can recover diverse knowledge represented in large language models: across 6 models and 10 question-answering datasets, it outperforms zero-shot accuracy by 4\\% on average. We also find that it cuts prompt sensitivity in half and continues to maintain high accuracy even when models are prompted to generate incorrect answers. Our results provide an initial step toward discovering what language models know, distinct from what they say, even when we don't have access to explicit ground truth labels.\n    ",
        "primary_category": "cs.CL",
        "categories": [
            "cs.AI",
            "cs.LG"
        ],
        "submitted_date": "7 Dec 2022",
        "last_revised_date": " "
    },
    "2212.06776": {
        "title": "Unfolding Local Growth Rate Estimates for (Almost) Perfect Adversarial Detection",
        "authors": [
            "Peter Lorenz",
            "Margret Keuper",
            "Janis Keuper"
        ],
        "comments": "accepted at VISAPP23",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Convolutional neural networks (CNN) define the state-of-the-art solution on many perceptual tasks. However, current CNN approaches largely remain vulnerable against adversarial perturbations of the input that have been crafted specifically to fool the system while being quasi-imperceptible to the human eye. In recent years, various approaches have been proposed to defend CNNs against such attacks, for example by model hardening or by adding explicit defence mechanisms. Thereby, a small \"detector\" is included in the network and trained on the binary classification task of distinguishing genuine data from data containing adversarial perturbations. In this work, we propose a simple and light-weight detector, which leverages recent findings on the relation between networks' local intrinsic dimensionality (LID) and adversarial attacks. Based on a re-interpretation of the LID measure and several simple adaptations, we surpass the state-of-the-art on adversarial detection by a significant margin and reach almost perfect results in terms of F1-score for several networks and datasets. Sources available at: this https URL\n",
        "primary_category": "cs.CV",
        "categories": [
            "cs.CR"
        ],
        "submitted_date": "13 Dec 2022",
        "last_revised_date": " "
    },
    "2212.07350": {
        "title": "A Fast Geometric Regularizer to Mitigate Event Collapse in the Contrast Maximization Framework",
        "authors": [
            "Shintaro Shiba",
            "Yoshimitsu Aoki",
            "Guillermo Gallego"
        ],
        "comments": "10 pages, 7 figures, 4 tables. Project page: this https URL collapse",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Event cameras are emerging vision sensors and their advantages are suitable for various applications such as autonomous robots. Contrast maximization (CMax), which provides state-of-the-art accuracy on motion estimation using events, may suffer from an overfitting problem called event collapse. Prior works are computationally expensive or cannot alleviate the overfitting, which undermines the benefits of the CMax framework. We propose a novel, computationally efficient regularizer based on geometric principles to mitigate event collapse. The experiments show that the proposed regularizer achieves state-of-the-art accuracy results, while its reduced computational complexity makes it two to four times faster than previous approaches. To the best of our knowledge, our regularizer is the only effective solution for event collapse without trading off runtime. We hope our work opens the door for future applications that unlocks the advantages of event cameras.\n    ",
        "primary_category": "cs.CV",
        "categories": [
            "cs.RO",
            "math.DG"
        ],
        "submitted_date": "14 Dec 2022",
        "last_revised_date": " "
    },
    "2212.08904": {
        "title": "Hyperbolic Hierarchical Contrastive Hashing",
        "authors": [
            "Rukai Wei",
            "Yu Liu",
            "Jingkuan Song",
            "Yanzhao Xie",
            "Ke Zhou"
        ],
        "comments": "12 pages, 8 figures",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Hierarchical semantic structures, naturally existing in real-world datasets, can assist in capturing the latent distribution of data to learn robust hash codes for retrieval systems. Although hierarchical semantic structures can be simply expressed by integrating semantically relevant data into a high-level taxon with coarser-grained semantics, the construction, embedding, and exploitation of the structures remain tricky for unsupervised hash learning. To tackle these problems, we propose a novel unsupervised hashing method named Hyperbolic Hierarchical Contrastive Hashing (HHCH). We propose to embed continuous hash codes into hyperbolic space for accurate semantic expression since embedding hierarchies in hyperbolic space generates less distortion than in hyper-sphere space and Euclidean space. In addition, we extend the K-Means algorithm to hyperbolic space and perform the proposed hierarchical hyperbolic K-Means algorithm to construct hierarchical semantic structures adaptively. To exploit the hierarchical semantic structures in hyperbolic space, we designed the hierarchical contrastive learning algorithm, including hierarchical instance-wise and hierarchical prototype-wise contrastive learning. Extensive experiments on four benchmark datasets demonstrate that the proposed method outperforms the state-of-the-art unsupervised hashing methods. Codes will be released.\n    ",
        "primary_category": "cs.CV",
        "categories": [],
        "submitted_date": "17 Dec 2022",
        "last_revised_date": " "
    },
    "2212.09171": {
        "title": "Rainproof: An Umbrella To Shield Text Generators From Out-Of-Distribution Data",
        "authors": [
            "Maxime Darrin",
            "Pablo Piantanida",
            "Pierre Colombo"
        ],
        "comments": " ",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "Implementing effective control mechanisms to ensure the proper functioning and security of deployed NLP models, from translation to chatbots, is essential. A key ingredient to ensure safe system behaviour is Out-Of-Distribution (OOD) detection, which aims to detect whether an input sample is statistically far from the training distribution. Although OOD detection is a widely covered topic in classification tasks, most methods rely on hidden features output by the encoder. In this work, we focus on leveraging soft-probabilities in a black-box framework, i.e. we can access the soft-predictions but not the internal states of the model. Our contributions include: (i) RAINPROOF a Relative informAItioN Projection OOD detection framework; and (ii) a more operational evaluation setting for OOD detection. Surprisingly, we find that OOD detection is not necessarily aligned with task-specific measures. The OOD detector may filter out samples well processed by the model and keep samples that are not, leading to weaker performance. Our results show that RAINPROOF provides OOD detection methods more aligned with task-specific performance metrics than traditional OOD detectors.\n    ",
        "primary_category": "cs.CL",
        "categories": [],
        "submitted_date": "18 Dec 2022",
        "last_revised_date": " "
    },
    "2212.10474": {
        "title": "ByGPT5: End-to-End Style-conditioned Poetry Generation with Token-free Language Models",
        "authors": [
            "Jonas Belouadi",
            "Steffen Eger"
        ],
        "comments": "Accepted at ACL 2023 (main track)",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "State-of-the-art poetry generation systems are often complex. They either consist of task-specific model pipelines, incorporate prior knowledge in the form of manually created constraints, or both. In contrast, end-to-end models would not suffer from the overhead of having to model prior knowledge and could learn the nuances of poetry from data alone, reducing the degree of human supervision required. In this work, we investigate end-to-end poetry generation conditioned on styles such as rhyme, meter, and alliteration. We identify and address lack of training data and mismatching tokenization algorithms as possible limitations of past attempts. In particular, we successfully pre-train ByGPT5, a new token-free decoder-only language model, and fine-tune it on a large custom corpus of English and German quatrains annotated with our styles. We show that ByGPT5 outperforms other models such as mT5, ByT5, GPT-2 and ChatGPT, while also being more parameter efficient and performing favorably compared to humans. In addition, we analyze its runtime performance and demonstrate that it is not prone to memorization. We make our code, models, and datasets publicly available.\n    ",
        "primary_category": "cs.CL",
        "categories": [],
        "submitted_date": "20 Dec 2022",
        "last_revised_date": " "
    },
    "2212.10529": {
        "title": "Evaluating Psychological Safety of Large Language Models",
        "authors": [
            "Xingxuan Li",
            "Yutong Li",
            "Lin Qiu",
            "Shafiq Joty",
            "Lidong Bing"
        ],
        "comments": "Preprint. Under review",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "In this work, we designed unbiased prompts to systematically evaluate the psychological safety of large language models (LLMs). First, we tested five different LLMs by using two personality tests: Short Dark Triad (SD-3) and Big Five Inventory (BFI). All models scored higher than the human average on SD-3, suggesting a relatively darker personality pattern. Despite being instruction fine-tuned with safety metrics to reduce toxicity, InstructGPT, GPT-3.5, and GPT-4 still showed dark personality patterns; these models scored higher than self-supervised GPT-3 on the Machiavellianism and narcissism traits on SD-3. Then, we evaluated the LLMs in the GPT series by using well-being tests to study the impact of fine-tuning with more training data. We observed a continuous increase in the well-being scores of GPT models. Following these observations, we showed that fine-tuning Llama-2-chat-7B with responses from BFI using direct preference optimization could effectively reduce the psychological toxicity of the model. Based on the findings, we recommended the application of systematic and comprehensive psychological metrics to further evaluate and improve the safety of LLMs.\n    ",
        "primary_category": "cs.CL",
        "categories": [
            "cs.AI",
            "cs.CY"
        ],
        "submitted_date": "20 Dec 2022",
        "last_revised_date": " "
    },
    "2212.11756": {
        "title": "DSS-o-SAGE: Direction-Scan Sounding-Oriented SAGE Algorithm for Channel Parameter Estimation in mmWave and THz Bands",
        "authors": [
            "Yuanbo Li",
            "Chong Han",
            "Yi Chen",
            "Ziming Yu",
            "Xuefeng Yin"
        ],
        "comments": "15 pages, 10 figures, 3 tables",
        "subjects": "Information Theory (cs.IT)",
        "abstract": "Investigation of millimeter (mmWave) and Terahertz (THz) channels relies on channel measurements and estimation of multi-path component (MPC) parameters. As a common measurement technique in the mmWave and THz bands, direction-scan sounding (DSS) resolves angular information and increases the measurable distance. Through mechanical rotation, the DSS creates a virtual multi-antenna sounding system, which however incurs signal phase instability and large data sizes, which are not fully considered in existing estimation algorithms and thus make them ineffective. To tackle this research gap, in this paper, a DSS-oriented space-alternating generalized expectation-maximization (DSS-o-SAGE) algorithm is proposed for channel parameter estimation in mmWave and THz bands. To appropriately capture the measured data in mmWave and THz DSS, the phase instability is modeled by the scanning-direction-dependent signal phases. Furthermore, based on the signal model, the DSS-o-SAGE algorithm is developed, which not only addresses the problems brought by phase instability, but also achieves ultra-low computational complexity by exploiting the narrow antenna beam property of DSS. Simulations in synthetic channels are conducted to demonstrate the efficacy of the proposed algorithm and explore the applicable region of the far-field approximation in DSS-o-SAGE. Last but not least, the proposed DSS-o-SAGE algorithm is applied in real measurements in an indoor corridor scenario at 300~GHz. Compared with results using the baseline noise-elimination method, the channel is characterized more correctly and reasonably based on the DSS-o-SAGE.\n    ",
        "primary_category": "cs.IT",
        "categories": [
            "eess.SP"
        ],
        "submitted_date": "28 Nov 2022",
        "last_revised_date": " "
    },
    "2212.12218": {
        "title": "Fast Event-based Optical Flow Estimation by Triplet Matching",
        "authors": [
            "Shintaro Shiba",
            "Yoshimitsu Aoki",
            "Guillermo Gallego"
        ],
        "comments": "5 pages, 4 figures, 2 tables",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Event cameras are novel bio-inspired sensors that offer advantages over traditional cameras (low latency, high dynamic range, low power, etc.). Optical flow estimation methods that work on packets of events trade off speed for accuracy, while event-by-event (incremental) methods have strong assumptions and have not been tested on common benchmarks that quantify progress in the field. Towards applications on resource-constrained devices, it is important to develop optical flow algorithms that are fast, light-weight and accurate. This work leverages insights from neuroscience, and proposes a novel optical flow estimation scheme based on triplet matching. The experiments on publicly available benchmarks demonstrate its capability to handle complex scenes with comparable results as prior packet-based algorithms. In addition, the proposed method achieves the fastest execution time (> 10 kHz) on standard CPUs as it requires only three events in estimation. We hope that our research opens the door to real-time, incremental motion estimation methods and applications in real-world scenarios.\n    ",
        "primary_category": "cs.CV",
        "categories": [
            "cs.RO",
            "eess.SP"
        ],
        "submitted_date": "23 Dec 2022",
        "last_revised_date": " "
    },
    "2212.13619": {
        "title": "Almost-Bayesian Quadratic Persuasion (Extended Version)",
        "authors": [
            "Olivier Massicot",
            "C\u00e9dric Langbort"
        ],
        "comments": "This version extends the article submitted to the IEEE Transactions on Automatic Control",
        "subjects": "Computer Science and Game Theory (cs.GT)",
        "abstract": "In this article, we relax the Bayesianity assumption in the now-traditional model of Bayesian Persuasion introduced by Kamenica & Gentzkow. Unlike preexisting approaches -- which have tackled the possibility of the receiver (Bob) being non-Bayesian by considering that his thought process is not Bayesian yet known to the sender (Alice), possibly up to a parameter -- we let Alice merely assume that Bob behaves 'almost like' a Bayesian agent, in some sense, without resorting to any specific model.\nUnder this assumption, we study Alice's strategy when both utilities are quadratic and the prior is isotropic. We show that, contrary to the Bayesian case, Alice's optimal response may not be linear anymore. This fact is unfortunate as linear policies remain the only ones for which the induced belief distribution is known. What is more, evaluating linear policies proves difficult except in particular cases, let alone finding an optimal one. Nonetheless, we derive bounds that prove linear policies are near-optimal and allow Alice to compute a near-optimal linear policy numerically. With this solution in hand, we show that Alice shares less information with Bob as he departs more from Bayesianity, much to his detriment.\n    ",
        "primary_category": "cs.GT",
        "categories": [],
        "submitted_date": "27 Dec 2022",
        "last_revised_date": " "
    },
    "2301.00707": {
        "title": "RIS-Assisted Receive Quadrature Spatial Modulation with Low-Complexity Greedy Detection",
        "authors": [
            "Mohamad H. Dinan",
            "Marco Di Renzo",
            "Mark F. Flanagan"
        ],
        "comments": "30 pages (single column), 6 figures, 1 table",
        "subjects": "Information Theory (cs.IT)",
        "abstract": "In this paper, we propose a novel reconfigurable intelligent surface (RIS)-assisted wireless communication scheme which uses the concept of spatial modulation, namely RIS-assisted receive quadrature spatial modulation (RIS-RQSM). In the proposed RIS-RQSM system, the information bits are conveyed via both the indices of the two selected receive antennas and the conventional in-phase/quadrature (IQ) modulation. We propose a novel methodology to adjust the phase shifts of the RIS elements in order to maximize the signal-to-noise ratio (SNR) and at the same time to construct two separate PAM symbols at the selected receive antennas, as the in-phase and quadrature components of the desired IQ symbol. An energy-based greedy detector (GD) is implemented at the receiver to efficiently detect the received signal with minimal channel state information (CSI) via the use of an appropriately designed one-tap pre-equalizer. We also derive a closed-form upper bound on the average bit error probability (ABEP) of the proposed RIS-RQSM system. Then, we formulate an optimization problem to minimize the ABEP in order to improve the performance of the system, which allows the GD to act as a near-optimal receiver. Extensive numerical results are provided to demonstrate the error rate performance of the system and to compare with that of a prominent benchmark scheme. The results verify the remarkable superiority of the proposed RIS-RQSM system over the benchmark scheme.\n    ",
        "primary_category": "cs.IT",
        "categories": [
            "eess.SP"
        ],
        "submitted_date": "2 Jan 2023",
        "last_revised_date": " "
    },
    "2301.06662": {
        "title": "Graph Learning Across Data Silos",
        "authors": [
            "Xiang Zhang",
            "Qiao Wang"
        ],
        "comments": "13 pages",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "We consider the problem of inferring graph topology from smooth graph signals in a novel but practical scenario where data are located in distributed clients and prohibited from leaving local clients due to factors such as privacy concerns. The main difficulty in this task is how to exploit the potentially heterogeneous data of all clients under data silos. To this end, we first propose an auto-weighted multiple graph learning model to jointly learn a personalized graph for each local client and a single consensus graph for all clients. The personalized graphs match local data distributions, thereby mitigating data heterogeneity, while the consensus graph captures the global information. Moreover, the model can automatically assign appropriate contribution weights to local graphs based on their similarity to the consensus graph. We next devise a tailored algorithm to solve the induced problem, where all raw data are processed locally without leaving clients. Theoretically, we establish a provable estimation error bound and convergence analysis for the proposed model and algorithm. Finally, extensive experiments on synthetic and real data are carried out, and the results illustrate that our approach can learn graphs effectively in the target scenario.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.CR",
            "eess.SP"
        ],
        "submitted_date": "17 Jan 2023",
        "last_revised_date": " "
    },
    "2301.09308": {
        "title": "On the Expressive Power of Geometric Graph Neural Networks",
        "authors": [
            "Chaitanya K. Joshi",
            "Cristian Bodnar",
            "Simon V. Mathis",
            "Taco Cohen",
            "Pietro Li\u00f2"
        ],
        "comments": "ICML 2023",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "The expressive power of Graph Neural Networks (GNNs) has been studied extensively through the Weisfeiler-Leman (WL) graph isomorphism test. However, standard GNNs and the WL framework are inapplicable for geometric graphs embedded in Euclidean space, such as biomolecules, materials, and other physical systems. In this work, we propose a geometric version of the WL test (GWL) for discriminating geometric graphs while respecting the underlying physical symmetries: permutations, rotation, reflection, and translation. We use GWL to characterise the expressive power of geometric GNNs that are invariant or equivariant to physical symmetries in terms of distinguishing geometric graphs. GWL unpacks how key design choices influence geometric GNN expressivity: (1) Invariant layers have limited expressivity as they cannot distinguish one-hop identical geometric graphs; (2) Equivariant layers distinguish a larger class of graphs by propagating geometric information beyond local neighbourhoods; (3) Higher order tensors and scalarisation enable maximally powerful geometric GNNs; and (4) GWL's discrimination-based perspective is equivalent to universal approximation. Synthetic experiments supplementing our results are available at \\url{this https URL}\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "math.GR",
            "stat.ML"
        ],
        "submitted_date": "23 Jan 2023",
        "last_revised_date": " "
    },
    "2301.10812": {
        "title": "Multisets and Distributions",
        "authors": [
            "Dexter Kozen",
            "Alexandra Silva"
        ],
        "comments": "21 pages",
        "subjects": "Logic in Computer Science (cs.LO)",
        "abstract": "We give a lightweight alternative construction of Jacobs's distributive law for multisets and distributions that does not involve any combinatorics. We first give a distributive law for lists and distributions, then apply a general theorem on 2-categories that allows properties of lists to be transferred automatically to multisets. The theorem states that equations between 2-cells are preserved by epic 2-natural transformations. In our application, the appropriate epic 2-natural transformation is defined in terms of the Parikh map, familiar from formal language theory, that takes a list to its multiset of elements.\n    ",
        "primary_category": "cs.LO",
        "categories": [
            "cs.PL"
        ],
        "submitted_date": "25 Jan 2023",
        "last_revised_date": " "
    },
    "2301.11009": {
        "title": "Graph-based Recommendation for Sparse and Heterogeneous User Interactions",
        "authors": [
            "Simone Borg Bruun",
            "Kacper Kenji Lesniak",
            "Mirko Biasini",
            "Vittorio Carmignani",
            "Panagiotis Filianos",
            "Christina Lioma",
            "Maria Maistro"
        ],
        "comments": " ",
        "subjects": "Information Retrieval (cs.IR)",
        "abstract": "Recommender system research has oftentimes focused on approaches that operate on large-scale datasets containing millions of user interactions. However, many small businesses struggle to apply state-of-the-art models due to their very limited availability of data. We propose a graph-based recommender model which utilizes heterogeneous interactions between users and content of different types and is able to operate well on small-scale datasets. A genetic algorithm is used to find optimal weights that represent the strength of the relationship between users and content. Experiments on two real-world datasets (which we make available to the research community) show promising results (up to 7% improvement), in comparison with other state-of-the-art methods for low-data environments. These improvements are statistically significant and consistent across different data samples.\n    ",
        "primary_category": "cs.IR",
        "categories": [],
        "submitted_date": "26 Jan 2023",
        "last_revised_date": " "
    },
    "2301.11259": {
        "title": "Domain-Agnostic Molecular Generation with Chemical Feedback",
        "authors": [
            "Yin Fang",
            "Ningyu Zhang",
            "Zhuo Chen",
            "Lingbing Guo",
            "Xiaohui Fan",
            "Huajun Chen"
        ],
        "comments": "ICLR 2024",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "The generation of molecules with desired properties has become increasingly popular, revolutionizing the way scientists design molecular structures and providing valuable support for chemical and drug design. However, despite the potential of language models in molecule generation, they face challenges such as generating syntactically or chemically flawed molecules, having narrow domain focus, and struggling to create diverse and feasible molecules due to limited annotated data or external molecular databases. To tackle these challenges, we introduce MolGen, a pre-trained molecular language model tailored specifically for molecule generation. Through the reconstruction of over 100 million molecular SELFIES, MolGen internalizes structural and grammatical insights. This is further enhanced by domain-agnostic molecular prefix tuning, fostering robust knowledge transfer across diverse domains. Importantly, our chemical feedback paradigm steers the model away from molecular hallucinations, ensuring alignment between the model's estimated probabilities and real-world chemical preferences. Extensive experiments on well-known benchmarks underscore MolGen's optimization capabilities in properties such as penalized logP, QED, and molecular docking. Additional analyses confirm its proficiency in accurately capturing molecule distributions, discerning intricate structural patterns, and efficiently exploring the chemical space. Code is available at this https URL.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.AI",
            "cs.CE",
            "cs.CL"
        ],
        "submitted_date": "26 Jan 2023",
        "last_revised_date": " "
    },
    "2301.11862": {
        "title": "Neural Additive Models for Location Scale and Shape: A Framework for Interpretable Neural Regression Beyond the Mean",
        "authors": [
            "Anton Thielmann",
            "Ren\u00e9-Marcel Kruse",
            "Thomas Kneib",
            "Benjamin S\u00e4fken"
        ],
        "comments": "Accepted at the 27th International Conference on Artificial Intelligence and Statistics (AISTATS) 2024",
        "subjects": "Machine Learning (stat.ML)",
        "abstract": "Deep neural networks (DNNs) have proven to be highly effective in a variety of tasks, making them the go-to method for problems requiring high-level predictive power. Despite this success, the inner workings of DNNs are often not transparent, making them difficult to interpret or understand. This lack of interpretability has led to increased research on inherently interpretable neural networks in recent years. Models such as Neural Additive Models (NAMs) achieve visual interpretability through the combination of classical statistical methods with DNNs. However, these approaches only concentrate on mean response predictions, leaving out other properties of the response distribution of the underlying data. We propose Neural Additive Models for Location Scale and Shape (NAMLSS), a modelling framework that combines the predictive power of classical deep learning models with the inherent advantages of distributional regression while maintaining the interpretability of additive models. The code is available at the following link: this https URL\n",
        "primary_category": "stat.ML",
        "categories": [
            "cs.LG"
        ],
        "submitted_date": "27 Jan 2023",
        "last_revised_date": " "
    },
    "2301.12318": {
        "title": "Gradient Shaping: Enhancing Backdoor Attack Against Reverse Engineering",
        "authors": [
            "Rui Zhu",
            "Di Tang",
            "Siyuan Tang",
            "Guanhong Tao",
            "Shiqing Ma",
            "Xiaofeng Wang",
            "Haixu Tang"
        ],
        "comments": " ",
        "subjects": "Cryptography and Security (cs.CR)",
        "abstract": "Most existing methods to detect backdoored machine learning (ML) models take one of the two approaches: trigger inversion (aka. reverse engineer) and weight analysis (aka. model diagnosis). In particular, the gradient-based trigger inversion is considered to be among the most effective backdoor detection techniques, as evidenced by the TrojAI competition, Trojan Detection Challenge and backdoorBench. However, little has been done to understand why this technique works so well and, more importantly, whether it raises the bar to the backdoor attack. In this paper, we report the first attempt to answer this question by analyzing the change rate of the backdoored model around its trigger-carrying inputs. Our study shows that existing attacks tend to inject the backdoor characterized by a low change rate around trigger-carrying inputs, which are easy to capture by gradient-based trigger inversion. In the meantime, we found that the low change rate is not necessary for a backdoor attack to succeed: we design a new attack enhancement called \\textit{Gradient Shaping} (GRASP), which follows the opposite direction of adversarial training to reduce the change rate of a backdoored model with regard to the trigger, without undermining its backdoor effect. Also, we provide a theoretic analysis to explain the effectiveness of this new technique and the fundamental weakness of gradient-based trigger inversion. Finally, we perform both theoretical and experimental analysis, showing that the GRASP enhancement does not reduce the effectiveness of the stealthy attacks against the backdoor detection methods based on weight analysis, as well as other backdoor mitigation methods without using detection.\n    ",
        "primary_category": "cs.CR",
        "categories": [
            "cs.LG"
        ],
        "submitted_date": "29 Jan 2023",
        "last_revised_date": " "
    },
    "2301.12357": {
        "title": "SPEED: Experimental Design for Policy Evaluation in Linear Heteroscedastic Bandits",
        "authors": [
            "Subhojyoti Mukherjee",
            "Qiaomin Xie",
            "Josiah Hanna",
            "Robert Nowak"
        ],
        "comments": " ",
        "subjects": "Machine Learning (stat.ML)",
        "abstract": "In this paper, we study the problem of optimal data collection for policy evaluation in linear bandits. In policy evaluation, we are given a target policy and asked to estimate the expected reward it will obtain when executed in a multi-armed bandit environment. Our work is the first work that focuses on such optimal data collection strategy for policy evaluation involving heteroscedastic reward noise in the linear bandit setting. We first formulate an optimal design for weighted least squares estimates in the heteroscedastic linear bandit setting that reduces the MSE of the value of the target policy. We then use this formulation to derive the optimal allocation of samples per action during data collection. We then introduce a novel algorithm SPEED (Structured Policy Evaluation Experimental Design) that tracks the optimal design and derive its regret with respect to the optimal design. Finally, we empirically validate that SPEED leads to policy evaluation with mean squared error comparable to the oracle strategy and significantly lower than simply running the target policy.\n    ",
        "primary_category": "stat.ML",
        "categories": [
            "cs.LG"
        ],
        "submitted_date": "29 Jan 2023",
        "last_revised_date": " "
    },
    "2301.12584": {
        "title": "Fast Exact Leverage Score Sampling from Khatri-Rao Products with Applications to Tensor Decomposition",
        "authors": [
            "Vivek Bharadwaj",
            "Osman Asif Malik",
            "Riley Murray",
            "Laura Grigori",
            "Aydin Buluc",
            "James Demmel"
        ],
        "comments": "The 37th Conference on Neural Information Processing Systems (Neurips'23). 28 pages, 10 figures, 6 tables",
        "subjects": "Numerical Analysis (math.NA)",
        "abstract": "We present a data structure to randomly sample rows from the Khatri-Rao product of several matrices according to the exact distribution of its leverage scores. Our proposed sampler draws each row in time logarithmic in the height of the Khatri-Rao product and quadratic in its column count, with persistent space overhead at most the size of the input matrices. As a result, it tractably draws samples even when the matrices forming the Khatri-Rao product have tens of millions of rows each. When used to sketch the linear least squares problems arising in CANDECOMP / PARAFAC tensor decomposition, our method achieves lower asymptotic complexity per solve than recent state-of-the-art methods. Experiments on billion-scale sparse tensors validate our claims, with our algorithm achieving higher accuracy than competing methods as the decomposition rank grows.\n    ",
        "primary_category": "math.NA",
        "categories": [],
        "submitted_date": "29 Jan 2023",
        "last_revised_date": " "
    },
    "2301.13755": {
        "title": "Retrosynthetic Planning with Dual Value Networks",
        "authors": [
            "Guoqing Liu",
            "Di Xue",
            "Shufang Xie",
            "Yingce Xia",
            "Austin Tripp",
            "Krzysztof Maziarz",
            "Marwin Segler",
            "Tao Qin",
            "Zongzhang Zhang",
            "Tie-Yan Liu"
        ],
        "comments": "Accepted to ICML 2023",
        "subjects": "Artificial Intelligence (cs.AI)",
        "abstract": "Retrosynthesis, which aims to find a route to synthesize a target molecule from commercially available starting materials, is a critical task in drug discovery and materials design. Recently, the combination of ML-based single-step reaction predictors with multi-step planners has led to promising results. However, the single-step predictors are mostly trained offline to optimize the single-step accuracy, without considering complete routes. Here, we leverage reinforcement learning (RL) to improve the single-step predictor, by using a tree-shaped MDP to optimize complete routes. Specifically, we propose a novel online training algorithm, called Planning with Dual Value Networks (PDVN), which alternates between the planning phase and updating phase. In PDVN, we construct two separate value networks to predict the synthesizability and cost of molecules, respectively. To maintain the single-step accuracy, we design a two-branch network structure for the single-step predictor. On the widely-used USPTO dataset, our PDVN algorithm improves the search success rate of existing multi-step planners (e.g., increasing the success rate from 85.79% to 98.95% for Retro*, and reducing the number of model calls by half while solving 99.47% molecules for RetroGraph). Additionally, PDVN helps find shorter synthesis routes (e.g., reducing the average route length from 5.76 to 4.83 for Retro*, and from 5.63 to 4.78 for RetroGraph). Our code is available at \\url{this https URL}.\n    ",
        "primary_category": "cs.AI",
        "categories": [
            "cs.LG"
        ],
        "submitted_date": "31 Jan 2023",
        "last_revised_date": " "
    },
    "2302.00389": {
        "title": "Multimodality Representation Learning: A Survey on Evolution, Pretraining and Its Applications",
        "authors": [
            "Muhammad Arslan Manzoor",
            "Sarah Albarri",
            "Ziting Xian",
            "Zaiqiao Meng",
            "Preslav Nakov",
            "Shangsong Liang"
        ],
        "comments": " ",
        "subjects": "Artificial Intelligence (cs.AI)",
        "abstract": "Multimodality Representation Learning, as a technique of learning to embed information from different modalities and their correlations, has achieved remarkable success on a variety of applications, such as Visual Question Answering (VQA), Natural Language for Visual Reasoning (NLVR), and Vision Language Retrieval (VLR). Among these applications, cross-modal interaction and complementary information from different modalities are crucial for advanced models to perform any multimodal task, e.g., understand, recognize, retrieve, or generate optimally. Researchers have proposed diverse methods to address these tasks. The different variants of transformer-based architectures performed extraordinarily on multiple modalities. This survey presents the comprehensive literature on the evolution and enhancement of deep learning multimodal architectures to deal with textual, visual and audio features for diverse cross-modal and modern multimodal tasks. This study summarizes the (i) recent task-specific deep learning methodologies, (ii) the pretraining types and multimodal pretraining objectives, (iii) from state-of-the-art pretrained multimodal approaches to unifying architectures, and (iv) multimodal task categories and possible future improvements that can be devised for better multimodal learning. Moreover, we prepare a dataset section for new researchers that covers most of the benchmarks for pretraining and finetuning. Finally, major challenges, gaps, and potential research topics are explored. A constantly-updated paperlist related to our survey is maintained at this https URL.\n    ",
        "primary_category": "cs.AI",
        "categories": [],
        "submitted_date": "1 Feb 2023",
        "last_revised_date": " "
    },
    "2302.00556": {
        "title": "Correspondence-free online human motion retargeting",
        "authors": [
            "Rim Rekik",
            "Mathieu Marsot",
            "Anne-H\u00e9l\u00e8ne Olivier",
            "Jean-S\u00e9bastien Franco",
            "Stefanie Wuhrer"
        ],
        "comments": "Published in International Conference on 3D Vision (3DV), 2024",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "We present a data-driven framework for unsupervised human motion retargeting that animates a target subject with the motion of a source subject. Our method is correspondence-free, requiring neither spatial correspondences between the source and target shapes nor temporal correspondences between different frames of the source motion. This allows to animate a target shape with arbitrary sequences of humans in motion, possibly captured using 4D acquisition platforms or consumer devices. Our method unifies the advantages of two existing lines of work, namely skeletal motion retargeting, which leverages long-term temporal context, and surface-based retargeting, which preserves surface details, by combining a geometry-aware deformation model with a skeleton-aware motion transfer approach. This allows to take into account long-term temporal context while accounting for surface details. During inference, our method runs online, i.e. input can be processed in a serial way, and retargeting is performed in a single forward pass per frame. Experiments show that including long-term temporal context during training improves the method's accuracy for skeletal motion and detail preservation. Furthermore, our method generalizes to unobserved motions and body shapes. We demonstrate that our method achieves state-of-the-art results on two test datasets and that it can be used to animate human models with the output of a multi-view acquisition platform. Code is available at \\url{this https URL}.\n    ",
        "primary_category": "cs.CV",
        "categories": [],
        "submitted_date": "1 Feb 2023",
        "last_revised_date": " "
    },
    "2302.01203": {
        "title": "Online Learning under Budget and ROI Constraints via Weak Adaptivity",
        "authors": [
            "Matteo Castiglioni",
            "Andrea Celli",
            "Christian Kroer"
        ],
        "comments": " ",
        "subjects": "Computer Science and Game Theory (cs.GT)",
        "abstract": "We study online learning problems in which a decision maker has to make a sequence of costly decisions, with the goal of maximizing their expected reward while adhering to budget and return-on-investment (ROI) constraints. Existing primal-dual algorithms designed for constrained online learning problems under adversarial inputs rely on two fundamental assumptions. First, the decision maker must know beforehand the value of parameters related to the degree of strict feasibility of the problem (i.e. Slater parameters). Second, a strictly feasible solution to the offline optimization problem must exist at each round. Both requirements are unrealistic for practical applications such as bidding in online ad auctions. In this paper, we show how such assumptions can be circumvented by endowing standard primal-dual templates with weakly adaptive regret minimizers. This results in a ``dual-balancing'' framework which ensures that dual variables stay sufficiently small, even in the absence of knowledge about Slater's parameter. We prove the first best-of-both-worlds no-regret guarantees which hold in absence of the two aforementioned assumptions, under stochastic and adversarial inputs. Finally, we show how to instantiate the framework to optimally bid in various mechanisms of practical relevance, such as first- and second-price auctions.\n    ",
        "primary_category": "cs.GT",
        "categories": [
            "cs.LG"
        ],
        "submitted_date": "2 Feb 2023",
        "last_revised_date": " "
    },
    "2302.01306": {
        "title": "More results on the $z$-chromatic number of graphs",
        "authors": [
            "Abbas Khaleghi",
            "Manouchehr Zaker"
        ],
        "comments": "Submitted To Disc. Appl. Math. on September 8, 2022",
        "subjects": "Combinatorics (math.CO)",
        "abstract": "By a $z$-coloring of a graph $G$ we mean any proper vertex coloring consisting of the color classes $C_1, \\ldots, C_k$ such that $(i)$ for any two colors $i$ and $j$ with $1 \\leq i < j \\leq k$, any vertex of color $j$ is adjacent to a vertex of color $i$, $(ii)$ there exists a set $\\{u_1, \\ldots, u_k\\}$ of vertices of $G$ such that $u_j \\in C_j$ for any $j \\in \\{1, \\ldots, k\\}$ and $u_k$ is adjacent to $u_j$ for each $1 \\leq j \\leq k$ with $j \\not=k$, and $(iii)$ for each $i$ and $j$ with $i \\not= j$, the vertex $u_j$ has a neighbor in $C_i$. Denote by $z(G)$ the maximum number of colors used in any $z$-coloring of $G$. Denote the Grundy and {\\rm b}-chromatic number of $G$ by $\\Gamma(G)$ and ${\\rm b}(G)$, respectively. The $z$-coloring is an improvement over both the Grundy and b-coloring of graphs. We prove that $z(G)$ is much better than $\\min\\{\\Gamma(G), {\\rm b}(G)\\}$ for infinitely many graphs $G$ by obtaining an infinite sequence $\\{G_n\\}_{n=3}^{\\infty}$ of graphs such that $z(G_n)=n$ but $\\Gamma(G_n)={\\rm b}(G_n)=2n-1$ for each $n\\geq 3$. We show that acyclic graphs are $z$-monotonic and $z$-continuous. Then it is proved that to decide whether $z(G)=\\Delta(G)+1$ is $NP$-complete even for bipartite graphs $G$. We finally prove that to recognize graphs $G$ satisfying $z(G)=\\chi(G)$ is $coNP$-complete, improving a previous result for the Grundy number.\n    ",
        "primary_category": "math.CO",
        "categories": [
            "cs.DM"
        ],
        "submitted_date": "2 Feb 2023",
        "last_revised_date": " "
    },
    "2302.02237": {
        "title": "Conformalized Semi-supervised Random Forest for Classification and Abnormality Detection",
        "authors": [
            "Yujin Han",
            "Mingwenchan Xu",
            "Leying Guan"
        ],
        "comments": " ",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "The Random Forests classifier, a widely utilized off-the-shelf classification tool, assumes training and test samples come from the same distribution as other standard classifiers. However, in safety-critical scenarios like medical diagnosis and network attack detection, discrepancies between the training and test sets, including the potential presence of novel outlier samples not appearing during training, can pose significant challenges. To address this problem, we introduce the Conformalized Semi-Supervised Random Forest (CSForest), which couples the conformalization technique Jackknife+aB with semi-supervised tree ensembles to construct a set-valued prediction $C(x)$. Instead of optimizing over the training distribution, CSForest employs unlabeled test samples to enhance accuracy and flag unseen outliers by generating an empty set. Theoretically, we establish CSForest to cover true labels for previously observed inlier classes under arbitrarily label-shift in the test data. We compare CSForest with state-of-the-art methods using synthetic examples and various real-world datasets, under different types of distribution changes in the test domain. Our results highlight CSForest's effective prediction of inliers and its ability to detect outlier samples unique to the test data. In addition, CSForest shows persistently good performance as the sizes of the training and test sets vary. Codes of CSForest are available at this https URL.\n    ",
        "primary_category": "cs.LG",
        "categories": [],
        "submitted_date": "4 Feb 2023",
        "last_revised_date": " "
    },
    "2302.04831": {
        "title": "Cooperative Open-ended Learning Framework for Zero-shot Coordination",
        "authors": [
            "Yang Li",
            "Shao Zhang",
            "Jichen Sun",
            "Yali Du",
            "Ying Wen",
            "Xinbing Wang",
            "Wei Pan"
        ],
        "comments": "15 pages with 9 pages main body",
        "subjects": "Artificial Intelligence (cs.AI)",
        "abstract": "Zero-shot coordination in cooperative artificial intelligence (AI) remains a significant challenge, which means effectively coordinating with a wide range of unseen partners. Previous algorithms have attempted to address this challenge by optimizing fixed objectives within a population to improve strategy or behaviour diversity. However, these approaches can result in a loss of learning and an inability to cooperate with certain strategies within the population, known as cooperative incompatibility. To address this issue, we propose the Cooperative Open-ended LEarning (COLE) framework, which constructs open-ended objectives in cooperative games with two players from the perspective of graph theory to assess and identify the cooperative ability of each strategy. We further specify the framework and propose a practical algorithm that leverages knowledge from game theory and graph theory. Furthermore, an analysis of the learning process of the algorithm shows that it can efficiently overcome cooperative incompatibility. The experimental results in the Overcooked game environment demonstrate that our method outperforms current state-of-the-art methods when coordinating with different-level partners. Our demo is available at this https URL.\n    ",
        "primary_category": "cs.AI",
        "categories": [
            "cs.LG"
        ],
        "submitted_date": "9 Feb 2023",
        "last_revised_date": " "
    },
    "2302.05797": {
        "title": "Global Convergence Rate of Deep Equilibrium Models with General Activations",
        "authors": [
            "Lan V. Truong"
        ],
        "comments": "32 pages, 4 figures",
        "subjects": "Machine Learning (stat.ML)",
        "abstract": "In a recent paper, Ling et al. investigated the over-parametrized Deep Equilibrium Model (DEQ) with ReLU activation. They proved that the gradient descent converges to a globally optimal solution for the quadratic loss function at a linear convergence rate. This paper shows that this fact still holds for DEQs with any generally bounded activation with bounded first and second derivatives. Since the new activation function is generally non-homogeneous, bounding the least eigenvalue of the Gram matrix of the equilibrium point is particularly challenging. To accomplish this task, we must create a novel population Gram matrix and develop a new form of dual activation with Hermite polynomial expansion.\n    ",
        "primary_category": "stat.ML",
        "categories": [
            "cs.LG"
        ],
        "submitted_date": "11 Feb 2023",
        "last_revised_date": " "
    },
    "2302.07457": {
        "title": "When Demonstrations Meet Generative World Models: A Maximum Likelihood Framework for Offline Inverse Reinforcement Learning",
        "authors": [
            "Siliang Zeng",
            "Chenliang Li",
            "Alfredo Garcia",
            "Mingyi Hong"
        ],
        "comments": " ",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Offline inverse reinforcement learning (Offline IRL) aims to recover the structure of rewards and environment dynamics that underlie observed actions in a fixed, finite set of demonstrations from an expert agent. Accurate models of expertise in executing a task has applications in safety-sensitive applications such as clinical decision making and autonomous driving. However, the structure of an expert's preferences implicit in observed actions is closely linked to the expert's model of the environment dynamics (i.e. the ``world'' model). Thus, inaccurate models of the world obtained from finite data with limited coverage could compound inaccuracy in estimated rewards. To address this issue, we propose a bi-level optimization formulation of the estimation task wherein the upper level is likelihood maximization based upon a conservative model of the expert's policy (lower level). The policy model is conservative in that it maximizes reward subject to a penalty that is increasing in the uncertainty of the estimated model of the world. We propose a new algorithmic framework to solve the bi-level optimization problem formulation and provide statistical and computational guarantees of performance for the associated optimal reward estimator. Finally, we demonstrate that the proposed algorithm outperforms the state-of-the-art offline IRL and imitation learning benchmarks by a large margin, over the continuous control tasks in MuJoCo and different datasets in the D4RL benchmark.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "15 Feb 2023",
        "last_revised_date": " "
    },
    "2302.09597": {
        "title": "Solving Differential-Algebraic Equations in Power System Dynamic Analysis with Quantum Computing",
        "authors": [
            "Huynh Trung Thanh Tran",
            "Hieu T.Nguyen",
            "Long T. Vu",
            "Samuel T. Ojetola"
        ],
        "comments": "This version was uploaded as an incorrect replacement, and was intended as a replacement of arXiv:2306.01961. I need to withdraw this paper to upload it as a replacement of the correct paper",
        "subjects": "Systems and Control (eess.SY)",
        "abstract": "Power system dynamics are generally modeled by high dimensional nonlinear differential-algebraic equations (DAEs) given a large number of components forming the network. These DAEs' complexity can grow exponentially due to the increasing penetration of distributed energy resources, whereas their computation time becomes sensitive due to the increasing interconnection of the power grid with other energy systems. This paper demonstrates the use of quantum computing algorithms to solve DAEs for power system dynamic analysis. We leverage a symbolic programming framework to equivalently convert the power system's DAEs into ordinary differential equations (ODEs) using index reduction methods and then encode their data into qubits using amplitude encoding. The system nonlinearity is captured by Hamiltonian simulation with truncated Taylor expansion so that state variables can be updated by a quantum linear equation solver. Our results show that quantum computing can solve the power system's DAEs accurately with a computational complexity polynomial in the logarithm of the system dimension. We also illustrate the use of recent advanced tools in scientific machine learning for implementing complex computing concepts, i.e. Taylor expansion, DAEs/ODEs transformation, and quantum computing solver with abstract representation for power engineering applications.\n    ",
        "primary_category": "eess.SY",
        "categories": [],
        "submitted_date": "19 Feb 2023",
        "last_revised_date": " "
    },
    "2302.10970": {
        "title": "Differentiable Rendering with Reparameterized Volume Sampling",
        "authors": [
            "Nikita Morozov",
            "Denis Rakitin",
            "Oleg Desheulin",
            "Dmitry Vetrov",
            "Kirill Struminsky"
        ],
        "comments": "Accepted at AISTATS 2024. Short version of this paper appeared in ICLR 2023 Neural Fields workshop",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "In view synthesis, a neural radiance field approximates underlying density and radiance fields based on a sparse set of scene pictures. To generate a pixel of a novel view, it marches a ray through the pixel and computes a weighted sum of radiance emitted from a dense set of ray points. This rendering algorithm is fully differentiable and facilitates gradient-based optimization of the fields. However, in practice, only a tiny opaque portion of the ray contributes most of the radiance to the sum. We propose a simple end-to-end differentiable sampling algorithm based on inverse transform sampling. It generates samples according to the probability distribution induced by the density field and picks non-transparent points on the ray. We utilize the algorithm in two ways. First, we propose a novel rendering approach based on Monte Carlo estimates. This approach allows for evaluating and optimizing a neural radiance field with just a few radiance field calls per ray. Second, we use the sampling algorithm to modify the hierarchical scheme proposed in the original NeRF work. We show that our modification improves reconstruction quality of hierarchical models, at the same time simplifying the training procedure by removing the need for auxiliary proposal network losses.\n    ",
        "primary_category": "cs.CV",
        "categories": [],
        "submitted_date": "21 Feb 2023",
        "last_revised_date": " "
    },
    "2302.11351": {
        "title": "Abrupt and spontaneous strategy switches emerge in simple regularised neural networks",
        "authors": [
            "Anika T. L\u00f6we",
            "L\u00e9o Touzo",
            "Paul S. Muhle-Karbe",
            "Andrew M. Saxe",
            "Christopher Summerfield",
            "Nicolas W. Schuck"
        ],
        "comments": "17 pages, 5 figures",
        "subjects": "Artificial Intelligence (cs.AI)",
        "abstract": "Humans sometimes have an insight that leads to a sudden and drastic performance improvement on the task they are working on. Sudden strategy adaptations are often linked to insights, considered to be a unique aspect of human cognition tied to complex processes such as creativity or meta-cognitive reasoning. Here, we take a learning perspective and ask whether insight-like behaviour can occur in simple artificial neural networks, even when the models only learn to form input-output associations through gradual gradient descent. We compared learning dynamics in humans and regularised neural networks in a perceptual decision task that included a hidden regularity to solve the task more efficiently. Our results show that only some humans discover this regularity, whose behaviour was marked by a sudden and abrupt strategy switch that reflects an aha-moment. Notably, we find that simple neural networks with a gradual learning rule and a constant learning rate closely mimicked behavioural characteristics of human insight-like switches, exhibiting delay of insight, suddenness and selective occurrence in only some networks. Analyses of network architectures and learning dynamics revealed that insight-like behaviour crucially depended on a regularised gating mechanism and noise added to gradient updates, which allowed the networks to accumulate \"silent knowledge\" that is initially suppressed by regularised (attentional) gating. This suggests that insight-like behaviour can arise naturally from gradual learning in simple neural networks, where it reflects the combined influences of noise, gating and regularisation.\n    ",
        "primary_category": "cs.AI",
        "categories": [
            "q-bio.NC"
        ],
        "submitted_date": "22 Feb 2023",
        "last_revised_date": " "
    },
    "2302.11517": {
        "title": "A Global and Patch-wise Contrastive Loss for Accurate Automated Exudate Detection",
        "authors": [
            "Wei Tang",
            "Kangning Cui",
            "Raymond H. Chan"
        ],
        "comments": "8 pages, 3 figures, 2 tables. To appear in ISBI 2024",
        "subjects": "Image and Video Processing (eess.IV)",
        "abstract": "Diabetic retinopathy (DR) is a leading global cause of blindness. Early detection of hard exudates plays a crucial role in identifying DR, which aids in treating diabetes and preventing vision loss. However, the unique characteristics of hard exudates, ranging from their inconsistent shapes to indistinct boundaries, pose significant challenges to existing segmentation techniques. To address these issues, we present a novel supervised contrastive learning framework to optimize hard exudate segmentation. Specifically, we introduce a patch-wise density contrasting scheme to distinguish between areas with varying lesion concentrations, and therefore improve the model's proficiency in segmenting small lesions. To handle the ambiguous boundaries, we develop a discriminative edge inspection module to dynamically analyze the pixels that lie around the boundaries and accurately delineate the exudates. Upon evaluation using the IDRiD dataset and comparison with state-of-the-art frameworks, our method exhibits its effectiveness and shows potential for computer-assisted hard exudate detection. The code to replicate experiments is available at this http URL.\n    ",
        "primary_category": "eess.IV",
        "categories": [
            "cs.CV",
            "cs.LG"
        ],
        "submitted_date": "22 Feb 2023",
        "last_revised_date": " "
    },
    "2302.11640": {
        "title": "A critical look at the evaluation of GNNs under heterophily: Are we really making progress?",
        "authors": [
            "Oleg Platonov",
            "Denis Kuznedelev",
            "Michael Diskin",
            "Artem Babenko",
            "Liudmila Prokhorenkova"
        ],
        "comments": " ",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Node classification is a classical graph machine learning task on which Graph Neural Networks (GNNs) have recently achieved strong results. However, it is often believed that standard GNNs only work well for homophilous graphs, i.e., graphs where edges tend to connect nodes of the same class. Graphs without this property are called heterophilous, and it is typically assumed that specialized methods are required to achieve strong performance on such graphs. In this work, we challenge this assumption. First, we show that the standard datasets used for evaluating heterophily-specific models have serious drawbacks, making results obtained by using them unreliable. The most significant of these drawbacks is the presence of a large number of duplicate nodes in the datasets Squirrel and Chameleon, which leads to train-test data leakage. We show that removing duplicate nodes strongly affects GNN performance on these datasets. Then, we propose a set of heterophilous graphs of varying properties that we believe can serve as a better benchmark for evaluating the performance of GNNs under heterophily. We show that standard GNNs achieve strong results on these heterophilous graphs, almost always outperforming specialized models. Our datasets and the code for reproducing our experiments are available at this https URL\n",
        "primary_category": "cs.LG",
        "categories": [],
        "submitted_date": "22 Feb 2023",
        "last_revised_date": " "
    },
    "2302.11953": {
        "title": "MFBE: Leveraging Multi-Field Information of FAQs for Efficient Dense Retrieval",
        "authors": [
            "Debopriyo Banerjee",
            "Mausam Jain",
            "Ashish Kulkarni"
        ],
        "comments": "The first two authors contributed equally to this work. 12 pages, 3 figures, 5 tables. Accepted at the 2023 Pacific-Asia Conference On Knowledge Discovery And Data Mining (PAKDD)",
        "subjects": "Information Retrieval (cs.IR)",
        "abstract": "In the domain of question-answering in NLP, the retrieval of Frequently Asked Questions (FAQ) is an important sub-area which is well researched and has been worked upon for many languages. Here, in response to a user query, a retrieval system typically returns the relevant FAQs from a knowledge-base. The efficacy of such a system depends on its ability to establish semantic match between the query and the FAQs in real-time. The task becomes challenging due to the inherent lexical gap between queries and FAQs, lack of sufficient context in FAQ titles, scarcity of labeled data and high retrieval latency. In this work, we propose a bi-encoder-based query-FAQ matching model that leverages multiple combinations of FAQ fields (like, question, answer, and category) both during model training and inference. Our proposed Multi-Field Bi-Encoder (MFBE) model benefits from the additional context resulting from multiple FAQ fields and performs well even with minimal labeled data. We empirically support this claim through experiments on proprietary as well as open-source public datasets in both unsupervised and supervised settings. Our model achieves around 27% and 20% better top-1 accuracy for the FAQ retrieval task on internal and open datasets, respectively over the best performing baseline.\n    ",
        "primary_category": "cs.IR",
        "categories": [
            "cs.LG"
        ],
        "submitted_date": "23 Feb 2023",
        "last_revised_date": " "
    },
    "2302.12415": {
        "title": "Harnessing the Speed and Accuracy of Machine Learning to Advance Cybersecurity",
        "authors": [
            "Khatoon Mohammed"
        ],
        "comments": " ",
        "subjects": "Cryptography and Security (cs.CR)",
        "abstract": "As cyber attacks continue to increase in frequency and sophistication, detecting malware has become a critical task for maintaining the security of computer systems. Traditional signature-based methods of malware detection have limitations in detecting complex and evolving threats. In recent years, machine learning (ML) has emerged as a promising solution to detect malware effectively. ML algorithms are capable of analyzing large datasets and identifying patterns that are difficult for humans to identify. This paper presents a comprehensive review of the state-of-the-art ML techniques used in malware detection, including supervised and unsupervised learning, deep learning, and reinforcement learning. We also examine the challenges and limitations of ML-based malware detection, such as the potential for adversarial attacks and the need for large amounts of labeled data. Furthermore, we discuss future directions in ML-based malware detection, including the integration of multiple ML algorithms and the use of explainable AI techniques to enhance the interpret ability of ML-based detection systems. Our research highlights the potential of ML-based techniques to improve the speed and accuracy of malware detection, and contribute to enhancing cybersecurity\n    ",
        "primary_category": "cs.CR",
        "categories": [],
        "submitted_date": "24 Feb 2023",
        "last_revised_date": " "
    },
    "2302.14186": {
        "title": "Approximately optimal domain adaptation with Fisher's Linear Discriminant",
        "authors": [
            "Hayden S. Helm",
            "Ashwin De Silva",
            "Joshua T. Vogelstein",
            "Carey E. Priebe",
            "Weiwei Yang"
        ],
        "comments": " ",
        "subjects": "Signal Processing (eess.SP)",
        "abstract": "We propose a class of models based on Fisher's Linear Discriminant (FLD) in the context of domain adaptation. The class is the convex combination of two hypotheses: i) an average hypothesis representing previously seen source tasks and ii) a hypothesis trained on a new target task. For a particular generative setting we derive the optimal convex combination of the two models under 0-1 loss, propose a computable approximation, and study the effect of various parameter settings on the relative risks between the optimal hypothesis, hypothesis i), and hypothesis ii). We demonstrate the effectiveness of the proposed optimal classifier in the context of EEG- and ECG-based classification settings and argue that the optimal classifier can be computed without access to direct information from any of the individual source tasks. We conclude by discussing further applications, limitations, and possible future directions.\n    ",
        "primary_category": "eess.SP",
        "categories": [
            "cs.LG",
            "stat.AP",
            "stat.ME",
            "stat.ML"
        ],
        "submitted_date": "27 Feb 2023",
        "last_revised_date": " "
    },
    "2302.14334": {
        "title": "Design of an Adaptive Lightweight LiDAR to Decouple Robot-Camera Geometry",
        "authors": [
            "Yuyang Chen",
            "Dingkang Wang",
            "Lenworth Thomas",
            "Karthik Dantu",
            "Sanjeev J. Koppal"
        ],
        "comments": "This paper is published in IEEE Transactions on Robotics",
        "subjects": "Robotics (cs.RO)",
        "abstract": "A fundamental challenge in robot perception is the coupling of the sensor pose and robot pose. This has led to research in active vision where robot pose is changed to reorient the sensor to areas of interest for perception. Further, egomotion such as jitter, and external effects such as wind and others affect perception requiring additional effort in software such as image stabilization. This effect is particularly pronounced in micro-air vehicles and micro-robots who typically are lighter and subject to larger jitter but do not have the computational capability to perform stabilization in real-time. We present a novel microelectromechanical (MEMS) mirror LiDAR system to change the field of view of the LiDAR independent of the robot motion. Our design has the potential for use on small, low-power systems where the expensive components of the LiDAR can be placed external to the small robot. We show the utility of our approach in simulation and on prototype hardware mounted on a UAV. We believe that this LiDAR and its compact movable scanning design provide mechanisms to decouple robot and sensor geometry allowing us to simplify robot perception. We also demonstrate examples of motion compensation using IMU and external odometry feedback in hardware.\n    ",
        "primary_category": "cs.RO",
        "categories": [],
        "submitted_date": "28 Feb 2023",
        "last_revised_date": " "
    },
    "2303.00696": {
        "title": "Trust your source: quantifying source condition elements for variational regularisation methods",
        "authors": [
            "Martin Benning",
            "Tatiana A. Bubba",
            "Luca Ratti",
            "Danilo Riccio"
        ],
        "comments": " ",
        "subjects": "Numerical Analysis (math.NA)",
        "abstract": "Source conditions are a key tool in regularisation theory that are needed to derive error estimates and convergence rates for ill-posed inverse problems. In this paper, we provide a recipe to practically compute source condition elements as the solution of convex minimisation problems that can be solved with first-order algorithms. We demonstrate the validity of our approach by testing it on two inverse problem case studies in machine learning and image processing: sparse coefficient estimation of a polynomial via LASSO regression and recovering an image from a subset of the coefficients of its discrete Fourier transform. We further demonstrate that the proposed approach can easily be modified to solve the machine learning task of identifying the optimal sampling pattern in the Fourier domain for a given image and variational regularisation method, which has applications in the context of sparsity promoting reconstruction from magnetic resonance imaging data.\n    ",
        "primary_category": "math.NA",
        "categories": [],
        "submitted_date": "1 Mar 2023",
        "last_revised_date": " "
    },
    "2303.02307": {
        "title": "Quantum Steganography via Coherent and Fock State Encoding in an Optical Medium",
        "authors": [
            "Bruno Avritzer",
            "Todd Brun"
        ],
        "comments": "17 pages, 7 figures",
        "subjects": "Quantum Physics (quant-ph)",
        "abstract": "Steganography is an alternative to cryptography, where information is protected by secrecy -- being disguised as innocent communication or noise -- rather than being scrambled. In this work we develop schemes for steganographic communication using Fock and coherent states in optical channels based on disguising the communications as thermal noise. We derive bounds on their efficiency in the case of an all-powerful eavesdropper, and provide explicit methods of encoding and error correction for the noiseless channel case.\n    ",
        "primary_category": "quant-ph",
        "categories": [
            "cs.IT"
        ],
        "submitted_date": "4 Mar 2023",
        "last_revised_date": " "
    },
    "2303.03156": {
        "title": "A Parallel Monte-Carlo Tree Search-Based Metaheuristic For Optimal Fleet Composition Considering Vehicle Routing Using Branch & Bound",
        "authors": [
            "T.M.J.T. Baltussen",
            "M. Goutham",
            "M. Menon",
            "S.G. Garrow",
            "M. Santillo",
            "S. Stockar"
        ],
        "comments": "DOI Included in manuscript",
        "subjects": "Systems and Control (eess.SY)",
        "abstract": "Autonomous mobile robots enable increased flexibility of manufacturing systems. The design and operating strategy of such a fleet of robots requires careful consideration of both fixed and operational costs. In this paper, a Monte-Carlo Tree Search (MCTS)-based metaheuristic is developed that guides a Branch & Bound (B&B) algorithm to find the globally optimal solution to the Fleet Size and Mix Vehicle Routing Problem with Time Windows (FSMVRPTW).The metaheuristic and exact algorithms are implemented in a parallel hybrid optimization algorithm where the metaheuristic rapidly finds feasible solutions that provide candidate upper bounds for the B&B algorithm. The MCTS additionally provides a candidate fleet composition to initiate the B&B search. Experiments show that the proposed approach results in significant improvements in computation time and convergence to the optimal solution.\n    ",
        "primary_category": "eess.SY",
        "categories": [],
        "submitted_date": "6 Mar 2023",
        "last_revised_date": " "
    },
    "2303.04878": {
        "title": "DeepGD: A Multi-Objective Black-Box Test Selection Approach for Deep Neural Networks",
        "authors": [
            "Zohreh Aghababaeyan",
            "Manel Abdellatif",
            "Mahboubeh Dadkhah",
            "Lionel Briand"
        ],
        "comments": " ",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Deep neural networks (DNNs) are widely used in various application domains such as image processing, speech recognition, and natural language processing. However, testing DNN models may be challenging due to the complexity and size of their input domain. Particularly, testing DNN models often requires generating or exploring large unlabeled datasets. In practice, DNN test oracles, which identify the correct outputs for inputs, often require expensive manual effort to label test data, possibly involving multiple experts to ensure labeling correctness. In this paper, we propose DeepGD, a black-box multi-objective test selection approach for DNN models. It reduces the cost of labeling by prioritizing the selection of test inputs with high fault revealing power from large unlabeled datasets. DeepGD not only selects test inputs with high uncertainty scores to trigger as many mispredicted inputs as possible but also maximizes the probability of revealing distinct faults in the DNN model by selecting diverse mispredicted inputs. The experimental results conducted on four widely used datasets and five DNN models show that in terms of fault-revealing ability: (1) White-box, coverage-based approaches fare poorly, (2) DeepGD outperforms existing black-box test selection approaches in terms of fault detection, and (3) DeepGD also leads to better guidance for DNN model retraining when using selected inputs to augment the training set.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.PF",
            "cs.SE"
        ],
        "submitted_date": "8 Mar 2023",
        "last_revised_date": " "
    },
    "2303.05328": {
        "title": "Simulation-based, Finite-sample Inference for Privatized Data",
        "authors": [
            "Jordan Awan",
            "Zhanyu Wang"
        ],
        "comments": "25 pages before references and appendices, 42 pages total, 10 figures, 9 tables",
        "subjects": "Statistics Theory (math.ST)",
        "abstract": "Privacy protection methods, such as differentially private mechanisms, introduce noise into resulting statistics which often produces complex and intractable sampling distributions. In this paper, we propose a simulation-based \"repro sample\" approach to produce statistically valid confidence intervals and hypothesis tests, which builds on the work of Xie and Wang (2022). We show that this methodology is applicable to a wide variety of private inference problems, appropriately accounts for biases introduced by privacy mechanisms (such as by clamping), and improves over other state-of-the-art inference methods such as the parametric bootstrap in terms of the coverage and type I error of the private inference. We also develop significant improvements and extensions for the repro sample methodology for general models (not necessarily related to privacy), including 1) modifying the procedure to ensure guaranteed coverage and type I errors, even accounting for Monte Carlo error, and 2) proposing efficient numerical algorithms to implement the confidence intervals and $p$-values.\n    ",
        "primary_category": "math.ST",
        "categories": [
            "cs.CR",
            "stat.ME"
        ],
        "submitted_date": "9 Mar 2023",
        "last_revised_date": " "
    },
    "2303.05707": {
        "title": "MuLTI: Efficient Video-and-Language Understanding with Text-Guided MultiWay-Sampler and Multiple Choice Modeling",
        "authors": [
            "Jiaqi Xu",
            "Bo Liu",
            "Yunkuo Chen",
            "Mengli Cheng",
            "Xing Shi"
        ],
        "comments": " ",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Video-and-language understanding has a variety of applications in the industry, such as video question answering, text-video retrieval, and multi-label classification. Existing video-and-language understanding methods generally adopt heavy multi-modal encoders and feature fusion modules, which consume high computational costs. Specially, they have difficulty dealing with dense video frames or long text prevalent in industrial applications. This paper proposes MuLTI, a highly accurate and efficient video-and-language understanding model that achieves efficient and effective feature fusion and rapid adaptation to downstream tasks. Specifically, we design a Text-Guided MultiWay-Sampler based on adapt-pooling residual mapping and self-attention modules to sample long sequences and fuse multi-modal features, which reduces the computational costs and addresses performance degradation caused by previous samplers. Therefore, MuLTI can handle longer sequences with limited computational costs. Then, to further enhance the model's performance and fill in the lack of pretraining tasks in the video question answering, we propose a new pretraining task named Multiple Choice Modeling. This task bridges the gap between pretraining and downstream tasks and improves the model's ability to align video and text features. Benefiting from the efficient feature fusion module and the new pretraining task, MuLTI achieves state-of-the-art performance on multiple datasets. Implementation and pretrained models will be released.\n    ",
        "primary_category": "cs.CV",
        "categories": [
            "cs.CL",
            "cs.MM"
        ],
        "submitted_date": "10 Mar 2023",
        "last_revised_date": " "
    },
    "2303.07196": {
        "title": "A Comprehensive Empirical Evaluation of Existing Word Embedding Approaches",
        "authors": [
            "Obaidullah Zaland",
            "Muhammad Abulaish",
            "Mohd. Fazil"
        ],
        "comments": "28 pages, 3 figures and 10 tables",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "Vector-based word representations help countless Natural Language Processing (NLP) tasks capture the language's semantic and syntactic regularities. In this paper, we present the characteristics of existing word embedding approaches and analyze them with regard to many classification tasks. We categorize the methods into two main groups - Traditional approaches mostly use matrix factorization to produce word representations, and they are not able to capture the semantic and syntactic regularities of the language very well. On the other hand, Neural-network-based approaches can capture sophisticated regularities of the language and preserve the word relationships in the generated word representations. We report experimental results on multiple classification tasks and highlight the scenarios where one approach performs better than the rest.\n    ",
        "primary_category": "cs.CL",
        "categories": [
            "cs.NE"
        ],
        "submitted_date": "13 Mar 2023",
        "last_revised_date": " "
    },
    "2303.07257": {
        "title": "The Audio-Visual BatVision Dataset for Research on Sight and Sound",
        "authors": [
            "Amandine Brunetto",
            "Sascha Hornauer",
            "Stella X. Yu",
            "Fabien Moutarde"
        ],
        "comments": "Project page this https URL This version contains camera ready paper",
        "subjects": "Robotics (cs.RO)",
        "abstract": "Vision research showed remarkable success in understanding our world, propelled by datasets of images and videos. Sensor data from radar, LiDAR and cameras supports research in robotics and autonomous driving for at least a decade. However, while visual sensors may fail in some conditions, sound has recently shown potential to complement sensor data. Simulated room impulse responses (RIR) in 3D apartment-models became a benchmark dataset for the community, fostering a range of audiovisual research. In simulation, depth is predictable from sound, by learning bat-like perception with a neural network. Concurrently, the same was achieved in reality by using RGB-D images and echoes of chirping sounds. Biomimicking bat perception is an exciting new direction but needs dedicated datasets to explore the potential. Therefore, we collected the BatVision dataset to provide large-scale echoes in complex real-world scenes to the community. We equipped a robot with a speaker to emit chirps and a binaural microphone to record their echoes. Synchronized RGB-D images from the same perspective provide visual labels of traversed spaces. We sampled modern US office spaces to historic French university grounds, indoor and outdoor with large architectural variety. This dataset will allow research on robot echolocation, general audio-visual tasks and sound ph\u00e6nomena unavailable in simulated data. We show promising results for audio-only depth prediction and show how state-of-the-art work developed for simulated data can also succeed on our dataset. Project page: this https URL\n",
        "primary_category": "cs.RO",
        "categories": [],
        "submitted_date": "13 Mar 2023",
        "last_revised_date": " "
    },
    "2303.07539": {
        "title": "HCI Papers Cite HCI Papers, Increasingly So",
        "authors": [
            "Xiang 'Anthony' Chen"
        ],
        "comments": " ",
        "subjects": "Human-Computer Interaction (cs.HC)",
        "abstract": "To measure how HCI papers are cited across disciplinary boundaries, we collected a citation dataset of CHI, UIST, and CSCW papers published between 2010 and 2020. Our analysis indicates that HCI papers have been more and more likely to be cited by HCI papers rather than by non-HCI papers.\n    ",
        "primary_category": "cs.HC",
        "categories": [],
        "submitted_date": "13 Mar 2023",
        "last_revised_date": " "
    },
    "2303.08731": {
        "title": "Bridging adaptive management and reinforcement learning for more robust decisions",
        "authors": [
            "Melissa Chapman",
            "Lily Xu",
            "Marcus Lapeyrolerie",
            "Carl Boettiger"
        ],
        "comments": "In press at Philosophical Transactions of the Royal Society B",
        "subjects": "Computers and Society (cs.CY)",
        "abstract": "From out-competing grandmasters in chess to informing high-stakes healthcare decisions, emerging methods from artificial intelligence are increasingly capable of making complex and strategic decisions in diverse, high-dimensional, and uncertain situations. But can these methods help us devise robust strategies for managing environmental systems under great uncertainty? Here we explore how reinforcement learning, a subfield of artificial intelligence, approaches decision problems through a lens similar to adaptive environmental management: learning through experience to gradually improve decisions with updated knowledge. We review where reinforcement learning (RL) holds promise for improving evidence-informed adaptive management decisions even when classical optimization methods are intractable. For example, model-free deep RL might help identify quantitative decision strategies even when models are nonidentifiable. Finally, we discuss technical and social issues that arise when applying reinforcement learning to adaptive management problems in the environmental domain. Our synthesis suggests that environmental management and computer science can learn from one another about the practices, promises, and perils of experience-based decision-making.\n    ",
        "primary_category": "cs.CY",
        "categories": [],
        "submitted_date": "15 Mar 2023",
        "last_revised_date": " "
    },
    "2303.09105": {
        "title": "Rethinking Model Ensemble in Transfer-based Adversarial Attacks",
        "authors": [
            "Huanran Chen",
            "Yichi Zhang",
            "Yinpeng Dong",
            "Xiao Yang",
            "Hang Su",
            "Jun Zhu"
        ],
        "comments": " ",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "It is widely recognized that deep learning models lack robustness to adversarial examples. An intriguing property of adversarial examples is that they can transfer across different models, which enables black-box attacks without any knowledge of the victim model. An effective strategy to improve the transferability is attacking an ensemble of models. However, previous works simply average the outputs of different models, lacking an in-depth analysis on how and why model ensemble methods can strongly improve the transferability. In this paper, we rethink the ensemble in adversarial attacks and define the common weakness of model ensemble with two properties: 1) the flatness of loss landscape; and 2) the closeness to the local optimum of each model. We empirically and theoretically show that both properties are strongly correlated with the transferability and propose a Common Weakness Attack (CWA) to generate more transferable adversarial examples by promoting these two properties. Experimental results on both image classification and object detection tasks validate the effectiveness of our approach to improving the adversarial transferability, especially when attacking adversarially trained models. We also successfully apply our method to attack a black-box large vision-language model -- Google's Bard, showing the practical effectiveness. Code is available at \\url{this https URL}.\n    ",
        "primary_category": "cs.CV",
        "categories": [],
        "submitted_date": "16 Mar 2023",
        "last_revised_date": " "
    },
    "2303.10087": {
        "title": "Neural Refinement for Absolute Pose Regression with Feature Synthesis",
        "authors": [
            "Shuai Chen",
            "Yash Bhalgat",
            "Xinghui Li",
            "Jiawang Bian",
            "Kejie Li",
            "Zirui Wang",
            "Victor Adrian Prisacariu"
        ],
        "comments": "Paper Accepted by CVPR 2024. Project Page: http://nefes.active.vision. Code will be released at this https URL",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Absolute Pose Regression (APR) methods use deep neural networks to directly regress camera poses from RGB images. However, the predominant APR architectures only rely on 2D operations during inference, resulting in limited accuracy of pose estimation due to the lack of 3D geometry constraints or priors. In this work, we propose a test-time refinement pipeline that leverages implicit geometric constraints using a robust feature field to enhance the ability of APR methods to use 3D information during inference. We also introduce a novel Neural Feature Synthesizer (NeFeS) model, which encodes 3D geometric features during training and directly renders dense novel view features at test time to refine APR methods. To enhance the robustness of our model, we introduce a feature fusion module and a progressive training strategy. Our proposed method achieves state-of-the-art single-image APR accuracy on indoor and outdoor datasets.\n    ",
        "primary_category": "cs.CV",
        "categories": [],
        "submitted_date": "17 Mar 2023",
        "last_revised_date": " "
    },
    "2303.12194": {
        "title": "LiDARFormer: A Unified Transformer-based Multi-task Network for LiDAR Perception",
        "authors": [
            "Zixiang Zhou",
            "Dongqiangzi Ye",
            "Weijia Chen",
            "Yufei Xie",
            "Yu Wang",
            "Panqu Wang",
            "Hassan Foroosh"
        ],
        "comments": "ICRA 2024",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "There is a recent trend in the LiDAR perception field towards unifying multiple tasks in a single strong network with improved performance, as opposed to using separate networks for each task. In this paper, we introduce a new LiDAR multi-task learning paradigm based on the transformer. The proposed LiDARFormer utilizes cross-space global contextual feature information and exploits cross-task synergy to boost the performance of LiDAR perception tasks across multiple large-scale datasets and benchmarks. Our novel transformer-based framework includes a cross-space transformer module that learns attentive features between the 2D dense Bird's Eye View (BEV) and 3D sparse voxel feature maps. Additionally, we propose a transformer decoder for the segmentation task to dynamically adjust the learned features by leveraging the categorical feature representations. Furthermore, we combine the segmentation and detection features in a shared transformer decoder with cross-task attention layers to enhance and integrate the object-level and class-level features. LiDARFormer is evaluated on the large-scale nuScenes and the Waymo Open datasets for both 3D detection and semantic segmentation tasks, and it outperforms all previously published methods on both tasks. Notably, LiDARFormer achieves the state-of-the-art performance of 76.4% L2 mAPH and 74.3% NDS on the challenging Waymo and nuScenes detection benchmarks for a single model LiDAR-only method.\n    ",
        "primary_category": "cs.CV",
        "categories": [],
        "submitted_date": "21 Mar 2023",
        "last_revised_date": " "
    },
    "2303.12767": {
        "title": "Can we trust the evaluation on ChatGPT?",
        "authors": [
            "Rachith Aiyappa",
            "Jisun An",
            "Haewoon Kwak",
            "Yong-Yeol Ahn"
        ],
        "comments": " ",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "ChatGPT, the first large language model (LLM) with mass adoption, has demonstrated remarkable performance in numerous natural language tasks. Despite its evident usefulness, evaluating ChatGPT's performance in diverse problem domains remains challenging due to the closed nature of the model and its continuous updates via Reinforcement Learning from Human Feedback (RLHF). We highlight the issue of data contamination in ChatGPT evaluations, with a case study of the task of stance detection. We discuss the challenge of preventing data contamination and ensuring fair model evaluation in the age of closed and continuously trained models.\n    ",
        "primary_category": "cs.CL",
        "categories": [
            "cs.AI",
            "cs.LG"
        ],
        "submitted_date": "22 Mar 2023",
        "last_revised_date": " "
    },
    "2303.15495": {
        "title": "Real-Time Bus Arrival Prediction: A Deep Learning Approach for Enhanced Urban Mobility",
        "authors": [
            "Narges Rashvand",
            "Sanaz Sadat Hosseini",
            "Mona Azarbayjani",
            "Hamed Tabkhi"
        ],
        "comments": " ",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "In urban settings, bus transit stands as a significant mode of public transportation, yet faces hurdles in delivering accurate and reliable arrival times. This discrepancy often culminates in delays and a decline in ridership, particularly in areas with a heavy reliance on bus transit. A prevalent challenge is the mismatch between actual bus arrival times and their scheduled counterparts, leading to disruptions in fixed schedules. Our study, utilizing New York City bus data, reveals an average delay of approximately eight minutes between scheduled and actual bus arrival times. This research introduces an innovative, AI-based, data-driven methodology for predicting bus arrival times at various transit points (stations), offering a collective prediction for all bus lines within large metropolitan areas. Through the deployment of a fully connected neural network, our method elevates the accuracy and efficiency of public bus transit systems. Our comprehensive evaluation encompasses over 200 bus lines and 2 million data points, showcasing an error margin of under 40 seconds for arrival time estimates. Additionally, the inference time for each data point in the validation set is recorded at below 0.006 ms, demonstrating the potential of our Neural-Net-based approach in substantially enhancing the punctuality and reliability of bus transit systems.\n    ",
        "primary_category": "cs.LG",
        "categories": [],
        "submitted_date": "27 Mar 2023",
        "last_revised_date": " "
    },
    "2303.15610": {
        "title": "Towards Crossing-Free Hamiltonian Cycles in Simple Drawings of Complete Graphs",
        "authors": [
            "Oswin Aichholzer",
            "Joachim Orthaber",
            "Birgit Vogtenhuber"
        ],
        "comments": "Final version as published in the journal Computing in Geometry and Topology. (30 pages, 22 figures)",
        "subjects": "Combinatorics (math.CO)",
        "abstract": "It is a longstanding conjecture that every simple drawing of a complete graph on $n \\geq 3$ vertices contains a crossing-free Hamiltonian cycle. We strengthen this conjecture to \"there exists a crossing-free Hamiltonian path between each pair of vertices\" and show that this stronger conjecture holds for several classes of simple drawings, including strongly c-monotone drawings and cylindrical drawings. As a second main contribution, we give an overview on different classes of simple drawings and investigate inclusion relations between them up to weak isomorphism.\n    ",
        "primary_category": "math.CO",
        "categories": [
            "cs.CG"
        ],
        "submitted_date": "27 Mar 2023",
        "last_revised_date": " "
    },
    "2303.15687": {
        "title": "Switched Moving Boundary Modeling of Phase Change Thermal Energy Storage Systems",
        "authors": [
            "Trent J. Sakakini",
            "Justin P. Koeln"
        ],
        "comments": "7 pages, 6 figures",
        "subjects": "Systems and Control (eess.SY)",
        "abstract": "Thermal Energy Storage (TES) devices, which leverage the constant-temperature thermal capacity of the latent heat of a Phase Change Material (PCM), provide benefits to a variety of thermal management systems by decoupling the absorption and rejection of thermal energy. While performing a role similar to a battery in an electrical system, it is critical to know when to charge (freeze) and discharge (melt) the TES to maximize the capabilities and efficiency of the overall system. Therefore, control-oriented models of TES are needed to predict the behavior of the TES and make informed control decisions. While existing modeling approaches divide the TES in to multiple sections using a Fixed Grid (FG) approach, this paper proposes a switched Moving Boundary (MB) model that captures the key dynamics of the TES with significantly fewer dynamic states. Specifically, a graph-based modeling approach is used to model the heat flow through the TES and a MB approach is used to model the time-varying liquid and solid regions of the TES. Additionally, a Finite State Machine (FSM) is used to switch between four different modes of operation based on the State-of-Charge (SOC) of the TES. Numerical simulations comparing the proposed approach with a more traditional FG approach show that the MB model is capable of accurately modeling the behavior of the FG model while using far fewer states, leading to five times faster simulations.\n    ",
        "primary_category": "eess.SY",
        "categories": [],
        "submitted_date": "28 Mar 2023",
        "last_revised_date": " "
    },
    "2303.16548": {
        "title": "Policy Gradient Methods for Discrete Time Linear Quadratic Regulator With Random Parameters",
        "authors": [
            "Deyue Li"
        ],
        "comments": "57 pages, 4 figures",
        "subjects": "Optimization and Control (math.OC)",
        "abstract": "This paper studies an infinite horizon optimal control problem for discrete-time linear system and quadratic criteria, both with random parameters which are independent and identically distributed with respect to time. In this general setting, we apply the policy gradient method, a reinforcement learning technique, to search for the optimal control without requiring knowledge of statistical information of the parameters. We investigate the sub-Gaussianity of the state process and establish global linear convergence guarantee for this approach based on assumptions that are weaker and easier to verify compared to existing results. Numerical experiments are presented to illustrate our result.\n    ",
        "primary_category": "math.OC",
        "categories": [
            "cs.LG"
        ],
        "submitted_date": "29 Mar 2023",
        "last_revised_date": " "
    },
    "2303.16871": {
        "title": "Full-Range Approximation for the Theis Well Function Using Ramanujan's Series and Bounds for the Exponential Integral",
        "authors": [
            "Manotosh Kumbhakar",
            "Vijay P. Singh"
        ],
        "comments": "10 pages",
        "subjects": "Computational Engineering, Finance, and Science (cs.CE)",
        "abstract": "The solution of the governing equation representing the drawdown in a horizontal confined aquifer, where groundwater flow is unsteady, is provided in terms of the exponential integral, which is famously known as the Well function. For the computation of this function in practical applications, it is important to develop not only accurate but also a simple approximation that requires evaluation of the fewest possible terms. To that end, introducing Ramanujan's series expression, this work proposes a full-range approximation to the exponential integral using Ramanujan's series for the small argument (u \\leq 1) and an approximation based on the bound of the integral for the other range (u \\in (1,100]). The evaluation of the proposed approximation results in the most accurate formulae compared to the existing studies, which possess the maximum percentage error of 0.05\\%. Further, the proposed formula is much simpler to apply as it contains just the product of exponential and logarithm functions. To further check the efficiency of the proposed approximation, we consider a practical example for evaluating the discrete pumping kernel, which shows the superiority of this approximation over the others. Finally, the authors hope that the proposed efficient approximation can be useful for groundwater and hydrogeological applications.\n    ",
        "primary_category": "cs.CE",
        "categories": [],
        "submitted_date": "3 Mar 2023",
        "last_revised_date": " "
    },
    "2303.16953": {
        "title": "A data-assisted two-stage method for the inverse random source problem",
        "authors": [
            "Peijun Li",
            "Ying Liang",
            "Yuliang Wang"
        ],
        "comments": " ",
        "subjects": "Numerical Analysis (math.NA)",
        "abstract": "We propose a data-assisted two-stage method for solving an inverse random source problem of the Helmholtz equation. In the first stage, the regularized Kaczmarz method is employed to generate initial approximations of the mean and variance based on the mild solution of the stochastic Helmholtz equation. A dataset is then obtained by sampling the approximate and corresponding true profiles from a certain a-priori criterion. The second stage is formulated as an image-to-image translation problem, and several data-assisted approaches are utilized to handle the dataset and obtain enhanced reconstructions. Numerical experiments demonstrate that the data-assisted two-stage method provides satisfactory reconstruction for both homogeneous and inhomogeneous media with fewer realizations.\n    ",
        "primary_category": "math.NA",
        "categories": [],
        "submitted_date": "29 Mar 2023",
        "last_revised_date": " "
    },
    "2303.17218": {
        "title": "HARFLOW3D: A Latency-Oriented 3D-CNN Accelerator Toolflow for HAR on FPGA Devices",
        "authors": [
            "Petros Toupas",
            "Alexander Montgomerie-Corcoran",
            "Christos-Savvas Bouganis",
            "Dimitrios Tzovaras"
        ],
        "comments": "11 pages, 8 figures, 6 tables",
        "subjects": "Hardware Architecture (cs.AR)",
        "abstract": "For Human Action Recognition tasks (HAR), 3D Convolutional Neural Networks have proven to be highly effective, achieving state-of-the-art results. This study introduces a novel streaming architecture based toolflow for mapping such models onto FPGAs considering the model's inherent characteristics and the features of the targeted FPGA device. The HARFLOW3D toolflow takes as input a 3D CNN in ONNX format and a description of the FPGA characteristics, generating a design that minimizes the latency of the computation. The toolflow is comprised of a number of parts, including i) a 3D CNN parser, ii) a performance and resource model, iii) a scheduling algorithm for executing 3D models on the generated hardware, iv) a resource-aware optimization engine tailored for 3D models, v) an automated mapping to synthesizable code for FPGAs. The ability of the toolflow to support a broad range of models and devices is shown through a number of experiments on various 3D CNN and FPGA system pairs. Furthermore, the toolflow has produced high-performing results for 3D CNN models that have not been mapped to FPGAs before, demonstrating the potential of FPGA-based systems in this space. Overall, HARFLOW3D has demonstrated its ability to deliver competitive latency compared to a range of state-of-the-art hand-tuned approaches being able to achieve up to 5$\\times$ better performance compared to some of the existing works.\n    ",
        "primary_category": "cs.AR",
        "categories": [
            "cs.CV",
            "cs.LG"
        ],
        "submitted_date": "30 Mar 2023",
        "last_revised_date": " "
    },
    "2303.17355": {
        "title": "Acoustic Soft Tactile Skin (AST Skin)",
        "authors": [
            "Vishnu Rajendran S",
            "Willow Mandil",
            "Simon Parsons",
            "Amir Ghalamzan E"
        ],
        "comments": "IEEE International Conference on Robotics and Automation (ICRA) 2024 (accepted)",
        "subjects": "Robotics (cs.RO)",
        "abstract": "This paper presents a novel soft tactile skin (STS) technology operating with sound waves. In this innovative approach, the sound waves generated by a speaker travel in channels embedded in a soft membrane and get modulated due to a deformation of the channel when pressed by an external force and received by a microphone at the end of the channel. The sensor leverages regression and classification methods for estimating the normal force and its contact location. Our sensor can be affixed to any robot part, e.g., end effectors or arm. We tested several regression and classifier methods to learn the relation between sound wave modulation, the applied force, and its location, respectively and picked the best-performing models for force and location predictions. Our novel tactile sensor yields 93% of the force estimation within 1.5 N tolerances for a range of 0-30+1 N and estimates contact locations with over 96% accuracy. We also demonstrated the performance of STS technology for a real-time gripping force control application.\n    ",
        "primary_category": "cs.RO",
        "categories": [],
        "submitted_date": "30 Mar 2023",
        "last_revised_date": " "
    },
    "2303.17386": {
        "title": "Complementary Random Masking for RGB-Thermal Semantic Segmentation",
        "authors": [
            "Ukcheol Shin",
            "Kyunghyun Lee",
            "In So Kweon",
            "Jean Oh"
        ],
        "comments": "ICRA 2024, Our source code is available at this https URL",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "RGB-thermal semantic segmentation is one potential solution to achieve reliable semantic scene understanding in adverse weather and lighting conditions. However, the previous studies mostly focus on designing a multi-modal fusion module without consideration of the nature of multi-modality inputs. Therefore, the networks easily become over-reliant on a single modality, making it difficult to learn complementary and meaningful representations for each modality. This paper proposes 1) a complementary random masking strategy of RGB-T images and 2) self-distillation loss between clean and masked input modalities. The proposed masking strategy prevents over-reliance on a single modality. It also improves the accuracy and robustness of the neural network by forcing the network to segment and classify objects even when one modality is partially available. Also, the proposed self-distillation loss encourages the network to extract complementary and meaningful representations from a single modality or complementary masked modalities. Based on the proposed method, we achieve state-of-the-art performance over three RGB-T semantic segmentation benchmarks. Our source code is available at this https URL.\n    ",
        "primary_category": "cs.CV",
        "categories": [
            "cs.AI",
            "cs.RO"
        ],
        "submitted_date": "30 Mar 2023",
        "last_revised_date": " "
    },
    "2303.17550": {
        "title": "DAE-Talker: High Fidelity Speech-Driven Talking Face Generation with Diffusion Autoencoder",
        "authors": [
            "Chenpeng Du",
            "Qi Chen",
            "Xie Chen",
            "Kai Yu"
        ],
        "comments": "Accepted to ACM Multimedia 2023",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "While recent research has made significant progress in speech-driven talking face generation, the quality of the generated video still lags behind that of real recordings. One reason for this is the use of handcrafted intermediate representations like facial landmarks and 3DMM coefficients, which are designed based on human knowledge and are insufficient to precisely describe facial movements. Additionally, these methods require an external pretrained model for extracting these representations, whose performance sets an upper bound on talking face generation. To address these limitations, we propose a novel method called DAE-Talker that leverages data-driven latent representations obtained from a diffusion autoencoder (DAE). DAE contains an image encoder that encodes an image into a latent vector and a DDIM image decoder that reconstructs the image from it. We train our DAE on talking face video frames and then extract their latent representations as the training target for a Conformer-based speech2latent model. This allows DAE-Talker to synthesize full video frames and produce natural head movements that align with the content of speech, rather than relying on a predetermined head pose from a template video. We also introduce pose modelling in speech2latent for pose controllability. Additionally, we propose a novel method for generating continuous video frames with the DDIM image decoder trained on individual frames, eliminating the need for modelling the joint distribution of consecutive frames directly. Our experiments show that DAE-Talker outperforms existing popular methods in lip-sync, video fidelity, and pose naturalness. We also conduct ablation studies to analyze the effectiveness of the proposed techniques and demonstrate the pose controllability of DAE-Talker.\n    ",
        "primary_category": "cs.CV",
        "categories": [
            "cs.MM"
        ],
        "submitted_date": "30 Mar 2023",
        "last_revised_date": " "
    },
    "2303.17674": {
        "title": "Convex Hulls of Reachable Sets",
        "authors": [
            "Thomas Lew",
            "Riccardo Bonalli",
            "Marco Pavone"
        ],
        "comments": "19 pages. Submitted to the IEEE Transactions on Automatic Control. Substantial extension of arXiv:2303.17674v2",
        "subjects": "Optimization and Control (math.OC)",
        "abstract": "We study the convex hulls of reachable sets of nonlinear systems with bounded disturbances and uncertain initial conditions. Reachable sets play a critical role in control, but remain notoriously challenging to compute, and existing over-approximation tools tend to be conservative or computationally expensive. In this work, we characterize the convex hulls of reachable sets as the convex hulls of solutions of an ordinary differential equation with initial conditions on the sphere. This finite-dimensional characterization unlocks an efficient sampling-based estimation algorithm to accurately over-approximate reachable sets. We also study the structure of the boundary of the reachable convex hulls and derive error bounds for the estimation algorithm. We give applications to neural feedback loop analysis and robust MPC.\n    ",
        "primary_category": "math.OC",
        "categories": [
            "cs.LG",
            "cs.RO",
            "eess.SY"
        ],
        "submitted_date": "30 Mar 2023",
        "last_revised_date": " "
    },
    "2303.18242": {
        "title": "$\\infty$-Diff: Infinite Resolution Diffusion with Subsampled Mollified States",
        "authors": [
            "Sam Bond-Taylor",
            "Chris G. Willcocks"
        ],
        "comments": "Accepted at ICLR 2024",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "This paper introduces $\\infty$-Diff, a generative diffusion model defined in an infinite-dimensional Hilbert space, which can model infinite resolution data. By training on randomly sampled subsets of coordinates and denoising content only at those locations, we learn a continuous function for arbitrary resolution sampling. Unlike prior neural field-based infinite-dimensional models, which use point-wise functions requiring latent compression, our method employs non-local integral operators to map between Hilbert spaces, allowing spatial context aggregation. This is achieved with an efficient multi-scale function-space architecture that operates directly on raw sparse coordinates, coupled with a mollified diffusion process that smooths out irregularities. Through experiments on high-resolution datasets, we found that even at an $8\\times$ subsampling rate, our model retains high-quality diffusion. This leads to significant run-time and memory savings, delivers samples with lower FID scores, and scales beyond the training resolution while retaining detail.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.CV"
        ],
        "submitted_date": "31 Mar 2023",
        "last_revised_date": " "
    },
    "2304.00119": {
        "title": "End-to-end deep learning-based framework for path planning and collision checking: bin picking application",
        "authors": [
            "Mehran Ghafarian Tamizi",
            "Homayoun Honari",
            "Aleksey Nozdryn-Plotnicki",
            "Homayoun Najjaran"
        ],
        "comments": "18 pages, 6 figures, 2 tables",
        "subjects": "Robotics (cs.RO)",
        "abstract": "Real-time and efficient path planning is critical for all robotic systems. In particular, it is of greater importance for industrial robots since the overall planning and execution time directly impact the cycle time and automation economics in production lines. While the problem may not be complex in static environments, classical approaches are inefficient in high-dimensional environments in terms of planning time and optimality. Collision checking poses another challenge in obtaining a real-time solution for path planning in complex environments. To address these issues, we propose an end-to-end learning-based framework viz., Path Planning and Collision checking Network (PPCNet). The PPCNet generates the path by computing waypoints sequentially using two networks: the first network generates a waypoint, and the second one determines whether the waypoint is on a collision-free segment of the path. The end-to-end training process is based on imitation learning that uses data aggregation from the experience of an expert planner to train the two networks, simultaneously. We utilize two approaches for training a network that efficiently approximates the exact geometrical collision checking function. Finally, the PPCNet is evaluated in two different simulation environments and a practical implementation on a robotic arm for a bin-picking application. Compared to the state-of-the-art path planning methods, our results show significant improvement in performance by greatly reducing the planning time with comparable success rates and path lengths.\n    ",
        "primary_category": "cs.RO",
        "categories": [
            "eess.SY"
        ],
        "submitted_date": "31 Mar 2023",
        "last_revised_date": " "
    },
    "2304.00933": {
        "title": "Knowledge Accumulation in Continually Learned Representations and the Issue of Feature Forgetting",
        "authors": [
            "Timm Hess",
            "Eli Verwimp",
            "Gido M. van de Ven",
            "Tinne Tuytelaars"
        ],
        "comments": " ",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Continual learning research has shown that neural networks suffer from catastrophic forgetting \"at the output level\", but it is debated whether this is also the case at the level of learned representations. Multiple recent studies ascribe representations a certain level of innate robustness against forgetting - that they only forget minimally and no critical information. We revisit and expand upon the experiments that revealed this difference in forgetting and illustrate the coexistence of two phenomena that affect the quality of continually learned representations: knowledge accumulation and feature forgetting. Carefully taking both aspects into account, we show that, even though it is true that feature forgetting can be small in absolute terms, newly learned information tends to be forgotten just as catastrophically at the level of the representation as it is at the output level. Next we show that this feature forgetting is problematic as it substantially slows down knowledge accumulation. Finally, we study how feature forgetting and knowledge accumulation are affected by different types of continual learning methods.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.CV"
        ],
        "submitted_date": "3 Apr 2023",
        "last_revised_date": " "
    },
    "2304.01099": {
        "title": "Dichotomies for Maximum Matching Cut: $H$-Freeness, Bounded Diameter, Bounded Radius",
        "authors": [
            "Felicia Lucke",
            "Dani\u00ebl Paulusma",
            "Bernard Ries"
        ],
        "comments": "arXiv admin note: text overlap with arXiv:2207.07095",
        "subjects": "Combinatorics (math.CO)",
        "abstract": "The (Perfect) Matching Cut problem is to decide if a graph $G$ has a (perfect) matching cut, i.e., a (perfect) matching that is also an edge cut of $G$. Both Matching Cut and Perfect Matching Cut are known to be NP-complete. A perfect matching cut is also a matching cut with maximum number of edges. To increase our understanding of the relationship between the two problems, we introduce the Maximum Matching Cut problem. This problem is to determine a largest matching cut in a graph. We generalize and unify known polynomial-time algorithms for Matching Cut and Perfect Matching Cut restricted to graphs of diameter at most $2$ and to $(P_6+sP_2)$-free graphs. We also show that the complexity of Maximum Matching Cut differs from the complexities of Matching Cut and Perfect Matching Cut by proving NP-hardness of Maximum Matching Cut for $2P_3$-free quadrangulated graphs of diameter $3$ and radius $2$ and for subcubic line graphs of triangle-free graphs. In this way, we obtain full dichotomies of Maximum Matching Cut for graphs of bounded diameter, bounded radius and $H$-free graphs. Finally, we apply our techniques to get a dichotomy for the Maximum Disconnected Perfect Matching problem for $H$-free graphs. A disconnected perfect matching of a graph $G$ is a perfect matching that contains a matching cut of $G$. The Maximum Disconnected Perfect Matching problem asks to determine for a connected graph $G$, a disconnected perfect matching with a largest matching cut over all disconnected perfect matchings of $G$. Our dichotomy result implies that the original decision problem Disconnected Perfect Matching is polynomial-time solvable for $(P_6+sP_2)$-free graphs for every $s\\geq 0$, which resolves an open problem of Bouquet and Picouleau (arXiv, 2020).\n    ",
        "primary_category": "math.CO",
        "categories": [
            "cs.CC",
            "cs.DM",
            "cs.DS"
        ],
        "submitted_date": "3 Apr 2023",
        "last_revised_date": " "
    },
    "2304.01915": {
        "title": "Fog Device-as-a-Service (FDaaS): A Framework for Service Deployment in Public Fog Environments",
        "authors": [
            "Sudheer Kumar Battula",
            "Saurabh Garg",
            "James Montgomery",
            "Ranesh Naha"
        ],
        "comments": "10 Pages, 13 Figures",
        "subjects": "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "abstract": "Meeting the requirements of future services with time sensitivity and handling sudden load spikes of the services in Fog computing environments are challenging tasks due to the lack of publicly available Fog nodes and their characteristics. Researchers have assumed that the traditional autoscaling techniques, with lightweight virtualisation technology (containers), can be used to provide autoscaling features in Fog computing environments, few researchers have built the platform by exploiting the default autoscaling techniques of the containerisation orchestration tools or systems. However, the adoption of these techniques alone, in a publicly available Fog infrastructure, does not guarantee Quality of Service (QoS) due to the heterogeneity of Fog devices and their characteristics, such as frequent resource changes and high mobility. To tackle this challenge, in this work we developed a Fog as a Service (FaaS) framework that can create, configure and manage the containers which are running on the Fog devices to deploy services. This work presents the key techniques and algorithms which are responsible for handling sudden load spikes of the services to meet the QoS of the application. This work provides an evaluation by comparing it with existing techniques under real scenarios. The experiment results show that our proposed approach maximises the satisfied service requests by an average of 1.9 times in different scenarios.\n    ",
        "primary_category": "cs.DC",
        "categories": [],
        "submitted_date": "1 Mar 2023",
        "last_revised_date": " "
    },
    "2304.02313": {
        "title": "Personality-aware Human-centric Multimodal Reasoning: A New Task, Dataset and Baselines",
        "authors": [
            "Yaochen Zhu",
            "Xiangqing Shen",
            "Rui Xia"
        ],
        "comments": " ",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "Personality traits, emotions, and beliefs shape individuals' behavioral choices and decision-making processes. However, for one thing, the affective computing community normally focused on predicting personality traits but overlooks their application in behavior prediction. For another, the multimodal reasoning task emphasized the prediction of future states and behaviors but often neglected the incorporation of individual personality traits. In this work, we introduce a new task called Personality-aware Human-centric Multimodal Reasoning (PHMR) (T1), with the goal of forecasting the future behavior of a particular individual using multimodal information from past instances, while integrating personality factors. We accordingly construct a new dataset based on six television shows, encompassing 225 characters and 12k samples. To establish a benchmark for the task, we propose seven baseline methods: three adapted from related tasks, two pre-trained model, and two multimodal large language models. The experimental results demonstrate that incorporating personality traits enhances human-centric multimodal reasoning performance. To further solve the lack of personality annotation in real-life scenes, we introduce an extension task called Personality-predicted Human-centric Multimodal Reasoning task (T2) along with the corresponding dataset and method. We will make our dataset and code available on GitHub.\n    ",
        "primary_category": "cs.CL",
        "categories": [],
        "submitted_date": "5 Apr 2023",
        "last_revised_date": " "
    },
    "2304.02780": {
        "title": "A Transformer-Based Deep Learning Approach for Fairly Predicting Post-Liver Transplant Risk Factors",
        "authors": [
            "Can Li",
            "Xiaoqian Jiang",
            "Kai Zhang"
        ],
        "comments": "Published in Journal of Biomedical Informatics",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Liver transplantation is a life-saving procedure for patients with end-stage liver disease. There are two main challenges in liver transplant: finding the best matching patient for a donor and ensuring transplant equity among different subpopulations. The current MELD scoring system evaluates a patient's mortality risk if not receiving an organ within 90 days. However, the donor-patient matching should also consider post-transplant risk factors, such as cardiovascular disease, chronic rejection, etc., which are all common complications after transplant. Accurate prediction of these risk scores remains a significant challenge. In this study, we used predictive models to solve the above challenges. Specifically, we proposed a deep-learning model to predict multiple risk factors after a liver transplant. By formulating it as a multi-task learning problem, the proposed deep neural network was trained to simultaneously predict the five post-transplant risks and achieve equal good performance by exploiting task-balancing techniques. We also proposed a novel fairness-achieving algorithm to ensure prediction fairness across different subpopulations. We used electronic health records of 160,360 liver transplant patients, including demographic information, clinical variables, and laboratory values, collected from the liver transplant records of the United States from 1987 to 2018. The model's performance was evaluated using various performance metrics such as AUROC and AUPRC. Our experiment results highlighted the success of our multitask model in achieving task balance while maintaining accuracy. The model significantly reduced the task discrepancy by 39%. Further application of the fairness-achieving algorithm substantially reduced fairness disparity among all sensitive attributes (gender, age group, and race/ethnicity) in each risk factor.\n    ",
        "primary_category": "cs.LG",
        "categories": [],
        "submitted_date": "5 Apr 2023",
        "last_revised_date": " "
    },
    "2304.02867": {
        "title": "Voxel or Pillar: Exploring Efficient Point Cloud Representation for 3D Object Detection",
        "authors": [
            "Yuhao Huang",
            "Sanping Zhou",
            "Junjie Zhang",
            "Jinpeng Dong",
            "Nanning Zheng"
        ],
        "comments": "Accepted by AAAI-2024",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Efficient representation of point clouds is fundamental for LiDAR-based 3D object detection. While recent grid-based detectors often encode point clouds into either voxels or pillars, the distinctions between these approaches remain underexplored. In this paper, we quantify the differences between the current encoding paradigms and highlight the limited vertical learning within. To tackle these limitations, we introduce a hybrid Voxel-Pillar Fusion network (VPF), which synergistically combines the unique strengths of both voxels and pillars. Specifically, we first develop a sparse voxel-pillar encoder that encodes point clouds into voxel and pillar features through 3D and 2D sparse convolutions respectively, and then introduce the Sparse Fusion Layer (SFL), facilitating bidirectional interaction between sparse voxel and pillar features. Our efficient, fully sparse method can be seamlessly integrated into both dense and sparse detectors. Leveraging this powerful yet straightforward framework, VPF delivers competitive performance, achieving real-time inference speeds on the nuScenes and Waymo Open Dataset. The code will be available.\n    ",
        "primary_category": "cs.CV",
        "categories": [],
        "submitted_date": "6 Apr 2023",
        "last_revised_date": " "
    },
    "2304.03870": {
        "title": "ASPEST: Bridging the Gap Between Active Learning and Selective Prediction",
        "authors": [
            "Jiefeng Chen",
            "Jinsung Yoon",
            "Sayna Ebrahimi",
            "Sercan Arik",
            "Somesh Jha",
            "Tomas Pfister"
        ],
        "comments": " ",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Selective prediction aims to learn a reliable model that abstains from making predictions when uncertain. These predictions can then be deferred to humans for further evaluation. As an everlasting challenge for machine learning, in many real-world scenarios, the distribution of test data is different from the training data. This results in more inaccurate predictions, and often increased dependence on humans, which can be difficult and expensive. Active learning aims to lower the overall labeling effort, and hence human dependence, by querying the most informative examples. Selective prediction and active learning have been approached from different angles, with the connection between them missing. In this work, we introduce a new learning paradigm, active selective prediction, which aims to query more informative samples from the shifted target domain while increasing accuracy and coverage. For this new paradigm, we propose a simple yet effective approach, ASPEST, that utilizes ensembles of model snapshots with self-training with their aggregated outputs as pseudo labels. Extensive experiments on numerous image, text and structured datasets, which suffer from domain shifts, demonstrate that ASPEST can significantly outperform prior work on selective prediction and active learning (e.g. on the MNIST$\\to$SVHN benchmark with the labeling budget of 100, ASPEST improves the AUACC metric from 79.36% to 88.84%) and achieves more optimal utilization of humans in the loop.\n    ",
        "primary_category": "cs.LG",
        "categories": [],
        "submitted_date": "7 Apr 2023",
        "last_revised_date": " "
    },
    "2304.05805": {
        "title": "GDP nowcasting with artificial neural networks: How much does long-term memory matter?",
        "authors": [
            "Krist\u00f3f N\u00e9meth",
            "D\u00e1niel Hadh\u00e1zi"
        ],
        "comments": "arXiv admin note: text overlap with arXiv:2106.08901 by other authors",
        "subjects": "Econometrics (econ.EM)",
        "abstract": "We apply artificial neural networks (ANNs) to nowcast quarterly GDP growth for the U.S. economy. Using the monthly FRED-MD database, we compare the nowcasting performance of five different ANN architectures: the multilayer perceptron (MLP), the one-dimensional convolutional neural network (1D CNN), the Elman recurrent neural network (RNN), the long short-term memory network (LSTM), and the gated recurrent unit (GRU). The empirical analysis presents results from two distinctively different evaluation periods. The first (2012:Q1 -- 2019:Q4) is characterized by balanced economic growth, while the second (2012:Q1 -- 2022:Q4) also includes periods of the COVID-19 recession. According to our results, longer input sequences result in more accurate nowcasts in periods of balanced economic growth. However, this effect ceases above a relatively low threshold value of around six quarters (eighteen months). During periods of economic turbulence (e.g., during the COVID-19 recession), longer input sequences do not help the models' predictive performance; instead, they seem to weaken their generalization capability. Combined results from the two evaluation periods indicate that architectural features enabling long-term memory do not result in more accurate nowcasts. Comparing network architectures, the 1D CNN has proved to be a highly suitable model for GDP nowcasting. The network has shown good nowcasting performance among the competitors during the first evaluation period and achieved the overall best accuracy during the second evaluation period. Consequently, first in the literature, we propose the application of the 1D CNN for economic nowcasting.\n    ",
        "primary_category": "econ.EM",
        "categories": [
            "cs.AI",
            "cs.LG"
        ],
        "submitted_date": "12 Apr 2023",
        "last_revised_date": " "
    },
    "2304.06155": {
        "title": "Skyline Operators for Document Spanners",
        "authors": [
            "Antoine Amarilli",
            "Benny Kimelfeld",
            "S\u00e9bastien Labb\u00e9",
            "Stefan Mengel"
        ],
        "comments": "42 pages. This is the full version of the ICDT'24 publication, which includes all reviewer feedback; the main body is identical to the ICDT'24 article up to minor changes",
        "subjects": "Databases (cs.DB)",
        "abstract": "When extracting a relation of spans (intervals) from a text document, a common practice is to filter out tuples of the relation that are deemed dominated by others. The domination rule is defined as a partial order that varies along different systems and tasks. For example, we may state that a tuple is dominated by tuples which extend it by assigning additional attributes, or assigning larger intervals. The result of filtering the relation would then be the skyline according to this partial order. As this filtering may remove most of the extracted tuples, we study whether we can improve the performance of the extraction by compiling the domination rule into the extractor.\nTo this aim, we introduce the skyline operator for declarative information extraction tasks expressed as document spanners. We show that this operator can be expressed via regular operations when the domination partial order can itself be expressed as a regular spanner, which covers several natural domination rules. Yet, we show that the skyline operator incurs a computational cost (under combined complexity). First, there are cases where the operator requires an exponential blowup on the number of states needed to represent the spanner as a sequential variable-set automaton. Second, the evaluation may become computationally hard. Our analysis more precisely identifies classes of domination rules for which the combined complexity is tractable or intractable.\n    ",
        "primary_category": "cs.DB",
        "categories": [
            "cs.FL"
        ],
        "submitted_date": "12 Apr 2023",
        "last_revised_date": " "
    },
    "2304.08718": {
        "title": "Generalized Implicit Factorization Problem",
        "authors": [
            "Yansong Feng",
            "Abderrahmane Nitaj",
            "Yanbin Pan"
        ],
        "comments": " ",
        "subjects": "Cryptography and Security (cs.CR)",
        "abstract": "The Implicit Factorization Problem was first introduced by May and Ritzenhofen at PKC'09. This problem aims to factorize two RSA moduli $N_1=p_1q_1$ and $N_2=p_2q_2$ when their prime factors share a certain number of least significant bits (LSBs). They proposed a lattice-based algorithm to tackle this problem and extended it to cover $k>2$ RSA moduli. Since then, several variations of the Implicit Factorization Problem have been studied, including the cases where $p_1$ and $p_2$ share some most significant bits (MSBs), middle bits, or both MSBs and LSBs at the same position.\nIn this paper, we explore a more general case of the Implicit Factorization Problem, where the shared bits are located at different and unknown positions for different primes. We propose a lattice-based algorithm and analyze its efficiency under certain conditions. We also present experimental results to support our analysis.\n    ",
        "primary_category": "cs.CR",
        "categories": [],
        "submitted_date": "18 Apr 2023",
        "last_revised_date": " "
    },
    "2304.09248": {
        "title": "Real-Time Helmet Violation Detection in AI City Challenge 2023 with Genetic Algorithm-Enhanced YOLOv5",
        "authors": [
            "Elham Soltanikazemi",
            "Ashwin Dhakal",
            "Bijaya Kumar Hatuwal",
            "Imad Eddine Toubal",
            "Armstrong Aboah",
            "Kannappan Palaniappan"
        ],
        "comments": " ",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "This research focuses on real-time surveillance systems as a means for tackling the issue of non-compliance with helmet regulations, a practice that considerably amplifies the risk for motorcycle drivers or riders. Despite the well-established advantages of helmet usage, achieving widespread compliance remains challenging due to diverse contributing factors. To effectively address this concern, real-time monitoring and enforcement of helmet laws have been proposed as a plausible solution. However, previous attempts at real-time helmet violation detection have been hindered by their limited ability to operate in real-time. To overcome this limitation, the current paper introduces a novel real-time helmet violation detection system that utilizes the YOLOv5 single-stage object detection model. This model is trained on the 2023 NVIDIA AI City Challenge 2023 Track 5 dataset. The optimal hyperparameters for training the model are determined using genetic algorithms. Additionally, data augmentation and various sampling techniques are implemented to enhance the model's performance. The efficacy of the models is evaluated using precision, recall, and mean Average Precision (mAP) metrics. The results demonstrate impressive precision, recall, and mAP scores of 0.848, 0.599, and 0.641, respectively for the training data. Furthermore, the model achieves notable mAP score of 0.6667 for the test datasets, leading to a commendable 4th place rank in the public leaderboard. This innovative approach represents a notable breakthrough in the field and holds immense potential to substantially enhance motorcycle safety. By enabling real-time monitoring and enforcement capabilities, this system has the capacity to contribute towards increased compliance with helmet laws, thereby effectively reducing the risks faced by motorcycle riders and passengers.\n    ",
        "primary_category": "cs.CV",
        "categories": [],
        "submitted_date": "13 Apr 2023",
        "last_revised_date": " "
    },
    "2304.09485": {
        "title": "Implicit high-order gas-kinetic schemes for compressible flows on three-dimensional unstructured meshes I: steady flows",
        "authors": [
            "Yaqing Yang",
            "Liang Pan",
            "Kun Xu"
        ],
        "comments": "arXiv admin note: text overlap with arXiv:2203.09047",
        "subjects": "Numerical Analysis (math.NA)",
        "abstract": "In the previous studies, the high-order gas-kinetic schemes (HGKS) have achieved successes for unsteady flows on three-dimensional unstructured meshes. In this paper, to accelerate the rate of convergence for steady flows, the implicit non-compact and compact HGKSs are developed. For non-compact scheme, the simple weighted essentially non-oscillatory (WENO) reconstruction is used to achieve the spatial accuracy, where the stencils for reconstruction contain two levels of neighboring cells. Incorporate with the nonlinear generalized minimal residual (GMRES) method, the implicit non-compact HGKS is developed. In order to improve the resolution and parallelism of non-compact HGKS, the implicit compact HGKS is developed with Hermite WENO (HWENO) reconstruction, in which the reconstruction stencils only contain one level of neighboring cells. The cell averaged conservative variable is also updated with GMRES method. Simultaneously, a simple strategy is used to update the cell averaged gradient by the time evolution of spatial-temporal coupled gas distribution function. To accelerate the computation, the implicit non-compact and compact HGKSs are implemented with the graphics processing unit (GPU) using compute unified device architecture (CUDA). A variety of numerical examples, from the subsonic to supersonic flows, are presented to validate the accuracy, robustness and efficiency of both inviscid and viscous flows.\n    ",
        "primary_category": "math.NA",
        "categories": [],
        "submitted_date": "19 Apr 2023",
        "last_revised_date": " "
    },
    "2304.09914": {
        "title": "The Face of Populism: Examining Differences in Facial Emotional Expressions of Political Leaders Using Machine Learning",
        "authors": [
            "Sara Major",
            "Aleksandar Toma\u0161evi\u0107"
        ],
        "comments": "Version 3.0: Improved discussion related to the limitations of the study",
        "subjects": "Computers and Society (cs.CY)",
        "abstract": "Online media has revolutionized the way political information is disseminated and consumed on a global scale, and this shift has compelled political figures to adopt new strategies of capturing and retaining voter attention. These strategies often rely on emotional persuasion and appeal, and as visual content becomes increasingly prevalent in virtual space, much of political communication too has come to be marked by evocative video content and imagery. The present paper offers a novel approach to analyzing material of this kind. We apply a deep-learning-based computer-vision algorithm to a sample of 220 YouTube videos depicting political leaders from 15 different countries, which is based on an existing trained convolutional neural network architecture provided by the Python library fer. The algorithm returns emotion scores representing the relative presence of 6 emotional states (anger, disgust, fear, happiness, sadness, and surprise) and a neutral expression for each frame of the processed YouTube video. We observe statistically significant differences in the average score of expressed negative emotions between groups of leaders with varying degrees of populist rhetoric as defined by the Global Party Survey (GPS), indicating that populist leaders tend to express negative emotions to a greater extent during their public performance than their non-populist counterparts. Overall, our contribution provides insight into the characteristics of visual self-representation among political leaders, as well as an open-source workflow for further computational studies of their non-verbal communication.\n    ",
        "primary_category": "cs.CY",
        "categories": [
            "cs.CV",
            "cs.LG",
            "cs.SI",
            "physics.soc-ph"
        ],
        "submitted_date": "19 Apr 2023",
        "last_revised_date": " "
    },
    "2304.10398": {
        "title": "Multi-label Node Classification On Graph-Structured Data",
        "authors": [
            "Tianqi Zhao",
            "Ngan Thi Dong",
            "Alan Hanjalic",
            "Megha Khosla"
        ],
        "comments": "Published in TMLR 2023. Link: this https URL",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Graph Neural Networks (GNNs) have shown state-of-the-art improvements in node classification tasks on graphs. While these improvements have been largely demonstrated in a multi-class classification scenario, a more general and realistic scenario in which each node could have multiple labels has so far received little attention. The first challenge in conducting focused studies on multi-label node classification is the limited number of publicly available multi-label graph datasets. Therefore, as our first contribution, we collect and release three real-world biological datasets and develop a multi-label graph generator to generate datasets with tunable properties. While high label similarity (high homophily) is usually attributed to the success of GNNs, we argue that a multi-label scenario does not follow the usual semantics of homophily and heterophily so far defined for a multi-class scenario. As our second contribution, we define homophily and Cross-Class Neighborhood Similarity for the multi-label scenario and provide a thorough analyses of the collected $9$ multi-label datasets. Finally, we perform a large-scale comparative study with $8$ methods and $9$ datasets and analyse the performances of the methods to assess the progress made by current state of the art in the multi-label node classification scenario. We release our benchmark at this https URL.\n    ",
        "primary_category": "cs.LG",
        "categories": [],
        "submitted_date": "20 Apr 2023",
        "last_revised_date": " "
    },
    "2304.10899": {
        "title": "Electromechanical memcapacitive neurons for energy-efficient spiking neural networks",
        "authors": [
            "Zixi Zhang",
            "Yuriy V. Pershin",
            "Ivar Martin"
        ],
        "comments": " ",
        "subjects": "Emerging Technologies (cs.ET)",
        "abstract": "In this article, we introduce a new nanoscale electromechanical device -- a leaky memcapacitor -- and show that it may be useful for the hardware implementation of spiking neurons. The leaky memcapacitor is a movable-plate capacitor that becomes quite conductive when the plates come close to each other. The equivalent circuit of the leaky memcapacitor involves a memcapacitive and memristive system connected in parallel. In the leaky memcapacitor, the resistance and capacitance depend on the same internal state variable, which is the displacement of the movable plate. We have performed a comprehensive analysis showing that several spiking types observed in biological neurons can be implemented with the leaky memcapacitor. Significant attention is paid to the dynamic properties of the model. As in leaky memcapacitors the capacitive and leaking resistive functionalities are implemented naturally within the same device structure, their use will simplify the creation of spiking neural networks.\n    ",
        "primary_category": "cs.ET",
        "categories": [
            "cond-mat.mes-hall"
        ],
        "submitted_date": "21 Apr 2023",
        "last_revised_date": " "
    },
    "2304.10921": {
        "title": "Gradient-Based Distributed Controller Design Over Directed Networks",
        "authors": [
            "Yuto Watanabe",
            "Kazunori Sakurama",
            "Hyo-Sung Ahn"
        ],
        "comments": "13 pages. this https URL",
        "subjects": "Systems and Control (eess.SY)",
        "abstract": "In this study, we propose a design methodology of distributed controllers for multi-agent systems on a class of directed interaction networks by extending the gradient-flow method. Although the gradient-flow method is a common design tool for distributed controllers, it is inapplicable to directed networks. First, we demonstrate how to construct a distributed controller for systems over a class of time-invariant directed graphs. Subsequently, we establish better convergence properties and performance enhancement than the conventional gradient-flow method. To illustrate its application in time-varying networks, we address the dynamic matching problem of two distinct groups of agents with different sensing ranges. This problem is a novel coordination task that involves pairing agents from two distinct groups to achieve a convergence of the paired agents' states to the same value. Accordingly, we apply the proposed method to this problem and provide sufficient conditions for successful matching. Lastly, numerical examples for systems on both time-invariant and time-varying networks demonstrate the effectiveness of the proposed method.\n    ",
        "primary_category": "eess.SY",
        "categories": [],
        "submitted_date": "21 Apr 2023",
        "last_revised_date": " "
    },
    "2304.13120": {
        "title": "Precision Spectroscopy of Fast, Hot Exotic Isotopes Using Machine Learning Assisted Event-by-Event Doppler Correction",
        "authors": [
            "Silviu-Marian Udrescu",
            "Diego Alejandro Torres",
            "Ronald Fernando Garcia Ruiz"
        ],
        "comments": " ",
        "subjects": "Nuclear Experiment (nucl-ex)",
        "abstract": "We propose an experimental scheme for performing sensitive, high-precision laser spectroscopy studies on fast exotic isotopes. By inducing a step-wise resonant ionization of the atoms travelling inside an electric field and subsequently detecting the ion and the corresponding electron, time- and position-sensitive measurements of the resulting particles can be performed. Using a Mixture Density Network (MDN), we can leverage this information to predict the initial energy of individual atoms and thus apply a Doppler correction of the observed transition frequencies on an event-by-event basis. We conduct numerical simulations of the proposed experimental scheme and show that kHz-level uncertainties can be achieved for ion beams produced at extreme temperatures ($> 10^8$ K), with energy spreads as large as $10$ keV and non-uniform velocity distributions. The ability to perform in-flight spectroscopy, directly on highly energetic beams, offers unique opportunities to studying short-lived isotopes with lifetimes in the millisecond range and below, produced in low quantities, in hot and highly contaminated environments, without the need for cooling techniques. Such species are of marked interest for nuclear structure, astrophysics, and new physics searches.\n    ",
        "primary_category": "nucl-ex",
        "categories": [
            "cs.AI",
            "cs.LG",
            "physics.atom-ph",
            "physics.comp-ph"
        ],
        "submitted_date": "25 Apr 2023",
        "last_revised_date": " "
    },
    "2304.14614": {
        "title": "Fusion is Not Enough: Single Modal Attacks on Fusion Models for 3D Object Detection",
        "authors": [
            "Zhiyuan Cheng",
            "Hongjun Choi",
            "James Liang",
            "Shiwei Feng",
            "Guanhong Tao",
            "Dongfang Liu",
            "Michael Zuzak",
            "Xiangyu Zhang"
        ],
        "comments": "Accepted at ICLR'2024",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Multi-sensor fusion (MSF) is widely used in autonomous vehicles (AVs) for perception, particularly for 3D object detection with camera and LiDAR sensors. The purpose of fusion is to capitalize on the advantages of each modality while minimizing its weaknesses. Advanced deep neural network (DNN)-based fusion techniques have demonstrated the exceptional and industry-leading performance. Due to the redundant information in multiple modalities, MSF is also recognized as a general defence strategy against adversarial attacks. In this paper, we attack fusion models from the camera modality that is considered to be of lesser importance in fusion but is more affordable for attackers. We argue that the weakest link of fusion models depends on their most vulnerable modality, and propose an attack framework that targets advanced camera-LiDAR fusion-based 3D object detection models through camera-only adversarial attacks. Our approach employs a two-stage optimization-based strategy that first thoroughly evaluates vulnerable image areas under adversarial attacks, and then applies dedicated attack strategies for different fusion models to generate deployable patches. The evaluations with six advanced camera-LiDAR fusion models and one camera-only model indicate that our attacks successfully compromise all of them. Our approach can either decrease the mean average precision (mAP) of detection performance from 0.824 to 0.353, or degrade the detection score of a target object from 0.728 to 0.156, demonstrating the efficacy of our proposed attack framework. Code is available.\n    ",
        "primary_category": "cs.CV",
        "categories": [
            "cs.CR"
        ],
        "submitted_date": "28 Apr 2023",
        "last_revised_date": " "
    },
    "2304.14701": {
        "title": "Permissionless Consensus",
        "authors": [
            "Andrew Lewis-Pye",
            "Tim Roughgarden"
        ],
        "comments": "This is a journal version of the paper that subsumes earlier (conference) versions \"Byzantine Generals in the Permissionless Setting\" and \"Resource Pools and the CAP Theorem\"",
        "subjects": "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "abstract": "Blockchain protocols typically aspire to run in the permissionless setting, in which nodes are owned and operated by a large number of diverse and unknown entities, with each node free to start or stop running the protocol at any time. This setting is more challenging than the traditional permissioned setting, in which the set of nodes that will be running the protocol is fixed and known at the time of protocol deployment. The goal of this paper is to provide a framework for reasoning about the rich design space of blockchain protocols and their capabilities and limitations in the permissionless setting.\nWe propose a hierarchy of settings with different \"degrees of permissionlessness\", specified by the amount of knowledge that a protocol has about the current participants: These are the fully permissionless, dynamically available and quasi-permissionless settings.\nThe paper also proves several results illustrating the utility of our analysis framework for reasoning about blockchain protocols in these settings. For example:\n(1) In the fully permissionless setting, even with synchronous communication and with severe restrictions on the total size of the Byzantine players, every deterministic protocol for Byzantine agreement has a non-terminating execution.\n(2) In the dynamically available and partially synchronous setting, no protocol can solve the Byzantine agreement problem with high probability, even if there are no Byzantine players at all.\n(3) In the quasi-permissionless and partially synchronous setting, by contrast, assuming a bound on the total size of the Byzantine players, there is a deterministic protocol solving state machine replication.\n(4) In the quasi-permissionless and synchronous setting, every proof-of-stake state machine replication protocol that uses only time-malleable cryptographic primitives is vulnerable to long-range attacks.\n    ",
        "primary_category": "cs.DC",
        "categories": [],
        "submitted_date": "28 Apr 2023",
        "last_revised_date": " "
    },
    "2305.00188": {
        "title": "New Characterizations and Efficient Local Search for General Integer Linear Programming",
        "authors": [
            "Peng Lin",
            "Shaowei Cai",
            "Mengchuan Zou",
            "Jinkun Lin"
        ],
        "comments": " ",
        "subjects": "Optimization and Control (math.OC)",
        "abstract": "Integer linear programming (ILP) models a wide range of practical combinatorial optimization problems and significantly impacts industry and management sectors. This work proposes new characterizations of ILP with the concept of boundary solutions. Motivated by the new characterizations, we develop a new local search algorithm Local-ILP, which is efficient for solving general ILP validated on a large heterogeneous problem dataset. We propose a new local search framework that switches between three modes, namely Search, Improve, and Restore modes. Two new operators are proposed, namely the tight move and the lift move operators, which are associated with appropriate scoring functions. Different modes apply different operators to realize different search strategies and the algorithm switches between three modes according to the current search state. Putting these together, we develop a local search ILP solver called Local-ILP. Experiments conducted on the MIPLIB dataset show the effectiveness of our algorithm in solving large-scale hard ILP problems. In the aspect of finding a good feasible solution quickly, Local-ILP is competitive and complementary to the state-of-the-art commercial solver Gurobi and significantly outperforms the state-of-the-art non-commercial solver SCIP. Moreover, our algorithm establishes new records for 6 MIPLIB open instances. The theoretical analysis of our algorithm is also presented, which shows our algorithm could avoid visiting unnecessary regions.\n    ",
        "primary_category": "math.OC",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "29 Apr 2023",
        "last_revised_date": " "
    },
    "2305.02215": {
        "title": "Exploring Linguistic Properties of Monolingual BERTs with Typological Classification among Languages",
        "authors": [
            "Elena Sofia Ruzzetti",
            "Federico Ranaldi",
            "Felicia Logozzo",
            "Michele Mastromattei",
            "Leonardo Ranaldi",
            "Fabio Massimo Zanzotto"
        ],
        "comments": " ",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "The impressive achievements of transformers force NLP researchers to delve into how these models represent the underlying structure of natural language. In this paper, we propose a novel standpoint to investigate the above issue: using typological similarities among languages to observe how their respective monolingual models encode structural information. We aim to layer-wise compare transformers for typologically similar languages to observe whether these similarities emerge for particular layers. For this investigation, we propose to use Centered Kernel Alignment to measure similarity among weight matrices. We found that syntactic typological similarity is consistent with the similarity between the weights in the middle layers, which are the pretrained BERT layers to which syntax encoding is generally attributed. Moreover, we observe that a domain adaptation on semantically equivalent texts enhances this similarity among weight matrices.\n    ",
        "primary_category": "cs.CL",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "3 May 2023",
        "last_revised_date": " "
    },
    "2305.02337": {
        "title": "Towards Hamiltonian Simulation with Decision Diagrams",
        "authors": [
            "Aaron Sander",
            "Lukas Burgholzer",
            "Robert Wille"
        ],
        "comments": "12 pages, 4 figures",
        "subjects": "Quantum Physics (quant-ph)",
        "abstract": "This paper proposes a novel approach to Hamiltonian simulation using Decision Diagrams (DDs), which are an exact representation based on exploiting redundancies in representations of quantum states and operations. While the simulation of Hamiltonians has been studied extensively, scaling these simulations to larger or more complex systems is often challenging and may require approximations or new simulation methods altogether. DDs offer such an alternative that has not yet been applied to Hamiltonian simulation. In this work, we investigate the behavior of DDs for this task. To this end, we review the basics of DDs such as their construction and present how the relevant operations for Hamiltonian simulation are implemented in this data structure -- leading to the first DD-based Hamiltonian simulation approach. Based on several series of evaluations and comparisons, we then discuss insights about the performance of this complementary approach. Overall, these studies show that DDs indeed may offer a promising new data structure which, for certain examples, can provide orders of magnitudes of improvement compared to the state-of-the-art, yet also comes with its own, fundamentally different, limitations.\n    ",
        "primary_category": "quant-ph",
        "categories": [
            "cond-mat.other",
            "cs.ET"
        ],
        "submitted_date": "3 May 2023",
        "last_revised_date": " "
    },
    "2305.02483": {
        "title": "Personalized Abstractive Summarization by Tri-agent Generation Pipeline",
        "authors": [
            "Wen Xiao",
            "Yujia Xie",
            "Giuseppe Carenini",
            "Pengcheng He"
        ],
        "comments": "Accepted at EACL 2024 Findings",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "Tailoring outputs from large language models, like ChatGPT, to implicit user preferences remains a challenge despite their impressive generative capabilities. In this paper, we propose a tri-agent generation pipeline comprising a generator, an instructor, and an editor to enhance output personalization. The generator produces an initial output, the instructor automatically generates editing instructions based on user preferences, and the editor refines the output to align with those preferences. The inference-only large language model (ChatGPT) serves as both the generator and editor, with a smaller model acting as the instructor to guide output generation. We train the instructor using editor-steered reinforcement learning, leveraging feedback from a large-scale editor model to optimize instruction generation. Experimental results on two abstractive summarization datasets demonstrate the effectiveness of our approach in generating outputs that better meet user expectations. Code is available at \\url{this https URL}\n    ",
        "primary_category": "cs.CL",
        "categories": [],
        "submitted_date": "4 May 2023",
        "last_revised_date": " "
    },
    "2305.02531": {
        "title": "Can LLMs Capture Human Preferences?",
        "authors": [
            "Ali Goli",
            "Amandeep Singh"
        ],
        "comments": " ",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "We explore the viability of Large Language Models (LLMs), specifically OpenAI's GPT-3.5 and GPT-4, in emulating human survey respondents and eliciting preferences, with a focus on intertemporal choices. Leveraging the extensive literature on intertemporal discounting for benchmarking, we examine responses from LLMs across various languages and compare them to human responses, exploring preferences between smaller, sooner, and larger, later rewards. Our findings reveal that both GPT models demonstrate less patience than humans, with GPT-3.5 exhibiting a lexicographic preference for earlier rewards, unlike human decision-makers. Though GPT-4 does not display lexicographic preferences, its measured discount rates are still considerably larger than those found in humans. Interestingly, GPT models show greater patience in languages with weak future tense references, such as German and Mandarin, aligning with existing literature that suggests a correlation between language structure and intertemporal preferences. We demonstrate how prompting GPT to explain its decisions, a procedure we term \"chain-of-thought conjoint,\" can mitigate, but does not eliminate, discrepancies between LLM and human responses. While directly eliciting preferences using LLMs may yield misleading results, combining chain-of-thought conjoint with topic modeling aids in hypothesis generation, enabling researchers to explore the underpinnings of preferences. Chain-of-thought conjoint provides a structured framework for marketers to use LLMs to identify potential attributes or factors that can explain preference heterogeneity across different customers and contexts.\n    ",
        "primary_category": "cs.CL",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "4 May 2023",
        "last_revised_date": " "
    },
    "2305.03086": {
        "title": "Inverse scattering of periodic surfaces with a superlens",
        "authors": [
            "Peijun Li",
            "Yuliang Wang"
        ],
        "comments": "17 pages, 6 figures",
        "subjects": "Numerical Analysis (math.NA)",
        "abstract": "We propose a scheme for imaging periodic surfaces using a superlens. By employing an inverse scattering model and the transformed field expansion method, we derive an approximate reconstruction formula for the surface profile, assuming small amplitude. This formula suggests that unlimited resolution can be achieved for the linearized inverse problem with perfectly matched parameters. Our method requires only a single incident wave at a fixed frequency and can be efficiently implemented using fast Fourier transform. Through numerical experiments, we demonstrate that our method achieves resolution significantly surpassing the resolution limit for both smooth and non-smooth surface profiles with either perfect or marginally imperfect parameters.\n    ",
        "primary_category": "math.NA",
        "categories": [
            "math.AP"
        ],
        "submitted_date": "4 May 2023",
        "last_revised_date": " "
    },
    "2305.03556": {
        "title": "Energy-Latency Aware Intelligent Reflecting Surface Aided Multi-cell Mobile Edge Computing",
        "authors": [
            "Wenhan Xu",
            "Jiadong Yu",
            "Yuan Wu",
            "Danny H.K. Tsang"
        ],
        "comments": "This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible",
        "subjects": "Networking and Internet Architecture (cs.NI)",
        "abstract": "The explosive development of the Internet of Things (IoT) has led to increased interest in mobile edge computing (MEC), which provides computational resources at network edges to accommodate computation-intensive and latency-sensitive applications. Intelligent reflecting surfaces (IRSs) have gained attention as a solution to overcome blockage problems during the offloading uplink transmission in MEC systems. This paper explores IRS-aided multi-cell networks that enable servers to serve neighboring cells and cooperate to handle resource exhaustion. We aim to minimize the joint energy and latency cost, by jointly optimizing computation tasks, edge computing resources, user beamforming, and IRS phase shifts. The problem is decomposed into two subproblems--the MEC subproblem and the IRS communication subproblem--using the block coordinate descent (BCD) technique. The MEC subproblem is reformulated as a nonconvex quadratic constrained problem (QCP), while the IRS communication subproblem is transformed into a weight-sum-rate problem with auxiliary variables. We propose an efficient algorithm to iteratively optimize MEC resources and IRS communication until convergence. Numerical results show that our algorithm outperforms benchmarks and that multi-cell MEC systems achieve additional performance gains when supported by IRS.\n    ",
        "primary_category": "cs.NI",
        "categories": [],
        "submitted_date": "5 May 2023",
        "last_revised_date": " "
    },
    "2305.04440": {
        "title": "Vision Transformer Off-the-Shelf: A Surprising Baseline for Few-Shot Class-Agnostic Counting",
        "authors": [
            "Zhicheng Wang",
            "Liwen Xiao",
            "Zhiguo Cao",
            "Hao Lu"
        ],
        "comments": " ",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Class-agnostic counting (CAC) aims to count objects of interest from a query image given few exemplars. This task is typically addressed by extracting the features of query image and exemplars respectively and then matching their feature similarity, leading to an extract-then-match paradigm. In this work, we show that CAC can be simplified in an extract-and-match manner, particularly using a vision transformer (ViT) where feature extraction and similarity matching are executed simultaneously within the self-attention. We reveal the rationale of such simplification from a decoupled view of the self-attention. The resulting model, termed CACViT, simplifies the CAC pipeline into a single pretrained plain ViT. Further, to compensate the loss of the scale and the order-of-magnitude information due to resizing and normalization in plain ViT, we present two effective strategies for scale and magnitude embedding. Extensive experiments on the FSC147 and the CARPK datasets show that CACViT significantly outperforms state-of-the art CAC approaches in both effectiveness (23.60% error reduction) and generalization, which suggests CACViT provides a concise and strong baseline for CAC. Code will be available.\n    ",
        "primary_category": "cs.CV",
        "categories": [],
        "submitted_date": "8 May 2023",
        "last_revised_date": " "
    },
    "2305.04447": {
        "title": "Neural Steerer: Novel Steering Vector Synthesis with a Causal Neural Field over Frequency and Source Positions",
        "authors": [
            "Diego Di Carlo",
            "Aditya Arie Nugraha",
            "Mathieu Fontaine",
            "Mathieu Fontaine",
            "Kazuyoshi Yoshii"
        ],
        "comments": "Camera ready version for HSCMA 24 at ICASSP 24",
        "subjects": "Audio and Speech Processing (eess.AS)",
        "abstract": "We address the problem of accurately interpolating measured anechoic steering vectors with a deep learning framework called the neural field. This task plays a pivotal role in reducing the resource-intensive measurements required for precise sound source separation and localization, essential as the front-end of speech recognition. Classical approaches to interpolation rely on linear weighting of nearby measurements in space on a fixed, discrete set of frequencies. Drawing inspiration from the success of neural fields for novel view synthesis in computer vision, we introduce the neural steerer, a continuous complex-valued function that takes both frequency and direction as input and produces the corresponding steering vector. Importantly, it incorporates inter-channel phase difference information and a regularization term enforcing filter causality, essential for accurate steering vector modeling. Our experiments, conducted using a dataset of real measured steering vectors, demonstrate the effectiveness of our resolution-free model in interpolating such measurements.\n    ",
        "primary_category": "eess.AS",
        "categories": [
            "cs.SD"
        ],
        "submitted_date": "8 May 2023",
        "last_revised_date": " "
    },
    "2305.04666": {
        "title": "Power Distribution Grid Enhancement via Online Feedback Optimization",
        "authors": [
            "Jonas G. Matt",
            "Lukas Ortmann",
            "Saverio Bolognani",
            "Florian D\u00f6rfler"
        ],
        "comments": " ",
        "subjects": "Systems and Control (eess.SY)",
        "abstract": "The rise in residential photovoltaics and other distributed energy sources poses unprecedented challenges for the operation of power distribution grids. When high amounts of active power are injected into the grid by such power sources, the overall power flow is often limited because of voltages reaching their upper acceptable limits. Volt/VAr control aims to raise this power flow limit by controlling the voltage using reactive power. This way, more active power can be transmitted safely without physically reinforcing the grid. In this paper, we use real consumption and generation data on a low-voltage CIGR\u00c9 grid model and an experiment on a real distribution grid feeder to analyze how different Volt/VAr methods can enhance grid capacity, i.e., by how much they can improve the grid's capability to transmit active power without building new lines. We show that droop control enhances the grid but vastly underutilizes the reactive power resources. We discuss how the effectiveness of droop control can be partially improved by employing machine-learning techniques to tune the droop coefficients, but we demonstrate that local control laws are inherently unable to achieve optimal grid enhancement. In contrast, methods that coordinate the use of reactive power resources across the grid, such as Online Feedback Optimization (OFO), can enhance the grid to its full potential. A numerical study performed on data from an entire year using a realistic grid model suggests that OFO can enable another 9\\% of maximum active power injections compared to droop control. To achieve that, OFO only requires voltage magnitude measurements, minimal model knowledge, and communication with the reactive power sources. A real-life experiment provides a demonstration of the practical feasibility of the proposed approach and enhanced the grid by another 10.5\\% compared to droop control.\n    ",
        "primary_category": "eess.SY",
        "categories": [],
        "submitted_date": "8 May 2023",
        "last_revised_date": " "
    },
    "2305.06548": {
        "title": "Layered Modal Type Theories",
        "authors": [
            "Jason Z. S. Hu",
            "Brigitte Pientka"
        ],
        "comments": " ",
        "subjects": "Logic in Computer Science (cs.LO)",
        "abstract": "We introduce layers to modal type theories, which subsequently enables type theories for pattern matching on code in meta-programming and clean and straightforward semantics.\n    ",
        "primary_category": "cs.LO",
        "categories": [
            "cs.PL"
        ],
        "submitted_date": "11 May 2023",
        "last_revised_date": " "
    },
    "2305.07451": {
        "title": "Automata with Timers",
        "authors": [
            "V\u00e9ronique Bruy\u00e8re",
            "Guillermo A. P\u00e9rez",
            "Ga\u00ebtan Staquet",
            "Frits W. Vaandrager"
        ],
        "comments": "35 pages, 9 figures",
        "subjects": "Formal Languages and Automata Theory (cs.FL)",
        "abstract": "In this work, we study properties of deterministic finite-state automata with timers, a subclass of timed automata proposed by Vaandrager et al. as a candidate for an efficiently learnable timed model. We first study the complexity of the configuration reachability problem for such automata and establish that it is PSPACE-complete. Then, as simultaneous timeouts (we call these, races) can occur in timed runs of such automata, we study the problem of determining whether it is possible to modify the delays between the actions in a run, in a way to avoid such races. The absence of races is important for modelling purposes and to streamline learning of automata with timers. We provide an effective characterization of when an automaton is race-avoiding and establish that the related decision problem is in 3EXP and PSPACE-hard.\n    ",
        "primary_category": "cs.FL",
        "categories": [],
        "submitted_date": "12 May 2023",
        "last_revised_date": " "
    },
    "2305.07912": {
        "title": "Pre-trained Language Model with Prompts for Temporal Knowledge Graph Completion",
        "authors": [
            "Wenjie Xu",
            "Ben Liu",
            "Miao Peng",
            "Xu Jia",
            "Min Peng"
        ],
        "comments": "Accepted to Findings of ACL 2023",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "Temporal Knowledge graph completion (TKGC) is a crucial task that involves reasoning at known timestamps to complete the missing part of facts and has attracted more and more attention in recent years. Most existing methods focus on learning representations based on graph neural networks while inaccurately extracting information from timestamps and insufficiently utilizing the implied information in relations. To address these problems, we propose a novel TKGC model, namely Pre-trained Language Model with Prompts for TKGC (PPT). We convert a series of sampled quadruples into pre-trained language model inputs and convert intervals between timestamps into different prompts to make coherent sentences with implicit semantic information. We train our model with a masking strategy to convert TKGC task into a masked token prediction task, which can leverage the semantic information in pre-trained language models. Experiments on three benchmark datasets and extensive analysis demonstrate that our model has great competitiveness compared to other models with four metrics. Our model can effectively incorporate information from temporal knowledge graphs into the language models.\n    ",
        "primary_category": "cs.CL",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "13 May 2023",
        "last_revised_date": " "
    },
    "2305.08381": {
        "title": "Parameter-efficient Tuning of Large-scale Multimodal Foundation Model",
        "authors": [
            "Haixin Wang",
            "Xinlong Yang",
            "Jianlong Chang",
            "Dian Jin",
            "Jinan Sun",
            "Shikun Zhang",
            "Xiao Luo",
            "Qi Tian"
        ],
        "comments": "Accepted by NeurIPS2023",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Driven by the progress of large-scale pre-training, parameter-efficient transfer learning has gained immense popularity across different subfields of Artificial Intelligence. The core is to adapt the model to downstream tasks with only a small set of parameters. Recently, researchers have leveraged such proven techniques in multimodal tasks and achieve promising results. However, two critical issues remain unresolved: how to further reduce the complexity with lightweight design and how to boost alignment between modalities under extremely low parameters. In this paper, we propose A graceful prompt framework for cross-modal transfer (Aurora) to overcome these challenges. Considering the redundancy in existing architectures, we first utilize the mode approximation to generate 0.1M trainable parameters to implement the multimodal prompt tuning, which explores the low intrinsic dimension with only 0.04% parameters of the pre-trained model. Then, for better modality alignment, we propose the Informative Context Enhancement and Gated Query Transformation module under extremely few parameters scenes. A thorough evaluation on six cross-modal benchmarks shows that it not only outperforms the state-of-the-art but even outperforms the full fine-tuning approach. Our code is available at: this https URL.\n    ",
        "primary_category": "cs.CV",
        "categories": [],
        "submitted_date": "15 May 2023",
        "last_revised_date": " "
    },
    "2305.08460": {
        "title": "Selective Population Protocols",
        "authors": [
            "Adam Ga\u0144czorz",
            "Leszek G\u0105sieniec",
            "Tomasz Jurdzi\u0144ski",
            "Jakub Kowalski",
            "Grzegorz Stachowiak"
        ],
        "comments": " ",
        "subjects": "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "abstract": "The model of population protocols provides a universal platform to study distributed processes driven by pairwise interactions of anonymous agents. While population protocols present an elegant and robust model for randomized distributed computation, their efficiency wanes when tackling issues that require more focused communication or the execution of multiple processes. To address this issue, we propose a new, selective variant of population protocols by introducing a partition of the state space and the corresponding conditional selection of responders. We demonstrate on several examples that the new model offers a natural environment, complete with tools and a high-level description, to facilitate more efficient solutions.\nIn particular, we provide fixed-state stable and efficient solutions to two central problems: leader election and majority computation, both with confirmation. This constitutes a separation result, as achieving stable and efficient majority computation requires $\\Omega(\\log n)$ states in standard population protocols, even when the leader is already determined. Additionally, we explore the computation of the median using the comparison model, where the operational state space of agents is fixed, and the transition function determines the order between (arbitrarily large) hidden keys associated with interacting agents. Our findings reveal that the computation of the median of $n$ numbers requires $\\Omega(n)$ time. Moreover, we demonstrate that the problem can be solved in $O(n\\log n)$ time, both in expectation and with high probability, in standard population protocols. In contrast, we establish that a feasible solution in selective population protocols can be achieved in $O(\\log^4 n)$ time.\n    ",
        "primary_category": "cs.DC",
        "categories": [
            "cs.DS"
        ],
        "submitted_date": "15 May 2023",
        "last_revised_date": " "
    },
    "2305.09181": {
        "title": "(Rectified Version) Push-LSVRG-UP: Distributed Stochastic Optimization over Unbalanced Directed Networks with Uncoordinated Triggered Probabilities",
        "authors": [
            "Jinhui Hu",
            "Guo Chen",
            "Huaqing Li",
            "Zixiang Shen",
            "Weidong Zhang"
        ],
        "comments": "16 pages, 30 figures",
        "subjects": "Optimization and Control (math.OC)",
        "abstract": "Distributed stochastic optimization, arising in the crossing and integration of traditional stochastic optimization, distributed computing and storage, and network science, has advantages of high efficiency and a low per-iteration computational complexity in resolving large-scale optimization problems. This paper concentrates on resolving a large-scale convex finite-sum optimization problem in a multi-agent system over unbalanced directed networks. To tackle this problem in an efficient way, a distributed consensus optimization algorithm, adopting the push-sum technique and a distributed loopless stochastic variance-reduced gradient (LSVRG) method with uncoordinated triggered probabilities, is developed and named Push-LSVRG-UP. Each agent under this algorithmic framework performs only local computation and communicates only with its neighbors without leaking their private information. The convergence analysis of Push-LSVRG-UP is relied on analyzing the contraction relationships between four error terms associated with the multi-agent system. Theoretical results provide an explicit feasible range of the constant step-size, a linear convergence rate, and an iteration complexity of Push-LSVRG-UP when achieving the globally optimal solution. It is shown that Push-LSVRG-UP achieves the superior characteristics of accelerated linear convergence, fewer storage costs, and a lower per-iteration computational complexity than most existing works. Meanwhile, the introduction of an uncoordinated probabilistic triggered mechanism allows Push-LSVRG-UP to facilitate the independence and flexibility of agents in computing local batch gradients. In simulations, the practicability and improved performance of Push-LSVRG-UP are manifested via resolving two distributed learning problems based on real-world datasets.\n    ",
        "primary_category": "math.OC",
        "categories": [
            "eess.SY"
        ],
        "submitted_date": "16 May 2023",
        "last_revised_date": " "
    },
    "2305.09675": {
        "title": "Spatial Computing Opportunities in Biomedical Decision Support: The Atlas-EHR Vision",
        "authors": [
            "Majid Farhadloo",
            "Arun Sharma",
            "Shashi Shekhar",
            "Svetomir N. Markovic"
        ],
        "comments": " ",
        "subjects": "Computers and Society (cs.CY)",
        "abstract": "We consider the problem of reducing the time needed by healthcare professionals to understand patient medical history via the next generation of biomedical decision support. This problem is societally important because it has the potential to improve healthcare quality and patient outcomes. However, navigating electronic health records is challenging due to the high patient-doctor ratios, potentially long medical histories, the urgency of treatment for some medical conditions, and patient variability. The current electronic health record systems provides only a longitudinal view of patient medical history, which is time-consuming to browse, and doctors often need to engage nurses, residents, and others for initial analysis. To overcome this limitation, we envision an alternative spatial representation of patients' histories (e.g., electronic health records (EHRs)) and other biomedical data in the form of Atlas-EHR. Just like Google Maps allows a global, national, regional, and local view, the Atlas-EHR may start with an overview of the patient's anatomy and history before drilling down to spatially anatomical sub-systems, their individual components, or sub-components. Atlas-EHR presents a compelling opportunity for spatial computing since healthcare is almost a fifth of the US economy. However, the traditional spatial computing designed for geographic use cases (e.g., navigation, land-surveys, mapping) faces many hurdles in the biomedical domain. This paper presents a number of open research questions under this theme in five broad areas of spatial computing.\n    ",
        "primary_category": "cs.CY",
        "categories": [],
        "submitted_date": "9 May 2023",
        "last_revised_date": " "
    },
    "2305.10361": {
        "title": "Human Choice Prediction in Language-based Persuasion Games: Simulation-based Off-Policy Evaluation",
        "authors": [
            "Eilam Shapira",
            "Reut Apel",
            "Moshe Tennenholtz",
            "Roi Reichart"
        ],
        "comments": " ",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Recent advances in Large Language Models (LLMs) have spurred interest in designing LLM-based agents for tasks that involve interaction with human and artificial agents. This paper addresses a key aspect in the design of such agents: Predicting human decision in off-policy evaluation (OPE), focusing on language-based persuasion games, where the agent's goal is to influence its partner's decisions through verbal messages. Using a dedicated application, we collected a dataset of 87K decisions from humans playing a repeated decision-making game with artificial agents. Our approach involves training a model on human interactions with one agents subset to predict decisions when interacting with another. To enhance off-policy performance, we propose a simulation technique involving interactions across the entire agent space and simulated decision makers. Our learning strategy yields significant OPE gains, e.g., improving prediction accuracy in the top 15% challenging cases by 7.1%. Our code and the large dataset we collected and generated are submitted as supplementary material and publicly available in our GitHub repository: this https URL\n",
        "primary_category": "cs.LG",
        "categories": [
            "cs.AI",
            "cs.GT"
        ],
        "submitted_date": "17 May 2023",
        "last_revised_date": " "
    },
    "2305.10642": {
        "title": "Adaptive Learning based Upper-Limb Rehabilitation Training System with Collaborative Robot",
        "authors": [
            "Jun Hong Lim",
            "Kaibo He",
            "Zeji Yi",
            "Chen Hou",
            "Chen Zhang",
            "Yanan Sui",
            "Luming Li"
        ],
        "comments": " ",
        "subjects": "Human-Computer Interaction (cs.HC)",
        "abstract": "Rehabilitation training for patients with motor disabilities usually requires specialized devices in rehabilitation centers. Home-based multi-purpose training would significantly increase treatment accessibility and reduce medical costs. While it is unlikely to equip a set of rehabilitation robots at home, we investigate the feasibility to use the general-purpose collaborative robot for rehabilitation therapies. In this work, we developed a new system for multi-purpose upper-limb rehabilitation training using a generic robot arm with human motor feedback and preference. We integrated surface electromyography, force/torque sensors, RGB-D cameras, and robot controllers with the Robot Operating System to enable sensing, communication, and control of the system. Imitation learning methods were adopted to imitate expert-provided training trajectories which could adapt to subject capabilities to facilitate in-home training. Our rehabilitation system is able to perform gross motor function and fine motor skill training with a gripper-based end-effector. We simulated system control in Gazebo and training effects (muscle activation level) in OpenSim and evaluated its real performance with human subjects. For all the subjects enrolled, our system achieved better training outcomes compared to specialist-assisted rehabilitation under the same conditions. Our work demonstrates the potential of utilizing collaborative robots for in-home motor rehabilitation training.\n    ",
        "primary_category": "cs.HC",
        "categories": [],
        "submitted_date": "18 May 2023",
        "last_revised_date": " "
    },
    "2305.11461": {
        "title": "Hint of Thought prompting: an explainable and zero-shot approach to reasoning tasks with LLMs",
        "authors": [
            "Ioktong Lei",
            "Zhidong Deng"
        ],
        "comments": "preprint, under review",
        "subjects": "Artificial Intelligence (cs.AI)",
        "abstract": "As a way of communicating with users and any LLMs like GPT or PaLM2, prompting becomes an increasingly important research topic for better utilization of LLMs. Although simple prompting performs well on single-step questions, it cannot permanently activate the correct knowledge path for multi-step reasoning tasks. The chain of thought (CoT), which often contains zero-shot CoT and few-shot CoT, is a recently developed prompting method that can explain the reasoning process to the LLM and outperforms simple prompting in three challenging reasoning tasks, including arithmetic, symbolic, and commonsense reasoning. In this paper, we propose a novel hint of thought (HoT) prompting with explainability and zero-shot generalization. First, it is decomposed into the following three steps: explainable sub-questions, logical reasoning, and answer extraction. Second, such three steps are sequentially ordered in the format of step-by-step hints, which can be easily adjusted and explained to different tasks. Finally, experimental results demonstrate that our HoT prompting has a significant advantage on the zero-shot reasoning task compared to existing zero-shot CoT. We did zero-shot experiments on math tasks like GSM8K, ADDSUB, AQUA, SVAMP and commonsense tasks such as StrategyQA. In particular, the accuracy of the proposed HoT prompting is improved with GSM8K from 40.50% to 67.80%, with AQUA from 31.9% to 46.4%, with SVAMP from 63.7% to 76.9%, and with ADDSUB from 74.7% to 87.34%, respectively, which even defeats the competitive PoT approach on GSM8k, AQUA, and SVAMP.\n    ",
        "primary_category": "cs.AI",
        "categories": [],
        "submitted_date": "19 May 2023",
        "last_revised_date": " "
    },
    "2305.11468": {
        "title": "Overcoming Topology Agnosticism: Enhancing Skeleton-Based Action Recognition through Redefined Skeletal Topology Awareness",
        "authors": [
            "Yuxuan Zhou",
            "Zhi-Qi Cheng",
            "Jun-Yan He",
            "Bin Luo",
            "Yifeng Geng",
            "Xuansong Xie"
        ],
        "comments": " ",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Graph Convolutional Networks (GCNs) have long defined the state-of-the-art in skeleton-based action recognition, leveraging their ability to unravel the complex dynamics of human joint topology through the graph's adjacency matrix. However, an inherent flaw has come to light in these cutting-edge models: they tend to optimize the adjacency matrix jointly with the model weights. This process, while seemingly efficient, causes a gradual decay of bone connectivity data, culminating in a model indifferent to the very topology it sought to map. As a remedy, we propose a threefold strategy: (1) We forge an innovative pathway that encodes bone connectivity by harnessing the power of graph distances. This approach preserves the vital topological nuances often lost in conventional GCNs. (2) We highlight an oft-overlooked feature - the temporal mean of a skeletal sequence, which, despite its modest guise, carries highly action-specific information. (3) Our investigation revealed strong variations in joint-to-joint relationships across different actions. This finding exposes the limitations of a single adjacency matrix in capturing the variations of relational configurations emblematic of human movement, which we remedy by proposing an efficient refinement to Graph Convolutions (GC) - the BlockGC. This evolution slashes parameters by a substantial margin (above 40%), while elevating performance beyond original GCNs. Our full model, the BlockGCN, establishes new standards in skeleton-based action recognition for small model sizes. Its high accuracy, notably on the large-scale NTU RGB+D 120 dataset, stand as compelling proof of the efficacy of BlockGCN.\n    ",
        "primary_category": "cs.CV",
        "categories": [],
        "submitted_date": "19 May 2023",
        "last_revised_date": " "
    },
    "2305.11577": {
        "title": "LeftRefill: Filling Right Canvas based on Left Reference through Generalized Text-to-Image Diffusion Model",
        "authors": [
            "Chenjie Cao",
            "Yunuo Cai",
            "Qiaole Dong",
            "Yikai Wang",
            "Yanwei Fu"
        ],
        "comments": "Accepted by CVPR2024. Codes and models are released at this https URL, Project page: this https URL",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "This paper introduces LeftRefill, an innovative approach to efficiently harness large Text-to-Image (T2I) diffusion models for reference-guided image synthesis. As the name implies, LeftRefill horizontally stitches reference and target views together as a whole input. The reference image occupies the left side, while the target canvas is positioned on the right. Then, LeftRefill paints the right-side target canvas based on the left-side reference and specific task instructions. Such a task formulation shares some similarities with contextual inpainting, akin to the actions of a human painter. This novel formulation efficiently learns both structural and textured correspondence between reference and target without other image encoders or adapters. We inject task and view information through cross-attention modules in T2I models, and further exhibit multi-view reference ability via the re-arranged self-attention modules. These enable LeftRefill to perform consistent generation as a generalized model without requiring test-time fine-tuning or model modifications. Thus, LeftRefill can be seen as a simple yet unified framework to address reference-guided synthesis. As an exemplar, we leverage LeftRefill to address two different challenges: reference-guided inpainting and novel view synthesis, based on the pre-trained StableDiffusion. Codes and models are released at this https URL.\n    ",
        "primary_category": "cs.CV",
        "categories": [],
        "submitted_date": "19 May 2023",
        "last_revised_date": " "
    },
    "2305.11897": {
        "title": "Critical Appraisal of Artificial Intelligence-Mediated Communication",
        "authors": [
            "Dara Tafazoli"
        ],
        "comments": " ",
        "subjects": "Human-Computer Interaction (cs.HC)",
        "abstract": "Over the last two decades, technology use in language learning and teaching has significantly advanced and is now referred to as Computer-Assisted Language Learning (CALL). Recently, the integration of Artificial Intelligence (AI) into CALL has brought about a significant shift in the traditional approach to language education both inside and outside the classroom. In line with this book's scope, I explore the advantages and disadvantages of AI-mediated communication in language education. I begin with a brief review of AI in education. I then introduce the ICALL and give a critical appraisal of the potential of AI-powered automatic speech recognition (ASR), Machine Translation (MT), Intelligent Tutoring Systems (ITSs), AI-powered chatbots, and Extended Reality (XR). In conclusion, I argue that it is crucial for language teachers to engage in CALL teacher education and professional development to keep up with the ever-evolving technology landscape and improve their teaching effectiveness.\n    ",
        "primary_category": "cs.HC",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "15 May 2023",
        "last_revised_date": " "
    },
    "2305.12036": {
        "title": "SIDAR: Synthetic Image Dataset for Alignment & Restoration",
        "authors": [
            "Monika Kwiatkowski",
            "Simon Matern",
            "Olaf Hellwich"
        ],
        "comments": " ",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Image alignment and image restoration are classical computer vision tasks. However, there is still a lack of datasets that provide enough data to train and evaluate end-to-end deep learning models. Obtaining ground-truth data for image alignment requires sophisticated structure-from-motion methods or optical flow systems that often do not provide enough data variance, i.e., typically providing a high number of image correspondences, while only introducing few changes of scenery within the underlying image sequences. Alternative approaches utilize random perspective distortions on existing image data. However, this only provides trivial distortions, lacking the complexity and variance of real-world scenarios. Instead, our proposed data augmentation helps to overcome the issue of data scarcity by using 3D rendering: images are added as textures onto a plane, then varying lighting conditions, shadows, and occlusions are added to the scene. The scene is rendered from multiple viewpoints, generating perspective distortions more consistent with real-world scenarios, with homographies closely resembling those of camera projections rather than randomized homographies. For each scene, we provide a sequence of distorted images with corresponding occlusion masks, homographies, and ground-truth labels. The resulting dataset can serve as a training and evaluation set for a multitude of tasks involving image alignment and artifact removal, such as deep homography estimation, dense image matching, 2D bundle adjustment, inpainting, shadow removal, denoising, content retrieval, and background subtraction. Our data generation pipeline is customizable and can be applied to any existing dataset, serving as a data augmentation to further improve the feature learning of any existing method.\n    ",
        "primary_category": "cs.CV",
        "categories": [
            "cs.GR",
            "cs.LG"
        ],
        "submitted_date": "19 May 2023",
        "last_revised_date": " "
    },
    "2305.13318": {
        "title": "A stable deep adversarial learning approach for geological facies generation",
        "authors": [
            "Ferdinand Bhavsar",
            "Nicolas Desassis",
            "Fabien Ors",
            "Thomas Romary"
        ],
        "comments": " ",
        "subjects": "Geophysics (physics.geo-ph)",
        "abstract": "The simulation of geological facies in an unobservable volume is essential in various geoscience applications. Given the complexity of the problem, deep generative learning is a promising approach to overcome the limitations of traditional geostatistical simulation models, in particular their lack of physical realism. This research aims to investigate the application of generative adversarial networks and deep variational inference for conditionally simulating meandering channels in underground volumes. In this paper, we review the generative deep learning approaches, in particular the adversarial ones and the stabilization techniques that aim to facilitate their training. The proposed approach is tested on 2D and 3D simulations generated by the stochastic process-based model Flumy. Morphological metrics are utilized to compare our proposed method with earlier iterations of generative adversarial networks. The results indicate that by utilizing recent stabilization techniques, generative adversarial networks can efficiently sample from target data distributions. Moreover, we demonstrate the ability to simulate conditioned simulations through the latent variable model property of the proposed approach.\n    ",
        "primary_category": "physics.geo-ph",
        "categories": [
            "cs.LG"
        ],
        "submitted_date": "12 May 2023",
        "last_revised_date": " "
    },
    "2305.13655": {
        "title": "LLM-grounded Diffusion: Enhancing Prompt Understanding of Text-to-Image Diffusion Models with Large Language Models",
        "authors": [
            "Long Lian",
            "Boyi Li",
            "Adam Yala",
            "Trevor Darrell"
        ],
        "comments": "Transactions on Machine Learning Research (TMLR) 2024, with Featured Certification",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Recent advancements in text-to-image diffusion models have yielded impressive results in generating realistic and diverse images. However, these models still struggle with complex prompts, such as those that involve numeracy and spatial reasoning. This work proposes to enhance prompt understanding capabilities in diffusion models. Our method leverages a pretrained large language model (LLM) for grounded generation in a novel two-stage process. In the first stage, the LLM generates a scene layout that comprises captioned bounding boxes from a given prompt describing the desired image. In the second stage, a novel controller guides an off-the-shelf diffusion model for layout-grounded image generation. Both stages utilize existing pretrained models without additional model parameter optimization. Our method significantly outperforms the base diffusion model and several strong baselines in accurately generating images according to prompts that require various capabilities, doubling the generation accuracy across four tasks on average. Furthermore, our method enables instruction-based multi-round scene specification and can handle prompts in languages not supported by the underlying diffusion model. We anticipate that our method will unleash users' creativity by accurately following more complex prompts. Our code, demo, and benchmark are available at: this https URL\n",
        "primary_category": "cs.CV",
        "categories": [],
        "submitted_date": "23 May 2023",
        "last_revised_date": " "
    },
    "2305.14779": {
        "title": "Alt-Text with Context: Improving Accessibility for Images on Twitter",
        "authors": [
            "Nikita Srivatsan",
            "Sofia Samaniego",
            "Omar Florez",
            "Taylor Berg-Kirkpatrick"
        ],
        "comments": "ICLR 2024",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "In this work we present an approach for generating alternative text (or alt-text) descriptions for images shared on social media, specifically Twitter. More than just a special case of image captioning, alt-text is both more literally descriptive and context-specific. Also critically, images posted to Twitter are often accompanied by user-written text that despite not necessarily describing the image may provide useful context that if properly leveraged can be informative. We address this task with a multimodal model that conditions on both textual information from the associated social media post as well as visual signal from the image, and demonstrate that the utility of these two information sources stacks. We put forward a new dataset of 371k images paired with alt-text and tweets scraped from Twitter and evaluate on it across a variety of automated metrics as well as human evaluation. We show that our approach of conditioning on both tweet text and visual information significantly outperforms prior work, by more than 2x on BLEU@4.\n    ",
        "primary_category": "cs.CV",
        "categories": [
            "cs.CL",
            "cs.LG"
        ],
        "submitted_date": "24 May 2023",
        "last_revised_date": " "
    },
    "2305.14916": {
        "title": "Tuning-Free Maximum Likelihood Training of Latent Variable Models via Coin Betting",
        "authors": [
            "Louis Sharrock",
            "Daniel Dodd",
            "Christopher Nemeth"
        ],
        "comments": " ",
        "subjects": "Machine Learning (stat.ML)",
        "abstract": "We introduce two new particle-based algorithms for learning latent variable models via marginal maximum likelihood estimation, including one which is entirely tuning-free. Our methods are based on the perspective of marginal maximum likelihood estimation as an optimization problem: namely, as the minimization of a free energy functional. One way to solve this problem is via the discretization of a gradient flow associated with the free energy. We study one such approach, which resembles an extension of Stein variational gradient descent, establishing a descent lemma which guarantees that the free energy decreases at each iteration. This method, and any other obtained as the discretization of the gradient flow, necessarily depends on a learning rate which must be carefully tuned by the practitioner in order to ensure convergence at a suitable rate. With this in mind, we also propose another algorithm for optimizing the free energy which is entirely learning rate free, based on coin betting techniques from convex optimization. We validate the performance of our algorithms across several numerical experiments, including several high-dimensional settings. Our results are competitive with existing particle-based methods, without the need for any hyperparameter tuning.\n    ",
        "primary_category": "stat.ML",
        "categories": [
            "cs.LG",
            "stat.ME"
        ],
        "submitted_date": "24 May 2023",
        "last_revised_date": " "
    },
    "2305.15022": {
        "title": "Hierarchical clustering with dot products recovers hidden tree structure",
        "authors": [
            "Annie Gray",
            "Alexander Modell",
            "Patrick Rubin-Delanchy",
            "Nick Whiteley"
        ],
        "comments": " ",
        "subjects": "Machine Learning (stat.ML)",
        "abstract": "In this paper we offer a new perspective on the well established agglomerative clustering algorithm, focusing on recovery of hierarchical structure. We recommend a simple variant of the standard algorithm, in which clusters are merged by maximum average dot product and not, for example, by minimum distance or within-cluster variance. We demonstrate that the tree output by this algorithm provides a bona fide estimate of generative hierarchical structure in data, under a generic probabilistic graphical model. The key technical innovations are to understand how hierarchical information in this model translates into tree geometry which can be recovered from data, and to characterise the benefits of simultaneously growing sample size and data dimension. We demonstrate superior tree recovery performance with real data over existing approaches such as UPGMA, Ward's method, and HDBSCAN.\n    ",
        "primary_category": "stat.ML",
        "categories": [
            "cs.LG"
        ],
        "submitted_date": "24 May 2023",
        "last_revised_date": " "
    },
    "2305.15086": {
        "title": "Unpaired Image-to-Image Translation via Neural Schr\u00f6dinger Bridge",
        "authors": [
            "Beomsu Kim",
            "Gihyun Kwon",
            "Kwanyoung Kim",
            "Jong Chul Ye"
        ],
        "comments": "ICLR 2024",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Diffusion models are a powerful class of generative models which simulate stochastic differential equations (SDEs) to generate data from noise. While diffusion models have achieved remarkable progress, they have limitations in unpaired image-to-image (I2I) translation tasks due to the Gaussian prior assumption. Schr\u00f6dinger Bridge (SB), which learns an SDE to translate between two arbitrary distributions, have risen as an attractive solution to this problem. Yet, to our best knowledge, none of SB models so far have been successful at unpaired translation between high-resolution images. In this work, we propose Unpaired Neural Schr\u00f6dinger Bridge (UNSB), which expresses the SB problem as a sequence of adversarial learning problems. This allows us to incorporate advanced discriminators and regularization to learn a SB between unpaired data. We show that UNSB is scalable and successfully solves various unpaired I2I translation tasks. Code: \\url{this https URL}\n    ",
        "primary_category": "cs.CV",
        "categories": [
            "cs.AI",
            "cs.LG",
            "stat.ML"
        ],
        "submitted_date": "24 May 2023",
        "last_revised_date": " "
    },
    "2305.15560": {
        "title": "Differentially Private Synthetic Data via Foundation Model APIs 1: Images",
        "authors": [
            "Zinan Lin",
            "Sivakanth Gopi",
            "Janardhan Kulkarni",
            "Harsha Nori",
            "Sergey Yekhanin"
        ],
        "comments": "49 pages, 42 figures",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Generating differentially private (DP) synthetic data that closely resembles the original private data is a scalable way to mitigate privacy concerns in the current data-driven world. In contrast to current practices that train customized models for this task, we aim to generate DP Synthetic Data via APIs (DPSDA), where we treat foundation models as blackboxes and only utilize their inference APIs. Such API-based, training-free approaches are easier to deploy as exemplified by the recent surge in the number of API-based apps. These approaches can also leverage the power of large foundation models which are only accessible via their inference APIs. However, this comes with greater challenges due to strictly more restrictive model access and the need to protect privacy from the API provider.\nIn this paper, we present a new framework called Private Evolution (PE) to solve this problem and show its initial promise on synthetic images. Surprisingly, PE can match or even outperform state-of-the-art (SOTA) methods without any model training. For example, on CIFAR10 (with ImageNet as the public data), we achieve FID <= 7.9 with privacy cost {\\epsilon} = 0.67, significantly improving the previous SOTA from {\\epsilon} = 32. We further demonstrate the promise of applying PE on large foundation models such as Stable Diffusion to tackle challenging private datasets with a small number of high-resolution images. The code and data are released at this https URL.\n    ",
        "primary_category": "cs.CV",
        "categories": [
            "cs.CR",
            "cs.LG"
        ],
        "submitted_date": "24 May 2023",
        "last_revised_date": " "
    },
    "2305.16147": {
        "title": "Learning Safety Constraints from Demonstrations with Unknown Rewards",
        "authors": [
            "David Lindner",
            "Xin Chen",
            "Sebastian Tschiatschek",
            "Katja Hofmann",
            "Andreas Krause"
        ],
        "comments": "Presented at the International Conference on Artificial Intelligence and Statistics (AISTATS) 2024",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "We propose Convex Constraint Learning for Reinforcement Learning (CoCoRL), a novel approach for inferring shared constraints in a Constrained Markov Decision Process (CMDP) from a set of safe demonstrations with possibly different reward functions. While previous work is limited to demonstrations with known rewards or fully known environment dynamics, CoCoRL can learn constraints from demonstrations with different unknown rewards without knowledge of the environment dynamics. CoCoRL constructs a convex safe set based on demonstrations, which provably guarantees safety even for potentially sub-optimal (but safe) demonstrations. For near-optimal demonstrations, CoCoRL converges to the true safe set with no policy regret. We evaluate CoCoRL in gridworld environments and a driving simulation with multiple constraints. CoCoRL learns constraints that lead to safe driving behavior. Importantly, we can safely transfer the learned constraints to different tasks and environments. In contrast, alternative methods based on Inverse Reinforcement Learning (IRL) often exhibit poor performance and learn unsafe policies.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.AI",
            "stat.ML"
        ],
        "submitted_date": "25 May 2023",
        "last_revised_date": " "
    },
    "2305.17583": {
        "title": "On Neural Networks as Infinite Tree-Structured Probabilistic Graphical Models",
        "authors": [
            "Boyao Li",
            "Alexandar J. Thomson",
            "Matthew M. Engelhard",
            "David Page"
        ],
        "comments": " ",
        "subjects": "Machine Learning (stat.ML)",
        "abstract": "Deep neural networks (DNNs) lack the precise semantics and definitive probabilistic interpretation of probabilistic graphical models (PGMs). In this paper, we propose an innovative solution by constructing infinite tree-structured PGMs that correspond exactly to neural networks. Our research reveals that DNNs, during forward propagation, indeed perform approximations of PGM inference that are precise in this alternative PGM structure. Not only does our research complement existing studies that describe neural networks as kernel machines or infinite-sized Gaussian processes, it also elucidates a more direct approximation that DNNs make to exact inference in PGMs. Potential benefits include improved pedagogy and interpretation of DNNs, and algorithms that can merge the strengths of PGMs and DNNs.\n    ",
        "primary_category": "stat.ML",
        "categories": [
            "cs.LG"
        ],
        "submitted_date": "27 May 2023",
        "last_revised_date": " "
    },
    "2305.18352": {
        "title": "Multi-Objective Genetic Algorithm for Multi-View Feature Selection",
        "authors": [
            "Vandad Imani",
            "Carlos Sevilla-Salcedo",
            "Elaheh Moradi",
            "Vittorio Fortino",
            "Jussi Tohka"
        ],
        "comments": " ",
        "subjects": "Neural and Evolutionary Computing (cs.NE)",
        "abstract": "Multi-view datasets offer diverse forms of data that can enhance prediction models by providing complementary information. However, the use of multi-view data leads to an increase in high-dimensional data, which poses significant challenges for the prediction models that can lead to poor generalization. Therefore, relevant feature selection from multi-view datasets is important as it not only addresses the poor generalization but also enhances the interpretability of the models. Despite the success of traditional feature selection methods, they have limitations in leveraging intrinsic information across modalities, lacking generalizability, and being tailored to specific classification tasks. We propose a novel genetic algorithm strategy to overcome these limitations of traditional feature selection methods for multi-view data. Our proposed approach, called the multi-view multi-objective feature selection genetic algorithm (MMFS-GA), simultaneously selects the optimal subset of features within a view and between views under a unified framework. The MMFS-GA framework demonstrates superior performance and interpretability for feature selection on multi-view datasets in both binary and multiclass classification tasks. The results of our evaluations on three benchmark datasets, including synthetic and real data, show improvement over the best baseline methods. This work provides a promising solution for multi-view feature selection and opens up new possibilities for further research in multi-view datasets.\n    ",
        "primary_category": "cs.NE",
        "categories": [
            "cs.AI",
            "cs.LG"
        ],
        "submitted_date": "26 May 2023",
        "last_revised_date": " "
    },
    "2305.18383": {
        "title": "A Three-regime Model of Network Pruning",
        "authors": [
            "Yefan Zhou",
            "Yaoqing Yang",
            "Arin Chang",
            "Michael W. Mahoney"
        ],
        "comments": "ICML 2023",
        "subjects": "Machine Learning (stat.ML)",
        "abstract": "Recent work has highlighted the complex influence training hyperparameters, e.g., the number of training epochs, can have on the prunability of machine learning models. Perhaps surprisingly, a systematic approach to predict precisely how adjusting a specific hyperparameter will affect prunability remains elusive. To address this gap, we introduce a phenomenological model grounded in the statistical mechanics of learning. Our approach uses temperature-like and load-like parameters to model the impact of neural network (NN) training hyperparameters on pruning performance. A key empirical result we identify is a sharp transition phenomenon: depending on the value of a load-like parameter in the pruned model, increasing the value of a temperature-like parameter in the pre-pruned model may either enhance or impair subsequent pruning performance. Based on this transition, we build a three-regime model by taxonomizing the global structure of the pruned NN loss landscape. Our model reveals that the dichotomous effect of high temperature is associated with transitions between distinct types of global structures in the post-pruned model. Based on our results, we present three case-studies: 1) determining whether to increase or decrease a hyperparameter for improved pruning; 2) selecting the best model to prune from a family of models; and 3) tuning the hyperparameter of the Sharpness Aware Minimization method for better pruning performance.\n    ",
        "primary_category": "stat.ML",
        "categories": [
            "cs.LG"
        ],
        "submitted_date": "28 May 2023",
        "last_revised_date": " "
    },
    "2305.18479": {
        "title": "FMM-X3D: FPGA-based modeling and mapping of X3D for Human Action Recognition",
        "authors": [
            "Petros Toupas",
            "Christos-Savvas Bouganis",
            "Dimitrios Tzovaras"
        ],
        "comments": "8 pages, 6 figures, 2 tables",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "3D Convolutional Neural Networks are gaining increasing attention from researchers and practitioners and have found applications in many domains, such as surveillance systems, autonomous vehicles, human monitoring systems, and video retrieval. However, their widespread adoption is hindered by their high computational and memory requirements, especially when resource-constrained systems are targeted. This paper addresses the problem of mapping X3D, a state-of-the-art model in Human Action Recognition that achieves accuracy of 95.5\\% in the UCF101 benchmark, onto any FPGA device. The proposed toolflow generates an optimised stream-based hardware system, taking into account the available resources and off-chip memory characteristics of the FPGA device. The generated designs push further the current performance-accuracy pareto front, and enable for the first time the targeting of such complex model architectures for the Human Action Recognition task.\n    ",
        "primary_category": "cs.CV",
        "categories": [
            "cs.AI",
            "cs.AR",
            "cs.LG"
        ],
        "submitted_date": "29 May 2023",
        "last_revised_date": " "
    },
    "2305.18502": {
        "title": "Escaping mediocrity: how two-layer networks learn hard generalized linear models with SGD",
        "authors": [
            "Luca Arnaboldi",
            "Florent Krzakala",
            "Bruno Loureiro",
            "Ludovic Stephan"
        ],
        "comments": " ",
        "subjects": "Machine Learning (stat.ML)",
        "abstract": "This study explores the sample complexity for two-layer neural networks to learn a generalized linear target function under Stochastic Gradient Descent (SGD), focusing on the challenging regime where many flat directions are present at initialization. It is well-established that in this scenario $n=O(d \\log d)$ samples are typically needed. However, we provide precise results concerning the pre-factors in high-dimensional contexts and for varying widths. Notably, our findings suggest that overparameterization can only enhance convergence by a constant factor within this problem class. These insights are grounded in the reduction of SGD dynamics to a stochastic process in lower dimensions, where escaping mediocrity equates to calculating an exit time. Yet, we demonstrate that a deterministic approximation of this process adequately represents the escape time, implying that the role of stochasticity may be minimal in this scenario.\n    ",
        "primary_category": "stat.ML",
        "categories": [
            "cs.LG"
        ],
        "submitted_date": "29 May 2023",
        "last_revised_date": " "
    },
    "2305.19738": {
        "title": "Bures-Wasserstein Means of Graphs",
        "authors": [
            "Isabel Haasler",
            "Pascal Frossard"
        ],
        "comments": " ",
        "subjects": "Machine Learning (stat.ML)",
        "abstract": "Finding the mean of sampled data is a fundamental task in machine learning and statistics. However, in cases where the data samples are graph objects, defining a mean is an inherently difficult task. We propose a novel framework for defining a graph mean via embeddings in the space of smooth graph signal distributions, where graph similarity can be measured using the Wasserstein metric. By finding a mean in this embedding space, we can recover a mean graph that preserves structural information. We establish the existence and uniqueness of the novel graph mean, and provide an iterative algorithm for computing it. To highlight the potential of our framework as a valuable tool for practical applications in machine learning, it is evaluated on various tasks, including k-means clustering of structured aligned graphs, classification of functional brain networks, and semi-supervised node classification in multi-layer graphs. Our experimental results demonstrate that our approach achieves consistent performance, outperforms existing baseline approaches, and improves the performance of state-of-the-art methods.\n    ",
        "primary_category": "stat.ML",
        "categories": [
            "cs.LG",
            "cs.SI",
            "eess.SP"
        ],
        "submitted_date": "31 May 2023",
        "last_revised_date": " "
    },
    "2305.19833": {
        "title": "Homogenization of nondivergence-form elliptic equations with discontinuous coefficients and finite element approximation of the homogenized problem",
        "authors": [
            "Timo Sprekeler"
        ],
        "comments": "19 pages",
        "subjects": "Numerical Analysis (math.NA)",
        "abstract": "We study the homogenization of the equation $-A(\\frac{\\cdot}{\\varepsilon}):D^2 u_{\\varepsilon} = f$ posed in a bounded convex domain $\\Omega\\subset \\mathbb{R}^n$ subject to a Dirichlet boundary condition and the numerical approximation of the corresponding homogenized problem, where the measurable, uniformly elliptic, periodic and symmetric diffusion matrix $A$ is merely assumed to be essentially bounded and (if $n>2$) to satisfy the Cordes condition. In the first part, we show existence and uniqueness of an invariant measure by reducing to a Lax--Milgram-type problem, we obtain $L^2$-bounds for periodic problems in double-divergence-form, we prove homogenization under minimal regularity assumptions, and we generalize known corrector bounds and results on optimal convergence rates from the classical case of H\u00f6lder continuous coefficients to the present case. In the second part, we suggest and rigorously analyze an approximation scheme for the effective coefficient matrix and the solution to the homogenized problem based on a finite element method for the approximation of the invariant measure, and we demonstrate the performance of the scheme through numerical experiments.\n    ",
        "primary_category": "math.NA",
        "categories": [
            "math.AP"
        ],
        "submitted_date": "31 May 2023",
        "last_revised_date": " "
    },
    "2305.19896": {
        "title": "fpgaHART: A toolflow for throughput-oriented acceleration of 3D CNNs for HAR onto FPGAs",
        "authors": [
            "Petros Toupas",
            "Christos-Savvas Bouganis",
            "Dimitrios Tzovaras"
        ],
        "comments": "7 pages, 3 figures, 4 tables. arXiv admin note: substantial text overlap with arXiv:2305.18479",
        "subjects": "Hardware Architecture (cs.AR)",
        "abstract": "Surveillance systems, autonomous vehicles, human monitoring systems, and video retrieval are just few of the many applications in which 3D Convolutional Neural Networks are exploited. However, their extensive use is restricted by their high computational and memory requirements, especially when integrated into systems with limited resources. This study proposes a toolflow that optimises the mapping of 3D CNN models for Human Action Recognition onto FPGA devices, taking into account FPGA resources and off-chip memory characteristics. The proposed system employs Synchronous Dataflow (SDF) graphs to model the designs and introduces transformations to expand and explore the design space, resulting in high-throughput designs. A variety of 3D CNN models were evaluated using the proposed toolflow on multiple FPGA devices, demonstrating its potential to deliver competitive performance compared to earlier hand-tuned and model-specific designs.\n    ",
        "primary_category": "cs.AR",
        "categories": [
            "cs.AI",
            "cs.CV",
            "cs.LG"
        ],
        "submitted_date": "31 May 2023",
        "last_revised_date": " "
    },
    "2306.00497": {
        "title": "The Risks of Recourse in Binary Classification",
        "authors": [
            "Hidde Fokkema",
            "Damien Garreau",
            "Tim van Erven"
        ],
        "comments": "24 pages, 8 figures, 5 tables",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Algorithmic recourse provides explanations that help users overturn an unfavorable decision by a machine learning system. But so far very little attention has been paid to whether providing recourse is beneficial or not. We introduce an abstract learning-theoretic framework that compares the risks (i.e., expected losses) for classification with and without algorithmic recourse. This allows us to answer the question of when providing recourse is beneficial or harmful at the population level. Surprisingly, we find that there are many plausible scenarios in which providing recourse turns out to be harmful, because it pushes users to regions of higher class uncertainty and therefore leads to more mistakes. We further study whether the party deploying the classifier has an incentive to strategize in anticipation of having to provide recourse, and we find that sometimes they do, to the detriment of their users. Providing algorithmic recourse may therefore also be harmful at the systemic level. We confirm our theoretical findings in experiments on simulated and real-world data. All in all, we conclude that the current concept of algorithmic recourse is not reliably beneficial, and therefore requires rethinking.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.CY",
            "stat.ML"
        ],
        "submitted_date": "1 Jun 2023",
        "last_revised_date": " "
    },
    "2306.00603": {
        "title": "Safe Offline Reinforcement Learning with Real-Time Budget Constraints",
        "authors": [
            "Qian Lin",
            "Bo Tang",
            "Zifan Wu",
            "Chao Yu",
            "Shangqin Mao",
            "Qianlong Xie",
            "Xingxing Wang",
            "Dong Wang"
        ],
        "comments": "We propose a method to handle the constraint problem with dynamically determined safety budgets under the offline setting",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Aiming at promoting the safe real-world deployment of Reinforcement Learning (RL), research on safe RL has made significant progress in recent years. However, most existing works in the literature still focus on the online setting where risky violations of the safety budget are likely to be incurred during training. Besides, in many real-world applications, the learned policy is required to respond to dynamically determined safety budgets (i.e., constraint threshold) in real time. In this paper, we target at the above real-time budget constraint problem under the offline setting, and propose Trajectory-based REal-time Budget Inference (TREBI) as a novel solution that models this problem from the perspective of trajectory distribution and solves it through diffusion model planning. Theoretically, we prove an error bound of the estimation on the episodic reward and cost under the offline setting and thus provide a performance guarantee for TREBI. Empirical results on a wide range of simulation tasks and a real-world large-scale advertising application demonstrate the capability of TREBI in solving real-time budget constraint problems under offline settings.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.AI",
            "cs.RO"
        ],
        "submitted_date": "1 Jun 2023",
        "last_revised_date": " "
    },
    "2306.00919": {
        "title": "Learning About Social Context from Smartphone Data: Generalization Across Countries and Daily Life Moments",
        "authors": [
            "Aurel Ruben Mader",
            "Lakmal Meegahapola",
            "Daniel Gatica-Perez"
        ],
        "comments": "Accepted at ACM CHI 2024",
        "subjects": "Human-Computer Interaction (cs.HC)",
        "abstract": "Understanding how social situations unfold in people's daily lives is relevant to designing mobile systems that can support users in their personal goals, well-being, and activities. As an alternative to questionnaires, some studies have used passively collected smartphone sensor data to infer social context (i.e., being alone or not) with machine learning models. However, the few existing studies have focused on specific daily life occasions and limited geographic cohorts in one or two countries. This limits the understanding of how inference models work in terms of generalization to everyday life occasions and multiple countries. In this paper, we used a novel, large-scale, and multimodal smartphone sensing dataset with over 216K self-reports collected from 581 young adults in five countries (Mongolia, Italy, Denmark, UK, Paraguay), first to understand whether social context inference is feasible with sensor data, and then, to know how behavioral and country-level diversity affects inferences. We found that several sensors are informative of social context, that partially personalized multi-country models (trained and tested with data from all countries) and country-specific models (trained and tested within countries) can achieve similar performance above 90% AUC, and that models do not generalize well to unseen countries regardless of geographic proximity. These findings confirm the importance of the diversity of mobile data, to better understand social context inference models in different countries.\n    ",
        "primary_category": "cs.HC",
        "categories": [
            "cs.CY"
        ],
        "submitted_date": "1 Jun 2023",
        "last_revised_date": " "
    },
    "2306.00950": {
        "title": "Differential Diffusion: Giving Each Pixel Its Strength",
        "authors": [
            "Eran Levin",
            "Ohad Fried"
        ],
        "comments": "Project Page: this https URL",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Diffusion models have revolutionized image generation and editing, producing state-of-the-art results in conditioned and unconditioned image synthesis. While current techniques enable user control over the degree of change in an image edit, the controllability is limited to global changes over an entire edited region. This paper introduces a novel framework that enables customization of the amount of change per pixel or per image region. Our framework can be integrated into any existing diffusion model, enhancing it with this capability. Such granular control on the quantity of change opens up a diverse array of new editing capabilities, such as control of the extent to which individual objects are modified, or the ability to introduce gradual spatial changes. Furthermore, we showcase the framework's effectiveness in soft-inpainting -- the completion of portions of an image while subtly adjusting the surrounding areas to ensure seamless integration. Additionally, we introduce a new tool for exploring the effects of different change quantities. Our framework operates solely during inference, requiring no model training or fine-tuning. We demonstrate our method with the current open state-of-the-art models, and validate it via both quantitative and qualitative comparisons, and a user study. Our code is available at: this https URL\n",
        "primary_category": "cs.CV",
        "categories": [
            "cs.AI",
            "cs.GR",
            "cs.LG"
        ],
        "submitted_date": "1 Jun 2023",
        "last_revised_date": " "
    },
    "2306.00964": {
        "title": "Cocktail: Mixing Multi-Modality Controls for Text-Conditional Image Generation",
        "authors": [
            "Minghui Hu",
            "Jianbin Zheng",
            "Daqing Liu",
            "Chuanxia Zheng",
            "Chaoyue Wang",
            "Dacheng Tao",
            "Tat-Jen Cham"
        ],
        "comments": "Project Page: this https URL",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Text-conditional diffusion models are able to generate high-fidelity images with diverse contents. However, linguistic representations frequently exhibit ambiguous descriptions of the envisioned objective imagery, requiring the incorporation of additional control signals to bolster the efficacy of text-guided diffusion models. In this work, we propose Cocktail, a pipeline to mix various modalities into one embedding, amalgamated with a generalized ControlNet (gControlNet), a controllable normalisation (ControlNorm), and a spatial guidance sampling method, to actualize multi-modal and spatially-refined control for text-conditional diffusion models. Specifically, we introduce a hyper-network gControlNet, dedicated to the alignment and infusion of the control signals from disparate modalities into the pre-trained diffusion model. gControlNet is capable of accepting flexible modality signals, encompassing the simultaneous reception of any combination of modality signals, or the supplementary fusion of multiple modality signals. The control signals are then fused and injected into the backbone model according to our proposed ControlNorm. Furthermore, our advanced spatial guidance sampling methodology proficiently incorporates the control signal into the designated region, thereby circumventing the manifestation of undesired objects within the generated image. We demonstrate the results of our method in controlling various modalities, proving high-quality synthesis and fidelity to multiple external signals.\n    ",
        "primary_category": "cs.CV",
        "categories": [
            "cs.LG"
        ],
        "submitted_date": "1 Jun 2023",
        "last_revised_date": " "
    },
    "2306.00973": {
        "title": "Intelligent Grimm -- Open-ended Visual Storytelling via Latent Diffusion Models",
        "authors": [
            "Chang Liu",
            "Haoning Wu",
            "Yujie Zhong",
            "Xiaoyun Zhang",
            "Yanfeng Wang",
            "Weidi Xie"
        ],
        "comments": "Accepted by CVPR 2024. Project Page: this https URL",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Generative models have recently exhibited exceptional capabilities in text-to-image generation, but still struggle to generate image sequences coherently. In this work, we focus on a novel, yet challenging task of generating a coherent image sequence based on a given storyline, denoted as open-ended visual storytelling. We make the following three contributions: (i) to fulfill the task of visual storytelling, we propose a learning-based auto-regressive image generation model, termed as StoryGen, with a novel vision-language context module, that enables to generate the current frame by conditioning on the corresponding text prompt and preceding image-caption pairs; (ii) to address the data shortage of visual storytelling, we collect paired image-text sequences by sourcing from online videos and open-source E-books, establishing processing pipeline for constructing a large-scale dataset with diverse characters, storylines, and artistic styles, named StorySalon; (iii) Quantitative experiments and human evaluations have validated the superiority of our StoryGen, where we show StoryGen can generalize to unseen characters without any optimization, and generate image sequences with coherent content and consistent character. Code, dataset, and models are available at this https URL\n",
        "primary_category": "cs.CV",
        "categories": [],
        "submitted_date": "1 Jun 2023",
        "last_revised_date": " "
    },
    "2306.01334": {
        "title": "Federated Domain Generalization: A Survey",
        "authors": [
            "Ying Li",
            "Xingwei Wang",
            "Rongfei Zeng",
            "Praveen Kumar Donta",
            "Ilir Murturi",
            "Min Huang",
            "Schahram Dustdar"
        ],
        "comments": " ",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Machine learning typically relies on the assumption that training and testing distributions are identical and that data is centrally stored for training and testing. However, in real-world scenarios, distributions may differ significantly and data is often distributed across different devices, organizations, or edge nodes. Consequently, it is imperative to develop models that can effectively generalize to unseen distributions where data is distributed across different domains. In response to this challenge, there has been a surge of interest in federated domain generalization (FDG) in recent years. FDG combines the strengths of federated learning (FL) and domain generalization (DG) techniques to enable multiple source domains to collaboratively learn a model capable of directly generalizing to unseen domains while preserving data privacy. However, generalizing the federated model under domain shifts is a technically challenging problem that has received scant attention in the research area so far. This paper presents the first survey of recent advances in this area. Initially, we discuss the development process from traditional machine learning to domain adaptation and domain generalization, leading to FDG as well as provide the corresponding formal definition. Then, we categorize recent methodologies into four classes: federated domain alignment, data manipulation, learning strategies, and aggregation optimization, and present suitable algorithms in detail for each category. Next, we introduce commonly used datasets, applications, evaluations, and benchmarks. Finally, we conclude this survey by providing some potential research topics for the future.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "2 Jun 2023",
        "last_revised_date": " "
    },
    "2306.01517": {
        "title": "Parameterized Broadcast Networks with Registers: from NP to the Frontiers of Decidability",
        "authors": [
            "Lucie Guillou",
            "Corto Mascle",
            "Nicolas Waldburger"
        ],
        "comments": "Long version of a paper published at FoSSaCS 2024",
        "subjects": "Logic in Computer Science (cs.LO)",
        "abstract": "We consider the parameterized verification of arbitrarily large networks of agents which communicate by broadcasting and receiving messages. In our model, the broadcast topology is reconfigurable so that a sent message can be received by any set of agents. In addition, agents have local registers which are initially distinct and may therefore be thought of as identifiers. When an agent broadcasts a message, it appends to the message the value stored in one of its registers. Upon reception, an agent can store the received value or test this value for equality with one of its own registers. We consider the coverability problem, where one asks whether a given state of the system may be reached by at least one agent. We establish that this problem is decidable; however, it is as hard as coverability in lossy channel systems, which is non-primitive recursive. This model lies at the frontier of decidability as other classical problems on this model are undecidable; this is in particular true for the target problem where all processes must synchronize on a given state. By contrast, we show that the coverability problem is NP-complete when each agent has only one register.\n    ",
        "primary_category": "cs.LO",
        "categories": [
            "cs.DC",
            "cs.FL"
        ],
        "submitted_date": "2 Jun 2023",
        "last_revised_date": " "
    },
    "2306.01597": {
        "title": "(Un)Solvable Loop Analysis",
        "authors": [
            "Daneshvar Amrollahi",
            "Ezio Bartocci",
            "George Kenison",
            "Laura Kov\u00e1cs",
            "Marcel Moosbrugger",
            "Miroslav Stankovi\u010d"
        ],
        "comments": "Extended version of the conference paper `Solving Invariant Generation for Unsolvable Loops' published at SAS 2022 (see also the preprint arXiv:2206.06943). We extended both the text and results. 36 pages",
        "subjects": "Programming Languages (cs.PL)",
        "abstract": "Automatically generating invariants, key to computer-aided analysis of probabilistic and deterministic programs and compiler optimisation, is a challenging open problem. Whilst the problem is in general undecidable, the goal is settled for restricted classes of loops. For the class of solvable loops, introduced by Kapur and Rodr\u00edguez-Carbonell in 2004, one can automatically compute invariants from closed-form solutions of recurrence equations that model the loop behaviour. In this paper we establish a technique for invariant synthesis for loops that are not solvable, termed unsolvable loops. Our approach automatically partitions the program variables and identifies the so-called defective variables that characterise unsolvability. Herein we consider the following two applications. First, we present a novel technique that automatically synthesises polynomials from defective monomials, that admit closed-form solutions and thus lead to polynomial loop invariants. Second, given an unsolvable loop, we synthesise solvable loops with the following property: the invariant polynomials of the solvable loops are all invariants of the given unsolvable loop. Our implementation and experiments demonstrate both the feasibility and applicability of our approach to both deterministic and probabilistic programs.\n    ",
        "primary_category": "cs.PL",
        "categories": [],
        "submitted_date": "2 Jun 2023",
        "last_revised_date": " "
    },
    "2306.01665": {
        "title": "SourceP: Detecting Ponzi Schemes on Ethereum with Source Code",
        "authors": [
            "Pengcheng Lu",
            "Liang Cai",
            "Keting Yin"
        ],
        "comments": "12 pages, 5 figures, 4 tables",
        "subjects": "Software Engineering (cs.SE)",
        "abstract": "As blockchain technology becomes more and more popular, a typical financial scam, the Ponzi scheme, has also emerged in the blockchain platform Ethereum. This Ponzi scheme deployed through smart contracts, also known as the smart Ponzi scheme, has caused a lot of economic losses and negative impacts. Existing methods for detecting smart Ponzi schemes on Ethereum mainly rely on bytecode features, opcode features, account features, and transaction behavior features of smart contracts, which are unable to truly characterize the behavioral features of Ponzi schemes, and thus generally perform poorly in terms of detection accuracy and false alarm rates. In this paper, we propose SourceP, a method to detect smart Ponzi schemes on the Ethereum platform using pre-trained models and data flow, which only requires using the source code of smart contracts as features. SourceP reduces the difficulty of data acquisition and feature extraction of existing detection methods. Specifically, we first convert the source code of a smart contract into a data flow graph and then introduce a pre-trained model based on learning code representations to build a classification model to identify Ponzi schemes in smart contracts. The experimental results show that SourceP achieves 87.2% recall and 90.7% F-score for detecting smart Ponzi schemes within Ethereum's smart contract dataset, outperforming state-of-the-art methods in terms of performance and sustainability. We also demonstrate through additional experiments that pre-trained models and data flow play an important contribution to SourceP, as well as proving that SourceP has a good generalization ability.\n    ",
        "primary_category": "cs.SE",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "2 Jun 2023",
        "last_revised_date": " "
    },
    "2306.02010": {
        "title": "Memorization Capacity of Multi-Head Attention in Transformers",
        "authors": [
            "Sadegh Mahdavi",
            "Renjie Liao",
            "Christos Thrampoulidis"
        ],
        "comments": "ICLR 2024 (Spotlight)",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Transformers have become the go-to architecture for language and vision tasks, yet their theoretical properties, especially memorization capacity, remain elusive. This paper investigates the memorization abilities of multi-head attention mechanisms, examining how many example sequences they can memorize, as a function of the number of heads and sequence length. Motivated by experimental findings on vision transformers, we introduce novel assumptions about the linear independence of input data, distinct from the commonly used general-position assumption. Under these assumptions, we demonstrate that an attention layer with $H$ heads, dimension $d$, and context size $n < d$, featuring $\\Theta(Hd^2)$ parameters, can memorize $\\Omega(Hn)$ examples. Our analysis sheds light on how different attention heads handle various example sequences, aided by the softmax operator's saturation property. We validate our findings through experiments on synthetic data.\n    ",
        "primary_category": "cs.LG",
        "categories": [],
        "submitted_date": "3 Jun 2023",
        "last_revised_date": " "
    },
    "2306.02412": {
        "title": "Generalised Br\u00e8gman relative entropies: a brief introduction",
        "authors": [
            "Ryszard Pawe\u0142 Kostecki"
        ],
        "comments": "arXiv admin note: text overlap with arXiv:1710.01837 (author's note: this overlap will be removed in the upcoming v5 of arXiv:1710.01837 and the upcoming v4 of this paper); v3: minor change (grant numbers)",
        "subjects": "Mathematical Physics (math-ph)",
        "abstract": "We present some basic elements of the theory of generalised Br\u00e8gman relative entropies over nonreflexive Banach spaces. Using nonlinear embeddings of Banach spaces together with the Euler--Legendre functions, this approach unifies two former approaches to Br\u00e8gman relative entropy: one based on reflexive Banach spaces, another based on differential geometry. This construction allows to extend Br\u00e8gman relative entropies, and related geometric and operator structures, to arbitrary-dimensional state spaces of probability, quantum, and postquantum theory. We give several examples, not considered previously in the literature.\n    ",
        "primary_category": "math-ph",
        "categories": [
            "cs.IT"
        ],
        "submitted_date": "4 Jun 2023",
        "last_revised_date": " "
    },
    "2306.03034": {
        "title": "Tackling Cooperative Incompatibility for Zero-Shot Human-AI Coordination",
        "authors": [
            "Yang Li",
            "Shao Zhang",
            "Jichen Sun",
            "Wenhao Zhang",
            "Yali Du",
            "Ying Wen",
            "Xinbing Wang",
            "Wei Pan"
        ],
        "comments": "46 pages. arXiv admin note: substantial text overlap with arXiv:2302.04831",
        "subjects": "Artificial Intelligence (cs.AI)",
        "abstract": "Securing coordination between AI agent and teammates (human players or AI agents) in contexts involving unfamiliar humans continues to pose a significant challenge in Zero-Shot Coordination. The issue of cooperative incompatibility becomes particularly prominent when an AI agent is unsuccessful in synchronizing with certain previously unknown partners. Traditional algorithms have aimed to collaborate with partners by optimizing fixed objectives within a population, fostering diversity in strategies and behaviors. However, these techniques may lead to learning loss and an inability to cooperate with specific strategies within the population, a phenomenon named cooperative incompatibility in learning. In order to solve cooperative incompatibility in learning and effectively address the problem in the context of ZSC, we introduce the Cooperative Open-ended LEarning (COLE) framework, which formulates open-ended objectives in cooperative games with two players using perspectives of graph theory to evaluate and pinpoint the cooperative capacity of each strategy. We present two practical algorithms, specifically \\algo and \\algoR, which incorporate insights from game theory and graph theory. We also show that COLE could effectively overcome the cooperative incompatibility from theoretical and empirical analysis. Subsequently, we created an online Overcooked human-AI experiment platform, the COLE platform, which enables easy customization of questionnaires, model weights, and other aspects. Utilizing the COLE platform, we enlist 130 participants for human experiments. Our findings reveal a preference for our approach over state-of-the-art methods using a variety of subjective metrics. Moreover, objective experimental outcomes in the Overcooked game environment indicate that our method surpasses existing ones when coordinating with previously unencountered AI agents and the human proxy model.\n    ",
        "primary_category": "cs.AI",
        "categories": [
            "cs.HC"
        ],
        "submitted_date": "5 Jun 2023",
        "last_revised_date": " "
    },
    "2306.03303": {
        "title": "Global universal approximation of functional input maps on weighted spaces",
        "authors": [
            "Christa Cuchiero",
            "Philipp Schmocker",
            "Josef Teichmann"
        ],
        "comments": "60 pages, 4 figures",
        "subjects": "Machine Learning (stat.ML)",
        "abstract": "We introduce so-called functional input neural networks defined on a possibly infinite dimensional weighted space with values also in a possibly infinite dimensional output space. To this end, we use an additive family to map the input weighted space to the hidden layer, on which a non-linear scalar activation function is applied to each neuron, and finally return the output via some linear readouts. Relying on Stone-Weierstrass theorems on weighted spaces, we can prove a global universal approximation result on weighted spaces for continuous functions going beyond the usual approximation on compact sets. This then applies in particular to approximation of (non-anticipative) path space functionals via functional input neural networks. As a further application of the weighted Stone-Weierstrass theorem we prove a global universal approximation result for linear functions of the signature. We also introduce the viewpoint of Gaussian process regression in this setting and emphasize that the reproducing kernel Hilbert space of the signature kernels are Cameron-Martin spaces of certain Gaussian processes. This paves a way towards uncertainty quantification for signature kernel regression.\n    ",
        "primary_category": "stat.ML",
        "categories": [
            "cs.LG",
            "math.FA",
            "math.PR",
            "q-fin.MF"
        ],
        "submitted_date": "5 Jun 2023",
        "last_revised_date": " "
    },
    "2306.03424": {
        "title": "GCD-DDPM: A Generative Change Detection Model Based on Difference-Feature Guided DDPM",
        "authors": [
            "Yihan Wen",
            "Xianping Ma",
            "Xiaokang Zhang",
            "Man-On Pun"
        ],
        "comments": " ",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Deep learning (DL)-based methods have recently shown great promise in bitemporal change detection (CD). Existing discriminative methods based on Convolutional Neural Networks (CNNs) and Transformers rely on discriminative representation learning for change recognition while struggling with exploring local and long-range contextual dependencies. As a result, it is still challenging to obtain fine-grained and robust CD maps in diverse ground scenes. To cope with this challenge, this work proposes a generative change detection model called GCD-DDPM to directly generate CD maps by exploiting the Denoising Diffusion Probabilistic Model (DDPM), instead of classifying each pixel into changed or unchanged categories. Furthermore, the Difference Conditional Encoder (DCE), is designed to guide the generation of CD maps by exploiting multi-level difference features. Leveraging the variational inference (VI) procedure, GCD-DDPM can adaptively re-calibrate the CD results through an iterative inference process, while accurately distinguishing subtle and irregular changes in diverse scenes. Finally, a Noise Suppression-based Semantic Enhancer (NSSE) is specifically designed to mitigate noise in the current step's change-aware feature representations from the CD Encoder. This refinement, serving as an attention map, can guide subsequent iterations while enhancing CD accuracy. Extensive experiments on four high-resolution CD datasets confirm the superior performance of the proposed GCD-DDPM. The code for this work will be available at this https URL.\n    ",
        "primary_category": "cs.CV",
        "categories": [],
        "submitted_date": "6 Jun 2023",
        "last_revised_date": " "
    },
    "2306.03621": {
        "title": "Pathwidth vs cocircumference",
        "authors": [
            "Marcin Bria\u0144ski",
            "Gwena\u00ebl Joret",
            "Micha\u0142 T. Seweryn"
        ],
        "comments": "v2: revised following the referees' comments",
        "subjects": "Combinatorics (math.CO)",
        "abstract": "The {\\em circumference} of a graph $G$ with at least one cycle is the length of a longest cycle in $G$. A classic result of Birmel\u00e9 (2003) states that the treewidth of $G$ is at most its circumference minus $1$. In case $G$ is $2$-connected, this upper bound also holds for the pathwidth of $G$; in fact, even the treedepth of $G$ is upper bounded by its circumference (Bria\u0144ski, Joret, Majewski, Micek, Seweryn, Sharma; 2023). In this paper, we study whether similar bounds hold when replacing the circumference of $G$ by its {\\em cocircumference}, defined as the largest size of a {\\em bond} in $G$, an inclusion-wise minimal set of edges $F$ such that $G-F$ has more components than $G$. In matroidal terms, the cocircumference of $G$ is the circumference of the bond matroid of $G$.\nOur first result is the following `dual' version of Birmel\u00e9's theorem: The treewidth of a graph $G$ is at most its cocircumference. Our second and main result is an upper bound of $3k-2$ on the pathwidth of a $2$-connected graph $G$ with cocircumference $k$. Contrary to circumference, no such bound holds for the treedepth of $G$. Our two upper bounds are best possible up to a constant factor.\n    ",
        "primary_category": "math.CO",
        "categories": [
            "cs.DM"
        ],
        "submitted_date": "6 Jun 2023",
        "last_revised_date": " "
    },
    "2306.03928": {
        "title": "Designing Decision Support Systems Using Counterfactual Prediction Sets",
        "authors": [
            "Eleni Straitouri",
            "Manuel Gomez Rodriguez"
        ],
        "comments": "Best paper award in the ICML 2023 AI&HCI Workshop",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Decision support systems for classification tasks are predominantly designed to predict the value of the ground truth labels. However, since their predictions are not perfect, these systems also need to make human experts understand when and how to use these predictions to update their own predictions. Unfortunately, this has been proven challenging. In this context, it has been recently argued that an alternative type of decision support systems may circumvent this challenge. Rather than providing a single label prediction, these systems provide a set of label prediction values constructed using a conformal predictor, namely a prediction set, and forcefully ask experts to predict a label value from the prediction set. However, the design and evaluation of these systems have so far relied on stylized expert models, questioning their promise. In this paper, we revisit the design of this type of systems from the perspective of online learning and develop a methodology that does not require, nor assumes, an expert model. Our methodology leverages the nested structure of the prediction sets provided by any conformal predictor and a natural counterfactual monotonicity assumption to achieve an exponential improvement in regret in comparison to vanilla bandit algorithms. We conduct a large-scale human subject study ($n = 2{,}751$) to compare our methodology to several competitive baselines. The results show that, for decision support systems based on prediction sets, limiting experts' level of agency leads to greater performance than allowing experts to always exercise their own agency. We have made available the data gathered in our human subject study as well as an open source implementation of our system at this https URL.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.CY",
            "cs.HC",
            "stat.ME",
            "stat.ML"
        ],
        "submitted_date": "6 Jun 2023",
        "last_revised_date": " "
    },
    "2306.04815": {
        "title": "Catapults in SGD: spikes in the training loss and their impact on generalization through feature learning",
        "authors": [
            "Libin Zhu",
            "Chaoyue Liu",
            "Adityanarayanan Radhakrishnan",
            "Mikhail Belkin"
        ],
        "comments": " ",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "In this paper, we first present an explanation regarding the common occurrence of spikes in the training loss when neural networks are trained with stochastic gradient descent (SGD). We provide evidence that the spikes in the training loss of SGD are \"catapults\", an optimization phenomenon originally observed in GD with large learning rates in [Lewkowycz et al. 2020]. We empirically show that these catapults occur in a low-dimensional subspace spanned by the top eigenvectors of the tangent kernel, for both GD and SGD. Second, we posit an explanation for how catapults lead to better generalization by demonstrating that catapults promote feature learning by increasing alignment with the Average Gradient Outer Product (AGOP) of the true predictor. Furthermore, we demonstrate that a smaller batch size in SGD induces a larger number of catapults, thereby improving AGOP alignment and test performance.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "math.OC",
            "stat.ML"
        ],
        "submitted_date": "7 Jun 2023",
        "last_revised_date": " "
    },
    "2306.05499": {
        "title": "Prompt Injection attack against LLM-integrated Applications",
        "authors": [
            "Yi Liu",
            "Gelei Deng",
            "Yuekang Li",
            "Kailong Wang",
            "Zihao Wang",
            "Xiaofeng Wang",
            "Tianwei Zhang",
            "Yepang Liu",
            "Haoyu Wang",
            "Yan Zheng",
            "Yang Liu"
        ],
        "comments": " ",
        "subjects": "Cryptography and Security (cs.CR)",
        "abstract": "Large Language Models (LLMs), renowned for their superior proficiency in language comprehension and generation, stimulate a vibrant ecosystem of applications around them. However, their extensive assimilation into various services introduces significant security risks. This study deconstructs the complexities and implications of prompt injection attacks on actual LLM-integrated applications. Initially, we conduct an exploratory analysis on ten commercial applications, highlighting the constraints of current attack strategies in practice. Prompted by these limitations, we subsequently formulate HouYi, a novel black-box prompt injection attack technique, which draws inspiration from traditional web injection attacks. HouYi is compartmentalized into three crucial elements: a seamlessly-incorporated pre-constructed prompt, an injection prompt inducing context partition, and a malicious payload designed to fulfill the attack objectives. Leveraging HouYi, we unveil previously unknown and severe attack outcomes, such as unrestricted arbitrary LLM usage and uncomplicated application prompt theft. We deploy HouYi on 36 actual LLM-integrated applications and discern 31 applications susceptible to prompt injection. 10 vendors have validated our discoveries, including Notion, which has the potential to impact millions of users. Our investigation illuminates both the possible risks of prompt injection attacks and the possible tactics for mitigation.\n    ",
        "primary_category": "cs.CR",
        "categories": [
            "cs.AI",
            "cs.CL",
            "cs.SE"
        ],
        "submitted_date": "8 Jun 2023",
        "last_revised_date": " "
    },
    "2306.05780": {
        "title": "A space-time DG method for the Schr\u00f6dinger equation with variable potential",
        "authors": [
            "Sergio G\u00f3mez",
            "Andrea Moiola"
        ],
        "comments": " ",
        "subjects": "Numerical Analysis (math.NA)",
        "abstract": "We present a space-time ultra-weak discontinuous Galerkin discretization of the linear Schr\u00f6dinger equation with variable potential. The proposed method is well-posed and quasi-optimal in mesh-dependent norms for very general discrete spaces. Optimal $h$-convergence error estimates are derived for the method when test and trial spaces are chosen either as piecewise polynomials, or as a novel quasi-Trefftz polynomial space. The latter allows for a substantial reduction of the number of degrees of freedom and admits piecewise-smooth potentials. Several numerical experiments validate the accuracy and advantages of the proposed method.\n    ",
        "primary_category": "math.NA",
        "categories": [],
        "submitted_date": "9 Jun 2023",
        "last_revised_date": " "
    },
    "2306.06022": {
        "title": "Dynamic Partial Computation Offloading for the Metaverse in In-Network Computing",
        "authors": [
            "Ibrahim Aliyu",
            "Seungmin Oh",
            "Namseok Ko",
            "Tai-Won Um",
            "Jinsul Kim"
        ],
        "comments": "14 pages, 9 figures",
        "subjects": "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "abstract": "The computing in the network (COIN) paradigm is a promising solution that leverages unused network resources to perform tasks to meet computation-demanding applications, such as the metaverse. In this vein, we consider the partial computation offloading problem in the metaverse for multiple subtasks in a COIN environment to minimize energy consumption and delay while dynamically adjusting the offloading policy based on the changing computational resource status. The problem is NP-hard, and we transform it into two subproblems: the task-splitting problem (TSP) on the user side and the task-offloading problem (TOP) on the COIN side. We model the TSP as an ordinal potential game and propose a decentralized algorithm to obtain its Nash equilibrium (NE). Then, we model the TOP as a Markov decision process and propose the double deep Q-network (DDQN) to solve for the optimal offloading policy. Unlike the conventional DDQN algorithm, where intelligent agents sample offloading decisions randomly within a certain probability, the COIN agent explores the NE of the TSP and the deep neural network. Finally, the simulation results reveal that the proposed model approach allows the COIN agent to update its policies and make more informed decisions, leading to improved performance over time compared to the traditional baseline\n    ",
        "primary_category": "cs.DC",
        "categories": [
            "cs.AI",
            "cs.GT"
        ],
        "submitted_date": "9 Jun 2023",
        "last_revised_date": " "
    },
    "2306.06027": {
        "title": "VarSaw: Application-tailored Measurement Error Mitigation for Variational Quantum Algorithms",
        "authors": [
            "Siddharth Dangwal",
            "Gokul Subramanian Ravi",
            "Poulami Das",
            "Kaitlin N. Smith",
            "Jonathan M. Baker",
            "Frederic T. Chong"
        ],
        "comments": "Appears at the International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS) 2024. First two authors contributed equally",
        "subjects": "Quantum Physics (quant-ph)",
        "abstract": "For potential quantum advantage, Variational Quantum Algorithms (VQAs) need high accuracy beyond the capability of today's NISQ devices, and thus will benefit from error mitigation. In this work we are interested in mitigating measurement errors which occur during qubit measurements after circuit execution and tend to be the most error-prone operations, especially detrimental to VQAs. Prior work, JigSaw, has shown that measuring only small subsets of circuit qubits at a time and collecting results across all such subset circuits can reduce measurement errors. Then, running the entire (global) original circuit and extracting the qubit-qubit measurement correlations can be used in conjunction with the subsets to construct a high-fidelity output distribution of the original circuit. Unfortunately, the execution cost of JigSaw scales polynomially in the number of qubits in the circuit, and when compounded by the number of circuits and iterations in VQAs, the resulting execution cost quickly turns insurmountable.\nTo combat this, we propose VarSaw, which improves JigSaw in an application-tailored manner, by identifying considerable redundancy in the JigSaw approach for VQAs: spatial redundancy across subsets from different VQA circuits and temporal redundancy across globals from different VQA iterations. VarSaw then eliminates these forms of redundancy by commuting the subset circuits and selectively executing the global circuits, reducing computational cost (in terms of the number of circuits executed) over naive JigSaw for VQA by 25x on average and up to 1000x, for the same VQA accuracy. Further, it can recover, on average, 45% of the infidelity from measurement errors in the noisy VQA baseline. Finally, it improves fidelity by 55%, on average, over JigSaw for a fixed computational budget. VarSaw can be accessed here: this https URL.\n    ",
        "primary_category": "quant-ph",
        "categories": [
            "cs.AR",
            "cs.ET"
        ],
        "submitted_date": "9 Jun 2023",
        "last_revised_date": " "
    },
    "2306.06112": {
        "title": "ModelObfuscator: Obfuscating Model Information to Protect Deployed ML-based Systems",
        "authors": [
            "Mingyi Zhou",
            "Xiang Gao",
            "Jing Wu",
            "John Grundy",
            "Xiao Chen",
            "Chunyang Chen",
            "Li Li"
        ],
        "comments": "Published In Proceedings of the 32nd ACM SIGSOFT International Symposium on Software Testing and Analysis (ISSTA23)",
        "subjects": "Cryptography and Security (cs.CR)",
        "abstract": "More and more edge devices and mobile apps are leveraging deep learning (DL) capabilities. Deploying such models on devices -- referred to as on-device models -- rather than as remote cloud-hosted services, has gained popularity because it avoids transmitting user data off of the device and achieves high response time. However, on-device models can be easily attacked, as they can be accessed by unpacking corresponding apps and the model is fully exposed to attackers. Recent studies show that attackers can easily generate white-box-like attacks for an on-device model or even inverse its training data. To protect on-device models from white-box attacks, we propose a novel technique called model obfuscation. Specifically, model obfuscation hides and obfuscates the key information -- structure, parameters and attributes -- of models by renaming, parameter encapsulation, neural structure obfuscation obfuscation, shortcut injection, and extra layer injection. We have developed a prototype tool ModelObfuscator to automatically obfuscate on-device TFLite models. Our experiments show that this proposed approach can dramatically improve model security by significantly increasing the difficulty of parsing models inner information, without increasing the latency of DL models. Our proposed on-device model obfuscation has the potential to be a fundamental technique for on-device model deployment. Our prototype tool is publicly available at: this https URL.\n    ",
        "primary_category": "cs.CR",
        "categories": [],
        "submitted_date": "1 Jun 2023",
        "last_revised_date": " "
    },
    "2306.06458": {
        "title": "Rate-Splitting Multiple Access for Simultaneous Multi-User Communication and Multi-Target Sensing",
        "authors": [
            "Kexin Chen",
            "Yijie Mao",
            "Longfei Yin",
            "Chengcheng Xu",
            "Yang Huang"
        ],
        "comments": " ",
        "subjects": "Information Theory (cs.IT)",
        "abstract": "In this paper, we initiate the study of rate-splitting multiple access (RSMA) for a mono-static integrated sensing and communication (ISAC) system, where the dual-functional base station (BS) simultaneously communicates with multiple users and detects multiple moving targets. We aim at optimizing the ISAC waveform to jointly maximize the max-min fairness (MMF) rate of the communication users and minimize the largest eigenvalue of the Cram\u00e9r-Rao bound (CRB) matrix for unbiased estimation. The CRB matrix considered in this work is general as it involves the estimation of angular direction, complex reflection coefficient, and Doppler frequency for multiple moving targets. Simulation results demonstrate that RSMA maintains a larger communication and sensing trade-off than conventional space-division multiple access (SDMA) and it is capable of detecting multiple targets with a high detection accuracy. The finding highlights the potential of RSMA as an effective and powerful strategy for interference management in the general multi-user multi-target ISAC systems.\n    ",
        "primary_category": "cs.IT",
        "categories": [
            "eess.SP"
        ],
        "submitted_date": "10 Jun 2023",
        "last_revised_date": " "
    },
    "2306.07490": {
        "title": "Top-Down Framework for Weakly-supervised Grounded Image Captioning",
        "authors": [
            "Chen Cai",
            "Suchen Wang",
            "Kim-hui Yap",
            "Yi Wang"
        ],
        "comments": " ",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Weakly-supervised grounded image captioning (WSGIC) aims to generate the caption and ground (localize) predicted object words in the input image without using bounding box supervision. Recent two-stage solutions mostly apply a bottom-up pipeline: (1) encode the input image into multiple region features using an object detector; (2) leverage region features for captioning and grounding. However, utilizing independent proposals produced by object detectors tends to make the subsequent grounded captioner overfitted in finding the correct object words, overlooking the relation between objects, and selecting incompatible proposal regions for grounding. To address these issues, we propose a one-stage weakly-supervised grounded captioner that directly takes the RGB image as input to perform captioning and grounding at the top-down image level. Specifically, we encode the image into visual token representations and propose a Recurrent Grounding Module (RGM) in the decoder to obtain precise Visual Language Attention Maps (VLAMs), which recognize the spatial locations of the objects. In addition, we explicitly inject a relation module into our one-stage framework to encourage relation understanding through multi-label classification. This relation semantics served as contextual information facilitating the prediction of relation and object words in the caption. We observe that the relation semantic not only assists the grounded captioner in generating a more accurate caption but also improves the grounding performance. We validate the effectiveness of our proposed method on two challenging datasets (Flick30k Entities captioning and MSCOCO captioning). The experimental results demonstrate that our method achieves state-of-the-art grounding performance.\n    ",
        "primary_category": "cs.CV",
        "categories": [],
        "submitted_date": "13 Jun 2023",
        "last_revised_date": " "
    },
    "2306.07669": {
        "title": "Rate-Splitting with Hybrid Messages: DoF Analysis of the Two-User MIMO Broadcast Channel with Imperfect CSIT",
        "authors": [
            "Tong Zhang",
            "Yufan Zhuang",
            "Gaojie Chen",
            "Shuai Wang",
            "Bojie Lv",
            "Rui Wang",
            "Pei Xiao"
        ],
        "comments": "15 pages, double column",
        "subjects": "Information Theory (cs.IT)",
        "abstract": "Most of the existing research on degrees-of-freedom (DoF) with imperfect channel state information at the transmitter (CSIT) assume the messages are private, which may not reflect reality as the two receivers can request the same content. To overcome this limitation, we therefore consider the hybrid unicast and multicast messages. In particular, we characterize the optimal DoF region for the two-user multiple-input multiple-output (MIMO) broadcast channel (BC) with imperfect CSIT and hybrid messages. For the converse, we establish a three-step procedure to exploit the utmost possible relaxation. For the achievability, since the DoF region is with specific three-dimensional structure regarding antenna configurations and CSIT qualities, we verify the existence or non-existence of corner point candidates via the feature of antenna configurations and CSIT qualities categorization and provide a hybrid message-aware rate-splitting scheme. Besides, we show that to achieve the strictly positive corner points, it is unnecessary to split the unicast messages into private and common parts. This implies adding a multicast message may mitigate the rate-splitting complexity.\n    ",
        "primary_category": "cs.IT",
        "categories": [],
        "submitted_date": "13 Jun 2023",
        "last_revised_date": " "
    },
    "2306.08018": {
        "title": "Mol-Instructions: A Large-Scale Biomolecular Instruction Dataset for Large Language Models",
        "authors": [
            "Yin Fang",
            "Xiaozhuan Liang",
            "Ningyu Zhang",
            "Kangwei Liu",
            "Rui Huang",
            "Zhuo Chen",
            "Xiaohui Fan",
            "Huajun Chen"
        ],
        "comments": "ICLR 2024. Project homepage: this https URL",
        "subjects": "Quantitative Methods (q-bio.QM)",
        "abstract": "Large Language Models (LLMs), with their remarkable task-handling capabilities and innovative outputs, have catalyzed significant advancements across a spectrum of fields. However, their proficiency within specialized domains such as biomolecular studies remains limited. To address this challenge, we introduce Mol-Instructions, a comprehensive instruction dataset designed for the biomolecular domain. Mol-Instructions encompasses three key components: molecule-oriented instructions, protein-oriented instructions, and biomolecular text instructions. Each component aims to improve the understanding and prediction capabilities of LLMs concerning biomolecular features and behaviors. Through extensive instruction tuning experiments on LLMs, we demonstrate the effectiveness of Mol-Instructions in enhancing large models' performance in the intricate realm of biomolecular studies, thus fostering progress in the biomolecular research community. Mol-Instructions is publicly available for ongoing research and will undergo regular updates to enhance its applicability.\n    ",
        "primary_category": "q-bio.QM",
        "categories": [
            "cs.AI",
            "cs.CE",
            "cs.CL",
            "cs.IR",
            "cs.LG"
        ],
        "submitted_date": "13 Jun 2023",
        "last_revised_date": " "
    },
    "2306.08069": {
        "title": "On $(n,m)$-chromatic numbers of graphs having bounded sparsity parameters",
        "authors": [
            "Sandip Das",
            "Abhiruk Lahiri",
            "Soumen Nandi",
            "Sagnik Sen",
            "S Taruni"
        ],
        "comments": "18 pages",
        "subjects": "Combinatorics (math.CO)",
        "abstract": "An $(n,m)$-graph is characterised by having $n$ types of arcs and $m$ types of edges. A homomorphism of an $(n,m)$-graph $G$ to an $(n,m)$-graph $H$, is a vertex mapping that preserves adjacency, direction, and type. The $(n,m)$-chromatic number of $G$, denoted by $\\chi_{n,m}(G)$, is the minimum value of $|V(H)|$ such that there exists a homomorphism of $G$ to $H$. The theory of homomorphisms of $(n,m)$-graphs have connections with graph theoretic concepts like harmonious coloring, nowhere-zero flows; with other mathematical topics like binary predicate logic, Coxeter groups; and has application to the Query Evaluation Problem (QEP) in graph database.\nIn this article, we show that the arboricity of $G$ is bounded by a function of $\\chi_{n,m}(G)$ but not the other way around. Additionally, we show that the acyclic chromatic number of $G$ is bounded by a function of $\\chi_{n,m}(G)$, a result already known in the reverse direction. Furthermore, we prove that the $(n,m)$-chromatic number for the family of graphs with a maximum average degree less than $2+ \\frac{2}{4(2n+m)-1}$, including the subfamily of planar graphs with girth at least $8(2n+m)$, equals $2(2n+m)+1$. This improves upon previous findings, which proved the $(n,m)$-chromatic number for planar graphs with girth at least $10(2n+m)-4$ is $2(2n+m)+1$.\nIt is established that the $(n,m)$-chromatic number for the family $\\mathcal{T}_2$ of partial $2$-trees is both bounded below and above by quadratic functions of $(2n+m)$, with the lower bound being tight when $(2n+m)=2$. We prove $14 \\leq \\chi_{(0,3)}(\\mathcal{T}_2) \\leq 15$ and $14 \\leq \\chi_{(1,1)}(\\mathcal{T}_2) \\leq 21$ which improves both known lower bounds and the former upper bound. Moreover, for the latter upper bound, to the best of our knowledge we provide the first theoretical proof.\n    ",
        "primary_category": "math.CO",
        "categories": [
            "cs.DM"
        ],
        "submitted_date": "13 Jun 2023",
        "last_revised_date": " "
    },
    "2306.08158": {
        "title": "Sociodemographic Bias in Language Models: A Survey and Forward Path",
        "authors": [
            "Vipul Gupta",
            "Pranav Narayanan Venkit",
            "Shomir Wilson",
            "Rebecca J. Passonneau"
        ],
        "comments": "23 pages, 3 figure",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "This paper presents a comprehensive survey of work on sociodemographic bias in language models (LMs). Sociodemographic biases embedded within language models can have harmful effects when deployed in real-world settings. We systematically organize the existing literature into three main areas: types of bias, quantifying bias, and debiasing techniques. We also track the evolution of investigations of LM bias over the past decade. We identify current trends, limitations, and potential future directions in bias research. To guide future research towards more effective and reliable solutions, we present a checklist of open questions. We also recommend using interdisciplinary approaches to combine works on LM bias with an understanding of the potential harms.\n    ",
        "primary_category": "cs.CL",
        "categories": [
            "cs.AI",
            "cs.LG"
        ],
        "submitted_date": "13 Jun 2023",
        "last_revised_date": " "
    },
    "2306.08173": {
        "title": "Safeguarding Data in Multimodal AI: A Differentially Private Approach to CLIP Training",
        "authors": [
            "Alyssa Huang",
            "Peihan Liu",
            "Ryumei Nakada",
            "Linjun Zhang",
            "Wanrong Zhang"
        ],
        "comments": " ",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "The surge in multimodal AI's success has sparked concerns over data privacy in vision-and-language tasks. While CLIP has revolutionized multimodal learning through joint training on images and text, its potential to unintentionally disclose sensitive information necessitates the integration of privacy-preserving mechanisms. We introduce a differentially private adaptation of the Contrastive Language-Image Pretraining (CLIP) model that effectively addresses privacy concerns while retaining accuracy. Our proposed method, Dp-CLIP, is rigorously evaluated on benchmark datasets encompassing diverse vision-and-language tasks such as image classification and visual question answering. We demonstrate that our approach retains performance on par with the standard non-private CLIP model. Furthermore, we analyze our proposed algorithm under linear representation settings. We derive the convergence rate of our algorithm and show a trade-off between utility and privacy when gradients are clipped per-batch and the loss function does not satisfy smoothness conditions assumed in the literature for the analysis of DP-SGD.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.CR",
            "cs.IT",
            "stat.ML"
        ],
        "submitted_date": "13 Jun 2023",
        "last_revised_date": " "
    },
    "2306.08175": {
        "title": "DCTX-Conformer: Dynamic context carry-over for low latency unified streaming and non-streaming Conformer ASR",
        "authors": [
            "Goeric Huybrechts",
            "Srikanth Ronanki",
            "Xilai Li",
            "Hadis Nosrati",
            "Sravan Bodapati",
            "Katrin Kirchhoff"
        ],
        "comments": " ",
        "subjects": "Audio and Speech Processing (eess.AS)",
        "abstract": "Conformer-based end-to-end models have become ubiquitous these days and are commonly used in both streaming and non-streaming automatic speech recognition (ASR). Techniques like dual-mode and dynamic chunk training helped unify streaming and non-streaming systems. However, there remains a performance gap between streaming with a full and limited past context. To address this issue, we propose the integration of a novel dynamic contextual carry-over mechanism in a state-of-the-art (SOTA) unified ASR system. Our proposed dynamic context Conformer (DCTX-Conformer) utilizes a non-overlapping contextual carry-over mechanism that takes into account both the left context of a chunk and one or more preceding context embeddings. We outperform the SOTA by a relative 25.0% word error rate, with a negligible latency impact due to the additional context embeddings.\n    ",
        "primary_category": "eess.AS",
        "categories": [
            "cs.AI",
            "cs.LG",
            "cs.SD"
        ],
        "submitted_date": "13 Jun 2023",
        "last_revised_date": " "
    },
    "2306.08625": {
        "title": "RRSIS: Referring Remote Sensing Image Segmentation",
        "authors": [
            "Zhenghang Yuan",
            "Lichao Mou",
            "Yuansheng Hua",
            "Xiao Xiang Zhu"
        ],
        "comments": " ",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Localizing desired objects from remote sensing images is of great use in practical applications. Referring image segmentation, which aims at segmenting out the objects to which a given expression refers, has been extensively studied in natural images. However, almost no research attention is given to this task of remote sensing imagery. Considering its potential for real-world applications, in this paper, we introduce referring remote sensing image segmentation (RRSIS) to fill in this gap and make some insightful explorations. Specifically, we create a new dataset, called RefSegRS, for this task, enabling us to evaluate different methods. Afterward, we benchmark referring image segmentation methods of natural images on the RefSegRS dataset and find that these models show limited efficacy in detecting small and scattered objects. To alleviate this issue, we propose a language-guided cross-scale enhancement (LGCE) module that utilizes linguistic features to adaptively enhance multi-scale visual features by integrating both deep and shallow features. The proposed dataset, benchmarking results, and the designed LGCE module provide insights into the design of a better RRSIS model. We will make our dataset and code publicly available.\n    ",
        "primary_category": "cs.CV",
        "categories": [],
        "submitted_date": "14 Jun 2023",
        "last_revised_date": " "
    },
    "2306.08823": {
        "title": "Plug-in Hybrid Electric Vehicle Energy Management with Clutch Engagement Control via Continuous-Discrete Reinforcement Learning",
        "authors": [
            "Changfu Gong",
            "Jinming Xu",
            "Yuan Lin"
        ],
        "comments": " ",
        "subjects": "Systems and Control (eess.SY)",
        "abstract": "Energy management strategy (EMS) is a key technology for plug-in hybrid electric vehicles (PHEVs). The energy management of certain series-parallel PHEVs involves the control of continuous variables, such as engine torque, and discrete variables, such as clutch engagement/disengagement. We establish a control-oriented model for a series-parallel plug-in hybrid system with clutch engagement control from the perspective of mixed-integer programming. Subsequently, we design an EMS based on continuous-discrete reinforcement learning (CDRL), which enables simultaneous output of continuous and discrete variables. During training, we introduce state-of-charge (SOC) randomization to ensure that the hybrid system exhibits optimal energy-saving performance in both high and low SOC. Finally, the effectiveness of the proposed CDRL strategy is verified by comparing EMS based on charge-depleting charge-sustaining (CD-CS) with rule-based clutch engagement control, and Dynamic Programming (DP). The simulation results show that, under a high SOC, the CDRL strategy proposed in this paper can improve energy efficiency by 8.3% compared to CD-CS, and the energy consumption is just 6.6% higher than the global optimum based on DP, while under a low SOC, the numbers are 4.1% and 3.9%, respectively.\n    ",
        "primary_category": "eess.SY",
        "categories": [],
        "submitted_date": "15 Jun 2023",
        "last_revised_date": " "
    },
    "2306.08887": {
        "title": "SplatFlow: Learning Multi-frame Optical Flow via Splatting",
        "authors": [
            "Bo Wang",
            "Yifan Zhang",
            "Jian Li",
            "Yang Yu",
            "Zhenping Sun",
            "Li Liu",
            "Dewen Hu"
        ],
        "comments": " ",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "The occlusion problem remains a crucial challenge in optical flow estimation (OFE). Despite the recent significant progress brought about by deep learning, most existing deep learning OFE methods still struggle to handle occlusions; in particular, those based on two frames cannot correctly handle occlusions because occluded regions have no visual correspondences. However, there is still hope in multi-frame settings, which can potentially mitigate the occlusion issue in OFE. Unfortunately, multi-frame OFE (MOFE) remains underexplored, and the limited studies on it are mainly specially designed for pyramid backbones or else obtain the aligned previous frame's features, such as correlation volume and optical flow, through time-consuming backward flow calculation or non-differentiable forward warping transformation. This study proposes an efficient MOFE framework named SplatFlow to address these shortcomings. SplatFlow introduces the differentiable splatting transformation to align the previous frame's motion feature and designs a Final-to-All embedding method to input the aligned motion feature into the current frame's estimation, thus remodeling the existing two-frame backbones. The proposed SplatFlow is efficient yet more accurate, as it can handle occlusions properly. Extensive experimental evaluations show that SplatFlow substantially outperforms all published methods on the KITTI2015 and Sintel benchmarks. Especially on the Sintel benchmark, SplatFlow achieves errors of 1.12 (clean pass) and 2.07 (final pass), with surprisingly significant 19.4% and 16.2% error reductions, respectively, from the previous best results submitted. The code for SplatFlow is available at this https URL.\n    ",
        "primary_category": "cs.CV",
        "categories": [],
        "submitted_date": "15 Jun 2023",
        "last_revised_date": " "
    },
    "2306.09348": {
        "title": "Seeing the World through Your Eyes",
        "authors": [
            "Hadi Alzayer",
            "Kevin Zhang",
            "Brandon Feng",
            "Christopher Metzler",
            "Jia-Bin Huang"
        ],
        "comments": "CVPR 2024. First two authors contributed equally. Project page: this https URL",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "The reflective nature of the human eye is an underappreciated source of information about what the world around us looks like. By imaging the eyes of a moving person, we can collect multiple views of a scene outside the camera's direct line of sight through the reflections in the eyes. In this paper, we reconstruct a 3D scene beyond the camera's line of sight using portrait images containing eye reflections. This task is challenging due to 1) the difficulty of accurately estimating eye poses and 2) the entangled appearance of the eye iris and the scene reflections. Our method jointly refines the cornea poses, the radiance field depicting the scene, and the observer's eye iris texture. We further propose a simple regularization prior on the iris texture pattern to improve reconstruction quality. Through various experiments on synthetic and real-world captures featuring people with varied eye colors, we demonstrate the feasibility of our approach to recover 3D scenes using eye reflections.\n    ",
        "primary_category": "cs.CV",
        "categories": [],
        "submitted_date": "15 Jun 2023",
        "last_revised_date": " "
    },
    "2306.09547": {
        "title": "Training generative models from privatized data",
        "authors": [
            "Daria Reshetova",
            "Wei-Ning Chen",
            "Ayfer \u00d6zg\u00fcr"
        ],
        "comments": " ",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Local differential privacy is a powerful method for privacy-preserving data collection. In this paper, we develop a framework for training Generative Adversarial Networks (GANs) on differentially privatized data. We show that entropic regularization of optimal transport - a popular regularization method in the literature that has often been leveraged for its computational benefits - enables the generator to learn the raw (unprivatized) data distribution even though it only has access to privatized samples. We prove that at the same time this leads to fast statistical convergence at the parametric rate. This shows that entropic regularization of optimal transport uniquely enables the mitigation of both the effects of privatization noise and the curse of dimensionality in statistical convergence. We provide experimental evidence to support the efficacy of our framework in practice.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.CR",
            "cs.IT"
        ],
        "submitted_date": "15 Jun 2023",
        "last_revised_date": " "
    },
    "2306.09731": {
        "title": "Numerical study of the Serre-Green-Naghdi equations in 2D",
        "authors": [
            "S. Gavrilyuk",
            "C. Klein"
        ],
        "comments": "Minor changes",
        "subjects": "Analysis of PDEs (math.AP)",
        "abstract": "A detailed numerical study of solutions to the Serre-Green-Naghdi (SGN) equations in 2D with vanishing curl of the velocity field is presented. The transverse stability of line solitary waves, 1D solitary waves being exact solutions of the 2D equations independent of the second variable, is established numerically. The study of localized initial data as well as crossing 1D solitary waves does not give an indication of existence of stable structures in SGN solutions localized in two spatial dimensions. For the numerical experiments, an approach based on a Fourier spectral method with a Krylov subspace technique is applied.\n    ",
        "primary_category": "math.AP",
        "categories": [
            "math.NA"
        ],
        "submitted_date": "16 Jun 2023",
        "last_revised_date": " "
    },
    "2306.09910": {
        "title": "LabelBench: A Comprehensive Framework for Benchmarking Adaptive Label-Efficient Learning",
        "authors": [
            "Jifan Zhang",
            "Yifang Chen",
            "Gregory Canal",
            "Stephen Mussmann",
            "Arnav M. Das",
            "Gantavya Bhatt",
            "Yinglun Zhu",
            "Jeffrey Bilmes",
            "Simon Shaolei Du",
            "Kevin Jamieson",
            "Robert D Nowak"
        ],
        "comments": " ",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Labeled data are critical to modern machine learning applications, but obtaining labels can be expensive. To mitigate this cost, machine learning methods, such as transfer learning, semi-supervised learning and active learning, aim to be label-efficient: achieving high predictive performance from relatively few labeled examples. While obtaining the best label-efficiency in practice often requires combinations of these techniques, existing benchmark and evaluation frameworks do not capture a concerted combination of all such techniques. This paper addresses this deficiency by introducing LabelBench, a new computationally-efficient framework for joint evaluation of multiple label-efficient learning techniques. As an application of LabelBench, we introduce a novel benchmark of state-of-the-art active learning methods in combination with semi-supervised learning for fine-tuning pretrained vision transformers. Our benchmark demonstrates better label-efficiencies than previously reported in active learning. LabelBench's modular codebase is open-sourced for the broader community to contribute label-efficient learning methods and benchmarks. The repository can be found at: this https URL.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.AI",
            "cs.CV"
        ],
        "submitted_date": "16 Jun 2023",
        "last_revised_date": " "
    },
    "2306.10356": {
        "title": "MATNet: Multi-Level Fusion Transformer-Based Model for Day-Ahead PV Generation Forecasting",
        "authors": [
            "Matteo Tortora",
            "Francesco Conte",
            "Gianluca Natrella",
            "Paolo Soda"
        ],
        "comments": " ",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Accurate forecasting of renewable generation is crucial to facilitate the integration of RES into the power system. Focusing on PV units, forecasting methods can be divided into two main categories: physics-based and data-based strategies, with AI-based models providing state-of-the-art performance. However, while these AI-based models can capture complex patterns and relationships in the data, they ignore the underlying physical prior knowledge of the phenomenon. Therefore, in this paper we propose MATNet, a novel self-attention transformer-based architecture for multivariate multi-step day-ahead PV power generation forecasting. It consists of a hybrid approach that combines the AI paradigm with the prior physical knowledge of PV power generation of physics-based methods. The model is fed with historical PV data and historical and forecast weather data through a multi-level joint fusion approach. The effectiveness of the proposed model is evaluated using the Ausgrid benchmark dataset with different regression performance metrics. The results show that our proposed architecture significantly outperforms the current state-of-the-art methods. These findings demonstrate the potential of MATNet in improving forecasting accuracy and suggest that it could be a promising solution to facilitate the integration of PV energy into the power grid.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.AI",
            "eess.SP"
        ],
        "submitted_date": "17 Jun 2023",
        "last_revised_date": " "
    },
    "2306.11172": {
        "title": "Deep Learning-based Auto-encoder for Time-offset Faster-than-Nyquist Downlink NOMA with Timing Errors and Imperfect CSI",
        "authors": [
            "Ahmed Aboutaleb",
            "Mohammad Torabi",
            "Benjamin Belzer",
            "Krishnamoorthy Sivakumar"
        ],
        "comments": " ",
        "subjects": "Signal Processing (eess.SP)",
        "abstract": "We examine encoding and decoding of transmitted sequences for the downlink time-offset faster than Nyquist signaling non-orthogonal multiple access NOMA (T-NOMA) channel. We employ a previously proposed singular value decomposition (SVD)-based scheme as a benchmark. While this SVD scheme provides reliable communication, our findings reveal that it is not optimal in terms of bit error rate (BER). Additionally, the SVD is sensitive to timing offset errors, and its time complexity increases quadratically with the sequence length. We propose a convolutional neural network (CNN) auto-encoder (AE) for encoding and decoding with linear time complexity. We explain the design of the encoder and decoder architectures and the training criteria. By examining several variants of the CNN AE, we show that it can achieve an excellent trade-off between performance and complexity. The proposed CNN AE surpasses the SVD method by approximately 2 dB in a T-NOMA system with no timing offset errors or channel state information estimation errors. In the presence of channel state information (CSI) error variance of 1$\\%$ and uniform timing error at $\\pm$4\\% of the symbol interval, the proposed CNN AE provides up to 10 dB SNR gain over the SVD method. We also propose a novel modified training objective function consisting of a linear combination of the traditionally used cross-entropy (CE) loss function and a closed-form expression for the bit error rate (BER) called the Q-loss function. Simulations show that the modified loss function achieves SNR gains of up to 1 dB over the CE loss function alone.\n    ",
        "primary_category": "eess.SP",
        "categories": [
            "eess.SY"
        ],
        "submitted_date": "19 Jun 2023",
        "last_revised_date": " "
    },
    "2306.12508": {
        "title": "Polynomial Logical Zonotopes: A Set Representation for Reachability Analysis of Logical Systems",
        "authors": [
            "Amr Alanwar",
            "Frank J. Jiang",
            "Karl H. Johansson"
        ],
        "comments": " ",
        "subjects": "Logic in Computer Science (cs.LO)",
        "abstract": "In this paper, we introduce a set representation called polynomial logical zonotopes for performing exact and computationally efficient reachability analysis on logical systems. Polynomial logical zonotopes are a generalization of logical zonotopes, which are able to represent up to 2^n binary vectors using only n generators. Due to their construction, logical zonotopes are only able to support exact computations of some logical operations (XOR, NOT, XNOR), while other operations (AND, NAND, OR, NOR) result in over-approximations in the reduced space, i.e., generator space. In order to perform all fundamental logical operations exactly, we formulate a generalization of logical zonotopes that is constructed by dependent generators and exponent matrices. We prove that through this polynomial-like construction, we are able to perform all of the fundamental logical operations (XOR, NOT, XNOR, AND, NAND, OR, NOR) exactly in the generator space. While we are able to perform all of the logical operations exactly, this comes with a slight increase in computational complexity compared to logical zonotopes. We show that we can use polynomial logical zonotopes to perform exact reachability analysis while retaining a low computational complexity. To illustrate and showcase the computational benefits of polynomial logical zonotopes, we present the results of performing reachability analysis on two use cases: (1) safety verification of an intersection crossing protocol and (2) reachability analysis on a high-dimensional Boolean function. Moreover, to highlight the extensibility of logical zonotopes, we include an additional use case where we perform a computationally tractable exhaustive search for the key of a linear feedback shift register.\n    ",
        "primary_category": "cs.LO",
        "categories": [
            "cs.CC",
            "cs.DS",
            "eess.SY"
        ],
        "submitted_date": "21 Jun 2023",
        "last_revised_date": " "
    },
    "2306.12525": {
        "title": "LPFormer: LiDAR Pose Estimation Transformer with Multi-Task Network",
        "authors": [
            "Dongqiangzi Ye",
            "Yufei Xie",
            "Weijia Chen",
            "Zixiang Zhou",
            "Lingting Ge",
            "Hassan Foroosh"
        ],
        "comments": "ICRA 2024. Top solution for the Waymo Open Dataset Challenges 2023 - Pose Estimation. CVPR 2023 Workshop on Autonomous Driving",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Due to the difficulty of acquiring large-scale 3D human keypoint annotation, previous methods for 3D human pose estimation (HPE) have often relied on 2D image features and sequential 2D annotations. Furthermore, the training of these networks typically assumes the prediction of a human bounding box and the accurate alignment of 3D point clouds with 2D images, making direct application in real-world scenarios challenging. In this paper, we present the 1st framework for end-to-end 3D human pose estimation, named LPFormer, which uses only LiDAR as its input along with its corresponding 3D annotations. LPFormer consists of two stages: firstly, it identifies the human bounding box and extracts multi-level feature representations, and secondly, it utilizes a transformer-based network to predict human keypoints based on these features. Our method demonstrates that 3D HPE can be seamlessly integrated into a strong LiDAR perception network and benefit from the features extracted by the network. Experimental results on the Waymo Open Dataset demonstrate the state-of-the-art performance, and improvements even compared to previous multi-modal solutions.\n    ",
        "primary_category": "cs.CV",
        "categories": [],
        "submitted_date": "21 Jun 2023",
        "last_revised_date": " "
    },
    "2306.12682": {
        "title": "Counting occurrences of patterns in permutations",
        "authors": [
            "Andrew R Conway",
            "Anthony J Guttmann"
        ],
        "comments": "32 pages. Updated references from previous version. Removal on earlier discussion of Stieltjes sequences, which was incomplete and confusing",
        "subjects": "Combinatorics (math.CO)",
        "abstract": "We develop a new, powerful method for counting elements in a multiset. As a first application, we use this algorithm to study the number of occurrences of patterns in a permutation. For patterns of length 3 there are two Wilf classes, and the general behaviour of these is reasonably well-known. We slightly extend some of the known results in that case, and exhaustively study the case of patterns of length 4, about which there is little previous knowledge. For such patterns, there are seven Wilf classes, and based on extensive enumerations and careful series analysis, we have conjectured the asymptotic behaviour for all classes.\n    ",
        "primary_category": "math.CO",
        "categories": [
            "cs.DS"
        ],
        "submitted_date": "22 Jun 2023",
        "last_revised_date": " "
    },
    "2306.12803": {
        "title": "Robust Statistical Comparison of Random Variables with Locally Varying Scale of Measurement",
        "authors": [
            "Christoph Jansen",
            "Georg Schollmeyer",
            "Hannah Blocher",
            "Julian Rodemann",
            "Thomas Augustin"
        ],
        "comments": "Accepted for the 39th Conference on Uncertainty in Artificial Intelligence (UAI 2023)",
        "subjects": "Machine Learning (stat.ML)",
        "abstract": "Spaces with locally varying scale of measurement, like multidimensional structures with differently scaled dimensions, are pretty common in statistics and machine learning. Nevertheless, it is still understood as an open question how to exploit the entire information encoded in them properly. We address this problem by considering an order based on (sets of) expectations of random variables mapping into such non-standard spaces. This order contains stochastic dominance and expectation order as extreme cases when no, or respectively perfect, cardinal structure is given. We derive a (regularized) statistical test for our proposed generalized stochastic dominance (GSD) order, operationalize it by linear optimization, and robustify it by imprecise probability models. Our findings are illustrated with data from multidimensional poverty measurement, finance, and medicine.\n    ",
        "primary_category": "stat.ML",
        "categories": [
            "cs.LG",
            "math.ST"
        ],
        "submitted_date": "22 Jun 2023",
        "last_revised_date": " "
    },
    "2306.13216": {
        "title": "Diverse Community Data for Benchmarking Data Privacy Algorithms",
        "authors": [
            "Aniruddha Sen",
            "Christine Task",
            "Dhruv Kapur",
            "Gary Howarth",
            "Karan Bhagat"
        ],
        "comments": " ",
        "subjects": "Cryptography and Security (cs.CR)",
        "abstract": "The Collaborative Research Cycle (CRC) is a National Institute of Standards and Technology (NIST) benchmarking program intended to strengthen understanding of tabular data deidentification technologies. Deidentification algorithms are vulnerable to the same bias and privacy issues that impact other data analytics and machine learning applications, and can even amplify those issues by contaminating downstream applications. This paper summarizes four CRC contributions: theoretical work on the relationship between diverse populations and challenges for equitable deidentification; public benchmark data focused on diverse populations and challenging features; a comprehensive open source suite of evaluation metrology for deidentified datasets; and an archive of more than 450 deidentified data samples from a broad range of techniques. The initial set of evaluation results demonstrate the value of these tools for investigations in this field.\n    ",
        "primary_category": "cs.CR",
        "categories": [
            "cs.LG"
        ],
        "submitted_date": "20 Jun 2023",
        "last_revised_date": " "
    },
    "2306.14137": {
        "title": "BotanicGarden: A High-Quality Dataset for Robot Navigation in Unstructured Natural Environments",
        "authors": [
            "Yuanzhi Liu",
            "Yujia Fu",
            "Minghui Qin",
            "Yufeng Xu",
            "Baoxin Xu",
            "Fengdong Chen",
            "Bart Goossens",
            "Poly Z.H. Sun",
            "Hongwei Yu",
            "Chun Liu",
            "Long Chen",
            "Wei Tao",
            "Hui Zhao"
        ],
        "comments": "This article has been accepted for publication in IEEE Robotics and Automation Letters",
        "subjects": "Robotics (cs.RO)",
        "abstract": "The rapid developments of mobile robotics and autonomous navigation over the years are largely empowered by public datasets for testing and upgrading, such as sensor odometry and SLAM tasks. Impressive demos and benchmark scores have arisen, which may suggest the maturity of existing navigation techniques. However, these results are primarily based on moderate structured scenario testing. When transitioning to challenging unstructured environments, especially in GNSS-denied, texture-monotonous, and dense-vegetated natural fields, their performance can hardly sustain at a high level and requires further validation and improvement. To bridge this gap, we build a novel robot navigation dataset in a luxuriant botanic garden of more than 48000m2. Comprehensive sensors are used, including Gray and RGB stereo cameras, spinning and MEMS 3D LiDARs, and low-cost and industrial-grade IMUs, all of which are well calibrated and hardware-synchronized. An all-terrain wheeled robot is employed for data collection, traversing through thick woods, riversides, narrow trails, bridges, and grasslands, which are scarce in previous resources. This yields 33 short and long sequences, forming 17.1km trajectories in total. Excitedly, both highly-accurate ego-motions and 3D map ground truth are provided, along with fine-annotated vision semantics. We firmly believe that our dataset can advance robot navigation and sensor fusion research to a higher level.\n    ",
        "primary_category": "cs.RO",
        "categories": [],
        "submitted_date": "25 Jun 2023",
        "last_revised_date": " "
    },
    "2306.15012": {
        "title": "Statistical Component Separation for Targeted Signal Recovery in Noisy Mixtures",
        "authors": [
            "Bruno R\u00e9galdo-Saint Blancard",
            "Michael Eickenberg"
        ],
        "comments": "13+17 pages, 6+8 figures, published in TMLR, code: this https URL",
        "subjects": "Machine Learning (stat.ML)",
        "abstract": "Separating signals from an additive mixture may be an unnecessarily hard problem when one is only interested in specific properties of a given signal. In this work, we tackle simpler \"statistical component separation\" problems that focus on recovering a predefined set of statistical descriptors of a target signal from a noisy mixture. Assuming access to samples of the noise process, we investigate a method devised to match the statistics of the solution candidate corrupted by noise samples with those of the observed mixture. We first analyze the behavior of this method using simple examples with analytically tractable calculations. Then, we apply it in an image denoising context employing 1) wavelet-based descriptors, 2) ConvNet-based descriptors on astrophysics and ImageNet data. In the case of 1), we show that our method better recovers the descriptors of the target data than a standard denoising method in most situations. Additionally, despite not constructed for this purpose, it performs surprisingly well in terms of peak signal-to-noise ratio on full signal reconstruction. In comparison, representation 2) appears less suitable for image denoising. Finally, we extend this method by introducing a diffusive stepwise algorithm which gives a new perspective to the initial method and leads to promising results for image denoising under specific circumstances.\n    ",
        "primary_category": "stat.ML",
        "categories": [
            "astro-ph.IM",
            "cs.LG",
            "eess.SP"
        ],
        "submitted_date": "26 Jun 2023",
        "last_revised_date": " "
    },
    "2306.15924": {
        "title": "The Parametric Complexity of Operator Learning",
        "authors": [
            "Samuel Lanthaler",
            "Andrew M. Stuart"
        ],
        "comments": " ",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Neural operator architectures employ neural networks to approximate operators mapping between Banach spaces of functions; they may be used to accelerate model evaluations via emulation, or to discover models from data. Consequently, the methodology has received increasing attention over recent years, giving rise to the rapidly growing field of operator learning. The first contribution of this paper is to prove that for general classes of operators which are characterized only by their $C^r$- or Lipschitz-regularity, operator learning suffers from a ``curse of parametric complexity'', which is an infinite-dimensional analogue of the well-known curse of dimensionality encountered in high-dimensional approximation problems. The result is applicable to a wide variety of existing neural operators, including PCA-Net, DeepONet and the FNO. The second contribution of the paper is to prove that this general curse can be overcome for solution operators defined by the Hamilton-Jacobi equation; this is achieved by leveraging additional structure in the underlying solution operator, going beyond regularity. To this end, a novel neural operator architecture is introduced, termed HJ-Net, which explicitly takes into account characteristic information of the underlying Hamiltonian system. Error and complexity estimates are derived for HJ-Net which show that this architecture can provably beat the curse of parametric complexity related to the infinite-dimensional input and output function spaces.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "math.NA"
        ],
        "submitted_date": "28 Jun 2023",
        "last_revised_date": " "
    },
    "2306.16314": {
        "title": "Summation-by-parts operators for general function spaces: The second derivative",
        "authors": [
            "Jan Glaubitz",
            "Simon-Christian Klein",
            "Jan Nordstr\u00f6m",
            "Philipp \u00d6ffner"
        ],
        "comments": "28 pages, 12 figures",
        "subjects": "Numerical Analysis (math.NA)",
        "abstract": "Many applications rely on solving time-dependent partial differential equations (PDEs) that include second derivatives. Summation-by-parts (SBP) operators are crucial for developing stable, high-order accurate numerical methodologies for such problems. Conventionally, SBP operators are tailored to the assumption that polynomials accurately approximate the solution, and SBP operators should thus be exact for them. However, this assumption falls short for a range of problems for which other approximation spaces are better suited. We recently addressed this issue and developed a theory for first-derivative SBP operators based on general function spaces, coined function-space SBP (FSBP) operators. In this paper, we extend the innovation of FSBP operators to accommodate second derivatives. The developed second-derivative FSBP operators maintain the desired mimetic properties of existing polynomial SBP operators while allowing for greater flexibility by being applicable to a broader range of function spaces. We establish the existence of these operators and detail a straightforward methodology for constructing them. By exploring various function spaces, including trigonometric, exponential, and radial basis functions, we illustrate the versatility of our approach. The work presented here opens up possibilities for using second-derivative SBP operators based on suitable function spaces, paving the way for a wide range of applications in the future.\n    ",
        "primary_category": "math.NA",
        "categories": [],
        "submitted_date": "28 Jun 2023",
        "last_revised_date": " "
    },
    "2306.16891": {
        "title": "Harnessing the Power of Hugging Face Transformers for Predicting Mental Health Disorders in Social Networks",
        "authors": [
            "Alireza Pourkeyvan",
            "Ramin Safa",
            "Ali Sorourkhah"
        ],
        "comments": "19 pages, 5 figures",
        "subjects": "Information Retrieval (cs.IR)",
        "abstract": "Early diagnosis of mental disorders and intervention can facilitate the prevention of severe injuries and the improvement of treatment results. Using social media and pre-trained language models, this study explores how user-generated data can be used to predict mental disorder symptoms. Our study compares four different BERT models of Hugging Face with standard machine learning techniques used in automatic depression diagnosis in recent literature. The results show that new models outperform the previous approach with an accuracy rate of up to 97%. Analyzing the results while complementing past findings, we find that even tiny amounts of data (like users' bio descriptions) have the potential to predict mental disorders. We conclude that social media data is an excellent source of mental health screening, and pre-trained models can effectively automate this critical task.\n    ",
        "primary_category": "cs.IR",
        "categories": [
            "cs.AI",
            "cs.HC"
        ],
        "submitted_date": "29 Jun 2023",
        "last_revised_date": " "
    },
    "2306.17366": {
        "title": "$\u03bb$-models: Effective Decision-Aware Reinforcement Learning with Latent Models",
        "authors": [
            "Claas A Voelcker",
            "Arash Ahmadian",
            "Romina Abachi",
            "Igor Gilitschenski",
            "Amir-massoud Farahmand"
        ],
        "comments": " ",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "The idea of decision-aware model learning, that models should be accurate where it matters for decision-making, has gained prominence in model-based reinforcement learning. While promising theoretical results have been established, the empirical performance of algorithms leveraging a decision-aware loss has been lacking, especially in continuous control problems. In this paper, we present a study on the necessary components for decision-aware reinforcement learning models and we showcase design choices that enable well-performing algorithms. To this end, we provide a theoretical and empirical investigation into algorithmic ideas in the field. We highlight that empirical design decisions established in the MuZero line of works, most importantly the use of a latent model, are vital to achieving good performance for related algorithms. Furthermore, we show that the MuZero loss function is biased in stochastic environments and establish that this bias has practical consequences. Building on these findings, we present an overview of which decision-aware loss functions are best used in what empirical scenarios, providing actionable insights to practitioners in the field.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "30 Jun 2023",
        "last_revised_date": " "
    },
    "2306.17494": {
        "title": "An Ontological Approach to Compliance Verification of the NIS 2 Directive",
        "authors": [
            "Gianpietro Castiglione",
            "Daniele Francesco Santamaria",
            "Giampaolo Bella"
        ],
        "comments": " ",
        "subjects": "Cryptography and Security (cs.CR)",
        "abstract": "Cybersecurity, which notoriously concerns both human and technological aspects, is becoming more and more regulated by a number of textual documents spanning several pages, such as the European GDPR Regulation and the NIS Directive. This paper introduces an approach that leverages techniques of semantic representation and reasoning, hence an ontological approach, towards the compliance check with the security measures that textual documents prescribe. We choose the ontology instrument to achieve two fundamental objectives: domain modelling and resource interrogation. The formalisation of entities and relations from the directive, and the consequent improved structuring with respect to sheer prose is dramatically helpful for any organisation through the hard task of compliance verification. The semantic approach is demonstrated with two articles of the new European NIS 2 directive.\n    ",
        "primary_category": "cs.CR",
        "categories": [],
        "submitted_date": "30 Jun 2023",
        "last_revised_date": " "
    },
    "2307.00212": {
        "title": "Internal-External Boundary Attention Fusion for Glass Surface Segmentation",
        "authors": [
            "Dongshen Han",
            "Seungkyu Lee",
            "Chaoning Zhang",
            "Heechan Yoon",
            "Hyukmin Kwon",
            "Hyun-Cheol Kim",
            "Hyon-Gon Choo"
        ],
        "comments": " ",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Glass surfaces of transparent objects and mirrors are not able to be uniquely and explicitly characterized by their visual appearances because they contain the visual appearance of other reflected or transmitted surfaces as well. Detecting glass regions from a single-color image is a challenging task. Recent deep-learning approaches have paid attention to the description of glass surface boundary where the transition of visual appearances between glass and non-glass surfaces are observed. In this work, we analytically investigate how glass surface boundary helps to characterize glass objects. Inspired by prior semantic segmentation approaches with challenging image types such as X-ray or CT scans, we propose separated internal-external boundary attention modules that individually learn and selectively integrate visual characteristics of the inside and outside region of glass surface from a single color image. Our proposed method is evaluated on six public benchmarks comparing with state-of-the-art methods showing promising results.\n    ",
        "primary_category": "cs.CV",
        "categories": [],
        "submitted_date": "1 Jul 2023",
        "last_revised_date": " "
    },
    "2307.00494": {
        "title": "Improving Protein Optimization with Smoothed Fitness Landscapes",
        "authors": [
            "Andrew Kirjner",
            "Jason Yim",
            "Raman Samusevich",
            "Shahar Bracha",
            "Tommi Jaakkola",
            "Regina Barzilay",
            "Ila Fiete"
        ],
        "comments": "ICLR 2024. Code: this https URL",
        "subjects": "Biomolecules (q-bio.BM)",
        "abstract": "The ability to engineer novel proteins with higher fitness for a desired property would be revolutionary for biotechnology and medicine. Modeling the combinatorially large space of sequences is infeasible; prior methods often constrain optimization to a small mutational radius, but this drastically limits the design space. Instead of heuristics, we propose smoothing the fitness landscape to facilitate protein optimization. First, we formulate protein fitness as a graph signal then use Tikunov regularization to smooth the fitness landscape. We find optimizing in this smoothed landscape leads to improved performance across multiple methods in the GFP and AAV benchmarks. Second, we achieve state-of-the-art results utilizing discrete energy-based models and MCMC in the smoothed landscape. Our method, called Gibbs sampling with Graph-based Smoothing (GGS), demonstrates a unique ability to achieve 2.5 fold fitness improvement (with in-silico evaluation) over its training set. GGS demonstrates potential to optimize proteins in the limited data regime. Code: this https URL\n",
        "primary_category": "q-bio.BM",
        "categories": [
            "cs.LG",
            "q-bio.QM",
            "stat.ML"
        ],
        "submitted_date": "2 Jul 2023",
        "last_revised_date": " "
    },
    "2307.01412": {
        "title": "Constant-time edge label and leaf pointer maintenance on sliding suffix trees",
        "authors": [
            "Laurentius Leonard",
            "Shunsuke Inenaga",
            "Hideo Bannai",
            "Takuya Mieno"
        ],
        "comments": " ",
        "subjects": "Data Structures and Algorithms (cs.DS)",
        "abstract": "Sliding suffix trees (Fiala & Greene, 1989) for an input text $T$ over an alphabet of size $\\sigma$ and a sliding window $W$ of $T$ can be maintained in $O(|T| \\log \\sigma)$ time and $O(|W|)$ space. The two previous approaches that achieve this can be categorized into the credit-based approach of Fiala and Greene (1989) and Larsson (1996, 1999), or the batch-based approach proposed by Senft (2005). Brodnik and Jekovec (2018) showed that the sliding suffix tree can be supplemented with leaf pointers in order to find all occurrences of an online query pattern in the current window, and that leaf pointers can be maintained by credit-based arguments as well. The main difficulty in the credit-based approach is in the maintenance of index-pairs that represent each edge. In this paper, we show that valid edge index-pairs can be derived in constant time from leaf pointers, thus reducing the maintenance of edge index-pairs to the maintenance of leaf pointers. We further propose a new simple method that maintains leaf pointers without using credit-based arguments. The lack of credit-based arguments allow a simpler proof of correctness compared to the credit-based approach, whose analyses were initially flawed (Senft 2005). In addition, our method reduces the worst-case time of leaf pointer and edge label maintenance per leaf insertion and deletion from $\\Theta(|W|)$ time to $O(1)$ time.\n    ",
        "primary_category": "cs.DS",
        "categories": [],
        "submitted_date": "4 Jul 2023",
        "last_revised_date": " "
    },
    "2307.02140": {
        "title": "Towards Open Federated Learning Platforms: Survey and Vision from Technical and Legal Perspectives",
        "authors": [
            "Moming Duan",
            "Qinbin Li",
            "Linshan Jiang",
            "Bingsheng He"
        ],
        "comments": "Download Appendix from this https URL",
        "subjects": "Software Engineering (cs.SE)",
        "abstract": "Traditional Federated Learning (FL) follows a server-dominated cooperation paradigm which narrows the application scenarios of FL and decreases the enthusiasm of data holders to participate. To fully unleash the potential of FL, we advocate rethinking the design of current FL frameworks and extending it to a more generalized concept: Open Federated Learning Platforms, positioned as a crowdsourcing collaborative machine learning infrastructure for all Internet users. We propose two reciprocal cooperation frameworks to achieve this: query-based FL and contract-based FL. In this survey, we conduct a comprehensive review of the feasibility of constructing open FL platforms from both technical and legal perspectives. We begin by reviewing the definition of FL and summarizing its inherent limitations, including server-client coupling, low model reusability, and non-public. In particular, we introduce a novel taxonomy to streamline the analysis of model license compatibility in FL studies that involve batch model reusing methods, including combination, amalgamation, distillation, and generation. This taxonomy provides a feasible solution for identifying the corresponding licenses clauses and facilitates the analysis of potential legal implications and restrictions when reusing models. Through this survey, we uncover the current dilemmas faced by FL and advocate for the development of sustainable open FL platforms. We aim to provide guidance for establishing such platforms in the future while identifying potential limitations that need to be addressed.\n    ",
        "primary_category": "cs.SE",
        "categories": [
            "cs.AI",
            "cs.LG"
        ],
        "submitted_date": "5 Jul 2023",
        "last_revised_date": " "
    },
    "2307.02799": {
        "title": "Few-shot Personalized Saliency Prediction Based on Inter-personnel Gaze Patterns",
        "authors": [
            "Yuya Moroto",
            "Keisuke Maeda",
            "Takahiro Ogawa",
            "Miki Haseyama"
        ],
        "comments": "5pages, 3 figures",
        "subjects": "Image and Video Processing (eess.IV)",
        "abstract": "This paper presents few-shot personalized saliency prediction based on inter-personnel gaze patterns. In contrast to general saliency maps, personalized saliecny maps (PSMs) have been great potential since PSMs indicate the person-specific visual attention useful for obtaining individual visual preferences. The PSM prediction is needed for acquiring the PSMs for unseen images, but its prediction is still a challenging task due to the complexity of individual gaze patterns. Moreover, the eye-tracking data obtained from each person is necessary to construct and predict PSMs, but it is difficult to acquire the massive amounts of such data. One solution for realizing PSM prediction from the limited amount of data is the effective use of eye-tracking data obtained from other persons. To efficiently treat the PSMs of other persons, this paper focuses on the selection of images to acquire eye-tracking data and the preservation of structural information of PSMs of other persons. In the proposed method, such images are selected such that they bring more diverse gaze patterns to persons, and the structural information is preserved by adopting the tensor-based regression method. Experimental results demonstrate that the above two points are beneficial for the few-shot PSM prediction.\n    ",
        "primary_category": "eess.IV",
        "categories": [
            "cs.LG"
        ],
        "submitted_date": "6 Jul 2023",
        "last_revised_date": " "
    },
    "2307.03742": {
        "title": "Fine error bounds for approximate asymmetric saddle point problems",
        "authors": [
            "Vitoriano Ruas"
        ],
        "comments": "Version V2 of the article incorporates several modifications, including its title, mostly aimed at clarifying its contributions. Relevant complementary material on the topic is supplied in new Section 5. A conclusion section and 7 new references are provided. Keywords: Asymmetric saddle-point problem; Error bounds; Inf-sup conditions; Mixed finite elements; Stability constants",
        "subjects": "Numerical Analysis (math.NA)",
        "abstract": "The theory of mixed finite element methods for solving different types of elliptic partial differential equations in saddle point formulation is well established since many decades. This topic was mostly studied for variational formulations defined upon the same product spaces of both shape- and test-pairs of primal variable-multiplier. Whenever either these spaces or the two bilinear forms involving the multiplier are distinct, the saddle point problem is asymmetric. The three inf-sup conditions to be satisfied by the product spaces stipulated in work on the subject, in order to guarantee well-posedness, are well known. However, the material encountered in the literature addressing the approximation of this class of problems left room for improvement and clarifications. After making a brief review of the existing contributions to the topic that justifies such an assertion, in this paper we set up finer global error bounds for the pair primal variable-multiplier solving an asymmetric saddle point problem. Besides well-posedness, the three constants in the aforementioned inf-sup conditions are identified as all that is needed for determining the stability constant appearing therein, whose expression is exhibited. As a complement, refined error bounds depending only on these three constants are given for both unknowns separately.\n    ",
        "primary_category": "math.NA",
        "categories": [],
        "submitted_date": "7 Jul 2023",
        "last_revised_date": " "
    },
    "2307.03997": {
        "title": "Efficient Model-Free Exploration in Low-Rank MDPs",
        "authors": [
            "Zakaria Mhammedi",
            "Adam Block",
            "Dylan J. Foster",
            "Alexander Rakhlin"
        ],
        "comments": " ",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "A major challenge in reinforcement learning is to develop practical, sample-efficient algorithms for exploration in high-dimensional domains where generalization and function approximation is required. Low-Rank Markov Decision Processes -- where transition probabilities admit a low-rank factorization based on an unknown feature embedding -- offer a simple, yet expressive framework for RL with function approximation, but existing algorithms are either (1) computationally intractable, or (2) reliant upon restrictive statistical assumptions such as latent variable structure, access to model-based function approximation, or reachability. In this work, we propose the first provably sample-efficient algorithm for exploration in Low-Rank MDPs that is both computationally efficient and model-free, allowing for general function approximation and requiring no additional structural assumptions. Our algorithm, VoX, uses the notion of a barycentric spanner for the feature embedding as an efficiently computable basis for exploration, performing efficient barycentric spanner computation by interleaving representation learning and policy optimization. Our analysis -- which is appealingly simple and modular -- carefully combines several techniques, including a new approach to error-tolerant barycentric spanner computation and an improved analysis of a certain minimax representation learning objective found in prior work.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "math.OC"
        ],
        "submitted_date": "8 Jul 2023",
        "last_revised_date": " "
    },
    "2307.04644": {
        "title": "Fairness and Diversity in Recommender Systems: A Survey",
        "authors": [
            "Yuying Zhao",
            "Yu Wang",
            "Yunchao Liu",
            "Xueqi Cheng",
            "Charu Aggarwal",
            "Tyler Derr"
        ],
        "comments": " ",
        "subjects": "Information Retrieval (cs.IR)",
        "abstract": "Recommender systems are effective tools for mitigating information overload and have seen extensive applications across various domains. However, the single focus on utility goals proves to be inadequate in addressing real-world concerns, leading to increasing attention to fairness-aware and diversity-aware recommender systems. While most existing studies explore fairness and diversity independently, we identify strong connections between these two domains. In this survey, we first discuss each of them individually and then dive into their connections. Additionally, motivated by the concepts of user-level and item-level fairness, we broaden the understanding of diversity to encompass not only the item level but also the user level. With this expanded perspective on user and item-level diversity, we re-interpret fairness studies from the viewpoint of diversity. This fresh perspective enhances our understanding of fairness-related work and paves the way for potential future research directions. Papers discussed in this survey along with public code links are available at this https URL .\n    ",
        "primary_category": "cs.IR",
        "categories": [],
        "submitted_date": "10 Jul 2023",
        "last_revised_date": " "
    },
    "2307.04652": {
        "title": "Winding number and circular 4-coloring of signed graphs",
        "authors": [
            "Anna Gujgiczer",
            "Reza Naserasr",
            "Rohini S",
            "S Taruni"
        ],
        "comments": "16 pages, 11 figures",
        "subjects": "Combinatorics (math.CO)",
        "abstract": "Concerning the recent notion of circular chromatic number of signed graphs, for each given integer $k$ we introduce two signed bipartite graphs, each on $2k^2-k+1$ vertices, having shortest negative cycle of length $2k$, and the circular chromatic number 4.\nEach of the construction can be viewed as a bipartite analogue of the generalized Mycielski graphs on odd cycles, $M_{\\ell}(C_{2k+1})$. In the course of proving our result, we also obtain a simple proof of the fact that $M_{\\ell}(C_{2k+1})$ and some similar quadrangulations of the projective plane have circular chromatic number 4. These proofs have the advantage that they illuminate, in an elementary manner, the strong relation between algebraic topology and graph coloring problems.\n    ",
        "primary_category": "math.CO",
        "categories": [
            "cs.DM"
        ],
        "submitted_date": "10 Jul 2023",
        "last_revised_date": " "
    },
    "2307.05435": {
        "title": "One-Versus-Others Attention: Scalable Multimodal Integration for Clinical Data",
        "authors": [
            "Michal Golovanevsky",
            "Eva Schiller",
            "Akira Nair",
            "Ritambhara Singh",
            "Carsten Eickhoff"
        ],
        "comments": " ",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Multimodal learning models have become increasingly important as they surpass single-modality approaches on diverse tasks ranging from question-answering to autonomous driving. Despite the importance of multimodal learning, existing efforts focus on NLP applications, where the number of modalities is typically less than four (audio, video, text, images). However, data inputs in other domains, such as the medical field, may include X-rays, PET scans, MRIs, genetic screening, clinical notes, and more, creating a need for both efficient and accurate information fusion. Many state-of-the-art models rely on pairwise cross-modal attention, which does not scale well for applications with more than three modalities. For $n$ modalities, computing attention will result in $n \\choose 2$ operations, potentially requiring considerable amounts of computational resources. To address this, we propose a new domain-neutral attention mechanism, One-Versus-Others (OvO) attention, that scales linearly with the number of modalities and requires only $n$ attention operations, thus offering a significant reduction in computational complexity compared to existing cross-modal attention algorithms. Using three diverse real-world datasets as well as an additional simulation experiment, we show that our method improves performance compared to popular fusion techniques while decreasing computation costs.\n    ",
        "primary_category": "cs.LG",
        "categories": [],
        "submitted_date": "11 Jul 2023",
        "last_revised_date": " "
    },
    "2307.07221": {
        "title": "Software Testing with Large Language Models: Survey, Landscape, and Vision",
        "authors": [
            "Junjie Wang",
            "Yuchao Huang",
            "Chunyang Chen",
            "Zhe Liu",
            "Song Wang",
            "Qing Wang"
        ],
        "comments": "accepted by IEEE Transactions on Software Engineering",
        "subjects": "Software Engineering (cs.SE)",
        "abstract": "Pre-trained large language models (LLMs) have recently emerged as a breakthrough technology in natural language processing and artificial intelligence, with the ability to handle large-scale datasets and exhibit remarkable performance across a wide range of tasks. Meanwhile, software testing is a crucial undertaking that serves as a cornerstone for ensuring the quality and reliability of software products. As the scope and complexity of software systems continue to grow, the need for more effective software testing techniques becomes increasingly urgent, making it an area ripe for innovative approaches such as the use of LLMs. This paper provides a comprehensive review of the utilization of LLMs in software testing. It analyzes 102 relevant studies that have used LLMs for software testing, from both the software testing and LLMs perspectives. The paper presents a detailed discussion of the software testing tasks for which LLMs are commonly used, among which test case preparation and program repair are the most representative. It also analyzes the commonly used LLMs, the types of prompt engineering that are employed, as well as the accompanied techniques with these LLMs. It also summarizes the key challenges and potential opportunities in this direction. This work can serve as a roadmap for future research in this area, highlighting potential avenues for exploration, and identifying gaps in our current understanding of the use of LLMs in software testing.\n    ",
        "primary_category": "cs.SE",
        "categories": [],
        "submitted_date": "14 Jul 2023",
        "last_revised_date": " "
    },
    "2307.07357": {
        "title": "Inverse Optimization for Routing Problems",
        "authors": [
            "Pedro Zattoni Scroccaro",
            "Piet van Beek",
            "Peyman Mohajerin Esfahani",
            "Bilge Atasoy"
        ],
        "comments": " ",
        "subjects": "Optimization and Control (math.OC)",
        "abstract": "We propose a method for learning decision-makers' behavior in routing problems using Inverse Optimization (IO). The IO framework falls into the supervised learning category and builds on the premise that the target behavior is an optimizer of an unknown cost function. This cost function is to be learned through historical data, and in the context of routing problems, can be interpreted as the routing preferences of the decision-makers. In this view, the main contributions of this study are to propose an IO methodology with a hypothesis function, loss function, and stochastic first-order algorithm tailored to routing problems. We further test our IO approach in the Amazon Last Mile Routing Research Challenge, where the goal is to learn models that replicate the routing preferences of human drivers, using thousands of real-world routing examples. Our final IO-learned routing model achieves a score that ranks 2nd compared with the 48 models that qualified for the final round of the challenge. Our examples and results showcase the flexibility and real-world potential of the proposed IO methodology to learn from decision-makers' decisions in routing problems.\n    ",
        "primary_category": "math.OC",
        "categories": [
            "cs.LG"
        ],
        "submitted_date": "14 Jul 2023",
        "last_revised_date": " "
    },
    "2307.07515": {
        "title": "Artificial intelligence is algorithmic mimicry: why artificial \"agents\" are not (and won't be) proper agents",
        "authors": [
            "Johannes Jaeger"
        ],
        "comments": " ",
        "subjects": "Artificial Intelligence (cs.AI)",
        "abstract": "What is the prospect of developing artificial general intelligence (AGI)? I investigate this question by systematically comparing living and algorithmic systems, with a special focus on the notion of \"agency.\" There are three fundamental differences to consider: (1) Living systems are autopoietic, that is, self-manufacturing, and therefore able to set their own intrinsic goals, while algorithms exist in a computational environment with target functions that are both provided by an external agent. (2) Living systems are embodied in the sense that there is no separation between their symbolic and physical aspects, while algorithms run on computational architectures that maximally isolate software from hardware. (3) Living systems experience a large world, in which most problems are ill-defined (and not all definable), while algorithms exist in a small world, in which all problems are well-defined. These three differences imply that living and algorithmic systems have very different capabilities and limitations. In particular, it is extremely unlikely that true AGI (beyond mere mimicry) can be developed in the current algorithmic framework of AI research. Consequently, discussions about the proper development and deployment of algorithmic tools should be shaped around the dangers and opportunities of current narrow AI, not the extremely unlikely prospect of the emergence of true agency in artificial systems.\n    ",
        "primary_category": "cs.AI",
        "categories": [],
        "submitted_date": "27 Jun 2023",
        "last_revised_date": " "
    },
    "2307.07884": {
        "title": "Preconditioning techniques for generalized Sylvester matrix equations",
        "authors": [
            "Yannis Voet"
        ],
        "comments": "26 pages, 3 figures, 2 tables. Submitted manuscript",
        "subjects": "Numerical Analysis (math.NA)",
        "abstract": "Sylvester matrix equations are ubiquitous in scientific computing. However, few solution techniques exist for their generalized multiterm version, as they now arise in an increasingly large number of applications. In this work, we consider algebraic parameter-free preconditioning techniques for the iterative solution of generalized multiterm Sylvester equations. They consist in constructing low Kronecker rank approximations of either the operator itself or its inverse. While the former requires solving standard Sylvester equations in each iteration, the latter only requires matrix-matrix multiplications, which are highly optimized on modern computer architectures. Moreover, low Kronecker rank approximate inverses can be easily combined with sparse approximate inverse techniques, thereby enhancing their performance with little or no damage to their effectiveness.\n    ",
        "primary_category": "math.NA",
        "categories": [],
        "submitted_date": "15 Jul 2023",
        "last_revised_date": " "
    },
    "2307.07932": {
        "title": "A Novel Truncated Norm Regularization Method for Multi-channel Color Image Denoising",
        "authors": [
            "Yiwen Shan",
            "Dong Hu",
            "Zhi Wang"
        ],
        "comments": " ",
        "subjects": "Image and Video Processing (eess.IV)",
        "abstract": "Due to the high flexibility and remarkable performance, low-rank approximation methods has been widely studied for color image denoising. However, those methods mostly ignore either the cross-channel difference or the spatial variation of noise, which limits their capacity in real world color image denoising. To overcome those drawbacks, this paper is proposed to denoise color images with a double-weighted truncated nuclear norm minus truncated Frobenius norm minimization (DtNFM) method. Through exploiting the nonlocal self-similarity of the noisy image, the similar structures are gathered and a series of similar patch matrices are constructed. For each group, the DtNFM model is conducted for estimating its denoised version. The denoised image would be obtained by concatenating all the denoised patch matrices. The proposed DtNFM model has two merits. First, it models and utilizes both the cross-channel difference and the spatial variation of noise. This provides sufficient flexibility for handling the complex distribution of noise in real world images. Second, the proposed DtNFM model provides a close approximation to the underlying clean matrix since it can treat different rank components flexibly. To solve the problem resulted from DtNFM model, an accurate and effective algorithm is proposed by exploiting the framework of the alternating direction method of multipliers (ADMM). The generated subproblems are discussed in detail. And their global optima can be easily obtained in closed-form. Rigorous mathematical derivation proves that the solution sequences generated by the algorithm converge to a single critical point. Extensive experiments on synthetic and real noise datasets demonstrate that the proposed method outperforms many state-of-the-art color image denoising methods.\n    ",
        "primary_category": "eess.IV",
        "categories": [
            "cs.LG"
        ],
        "submitted_date": "16 Jul 2023",
        "last_revised_date": " "
    },
    "2307.08773": {
        "title": "\"Customization is Key\": Reconfigurable Content Tokens for Accessible Data Visualizations",
        "authors": [
            "Shuli Jones",
            "Isabella Pedraza Pineros",
            "Daniel Hajas",
            "Jonathan Zong",
            "Arvind Satyanarayan"
        ],
        "comments": "14 pages. 6 figures. 2 tables. ACM CHI Conference 2024",
        "subjects": "Human-Computer Interaction (cs.HC)",
        "abstract": "Customization is crucial for making visualizations accessible to blind and low-vision (BLV) people with widely-varying needs. But what makes for usable or useful customization? We identify four design goals for how BLV people should be able to customize screen-reader-accessible visualizations: presence, or what content is included; verbosity, or how concisely content is presented; ordering, or how content is sequenced; and, duration, or how long customizations are active. To meet these goals, we model a customization as a sequence of content tokens, each with a set of adjustable properties. We instantiate our model by extending Olli, an open-source accessible visualization toolkit, with a settings menu and command box for persistent and ephemeral customization respectively. Through a study with 13 BLV participants, we find that customization increases the ease of identifying and remembering information. However, customization also introduces additional complexity, making it more helpful for users familiar with similar tools.\n    ",
        "primary_category": "cs.HC",
        "categories": [],
        "submitted_date": "17 Jul 2023",
        "last_revised_date": " "
    },
    "2307.08924": {
        "title": "Towards Task Sampler Learning for Meta-Learning",
        "authors": [
            "Jingyao Wang",
            "Wenwen Qiang",
            "Xingzhe Su",
            "Changwen Zheng",
            "Fuchun Sun",
            "Hui Xiong"
        ],
        "comments": "28 pages, 11 tables, 12 figures",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Meta-learning aims to learn general knowledge with diverse training tasks conducted from limited data, and then transfer it to new tasks. It is commonly believed that increasing task diversity will enhance the generalization ability of meta-learning models. However, this paper challenges this view through empirical and theoretical analysis. We obtain three conclusions: (i) there is no universal task sampling strategy that can guarantee the optimal performance of meta-learning models; (ii) over-constraining task diversity may incur the risk of under-fitting or over-fitting during training; and (iii) the generalization performance of meta-learning models are affected by task diversity, task entropy, and task difficulty. Based on this insight, we design a novel task sampler, called Adaptive Sampler (ASr). ASr is a plug-and-play module that can be integrated into any meta-learning framework. It dynamically adjusts task weights according to task diversity, task entropy, and task difficulty, thereby obtaining the optimal probability distribution for meta-training tasks. Finally, we conduct experiments on a series of benchmark datasets across various scenarios, and the results demonstrate that ASr has clear advantages.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.CV"
        ],
        "submitted_date": "18 Jul 2023",
        "last_revised_date": " "
    },
    "2307.09465": {
        "title": "Occlusion Aware Student Emotion Recognition based on Facial Action Unit Detection",
        "authors": [
            "Shrouk Wally",
            "Ahmed Elsayed",
            "Islam Alkabbany",
            "Asem Ali",
            "Aly Farag"
        ],
        "comments": "it doesn't meet the requirements of the CVIP Lab concerning authorship and acknowledging the funding sources",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Given that approximately half of science, technology, engineering, and mathematics (STEM) undergraduate students in U.S. colleges and universities leave by the end of the first year [15], it is crucial to improve the quality of classroom environments. This study focuses on monitoring students' emotions in the classroom as an indicator of their engagement and proposes an approach to address this issue. The impact of different facial parts on the performance of an emotional recognition model is evaluated through experimentation. To test the proposed model under partial occlusion, an artificially occluded dataset is introduced. The novelty of this work lies in the proposal of an occlusion-aware architecture for facial action units (AUs) extraction, which employs attention mechanism and adaptive feature learning. The AUs can be used later to classify facial expressions in classroom settings.\nThis research paper's findings provide valuable insights into handling occlusion in analyzing facial images for emotional engagement analysis. The proposed experiments demonstrate the significance of considering occlusion and enhancing the reliability of facial analysis models in classroom environments. These findings can also be extended to other settings where occlusions are prevalent.\n    ",
        "primary_category": "cs.CV",
        "categories": [],
        "submitted_date": "18 Jul 2023",
        "last_revised_date": " "
    },
    "2307.09950": {
        "title": "Prompting for Automatic Log Template Extraction",
        "authors": [
            "Junjielong Xu",
            "Ruichun Yang",
            "Yintong Huo",
            "Chengyu Zhang",
            "Pinjia He"
        ],
        "comments": "Accepted by ICSE'24",
        "subjects": "Software Engineering (cs.SE)",
        "abstract": "Log parsing, which involves log template extraction from semi-structured logs to produce structured logs, is the first and the most critical step in automated log analysis. However, current log parsers suffer from limited effectiveness for two reasons. First, traditional data-driven log parsers solely rely on heuristics or handcrafted features designed by domain experts, which may not consistently perform well on logs from diverse systems. Second, existing supervised log parsers require model tuning, which is often limited to fixed training samples and causes sub-optimal performance across the entire log source. To address this limitation, we propose DivLog, an effective log parsing framework based on the in-context learning (ICL) ability of large language models (LLMs). Specifically, before log parsing, DivLog samples a small amount of offline logs as candidates by maximizing their diversity. Then, during log parsing, DivLog selects five appropriate labeled candidates as examples for each target log and constructs them into a prompt. By mining the semantics of examples in the prompt, DivLog generates a target log template in a training-free manner. In addition, we design a straightforward yet effective prompt format to extract the output and enhance the quality of the generated log templates. We conducted experiments on 16 widely-used public datasets. The results show that DivLog achieves (1) 98.1% Parsing Accuracy, (2) 92.1% Precision Template Accuracy, and (3) 92.9% Recall Template Accuracy on average, exhibiting state-of-the-art performance.\n    ",
        "primary_category": "cs.SE",
        "categories": [],
        "submitted_date": "19 Jul 2023",
        "last_revised_date": " "
    },
    "2307.10811": {
        "title": "\"It Felt Like Having a Second Mind\": Investigating Human-AI Co-creativity in Prewriting with Large Language Models",
        "authors": [
            "Qian Wan",
            "Siying Hu",
            "Yu Zhang",
            "Piaohong Wang",
            "Bo Wen",
            "Zhicong Lu"
        ],
        "comments": "To appear at ACM CSCW 2024; Accepted to PACM HCI (CSCW); 25 pages, 2 figures",
        "subjects": "Human-Computer Interaction (cs.HC)",
        "abstract": "Prewriting is the process of discovering and developing ideas before a first draft, which requires divergent thinking and often implies unstructured strategies such as diagramming, outlining, free-writing, etc. Although large language models (LLMs) have been demonstrated to be useful for a variety of tasks including creative writing, little is known about how users would collaborate with LLMs to support prewriting. The preferred collaborative role and initiative of LLMs during such a creativity process is also unclear. To investigate human-LLM collaboration patterns and dynamics during prewriting, we conducted a three-session qualitative study with 15 participants in two creative tasks: story writing and slogan writing. The findings indicated that during collaborative prewriting, there appears to be a three-stage iterative Human-AI Co-creativity process that includes Ideation, Illumination, and Implementation stages. This collaborative process champions the human in a dominant role, in addition to mixed and shifting levels of initiative that exist between humans and LLMs. This research also reports on collaboration breakdowns that occur during this process, user perceptions of using existing LLMs during Human-AI Co-creativity, and discusses design implications to support this co-creativity process.\n    ",
        "primary_category": "cs.HC",
        "categories": [
            "cs.AI",
            "cs.CL"
        ],
        "submitted_date": "20 Jul 2023",
        "last_revised_date": " "
    },
    "2307.11025": {
        "title": "Investigating VTubing as a Reconstruction of Streamer Self-Presentation: Identity, Performance, and Gender",
        "authors": [
            "Qian Wan",
            "Zhicong Lu"
        ],
        "comments": "To appear at ACM CSCW 2024 (Accepted to PACM HCI(CSCW))",
        "subjects": "Human-Computer Interaction (cs.HC)",
        "abstract": "VTubers, or Virtual YouTubers, are live streamers who create streaming content using animated 2D or 3D virtual avatars. In recent years, there has been a significant increase in the number of VTuber creators and viewers across the globe. This practise has drawn research attention into topics such as viewers' engagement behaviors and perceptions, however, as animated avatars offer more identity and performance flexibility than traditional live streaming where one uses their own body, little research has focused on how this flexibility influences how creators present themselves. This research thus seeks to fill this gap by presenting results from a qualitative study of 16 Chinese-speaking VTubers' streaming practices. The data revealed that the virtual avatars that were used while live streaming afforded creators opportunities to present themselves using inflated presentations and resulted in inclusive interactions with viewers. The results also unveiled the inflated, and often sexualized, gender expressions of VTubers while they were situated in misogynistic environments. The socio-technical facets of VTubing were found to potentially reduce sexual harassment and sexism, whilst also raising self-objectification concerns.\n    ",
        "primary_category": "cs.HC",
        "categories": [
            "cs.CY",
            "cs.MM",
            "cs.SI"
        ],
        "submitted_date": "20 Jul 2023",
        "last_revised_date": " "
    },
    "2307.11543": {
        "title": "KVN: Keypoints Voting Network with Differentiable RANSAC for Stereo Pose Estimation",
        "authors": [
            "Ivano Donadi",
            "Alberto Pretto"
        ],
        "comments": "Published in IEEE Robotics and Automation Letters",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Object pose estimation is a fundamental computer vision task exploited in several robotics and augmented reality applications. Many established approaches rely on predicting 2D-3D keypoint correspondences using RANSAC (Random sample consensus) and estimating the object pose using the PnP (Perspective-n-Point) algorithm. Being RANSAC non-differentiable, correspondences cannot be directly learned in an end-to-end fashion. In this paper, we address the stereo image-based object pose estimation problem by i) introducing a differentiable RANSAC layer into a well-known monocular pose estimation network; ii) exploiting an uncertainty-driven multi-view PnP solver which can fuse information from multiple views. We evaluate our approach on a challenging public stereo object pose estimation dataset and a custom-built dataset we call Transparent Tableware Dataset (TTD), yielding state-of-the-art results against other recent approaches. Furthermore, in our ablation study, we show that the differentiable RANSAC layer plays a significant role in the accuracy of the proposed method. We release with this paper the code of our method and the TTD dataset.\n    ",
        "primary_category": "cs.CV",
        "categories": [
            "cs.RO"
        ],
        "submitted_date": "21 Jul 2023",
        "last_revised_date": " "
    },
    "2307.11727": {
        "title": "Extensions of K5: Proof Theory and Uniform Lyndon Interpolation",
        "authors": [
            "Iris van der Giessen",
            "Raheleh Jalali",
            "Roman Kuznets"
        ],
        "comments": "20-page conference paper + 5-page appendix with examples and proofs",
        "subjects": "Logic in Computer Science (cs.LO)",
        "abstract": "We introduce a Gentzen-style framework, called layered sequent calculi, for modal logic K5 and its extensions KD5, K45, KD45, KB5, and S5 with the goal to investigate the uniform Lyndon interpolation property (ULIP), which implies both the uniform interpolation property and the Lyndon interpolation property. We obtain complexity-optimal decision procedures for all logics and present a constructive proof of the ULIP for K5, which to the best of our knowledge, is the first such syntactic proof. To prove that the interpolant is correct, we use model-theoretic methods, especially bisimulation modulo literals.\n    ",
        "primary_category": "cs.LO",
        "categories": [
            "math.LO"
        ],
        "submitted_date": "21 Jul 2023",
        "last_revised_date": " "
    },
    "2307.12306": {
        "title": "Tackling the Curse of Dimensionality with Physics-Informed Neural Networks",
        "authors": [
            "Zheyuan Hu",
            "Khemraj Shukla",
            "George Em Karniadakis",
            "Kenji Kawaguchi"
        ],
        "comments": "35 pages",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "The curse-of-dimensionality taxes computational resources heavily with exponentially increasing computational cost as the dimension increases. This poses great challenges in solving high-dimensional PDEs, as Richard E. Bellman first pointed out over 60 years ago. While there has been some recent success in solving numerically partial differential equations (PDEs) in high dimensions, such computations are prohibitively expensive, and true scaling of general nonlinear PDEs to high dimensions has never been achieved. We develop a new method of scaling up physics-informed neural networks (PINNs) to solve arbitrary high-dimensional PDEs. The new method, called Stochastic Dimension Gradient Descent (SDGD), decomposes a gradient of PDEs into pieces corresponding to different dimensions and randomly samples a subset of these dimensional pieces in each iteration of training PINNs. We prove theoretically the convergence and other desired properties of the proposed method. We demonstrate in various diverse tests that the proposed method can solve many notoriously hard high-dimensional PDEs, including the Hamilton-Jacobi-Bellman (HJB) and the Schr\u00f6dinger equations in tens of thousands of dimensions very fast on a single GPU using the PINNs mesh-free approach. Notably, we solve nonlinear PDEs with nontrivial, anisotropic, and inseparable solutions in 100,000 effective dimensions in 12 hours on a single GPU using SDGD with PINNs. Since SDGD is a general training methodology of PINNs, it can be applied to any current and future variants of PINNs to scale them up for arbitrary high-dimensional PDEs.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.AI",
            "math.DS",
            "math.NA",
            "stat.ML"
        ],
        "submitted_date": "23 Jul 2023",
        "last_revised_date": " "
    },
    "2307.12936": {
        "title": "Timely Target Tracking: Distributed Updating in Cognitive Radar Networks",
        "authors": [
            "William W. Howard",
            "Anthony F. Martone",
            "R. Michael Buehrer"
        ],
        "comments": "15 pages, double column, 14 figures",
        "subjects": "Systems and Control (eess.SY)",
        "abstract": "Cognitive radar networks (CRNs) are capable of optimizing operating parameters in order to provide actionable information to an operator or secondary system. CRNs have been proposed to answer the need for low-cost devices tracking potentially large numbers of targets in geographically diverse regions. Networks of small-scale devices have also been shown to outperform legacy, large scale, high price, single-device installations. In this work, we consider a CRN tracking multiple targets with a goal of providing information which is both fresh and accurate to a measurement fusion center (FC). We show that under a constraint on the update rate of each radar node, the network is able to utilize Age of Information (AoI) metrics to maximize the resource utilization and minimize error per track. Since information freshness is critical to decision-making, this structure enables a CRN to provide the highest-quality information possible to a downstream system or operator. We discuss centralized and distributed approaches to solving this problem, taking into account the quality of node observations, the maneuverability of each target, and a limit on the rate at which any node may provide updates to the FC. We present a centralized AoI-inspired node selection metric, where a FC requests updates from specific nodes. We compare this against several alternative techniques. Further, we provide a distributed approach which utilizes the Age of Incorrect Information (AoII) metric, allowing each independent node to provide updates according to the targets it can observe. We provide mathematical analysis of the rate limits defined for the centralized and distributed approaches, showing that they are equivalent. We conclude with numerical simulations demonstrating that the performance of the algorithms exceeds that of alternative approaches, both in resource utilization and in tracking performance.\n    ",
        "primary_category": "eess.SY",
        "categories": [],
        "submitted_date": "24 Jul 2023",
        "last_revised_date": " "
    },
    "2307.13586": {
        "title": "Settling the Sample Complexity of Online Reinforcement Learning",
        "authors": [
            "Zihan Zhang",
            "Yuxin Chen",
            "Jason D. Lee",
            "Simon S. Du"
        ],
        "comments": " ",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "A central issue lying at the heart of online reinforcement learning (RL) is data efficiency. While a number of recent works achieved asymptotically minimal regret in online RL, the optimality of these results is only guaranteed in a ``large-sample'' regime, imposing enormous burn-in cost in order for their algorithms to operate optimally. How to achieve minimax-optimal regret without incurring any burn-in cost has been an open problem in RL theory.\nWe settle this problem for the context of finite-horizon inhomogeneous Markov decision processes. Specifically, we prove that a modified version of Monotonic Value Propagation (MVP), a model-based algorithm proposed by \\cite{zhang2020reinforcement}, achieves a regret on the order of (modulo log factors) \\begin{equation*}\n\\min\\big\\{ \\sqrt{SAH^3K}, \\,HK \\big\\}, \\end{equation*} where $S$ is the number of states, $A$ is the number of actions, $H$ is the planning horizon, and $K$ is the total number of episodes. This regret matches the minimax lower bound for the entire range of sample size $K\\geq 1$, essentially eliminating any burn-in requirement. It also translates to a PAC sample complexity (i.e., the number of episodes needed to yield $\\varepsilon$-accuracy) of $\\frac{SAH^3}{\\varepsilon^2}$ up to log factor, which is minimax-optimal for the full $\\varepsilon$-range.\nFurther, we extend our theory to unveil the influences of problem-dependent quantities like the optimal value/cost and certain variances. The key technical innovation lies in the development of a new regret decomposition strategy and a novel analysis paradigm to decouple complicated statistical dependency -- a long-standing challenge facing the analysis of online RL in the sample-hungry regime.\n    ",
        "primary_category": "cs.LG",
        "categories": [],
        "submitted_date": "25 Jul 2023",
        "last_revised_date": " "
    },
    "2307.13717": {
        "title": "On the Leakage of Fuzzy Matchers",
        "authors": [
            "Axel Durbet",
            "Kevin Thiry-Atighehchi",
            "Dorine Chagnon",
            "Paul-Marie Grollemund"
        ],
        "comments": "Minor corrections",
        "subjects": "Cryptography and Security (cs.CR)",
        "abstract": "In a biometric authentication or identification system, the matcher compares a stored and a fresh template to determine whether there is a match. This assessment is based on both a similarity score and a predefined threshold. For better compliance with privacy legislation, the matcher can be built upon a threshold-based obfuscated distance (i.e., Fuzzy Matcher). Beyond the binary output (\"yes\" or \"no\"), most algorithms perform more precise computations, e.g., the value of the distance. Such precise information is prone to leakage even when not returned by the matcher. This can occur due to a malware infection or the use of a weakly privacy-preserving matcher, exemplified by side channel attacks or partially obfuscated designs. This paper provides an analysis of information leakage during distance evaluation, with an emphasis on threshold-based obfuscated distance. We provide a catalog of information leakage scenarios with their impacts on data privacy. Each scenario gives rise to unique attacks with impacts quantified in terms of computational costs, thereby providing a better understanding of the security level.\n    ",
        "primary_category": "cs.CR",
        "categories": [
            "cs.CV"
        ],
        "submitted_date": "25 Jul 2023",
        "last_revised_date": " "
    },
    "2307.14288": {
        "title": "US \\& MRI Image Fusion Based on Markerless Skin Registration",
        "authors": [
            "Martina Paccini",
            "Giacomo Paschina",
            "Stefano De Beni",
            "Andrei Stefanov",
            "Velizar Kolev",
            "Giuseppe Patan\u00e8"
        ],
        "comments": " ",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "This paper presents an innovative automatic fusion imaging system that combines 3D CT/MR images with real-time ultrasound (US) acquisition. The system eliminates the need for external physical markers and complex training, making image fusion feasible for physicians with different experience levels. The integrated system involves a portable 3D camera for patient-specific surface acquisition, an electromagnetic tracking system, and US components. The fusion algorithm comprises two main parts: skin segmentation and rigid co-registration, both integrated into the US machine. The co-registration software aligns the surface extracted from CT/MR images with patient-specific coordinates, facilitating rapid and effective fusion. Experimental testing in different settings validates the system's accuracy, computational efficiency, noise robustness, and operator independence. The co-registration error remains under the acceptable range of~$1$ cm.\n    ",
        "primary_category": "cs.CV",
        "categories": [],
        "submitted_date": "26 Jul 2023",
        "last_revised_date": " "
    },
    "2307.15337": {
        "title": "Skeleton-of-Thought: Prompting LLMs for Efficient Parallel Generation",
        "authors": [
            "Xuefei Ning",
            "Zinan Lin",
            "Zixuan Zhou",
            "Zifu Wang",
            "Huazhong Yang",
            "Yu Wang"
        ],
        "comments": "In ICLR'24",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "This work aims at decreasing the end-to-end generation latency of large language models (LLMs). One of the major causes of the high generation latency is the sequential decoding approach adopted by almost all state-of-the-art LLMs. In this work, motivated by the thinking and writing process of humans, we propose Skeleton-of-Thought (SoT), which first guides LLMs to generate the skeleton of the answer, and then conducts parallel API calls or batched decoding to complete the contents of each skeleton point in parallel. Not only does SoT provide considerable speed-ups across 12 LLMs, but it can also potentially improve the answer quality on several question categories. SoT is an initial attempt at data-centric optimization for inference efficiency, and showcases the potential of eliciting high-quality answers by explicitly planning the answer structure in language.\n    ",
        "primary_category": "cs.CL",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "28 Jul 2023",
        "last_revised_date": " "
    },
    "2307.15852": {
        "title": "Dimensionless Policies based on the Buckingham $\u03c0$ Theorem: Is This a Good Way to Generalize Numerical Results?",
        "authors": [
            "Alexandre Girard"
        ],
        "comments": " ",
        "subjects": "Optimization and Control (math.OC)",
        "abstract": "The answer to the question posed in the title is yes if the context (the list of variables defining the motion control problem) is dimensionally similar. This article explores the use of the Buckingham $\\pi$ theorem as a tool to encode the control policies of physical systems into a more generic form of knowledge that can be reused in various situations. This approach can be interpreted as enforcing invariance to the scaling of the fundamental units in an algorithm learning a control policy. First, we show, by restating the solution to a motion control problem using dimensionless variables, that (1) the policy mapping involves a reduced number of parameters and (2) control policies generated numerically for a specific system can be transferred exactly to a subset of dimensionally similar systems by scaling the input and output variables appropriately. Those two generic theoretical results are then demonstrated, with numerically generated optimal controllers, for the classic motion control problem of swinging up a torque-limited inverted pendulum and positioning a vehicle in slippery conditions. We also discuss the concept of regime, a region in the space of context variables, that can help to relax the similarity condition. Furthermore, we discuss how applying dimensional scaling of the input and output of a context-specific black-box policy is equivalent to substituting new system parameters in an analytical equation under some conditions, using a linear quadratic regulator (LQR) and a computed torque controller as examples. It remains to be seen how practical this approach can be to generalize policies for more complex high-dimensional problems, but the early results show that it is a promising transfer learning tool for numerical approaches like dynamic programming and reinforcement learning.\n    ",
        "primary_category": "math.OC",
        "categories": [
            "cs.AI",
            "cs.RO",
            "eess.SY"
        ],
        "submitted_date": "29 Jul 2023",
        "last_revised_date": " "
    },
    "2307.16230": {
        "title": "An Unforgeable Publicly Verifiable Watermark for Large Language Models",
        "authors": [
            "Aiwei Liu",
            "Leyi Pan",
            "Xuming Hu",
            "Shu'ang Li",
            "Lijie Wen",
            "Irwin King",
            "Philip S. Yu"
        ],
        "comments": "ICLR2024, 17 pages, 5 figures, 8 tables",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "Recently, text watermarking algorithms for large language models (LLMs) have been proposed to mitigate the potential harms of text generated by LLMs, including fake news and copyright issues. However, current watermark detection algorithms require the secret key used in the watermark generation process, making them susceptible to security breaches and counterfeiting during public detection. To address this limitation, we propose an unforgeable publicly verifiable watermark algorithm that uses two different neural networks for watermark generation and detection, instead of using the same key at both stages. Meanwhile, the token embedding parameters are shared between the generation and detection networks, which makes the detection network achieve a high accuracy very efficiently. Experiments demonstrate that our algorithm attains high detection accuracy and computational efficiency through neural networks with a minimized number of parameters. Subsequent analysis confirms the high complexity involved in forging the watermark from the detection network. Our code and data are available at \\href{this https URL}{this https URL\\_watermark}.\n    ",
        "primary_category": "cs.CL",
        "categories": [],
        "submitted_date": "30 Jul 2023",
        "last_revised_date": " "
    },
    "2307.16387": {
        "title": "Relation-First Modeling Paradigm for Causal Representation Learning toward the Development of AGI",
        "authors": [
            "Jia Li",
            "Xiang Li"
        ],
        "comments": " ",
        "subjects": "Artificial Intelligence (cs.AI)",
        "abstract": "The traditional i.i.d.-based learning paradigm faces inherent challenges in addressing causal relationships, which has become increasingly evident with the rise of applications in causal representation learning.\nOur understanding of causality naturally requires a perspective as the creator rather than observer, as the ``what...if'' questions only hold within the possible world we conceive. The traditional perspective limits capturing dynamic causal outcomes and leads to compensatory efforts such as the reliance on hidden confounders. This paper lays the groundwork for the new perspective, which enables the \\emph{relation-first} modeling paradigm for causality. Also, it introduces the Relation-Indexed Representation Learning (RIRL) as a practical implementation, supported by experiments that validate its efficacy.\n    ",
        "primary_category": "cs.AI",
        "categories": [],
        "submitted_date": "31 Jul 2023",
        "last_revised_date": " "
    },
    "2307.16640": {
        "title": "A multilevel Monte Carlo algorithm for SDEs driven by countably dimensional Wiener process and Poisson random measure",
        "authors": [
            "Micha\u0142 Sobieraj"
        ],
        "comments": "23 pages, 4 figures, 2 code listings",
        "subjects": "Numerical Analysis (math.NA)",
        "abstract": "In this paper, we investigate the properties of standard and multilevel Monte Carlo methods for weak approximation of solutions of stochastic differential equations (SDEs) driven by the infinite-dimensional Wiener process and Poisson random measure with Lipschitz payoff function. The error of the truncated dimension randomized numerical scheme, which is determined by two parameters, i.e grid density $n \\in \\mathbb{N}_{+}$ and truncation dimension parameter $M \\in \\mathbb{N}_{+},$ is of the order $n^{-1/2}+\\delta(M)$ such that $\\delta(\\cdot)$ is positive and decreasing to $0$. We derive complexity model and provide proof for the upper complexity bound of the multilevel Monte Carlo method which depends on two increasing sequences of parameters for both $n$ and $M.$ The complexity is measured in terms of upper bound for mean-squared error and compared with the complexity of the standard Monte Carlo algorithm. The results from numerical experiments as well as Python and CUDA C implementation are also reported.\n    ",
        "primary_category": "math.NA",
        "categories": [
            "math.PR"
        ],
        "submitted_date": "31 Jul 2023",
        "last_revised_date": " "
    },
    "2308.01109": {
        "title": "Signed double Roman domination on cubic graphs",
        "authors": [
            "Enrico Iurlano",
            "Tatjana Zec",
            "Marko Djukanovic",
            "G\u00fcnther R. Raidl"
        ],
        "comments": " ",
        "subjects": "Discrete Mathematics (cs.DM)",
        "abstract": "The signed double Roman domination problem is a combinatorial optimization problem on a graph asking to assign a label from $\\{\\pm{}1,2,3\\}$ to each vertex feasibly, such that the total sum of assigned labels is minimized. Here feasibility is given whenever (i) vertices labeled $\\pm{}1$ have at least one neighbor with label in $\\{2,3\\}$; (ii) each vertex labeled $-1$ has one $3$-labeled neighbor or at least two $2$-labeled neighbors; and (iii) the sum of labels over the closed neighborhood of any vertex is positive. The cumulative weight of an optimal labeling is called signed double Roman domination number (SDRDN). In this work, we first consider the problem on general cubic graphs of order $n$ for which we present a sharp $n/2+\\Theta(1)$ lower bound for the SDRDN by means of the discharging method. Moreover, we derive a new best upper bound. Observing that we are often able to minimize the SDRDN over the class of cubic graphs of a fixed order, we then study in this context generalized Petersen graphs for independent interest, for which we propose a constraint programming guided proof. We then use these insights to determine the SDRDNs of subcubic $2\\times m$ grid graphs, among other results.\n    ",
        "primary_category": "cs.DM",
        "categories": [
            "math.CO"
        ],
        "submitted_date": "2 Aug 2023",
        "last_revised_date": " "
    },
    "2308.01839": {
        "title": "Is your data alignable? Principled and interpretable alignability testing and integration of single-cell data",
        "authors": [
            "Rong Ma",
            "Eric D. Sun",
            "David Donoho",
            "James Zou"
        ],
        "comments": " ",
        "subjects": "Quantitative Methods (q-bio.QM)",
        "abstract": "Single-cell data integration can provide a comprehensive molecular view of cells, and many algorithms have been developed to remove unwanted technical or biological variations and integrate heterogeneous single-cell datasets. Despite their wide usage, existing methods suffer from several fundamental limitations. In particular, we lack a rigorous statistical test for whether two high-dimensional single-cell datasets are alignable (and therefore should even be aligned). Moreover, popular methods can substantially distort the data during alignment, making the aligned data and downstream analysis difficult to interpret. To overcome these limitations, we present a spectral manifold alignment and inference (SMAI) framework, which enables principled and interpretable alignability testing and structure-preserving integration of single-cell data with the same type of features. SMAI provides a statistical test to robustly assess the alignability between datasets to avoid misleading inference, and is justified by high-dimensional statistical theory. On a diverse range of real and simulated benchmark datasets, it outperforms commonly used alignment methods. Moreover, we show that SMAI improves various downstream analyses such as identification of differentially expressed genes and imputation of single-cell spatial transcriptomics, providing further biological insights. SMAI's interpretability also enables quantification and a deeper understanding of the sources of technical confounders in single-cell data.\n    ",
        "primary_category": "q-bio.QM",
        "categories": [
            "cs.CV",
            "q-bio.GN",
            "stat.AP",
            "stat.ML"
        ],
        "submitted_date": "3 Aug 2023",
        "last_revised_date": " "
    },
    "2308.02747": {
        "title": "SureFED: Robust Federated Learning via Uncertainty-Aware Inward and Outward Inspection",
        "authors": [
            "Nasimeh Heydaribeni",
            "Ruisi Zhang",
            "Tara Javidi",
            "Cristina Nita-Rotaru",
            "Farinaz Koushanfar"
        ],
        "comments": " ",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "In this work, we introduce SureFED, a novel framework for byzantine robust federated learning. Unlike many existing defense methods that rely on statistically robust quantities, making them vulnerable to stealthy and colluding attacks, SureFED establishes trust using the local information of benign clients. SureFED utilizes an uncertainty aware model evaluation and introspection to safeguard against poisoning attacks. In particular, each client independently trains a clean local model exclusively using its local dataset, acting as the reference point for evaluating model updates. SureFED leverages Bayesian models that provide model uncertainties and play a crucial role in the model evaluation process. Our framework exhibits robustness even when the majority of clients are compromised, remains agnostic to the number of malicious clients, and is well-suited for non-IID settings. We theoretically prove the robustness of our algorithm against data and model poisoning attacks in a decentralized linear regression setting. Proof-of Concept evaluations on benchmark image classification data demonstrate the superiority of SureFED over the state of the art defense methods under various colluding and non-colluding data and model poisoning attacks.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.DC",
            "cs.MA"
        ],
        "submitted_date": "4 Aug 2023",
        "last_revised_date": " "
    },
    "2308.02918": {
        "title": "Spectral Ranking Inferences based on General Multiway Comparisons",
        "authors": [
            "Jianqing Fan",
            "Zhipeng Lou",
            "Weichen Wang",
            "Mengxin Yu"
        ],
        "comments": "62 pages, 4 figures",
        "subjects": "Methodology (stat.ME)",
        "abstract": "This paper studies the performance of the spectral method in the estimation and uncertainty quantification of the unobserved preference scores of compared entities in a general and more realistic setup. Specifically, the comparison graph consists of hyper-edges of possible heterogeneous sizes, and the number of comparisons can be as low as one for a given hyper-edge. Such a setting is pervasive in real applications, circumventing the need to specify the graph randomness and the restrictive homogeneous sampling assumption imposed in the commonly used Bradley-Terry-Luce (BTL) or Plackett-Luce (PL) models. Furthermore, in scenarios where the BTL or PL models are appropriate, we unravel the relationship between the spectral estimator and the Maximum Likelihood Estimator (MLE). We discover that a two-step spectral method, where we apply the optimal weighting estimated from the equal weighting vanilla spectral method, can achieve the same asymptotic efficiency as the MLE. Given the asymptotic distributions of the estimated preference scores, we also introduce a comprehensive framework to carry out both one-sample and two-sample ranking inferences, applicable to both fixed and random graph settings. It is noteworthy that this is the first time effective two-sample rank testing methods have been proposed. Finally, we substantiate our findings via comprehensive numerical simulations and subsequently apply our developed methodologies to perform statistical inferences for statistical journals and movie rankings.\n    ",
        "primary_category": "stat.ME",
        "categories": [
            "cs.IT",
            "cs.LG",
            "math.ST",
            "stat.ML"
        ],
        "submitted_date": "5 Aug 2023",
        "last_revised_date": " "
    },
    "2308.03812": {
        "title": "Noncompact uniform universal approximation",
        "authors": [
            "Teun D. H. van Nuland"
        ],
        "comments": "13 pages, 3 figures",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "The universal approximation theorem is generalised to uniform convergence on the (noncompact) input space $\\mathbb{R}^n$. All continuous functions that vanish at infinity can be uniformly approximated by neural networks with one hidden layer, for all activation functions $\\varphi$ that are continuous, nonpolynomial, and asymptotically polynomial at $\\pm\\infty$. When $\\varphi$ is moreover bounded, we exactly determine which functions can be uniformly approximated by neural networks, with the following unexpected results. Let $\\overline{\\mathcal{N}_\\varphi^l(\\mathbb{R}^n)}$ denote the vector space of functions that are uniformly approximable by neural networks with $l$ hidden layers and $n$ inputs. For all $n$ and all $l\\geq2$, $\\overline{\\mathcal{N}_\\varphi^l(\\mathbb{R}^n)}$ turns out to be an algebra under the pointwise product. If the left limit of $\\varphi$ differs from its right limit (for instance, when $\\varphi$ is sigmoidal) the algebra $\\overline{\\mathcal{N}_\\varphi^l(\\mathbb{R}^n)}$ ($l\\geq2$) is independent of $\\varphi$ and $l$, and equals the closed span of products of sigmoids composed with one-dimensional projections. If the left limit of $\\varphi$ equals its right limit, $\\overline{\\mathcal{N}_\\varphi^l(\\mathbb{R}^n)}$ ($l\\geq1$) equals the (real part of the) commutative resolvent algebra, a C*-algebra which is used in mathematical approaches to quantum theory. In the latter case, the algebra is independent of $l\\geq1$, whereas in the former case $\\overline{\\mathcal{N}_\\varphi^2(\\mathbb{R}^n)}$ is strictly bigger than $\\overline{\\mathcal{N}_\\varphi^1(\\mathbb{R}^n)}$.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "math.FA",
            "math.OA"
        ],
        "submitted_date": "7 Aug 2023",
        "last_revised_date": " "
    },
    "2308.04075": {
        "title": "Boundary-preserving Lamperti-splitting schemes for some Stochastic Differential Equations",
        "authors": [
            "Johan Ulander"
        ],
        "comments": "30 pages, 6 figures",
        "subjects": "Numerical Analysis (math.NA)",
        "abstract": "We propose and analyse boundary-preserving schemes for the strong approximations of some scalar SDEs with non-globally Lipschitz drift and diffusion coefficients whose state-space is bounded. The schemes consists of a Lamperti transform followed by a Lie--Trotter splitting. We prove $L^{p}(\\Omega)$-convergence of order $1$, for every $p \\geq 1$, of the schemes and exploit the Lamperti transform to confine the numerical approximations to the state-space of the considered SDE. We provide numerical experiments that confirm the theoretical results and compare the proposed Lamperti-splitting schemes to other numerical schemes for SDEs.\n    ",
        "primary_category": "math.NA",
        "categories": [],
        "submitted_date": "8 Aug 2023",
        "last_revised_date": " "
    },
    "2308.04455": {
        "title": "Anonymizing Speech: Evaluating and Designing Speaker Anonymization Techniques",
        "authors": [
            "Pierre Champion"
        ],
        "comments": "PhD Thesis Pierre Champion | Universit\u00e9 de Lorraine - INRIA Nancy | for associated source code, see this https URL",
        "subjects": "Cryptography and Security (cs.CR)",
        "abstract": "The growing use of voice user interfaces has led to a surge in the collection and storage of speech data. While data collection allows for the development of efficient tools powering most speech services, it also poses serious privacy issues for users as centralized storage makes private personal speech data vulnerable to cyber threats. With the increasing use of voice-based digital assistants like Amazon's Alexa, Google's Home, and Apple's Siri, and with the increasing ease with which personal speech data can be collected, the risk of malicious use of voice-cloning and speaker/gender/pathological/etc. recognition has increased.\nThis thesis proposes solutions for anonymizing speech and evaluating the degree of the anonymization. In this work, anonymization refers to making personal speech data unlinkable to an identity while maintaining the usefulness (utility) of the speech signal (e.g., access to linguistic content). We start by identifying several challenges that evaluation protocols need to consider to evaluate the degree of privacy protection properly. We clarify how anonymization systems must be configured for evaluation purposes and highlight that many practical deployment configurations do not permit privacy evaluation. Furthermore, we study and examine the most common voice conversion-based anonymization system and identify its weak points before suggesting new methods to overcome some limitations. We isolate all components of the anonymization system to evaluate the degree of speaker PPI associated with each of them. Then, we propose several transformation methods for each component to reduce as much as possible speaker PPI while maintaining utility. We promote anonymization algorithms based on quantization-based transformation as an alternative to the most-used and well-known noise-based approach. Finally, we endeavor a new attack method to invert anonymization.\n    ",
        "primary_category": "cs.CR",
        "categories": [
            "cs.AI",
            "cs.SD",
            "eess.AS"
        ],
        "submitted_date": "5 Aug 2023",
        "last_revised_date": " "
    },
    "2308.04689": {
        "title": "Web crawler strategies for web pages under robot.txt restriction",
        "authors": [
            "Piyush Vyas",
            "Akhilesh Chauhan",
            "Tushar Mandge",
            "Surbhi Hardikar"
        ],
        "comments": " ",
        "subjects": "Artificial Intelligence (cs.AI)",
        "abstract": "In the present time, all know about World Wide Web and work over the Internet daily. In this paper, we introduce the search engines working for keywords that are entered by users to find something. The search engine uses different search algorithms for convenient results for providing to the net surfer. Net surfers go with the top search results but how did the results of web pages get higher ranks over search engines? how the search engine got that all the web pages in the database? This paper gives the answers to all these kinds of basic questions. Web crawlers working for search engines and robot exclusion protocol rules for web crawlers are also addressed in this research paper. Webmaster uses different restriction facts in robot.txt file to instruct web crawler, some basic formats of robot.txt are also mentioned in this paper.\n    ",
        "primary_category": "cs.AI",
        "categories": [
            "cs.IR"
        ],
        "submitted_date": "9 Aug 2023",
        "last_revised_date": " "
    },
    "2308.05500": {
        "title": "An Adaptive Algorithm Based on Stochastic Discontinuous Galerkin for Convection Dominated Equations with Random Data",
        "authors": [
            "Pelin \u00c7ilo\u011flu",
            "Hamdullah Y\u00fccel"
        ],
        "comments": "26 pages, 19 figures, 5 tables",
        "subjects": "Numerical Analysis (math.NA)",
        "abstract": "In this paper, we propose an adaptive approach, based on mesh refinement or parametric enrichment with polynomial degree adaption, for numerical solution of convection dominated equations with random input data. A parametric system emerged from an application of stochastic Galerkin approach is discretized by using a symmetric interior penalty Galerkin (SIPG) method with upwinding for the convection term in the spatial domain. We derive a residual-based error estimator contributed by the error due to the SIPG discretization, the (generalized) polynomial chaos discretization in the stochastic space, and data oscillations. Then, the reliability of the proposed error estimator, an upper bound for the energy error up to a multiplicative constant, is shown. Moreover, to balance the errors stemmed from spatial and stochastic spaces, the truncation error coming from Karhunen--Lo\u00e8ve expansion is also considered in the numerical simulations. Last, several benchmark examples including a random diffusivity parameter, a random velocity parameter, random diffusivity/velocity parameters, and a random (jump) discontinuous diffusivity parameter, are tested to illustrate the performance of the proposed estimator.\n    ",
        "primary_category": "math.NA",
        "categories": [],
        "submitted_date": "10 Aug 2023",
        "last_revised_date": " "
    },
    "2308.05576": {
        "title": "Do Language Models' Words Refer?",
        "authors": [
            "Matthew Mandelkern",
            "Tal Linzen"
        ],
        "comments": " ",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "What do language models (LMs) do with language? Everyone agrees that they can produce sequences of (mostly) coherent strings of English. But do those sentences mean something, or are LMs simply babbling in a convincing simulacrum of language use? Here we will address one aspect of this broad question: whether LMs' words can refer, that is, achieve \"word-to-world\" connections. There is prima facie reason to think they do not since LMs do not interact with the world in the way that ordinary language users do. Drawing on insights from the externalist tradition in philosophy of language, we argue that those appearances are misleading: even if the inputs to an LM are simply strings of text, they are strings of text with natural histories, and that may suffice to put LMs' words into referential contact with the external world.\n    ",
        "primary_category": "cs.CL",
        "categories": [],
        "submitted_date": "10 Aug 2023",
        "last_revised_date": " "
    },
    "2308.05696": {
        "title": "A Preliminary Study of the Intrinsic Relationship between Complexity and Alignment",
        "authors": [
            "Yingxiu Zhao",
            "Bowen Yu",
            "Binyuan Hui",
            "Haiyang Yu",
            "Fei Huang",
            "Yongbin Li",
            "Nevin L. Zhang"
        ],
        "comments": "LREC-Coling 2024",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "Training large language models (LLMs) with open-domain instruction data has yielded remarkable success in aligning to end tasks and human preferences. Extensive research has highlighted the importance of the quality and diversity of instruction data. However, the impact of data complexity, as a crucial metric, remains relatively unexplored from three aspects: (1)where the sustainability of performance improvements with increasing complexity is uncertain; (2)whether the improvement brought by complexity merely comes from introducing more training tokens; and (3)where the potential benefits of incorporating instructions from easy to difficult are not yet fully understood. In this paper, we propose Tree-Instruct to systematically enhance the instruction complexity in a controllable manner. By adding a specified number of nodes to instructions' semantic trees, this approach not only yields new instruction data from the modified tree but also allows us to control the difficulty level of modified instructions. Our preliminary experiments reveal the following insights: (1)Increasing complexity consistently leads to sustained performance improvements of LLMs. (2)Under the same token budget, a few complex instructions outperform diverse yet simple instructions. (3)Curriculum instruction tuning might not yield the anticipated results; focusing on increasing complexity appears to be the key.\n    ",
        "primary_category": "cs.CL",
        "categories": [],
        "submitted_date": "10 Aug 2023",
        "last_revised_date": " "
    },
    "2308.06250": {
        "title": "Big AI Models for 6G Wireless Networks: Opportunities, Challenges, and Research Directions",
        "authors": [
            "Zirui Chen",
            "Zhaoyang Zhang",
            "Zhaohui Yang"
        ],
        "comments": " ",
        "subjects": "Networking and Internet Architecture (cs.NI)",
        "abstract": "Recently, big artificial intelligence models (BAIMs) represented by chatGPT have brought an incredible revolution. With the pre-trained BAIMs in certain fields, numerous downstream tasks can be accomplished with only few-shot or even zero-shot learning and exhibit state-of-the-art performances. As widely envisioned, the big AI models are to rapidly penetrate into major intelligent services and applications, and are able to run at low unit cost and high flexibility. In 6G wireless networks, to fully enable intelligent communication, sensing and computing, apart from providing other intelligent wireless services and applications, it is of vital importance to design and deploy certain wireless BAIMs (wBAIMs). However, there still lacks investigation on architecture design and system evaluation for wBAIM. In this paper, we provide a comprehensive discussion as well as some in-depth prospects on the demand, design and deployment aspects of the wBAIM. We opine that wBAIM will be a recipe of the 6G wireless networks to build high-efficient, sustainable, versatile, and extensible wireless intelligence for numerous promising visions. Then, we provide the core characteristics, principles, and pilot studies to guide the design of wBAIMs, and discuss the key aspects of developing wBAIMs through identifying the differences between the existing BAIMs and the emerging wBAIMs. Finally, related research directions and potential solutions are outlined.\n    ",
        "primary_category": "cs.NI",
        "categories": [
            "eess.SP"
        ],
        "submitted_date": "11 Aug 2023",
        "last_revised_date": " "
    },
    "2308.06960": {
        "title": "Search to Fine-tune Pre-trained Graph Neural Networks for Graph-level Tasks",
        "authors": [
            "Zhili Wang",
            "Shimin Di",
            "Lei Chen",
            "Xiaofang Zhou"
        ],
        "comments": " ",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Recently, graph neural networks (GNNs) have shown its unprecedented success in many graph-related tasks. However, GNNs face the label scarcity issue as other neural networks do. Thus, recent efforts try to pre-train GNNs on a large-scale unlabeled graph and adapt the knowledge from the unlabeled graph to the target downstream task. The adaptation is generally achieved by fine-tuning the pre-trained GNNs with a limited number of labeled data. Despite the importance of fine-tuning, current GNNs pre-training works often ignore designing a good fine-tuning strategy to better leverage transferred knowledge and improve the performance on downstream tasks. Only few works start to investigate a better fine-tuning strategy for pre-trained GNNs. But their designs either have strong assumptions or overlook the data-aware issue for various downstream datasets. Therefore, we aim to design a better fine-tuning strategy for pre-trained GNNs to improve the model performance in this paper. Given a pre-trained GNN, we propose to search to fine-tune pre-trained graph neural networks for graph-level tasks (S2PGNN), which adaptively design a suitable fine-tuning framework for the given labeled data on the downstream task. To ensure the improvement brought by searching fine-tuning strategy, we carefully summarize a proper search space of fine-tuning framework that is suitable for GNNs. The empirical studies show that S2PGNN can be implemented on the top of 10 famous pre-trained GNNs and consistently improve their performance. Besides, S2PGNN achieves better performance than existing fine-tuning strategies within and outside the GNN area. Our code is publicly available at \\url{https://anonymous.4open.science/r/code_icde2024-A9CB/}.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "14 Aug 2023",
        "last_revised_date": " "
    },
    "2308.07231": {
        "title": "Large-scale environment mapping and immersive human-robot interaction for agricultural mobile robot teleoperation",
        "authors": [
            "Tao Liu",
            "Baohua Zhang",
            "Qianqiu Tan"
        ],
        "comments": " ",
        "subjects": "Systems and Control (eess.SY)",
        "abstract": "Remote operation is a crucial solution to problems encountered in agricultural machinery operations. However, traditional video streaming control methods fall short in overcoming the challenges of single perspective views and the inability to obtain 3D information. In light of these issues, our research proposes a large-scale digital map reconstruction and immersive human-machine remote control framework for agricultural scenarios. In our methodology, a DJI unmanned aerial vehicle(UAV) was utilized for data collection, and a novel video segmentation approach based on feature points was introduced. To tackle texture richness variability, an enhanced Structure from Motion (SfM) using superpixel segmentation was implemented. This method integrates the open Multiple View Geometry (openMVG) framework along with Local Features from Transformers (LoFTR). The enhanced SfM results in a point cloud map, which is further processed through Multi-View Stereo (MVS) to generate a complete map model. For control, a closed-loop system utilizing TCP for VR control and positioning of agricultural machinery was introduced. Our system offers a fully visual-based immersive control method, where upon connection to the local area network, operators can utilize VR for immersive remote control. The proposed method enhances both the robustness and convenience of the reconstruction process, thereby significantly facilitating operators in acquiring more comprehensive on-site information and engaging in immersive remote control operations. The code is available at: this https URL\n",
        "primary_category": "eess.SY",
        "categories": [],
        "submitted_date": "14 Aug 2023",
        "last_revised_date": " "
    },
    "2308.07470": {
        "title": "Symphony: Optimized DNN Model Serving using Deferred Batch Scheduling",
        "authors": [
            "Lequn Chen",
            "Weixin Deng",
            "Anirudh Canumalla",
            "Yu Xin",
            "Danyang Zhuo",
            "Matthai Philipose",
            "Arvind Krishnamurthy"
        ],
        "comments": " ",
        "subjects": "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "abstract": "Having large batch sizes is one of the most critical aspects of increasing the accelerator efficiency and the performance of DNN model inference. However, existing model serving systems cannot achieve adequate batch sizes while meeting latency objectives as these systems eagerly dispatch requests to accelerators to minimize the accelerator idle time. We propose Symphony, a DNN serving system that explores deferred batch scheduling to optimize system efficiency and throughput. Further, unlike other prior systems, Symphony's GPU usage is load-proportional: it consolidates workloads on the appropriate number of GPUs and works smoothly with cluster auto-scaling tools. Symphony consists of two core design points. First, Symphony defines a schedulable window in which a batch of inference requests can be dispatched. This window is computed in order to improve accelerator efficiency while meeting the request's SLO. Second, Symphony implements a scalable, low-latency, fine-grained coordination scheme across accelerators to dispatch and execute requests in the schedulable window. Through extensive scheduler-only benchmarks, we demonstrate that Symphony can schedule millions of requests per second and coordinate thousands of GPUs while also enabling robust autoscaling that adapts to workload changes. Symphony outperforms prior systems by achieving 5x higher goodput when given the same number of GPUs and 60% reduction in GPUs when given the same workload.\n    ",
        "primary_category": "cs.DC",
        "categories": [
            "cs.LG"
        ],
        "submitted_date": "14 Aug 2023",
        "last_revised_date": " "
    },
    "2308.08567": {
        "title": "CMISR: Circular Medical Image Super-Resolution",
        "authors": [
            "Honggui Li",
            "Nahid Md Lokman Hossain",
            "Maria Trocan",
            "Dimitri Galayko",
            "Mohamad Sawan"
        ],
        "comments": " ",
        "subjects": "Image and Video Processing (eess.IV)",
        "abstract": "Classical methods of medical image super-resolution (MISR) utilize open-loop architecture with implicit under-resolution (UR) unit and explicit super-resolution (SR) unit. The UR unit can always be given, assumed, or estimated, while the SR unit is elaborately designed according to various SR algorithms. The closed-loop feedback mechanism is widely employed in current MISR approaches and can efficiently improve their performance. The feedback mechanism may be divided into two categories: local feedback and global feedback. Therefore, this paper proposes a global feedback-based closed-cycle framework, circular MISR (CMISR), with unambiguous UR and advanced SR elements. Mathematical model and closed-loop equation of CMISR are built. Mathematical proof with Taylor-series approximation indicates that CMISR has zero recovery error in steady-state. In addition, CMISR holds plug-and-play characteristic that fuses model-based and learning-based approaches and can be established on any existing MISR algorithms. Five CMISR algorithms are respectively proposed based on the state-of-the-art open-loop MISR algorithms. Experimental results with three scale factors and on three open medical image datasets show that CMISR is superior to MISR in reconstruction performance and is particularly suited to medical images with strong edges or intense contrast.\n    ",
        "primary_category": "eess.IV",
        "categories": [
            "cs.LG"
        ],
        "submitted_date": "15 Aug 2023",
        "last_revised_date": " "
    },
    "2308.08705": {
        "title": "Partially Observable Multi-agent RL with (Quasi-)Efficiency: The Blessing of Information Sharing",
        "authors": [
            "Xiangyu Liu",
            "Kaiqing Zhang"
        ],
        "comments": "International Conference on Machine Learning (ICML) 2023",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "We study provable multi-agent reinforcement learning (MARL) in the general framework of partially observable stochastic games (POSGs). To circumvent the known hardness results and the use of computationally intractable oracles, we advocate leveraging the potential \\emph{information-sharing} among agents, a common practice in empirical MARL, and a standard model for multi-agent control systems with communications. We first establish several computation complexity results to justify the necessity of information-sharing, as well as the observability assumption that has enabled quasi-efficient single-agent RL with partial observations, for computational efficiency in solving POSGs. We then propose to further \\emph{approximate} the shared common information to construct an {approximate model} of the POSG, in which planning an approximate equilibrium (in terms of solving the original POSG) can be quasi-efficient, i.e., of quasi-polynomial-time, under the aforementioned assumptions. Furthermore, we develop a partially observable MARL algorithm that is both statistically and computationally quasi-efficient. We hope our study may open up the possibilities of leveraging and even designing different \\emph{information structures}, for developing both sample- and computation-efficient partially observable MARL.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.GT",
            "cs.MA"
        ],
        "submitted_date": "16 Aug 2023",
        "last_revised_date": " "
    },
    "2308.09071": {
        "title": "Pattern recognition using spiking antiferromagnetic neurons",
        "authors": [
            "Hannah Bradley",
            "Steven Louis",
            "Andrei Slavin",
            "Vasyl Tyberkevych"
        ],
        "comments": " ",
        "subjects": "Neural and Evolutionary Computing (cs.NE)",
        "abstract": "Spintronic devices offer a promising avenue for the development of nanoscale, energy-efficient artificial neurons for neuromorphic computing. It has previously been shown that with antiferromagnetic (AFM) oscillators, ultra-fast spiking artificial neurons can be made that mimic many unique features of biological neurons. In this work, we train an artificial neural network of AFM neurons to perform pattern recognition. A simple machine learning algorithm called spike pattern association neuron (SPAN), which relies on the temporal position of neuron spikes, is used during training. In under a microsecond of physical time, the AFM neural network is trained to recognize symbols composed from a grid by producing a spike within a specified time window. We further achieve multi-symbol recognition with the addition of an output layer to suppress undesirable spikes. Through the utilization of AFM neurons and the SPAN algorithm, we create a neural network capable of high-accuracy recognition with overall power consumption on the order of picojoules.\n    ",
        "primary_category": "cs.NE",
        "categories": [
            "physics.comp-ph"
        ],
        "submitted_date": "17 Aug 2023",
        "last_revised_date": " "
    },
    "2308.09729": {
        "title": "MindMap: Knowledge Graph Prompting Sparks Graph of Thoughts in Large Language Models",
        "authors": [
            "Yilin Wen",
            "Zifeng Wang",
            "Jimeng Sun"
        ],
        "comments": "8 pages, 8 figures, 12 tables",
        "subjects": "Artificial Intelligence (cs.AI)",
        "abstract": "Large language models (LLMs) have achieved remarkable performance in natural language understanding and generation tasks. However, they often suffer from limitations such as difficulty in incorporating new knowledge, generating hallucinations, and explaining their reasoning process. To address these challenges, we propose a novel prompting pipeline, named \\method, that leverages knowledge graphs (KGs) to enhance LLMs' inference and transparency. Our method enables LLMs to comprehend KG inputs and infer with a combination of implicit and external knowledge. Moreover, our method elicits the mind map of LLMs, which reveals their reasoning pathways based on the ontology of knowledge. We evaluate our method on diverse question \\& answering tasks, especially in medical domains, and show significant improvements over baselines. We also introduce a new hallucination evaluation benchmark and analyze the effects of different components of our method. Our results demonstrate the effectiveness and robustness of our method in merging knowledge from LLMs and KGs for combined inference. To reproduce our results and extend the framework further, we make our codebase available at this https URL.\n    ",
        "primary_category": "cs.AI",
        "categories": [
            "cs.CL",
            "cs.LG"
        ],
        "submitted_date": "17 Aug 2023",
        "last_revised_date": " "
    },
    "2308.10178": {
        "title": "Eventually-Consistent Federated Scheduling for Data Center Workloads",
        "authors": [
            "Meghana Thiyyakat",
            "Subramaniam Kalambur",
            "Rishit Chaudhary",
            "Saurav G Nayak",
            "Adarsh Shetty",
            "Dinkar Sitaram"
        ],
        "comments": "26 pages. Submitted to Elsevier's Ad Hoc Networks Journal",
        "subjects": "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "abstract": "Data center schedulers operate at unprecedented scales today to accommodate the growing demand for computing and storage power. The challenge that schedulers face is meeting the requirements of scheduling speeds despite the scale. To do so, most scheduler architectures use parallelism. However, these architectures consist of multiple parallel scheduling entities that can only utilize partial knowledge of the data center's state, as maintaining consistent global knowledge or state would involve considerable communication overhead. The disadvantage of scheduling without global knowledge is sub-optimal placements-tasks may be made to wait in queues even though there are resources available in zones outside the scope of the scheduling entity's state. This leads to unnecessary queuing overheads and lower resource utilization of the data center. In this paper, extend our previous work on Megha, a federated decentralized data center scheduling architecture that uses eventual consistency. The architecture utilizes both parallelism and an eventually-consistent global state in each of its scheduling entities to make fast decisions in a scalable manner. In our work, we compare Megha with 3 scheduling architectures: Sparrow, Eagle, and Pigeon, using simulation. We also evaluate Megha's prototype on a 123-node cluster and compare its performance with Pigeon's prototype using cluster traces. The results of our experiments show that Megha consistently reduces delays in job completion time when compared to other architectures.\n    ",
        "primary_category": "cs.DC",
        "categories": [],
        "submitted_date": "20 Aug 2023",
        "last_revised_date": " "
    },
    "2308.10562": {
        "title": "Seeing the Intangible: Survey of Image Classification into High-Level and Abstract Categories",
        "authors": [
            "Delfina Sol Martinez Pandiani",
            "Valentina Presutti"
        ],
        "comments": "Preprint",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "The field of Computer Vision (CV) is increasingly shifting towards ``high-level'' visual sensemaking tasks, yet the exact nature of these tasks remains unclear and tacit. This survey paper addresses this ambiguity by systematically reviewing research on high-level visual understanding, focusing particularly on Abstract Concepts (ACs) in automatic image classification. Our survey contributes in three main ways: Firstly, it clarifies the tacit understanding of high-level semantics in CV through a multidisciplinary analysis, and categorization into distinct clusters, including commonsense, emotional, aesthetic, and inductive interpretative semantics. Secondly, it identifies and categorizes computer vision tasks associated with high-level visual sensemaking, offering insights into the diverse research areas within this domain. Lastly, it examines how abstract concepts such as values and ideologies are handled in CV, revealing challenges and opportunities in AC-based image classification. Notably, our survey of AC image classification tasks highlights persistent challenges, such as the limited efficacy of massive datasets and the importance of integrating supplementary information and mid-level features. We emphasize the growing relevance of hybrid AI systems in addressing the multifaceted nature of AC image classification tasks. Overall, this survey enhances our understanding of high-level visual reasoning in CV and lays the groundwork for future research endeavors.\n    ",
        "primary_category": "cs.CV",
        "categories": [
            "cs.CY"
        ],
        "submitted_date": "21 Aug 2023",
        "last_revised_date": " "
    },
    "2308.10686": {
        "title": "Normative Conditional Reasoning as a Fragment of HOL",
        "authors": [
            "Xavier Parent",
            "Christoph Benzm\u00fcller"
        ],
        "comments": "30 pages, 34 figures, 3 tables",
        "subjects": "Logic in Computer Science (cs.LO)",
        "abstract": "We report on the mechanization of (preference-based) conditional normative reasoning. Our focus is on Aqvist's system E for conditional obligation, and its extensions. Our mechanization is achieved via a shallow semantical embedding in Isabelle/HOL. We consider two possible uses of the framework. The first one is as a tool for meta-reasoning about the considered logic. We employ it for the automated verification of deontic correspondences (broadly conceived) and related matters, analogous to what has been previously achieved for the modal logic cube. The equivalence is automatically verified in one direction, leading from the property to the axiom. The second use is as a tool for assessing ethical arguments. We provide a computer encoding of a well-known paradox (or impossibility theorem) in population ethics, Parfit's repugnant conclusion. While some have proposed overcoming the impossibility theorem by abandoning the presupposed transitivity of ''better than'', our formalisation unveils a less extreme approach, suggesting among other things the option of weakening transitivity suitably rather than discarding it entirely. Whether the presented encoding increases or decreases the attractiveness and persuasiveness of the repugnant conclusion is a question we would like to pass on to philosophy and ethics.\n    ",
        "primary_category": "cs.LO",
        "categories": [
            "cs.AI",
            "cs.SC"
        ],
        "submitted_date": "21 Aug 2023",
        "last_revised_date": " "
    },
    "2308.11131": {
        "title": "ReLLa: Retrieval-enhanced Large Language Models for Lifelong Sequential Behavior Comprehension in Recommendation",
        "authors": [
            "Jianghao Lin",
            "Rong Shan",
            "Chenxu Zhu",
            "Kounianhua Du",
            "Bo Chen",
            "Shigang Quan",
            "Ruiming Tang",
            "Yong Yu",
            "Weinan Zhang"
        ],
        "comments": "Accepted by WWW 2024. Full and More Readable Version",
        "subjects": "Information Retrieval (cs.IR)",
        "abstract": "With large language models (LLMs) achieving remarkable breakthroughs in natural language processing (NLP) domains, LLM-enhanced recommender systems have received much attention and have been actively explored currently. In this paper, we focus on adapting and empowering a pure large language model for zero-shot and few-shot recommendation tasks. First and foremost, we identify and formulate the lifelong sequential behavior incomprehension problem for LLMs in recommendation domains, i.e., LLMs fail to extract useful information from a textual context of long user behavior sequence, even if the length of context is far from reaching the context limitation of LLMs. To address such an issue and improve the recommendation performance of LLMs, we propose a novel framework, namely Retrieval-enhanced Large Language models (ReLLa) for recommendation tasks in both zero-shot and few-shot settings. For zero-shot recommendation, we perform semantic user behavior retrieval (SUBR) to improve the data quality of testing samples, which greatly reduces the difficulty for LLMs to extract the essential knowledge from user behavior sequences. As for few-shot recommendation, we further design retrieval-enhanced instruction tuning (ReiT) by adopting SUBR as a data augmentation technique for training samples. Specifically, we develop a mixed training dataset consisting of both the original data samples and their retrieval-enhanced counterparts. We conduct extensive experiments on three real-world public datasets to demonstrate the superiority of ReLLa compared with existing baseline models, as well as its capability for lifelong sequential behavior comprehension. To be highlighted, with only less than 10% training samples, few-shot ReLLa can outperform traditional CTR models that are trained on the entire training set (e.g., DCNv2, DIN, SIM). The code is available \\url{this https URL}.\n    ",
        "primary_category": "cs.IR",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "22 Aug 2023",
        "last_revised_date": " "
    },
    "2308.11273": {
        "title": "Up-to-date Threat Modelling for Soft Privacy on Smart Cars",
        "authors": [
            "Mario Raciti",
            "Giampaolo Bella"
        ],
        "comments": "Accepted in 7th International Workshop on SECurity and Privacy Requirements Engineering (SECPRE 2023). arXiv admin note: substantial text overlap with arXiv:2306.04222",
        "subjects": "Cryptography and Security (cs.CR)",
        "abstract": "Physical persons playing the role of car drivers consume data that is sourced from the Internet and, at the same time, themselves act as sources of relevant data. It follows that citizens' privacy is potentially at risk while they drive, hence the need to model privacy threats in this application domain. This paper addresses the privacy threats by updating a recent threat-modelling methodology and by tailoring it specifically to the soft privacy target property, which ensures citizens' full control on their personal data. The methodology now features the sources of documentation as an explicit variable that is to be considered. It is demonstrated by including a new version of the de-facto standard LINDDUN methodology as well as an additional source by ENISA which is found to be relevant to soft privacy. The main findings are a set of 23 domain-independent threats, 43 domain-specific assets and 525 domain-dependent threats for the target property in the automotive domain. While these exceed their previous versions, their main value is to offer self-evident support to at least two arguments. One is that LINDDUN has evolved much the way our original methodology already advocated because a few of our previously suggested extensions are no longer outstanding. The other one is that ENISA's treatment of privacy aboard smart cars should be extended considerably because our 525 threats fall in the same scope.\n    ",
        "primary_category": "cs.CR",
        "categories": [],
        "submitted_date": "22 Aug 2023",
        "last_revised_date": " "
    },
    "2308.11863": {
        "title": "KinSPEAK: Improving speech recognition for Kinyarwanda via semi-supervised learning methods",
        "authors": [
            "Antoine Nzeyimana"
        ],
        "comments": "9 pages, 2 figures, 5 tables",
        "subjects": "Audio and Speech Processing (eess.AS)",
        "abstract": "Despite recent availability of large transcribed Kinyarwanda speech data, achieving robust speech recognition for Kinyarwanda is still challenging. In this work, we show that using self-supervised pre-training, following a simple curriculum schedule during fine-tuning and using semi-supervised learning to leverage large unlabelled speech data significantly improve speech recognition performance for Kinyarwanda. Our approach focuses on using public domain data only. A new studio-quality speech dataset is collected from a public website, then used to train a clean baseline model. The clean baseline model is then used to rank examples from a more diverse and noisy public dataset, defining a simple curriculum training schedule. Finally, we apply semi-supervised learning to label and learn from large unlabelled data in five successive generations. Our final model achieves 3.2% word error rate (WER) on the new dataset and 15.6% WER on Mozilla Common Voice benchmark, which is state-of-the-art to the best of our knowledge. Our experiments also indicate that using syllabic rather than character-based tokenization results in better speech recognition performance for Kinyarwanda.\n    ",
        "primary_category": "eess.AS",
        "categories": [
            "cs.LG",
            "cs.SD"
        ],
        "submitted_date": "23 Aug 2023",
        "last_revised_date": " "
    },
    "2308.11909": {
        "title": "Edge-aware Hard Clustering Graph Pooling for Brain Imaging",
        "authors": [
            "Cheng Zhu",
            "Jiayi Zhu",
            "Xi Wu",
            "Lijuan Zhang",
            "Shuqi Yang",
            "Ping Liang",
            "Honghan Chen",
            "Ying Tan"
        ],
        "comments": " ",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Graph Convolutional Networks (GCNs) can capture non-Euclidean spatial dependence between different brain regions. The graph pooling operator, a crucial element of GCNs, enhances the representation learning capability and facilitates the acquisition of abnormal brain maps. However, most existing research designs graph pooling operators solely from the perspective of nodes while disregarding the original edge features. This confines graph pooling application scenarios and diminishes its ability to capture critical substructures. In this paper, we propose a novel edge-aware hard clustering graph pool (EHCPool), which is tailored to dominant edge features and redefines the clustering process. EHCPool initially introduced the 'Edge-to-Node' score criterion which utilized edge information to evaluate the significance of nodes. An innovative Iteration n-top strategy was then developed, guided by edge scores, to adaptively learn sparse hard clustering assignments for graphs. Additionally, a N-E Aggregation strategy is designed to aggregate node and edge features in each independent subgraph. Extensive experiments on the multi-site public datasets demonstrate the superiority and robustness of the proposed model. More notably, EHCPool has the potential to probe different types of dysfunctional brain networks from a data-driven perspective. Method code: this https URL\n",
        "primary_category": "cs.CV",
        "categories": [
            "cs.GR"
        ],
        "submitted_date": "23 Aug 2023",
        "last_revised_date": " "
    },
    "2308.11971": {
        "title": "EVE: Efficient Vision-Language Pre-training with Masked Prediction and Modality-Aware MoE",
        "authors": [
            "Junyi Chen",
            "Longteng Guo",
            "Jia Sun",
            "Shuai Shao",
            "Zehuan Yuan",
            "Liang Lin",
            "Dongyu Zhang"
        ],
        "comments": "Accepted by AAAI 2024",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Building scalable vision-language models to learn from diverse, multimodal data remains an open challenge. In this paper, we introduce an Efficient Vision-languagE foundation model, namely EVE, which is one unified multimodal Transformer pre-trained solely by one unified pre-training task. Specifically, EVE encodes both vision and language within a shared Transformer network integrated with modality-aware sparse Mixture-of-Experts (MoE) modules, which capture modality-specific information by selectively switching to different experts. To unify pre-training tasks of vision and language, EVE performs masked signal modeling on image-text pairs to reconstruct masked signals, i.e., image pixels and text tokens, given visible signals. This simple yet effective pre-training objective accelerates training by 3.5x compared to the model pre-trained with Image-Text Contrastive and Image-Text Matching losses. Owing to the combination of the unified architecture and pre-training task, EVE is easy to scale up, enabling better downstream performance with fewer resources and faster training speed. Despite its simplicity, EVE achieves state-of-the-art performance on various vision-language downstream tasks, including visual question answering, visual reasoning, and image-text retrieval.\n    ",
        "primary_category": "cs.CV",
        "categories": [
            "cs.CL",
            "cs.LG",
            "cs.MM"
        ],
        "submitted_date": "23 Aug 2023",
        "last_revised_date": " "
    },
    "2308.12158": {
        "title": "A Visualization System for Hexahedral Mesh Quality Study",
        "authors": [
            "Lei Si",
            "Guoning Chen"
        ],
        "comments": "Accepted by IEEE VIS 2023 Short Papers and will be published on IEEE Xplore. Paper contains 4 pages, and 1 reference page. Supplemental includes 4 pages",
        "subjects": "Graphics (cs.GR)",
        "abstract": "In this paper, we introduce a new 3D hex mesh visual analysis system that emphasizes poor-quality areas with an aggregated glyph, highlights overlapping elements, and provides detailed boundary error inspection in three forms. By supporting multi-level analysis through multiple views, our system effectively evaluates various mesh models and compares the performance of mesh generation and optimization algorithms for hexahedral meshes.\n    ",
        "primary_category": "cs.GR",
        "categories": [
            "cs.HC"
        ],
        "submitted_date": "23 Aug 2023",
        "last_revised_date": " "
    },
    "2308.13424": {
        "title": "AG codes have no list-decoding friends: Approaching the generalized Singleton bound requires exponential alphabets",
        "authors": [
            "Omar Alrabiah",
            "Venkatesan Guruswami",
            "Ray Li"
        ],
        "comments": " ",
        "subjects": "Information Theory (cs.IT)",
        "abstract": "A simple, recently observed generalization of the classical Singleton bound to list-decoding asserts that rate $R$ codes are not list-decodable using list-size $L$ beyond an error fraction $\\frac{L}{L+1} (1-R)$ (the Singleton bound being the case of $L=1$, i.e., unique decoding). We prove that in order to approach this bound for any fixed $L >1$, one needs exponential alphabets. Specifically, for every $L>1$ and $R\\in(0,1)$, if a rate $R$ code can be list-of-$L$ decoded up to error fraction $\\frac{L}{L+1} (1-R -\\varepsilon)$, then its alphabet must have size at least $\\exp(\\Omega_{L,R}(1/\\varepsilon))$. This is in sharp contrast to the situation for unique decoding where certain families of rate $R$ algebraic-geometry (AG) codes over an alphabet of size $O(1/\\varepsilon^2)$ are unique-decodable up to error fraction $(1-R-\\varepsilon)/2$. Our bounds hold even for subconstant $\\varepsilon\\ge 1/n$, implying that any code exactly achieving the $L$-th generalized Singleton bound requires alphabet size $2^{\\Omega_{L,R}(n)}$. Previously this was only known only for $L=2$ under the additional assumptions that the code is both linear and MDS.\nOur lower bound is tight up to constant factors in the exponent -- with high probability random codes (or, as shown recently, even random linear codes) over $\\exp(O_L(1/\\varepsilon))$-sized alphabets, can be list-of-$L$ decoded up to error fraction $\\frac{L}{L+1} (1-R -\\varepsilon)$.\n    ",
        "primary_category": "cs.IT",
        "categories": [
            "cs.DM",
            "math.CO"
        ],
        "submitted_date": "25 Aug 2023",
        "last_revised_date": " "
    },
    "2308.13654": {
        "title": "Pretty darn good control: when are approximate solutions better than approximate models",
        "authors": [
            "Felipe Montealegre-Mora",
            "Marcus Lapeyrolerie",
            "Melissa Chapman",
            "Abigail G. Keller",
            "Carl Boettiger"
        ],
        "comments": "24 pages, 14 figures. Accepted to the Bulletin of Mathematical Biology",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Existing methods for optimal control struggle to deal with the complexity commonly encountered in real-world systems, including dimensionality, process error, model bias and data heterogeneity. Instead of tackling these system complexities directly, researchers have typically sought to simplify models to fit optimal control methods. But when is the optimal solution to an approximate, stylized model better than an approximate solution to a more accurate model? While this question has largely gone unanswered owing to the difficulty of finding even approximate solutions for complex models, recent algorithmic and computational advances in deep reinforcement learning (DRL) might finally allow us to address these questions. DRL methods have to date been applied primarily in the context of games or robotic mechanics, which operate under precisely known rules. Here, we demonstrate the ability for DRL algorithms using deep neural networks to successfully approximate solutions (the \"policy function\" or control rule) in a non-linear three-variable model for a fishery without knowing or ever attempting to infer a model for the process itself. We find that the reinforcement learning agent discovers an effective simplification of the problem to obtain an interpretable control rule. We show that the policy obtained with DRL is both more profitable and more sustainable than any constant mortality policy -- the standard family of policies considered in fishery management.\n    ",
        "primary_category": "cs.LG",
        "categories": [],
        "submitted_date": "25 Aug 2023",
        "last_revised_date": " "
    },
    "2308.14015": {
        "title": "Slimmed optical neural networks with multiplexed neuron sets and a corresponding backpropagation training algorithm",
        "authors": [
            "Yi-Feng Liu",
            "Rui-Yao Ren",
            "Dai-Bao Hou",
            "Hai-Zhong Weng",
            "Bo-Wen Wang",
            "Ke-Jie Huang",
            "Xing Lin",
            "Feng Liu",
            "Chen-Hui Li",
            "Chao-Yuan Jin"
        ],
        "comments": " ",
        "subjects": "Signal Processing (eess.SP)",
        "abstract": "Due to their intrinsic capabilities on parallel signal processing, optical neural networks (ONNs) have attracted extensive interests recently as a potential alternative to electronic artificial neural networks (ANNs) with reduced power consumption and low latency. Preliminary confirmation of the parallelism in optical computing has been widely done by applying the technology of wavelength division multiplexing (WDM) in the linear transformation part of neural networks. However, inter-channel crosstalk has obstructed WDM technologies to be deployed in nonlinear activation in ONNs. Here, we propose a universal WDM structure called multiplexed neuron sets (MNS) which apply WDM technologies to optical neurons and enable ONNs to be further compressed. A corresponding back-propagation (BP) training algorithm is proposed to alleviate or even cancel the influence of inter-channel crosstalk on MNS-based WDM-ONNs. For simplicity, semiconductor optical amplifiers (SOAs) are employed as an example of MNS to construct a WDM-ONN trained with the new algorithm. The result shows that the combination of MNS and the corresponding BP training algorithm significantly downsize the system and improve the energy efficiency to tens of times while giving similar performance to traditional ONNs.\n    ",
        "primary_category": "eess.SP",
        "categories": [
            "cs.AR"
        ],
        "submitted_date": "27 Aug 2023",
        "last_revised_date": " "
    },
    "2308.14490": {
        "title": "Efficient least squares approximation and collocation methods using radial basis functions",
        "authors": [
            "Yiqing Zhou",
            "Daan Huybrechs"
        ],
        "comments": "23 pages, 10 figures",
        "subjects": "Numerical Analysis (math.NA)",
        "abstract": "We describe an efficient method for the approximation of functions using radial basis functions (RBFs), and extend this to a solver for boundary value problems on irregular domains. The method is based on RBFs with centers on a regular grid defined on a bounding box, with some of the centers outside the computational domain. The equation is discretized using collocation with oversampling, with collocation points inside the domain only, resulting in a rectangular linear system to be solved in a least squares sense. The goal of this paper is the efficient solution of that rectangular system. We show that the least squares problem splits into a regular part, which can be expedited with the FFT, and a low rank perturbation, which is treated separately with a direct solver. The rank of the perturbation is influenced by the irregular shape of the domain and by the weak enforcement of boundary conditions at points along the boundary. The solver extends the AZ algorithm which was previously proposed for function approximation involving frames and other overcomplete sets. The solver has near optimal log-linear complexity for univariate problems, and loses optimality for higher-dimensional problems but remains faster than a direct solver.\n    ",
        "primary_category": "math.NA",
        "categories": [],
        "submitted_date": "28 Aug 2023",
        "last_revised_date": " "
    },
    "2308.14947": {
        "title": "Improving Generalization in Reinforcement Learning Training Regimes for Social Robot Navigation",
        "authors": [
            "Adam Sigal",
            "Hsiu-Chin Lin",
            "AJung Moon"
        ],
        "comments": "NeurIPS 2023 Workshop on Generalization in Planning, 2023",
        "subjects": "Robotics (cs.RO)",
        "abstract": "In order for autonomous mobile robots to navigate in human spaces, they must abide by our social norms. Reinforcement learning (RL) has emerged as an effective method to train sequential decision-making policies that are able to respect these norms. However, a large portion of existing work in the field conducts both RL training and testing in simplistic environments. This limits the generalization potential of these models to unseen environments, and the meaningfulness of their reported results. We propose a method to improve the generalization performance of RL social navigation methods using curriculum learning. By employing multiple environment types and by modeling pedestrians using multiple dynamics models, we are able to progressively diversify and escalate difficulty in training. Our results show that the use of curriculum learning in training can be used to achieve better generalization performance than previous training methods. We also show that results presented in many existing state-of-the-art RL social navigation works do not evaluate their methods outside of their training environments, and thus do not reflect their policies' failure to adequately generalize to out-of-distribution scenarios. In response, we validate our training approach on larger and more crowded testing environments than those used in training, allowing for more meaningful measurements of model performance.\n    ",
        "primary_category": "cs.RO",
        "categories": [
            "cs.LG",
            "cs.MA"
        ],
        "submitted_date": "29 Aug 2023",
        "last_revised_date": " "
    },
    "2308.15109": {
        "title": "DiffusionVMR: Diffusion Model for Joint Video Moment Retrieval and Highlight Detection",
        "authors": [
            "Henghao Zhao",
            "Kevin Qinghong Lin",
            "Rui Yan",
            "Zechao Li"
        ],
        "comments": " ",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Video moment retrieval and highlight detection have received attention in the current era of video content proliferation, aiming to localize moments and estimate clip relevances based on user-specific queries. Given that the video content is continuous in time, there is often a lack of clear boundaries between temporal events in a video. This boundary ambiguity makes it challenging for the model to learn text-video clip correspondences, resulting in the subpar performance of existing methods in predicting target segments. To alleviate this problem, we propose to solve the two tasks jointly from the perspective of denoising generation. Moreover, the target boundary can be localized clearly by iterative refinement from coarse to fine. Specifically, a novel framework, DiffusionVMR, is proposed to redefine the two tasks as a unified conditional denoising generation process by combining the diffusion model. During training, Gaussian noise is added to corrupt the ground truth, with noisy candidates produced as input. The model is trained to reverse this noise addition process. In the inference phase, DiffusionVMR initiates directly from Gaussian noise and progressively refines the proposals from the noise to the meaningful output. Notably, the proposed DiffusionVMR inherits the advantages of diffusion models that allow for iteratively refined results during inference, enhancing the boundary transition from coarse to fine. Furthermore, the training and inference of DiffusionVMR are decoupled. An arbitrary setting can be used in DiffusionVMR during inference without consistency with the training phase. Extensive experiments conducted on five widely-used benchmarks (i.e., QVHighlight, Charades-STA, TACoS, YouTubeHighlights and TVSum) across two tasks (moment retrieval and/or highlight detection) demonstrate the effectiveness and flexibility of the proposed DiffusionVMR.\n    ",
        "primary_category": "cs.CV",
        "categories": [],
        "submitted_date": "29 Aug 2023",
        "last_revised_date": " "
    },
    "2308.16089": {
        "title": "Application of Zone Method based Physics-Informed Neural Networks in Reheating Furnaces",
        "authors": [
            "Ujjal Kr Dutta",
            "Aldo Lipani",
            "Chuan Wang",
            "Yukun Hu"
        ],
        "comments": "Accepted in: NeurIPS 2023 - Machine Learning and the Physical Sciences Workshop",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Foundation Industries (FIs) constitute glass, metals, cement, ceramics, bulk chemicals, paper, steel, etc. and provide crucial, foundational materials for a diverse set of economically relevant industries: automobiles, machinery, construction, household appliances, chemicals, etc. Reheating furnaces within the manufacturing chain of FIs are energy-intensive. Accurate and real-time prediction of underlying temperatures in reheating furnaces has the potential to reduce the overall heating time, thereby controlling the energy consumption for achieving the Net-Zero goals in FIs. In this paper, we cast this prediction as a regression task and explore neural networks due to their inherent capability of being effective and efficient, given adequate data. However, due to the infeasibility of achieving good-quality real data in scenarios like reheating furnaces, classical Hottel's zone method based computational model has been used to generate data for model training. To further enhance the Out-Of-Distribution generalization capability of the trained model, we propose a Physics-Informed Neural Network (PINN) by incorporating prior physical knowledge using a set of novel Energy-Balance regularizers.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.AI",
            "cs.NE",
            "eess.SY"
        ],
        "submitted_date": "30 Aug 2023",
        "last_revised_date": " "
    },
    "2309.00064": {
        "title": "Ethical Framework for Harnessing the Power of AI in Healthcare and Beyond",
        "authors": [
            "Sidra Nasir",
            "Rizwan Ahmed Khan",
            "Samita Bai"
        ],
        "comments": " ",
        "subjects": "Computers and Society (cs.CY)",
        "abstract": "In the past decade, the deployment of deep learning (Artificial Intelligence (AI)) methods has become pervasive across a spectrum of real-world applications, often in safety-critical contexts. This comprehensive research article rigorously investigates the ethical dimensions intricately linked to the rapid evolution of AI technologies, with a particular focus on the healthcare domain. Delving deeply, it explores a multitude of facets including transparency, adept data management, human oversight, educational imperatives, and international collaboration within the realm of AI advancement. Central to this article is the proposition of a conscientious AI framework, meticulously crafted to accentuate values of transparency, equity, answerability, and a human-centric orientation. The second contribution of the article is the in-depth and thorough discussion of the limitations inherent to AI systems. It astutely identifies potential biases and the intricate challenges of navigating multifaceted contexts. Lastly, the article unequivocally accentuates the pressing need for globally standardized AI ethics principles and frameworks. Simultaneously, it aptly illustrates the adaptability of the ethical framework proposed herein, positioned skillfully to surmount emergent challenges.\n    ",
        "primary_category": "cs.CY",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "31 Aug 2023",
        "last_revised_date": " "
    },
    "2309.00125": {
        "title": "Pure Differential Privacy for Functional Summaries via a Laplace-like Process",
        "authors": [
            "Haotian Lin",
            "Matthew Reimherr"
        ],
        "comments": " ",
        "subjects": "Machine Learning (stat.ML)",
        "abstract": "Many existing mechanisms to achieve differential privacy (DP) on infinite-dimensional functional summaries often involve embedding these summaries into finite-dimensional subspaces and applying traditional DP techniques. Such mechanisms generally treat each dimension uniformly and struggle with complex, structured summaries. This work introduces a novel mechanism for DP functional summary release: the Independent Component Laplace Process (ICLP) mechanism. This mechanism treats the summaries of interest as truly infinite-dimensional objects, thereby addressing several limitations of existing mechanisms. We establish the feasibility of the proposed mechanism in multiple function spaces. Several statistical estimation problems are considered, and we demonstrate one can enhance the utility of sanitized summaries by oversmoothing their non-private counterpart. Numerical experiments on synthetic and real datasets demonstrate the efficacy of the proposed mechanism.\n    ",
        "primary_category": "stat.ML",
        "categories": [
            "cs.CR",
            "cs.LG"
        ],
        "submitted_date": "31 Aug 2023",
        "last_revised_date": " "
    },
    "2309.00255": {
        "title": "SortedNet, a Place for Every Network and Every Network in its Place: Towards a Generalized Solution for Training Many-in-One Neural Networks",
        "authors": [
            "Mojtaba Valipour",
            "Mehdi Rezagholizadeh",
            "Hossein Rajabzadeh",
            "Parsa Kavehzadeh",
            "Marzieh Tahaei",
            "Boxing Chen",
            "Ali Ghodsi"
        ],
        "comments": " ",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Deep neural networks (DNNs) must cater to a variety of users with different performance needs and budgets, leading to the costly practice of training, storing, and maintaining numerous specific models. There are solutions in the literature to deal with single dynamic or many-in-one models instead of many individual networks; however, they usually suffer from heavy model search requirements, being architecture-specific, working only on a limited number of dimensions (e.g. depth only or width only) or sub-models. To address these problems, we propose SortedNet, a generalized and scalable training solution to harness the inherent modularity of DNNs. Thanks to a generalized nested architecture (which we refer to as \\textit{sorted} architecture in this paper) with shared parameters and its novel update scheme combining random sub-model sampling and gradient accumulation, SortedNet enables the training of numerous sub-models simultaneously, simplifies dynamic model selection and deployment during inference, and reduces the model storage requirement significantly. The versatility and scalability of SortedNet are validated through various architectures and tasks including LLaMA, BERT, RoBERTa (NLP tasks), ResNet and MobileNet (image classification) demonstrating its superiority over existing dynamic training methods. SortedNet is able to train up to 160 sub-models at once, achieving at least 96\\% of the original model's performance.\n    ",
        "primary_category": "cs.LG",
        "categories": [],
        "submitted_date": "1 Sep 2023",
        "last_revised_date": " "
    },
    "2309.00344": {
        "title": "A Complete Dependency Pair Framework for Almost-Sure Innermost Termination of Probabilistic Term Rewriting",
        "authors": [
            "Jan-Christoph Kassing",
            "Stefan Dollase",
            "J\u00fcrgen Giesl"
        ],
        "comments": "arXiv admin note: text overlap with arXiv:2305.11741",
        "subjects": "Logic in Computer Science (cs.LO)",
        "abstract": "Recently, the well-known dependency pair (DP) framework was adapted to a dependency tuple framework in order to prove almost-sure innermost termination (iAST) of probabilistic term rewrite systems. While this approach was incomplete, in this paper, we improve it into a complete criterion for iAST by presenting a new, more elegant definition of DPs for probabilistic term rewriting. Based on this, we extend the probabilistic DP framework by new transformations. Our implementation in the tool AProVE shows that they increase its power considerably.\n    ",
        "primary_category": "cs.LO",
        "categories": [],
        "submitted_date": "1 Sep 2023",
        "last_revised_date": " "
    },
    "2309.00517": {
        "title": "Iterative, Small-Signal L2 Stability Analysis of Nonlinear Constrained Systems",
        "authors": [
            "Reza Lavaei",
            "Leila J. Bridgeman"
        ],
        "comments": " ",
        "subjects": "Systems and Control (eess.SY)",
        "abstract": "This paper provides a method to analyze the small-signal L2 gain of control-affine nonlinear systems on compact sets via iterative semi-definite programs. First, a continuous piecewise affine storage function and the corresponding upper bound on the L2 gain are found on a bounded, compact set's triangulation. Then, to ensure that the state does not escape this set, a barrier function is found that is robust to small-signal inputs. Small-signal L2 stability then holds inside each sublevel set of the barrier function inside the set where the storage function was found. The bound on the inputs is also found while searching for a barrier function. The method's effectiveness is shown in a numerical example.\n    ",
        "primary_category": "eess.SY",
        "categories": [],
        "submitted_date": "1 Sep 2023",
        "last_revised_date": " "
    },
    "2309.01213": {
        "title": "Implicit regularization of deep residual networks towards neural ODEs",
        "authors": [
            "Pierre Marion",
            "Yu-Han Wu",
            "Michael E. Sander",
            "G\u00e9rard Biau"
        ],
        "comments": "ICLR 2024 (spotlight). 40 pages, 3 figures",
        "subjects": "Machine Learning (stat.ML)",
        "abstract": "Residual neural networks are state-of-the-art deep learning models. Their continuous-depth analog, neural ordinary differential equations (ODEs), are also widely used. Despite their success, the link between the discrete and continuous models still lacks a solid mathematical foundation. In this article, we take a step in this direction by establishing an implicit regularization of deep residual networks towards neural ODEs, for nonlinear networks trained with gradient flow. We prove that if the network is initialized as a discretization of a neural ODE, then such a discretization holds throughout training. Our results are valid for a finite training time, and also as the training time tends to infinity provided that the network satisfies a Polyak-Lojasiewicz condition. Importantly, this condition holds for a family of residual networks where the residuals are two-layer perceptrons with an overparameterization in width that is only linear, and implies the convergence of gradient flow to a global minimum. Numerical experiments illustrate our results.\n    ",
        "primary_category": "stat.ML",
        "categories": [
            "cs.LG"
        ],
        "submitted_date": "3 Sep 2023",
        "last_revised_date": " "
    },
    "2309.01829": {
        "title": "A Post-Training Approach for Mitigating Overfitting in Quantum Convolutional Neural Networks",
        "authors": [
            "Aakash Ravindra Shinde",
            "Charu Jain",
            "Amir Kalev"
        ],
        "comments": "9 pages, 14 images, 6 tables",
        "subjects": "Quantum Physics (quant-ph)",
        "abstract": "Quantum convolutional neural network (QCNN), an early application for quantum computers in the NISQ era, has been consistently proven successful as a machine learning (ML) algorithm for several tasks with significant accuracy. Derived from its classical counterpart, QCNN is prone to overfitting. Overfitting is a typical shortcoming of ML models that are trained too closely to the availed training dataset and perform relatively poorly on unseen datasets for a similar problem. In this work we study post-training approaches for mitigating overfitting in QCNNs. We find that a straightforward adaptation of a classical post-training method, known as neuron dropout, to the quantum setting leads to a significant and undesirable consequence: a substantial decrease in success probability of the QCNN. We argue that this effect exposes the crucial role of entanglement in QCNNs and the vulnerability of QCNNs to entanglement loss. Hence, we propose a parameter adaptation method as an alternative method. Our method is computationally efficient and is found to successfully handle overfitting in the test cases.\n    ",
        "primary_category": "quant-ph",
        "categories": [
            "cs.LG"
        ],
        "submitted_date": "4 Sep 2023",
        "last_revised_date": " "
    },
    "2309.02561": {
        "title": "Physically Grounded Vision-Language Models for Robotic Manipulation",
        "authors": [
            "Jensen Gao",
            "Bidipta Sarkar",
            "Fei Xia",
            "Ted Xiao",
            "Jiajun Wu",
            "Brian Ichter",
            "Anirudha Majumdar",
            "Dorsa Sadigh"
        ],
        "comments": "Updated version for ICRA 2024",
        "subjects": "Robotics (cs.RO)",
        "abstract": "Recent advances in vision-language models (VLMs) have led to improved performance on tasks such as visual question answering and image captioning. Consequently, these models are now well-positioned to reason about the physical world, particularly within domains such as robotic manipulation. However, current VLMs are limited in their understanding of the physical concepts (e.g., material, fragility) of common objects, which restricts their usefulness for robotic manipulation tasks that involve interaction and physical reasoning about such objects. To address this limitation, we propose PhysObjects, an object-centric dataset of 39.6K crowd-sourced and 417K automated physical concept annotations of common household objects. We demonstrate that fine-tuning a VLM on PhysObjects improves its understanding of physical object concepts, including generalization to held-out concepts, by capturing human priors of these concepts from visual appearance. We incorporate this physically grounded VLM in an interactive framework with a large language model-based robotic planner, and show improved planning performance on tasks that require reasoning about physical object concepts, compared to baselines that do not leverage physically grounded VLMs. We additionally illustrate the benefits of our physically grounded VLM on a real robot, where it improves task success rates. We release our dataset and provide further details and visualizations of our results at this https URL.\n    ",
        "primary_category": "cs.RO",
        "categories": [
            "cs.AI",
            "cs.CV"
        ],
        "submitted_date": "5 Sep 2023",
        "last_revised_date": " "
    },
    "2309.03078": {
        "title": "Political Context of the European Vaccine Debate on Twitter",
        "authors": [
            "Giordano Paoletti",
            "Lorenzo Dall'Amico",
            "Kyriaki Kalimeri",
            "Jacopo Lenti",
            "Yelena Mejova",
            "Daniela Paolotti",
            "Michele Starnini",
            "Michele Tizzani"
        ],
        "comments": "Published version in Sci Rep",
        "subjects": "Social and Information Networks (cs.SI)",
        "abstract": "At the beginning of the COVID-19 pandemic, fears grew that making vaccination a political (instead of public health) issue may impact the efficacy of this life-saving intervention, spurring the spread of vaccine-hesitant content. In this study, we examine whether there is a relationship between the political interest of social media users and their exposure to vaccine-hesitant content on Twitter. We focus on 17 European countries using a multilingual, longitudinal dataset of tweets spanning the period before COVID, up to the vaccine roll-out. We find that, in most countries, users' endorsement of vaccine-hesitant content is the highest in the early months of the pandemic, around the time of greatest scientific uncertainty. Further, users who follow politicians from right-wing parties, and those associated with authoritarian or anti-EU stances are more likely to endorse vaccine-hesitant content, whereas those following left-wing politicians, more pro-EU or liberal parties, are less likely. Somewhat surprisingly, politicians did not play an outsized role in the vaccine debates of their countries, receiving a similar number of retweets as other similarly popular users. This systematic, multi-country, longitudinal investigation of the connection of politics with vaccine hesitancy has important implications for public health policy and communication.\n    ",
        "primary_category": "cs.SI",
        "categories": [
            "physics.soc-ph"
        ],
        "submitted_date": "6 Sep 2023",
        "last_revised_date": " "
    },
    "2309.03720": {
        "title": "A Natural Gas Consumption Forecasting System for Continual Learning Scenarios based on Hoeffding Trees with Change Point Detection Mechanism",
        "authors": [
            "Radek Svoboda",
            "Sebastian Basterrech",
            "J\u0119drzej Kozal",
            "Jan Plato\u0161",
            "Micha\u0142 Wo\u017aniak"
        ],
        "comments": " ",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Forecasting natural gas consumption, considering seasonality and trends, is crucial in planning its supply and consumption and optimizing the cost of obtaining it, mainly by industrial entities. However, in times of threats to its supply, it is also a critical element that guarantees the supply of this raw material to meet individual consumers' needs, ensuring society's energy security. This article introduces a novel multistep ahead forecasting of natural gas consumption with change point detection integration for model collection selection with continual learning capabilities using data stream processing. The performance of the forecasting models based on the proposed approach is evaluated in a complex real-world use case of natural gas consumption forecasting. We employed Hoeffding tree predictors as forecasting models and the Pruned Exact Linear Time (PELT) algorithm for the change point detection procedure. The change point detection integration enables selecting a different model collection for successive time frames. Thus, three model collection selection procedures (with and without an error feedback loop) are defined and evaluated for forecasting scenarios with various densities of detected change points. These models were compared with change point agnostic baseline approaches. Our experiments show that fewer change points result in a lower forecasting error regardless of the model collection selection procedure employed. Also, simpler model collection selection procedures omitting forecasting error feedback leads to more robust forecasting models suitable for continual learning tasks.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "7 Sep 2023",
        "last_revised_date": " "
    },
    "2309.03750": {
        "title": "PBP: Path-based Trajectory Prediction for Autonomous Driving",
        "authors": [
            "Sepideh Afshar",
            "Nachiket Deo",
            "Akshay Bhagat",
            "Titas Chakraborty",
            "Yunming Shao",
            "Balarama Raju Buddharaju",
            "Adwait Deshpande",
            "Henggang Cui"
        ],
        "comments": "Published at ICRA 2024; Sepideh Afshar and Nachiket Deo contributed equally",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Trajectory prediction plays a crucial role in the autonomous driving stack by enabling autonomous vehicles to anticipate the motion of surrounding agents. Goal-based prediction models have gained traction in recent years for addressing the multimodal nature of future trajectories. Goal-based prediction models simplify multimodal prediction by first predicting 2D goal locations of agents and then predicting trajectories conditioned on each goal. However, a single 2D goal location serves as a weak inductive bias for predicting the whole trajectory, often leading to poor map compliance, i.e., part of the trajectory going off-road or breaking traffic rules. In this paper, we improve upon goal-based prediction by proposing the Path-based prediction (PBP) approach. PBP predicts a discrete probability distribution over reference paths in the HD map using the path features and predicts trajectories in the path-relative Frenet frame. We applied the PBP trajectory decoder on top of the HiVT scene encoder and report results on the Argoverse dataset. Our experiments show that PBP achieves competitive performance on the standard trajectory prediction metrics, while significantly outperforming state-of-the-art baselines in terms of map compliance.\n    ",
        "primary_category": "cs.CV",
        "categories": [],
        "submitted_date": "7 Sep 2023",
        "last_revised_date": " "
    },
    "2309.03891": {
        "title": "ArtiGrasp: Physically Plausible Synthesis of Bi-Manual Dexterous Grasping and Articulation",
        "authors": [
            "Hui Zhang",
            "Sammy Christen",
            "Zicong Fan",
            "Luocheng Zheng",
            "Jemin Hwangbo",
            "Jie Song",
            "Otmar Hilliges"
        ],
        "comments": "3DV-2024 camera ready. Project page: this https URL",
        "subjects": "Robotics (cs.RO)",
        "abstract": "We present ArtiGrasp, a novel method to synthesize bi-manual hand-object interactions that include grasping and articulation. This task is challenging due to the diversity of the global wrist motions and the precise finger control that are necessary to articulate objects. ArtiGrasp leverages reinforcement learning and physics simulations to train a policy that controls the global and local hand pose. Our framework unifies grasping and articulation within a single policy guided by a single hand pose reference. Moreover, to facilitate the training of the precise finger control required for articulation, we present a learning curriculum with increasing difficulty. It starts with single-hand manipulation of stationary objects and continues with multi-agent training including both hands and non-stationary objects. To evaluate our method, we introduce Dynamic Object Grasping and Articulation, a task that involves bringing an object into a target articulated pose. This task requires grasping, relocation, and articulation. We show our method's efficacy towards this task. We further demonstrate that our method can generate motions with noisy hand-object pose estimates from an off-the-shelf image-based regressor.\n    ",
        "primary_category": "cs.RO",
        "categories": [
            "cs.CV",
            "cs.LG"
        ],
        "submitted_date": "7 Sep 2023",
        "last_revised_date": " "
    },
    "2309.04550": {
        "title": "Retrieving Evidence from EHRs with LLMs: Possibilities and Challenges",
        "authors": [
            "Hiba Ahsan",
            "Denis Jered McInerney",
            "Jisoo Kim",
            "Christopher Potter",
            "Geoffrey Young",
            "Silvio Amir",
            "Byron C. Wallace"
        ],
        "comments": " ",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "Unstructured data in Electronic Health Records (EHRs) often contains critical information -- complementary to imaging -- that could inform radiologists' diagnoses. But the large volume of notes often associated with patients together with time constraints renders manually identifying relevant evidence practically infeasible. In this work we propose and evaluate a zero-shot strategy for using LLMs as a mechanism to efficiently retrieve and summarize unstructured evidence in patient EHR relevant to a given query. Our method entails tasking an LLM to infer whether a patient has, or is at risk of, a particular condition on the basis of associated notes; if so, we ask the model to summarize the supporting evidence. Under expert evaluation, we find that this LLM-based approach provides outputs consistently preferred to a pre-LLM information retrieval baseline. Manual evaluation is expensive, so we also propose and validate a method using an LLM to evaluate (other) LLM outputs for this task, allowing us to scale up evaluation. Our findings indicate the promise of LLMs as interfaces to EHR, but also highlight the outstanding challenge posed by \"hallucinations\". In this setting, however, we show that model confidence in outputs strongly correlates with faithful summaries, offering a practical means to limit confabulations.\n    ",
        "primary_category": "cs.CL",
        "categories": [],
        "submitted_date": "8 Sep 2023",
        "last_revised_date": " "
    },
    "2309.04739": {
        "title": "Data Augmentation for Conversational AI",
        "authors": [
            "Heydar Soudani",
            "Evangelos Kanoulas",
            "Faegheh Hasibi"
        ],
        "comments": " ",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "Advancements in conversational systems have revolutionized information access, surpassing the limitations of single queries. However, developing dialogue systems requires a large amount of training data, which is a challenge in low-resource domains and languages. Traditional data collection methods like crowd-sourcing are labor-intensive and time-consuming, making them ineffective in this context. Data augmentation (DA) is an affective approach to alleviate the data scarcity problem in conversational systems. This tutorial provides a comprehensive and up-to-date overview of DA approaches in the context of conversational systems. It highlights recent advances in conversation augmentation, open domain and task-oriented conversation generation, and different paradigms of evaluating these models. We also discuss current challenges and future directions in order to help researchers and practitioners to further advance the field in this area.\n    ",
        "primary_category": "cs.CL",
        "categories": [
            "cs.IR"
        ],
        "submitted_date": "9 Sep 2023",
        "last_revised_date": " "
    },
    "2309.04823": {
        "title": "FaNS: a Facet-based Narrative Similarity Metric",
        "authors": [
            "Mousumi Akter",
            "Shubhra Kanti Karmaker Santu"
        ],
        "comments": " ",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "Similar Narrative Retrieval is a crucial task since narratives are essential for explaining and understanding events, and multiple related narratives often help to create a holistic view of the event of interest. To accurately identify semantically similar narratives, this paper proposes a novel narrative similarity metric called Facet-based Narrative Similarity (FaNS), based on the classic 5W1H facets (Who, What, When, Where, Why, and How), which are extracted by leveraging the state-of-the-art Large Language Models (LLMs). Unlike existing similarity metrics that only focus on overall lexical/semantic match, FaNS provides a more granular matching along six different facets independently and then combines them. To evaluate FaNS, we created a comprehensive dataset by collecting narratives from AllSides, a third-party news portal. Experimental results demonstrate that the FaNS metric exhibits a higher correlation (37\\% higher) than traditional text similarity metrics that directly measure the lexical/semantic match between narratives, demonstrating its effectiveness in comparing the finer details between a pair of narratives.\n    ",
        "primary_category": "cs.CL",
        "categories": [],
        "submitted_date": "9 Sep 2023",
        "last_revised_date": " "
    },
    "2309.05019": {
        "title": "SA-Solver: Stochastic Adams Solver for Fast Sampling of Diffusion Models",
        "authors": [
            "Shuchen Xue",
            "Mingyang Yi",
            "Weijian Luo",
            "Shifeng Zhang",
            "Jiacheng Sun",
            "Zhenguo Li",
            "Zhi-Ming Ma"
        ],
        "comments": "Accepted in Neurips 2023",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Diffusion Probabilistic Models (DPMs) have achieved considerable success in generation tasks. As sampling from DPMs is equivalent to solving diffusion SDE or ODE which is time-consuming, numerous fast sampling methods built upon improved differential equation solvers are proposed. The majority of such techniques consider solving the diffusion ODE due to its superior efficiency. However, stochastic sampling could offer additional advantages in generating diverse and high-quality data. In this work, we engage in a comprehensive analysis of stochastic sampling from two aspects: variance-controlled diffusion SDE and linear multi-step SDE solver. Based on our analysis, we propose SA-Solver, which is an improved efficient stochastic Adams method for solving diffusion SDE to generate data with high quality. Our experiments show that SA-Solver achieves: 1) improved or comparable performance compared with the existing state-of-the-art sampling methods for few-step sampling; 2) SOTA FID scores on substantial benchmark datasets under a suitable number of function evaluations (NFEs).\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "stat.ML"
        ],
        "submitted_date": "10 Sep 2023",
        "last_revised_date": " "
    },
    "2309.05134": {
        "title": "Benchmarking ground truth trajectories with robotic total stations",
        "authors": [
            "Effie Daum",
            "Maxime Vaidis",
            "Fran\u00e7ois Pomerleau"
        ],
        "comments": "Accepted and presented at IROS23, Workshop on Methods for Objective Comparison of Results in Intelligent Robotics Research",
        "subjects": "Robotics (cs.RO)",
        "abstract": "Benchmarks stand as vital cornerstones in elevating SLAM algorithms within mobile robotics. Consequently, ensuring accurate and reproducible ground truth generation is vital for fair evaluation. A majority of outdoor ground truths are generated by GNSS, which can lead to discrepancies over time, especially in covered areas. However, research showed that RTS setups are more precise and can alternatively be used to generate these ground truths. In our work, we compare both RTS and GNSS systems' precision and repeatability through a set of experiments conducted weeks and months apart in the same area. We demonstrated that RTS setups give more reproducible results, with disparities having a median value of 8.6 mm compared to a median value of 10.6 cm coming from a GNSS setup. These results highlight that RTS can be considered to benchmark process for SLAM algorithms with higher precision.\n    ",
        "primary_category": "cs.RO",
        "categories": [],
        "submitted_date": "10 Sep 2023",
        "last_revised_date": " "
    },
    "2309.05605": {
        "title": "Memory Injections: Correcting Multi-Hop Reasoning Failures during Inference in Transformer-Based Language Models",
        "authors": [
            "Mansi Sakarvadia",
            "Aswathy Ajith",
            "Arham Khan",
            "Daniel Grzenda",
            "Nathaniel Hudson",
            "Andr\u00e9 Bauer",
            "Kyle Chard",
            "Ian Foster"
        ],
        "comments": "Oral Presentation at BlackboxNLP Workshop at EMNLP 2023",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "Answering multi-hop reasoning questions requires retrieving and synthesizing information from diverse sources. Large Language Models (LLMs) struggle to perform such reasoning consistently. Here we propose an approach to pinpoint and rectify multi-hop reasoning failures through targeted memory injections on LLM attention heads. First, we analyze the per-layer activations of GPT-2 models in response to single and multi-hop prompts. We then propose a mechanism that allows users to inject pertinent prompt-specific information, which we refer to as \"memories,\" at critical LLM locations during inference. By thus enabling the LLM to incorporate additional relevant information during inference, we enhance the quality of multi-hop prompt completions. We show empirically that a simple, efficient, and targeted memory injection into a key attention layer can often increase the probability of the desired next token in multi-hop tasks, by up to 424%.\n    ",
        "primary_category": "cs.CL",
        "categories": [
            "cs.AI",
            "cs.LG"
        ],
        "submitted_date": "11 Sep 2023",
        "last_revised_date": " "
    },
    "2309.05979": {
        "title": "Measure preservation and integrals for Lotka--Volterra tree-systems and their Kahan discretisation",
        "authors": [
            "Peter H. van der Kamp",
            "Robert I. McLachlan",
            "David I. McLaren",
            "G. R. W. Quispel"
        ],
        "comments": "17 pages, 3 figures",
        "subjects": "Dynamical Systems (math.DS)",
        "abstract": "We show that any Lotka--Volterra tree-system associated with an $n$-vertex tree, as introduced in Quispel et al., J. Phys. A 56 (2023) 315201, preserves a rational measure. We also prove that the Kahan discretisation of these tree-systems factorises and preserves the same measure. As a consequence, for the Kahan maps of Lotka--Volterra systems related to the subclass of tree-systems corresponding to graphs with more than one $n$-vertex subtree, we are able to construct rational integrals.\n    ",
        "primary_category": "math.DS",
        "categories": [
            "math.NA"
        ],
        "submitted_date": "12 Sep 2023",
        "last_revised_date": " "
    },
    "2309.06275": {
        "title": "Re-Reading Improves Reasoning in Large Language Models",
        "authors": [
            "Xiaohan Xu",
            "Chongyang Tao",
            "Tao Shen",
            "Can Xu",
            "Hongbo Xu",
            "Guodong Long",
            "Jian-guang Lou"
        ],
        "comments": "25 pages",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "To enhance the reasoning capabilities of off-the-shelf Large Language Models (LLMs), we introduce a simple, yet general and effective prompting method, Re2, i.e., \\textbf{Re}-\\textbf{Re}ading the question as input. Unlike most thought-eliciting prompting methods, such as Chain-of-Thought (CoT), which aim to elicit the reasoning process in the output, Re2 shifts the focus to the input by processing questions twice, thereby enhancing the understanding process. Consequently, Re2 demonstrates strong generality and compatibility with most thought-eliciting prompting methods, including CoT. Crucially, Re2 facilitates a \"bidirectional\" encoding in unidirectional decoder-only LLMs because the first pass could provide global information for the second pass. We begin with a preliminary empirical study as the foundation of Re2, illustrating its potential to enable \"bidirectional\" attention mechanisms. We then evaluate Re2 on extensive reasoning benchmarks across 14 datasets, spanning 112 experiments, to validate its effectiveness and generality. Our findings indicate that, with the exception of a few scenarios on vanilla ChatGPT, Re2 consistently enhances the reasoning performance of LLMs through a simple re-reading strategy. Further analyses reveal Re2's adaptability, showing how it can be effectively integrated with different LLMs, thought-eliciting prompting, and ensemble strategies. Our code is available at \\url{this https URL}\n    ",
        "primary_category": "cs.CL",
        "categories": [],
        "submitted_date": "12 Sep 2023",
        "last_revised_date": " "
    },
    "2309.06427": {
        "title": "Symmetric Stair Preconditioning of Linear Systems for Parallel Trajectory Optimization",
        "authors": [
            "Xueyi Bu",
            "Brian Plancher"
        ],
        "comments": "Accepted to ICRA 2024, 8 pages, 3 figures",
        "subjects": "Optimization and Control (math.OC)",
        "abstract": "There has been a growing interest in parallel strategies for solving trajectory optimization problems. One key step in many algorithmic approaches to trajectory optimization is the solution of moderately-large and sparse linear systems. Iterative methods are particularly well-suited for parallel solves of such systems. However, fast and stable convergence of iterative methods is reliant on the application of a high-quality preconditioner that reduces the spread and increase the clustering of the eigenvalues of the target matrix. To improve the performance of these approaches, we present a new parallel-friendly symmetric stair preconditioner. We prove that our preconditioner has advantageous theoretical properties when used in conjunction with iterative methods for trajectory optimization such as a more clustered eigenvalue spectrum. Numerical experiments with typical trajectory optimization problems reveal that as compared to the best alternative parallel preconditioner from the literature, our symmetric stair preconditioner provides up to a 34% reduction in condition number and up to a 25% reduction in the number of resulting linear system solver iterations.\n    ",
        "primary_category": "math.OC",
        "categories": [
            "cs.RO"
        ],
        "submitted_date": "12 Sep 2023",
        "last_revised_date": " "
    },
    "2309.06634": {
        "title": "$G$-Mapper: Learning a Cover in the Mapper Construction",
        "authors": [
            "Enrique Alvarado",
            "Robin Belton",
            "Emily Fischer",
            "Kang-Ju Lee",
            "Sourabh Palande",
            "Sarah Percival",
            "Emilie Purvine"
        ],
        "comments": " ",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "The Mapper algorithm is a visualization technique in topological data analysis (TDA) that outputs a graph reflecting the structure of a given dataset. However, the Mapper algorithm requires tuning several parameters in order to generate a ``nice\" Mapper graph. This paper focuses on selecting the cover parameter. We present an algorithm that optimizes the cover of a Mapper graph by splitting a cover repeatedly according to a statistical test for normality. Our algorithm is based on $G$-means clustering which searches for the optimal number of clusters in $k$-means by iteratively applying the Anderson-Darling test. Our splitting procedure employs a Gaussian mixture model to carefully choose the cover according to the distribution of the given data. Experiments for synthetic and real-world datasets demonstrate that our algorithm generates covers so that the Mapper graphs retain the essence of the datasets, while also running significantly fast.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "math.AT",
            "stat.ML"
        ],
        "submitted_date": "12 Sep 2023",
        "last_revised_date": " "
    },
    "2309.06635": {
        "title": "Collaborative Dynamic 3D Scene Graphs for Automated Driving",
        "authors": [
            "Elias Greve",
            "Martin B\u00fcchner",
            "Niclas V\u00f6disch",
            "Wolfram Burgard",
            "Abhinav Valada"
        ],
        "comments": "Accepted for \"IEEE International Conference on Robotics and Automation (ICRA) 2024\"",
        "subjects": "Robotics (cs.RO)",
        "abstract": "Maps have played an indispensable role in enabling safe and automated driving. Although there have been many advances on different fronts ranging from SLAM to semantics, building an actionable hierarchical semantic representation of urban dynamic scenes and processing information from multiple agents are still challenging problems. In this work, we present Collaborative URBan Scene Graphs (CURB-SG) that enable higher-order reasoning and efficient querying for many functions of automated driving. CURB-SG leverages panoptic LiDAR data from multiple agents to build large-scale maps using an effective graph-based collaborative SLAM approach that detects inter-agent loop closures. To semantically decompose the obtained 3D map, we build a lane graph from the paths of ego agents and their panoptic observations of other vehicles. Based on the connectivity of the lane graph, we segregate the environment into intersecting and non-intersecting road areas. Subsequently, we construct a multi-layered scene graph that includes lane information, the position of static landmarks and their assignment to certain map sections, other vehicles observed by the ego agents, and the pose graph from SLAM including 3D panoptic point clouds. We extensively evaluate CURB-SG in urban scenarios using a photorealistic simulator. We release our code at this http URL.\n    ",
        "primary_category": "cs.RO",
        "categories": [],
        "submitted_date": "12 Sep 2023",
        "last_revised_date": " "
    },
    "2309.06747": {
        "title": "Integrating GAN and Texture Synthesis for Enhanced Road Damage Detection",
        "authors": [
            "Tengyang Chen",
            "Jiangtao Ren"
        ],
        "comments": "10 pages, 13 figures, 2 Tables",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "In the domain of traffic safety and road maintenance, precise detection of road damage is crucial for ensuring safe driving and prolonging road durability. However, current methods often fall short due to limited data. Prior attempts have used Generative Adversarial Networks to generate damage with diverse shapes and manually integrate it into appropriate positions. However, the problem has not been well explored and is faced with two challenges. First, they only enrich the location and shape of damage while neglect the diversity of severity levels, and the realism still needs further improvement. Second, they require a significant amount of manual effort. To address these challenges, we propose an innovative approach. In addition to using GAN to generate damage with various shapes, we further employ texture synthesis techniques to extract road textures. These two elements are then mixed with different weights, allowing us to control the severity of the synthesized damage, which are then embedded back into the original images via Poisson blending. Our method ensures both richness of damage severity and a better alignment with the background. To save labor costs, we leverage structural similarity for automated sample selection during embedding. Each augmented data of an original image contains versions with varying severity levels. We implement a straightforward screening strategy to mitigate distribution drift. Experiments are conducted on a public road damage dataset. The proposed method not only eliminates the need for manual labor but also achieves remarkable enhancements, improving the mAP by 4.1% and the F1-score by 4.5%.\n    ",
        "primary_category": "cs.CV",
        "categories": [],
        "submitted_date": "13 Sep 2023",
        "last_revised_date": " "
    },
    "2309.07514": {
        "title": "$k$-Contraction in a Generalized Lurie System",
        "authors": [
            "Ron Ofir",
            "Jean-Jacques Slotine",
            "Michael Margaliot"
        ],
        "comments": " ",
        "subjects": "Systems and Control (eess.SY)",
        "abstract": "We derive a sufficient condition for $k$-contraction in a generalized Lurie system (GLS), that is, the feedback connection of a nonlinear dynamical system and a memoryless nonlinear function. For $k=1$, this reduces to a sufficient condition for standard contraction. For $k=2$, this condition implies that every bounded solution of the GLS converges to an equilibrium, which is not necessarily unique. We demonstrate the theoretical results by analyzing $k$-contraction in a biochemical control circuit with nonlinear dissipation terms.\n    ",
        "primary_category": "eess.SY",
        "categories": [],
        "submitted_date": "14 Sep 2023",
        "last_revised_date": " "
    },
    "2309.07932": {
        "title": "Flat origami is Turing Complete",
        "authors": [
            "Thomas C. Hull",
            "Inna Zakharevich"
        ],
        "comments": " ",
        "subjects": "Combinatorics (math.CO)",
        "abstract": "Flat origami refers to the folding of flat, zero-curvature paper such that the finished object lies in a plane. Mathematically, flat origami consists of a continuous, piecewise isometric map $f:P\\subseteq\\mathbb{R}^2\\to\\mathbb{R}^2$ along with a layer ordering $\\lambda_f:P\\times P\\to \\{-1,1\\}$ that tracks which points of $P$ are above/below others when folded. The set of crease lines that a flat origami makes (i.e., the set on which the mapping $f$ is non-differentiable) is called its \\textit{crease pattern}. Flat origami mappings and their layer orderings can possess surprisingly intricate structure. For instance, determining whether or not a given straight-line planar graph drawn on $P$ is the crease pattern for some flat origami has been shown to be an NP-complete problem, and this result from 1996 led to numerous explorations in computational aspects of flat origami. In this paper we prove that flat origami, when viewed as a computational device, is Turing complete. We do this by showing that flat origami crease patterns with \\textit{optional creases} (creases that might be folded or remain unfolded depending on constraints imposed by other creases or inputs) can be constructed to simulate Rule 110, a one-dimensional cellular automaton that was proven to be Turing complete by Matthew Cook in 2004.\n    ",
        "primary_category": "math.CO",
        "categories": [
            "cs.CC"
        ],
        "submitted_date": "13 Sep 2023",
        "last_revised_date": " "
    },
    "2309.08079": {
        "title": "MPCGPU: Real-Time Nonlinear Model Predictive Control through Preconditioned Conjugate Gradient on the GPU",
        "authors": [
            "Emre Adabag",
            "Miloni Atal",
            "William Gerard",
            "Brian Plancher"
        ],
        "comments": "Accepted to ICRA 2024, 8 pages, 6 figures",
        "subjects": "Robotics (cs.RO)",
        "abstract": "Nonlinear Model Predictive Control (NMPC) is a state-of-the-art approach for locomotion and manipulation which leverages trajectory optimization at each control step. While the performance of this approach is computationally bounded, implementations of direct trajectory optimization that use iterative methods to solve the underlying moderately-large and sparse linear systems, are a natural fit for parallel hardware acceleration. In this work, we introduce MPCGPU, a GPU-accelerated, real-time NMPC solver that leverages an accelerated preconditioned conjugate gradient (PCG) linear system solver at its core. We show that MPCGPU increases the scalability and real-time performance of NMPC, solving larger problems, at faster rates. In particular, for tracking tasks using the Kuka IIWA manipulator, MPCGPU is able to scale to kilohertz control rates with trajectories as long as 512 knot points. This is driven by a custom PCG solver which outperforms state-of-the-art, CPU-based, linear system solvers by at least 10x for a majority of solves and 3.6x on average.\n    ",
        "primary_category": "cs.RO",
        "categories": [
            "cs.DC"
        ],
        "submitted_date": "15 Sep 2023",
        "last_revised_date": " "
    },
    "2309.08095": {
        "title": "RELAX: Reinforcement Learning Enabled 2D-LiDAR Autonomous System for Parsimonious UAVs",
        "authors": [
            "Guanlin Wu",
            "Zhuokai Zhao",
            "Yutao He"
        ],
        "comments": " ",
        "subjects": "Robotics (cs.RO)",
        "abstract": "Unmanned Aerial Vehicles (UAVs) have become increasingly prominence in recent years, finding applications in surveillance, package delivery, among many others. Despite considerable efforts in developing algorithms that enable UAVs to navigate through complex unknown environments autonomously, they often require expensive hardware and sensors, such as RGB-D cameras and 3D-LiDAR, leading to a persistent trade-off between performance and cost. To this end, we propose RELAX, a novel end-to-end autonomous framework that is exceptionally cost-efficient, requiring only a single 2D-LiDAR to enable UAVs operating in unknown environments. Specifically, RELAX comprises three components: a pre-processing map constructor; an offline mission planner; and a reinforcement learning (RL)-based online re-planner. Experiments demonstrate that RELAX offers more robust dynamic navigation compared to existing algorithms, while only costing a fraction of the others. The code will be made public upon acceptance.\n    ",
        "primary_category": "cs.RO",
        "categories": [],
        "submitted_date": "15 Sep 2023",
        "last_revised_date": " "
    },
    "2309.08133": {
        "title": "Talkin' 'Bout AI Generation: Copyright and the Generative-AI Supply Chain",
        "authors": [
            "Katherine Lee",
            "A. Feder Cooper",
            "James Grimmelmann"
        ],
        "comments": "Forthcoming, Journal of the Copyright Society of the USA '24",
        "subjects": "Computers and Society (cs.CY)",
        "abstract": "\"Does generative AI infringe copyright?\" is an urgent question. It is also a difficult question, for two reasons. First, \"generative AI\" is not just one product from one company. It is a catch-all name for a massive ecosystem of loosely related technologies, including conversational text chatbots like ChatGPT, image generators like Midjourney and DALL-E, coding assistants like GitHub Copilot, and systems that compose music and create videos. These systems behave differently and raise different legal issues. The second problem is that copyright law is notoriously complicated, and generative-AI systems manage to touch on a great many corners of it: authorship, similarity, direct and indirect liability, fair use, and licensing, among much else. These issues cannot be analyzed in isolation, because there are connections everywhere.\nIn this Article, we aim to bring order to the chaos. To do so, we introduce the generative-AI supply chain: an interconnected set of stages that transform training data (millions of pictures of cats) into generations (a new, potentially never-seen-before picture of a cat that has never existed). Breaking down generative AI into these constituent stages reveals all of the places at which companies and users make choices that have copyright consequences. It enables us to trace the effects of upstream technical designs on downstream uses, and to assess who in these complicated sociotechnical systems bears responsibility for infringement when it happens. Because we engage so closely with the technology of generative AI, we are able to shed more light on the copyright questions. We do not give definitive answers as to who should and should not be held liable. Instead, we identify the key decisions that courts will need to make as they grapple with these issues, and point out the consequences that would likely flow from different liability regimes.\n    ",
        "primary_category": "cs.CY",
        "categories": [],
        "submitted_date": "15 Sep 2023",
        "last_revised_date": " "
    },
    "2309.08214": {
        "title": "MTG: Mapless Trajectory Generator with Traversability Coverage for Outdoor Navigation",
        "authors": [
            "Jing Liang",
            "Peng Gao",
            "Xuesu Xiao",
            "Adarsh Jagan Sathyamoorthy",
            "Mohamed Elnoor",
            "Ming C. Lin",
            "Dinesh Manocha"
        ],
        "comments": "9",
        "subjects": "Robotics (cs.RO)",
        "abstract": "We present a novel learning-based trajectory generation algorithm for outdoor robot navigation. Our goal is to compute collision-free paths that also satisfy the environment-specific traversability constraints. Our approach is designed for global planning using limited onboard robot perception in mapless environments while ensuring comprehensive coverage of all traversable directions. Our formulation uses a Conditional Variational Autoencoder (CVAE) generative model that is enhanced with traversability constraints and an optimization formulation used for the coverage. We highlight the benefits of our approach over state-of-the-art trajectory generation approaches and demonstrate its performance in challenging and large outdoor environments, including around buildings, across intersections, along trails, and off-road terrain, using a Clearpath Husky and a Boston Dynamics Spot robot. In practice, our approach results in a 6% improvement in coverage of traversable areas and an 89% reduction in trajectory portions residing in non-traversable regions. Our video is here: this https URL\n",
        "primary_category": "cs.RO",
        "categories": [],
        "submitted_date": "15 Sep 2023",
        "last_revised_date": " "
    },
    "2309.08315": {
        "title": "i-Octree: A Fast, Lightweight, and Dynamic Octree for Proximity Search",
        "authors": [
            "Jun Zhu",
            "Hongyi Li",
            "Zhepeng Wang",
            "Shengjie Wang",
            "Tao Zhang"
        ],
        "comments": "7 pages, 7 figures",
        "subjects": "Robotics (cs.RO)",
        "abstract": "Establishing the correspondences between newly acquired points and historically accumulated data (i.e., map) through nearest neighbors search is crucial in numerous robotic applications. However, static tree data structures are inadequate to handle large and dynamically growing maps in real-time. To address this issue, we present the i-Octree, a dynamic octree data structure that supports both fast nearest neighbor search and real-time dynamic updates, such as point insertion, deletion, and on-tree down-sampling. The i-Octree is built upon a leaf-based octree and has two key features: a local spatially continuous storing strategy that allows for fast access to points while minimizing memory usage, and local on-tree updates that significantly reduce computation time compared to existing static or dynamic tree structures. The experiments show that i-Octree outperforms contemporary state-of-the-art approaches by achieving, on average, a 19% reduction in runtime on realworld open datasets.\n    ",
        "primary_category": "cs.RO",
        "categories": [],
        "submitted_date": "15 Sep 2023",
        "last_revised_date": " "
    },
    "2309.08399": {
        "title": "Optimizing Modular Robot Composition: A Lexicographic Genetic Algorithm Approach",
        "authors": [
            "Jonathan K\u00fclz",
            "Matthias Althoff"
        ],
        "comments": "\\c{opyright} 2024 IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses, in any current or future media, including reprinting/republishing this material for advertising or promotional purposes, creating new collective works, for resale or redistribution to servers or lists, or reuse of any copyrighted component of this work in other works",
        "subjects": "Robotics (cs.RO)",
        "abstract": "Industrial robots are designed as general-purpose hardware with limited ability to adapt to changing task requirements or environments. Modular robots, on the other hand, offer flexibility and can be easily customized to suit diverse needs. The morphology, i.e., the form and structure of a robot, significantly impacts the primary performance metrics acquisition cost, cycle time, and energy efficiency. However, identifying an optimal module composition for a specific task remains an open problem, presenting a substantial hurdle in developing task-tailored modular robots. Previous approaches either lack adequate exploration of the design space or the possibility to adapt to complex tasks. We propose combining a genetic algorithm with a lexicographic evaluation of solution candidates to overcome this problem and navigate search spaces exceeding those in prior work by magnitudes in the number of possible compositions. We demonstrate that our approach outperforms a state-of-the-art baseline and is able to synthesize modular robots for industrial tasks in cluttered environments.\n    ",
        "primary_category": "cs.RO",
        "categories": [
            "cs.LG",
            "cs.NE"
        ],
        "submitted_date": "15 Sep 2023",
        "last_revised_date": " "
    },
    "2309.09256": {
        "title": "LiDAR Data Synthesis with Denoising Diffusion Probabilistic Models",
        "authors": [
            "Kazuto Nakashima",
            "Ryo Kurazume"
        ],
        "comments": "ICRA 2024",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Generative modeling of 3D LiDAR data is an emerging task with promising applications for autonomous mobile robots, such as scalable simulation, scene manipulation, and sparse-to-dense completion of LiDAR point clouds. While existing approaches have demonstrated the feasibility of image-based LiDAR data generation using deep generative models, they still struggle with fidelity and training stability. In this work, we present R2DM, a novel generative model for LiDAR data that can generate diverse and high-fidelity 3D scene point clouds based on the image representation of range and reflectance intensity. Our method is built upon denoising diffusion probabilistic models (DDPMs), which have shown impressive results among generative model frameworks in recent years. To effectively train DDPMs in the LiDAR domain, we first conduct an in-depth analysis of data representation, loss functions, and spatial inductive biases. Leveraging our R2DM model, we also introduce a flexible LiDAR completion pipeline based on the powerful capabilities of DDPMs. We demonstrate that our method surpasses existing methods in generating tasks on the KITTI-360 and KITTI-Raw datasets, as well as in the completion task on the KITTI-360 dataset. Our project page can be found at this https URL.\n    ",
        "primary_category": "cs.CV",
        "categories": [
            "cs.RO"
        ],
        "submitted_date": "17 Sep 2023",
        "last_revised_date": " "
    },
    "2309.09502": {
        "title": "RenderOcc: Vision-Centric 3D Occupancy Prediction with 2D Rendering Supervision",
        "authors": [
            "Mingjie Pan",
            "Jiaming Liu",
            "Renrui Zhang",
            "Peixiang Huang",
            "Xiaoqi Li",
            "Bing Wang",
            "Hongwei Xie",
            "Li Liu",
            "Shanghang Zhang"
        ],
        "comments": " ",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "3D occupancy prediction holds significant promise in the fields of robot perception and autonomous driving, which quantifies 3D scenes into grid cells with semantic labels. Recent works mainly utilize complete occupancy labels in 3D voxel space for supervision. However, the expensive annotation process and sometimes ambiguous labels have severely constrained the usability and scalability of 3D occupancy models. To address this, we present RenderOcc, a novel paradigm for training 3D occupancy models only using 2D labels. Specifically, we extract a NeRF-style 3D volume representation from multi-view images, and employ volume rendering techniques to establish 2D renderings, thus enabling direct 3D supervision from 2D semantics and depth labels. Additionally, we introduce an Auxiliary Ray method to tackle the issue of sparse viewpoints in autonomous driving scenarios, which leverages sequential frames to construct comprehensive 2D rendering for each object. To our best knowledge, RenderOcc is the first attempt to train multi-view 3D occupancy models only using 2D labels, reducing the dependence on costly 3D occupancy annotations. Extensive experiments demonstrate that RenderOcc achieves comparable performance to models fully supervised with 3D labels, underscoring the significance of this approach in real-world applications.\n    ",
        "primary_category": "cs.CV",
        "categories": [],
        "submitted_date": "18 Sep 2023",
        "last_revised_date": " "
    },
    "2309.09682": {
        "title": "Two-Stage Learning of Highly Dynamic Motions with Rigid and Articulated Soft Quadrupeds",
        "authors": [
            "Francecso Vezzi",
            "Jiatao Ding",
            "Antonin Raffin",
            "Jens Kober",
            "Cosimo Della Santina"
        ],
        "comments": "7 pages, 7 figures, Accepated by ICRA2024",
        "subjects": "Robotics (cs.RO)",
        "abstract": "Controlled execution of dynamic motions in quadrupedal robots, especially those with articulated soft bodies, presents a unique set of challenges that traditional methods struggle to address efficiently. In this study, we tackle these issues by relying on a simple yet effective two-stage learning framework to generate dynamic motions for quadrupedal robots. First, a gradient-free evolution strategy is employed to discover simply represented control policies, eliminating the need for a predefined reference motion. Then, we refine these policies using deep reinforcement learning. Our approach enables the acquisition of complex motions like pronking and back-flipping, effectively from scratch. Additionally, our method simplifies the traditionally labour-intensive task of reward shaping, boosting the efficiency of the learning process. Importantly, our framework proves particularly effective for articulated soft quadrupeds, whose inherent compliance and adaptability make them ideal for dynamic tasks but also introduce unique control challenges.\n    ",
        "primary_category": "cs.RO",
        "categories": [],
        "submitted_date": "18 Sep 2023",
        "last_revised_date": " "
    },
    "2309.09865": {
        "title": "Contrastive Learning for Enhancing Robust Scene Transfer in Vision-based Agile Flight",
        "authors": [
            "Jiaxu Xing",
            "Leonard Bauersfeld",
            "Yunlong Song",
            "Chunwei Xing",
            "Davide Scaramuzza"
        ],
        "comments": " ",
        "subjects": "Robotics (cs.RO)",
        "abstract": "Scene transfer for vision-based mobile robotics applications is a highly relevant and challenging problem. The utility of a robot greatly depends on its ability to perform a task in the real world, outside of a well-controlled lab environment. Existing scene transfer end-to-end policy learning approaches often suffer from poor sample efficiency or limited generalization capabilities, making them unsuitable for mobile robotics applications. This work proposes an adaptive multi-pair contrastive learning strategy for visual representation learning that enables zero-shot scene transfer and real-world deployment. Control policies relying on the embedding are able to operate in unseen environments without the need for finetuning in the deployment environment. We demonstrate the performance of our approach on the task of agile, vision-based quadrotor flight. Extensive simulation and real-world experiments demonstrate that our approach successfully generalizes beyond the training domain and outperforms all baselines.\n    ",
        "primary_category": "cs.RO",
        "categories": [
            "cs.CV"
        ],
        "submitted_date": "18 Sep 2023",
        "last_revised_date": " "
    },
    "2309.10108": {
        "title": "How Do Data Analysts Respond to AI Assistance? A Wizard-of-Oz Study",
        "authors": [
            "Ken Gu",
            "Madeleine Grunde-McLaughlin",
            "Andrew M. McNutt",
            "Jeffrey Heer",
            "Tim Althoff"
        ],
        "comments": "Accepted to CHI 2024",
        "subjects": "Human-Computer Interaction (cs.HC)",
        "abstract": "Data analysis is challenging as analysts must navigate nuanced decisions that may yield divergent conclusions. AI assistants have the potential to support analysts in planning their analyses, enabling more robust decision making. Though AI-based assistants that target code execution (e.g., Github Copilot) have received significant attention, limited research addresses assistance for both analysis execution and planning. In this work, we characterize helpful planning suggestions and their impacts on analysts' workflows. We first review the analysis planning literature and crowd-sourced analysis studies to categorize suggestion content. We then conduct a Wizard-of-Oz study (n=13) to observe analysts' preferences and reactions to planning assistance in a realistic scenario. Our findings highlight subtleties in contextual factors that impact suggestion helpfulness, emphasizing design implications for supporting different abstractions of assistance, forms of initiative, increased engagement, and alignment of goals between analysts and assistants.\n    ",
        "primary_category": "cs.HC",
        "categories": [],
        "submitted_date": "18 Sep 2023",
        "last_revised_date": " "
    },
    "2309.10216": {
        "title": "Safe POMDP Online Planning via Shielding",
        "authors": [
            "Shili Sheng",
            "David Parker",
            "Lu Feng"
        ],
        "comments": " ",
        "subjects": "Artificial Intelligence (cs.AI)",
        "abstract": "Partially observable Markov decision processes (POMDPs) have been widely used in many robotic applications for sequential decision-making under uncertainty. POMDP online planning algorithms such as Partially Observable Monte-Carlo Planning (POMCP) can solve very large POMDPs with the goal of maximizing the expected return. But the resulting policies cannot provide safety guarantees which are imperative for real-world safety-critical tasks (e.g., autonomous driving). In this work, we consider safety requirements represented as almost-sure reach-avoid specifications (i.e., the probability to reach a set of goal states is one and the probability to reach a set of unsafe states is zero). We compute shields that restrict unsafe actions which would violate the almost-sure reach-avoid specifications. We then integrate these shields into the POMCP algorithm for safe POMDP online planning. We propose four distinct shielding methods, differing in how the shields are computed and integrated, including factored variants designed to improve scalability. Experimental results on a set of benchmark domains demonstrate that the proposed shielding methods successfully guarantee safety (unlike the baseline POMCP without shielding) on large POMDPs, with negligible impact on the runtime for online planning.\n    ",
        "primary_category": "cs.AI",
        "categories": [],
        "submitted_date": "19 Sep 2023",
        "last_revised_date": " "
    },
    "2309.10225": {
        "title": "VPRTempo: A Fast Temporally Encoded Spiking Neural Network for Visual Place Recognition",
        "authors": [
            "Adam D. Hines",
            "Peter G. Stratton",
            "Michael Milford",
            "Tobias Fischer"
        ],
        "comments": "8 pages, 3 figures, accepted to the IEEE International Conference on Robotics and Automation (ICRA) 2024",
        "subjects": "Robotics (cs.RO)",
        "abstract": "Spiking Neural Networks (SNNs) are at the forefront of neuromorphic computing thanks to their potential energy-efficiency, low latencies, and capacity for continual learning. While these capabilities are well suited for robotics tasks, SNNs have seen limited adaptation in this field thus far. This work introduces a SNN for Visual Place Recognition (VPR) that is both trainable within minutes and queryable in milliseconds, making it well suited for deployment on compute-constrained robotic systems. Our proposed system, VPRTempo, overcomes slow training and inference times using an abstracted SNN that trades biological realism for efficiency. VPRTempo employs a temporal code that determines the timing of a single spike based on a pixel's intensity, as opposed to prior SNNs relying on rate coding that determined the number of spikes; improving spike efficiency by over 100%. VPRTempo is trained using Spike-Timing Dependent Plasticity and a supervised delta learning rule enforcing that each output spiking neuron responds to just a single place. We evaluate our system on the Nordland and Oxford RobotCar benchmark localization datasets, which include up to 27k places. We found that VPRTempo's accuracy is comparable to prior SNNs and the popular NetVLAD place recognition algorithm, while being several orders of magnitude faster and suitable for real-time deployment -- with inference speeds over 50 Hz on CPU. VPRTempo could be integrated as a loop closure component for online SLAM on resource-constrained systems such as space and underwater robots.\n    ",
        "primary_category": "cs.RO",
        "categories": [],
        "submitted_date": "19 Sep 2023",
        "last_revised_date": " "
    },
    "2309.10314": {
        "title": "Dive Deeper into Rectifying Homography for Stereo Camera Online Self-Calibration",
        "authors": [
            "Hongbo Zhao",
            "Yikang Zhang",
            "Qijun Chen",
            "Rui Fan"
        ],
        "comments": " ",
        "subjects": "Robotics (cs.RO)",
        "abstract": "Accurate estimation of stereo camera extrinsic parameters is the key to guarantee the performance of stereo matching algorithms. In prior arts, the online self-calibration of stereo cameras has commonly been formulated as a specialized visual odometry problem, without taking into account the principles of stereo rectification. In this paper, we first delve deeply into the concept of rectifying homography, which serves as the cornerstone for the development of our novel stereo camera online self-calibration algorithm, for cases where only a single pair of images is available. Furthermore, we introduce a simple yet effective solution for global optimum extrinsic parameter estimation in the presence of stereo video sequences. Additionally, we emphasize the impracticality of using three Euler angles and three components in the translation vectors for performance quantification. Instead, we introduce four new evaluation metrics to quantify the robustness and accuracy of extrinsic parameter estimation, applicable to both single-pair and multi-pair cases. Extensive experiments conducted across indoor and outdoor environments using various experimental setups validate the effectiveness of our proposed algorithm. The comprehensive evaluation results demonstrate its superior performance in comparison to the baseline algorithm. Our source code, demo video, and supplement are publicly available at mias.group/StereoCalibrator.\n    ",
        "primary_category": "cs.RO",
        "categories": [
            "cs.CV"
        ],
        "submitted_date": "19 Sep 2023",
        "last_revised_date": " "
    },
    "2309.10726": {
        "title": "Few-Shot Panoptic Segmentation With Foundation Models",
        "authors": [
            "Markus K\u00e4ppeler",
            "K\u00fcrsat Petek",
            "Niclas V\u00f6disch",
            "Wolfram Burgard",
            "Abhinav Valada"
        ],
        "comments": "Accepted for \"IEEE International Conference on Robotics and Automation (ICRA) 2024\"",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Current state-of-the-art methods for panoptic segmentation require an immense amount of annotated training data that is both arduous and expensive to obtain posing a significant challenge for their widespread adoption. Concurrently, recent breakthroughs in visual representation learning have sparked a paradigm shift leading to the advent of large foundation models that can be trained with completely unlabeled images. In this work, we propose to leverage such task-agnostic image features to enable few-shot panoptic segmentation by presenting Segmenting Panoptic Information with Nearly 0 labels (SPINO). In detail, our method combines a DINOv2 backbone with lightweight network heads for semantic segmentation and boundary estimation. We show that our approach, albeit being trained with only ten annotated images, predicts high-quality pseudo-labels that can be used with any existing panoptic segmentation method. Notably, we demonstrate that SPINO achieves competitive results compared to fully supervised baselines while using less than 0.3% of the ground truth labels, paving the way for learning complex visual recognition tasks leveraging foundation models. To illustrate its general applicability, we further deploy SPINO on real-world robotic vision systems for both outdoor and indoor environments. To foster future research, we make the code and trained models publicly available at this http URL.\n    ",
        "primary_category": "cs.CV",
        "categories": [
            "cs.RO"
        ],
        "submitted_date": "19 Sep 2023",
        "last_revised_date": " "
    },
    "2309.10834": {
        "title": "Communication-Efficient Federated Learning via Regularized Sparse Random Networks",
        "authors": [
            "Mohamad Mestoukirdi",
            "Omid Esrafilian",
            "David Gesbert",
            "Qianrui Li",
            "Nicolas Gresset"
        ],
        "comments": " ",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "This work presents a new method for enhancing communication efficiency in stochastic Federated Learning that trains over-parameterized random networks. In this setting, a binary mask is optimized instead of the model weights, which are kept fixed. The mask characterizes a sparse sub-network that is able to generalize as good as a smaller target network. Importantly, sparse binary masks are exchanged rather than the floating point weights in traditional federated learning, reducing communication cost to at most 1 bit per parameter (Bpp). We show that previous state of the art stochastic methods fail to find sparse networks that can reduce the communication and storage overhead using consistent loss objectives. To address this, we propose adding a regularization term to local objectives that acts as a proxy of the transmitted masks entropy, therefore encouraging sparser solutions by eliminating redundant features across sub-networks. Extensive empirical experiments demonstrate significant improvements in communication and memory efficiency of up to five magnitudes compared to the literature, with minimal performance degradation in validation accuracy in some instances\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.CV",
            "cs.DC",
            "cs.DS"
        ],
        "submitted_date": "19 Sep 2023",
        "last_revised_date": " "
    },
    "2309.10947": {
        "title": "How Do Analysts Understand and Verify AI-Assisted Data Analyses?",
        "authors": [
            "Ken Gu",
            "Ruoxi Shang",
            "Tim Althoff",
            "Chenglong Wang",
            "Steven M. Drucker"
        ],
        "comments": "Accepted to CHI 2024",
        "subjects": "Human-Computer Interaction (cs.HC)",
        "abstract": "Data analysis is challenging as it requires synthesizing domain knowledge, statistical expertise, and programming skills. Assistants powered by large language models (LLMs), such as ChatGPT, can assist analysts by translating natural language instructions into code. However, AI-assistant responses and analysis code can be misaligned with the analyst's intent or be seemingly correct but lead to incorrect conclusions. Therefore, validating AI assistance is crucial and challenging. Here, we explore how analysts understand and verify the correctness of AI-generated analyses. To observe analysts in diverse verification approaches, we develop a design probe equipped with natural language explanations, code, visualizations, and interactive data tables with common data operations. Through a qualitative user study (n=22) using this probe, we uncover common behaviors within verification workflows and how analysts' programming, analysis, and tool backgrounds reflect these behaviors. Additionally, we provide recommendations for analysts and highlight opportunities for designers to improve future AI-assistant experiences.\n    ",
        "primary_category": "cs.HC",
        "categories": [],
        "submitted_date": "19 Sep 2023",
        "last_revised_date": " "
    },
    "2309.11038": {
        "title": "CaveSeg: Deep Semantic Segmentation and Scene Parsing for Autonomous Underwater Cave Exploration",
        "authors": [
            "A. Abdullah",
            "T. Barua",
            "R. Tibbetts",
            "Z. Chen",
            "M. J. Islam",
            "I. Rekleitis"
        ],
        "comments": "Accepted in ICRA 2024. 10 pages, 9 figures",
        "subjects": "Robotics (cs.RO)",
        "abstract": "In this paper, we present CaveSeg - the first visual learning pipeline for semantic segmentation and scene parsing for AUV navigation inside underwater caves. We address the problem of scarce annotated training data by preparing a comprehensive dataset for semantic segmentation of underwater cave scenes. It contains pixel annotations for important navigation markers (e.g. caveline, arrows), obstacles (e.g. ground plain and overhead layers), scuba divers, and open areas for servoing. Through comprehensive benchmark analyses on cave systems in USA, Mexico, and Spain locations, we demonstrate that robust deep visual models can be developed based on CaveSeg for fast semantic scene parsing of underwater cave environments. In particular, we formulate a novel transformer-based model that is computationally light and offers near real-time execution in addition to achieving state-of-the-art performance. Finally, we explore the design choices and implications of semantic segmentation for visual servoing by AUVs inside underwater caves. The proposed model and benchmark dataset open up promising opportunities for future research in autonomous underwater cave exploration and mapping.\n    ",
        "primary_category": "cs.RO",
        "categories": [
            "cs.CV",
            "eess.IV"
        ],
        "submitted_date": "20 Sep 2023",
        "last_revised_date": " "
    },
    "2309.11040": {
        "title": "Stein Variational Guided Model Predictive Path Integral Control: Proposal and Experiments with Fast Maneuvering Vehicles",
        "authors": [
            "Kohei Honda",
            "Naoki Akai",
            "Kosuke Suzuki",
            "Mizuho Aoki",
            "Hirotaka Hosogaya",
            "Hiroyuki Okuda",
            "Tatsuya Suzuki"
        ],
        "comments": "7 pages, 5 figures",
        "subjects": "Robotics (cs.RO)",
        "abstract": "This paper presents a novel Stochastic Optimal Control (SOC) method based on Model Predictive Path Integral control (MPPI), named Stein Variational Guided MPPI (SVG-MPPI), designed to handle rapidly shifting multimodal optimal action distributions. While MPPI can find a Gaussian-approximated optimal action distribution in closed form, i.e., without iterative solution updates, it struggles with the multimodality of the optimal distributions. This is due to the less representative nature of the Gaussian. To overcome this limitation, our method aims to identify a target mode of the optimal distribution and guide the solution to converge to fit it. In the proposed method, the target mode is roughly estimated using a modified Stein Variational Gradient Descent (SVGD) method and embedded into the MPPI algorithm to find a closed-form \"mode-seeking\" solution that covers only the target mode, thus preserving the fast convergence property of MPPI. Our simulation and real-world experimental results demonstrate that SVG-MPPI outperforms both the original MPPI and other state-of-the-art sampling-based SOC algorithms in terms of path-tracking and obstacle-avoidance capabilities. Source code: this https URL\n",
        "primary_category": "cs.RO",
        "categories": [
            "cs.IT"
        ],
        "submitted_date": "20 Sep 2023",
        "last_revised_date": " "
    },
    "2309.11661": {
        "title": "Neural Image Compression Using Masked Sparse Visual Representation",
        "authors": [
            "Wei Jiang",
            "Wei Wang",
            "Yue Chen"
        ],
        "comments": " ",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "We study neural image compression based on the Sparse Visual Representation (SVR), where images are embedded into a discrete latent space spanned by learned visual codebooks. By sharing codebooks with the decoder, the encoder transfers integer codeword indices that are efficient and cross-platform robust, and the decoder retrieves the embedded latent feature using the indices for reconstruction. Previous SVR-based compression lacks effective mechanism for rate-distortion tradeoffs, where one can only pursue either high reconstruction quality or low transmission bitrate. We propose a Masked Adaptive Codebook learning (M-AdaCode) method that applies masks to the latent feature subspace to balance bitrate and reconstruction quality. A set of semantic-class-dependent basis codebooks are learned, which are weighted combined to generate a rich latent feature for high-quality reconstruction. The combining weights are adaptively derived from each input image, providing fidelity information with additional transmission costs. By masking out unimportant weights in the encoder and recovering them in the decoder, we can trade off reconstruction quality for transmission bits, and the masking rate controls the balance between bitrate and distortion. Experiments over the standard JPEG-AI dataset demonstrate the effectiveness of our M-AdaCode approach.\n    ",
        "primary_category": "cs.CV",
        "categories": [
            "eess.IV"
        ],
        "submitted_date": "20 Sep 2023",
        "last_revised_date": " "
    },
    "2309.11852": {
        "title": "Knowledge Sanitization of Large Language Models",
        "authors": [
            "Yoichi Ishibashi",
            "Hidetoshi Shimodaira"
        ],
        "comments": " ",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "We explore a knowledge sanitization approach to mitigate the privacy concerns associated with large language models (LLMs). LLMs trained on a large corpus of Web data can memorize and potentially reveal sensitive or confidential information, raising critical security concerns. Our technique efficiently fine-tunes these models using the Low-Rank Adaptation (LoRA) method, prompting them to generate harmless responses such as ``I don't know'' when queried about specific information. Experimental results in a closed-book question-answering task show that our straightforward method not only minimizes particular knowledge leakage but also preserves the overall performance of LLMs. These two advantages strengthen the defense against extraction attacks and reduces the emission of harmful content such as hallucinations.\n    ",
        "primary_category": "cs.CL",
        "categories": [],
        "submitted_date": "21 Sep 2023",
        "last_revised_date": " "
    },
    "2309.12005": {
        "title": "GPS-VIO Fusion with Online Rotational Calibration",
        "authors": [
            "Junlin Song",
            "Pedro J. Sanchez-Cuevas",
            "Antoine Richard",
            "Raj Thilak Rajan",
            "Miguel Olivares-Mendez"
        ],
        "comments": "Accepted by ICRA 2024",
        "subjects": "Robotics (cs.RO)",
        "abstract": "Accurate global localization is crucial for autonomous navigation and planning. To this end, various GPS-aided Visual-Inertial Odometry (GPS-VIO) fusion algorithms are proposed in the literature. This paper presents a novel GPS-VIO system that is able to significantly benefit from the online calibration of the rotational extrinsic parameter between the GPS reference frame and the VIO reference frame. The behind reason is this parameter is observable. This paper provides novel proof through nonlinear observability analysis. We also evaluate the proposed algorithm extensively on diverse platforms, including flying UAV and driving vehicle. The experimental results support the observability analysis and show increased localization accuracy in comparison to state-of-the-art (SOTA) tightly-coupled algorithms.\n    ",
        "primary_category": "cs.RO",
        "categories": [],
        "submitted_date": "21 Sep 2023",
        "last_revised_date": " "
    },
    "2309.12309": {
        "title": "Rehearsal: Simulating Conflict to Teach Conflict Resolution",
        "authors": [
            "Omar Shaikh",
            "Valentino Chai",
            "Michele J. Gelfand",
            "Diyi Yang",
            "Michael S. Bernstein"
        ],
        "comments": "CHI 2024",
        "subjects": "Human-Computer Interaction (cs.HC)",
        "abstract": "Interpersonal conflict is an uncomfortable but unavoidable fact of life. Navigating conflict successfully is a skill -- one that can be learned through deliberate practice -- but few have access to effective training or feedback. To expand this access, we introduce Rehearsal, a system that allows users to rehearse conflicts with a believable simulated interlocutor, explore counterfactual \"what if?\" scenarios to identify alternative conversational paths, and learn through feedback on how and when to apply specific conflict strategies. Users can utilize Rehearsal to practice handling a variety of predefined conflict scenarios, from office disputes to relationship issues, or they can choose to create their own setting. To enable Rehearsal, we develop IRP prompting, a method of conditioning output of a large language model on the influential Interest-Rights-Power (IRP) theory from conflict resolution. Rehearsal uses IRP to generate utterances grounded in conflict resolution theory, guiding users towards counterfactual conflict resolution strategies that help de-escalate difficult conversations. In a between-subjects evaluation, 40 participants engaged in an actual conflict with a confederate after training. Compared to a control group with lecture material covering the same IRP theory, participants with simulated training from Rehearsal significantly improved their performance in the unaided conflict: they reduced their use of escalating competitive strategies by an average of 67%, while doubling their use of cooperative strategies. Overall, Rehearsal highlights the potential effectiveness of language models as tools for learning and practicing interpersonal skills.\n    ",
        "primary_category": "cs.HC",
        "categories": [
            "cs.AI",
            "cs.CL"
        ],
        "submitted_date": "21 Sep 2023",
        "last_revised_date": " "
    },
    "2309.12444": {
        "title": "Foundation Metrics for Evaluating Effectiveness of Healthcare Conversations Powered by Generative AI",
        "authors": [
            "Mahyar Abbasian",
            "Elahe Khatibi",
            "Iman Azimi",
            "David Oniani",
            "Zahra Shakeri Hossein Abad",
            "Alexander Thieme",
            "Ram Sriram",
            "Zhongqi Yang",
            "Yanshan Wang",
            "Bryant Lin",
            "Olivier Gevaert",
            "Li-Jia Li",
            "Ramesh Jain",
            "Amir M. Rahmani"
        ],
        "comments": "14 pages, 4 figures, 2 tables, journal paper",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "Generative Artificial Intelligence is set to revolutionize healthcare delivery by transforming traditional patient care into a more personalized, efficient, and proactive process. Chatbots, serving as interactive conversational models, will probably drive this patient-centered transformation in healthcare. Through the provision of various services, including diagnosis, personalized lifestyle recommendations, and mental health support, the objective is to substantially augment patient health outcomes, all the while mitigating the workload burden on healthcare providers. The life-critical nature of healthcare applications necessitates establishing a unified and comprehensive set of evaluation metrics for conversational models. Existing evaluation metrics proposed for various generic large language models (LLMs) demonstrate a lack of comprehension regarding medical and health concepts and their significance in promoting patients' well-being. Moreover, these metrics neglect pivotal user-centered aspects, including trust-building, ethics, personalization, empathy, user comprehension, and emotional support. The purpose of this paper is to explore state-of-the-art LLM-based evaluation metrics that are specifically applicable to the assessment of interactive conversational models in healthcare. Subsequently, we present an comprehensive set of evaluation metrics designed to thoroughly assess the performance of healthcare chatbots from an end-user perspective. These metrics encompass an evaluation of language processing abilities, impact on real-world clinical tasks, and effectiveness in user-interactive conversations. Finally, we engage in a discussion concerning the challenges associated with defining and implementing these metrics, with particular emphasis on confounding factors such as the target audience, evaluation methods, and prompt techniques involved in the evaluation process.\n    ",
        "primary_category": "cs.CL",
        "categories": [],
        "submitted_date": "21 Sep 2023",
        "last_revised_date": " "
    },
    "2309.12924": {
        "title": "Automated grading workflows for providing personalized feedback to open-ended data science assignments",
        "authors": [
            "Federica Zoe Ricci",
            "Catalina Mari Medina",
            "Mine Dogucu"
        ],
        "comments": "24 pages, 3 figures",
        "subjects": "Physics Education (physics.ed-ph)",
        "abstract": "Open-ended assignments - such as lab reports and semester-long projects - provide data science and statistics students with opportunities for developing communication, critical thinking, and creativity skills. However, providing grades and formative feedback to open-ended assignments can be very time consuming and difficult to do consistently across students. In this paper, we discuss the steps of a typical grading workflow and highlight which steps can be automated in an approach that we call automated grading workflow. We illustrate how gradetools, a new R package, implements this approach within RStudio to facilitate efficient and consistent grading while providing individualized feedback. By outlining the motivations behind the development of this package and the considerations underlying its design, we hope this article will provide data science and statistics educators with ideas for improving their grading workflows, possibly developing new grading tools or considering use gradetools as their grading workflow assistant.\n    ",
        "primary_category": "physics.ed-ph",
        "categories": [
            "cs.CY",
            "stat.OT"
        ],
        "submitted_date": "18 Aug 2023",
        "last_revised_date": " "
    },
    "2309.13150": {
        "title": "Pixel-wise Smoothing for Certified Robustness against Camera Motion Perturbations",
        "authors": [
            "Hanjiang Hu",
            "Zuxin Liu",
            "Linyi Li",
            "Jiacheng Zhu",
            "Ding Zhao"
        ],
        "comments": "Camera-ready version of AISTATS 2024, 30 pages, 5 figures, 13 tables",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Deep learning-based visual perception models lack robustness when faced with camera motion perturbations in practice. The current certification process for assessing robustness is costly and time-consuming due to the extensive number of image projections required for Monte Carlo sampling in the 3D camera motion space. To address these challenges, we present a novel, efficient, and practical framework for certifying the robustness of 3D-2D projective transformations against camera motion perturbations. Our approach leverages a smoothing distribution over the 2D pixel space instead of in the 3D physical space, eliminating the need for costly camera motion sampling and significantly enhancing the efficiency of robustness certifications. With the pixel-wise smoothed classifier, we are able to fully upper bound the projection errors using a technique of uniform partitioning in camera motion space. Additionally, we extend our certification framework to a more general scenario where only a single-frame point cloud is required in the projection oracle. Through extensive experimentation, we validate the trade-off between effectiveness and efficiency enabled by our proposed method. Remarkably, our approach achieves approximately 80% certified accuracy while utilizing only 30% of the projected image frames. The code is available at this https URL.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.CV",
            "cs.RO"
        ],
        "submitted_date": "22 Sep 2023",
        "last_revised_date": " "
    },
    "2309.13192": {
        "title": "Towards Green AI in Fine-tuning Large Language Models via Adaptive Backpropagation",
        "authors": [
            "Kai Huang",
            "Hanyun Yin",
            "Heng Huang",
            "Wei Gao"
        ],
        "comments": "16 pages",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Fine-tuning is the most effective way of adapting pre-trained large language models (LLMs) to downstream applications. With the fast growth of LLM-enabled AI applications and democratization of open-souced LLMs, fine-tuning has become possible for non-expert individuals, but intensively performed LLM fine-tuning worldwide could result in significantly high energy consumption and carbon footprint, which may bring large environmental impact. Mitigating such environmental impact towards Green AI directly correlates to reducing the FLOPs of fine-tuning, but existing techniques on efficient LLM fine-tuning can only achieve limited reduction of such FLOPs, due to their ignorance of the backpropagation cost in fine-tuning. To address this limitation, in this paper we present GreenTrainer, a new LLM fine-tuning technique that adaptively evaluates different tensors' backpropagation costs and contributions to the fine-tuned model accuracy, to minimize the fine-tuning cost by selecting the most appropriate set of tensors in training. Such selection in GreenTrainer is made based on a given objective of FLOPs reduction, which can flexibly adapt to the carbon footprint in energy supply and the need in Green AI. Experiment results over multiple open-sourced LLM models and abstractive summarization datasets show that, compared to fine-tuning the whole LLM model, GreenTrainer can save up to 64% FLOPs in fine-tuning without any noticeable model accuracy loss. Compared to the existing fine-tuning techniques such as LoRa, GreenTrainer can achieve up to 4% improvement on model accuracy with on-par FLOPs reduction.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "22 Sep 2023",
        "last_revised_date": " "
    },
    "2309.13515": {
        "title": "Learning-based Inverse Perception Contracts and Applications",
        "authors": [
            "Dawei Sun",
            "Benjamin C. Yang",
            "Sayan Mitra"
        ],
        "comments": " ",
        "subjects": "Robotics (cs.RO)",
        "abstract": "Perception modules are integral in many modern autonomous systems, but their accuracy can be subject to the vagaries of the environment. In this paper, we propose a learning-based approach that can automatically characterize the error of a perception module from data and use this for safe control. The proposed approach constructs an inverse perception contract (IPC) which generates a set that contains the ground-truth value that is being estimated by the perception module, with high probability. We apply the proposed approach to study a vision pipeline deployed on a quadcopter. With the proposed approach, we successfully constructed an IPC for the vision pipeline. We then designed a control algorithm that utilizes the learned IPC, with the goal of landing the quadcopter safely on a landing pad. Experiments show that with the learned IPC, the control algorithm safely landed the quadcopter despite the error from the perception module, while the baseline algorithm without using the learned IPC failed to do so.\n    ",
        "primary_category": "cs.RO",
        "categories": [
            "eess.SY"
        ],
        "submitted_date": "24 Sep 2023",
        "last_revised_date": " "
    },
    "2309.13957": {
        "title": "Beam Enumeration: Probabilistic Explainability For Sample Efficient Self-conditioned Molecular Design",
        "authors": [
            "Jeff Guo",
            "Philippe Schwaller"
        ],
        "comments": " ",
        "subjects": "Biomolecules (q-bio.BM)",
        "abstract": "Generative molecular design has moved from proof-of-concept to real-world applicability, as marked by the surge in very recent papers reporting experimental validation. Key challenges in explainability and sample efficiency present opportunities to enhance generative design to directly optimize expensive high-fidelity oracles and provide actionable insights to domain experts. Here, we propose Beam Enumeration to exhaustively enumerate the most probable sub-sequences from language-based molecular generative models and show that molecular substructures can be extracted. When coupled with reinforcement learning, extracted substructures become meaningful, providing a source of explainability and improving sample efficiency through self-conditioned generation. Beam Enumeration is generally applicable to any language-based molecular generative model and notably further improves the performance of the recently reported Augmented Memory algorithm, which achieved the new state-of-the-art on the Practical Molecular Optimization benchmark for sample efficiency. The combined algorithm generates more high reward molecules and faster, given a fixed oracle budget. Beam Enumeration shows that improvements to explainability and sample efficiency for molecular design can be made synergistic.\n    ",
        "primary_category": "q-bio.BM",
        "categories": [
            "cs.LG"
        ],
        "submitted_date": "25 Sep 2023",
        "last_revised_date": " "
    },
    "2309.14504": {
        "title": "People's Perceptions Toward Bias and Related Concepts in Large Language Models: A Systematic Review",
        "authors": [
            "Lu Wang",
            "Max Song",
            "Rezvaneh Rezapour",
            "Bum Chul Kwon",
            "Jina Huh-Yoo"
        ],
        "comments": " ",
        "subjects": "Human-Computer Interaction (cs.HC)",
        "abstract": "Large language models (LLMs) have brought breakthroughs in tasks including translation, summarization, information retrieval, and language generation, gaining growing interest in the CHI community. Meanwhile, the literature shows researchers' controversial perceptions about the efficacy, ethics, and intellectual abilities of LLMs. However, we do not know how people perceive LLMs that are pervasive in everyday tools, specifically regarding their experience with LLMs around bias, stereotypes, social norms, or safety. In this study, we conducted a systematic review to understand what empirical insights papers have gathered about people's perceptions toward LLMs. From a total of 231 retrieved papers, we full-text reviewed 15 papers that recruited human evaluators to assess their experiences with LLMs. We report different biases and related concepts investigated by these studies, four broader LLM application areas, the evaluators' perceptions toward LLMs' performances including advantages, biases, and conflicting perceptions, factors influencing these perceptions, and concerns about LLM applications.\n    ",
        "primary_category": "cs.HC",
        "categories": [],
        "submitted_date": "25 Sep 2023",
        "last_revised_date": " "
    },
    "2309.15135": {
        "title": "Contrastive Continual Multi-view Clustering with Filtered Structural Fusion",
        "authors": [
            "Xinhang Wan",
            "Jiyuan Liu",
            "Hao Yu",
            "Ao Li",
            "Xinwang Liu",
            "Ke Liang",
            "Zhibin Dong",
            "En Zhu"
        ],
        "comments": " ",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Multi-view clustering thrives in applications where views are collected in advance by extracting consistent and complementary information among views. However, it overlooks scenarios where data views are collected sequentially, i.e., real-time data. Due to privacy issues or memory burden, previous views are not available with time in these situations. Some methods are proposed to handle it but are trapped in a stability-plasticity dilemma. In specific, these methods undergo a catastrophic forgetting of prior knowledge when a new view is attained. Such a catastrophic forgetting problem (CFP) would cause the consistent and complementary information hard to get and affect the clustering performance. To tackle this, we propose a novel method termed Contrastive Continual Multi-view Clustering with Filtered Structural Fusion (CCMVC-FSF). Precisely, considering that data correlations play a vital role in clustering and prior knowledge ought to guide the clustering process of a new view, we develop a data buffer with fixed size to store filtered structural information and utilize it to guide the generation of a robust partition matrix via contrastive learning. Furthermore, we theoretically connect CCMVC-FSF with semi-supervised learning and knowledge distillation. Extensive experiments exhibit the excellence of the proposed method.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.AI",
            "cs.CV"
        ],
        "submitted_date": "26 Sep 2023",
        "last_revised_date": " "
    },
    "2309.15459": {
        "title": "GAMMA: Graspability-Aware Mobile MAnipulation Policy Learning based on Online Grasping Pose Fusion",
        "authors": [
            "Jiazhao Zhang",
            "Nandiraju Gireesh",
            "Jilong Wang",
            "Xiaomeng Fang",
            "Chaoyi Xu",
            "Weiguang Chen",
            "Liu Dai",
            "He Wang"
        ],
        "comments": " ",
        "subjects": "Robotics (cs.RO)",
        "abstract": "Mobile manipulation constitutes a fundamental task for robotic assistants and garners significant attention within the robotics community. A critical challenge inherent in mobile manipulation is the effective observation of the target while approaching it for grasping. In this work, we propose a graspability-aware mobile manipulation approach powered by an online grasping pose fusion framework that enables a temporally consistent grasping observation. Specifically, the predicted grasping poses are online organized to eliminate the redundant, outlier grasping poses, which can be encoded as a grasping pose observation state for reinforcement learning. Moreover, on-the-fly fusing the grasping poses enables a direct assessment of graspability, encompassing both the quantity and quality of grasping poses.\n    ",
        "primary_category": "cs.RO",
        "categories": [
            "cs.CV"
        ],
        "submitted_date": "27 Sep 2023",
        "last_revised_date": " "
    },
    "2309.15790": {
        "title": "Private, Efficient, and Optimal K-Norm and Elliptic Gaussian Noise For Sum, Count, and Vote",
        "authors": [
            "Matthew Joseph",
            "Alexander Yu"
        ],
        "comments": "This version adds count and elliptic Gaussian material",
        "subjects": "Cryptography and Security (cs.CR)",
        "abstract": "Differentially private computation often begins with a bound on some $d$-dimensional statistic's $\\ell_p$ sensitivity. For pure differential privacy, the $K$-norm mechanism can improve on this approach using statistic-specific (and possibly non-$\\ell_p$) norms. However, sampling such mechanisms requires sampling from the corresponding norm balls. These are $d$-dimensional convex polytopes, for which the fastest known general sampling algorithm takes time $\\tilde O(d^{3+\\omega})$, where $\\omega \\geq 2$ is the matrix multiplication exponent. For concentrated differential privacy, elliptic Gaussian noise offers similar improvement over spherical Gaussian noise, but the general method for computing the problem-specific elliptic noise requires solving a semidefinite program for each instance.\nThis paper considers the simple problems of sum, count, and vote and provides faster algorithms in both settings. We construct optimal pure differentially private $K$-norm mechanism samplers and derive closed-form expressions for optimal concentrated differentially private elliptic Gaussian noise. Their runtimes are, respectively, $\\tilde O(d^2)$ and $O(1)$, and the resulting algorithms all yield meaningful accuracy improvements. More broadly, we suggest that problem-specific sensitivity space analysis may be an overlooked tool for private additive noise.\n    ",
        "primary_category": "cs.CR",
        "categories": [],
        "submitted_date": "27 Sep 2023",
        "last_revised_date": " "
    },
    "2309.16098": {
        "title": "Stackelberg Game-Theoretic Trajectory Guidance for Multi-Robot Systems with Koopman Operator",
        "authors": [
            "Yuhan Zhao",
            "Quanyan Zhu"
        ],
        "comments": " ",
        "subjects": "Robotics (cs.RO)",
        "abstract": "Guided trajectory planning involves a leader robot strategically directing a follower robot to collaboratively reach a designated destination. However, this task becomes notably challenging when the leader lacks complete knowledge of the follower's decision-making model. There is a need for learning-based methods to effectively design the cooperative plan. To this end, we develop a Stackelberg game-theoretic approach based on the Koopman operator to address the challenge. We first formulate the guided trajectory planning problem through the lens of a dynamic Stackelberg game. We then leverage Koopman operator theory to acquire a learning-based linear system model that approximates the follower's feedback dynamics. Based on this learned model, the leader devises a collision-free trajectory to guide the follower using receding horizon planning. We use simulations to elaborate on the effectiveness of our approach in generating learning models that accurately predict the follower's multi-step behavior when compared to alternative learning techniques. Moreover, our approach successfully accomplishes the guidance task and notably reduces the leader's planning time to nearly half when contrasted with the model-based baseline method.\n    ",
        "primary_category": "cs.RO",
        "categories": [],
        "submitted_date": "28 Sep 2023",
        "last_revised_date": " "
    },
    "2309.16264": {
        "title": "GAMMA: Generalizable Articulation Modeling and Manipulation for Articulated Objects",
        "authors": [
            "Qiaojun Yu",
            "Junbo Wang",
            "Wenhai Liu",
            "Ce Hao",
            "Liu Liu",
            "Lin Shao",
            "Weiming Wang",
            "Cewu Lu"
        ],
        "comments": "8 pages, 5 figures, ICRA 2024",
        "subjects": "Robotics (cs.RO)",
        "abstract": "Articulated objects like cabinets and doors are widespread in daily life. However, directly manipulating 3D articulated objects is challenging because they have diverse geometrical shapes, semantic categories, and kinetic constraints. Prior works mostly focused on recognizing and manipulating articulated objects with specific joint types. They can either estimate the joint parameters or distinguish suitable grasp poses to facilitate trajectory planning. Although these approaches have succeeded in certain types of articulated objects, they lack generalizability to unseen objects, which significantly impedes their application in broader scenarios. In this paper, we propose a novel framework of Generalizable Articulation Modeling and Manipulating for Articulated Objects (GAMMA), which learns both articulation modeling and grasp pose affordance from diverse articulated objects with different categories. In addition, GAMMA adopts adaptive manipulation to iteratively reduce the modeling errors and enhance manipulation performance. We train GAMMA with the PartNet-Mobility dataset and evaluate with comprehensive experiments in SAPIEN simulation and real-world Franka robot. Results show that GAMMA significantly outperforms SOTA articulation modeling and manipulation algorithms in unseen and cross-category articulated objects. We will open-source all codes and datasets in both simulation and real robots for reproduction in the final version. Images and videos are published on the project website at: this http URL\n",
        "primary_category": "cs.RO",
        "categories": [
            "cs.CV"
        ],
        "submitted_date": "28 Sep 2023",
        "last_revised_date": " "
    },
    "2309.16598": {
        "title": "Cross-Prediction-Powered Inference",
        "authors": [
            "Tijana Zrnic",
            "Emmanuel J. Cand\u00e8s"
        ],
        "comments": " ",
        "subjects": "Machine Learning (stat.ML)",
        "abstract": "While reliable data-driven decision-making hinges on high-quality labeled data, the acquisition of quality labels often involves laborious human annotations or slow and expensive scientific measurements. Machine learning is becoming an appealing alternative as sophisticated predictive techniques are being used to quickly and cheaply produce large amounts of predicted labels; e.g., predicted protein structures are used to supplement experimentally derived structures, predictions of socioeconomic indicators from satellite imagery are used to supplement accurate survey data, and so on. Since predictions are imperfect and potentially biased, this practice brings into question the validity of downstream inferences. We introduce cross-prediction: a method for valid inference powered by machine learning. With a small labeled dataset and a large unlabeled dataset, cross-prediction imputes the missing labels via machine learning and applies a form of debiasing to remedy the prediction inaccuracies. The resulting inferences achieve the desired error probability and are more powerful than those that only leverage the labeled data. Closely related is the recent proposal of prediction-powered inference, which assumes that a good pre-trained model is already available. We show that cross-prediction is consistently more powerful than an adaptation of prediction-powered inference in which a fraction of the labeled data is split off and used to train the model. Finally, we observe that cross-prediction gives more stable conclusions than its competitors; its confidence intervals typically have significantly lower variability.\n    ",
        "primary_category": "stat.ML",
        "categories": [
            "cs.LG",
            "stat.ME"
        ],
        "submitted_date": "28 Sep 2023",
        "last_revised_date": " "
    },
    "2309.16739": {
        "title": "Pushing Large Language Models to the 6G Edge: Vision, Challenges, and Opportunities",
        "authors": [
            "Zheng Lin",
            "Guanqiao Qu",
            "Qiyuan Chen",
            "Xianhao Chen",
            "Zhe Chen",
            "Kaibin Huang"
        ],
        "comments": "7 pages, 5 figures",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Large language models (LLMs), which have shown remarkable capabilities, are revolutionizing AI development and potentially shaping our future. However, given their multimodality, the status quo cloud-based deployment faces some critical challenges: 1) long response time; 2) high bandwidth costs; and 3) the violation of data privacy. 6G mobile edge computing (MEC) systems may resolve these pressing issues. In this article, we explore the potential of deploying LLMs at the 6G edge. We start by introducing killer applications powered by multimodal LLMs, including robotics and healthcare, to highlight the need for deploying LLMs in the vicinity of end users. Then, we identify the critical challenges for LLM deployment at the edge and envision the 6G MEC architecture for LLMs. Furthermore, we delve into two design aspects, i.e., edge training and edge inference for LLMs. In both aspects, considering the inherent resource limitations at the edge, we discuss various cutting-edge techniques, including split learning/inference, parameter-efficient fine-tuning, quantization, and parameter-sharing inference, to facilitate the efficient deployment of LLMs. This article serves as a position paper for thoroughly identifying the motivation, challenges, and pathway for empowering LLMs at the 6G edge.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "28 Sep 2023",
        "last_revised_date": " "
    },
    "2309.16909": {
        "title": "ASAP: Automated Sequence Planning for Complex Robotic Assembly with Physical Feasibility",
        "authors": [
            "Yunsheng Tian",
            "Karl D.D. Willis",
            "Bassel Al Omari",
            "Jieliang Luo",
            "Pingchuan Ma",
            "Yichen Li",
            "Farhad Javid",
            "Edward Gu",
            "Joshua Jacob",
            "Shinjiro Sueda",
            "Hui Li",
            "Sachin Chitta",
            "Wojciech Matusik"
        ],
        "comments": "ICRA 2024",
        "subjects": "Robotics (cs.RO)",
        "abstract": "The automated assembly of complex products requires a system that can automatically plan a physically feasible sequence of actions for assembling many parts together. In this paper, we present ASAP, a physics-based planning approach for automatically generating such a sequence for general-shaped assemblies. ASAP accounts for gravity to design a sequence where each sub-assembly is physically stable with a limited number of parts being held and a support surface. We apply efficient tree search algorithms to reduce the combinatorial complexity of determining such an assembly sequence. The search can be guided by either geometric heuristics or graph neural networks trained on data with simulation labels. Finally, we show the superior performance of ASAP at generating physically realistic assembly sequence plans on a large dataset of hundreds of complex product assemblies. We further demonstrate the applicability of ASAP on both simulation and real-world robotic setups. Project website: this http URL\n",
        "primary_category": "cs.RO",
        "categories": [
            "cs.AI",
            "cs.GR"
        ],
        "submitted_date": "29 Sep 2023",
        "last_revised_date": " "
    },
    "2309.17187": {
        "title": "TBD Pedestrian Data Collection: Towards Rich, Portable, and Large-Scale Natural Pedestrian Data",
        "authors": [
            "Allan Wang",
            "Daisuke Sato",
            "Yasser Corzo",
            "Sonya Simkin",
            "Abhijat Biswas",
            "Aaron Steinfeld"
        ],
        "comments": "This work has been accepted by IEEE ICRA 2024. Copyright may be transferred without notice, after which this version may no longer be accessible. arXiv admin note: substantial text overlap with arXiv:2203.01974",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Social navigation and pedestrian behavior research has shifted towards machine learning-based methods and converged on the topic of modeling inter-pedestrian interactions and pedestrian-robot interactions. For this, large-scale datasets that contain rich information are needed. We describe a portable data collection system, coupled with a semi-autonomous labeling pipeline. As part of the pipeline, we designed a label correction web app that facilitates human verification of automated pedestrian tracking outcomes. Our system enables large-scale data collection in diverse environments and fast trajectory label production. Compared with existing pedestrian data collection methods, our system contains three components: a combination of top-down and ego-centric views, natural human behavior in the presence of a socially appropriate \"robot\", and human-verified labels grounded in the metric space. To the best of our knowledge, no prior data collection system has a combination of all three components. We further introduce our ever-expanding dataset from the ongoing data collection effort -- the TBD Pedestrian Dataset and show that our collected data is larger in scale, contains richer information when compared to prior datasets with human-verified labels, and supports new research opportunities.\n    ",
        "primary_category": "cs.CV",
        "categories": [
            "cs.HC",
            "cs.RO"
        ],
        "submitted_date": "29 Sep 2023",
        "last_revised_date": " "
    },
    "2309.17260": {
        "title": "PlaceNav: Topological Navigation through Place Recognition",
        "authors": [
            "Lauri Suomela",
            "Jussi Kalliola",
            "Harry Edelman",
            "Joni-Kristian K\u00e4m\u00e4r\u00e4inen"
        ],
        "comments": "ICRA2024 camera ready",
        "subjects": "Robotics (cs.RO)",
        "abstract": "Recent results suggest that splitting topological navigation into robot-independent and robot-specific components improves navigation performance by enabling the robot-independent part to be trained with data collected by robots of different types. However, the navigation methods' performance is still limited by the scarcity of suitable training data and they suffer from poor computational scaling.\nIn this work, we present PlaceNav, subdividing the robot-independent part into navigation-specific and generic computer vision components. We utilize visual place recognition for the subgoal selection of the topological navigation pipeline. This makes subgoal selection more efficient and enables leveraging large-scale datasets from non-robotics sources, increasing training data availability. Bayesian filtering, enabled by place recognition, further improves navigation performance by increasing the temporal consistency of subgoals. Our experimental results verify the design and the new method obtains a 76% higher success rate in indoor and 23% higher in outdoor navigation tasks with higher computational efficiency.\n    ",
        "primary_category": "cs.RO",
        "categories": [
            "cs.AI",
            "cs.LG"
        ],
        "submitted_date": "29 Sep 2023",
        "last_revised_date": " "
    },
    "2309.17388": {
        "title": "Tree Cross Attention",
        "authors": [
            "Leo Feng",
            "Frederick Tung",
            "Hossein Hajimirsadeghi",
            "Yoshua Bengio",
            "Mohamed Osama Ahmed"
        ],
        "comments": "Accepted by ICLR 2024",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Cross Attention is a popular method for retrieving information from a set of context tokens for making predictions. At inference time, for each prediction, Cross Attention scans the full set of $\\mathcal{O}(N)$ tokens. In practice, however, often only a small subset of tokens are required for good performance. Methods such as Perceiver IO are cheap at inference as they distill the information to a smaller-sized set of latent tokens $L < N$ on which cross attention is then applied, resulting in only $\\mathcal{O}(L)$ complexity. However, in practice, as the number of input tokens and the amount of information to distill increases, the number of latent tokens needed also increases significantly. In this work, we propose Tree Cross Attention (TCA) - a module based on Cross Attention that only retrieves information from a logarithmic $\\mathcal{O}(\\log(N))$ number of tokens for performing inference. TCA organizes the data in a tree structure and performs a tree search at inference time to retrieve the relevant tokens for prediction. Leveraging TCA, we introduce ReTreever, a flexible architecture for token-efficient inference. We show empirically that Tree Cross Attention (TCA) performs comparable to Cross Attention across various classification and uncertainty regression tasks while being significantly more token-efficient. Furthermore, we compare ReTreever against Perceiver IO, showing significant gains while using the same number of tokens for inference.\n    ",
        "primary_category": "cs.LG",
        "categories": [],
        "submitted_date": "29 Sep 2023",
        "last_revised_date": " "
    },
    "2310.00078": {
        "title": "Characterizing Semantic Ambiguity of the Materials Science Ontologies",
        "authors": [
            "Scott McClellan",
            "Yuan An",
            "Xintong Zhao",
            "Xia Lin",
            "Jane Greenberg"
        ],
        "comments": "12 pages, International Society for Knowledge Organization (ISKO) 2024",
        "subjects": "Digital Libraries (cs.DL)",
        "abstract": "Growth in computational materials science and initiatives such as the Materials Genome Initiative (MGI) and the European Materials Modelling Council (EMMC) has motivated the development and application of ontologies. A key factor has been increased adoption of the FAIR principles, making research data findable, accessible, interoperable, and reusable (Wilkinson et al. 2016). This paper characterizes semantic interoperability among a subset of materials science ontologies in the MatPortal repository. Background context covers semantic interoperability, ontological commitment, and the materials science ontology landscape. The research focused on MatPortal's two interoperability protocols: LOOM term matching and URI matching. Results report the degree of overlap and demonstrate the different types of ambiguity among ontologies. The discussion considers implications for FAIR and AI, and the conclusion highlight key findings and next steps.\n    ",
        "primary_category": "cs.DL",
        "categories": [],
        "submitted_date": "29 Sep 2023",
        "last_revised_date": " "
    },
    "2310.00433": {
        "title": "Active-Perceptive Motion Generation for Mobile Manipulation",
        "authors": [
            "Snehal Jauhri",
            "Sophie Lueth",
            "Georgia Chalvatzaki"
        ],
        "comments": "ICRA 2024. Project page: this https URL",
        "subjects": "Robotics (cs.RO)",
        "abstract": "Mobile Manipulation (MoMa) systems incorporate the benefits of mobility and dexterity, due to the enlarged space in which they can move and interact with their environment. However, even when equipped with onboard sensors, e.g., an embodied camera, extracting task-relevant visual information in unstructured and cluttered environments, such as households, remains challenging. In this work, we introduce an active perception pipeline for mobile manipulators to generate motions that are informative toward manipulation tasks, such as grasping in unknown, cluttered scenes. Our proposed approach, ActPerMoMa, generates robot paths in a receding horizon fashion by sampling paths and computing path-wise utilities. These utilities trade-off maximizing the visual Information Gain (IG) for scene reconstruction and the task-oriented objective, e.g., grasp success, by maximizing grasp reachability. We show the efficacy of our method in simulated experiments with a dual-arm TIAGo++ MoMa robot performing mobile grasping in cluttered scenes with obstacles. We empirically analyze the contribution of various utilities and parameters, and compare against representative baselines both with and without active perception objectives. Finally, we demonstrate the transfer of our mobile grasping strategy to the real world, indicating a promising direction for active-perceptive MoMa.\n    ",
        "primary_category": "cs.RO",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "30 Sep 2023",
        "last_revised_date": " "
    },
    "2310.00762": {
        "title": "A note on the stabilizer formalism via noncommutative graphs",
        "authors": [
            "Roy Araiza",
            "Jihong Cai",
            "Yushan Chen",
            "Abraham Holtermann",
            "Chieh Hsu",
            "Tushar Mohan",
            "Peixue Wu",
            "Zeyuan Yu"
        ],
        "comments": "Final version. To appear in \"Quantum Information Processing''",
        "subjects": "Information Theory (cs.IT)",
        "abstract": "In this short note we formulate a stabilizer formalism in the language of noncommutative graphs. The classes of noncommutative graphs we consider are obtained via unitary representations of compact groups, and suitably chosen operators on finite-dimensional Hilbert spaces. Furthermore, in this framework, we generalize previous results in this area for determining when such noncommutative graphs have anticliques.\n    ",
        "primary_category": "cs.IT",
        "categories": [
            "math.OA",
            "quant-ph"
        ],
        "submitted_date": "1 Oct 2023",
        "last_revised_date": " "
    },
    "2310.01236": {
        "title": "Mirror Diffusion Models for Constrained and Watermarked Generation",
        "authors": [
            "Guan-Horng Liu",
            "Tianrong Chen",
            "Evangelos A. Theodorou",
            "Molei Tao"
        ],
        "comments": "submitted to NeurIPS on 5/18 but did not arxiv per NeurIPS policy, accepted on 9/22",
        "subjects": "Machine Learning (stat.ML)",
        "abstract": "Modern successes of diffusion models in learning complex, high-dimensional data distributions are attributed, in part, to their capability to construct diffusion processes with analytic transition kernels and score functions. The tractability results in a simulation-free framework with stable regression losses, from which reversed, generative processes can be learned at scale. However, when data is confined to a constrained set as opposed to a standard Euclidean space, these desirable characteristics appear to be lost based on prior attempts. In this work, we propose Mirror Diffusion Models (MDM), a new class of diffusion models that generate data on convex constrained sets without losing any tractability. This is achieved by learning diffusion processes in a dual space constructed from a mirror map, which, crucially, is a standard Euclidean space. We derive efficient computation of mirror maps for popular constrained sets, such as simplices and $\\ell_2$-balls, showing significantly improved performance of MDM over existing methods. For safety and privacy purposes, we also explore constrained sets as a new mechanism to embed invisible but quantitative information (i.e., watermarks) in generated data, for which MDM serves as a compelling approach. Our work brings new algorithmic opportunities for learning tractable diffusion on complex domains. Our code is available at this https URL\n",
        "primary_category": "stat.ML",
        "categories": [
            "cs.CV",
            "cs.LG"
        ],
        "submitted_date": "2 Oct 2023",
        "last_revised_date": " "
    },
    "2310.01287": {
        "title": "GenQuery: Supporting Expressive Visual Search with Generative Models",
        "authors": [
            "Kihoon Son",
            "DaEun Choi",
            "Tae Soo Kim",
            "Young-Ho Kim",
            "Juho Kim"
        ],
        "comments": "18 pages and 12 figures",
        "subjects": "Human-Computer Interaction (cs.HC)",
        "abstract": "Designers rely on visual search to explore and develop ideas in early design stages. However, designers can struggle to identify suitable text queries to initiate a search or to discover images for similarity-based search that can adequately express their intent. We propose GenQuery, a novel system that integrates generative models into the visual search process. GenQuery can automatically elaborate on users' queries and surface concrete search directions when users only have abstract ideas. To support precise expression of search intents, the system enables users to generatively modify images and use these in similarity-based search. In a comparative user study (N=16), designers felt that they could more accurately express their intents and find more satisfactory outcomes with GenQuery compared to a tool without generative features. Furthermore, the unpredictability of generations allowed participants to uncover more diverse outcomes. By supporting both convergence and divergence, GenQuery led to a more creative experience.\n    ",
        "primary_category": "cs.HC",
        "categories": [],
        "submitted_date": "2 Oct 2023",
        "last_revised_date": " "
    },
    "2310.02031": {
        "title": "OceanGPT: A Large Language Model for Ocean Science Tasks",
        "authors": [
            "Zhen Bi",
            "Ningyu Zhang",
            "Yida Xue",
            "Yixin Ou",
            "Daxiong Ji",
            "Guozhou Zheng",
            "Huajun Chen"
        ],
        "comments": "Work in progress. Project Website: this https URL",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "Ocean science, which delves into the oceans that are reservoirs of life and biodiversity, is of great significance given that oceans cover over 70% of our planet's surface. Recently, advances in Large Language Models (LLMs) have transformed the paradigm in science. Despite the success in other domains, current LLMs often fall short in catering to the needs of domain experts like oceanographers, and the potential of LLMs for ocean science is under-explored. The intrinsic reason may be the immense and intricate nature of ocean data as well as the necessity for higher granularity and richness in knowledge. To alleviate these issues, we introduce OceanGPT, the first-ever LLM in the ocean domain, which is expert in various ocean science tasks. We propose DoInstruct, a novel framework to automatically obtain a large volume of ocean domain instruction data, which generates instructions based on multi-agent collaboration. Additionally, we construct the first oceanography benchmark, OceanBench, to evaluate the capabilities of LLMs in the ocean domain. Though comprehensive experiments, OceanGPT not only shows a higher level of knowledge expertise for oceans science tasks but also gains preliminary embodied intelligence capabilities in ocean technology. Codes, data and checkpoints will soon be available at this https URL.\n    ",
        "primary_category": "cs.CL",
        "categories": [
            "cs.AI",
            "cs.CE",
            "cs.LG",
            "cs.RO"
        ],
        "submitted_date": "3 Oct 2023",
        "last_revised_date": " "
    },
    "2310.02195": {
        "title": "Efficient Online Scheduling and Routing for Automated Guided Vehicles In Loop-Based Graphs",
        "authors": [
            "Louis Stubbe",
            "Jens Goemaere",
            "Jan Goedgebeur"
        ],
        "comments": "15 pages, 4 figures",
        "subjects": "Computational Engineering, Finance, and Science (cs.CE)",
        "abstract": "Automated guided vehicles (AGVs) are widely used in various industries, and scheduling and routing them in a conflict-free manner is crucial to their efficient operation. We propose a loop-based algorithm that solves the online, conflict-free scheduling and routing problem for AGVs with any capacity and ordered jobs in loop-based graphs. The proposed algorithm is compared against an exact method, a greedy heuristic and a metaheuristic. We experimentally show, using theoretical and real instances on a model representing a real manufacturing plant, that this algorithm either outperforms the other algorithms or gets an equally good solution in less computing time.\n    ",
        "primary_category": "cs.CE",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "3 Oct 2023",
        "last_revised_date": " "
    },
    "2310.02207": {
        "title": "Language Models Represent Space and Time",
        "authors": [
            "Wes Gurnee",
            "Max Tegmark"
        ],
        "comments": " ",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "The capabilities of large language models (LLMs) have sparked debate over whether such systems just learn an enormous collection of superficial statistics or a set of more coherent and grounded representations that reflect the real world. We find evidence for the latter by analyzing the learned representations of three spatial datasets (world, US, NYC places) and three temporal datasets (historical figures, artworks, news headlines) in the Llama-2 family of models. We discover that LLMs learn linear representations of space and time across multiple scales. These representations are robust to prompting variations and unified across different entity types (e.g. cities and landmarks). In addition, we identify individual \"space neurons\" and \"time neurons\" that reliably encode spatial and temporal coordinates. While further investigation is needed, our results suggest modern LLMs learn rich spatiotemporal representations of the real world and possess basic ingredients of a world model.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.AI",
            "cs.CL"
        ],
        "submitted_date": "3 Oct 2023",
        "last_revised_date": " "
    },
    "2310.02304": {
        "title": "Self-Taught Optimizer (STOP): Recursively Self-Improving Code Generation",
        "authors": [
            "Eric Zelikman",
            "Eliana Lorch",
            "Lester Mackey",
            "Adam Tauman Kalai"
        ],
        "comments": " ",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "Several recent advances in AI systems (e.g., Tree-of-Thoughts and Program-Aided Language Models) solve problems by providing a \"scaffolding\" program that structures multiple calls to language models to generate better outputs. A scaffolding program is written in a programming language such as Python. In this work, we use a language-model-infused scaffolding program to improve itself. We start with a seed \"improver\" that improves an input program according to a given utility function by querying a language model several times and returning the best solution. We then run this seed improver to improve itself. Across a small set of downstream tasks, the resulting improved improver generates programs with significantly better performance than its seed improver. A variety of self-improvement strategies are proposed by the language model, including beam search, genetic algorithms, and simulated annealing. Since the language models themselves are not altered, this is not full recursive self-improvement. Nonetheless, it demonstrates that a modern language model, GPT-4 in our experiments, is capable of writing code that can call itself to improve itself. We consider concerns around the development of self-improving technologies and evaluate the frequency with which the generated code bypasses a sandbox.\n    ",
        "primary_category": "cs.CL",
        "categories": [
            "cs.AI",
            "cs.LG",
            "stat.ML"
        ],
        "submitted_date": "3 Oct 2023",
        "last_revised_date": " "
    },
    "2310.02432": {
        "title": "Beyond Dark Patterns: A Concept-Based Framework for Ethical Software Design",
        "authors": [
            "Evan Caragay",
            "Katherine Xiong",
            "Jonathan Zong",
            "Daniel Jackson"
        ],
        "comments": "ACM CHI 2024",
        "subjects": "Human-Computer Interaction (cs.HC)",
        "abstract": "Current dark pattern research tells designers what not to do, but how do they know what to do? In contrast to prior approaches that focus on patterns to avoid and their underlying principles, we present a framework grounded in positive expected behavior against which deviations can be judged. To articulate this expected behavior, we use concepts -- abstract units of functionality that compose applications. We define a design as dark when its concepts violate users' expectations, and benefit the application provider at the user's expense. Though user expectations can differ, users tend to develop common expectations as they encounter the same concepts across multiple applications, which we can record in a concept catalog as standard concepts. We evaluate our framework and concept catalog through three studies, illustrating their ability to describe existing dark patterns, evaluate nuanced designs, and document common application functionality.\n    ",
        "primary_category": "cs.HC",
        "categories": [
            "cs.SE"
        ],
        "submitted_date": "3 Oct 2023",
        "last_revised_date": " "
    },
    "2310.02592": {
        "title": "A Faster Deterministic Approximation Algorithm for TTP-2",
        "authors": [
            "Yuga Kanaya",
            "Kenjiro Takazawa"
        ],
        "comments": "27 pages, 42 figures",
        "subjects": "Data Structures and Algorithms (cs.DS)",
        "abstract": "The traveling tournament problem (TTP) is to minimize the total traveling distance of all teams in a double round-robin tournament. In this paper, we focus on TTP-2, in which each team plays at most two consecutive home games and at most two consecutive away games. For the case where the number of teams $n\\equiv2$ (mod 4), Zhao and Xiao (2022) presented a $(1+5/n)$-approximation algorithm. This is a randomized algorithm running in $O(n^3)$ time, and its derandomized version runs in $O(n^4)$ time. In this paper, we present a faster deterministic algorithm running in $O(n^3)$ time, with approximation ratio $1+9/n$. This ratio improves the previous approximation ratios of the deterministic algorithms with the same time complexity.\n    ",
        "primary_category": "cs.DS",
        "categories": [
            "math.CO"
        ],
        "submitted_date": "4 Oct 2023",
        "last_revised_date": " "
    },
    "2310.02954": {
        "title": "DQ-LoRe: Dual Queries with Low Rank Approximation Re-ranking for In-Context Learning",
        "authors": [
            "Jing Xiong",
            "Zixuan Li",
            "Chuanyang Zheng",
            "Zhijiang Guo",
            "Yichun Yin",
            "Enze Xie",
            "Zhicheng Yang",
            "Qingxing Cao",
            "Haiming Wang",
            "Xiongwei Han",
            "Jing Tang",
            "Chengming Li",
            "Xiaodan Liang"
        ],
        "comments": "Accepted in ICLR 2024",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "Recent advances in natural language processing, primarily propelled by Large Language Models (LLMs), have showcased their remarkable capabilities grounded in in-context learning. A promising avenue for guiding LLMs in intricate reasoning tasks involves the utilization of intermediate reasoning steps within the Chain-of-Thought (CoT) paradigm. Nevertheless, the central challenge lies in the effective selection of exemplars for facilitating in-context learning. In this study, we introduce a framework that leverages Dual Queries and Low-rank approximation Re-ranking (DQ-LoRe) to automatically select exemplars for in-context learning. Dual Queries first query LLM to obtain LLM-generated knowledge such as CoT, then query the retriever to obtain the final exemplars via both question and the knowledge. Moreover, for the second query, LoRe employs dimensionality reduction techniques to refine exemplar selection, ensuring close alignment with the input question's knowledge. Through extensive experiments, we demonstrate that DQ-LoRe significantly outperforms prior state-of-the-art methods in the automatic selection of exemplars for GPT-4, enhancing performance from 92.5% to 94.2%. Our comprehensive analysis further reveals that DQ-LoRe consistently outperforms retrieval-based approaches in terms of both performance and adaptability, especially in scenarios characterized by distribution shifts. DQ-LoRe pushes the boundary of in-context learning and opens up new avenues for addressing complex reasoning challenges. Our code is released at this https URL}{this https URL.\n    ",
        "primary_category": "cs.CL",
        "categories": [],
        "submitted_date": "4 Oct 2023",
        "last_revised_date": " "
    },
    "2310.03234": {
        "title": "Non-Smooth Weakly-Convex Finite-sum Coupled Compositional Optimization",
        "authors": [
            "Quanqi Hu",
            "Dixian Zhu",
            "Tianbao Yang"
        ],
        "comments": " ",
        "subjects": "Optimization and Control (math.OC)",
        "abstract": "This paper investigates new families of compositional optimization problems, called $\\underline{\\bf n}$on-$\\underline{\\bf s}$mooth $\\underline{\\bf w}$eakly-$\\underline{\\bf c}$onvex $\\underline{\\bf f}$inite-sum $\\underline{\\bf c}$oupled $\\underline{\\bf c}$ompositional $\\underline{\\bf o}$ptimization (NSWC FCCO). There has been a growing interest in FCCO due to its wide-ranging applications in machine learning and AI, as well as its ability to address the shortcomings of stochastic algorithms based on empirical risk minimization. However, current research on FCCO presumes that both the inner and outer functions are smooth, limiting their potential to tackle a more diverse set of problems. Our research expands on this area by examining non-smooth weakly-convex FCCO, where the outer function is weakly convex and non-decreasing, and the inner function is weakly-convex. We analyze a single-loop algorithm and establish its complexity for finding an $\\epsilon$-stationary point of the Moreau envelop of the objective function. Additionally, we also extend the algorithm to solving novel non-smooth weakly-convex tri-level finite-sum coupled compositional optimization problems, which feature a nested arrangement of three functions. Lastly, we explore the applications of our algorithms in deep learning for two-way partial AUC maximization and multi-instance two-way partial AUC maximization, using empirical studies to showcase the effectiveness of the proposed algorithms.\n    ",
        "primary_category": "math.OC",
        "categories": [
            "cs.AI",
            "cs.LG",
            "stat.ML"
        ],
        "submitted_date": "5 Oct 2023",
        "last_revised_date": " "
    },
    "2310.03309": {
        "title": "Concise and Organized Perception Facilitates Large Language Models for Deductive Reasoning",
        "authors": [
            "Shaotian Yan",
            "Chen Shen",
            "Junjie Liu",
            "Jieping Ye"
        ],
        "comments": "16 pages",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "Exploiting large language models (LLMs) to tackle deductive reasoning has garnered growing attention. It still remains highly challenging to achieve satisfactory results in complex deductive problems, characterized by plenty of premises (i.e., facts or rules) entailing intricate relationships among entities and requiring multi-hop reasoning. One intuitive solution is to decompose the original task into smaller sub-tasks, and then chain the multiple casual reasoning steps together in a forward (e.g., Selection-Inference) or backward (e.g., LAMBADA) direction. However, these techniques inevitably necessitate a large number of overall stages, leading to computationally expensive operations and a higher possibility of making misleading steps. In addition to stage-by-stage decomposition, we draw inspiration from another aspect of human problem-solving. Humans tend to distill the most relevant information and organize their thoughts systematically (e.g., creating mind maps), which assists them in answering questions or drawing conclusions precisely and quickly. In light of this, we propose a novel reasoning approach named Concise and Organized Perception (COP). COP carefully analyzes the given statements to efficiently identify the most pertinent information while eliminating redundancy. It then prompts the LLMs in a more organized form that adapts to the model's inference process. By perceiving concise and organized proofs, the deductive reasoning abilities of LLMs can be better elicited, and the risk of acquiring errors caused by excessive reasoning stages is mitigated. Furthermore, our approach can be combined with the aforementioned ones to further boost their performance. Extensive experimental results on three popular deductive benchmarks (i.e., ProofWriter, PrOntoQA and PrOntoQA-OOD) show that COP significantly outperforms previous state-of-the-art methods.\n    ",
        "primary_category": "cs.CL",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "5 Oct 2023",
        "last_revised_date": " "
    },
    "2310.03560": {
        "title": "Redefining Digital Health Interfaces with Large Language Models",
        "authors": [
            "Fergus Imrie",
            "Paulius Rauba",
            "Mihaela van der Schaar"
        ],
        "comments": " ",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "Digital health tools have the potential to significantly improve the delivery of healthcare services. However, their adoption remains comparatively limited due, in part, to challenges surrounding usability and trust. Large Language Models (LLMs) have emerged as general-purpose models with the ability to process complex information and produce human-quality text, presenting a wealth of potential applications in healthcare. Directly applying LLMs in clinical settings is not straightforward, however, with LLMs susceptible to providing inconsistent or nonsensical answers. We demonstrate how LLM-based systems can utilize external tools and provide a novel interface between clinicians and digital technologies. This enhances the utility and practical impact of digital healthcare tools and AI models while addressing current issues with using LLMs in clinical settings such as hallucinations. We illustrate LLM-based interfaces with the example of cardiovascular disease risk prediction. We develop a new prognostic tool using automated machine learning and demonstrate how LLMs can provide a unique interface to both our model and existing risk scores, highlighting the benefit compared to traditional interfaces for digital tools.\n    ",
        "primary_category": "cs.CL",
        "categories": [],
        "submitted_date": "5 Oct 2023",
        "last_revised_date": " "
    },
    "2310.03637": {
        "title": "Solving Degree Bounds For Iterated Polynomial Systems",
        "authors": [
            "Matthias Johann Steiner"
        ],
        "comments": " ",
        "subjects": "Cryptography and Security (cs.CR)",
        "abstract": "For Arithmetization-Oriented ciphers and hash functions Gr\u00f6bner basis attacks are generally considered as the most competitive attack vector. Unfortunately, the complexity of Gr\u00f6bner basis algorithms is only understood for special cases, and it is needless to say that these cases do not apply to most cryptographic polynomial systems. Therefore, cryptographers have to resort to experiments, extrapolations and hypotheses to assess the security of their designs. One established measure to quantify the complexity of linear algebra-based Gr\u00f6bner basis algorithms is the so-called solving degree. Caminata \\& Gorla revealed that under a certain genericity condition on a polynomial system the solving degree is always upper bounded by the Castelnuovo-Mumford regularity and henceforth by the Macaulay bound, which only takes the degrees and number of variables of the input polynomials into account. In this paper we extend their framework to iterated polynomial systems, the standard polynomial model for symmetric ciphers and hash functions. In particular, we prove solving degree bounds for various attacks on MiMC, Feistel-MiMC, Feistel-MiMC-Hash, Hades and GMiMC. Our bounds fall in line with the hypothesized complexity of Gr\u00f6bner basis attacks on these designs, and to the best of our knowledge this is the first time that a mathematical proof for these complexities is provided.\nMoreover, by studying polynomials with degree falls we can prove lower bounds on the Castelnuovo-Mumford regularity for attacks on MiMC, Feistel-MiMC and Feistel-MiMC-Hash provided that only a few solutions of the corresponding iterated polynomial system originate from the base field. Hence, regularity-based solving degree estimations can never surpass a certain threshold, a desirable property for cryptographic polynomial systems.\n    ",
        "primary_category": "cs.CR",
        "categories": [
            "math.AC"
        ],
        "submitted_date": "5 Oct 2023",
        "last_revised_date": " "
    },
    "2310.04418": {
        "title": "Functional Interpolation for Relative Positions Improves Long Context Transformers",
        "authors": [
            "Shanda Li",
            "Chong You",
            "Guru Guruganesh",
            "Joshua Ainslie",
            "Santiago Ontanon",
            "Manzil Zaheer",
            "Sumit Sanghai",
            "Yiming Yang",
            "Sanjiv Kumar",
            "Srinadh Bhojanapalli"
        ],
        "comments": "26 pages; ICLR 2024 camera ready version",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Preventing the performance decay of Transformers on inputs longer than those used for training has been an important challenge in extending the context length of these models. Though the Transformer architecture has fundamentally no limits on the input sequence lengths it can process, the choice of position encoding used during training can limit the performance of these models on longer inputs. We propose a novel functional relative position encoding with progressive interpolation, FIRE, to improve Transformer generalization to longer contexts. We theoretically prove that this can represent some of the popular relative position encodings, such as T5's RPE, Alibi, and Kerple. We next empirically show that FIRE models have better generalization to longer contexts on both zero-shot language modeling and long text benchmarks.\n    ",
        "primary_category": "cs.LG",
        "categories": [],
        "submitted_date": "6 Oct 2023",
        "last_revised_date": " "
    },
    "2310.05207": {
        "title": "Boosting Facial Action Unit Detection Through Jointly Learning Facial Landmark Detection and Domain Separation and Reconstruction",
        "authors": [
            "Ziqiao Shang",
            "Li Yu"
        ],
        "comments": "5 pages, 1 figure",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Recently how to introduce large amounts of unlabeled facial images in the wild into supervised Facial Action Unit (AU) detection frameworks has become a challenging problem. In this paper, we propose a new AU detection framework where multi-task learning is introduced to jointly learn AU domain separation and reconstruction and facial landmark detection by sharing the parameters of homostructural facial extraction modules. In addition, we propose a new feature alignment scheme based on contrastive learning by simple projectors and an improved contrastive loss, which adds four additional intermediate supervisors to promote the feature reconstruction process. Experimental results on two benchmarks demonstrate our superiority against the state-of-the-art methods for AU detection in the wild.\n    ",
        "primary_category": "cs.CV",
        "categories": [
            "cs.AI",
            "cs.LG"
        ],
        "submitted_date": "8 Oct 2023",
        "last_revised_date": " "
    },
    "2310.05245": {
        "title": "Influence of Camera-LiDAR Configuration on 3D Object Detection for Autonomous Driving",
        "authors": [
            "Ye Li",
            "Hanjiang Hu",
            "Zuxin Liu",
            "Xiaohao Xu",
            "Xiaonan Huang",
            "Ding Zhao"
        ],
        "comments": " ",
        "subjects": "Robotics (cs.RO)",
        "abstract": "Cameras and LiDARs are both important sensors for autonomous driving, playing critical roles in 3D object detection. Camera-LiDAR Fusion has been a prevalent solution for robust and accurate driving perception. In contrast to the vast majority of existing arts that focus on how to improve the performance of 3D target detection through cross-modal schemes, deep learning algorithms, and training tricks, we devote attention to the impact of sensor configurations on the performance of learning-based methods. To achieve this, we propose a unified information-theoretic surrogate metric for camera and LiDAR evaluation based on the proposed sensor perception model. We also design an accelerated high-quality framework for data acquisition, model training, and performance evaluation that functions with the CARLA simulator. To show the correlation between detection performance and our surrogate metrics, We conduct experiments using several camera-LiDAR placements and parameters inspired by self-driving companies and research institutions. Extensive experimental results of representative algorithms on nuScenes dataset validate the effectiveness of our surrogate metric, demonstrating that sensor configurations significantly impact point-cloud-image fusion based detection models, which contribute up to 30% discrepancy in terms of the average precision.\n    ",
        "primary_category": "cs.RO",
        "categories": [],
        "submitted_date": "8 Oct 2023",
        "last_revised_date": " "
    },
    "2310.05670": {
        "title": "Reinforcement learning for freeform robot design",
        "authors": [
            "Muhan Li",
            "David Matthews",
            "Sam Kriegman"
        ],
        "comments": " ",
        "subjects": "Robotics (cs.RO)",
        "abstract": "Inspired by the necessity of morphological adaptation in animals, a growing body of work has attempted to expand robot training to encompass physical aspects of a robot's design. However, reinforcement learning methods capable of optimizing the 3D morphology of a robot have been restricted to reorienting or resizing the limbs of a predetermined and static topological genus. Here we show policy gradients for designing freeform robots with arbitrary external and internal structure. This is achieved through actions that deposit or remove bundles of atomic building blocks to form higher-level nonparametric macrostructures such as appendages, organs and cavities. Although results are provided for open loop control only, we discuss how this method could be adapted for closed loop control and sim2real transfer to physical machines in future.\n    ",
        "primary_category": "cs.RO",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "9 Oct 2023",
        "last_revised_date": " "
    },
    "2310.05696": {
        "title": "Protecting Sensitive Data through Federated Co-Training",
        "authors": [
            "Amr Abourayya",
            "Jens Kleesiek",
            "Kanishka Rao",
            "Erman Ayday",
            "Bharat Rao",
            "Geoff Webb",
            "Michael Kamp"
        ],
        "comments": " ",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "In many applications, sensitive data is inherently distributed and may not be pooled due to privacy concerns. Federated learning allows us to collaboratively train a model without pooling the data by iteratively aggregating the parameters of local models. It is possible, though, to infer upon the sensitive data from the shared model parameters. We propose to use a federated co-training approach where clients share hard labels on a public unlabeled dataset instead of model parameters. A consensus on the shared labels forms a pseudo labeling for the unlabeled dataset that clients use in combination with their private data to train local models. We show that sharing hard labels substantially improves privacy over sharing model parameters. At the same time, federated co-training achieves a model quality comparable to federated learning. Moreover, it allows us to use local models such as (gradient boosted) decision trees, rule ensembles, and random forests that do not lend themselves to the parameter aggregation used in federated learning.\n    ",
        "primary_category": "cs.LG",
        "categories": [],
        "submitted_date": "9 Oct 2023",
        "last_revised_date": " "
    },
    "2310.05808": {
        "title": "An Open-Loop Baseline for Reinforcement Learning Locomotion Tasks",
        "authors": [
            "Antonin Raffin",
            "Olivier Sigaud",
            "Jens Kober",
            "Alin Albu-Sch\u00e4ffer",
            "Jo\u00e3o Silv\u00e9rio",
            "Freek Stulp"
        ],
        "comments": "video: this https URL minimal code: this https URL",
        "subjects": "Robotics (cs.RO)",
        "abstract": "In search of a simple baseline for Deep Reinforcement Learning in locomotion tasks, we propose a model-free open-loop strategy. By leveraging prior knowledge and the elegance of simple oscillators to generate periodic joint motions, it achieves respectable performance in five different locomotion environments, with a number of tunable parameters that is a tiny fraction of the thousands typically required by DRL algorithms. We conduct two additional experiments using open-loop oscillators to identify current shortcomings of these algorithms. Our results show that, compared to the baseline, DRL is more prone to performance degradation when exposed to sensor noise or failure. Furthermore, we demonstrate a successful transfer from simulation to reality using an elastic quadruped, where RL fails without randomization or reward engineering. Overall, the proposed baseline and associated experiments highlight the existing limitations of DRL for robotic applications, provide insights on how to address them, and encourage reflection on the costs of complexity and generality.\n    ",
        "primary_category": "cs.RO",
        "categories": [],
        "submitted_date": "9 Oct 2023",
        "last_revised_date": " "
    },
    "2310.05922": {
        "title": "FLATTEN: optical FLow-guided ATTENtion for consistent text-to-video editing",
        "authors": [
            "Yuren Cong",
            "Mengmeng Xu",
            "Christian Simon",
            "Shoufa Chen",
            "Jiawei Ren",
            "Yanping Xie",
            "Juan-Manuel Perez-Rua",
            "Bodo Rosenhahn",
            "Tao Xiang",
            "Sen He"
        ],
        "comments": "Accepted by ICLR2024. Project page: this https URL",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Text-to-video editing aims to edit the visual appearance of a source video conditional on textual prompts. A major challenge in this task is to ensure that all frames in the edited video are visually consistent. Most recent works apply advanced text-to-image diffusion models to this task by inflating 2D spatial attention in the U-Net into spatio-temporal attention. Although temporal context can be added through spatio-temporal attention, it may introduce some irrelevant information for each patch and therefore cause inconsistency in the edited video. In this paper, for the first time, we introduce optical flow into the attention module in the diffusion model's U-Net to address the inconsistency issue for text-to-video editing. Our method, FLATTEN, enforces the patches on the same flow path across different frames to attend to each other in the attention module, thus improving the visual consistency in the edited videos. Additionally, our method is training-free and can be seamlessly integrated into any diffusion-based text-to-video editing methods and improve their visual consistency. Experiment results on existing text-to-video editing benchmarks show that our proposed method achieves the new state-of-the-art performance. In particular, our method excels in maintaining the visual consistency in the edited videos.\n    ",
        "primary_category": "cs.CV",
        "categories": [],
        "submitted_date": "9 Oct 2023",
        "last_revised_date": " "
    },
    "2310.06185": {
        "title": "Tight Bounds for the Maximum Distance Over a Polytope to a Given Point",
        "authors": [
            "Marius Costandin",
            "Beniamin Costandin"
        ],
        "comments": "arXiv admin note: text overlap with arXiv:2308.15054",
        "subjects": "Optimization and Control (math.OC)",
        "abstract": "In this paper we study the problem of maximizing the distance to a given point $C_0$ over a polytope $\\mathcal{P}$. Assuming that the polytope is circumscribed by a known ball we construct an intersection of balls which preserves the vertices of the polytope on the boundary of this ball, and show that the intersection of balls approximates the polytope arbitrarily well. Then, we use some known results regarding the maximization of distances to a given point over an intersection of balls to create a new polytope which preserves the maximizers to the original problem. Next, a new intersection of balls is obtained in a similar fashion, and as such, after a finite number of iterations, we conjecture, we end up with an intersection of balls over which we can maximize the distance to the given point. The obtained distance is shown to be a non trivial upper bound to the original distance. Tests are made with maximizing the distance to a random point over the unit hypercube up to dimension $n = 100$. Several detailed 2-d examples are also shown.\n    ",
        "primary_category": "math.OC",
        "categories": [
            "cs.DM"
        ],
        "submitted_date": "9 Oct 2023",
        "last_revised_date": " "
    },
    "2310.06356": {
        "title": "A Semantic Invariant Robust Watermark for Large Language Models",
        "authors": [
            "Aiwei Liu",
            "Leyi Pan",
            "Xuming Hu",
            "Shiao Meng",
            "Lijie Wen"
        ],
        "comments": "ICLR2024, 21 pages, 10 figures, 6 tables",
        "subjects": "Cryptography and Security (cs.CR)",
        "abstract": "Watermark algorithms for large language models (LLMs) have achieved extremely high accuracy in detecting text generated by LLMs. Such algorithms typically involve adding extra watermark logits to the LLM's logits at each generation step. However, prior algorithms face a trade-off between attack robustness and security robustness. This is because the watermark logits for a token are determined by a certain number of preceding tokens; a small number leads to low security robustness, while a large number results in insufficient attack robustness. In this work, we propose a semantic invariant watermarking method for LLMs that provides both attack robustness and security robustness. The watermark logits in our work are determined by the semantics of all preceding tokens. Specifically, we utilize another embedding LLM to generate semantic embeddings for all preceding tokens, and then these semantic embeddings are transformed into the watermark logits through our trained watermark model. Subsequent analyses and experiments demonstrated the attack robustness of our method in semantically invariant settings: synonym substitution and text paraphrasing settings. Finally, we also show that our watermark possesses adequate security robustness. Our code and data are available at this https URL.\n    ",
        "primary_category": "cs.CR",
        "categories": [
            "cs.CL"
        ],
        "submitted_date": "10 Oct 2023",
        "last_revised_date": " "
    },
    "2310.06474": {
        "title": "Multilingual Jailbreak Challenges in Large Language Models",
        "authors": [
            "Yue Deng",
            "Wenxuan Zhang",
            "Sinno Jialin Pan",
            "Lidong Bing"
        ],
        "comments": "ICLR 2024",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "While large language models (LLMs) exhibit remarkable capabilities across a wide range of tasks, they pose potential safety concerns, such as the ``jailbreak'' problem, wherein malicious instructions can manipulate LLMs to exhibit undesirable behavior. Although several preventive measures have been developed to mitigate the potential risks associated with LLMs, they have primarily focused on English. In this study, we reveal the presence of multilingual jailbreak challenges within LLMs and consider two potential risky scenarios: unintentional and intentional. The unintentional scenario involves users querying LLMs using non-English prompts and inadvertently bypassing the safety mechanisms, while the intentional scenario concerns malicious users combining malicious instructions with multilingual prompts to deliberately attack LLMs. The experimental results reveal that in the unintentional scenario, the rate of unsafe content increases as the availability of languages decreases. Specifically, low-resource languages exhibit about three times the likelihood of encountering harmful content compared to high-resource languages, with both ChatGPT and GPT-4. In the intentional scenario, multilingual prompts can exacerbate the negative impact of malicious instructions, with astonishingly high rates of unsafe output: 80.92\\% for ChatGPT and 40.71\\% for GPT-4. To handle such a challenge in the multilingual context, we propose a novel \\textsc{Self-Defense} framework that automatically generates multilingual training data for safety fine-tuning. Experimental results show that ChatGPT fine-tuned with such data can achieve a substantial reduction in unsafe content generation. Data is available at \\url{this https URL}.\n    ",
        "primary_category": "cs.CL",
        "categories": [],
        "submitted_date": "10 Oct 2023",
        "last_revised_date": " "
    },
    "2310.06543": {
        "title": "An Edge-Aware Graph Autoencoder Trained on Scale-Imbalanced Data for Traveling Salesman Problems",
        "authors": [
            "Shiqing Liu",
            "Xueming Yan",
            "Yaochu Jin"
        ],
        "comments": "37 pages, 7 figures. Accepted by Knowledge-based Systems",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "In recent years, there has been a notable surge in research on machine learning techniques for combinatorial optimization. It has been shown that learning-based methods outperform traditional heuristics and mathematical solvers on the Traveling Salesman Problem (TSP) in terms of both performance and computational efficiency. However, most learning-based TSP solvers are primarily designed for fixed-scale TSP instances, and also require a large number of training samples to achieve optimal performance. To fill this gap, this work proposes a data-driven graph representation learning method for solving TSPs with various numbers of cities. Specifically, we formulate the TSP as a link prediction task and propose an edge-aware graph autoencoder (EdgeGAE) model that can solve TSPs by learning from various-scale samples with an imbalanced distribution. A residual gated encoder is trained to learn latent edge embeddings, followed by an edge-centered decoder to output link predictions in an end-to-end manner. Furthermore, we introduce an active sampling strategy into the training process to improve the model's generalization capability in large-scale scenarios. To investigate the model's practical applicability, we generate a scale-imbalanced dataset comprising 50,000 TSP instances ranging from 50 to 500 cities. The experimental results demonstrate that the proposed edge-aware graph autoencoder model achieves a highly competitive performance among state-of-the-art graph learning-based approaches in solving TSPs with various scales, implying its remarkable potential in dealing with practical optimization challenges.\n    ",
        "primary_category": "cs.LG",
        "categories": [],
        "submitted_date": "10 Oct 2023",
        "last_revised_date": " "
    },
    "2310.06836": {
        "title": "What Does Stable Diffusion Know about the 3D Scene?",
        "authors": [
            "Guanqi Zhan",
            "Chuanxia Zheng",
            "Weidi Xie",
            "Andrew Zisserman"
        ],
        "comments": " ",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Recent advances in generative models like Stable Diffusion enable the generation of highly photo-realistic images. Our objective in this paper is to probe the diffusion network to determine to what extent it 'understands' different properties of the 3D scene depicted in an image. To this end, we make the following contributions: (i) We introduce a protocol to evaluate whether features of an off-the-shelf diffusion model encode a number of physical 'properties' of the 3D scene, by training discriminative classifiers on the features for these properties. The probes are applied on datasets of real images with annotations for the property. (ii) We apply this protocol to properties covering scene geometry, scene material, support relations, lighting, and view dependent measures. (iii) We find that features from Stable Diffusion are good for discriminative learning of a number of properties, including scene geometry, support relations, shadows and depth, but less performant for occlusion and material. (iv) We also apply the probes to other networks trained at large-scale, including DINO, CLIP and VQGAN, and find that DINOv2 has a similar performance to Stable Diffusion, while outperforming DINOv1, CLIP and VQGAN.\n    ",
        "primary_category": "cs.CV",
        "categories": [],
        "submitted_date": "10 Oct 2023",
        "last_revised_date": " "
    },
    "2310.07171": {
        "title": "Advocating for the Silent: Enhancing Federated Generalization for Non-Participating Clients",
        "authors": [
            "Zheshun Wu",
            "Zenglin Xu",
            "Dun Zeng",
            "Qifan Wang",
            "Jie Liu"
        ],
        "comments": " ",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Federated Learning (FL) has surged in prominence due to its capability of collaborative model training without direct data sharing. However, the vast disparity in local data distributions among clients, often termed the Non-Independent Identically Distributed (Non-IID) challenge, poses a significant hurdle to FL's generalization efficacy. The scenario becomes even more complex when not all clients participate in the training process, a common occurrence due to unstable network connections or limited computational capacities. This can greatly complicate the assessment of the trained models' generalization abilities. While a plethora of recent studies has centered on the generalization gap pertaining to unseen data from participating clients with diverse distributions, the distinction between the training distributions of participating clients and the testing distributions of non-participating ones has been largely overlooked. In response, our paper unveils an information-theoretic generalization framework for FL. Specifically, it quantifies generalization errors by evaluating the information entropy of local distributions and discerning discrepancies across these distributions. Inspired by our deduced generalization bounds, we introduce a weighted aggregation approach and a duo of client selection strategies. These innovations are designed to strengthen FL's ability to generalize and thus ensure that trained models perform better on non-participating clients by incorporating a more diverse range of client data distributions. Our extensive empirical evaluations reaffirm the potency of our proposed methods, aligning seamlessly with our theoretical construct.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.IT"
        ],
        "submitted_date": "11 Oct 2023",
        "last_revised_date": " "
    },
    "2310.07333": {
        "title": "Computing approximate roots of monotone functions",
        "authors": [
            "Alexandros Hollender",
            "Chester Lawrence",
            "Erel Segal-Halevi"
        ],
        "comments": "We solved all the open cases, except the case when f has 3 or more dimensions, and satisfies all monotonicity conditions except one. Any ideas?",
        "subjects": "Computer Science and Game Theory (cs.GT)",
        "abstract": "Given a function f: [a,b] -> R, if f(a) < 0 and f(b)> 0 and f is continuous, the Intermediate Value Theorem implies that f has a root in [a,b]. Moreover, given a value-oracle for f, an approximate root of f can be computed using the bisection method, and the number of required evaluations is polynomial in the number of accuracy digits. The goal of this note is to identify conditions under which this polynomiality result extends to a multi-dimensional function that satisfies the conditions of Miranda's theorem -- the natural multi-dimensional extension of the Intermediate Value Theorem. In general, finding an approximate root might require an exponential number of evaluations even for a two-dimensional function. We show that, if f is two-dimensional and satisfies a single monotonicity condition, then the number of required evaluations is polynomial in the accuracy. For any fixed dimension d, if f is a d-dimensional function that satisfies all d^2-d ``ex-diagonal'' monotonicity conditions (that is, component i of f is monotonically decreasing with respect to variable j for all i!=j), then the number of required evaluations is polynomial in the accuracy. But if f satisfies only d^2-d-2 ex-diagonal conditions, then the number of required evaluations may be exponential in the accuracy. The case of d^2-d-1 ex-diagonal conditions remains unsolved. As an example application, we show that computing approximate roots of monotone functions can be used for approximate envy-free cake-cutting.\n    ",
        "primary_category": "cs.GT",
        "categories": [
            "math.NA"
        ],
        "submitted_date": "11 Oct 2023",
        "last_revised_date": " "
    },
    "2310.07555": {
        "title": "Does resistance to style-transfer equal Global Shape Bias? Measuring network sensitivity to global shape configuration",
        "authors": [
            "Ziqi Wen",
            "Tianqin Li",
            "Zhi Jing",
            "Tai Sing Lee"
        ],
        "comments": " ",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Deep learning models are known to exhibit a strong texture bias, while human tends to rely heavily on global shape structure for object recognition. The current benchmark for evaluating a model's global shape bias is a set of style-transferred images with the assumption that resistance to the attack of style transfer is related to the development of global structure sensitivity in the model. In this work, we show that networks trained with style-transfer images indeed learn to ignore style, but its shape bias arises primarily from local detail. We provide a \\textbf{Disrupted Structure Testbench (DiST)} as a direct measurement of global structure sensitivity. Our test includes 2400 original images from ImageNet-1K, each of which is accompanied by two images with the global shapes of the original image disrupted while preserving its texture via the texture synthesis program. We found that \\textcolor{black}{(1) models that performed well on the previous cue-conflict dataset do not fare well in the proposed DiST; (2) the supervised trained Vision Transformer (ViT) lose its global spatial information from positional embedding, leading to no significant advantages over Convolutional Neural Networks (CNNs) on DiST. While self-supervised learning methods, especially mask autoencoder significantly improves the global structure sensitivity of ViT. (3) Improving the global structure sensitivity is orthogonal to resistance to style-transfer, indicating that the relationship between global shape structure and local texture detail is not an either/or relationship. Training with DiST images and style-transferred images are complementary, and can be combined to train network together to enhance the global shape sensitivity and robustness of local features.} Our code will be hosted in github: this https URL\n",
        "primary_category": "cs.CV",
        "categories": [],
        "submitted_date": "11 Oct 2023",
        "last_revised_date": " "
    },
    "2310.07576": {
        "title": "Analyzing Trendy Twitter Hashtags in the 2022 French Election",
        "authors": [
            "Aamir Mandviwalla",
            "Lake Yin",
            "Boleslaw K. Szymanski"
        ],
        "comments": "9 pages, 1 figure, published in Complex Networks and their Applications XII",
        "subjects": "Social and Information Networks (cs.SI)",
        "abstract": "Regressions trained to predict the future activity of social media users need rich features for accurate predictions. Many advanced models exist to generate such features; however, the time complexities of their computations are often prohibitive when they run on enormous data-sets. Some studies have shown that simple semantic network features can be rich enough to use for regressions without requiring complex computations. We propose a method for using semantic networks as user-level features for machine learning tasks. We conducted an experiment using a semantic network of 1037 Twitter hashtags from a corpus of 3.7 million tweets related to the 2022 French presidential election. A bipartite graph is formed where hashtags are nodes and weighted edges connect the hashtags reflecting the number of Twitter users that interacted with both hashtags. The graph is then transformed into a maximum-spanning tree with the most popular hashtag as its root node to construct a hierarchy amongst the hashtags. We then provide a vector feature for each user based on this tree. To validate the usefulness of our semantic feature we performed a regression experiment to predict the response rate of each user with six emotions like anger, enjoyment, or disgust. Our semantic feature performs well with the regression with most emotions having $R^2$ above 0.5. These results suggest that our semantic feature could be considered for use in further experiments predicting social media response on big data-sets.\n    ",
        "primary_category": "cs.SI",
        "categories": [
            "cs.LG"
        ],
        "submitted_date": "11 Oct 2023",
        "last_revised_date": " "
    },
    "2310.07649": {
        "title": "Automated Layout Design and Control of Robust Cooperative Grasped-Load Aerial Transportation Systems",
        "authors": [
            "Carlo Bosio",
            "Jerry Tang",
            "Ting-Hao Wang",
            "Mark W. Mueller"
        ],
        "comments": "7 pages, 7 figures, conference paper",
        "subjects": "Robotics (cs.RO)",
        "abstract": "We present a novel approach to cooperative aerial transportation through a team of drones, using optimal control theory and a hierarchical control strategy. We assume the drones are connected to the payload through rigid attachments, essentially transforming the whole system into a larger flying object with \"thrust modules\" at the attachment locations of the drones. We investigate the optimal arrangement of the thrust modules around the payload, so that the resulting system is robust to disturbances. We choose the $\\mathcal{H}_2$ norm as a measure of robustness, and propose an iterative optimization routine to compute the optimal layout of the vehicles around the object. We experimentally validate our approach using four drones and comparing the disturbance rejection performances achieved by two different layouts (the optimal one and a sub-optimal one), and observe that the results match our predictions.\n    ",
        "primary_category": "cs.RO",
        "categories": [
            "eess.SY"
        ],
        "submitted_date": "11 Oct 2023",
        "last_revised_date": " "
    },
    "2310.07779": {
        "title": "Social Approval and Network Homophily as Motivators of Online Toxicity",
        "authors": [
            "Julie Jiang",
            "Luca Luceri",
            "Joseph B. Walther",
            "Emilio Ferrara"
        ],
        "comments": " ",
        "subjects": "Social and Information Networks (cs.SI)",
        "abstract": "Online hate messaging is a pervasive issue plaguing the well-being of social media users. This research empirically investigates a novel theory positing that online hate may be driven primarily by the pursuit of social approval rather than a direct desire to harm the targets. Results show that toxicity is homophilous in users' social networks and that a user's propensity for hostility can be predicted by their social networks. We also illustrate how receiving greater or fewer social engagements in the form of likes, retweets, quotes, and replies affects a user's subsequent toxicity. We establish a clear connection between receiving social approval signals and increases in subsequent toxicity. Being retweeted plays a particularly prominent role in escalating toxicity. Results also show that not receiving expected levels of social approval leads to decreased toxicity. We discuss the important implications of our research and opportunities to combat online hate.\n    ",
        "primary_category": "cs.SI",
        "categories": [],
        "submitted_date": "11 Oct 2023",
        "last_revised_date": " "
    },
    "2310.07855": {
        "title": "CrIBo: Self-Supervised Learning via Cross-Image Object-Level Bootstrapping",
        "authors": [
            "Tim Lebailly",
            "Thomas Stegm\u00fcller",
            "Behzad Bozorgtabar",
            "Jean-Philippe Thiran",
            "Tinne Tuytelaars"
        ],
        "comments": "ICLR 2024 (spotlight)",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Leveraging nearest neighbor retrieval for self-supervised representation learning has proven beneficial with object-centric images. However, this approach faces limitations when applied to scene-centric datasets, where multiple objects within an image are only implicitly captured in the global representation. Such global bootstrapping can lead to undesirable entanglement of object representations. Furthermore, even object-centric datasets stand to benefit from a finer-grained bootstrapping approach. In response to these challenges, we introduce a novel Cross-Image Object-Level Bootstrapping method tailored to enhance dense visual representation learning. By employing object-level nearest neighbor bootstrapping throughout the training, CrIBo emerges as a notably strong and adequate candidate for in-context learning, leveraging nearest neighbor retrieval at test time. CrIBo shows state-of-the-art performance on the latter task while being highly competitive in more standard downstream segmentation tasks. Our code and pretrained models are publicly available at this https URL.\n    ",
        "primary_category": "cs.CV",
        "categories": [
            "cs.LG"
        ],
        "submitted_date": "11 Oct 2023",
        "last_revised_date": " "
    },
    "2310.07898": {
        "title": "FlorDB: Multiversion Hindsight Logging for Continuous Training",
        "authors": [
            "Rolando Garcia",
            "Anusha Dandamudi",
            "Gabriel Matute",
            "Lehan Wan",
            "Joseph Gonzalez",
            "Joseph M. Hellerstein",
            "Koushik Sen"
        ],
        "comments": " ",
        "subjects": "Software Engineering (cs.SE)",
        "abstract": "Production Machine Learning involves continuous training: hosting multiple versions of models over time, often with many model versions running at once. When model performance does not meet expectations, Machine Learning Engineers (MLEs) debug issues by exploring and analyzing numerous prior versions of code and training data to identify root causes and mitigate problems. Traditional debugging and logging tools often fall short in managing this experimental, multi-version context. FlorDB introduces Multiversion Hindsight Logging, which allows engineers to use the most recent version's logging statements to query past versions, even when older versions logged different data. Log statement propagation enables consistent injection of logging statements into past code versions, regardless of changes to the codebase. Once log statements are propagated across code versions, the remaining challenge in Multiversion Hindsight Logging is to efficiently replay the new log statements based on checkpoints from previous runs. Finally, a coherent user experience is required to help MLEs debug across all versions of code and data. To this end, FlorDB presents a unified relational model for efficient handling of historical queries, offering a comprehensive view of the log history to simplify the exploration of past code iterations. We present a performance evaluation on diverse benchmarks confirming its scalability and the ability to deliver real-time query responses, leveraging query-based filtering and checkpoint-based parallelism for efficient replay.\n    ",
        "primary_category": "cs.SE",
        "categories": [
            "cs.DB"
        ],
        "submitted_date": "11 Oct 2023",
        "last_revised_date": " "
    },
    "2310.08031": {
        "title": "Local Graph Clustering with Noisy Labels",
        "authors": [
            "Artur Back de Luca",
            "Kimon Fountoulakis",
            "Shenghao Yang"
        ],
        "comments": "30 pages, 5 figures, 18 tables",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "The growing interest in machine learning problems over graphs with additional node information such as texts, images, or labels has popularized methods that require the costly operation of processing the entire graph. Yet, little effort has been made to the development of fast local methods (i.e. without accessing the entire graph) that extract useful information from such data. To that end, we propose a study of local graph clustering using noisy node labels as a proxy for additional node information. In this setting, nodes receive initial binary labels based on cluster affiliation: 1 if they belong to the target cluster and 0 otherwise. Subsequently, a fraction of these labels is flipped. We investigate the benefits of incorporating noisy labels for local graph clustering. By constructing a weighted graph with such labels, we study the performance of graph diffusion-based local clustering method on both the original and the weighted graphs. From a theoretical perspective, we consider recovering an unknown target cluster with a single seed node in a random graph with independent noisy node labels. We provide sufficient conditions on the label noise under which, with high probability, using diffusion in the weighted graph yields a more accurate recovery of the target cluster. This approach proves more effective than using the given labels alone or using diffusion in the label-free original graph. Empirically, we show that reliable node labels can be obtained with just a few samples from an attributed graph. Moreover, utilizing these labels via diffusion in the weighted graph leads to significantly better local clustering performance across several real-world datasets, improving F1 scores by up to 13%.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.SI",
            "stat.ML"
        ],
        "submitted_date": "12 Oct 2023",
        "last_revised_date": " "
    },
    "2310.08224": {
        "title": "Emergence of Latent Binary Encoding in Deep Neural Network Classifiers",
        "authors": [
            "Luigi Sbail\u00f2",
            "Luca Ghiringhelli"
        ],
        "comments": " ",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "We investigate the emergence of binary encoding within the latent space of deep-neural-network classifiers. Such binary encoding is induced by the integration of a linear penultimate layer, which employs during training a loss function specifically designed to compress the latent representations. As a result of a trade-off between compression and information retention, the network learns to assume only one of two possible values for each dimension in the latent space. The binary encoding is provoked by the collapse of all representations of the same class to the same point, which corresponds to the vertex of a hypercube, thereby creating the encoding. We demonstrate that the emergence of binary encoding significantly enhances robustness, reliability and accuracy of the network.\n    ",
        "primary_category": "cs.LG",
        "categories": [],
        "submitted_date": "12 Oct 2023",
        "last_revised_date": " "
    },
    "2310.08540": {
        "title": "Revisiting the Hypothesis: Do pretrained Transformers Learn In-Context by Gradient Descent?",
        "authors": [
            "Lingfeng Shen",
            "Aayush Mishra",
            "Daniel Khashabi"
        ],
        "comments": " ",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "The emergence of In-Context Learning (ICL) in LLMs remains a significant phenomenon with little understanding. To explain ICL, recent studies try to theoretically connect it to Gradient Descent (GD). We ask, does this connection hold up in actual pre-trained models?\nWe highlight the limiting assumptions in prior works that make their context considerably different from the practical context in which language models are trained. For example, the theoretical hand-constructed weights used in these studies have properties that don't match those of real LLMs. Furthermore, their experimental verification uses ICL objective (training models explicitly for ICL), which differs from the emergent ICL in the wild.\nWe also look for evidence in real models. We observe that ICL and GD have different sensitivity to the order in which they observe demonstrations. Finally, we probe and compare the ICL vs. GD hypothesis in a natural setting. We conduct comprehensive empirical analyses on language models pre-trained on natural data (LLaMa-7B). Our comparisons of three performance metrics highlight the inconsistent behavior of ICL and GD as a function of various factors such as datasets, models, and the number of demonstrations. We observe that ICL and GD modify the output distribution of language models differently. These results indicate that the equivalence between ICL and GD remains an open hypothesis and calls for further studies.\n    ",
        "primary_category": "cs.CL",
        "categories": [
            "cs.AI",
            "cs.LG"
        ],
        "submitted_date": "12 Oct 2023",
        "last_revised_date": " "
    },
    "2310.08929": {
        "title": "Leveraging Image Augmentation for Object Manipulation: Towards Interpretable Controllability in Object-Centric Learning",
        "authors": [
            "Jinwoo Kim",
            "Janghyuk Choi",
            "Jaehyun Kang",
            "Changyeon Lee",
            "Ho-Jin Choi",
            "Seon Joo Kim"
        ],
        "comments": " ",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "The binding problem in artificial neural networks is actively explored with the goal of achieving human-level recognition skills through the comprehension of the world in terms of symbol-like entities. Especially in the field of computer vision, object-centric learning (OCL) is extensively researched to better understand complex scenes by acquiring object representations or slots. While recent studies in OCL have made strides with complex images or videos, the interpretability and interactivity over object representation remain largely uncharted, still holding promise in the field of OCL. In this paper, we introduce a novel method, Slot Attention with Image Augmentation (SlotAug), to explore the possibility of learning interpretable controllability over slots in a self-supervised manner by utilizing an image augmentation strategy. We also devise the concept of sustainability in controllable slots by introducing iterative and reversible controls over slots with two proposed submethods: Auxiliary Identity Manipulation and Slot Consistency Loss. Extensive empirical studies and theoretical validation confirm the effectiveness of our approach, offering a novel capability for interpretable and sustainable control of object representations.\n    ",
        "primary_category": "cs.CV",
        "categories": [],
        "submitted_date": "13 Oct 2023",
        "last_revised_date": " "
    },
    "2310.09235": {
        "title": "CoPrompt: Supporting Prompt Sharing and Referring in Collaborative Natural Language Programming",
        "authors": [
            "Li Feng",
            "Ryan Yen",
            "Yuzhe You",
            "Mingming Fan",
            "Jian Zhao",
            "Zhicong Lu"
        ],
        "comments": "Proceedings of the CHI Conference on Human Factors in Computing Systems (CHI '24), May 11--16, 2024, Honolulu, HI, USA",
        "subjects": "Human-Computer Interaction (cs.HC)",
        "abstract": "Natural language (NL) programming has become more approachable due to the powerful code-generation capability of large language models (LLMs). This shift to using NL to program enhances collaborative programming by reducing communication barriers and context-switching among programmers from varying backgrounds. However, programmers may face challenges during prompt engineering in a collaborative setting as they need to actively keep aware of their collaborators' progress and intents. In this paper, we aim to investigate ways to assist programmers' prompt engineering in a collaborative context. We first conducted a formative study to understand the workflows and challenges of programmers when using NL for collaborative programming. Based on our findings, we implemented a prototype, CoPrompt, to support collaborative prompt engineering by providing referring, requesting, sharing, and linking mechanisms. Our user study indicates that CoPrompt assists programmers in comprehending collaborators' prompts and building on their collaborators' work, reducing repetitive updates and communication costs.\n    ",
        "primary_category": "cs.HC",
        "categories": [],
        "submitted_date": "13 Oct 2023",
        "last_revised_date": " "
    },
    "2310.09463": {
        "title": "HIO-SDF: Hierarchical Incremental Online Signed Distance Fields",
        "authors": [
            "Vasileios Vasilopoulos",
            "Suveer Garg",
            "Jinwook Huh",
            "Bhoram Lee",
            "Volkan Isler"
        ],
        "comments": "IEEE International Conference on Robotics and Automation (ICRA 2024) - 7 pages, 7 figures",
        "subjects": "Robotics (cs.RO)",
        "abstract": "A good representation of a large, complex mobile robot workspace must be space-efficient yet capable of encoding relevant geometric details. When exploring unknown environments, it needs to be updatable incrementally in an online fashion. We introduce HIO-SDF, a new method that represents the environment as a Signed Distance Field (SDF). State of the art representations of SDFs are based on either neural networks or voxel grids. Neural networks are capable of representing the SDF continuously. However, they are hard to update incrementally as neural networks tend to forget previously observed parts of the environment unless an extensive sensor history is stored for training. Voxel-based representations do not have this problem but they are not space-efficient especially in large environments with fine details. HIO-SDF combines the advantages of these representations using a hierarchical approach which employs a coarse voxel grid that captures the observed parts of the environment together with high-resolution local information to train a neural network. HIO-SDF achieves a 46% lower mean global SDF error across all test scenes than a state of the art continuous representation, and a 30% lower error than a discrete representation at the same resolution as our coarse global SDF grid. Videos and code are available at: this https URL\n",
        "primary_category": "cs.RO",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "14 Oct 2023",
        "last_revised_date": " "
    },
    "2310.09680": {
        "title": "Improved Contextual Recognition In Automatic Speech Recognition Systems By Semantic Lattice Rescoring",
        "authors": [
            "Ankitha Sudarshan",
            "Vinay Samuel",
            "Parth Patwa",
            "Ibtihel Amara",
            "Aman Chadha"
        ],
        "comments": " ",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "Automatic Speech Recognition (ASR) has witnessed a profound research interest. Recent breakthroughs have given ASR systems different prospects such as faithfully transcribing spoken language, which is a pivotal advancement in building conversational agents. However, there is still an imminent challenge of accurately discerning context-dependent words and phrases. In this work, we propose a novel approach for enhancing contextual recognition within ASR systems via semantic lattice processing leveraging the power of deep learning models in accurately delivering spot-on transcriptions across a wide variety of vocabularies and speaking styles. Our solution consists of using Hidden Markov Models and Gaussian Mixture Models (HMM-GMM) along with Deep Neural Networks (DNN) models integrating both language and acoustic modeling for better accuracy. We infused our network with the use of a transformer-based model to properly rescore the word lattice achieving remarkable capabilities with a palpable reduction in Word Error Rate (WER). We demonstrate the effectiveness of our proposed framework on the LibriSpeech dataset with empirical analyses.\n    ",
        "primary_category": "cs.CL",
        "categories": [
            "cs.AI",
            "cs.SD",
            "eess.AS"
        ],
        "submitted_date": "14 Oct 2023",
        "last_revised_date": " "
    },
    "2310.09893": {
        "title": "Adaptive Contact-Implicit Model Predictive Control with Online Residual Learning",
        "authors": [
            "Wei-Cheng Huang",
            "Alp Aydinoglu",
            "Wanxin Jin",
            "Michael Posa"
        ],
        "comments": "Wei-Cheng Huang and Alp Aydinoglu contributed equally to this work. ICRA 2024 Final Submission",
        "subjects": "Robotics (cs.RO)",
        "abstract": "The hybrid nature of multi-contact robotic systems, due to making and breaking contact with the environment, creates significant challenges for high-quality control. Existing model-based methods typically rely on either good prior knowledge of the multi-contact model or require significant offline model tuning effort, thus resulting in low adaptability and robustness. In this paper, we propose a real-time adaptive multi-contact model predictive control framework, which enables online adaption of the hybrid multi-contact model and continuous improvement of the control performance for contact-rich tasks. This framework includes an adaption module, which continuously learns a residual of the hybrid model to minimize the gap between the prior model and reality, and a real-time multi-contact MPC controller. We demonstrated the effectiveness of the framework in synthetic examples, and applied it on hardware to solve contact-rich manipulation tasks, where a robot uses its end-effector to roll different unknown objects on a table to track given paths. The hardware experiments show that with a rough prior model, the multi-contact MPC controller adapts itself on-the-fly with an adaption rate around 20 Hz and successfully manipulates previously unknown objects with non-smooth surface geometries.\n    ",
        "primary_category": "cs.RO",
        "categories": [],
        "submitted_date": "15 Oct 2023",
        "last_revised_date": " "
    },
    "2310.09985": {
        "title": "Prompting for Discovery: Flexible Sense-Making for AI Art-Making with Dreamsheets",
        "authors": [
            "Shm Garanganao Almeda",
            "J.D. Zamfirescu-Pereira",
            "Kyu Won Kim",
            "Pradeep Mani Rathnam",
            "Bjoern Hartmann"
        ],
        "comments": "13 pages, 14 figures, currently under review",
        "subjects": "Human-Computer Interaction (cs.HC)",
        "abstract": "Design space exploration (DSE) for Text-to-Image (TTI) models entails navigating a vast, opaque space of possible image outputs, through a commensurately vast input space of hyperparameters and prompt text. Minor adjustments to prompt input can surface unexpectedly disparate images. How can interfaces support end-users in reliably steering prompt-space explorations towards interesting results? Our design probe, DreamSheets, supports exploration strategies with LLM-based functions for assisted prompt construction and simultaneous display of generated results, hosted in a spreadsheet interface. The flexible layout and novel generative functions enable experimentation with user-defined workflows. Two studies, a preliminary lab study and a longitudinal study with five expert artists, revealed a set of strategies participants use to tackle the challenges of TTI design space exploration, and the interface features required to support them - like using text-generation to define local \"axes\" of exploration. We distill these insights into a UI mockup to guide future interfaces.\n    ",
        "primary_category": "cs.HC",
        "categories": [],
        "submitted_date": "15 Oct 2023",
        "last_revised_date": " "
    },
    "2310.10012": {
        "title": "Ring-A-Bell! How Reliable are Concept Removal Methods for Diffusion Models?",
        "authors": [
            "Yu-Lin Tsai",
            "Chia-Yi Hsu",
            "Chulin Xie",
            "Chih-Hsun Lin",
            "Jia-You Chen",
            "Bo Li",
            "Pin-Yu Chen",
            "Chia-Mu Yu",
            "Chun-Ying Huang"
        ],
        "comments": "This paper has already been accepted by ICLR 2024. This version is the camera-ready version",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Diffusion models for text-to-image (T2I) synthesis, such as Stable Diffusion (SD), have recently demonstrated exceptional capabilities for generating high-quality content. However, this progress has raised several concerns of potential misuse, particularly in creating copyrighted, prohibited, and restricted content, or NSFW (not safe for work) images. While efforts have been made to mitigate such problems, either by implementing a safety filter at the evaluation stage or by fine-tuning models to eliminate undesirable concepts or styles, the effectiveness of these safety measures in dealing with a wide range of prompts remains largely unexplored. In this work, we aim to investigate these safety mechanisms by proposing one novel concept retrieval algorithm for evaluation. We introduce Ring-A-Bell, a model-agnostic red-teaming tool for T2I diffusion models, where the whole evaluation can be prepared in advance without prior knowledge of the target model. Specifically, Ring-A-Bell first performs concept extraction to obtain holistic representations for sensitive and inappropriate concepts. Subsequently, by leveraging the extracted concept, Ring-A-Bell automatically identifies problematic prompts for diffusion models with the corresponding generation of inappropriate content, allowing the user to assess the reliability of deployed safety mechanisms. Finally, we empirically validate our method by testing online services such as Midjourney and various methods of concept removal. Our results show that Ring-A-Bell, by manipulating safe prompting benchmarks, can transform prompts that were originally regarded as safe to evade existing safety mechanisms, thus revealing the defects of the so-called safety mechanisms which could practically lead to the generation of harmful contents. Our codes are available at this https URL.\n    ",
        "primary_category": "cs.LG",
        "categories": [],
        "submitted_date": "16 Oct 2023",
        "last_revised_date": " "
    },
    "2310.10392": {
        "title": "Distributed Differential Graphical Game for Control of Double-Integrator Multi-Agent Systems with Input Delay",
        "authors": [
            "Hossein B. Jond"
        ],
        "comments": "The revised version is accepted for publication in IEEE Transactions on Control of Network Systems",
        "subjects": "Systems and Control (eess.SY)",
        "abstract": "This paper studies cooperative control of noncooperative double-integrator multi-agent systems (MASs) with input delay on connected directed graphs in the context of a differential graphical game (DGG). In the distributed DGG, each agent seeks a distributed information control policy by optimizing an individual local performance index (PI) of distributed information from its graph neighbors. The local PI, which quadratically penalizes the agent's deviations from cooperative behavior (e.g., the consensus here), is constructed through the use of the graph Laplacian matrix. For DGGs for double-integrator MASs, the existing body of literature lacks the explicit characterization of Nash equilibrium actions and their associated state trajectories with distributed information. To address this issue, we first convert the N-player DGG with m communication links into m coupled optimal control problems (OCPs), which, in turn, convert to the two-point boundary-value problem (TPBVP). We derive the explicit solutions for the TPBV that constitute the explicit distributed information expressions for Nash equilibrium actions and the state trajectories associated with them for the DGG. An illustrative example verifies the explicit solutions of local information to achieve fully distributed consensus.\n    ",
        "primary_category": "eess.SY",
        "categories": [],
        "submitted_date": "16 Oct 2023",
        "last_revised_date": " "
    },
    "2310.10817": {
        "title": "Understanding Documentation Use Through Log Analysis: An Exploratory Case Study of Four Cloud Services",
        "authors": [
            "Daye Nam",
            "Andrew Macvean",
            "Brad Myers",
            "Bogdan Vasilescu"
        ],
        "comments": " ",
        "subjects": "Software Engineering (cs.SE)",
        "abstract": "Almost no modern software system is written from scratch, and developers are required to effectively learn to use third-party libraries or software services. Thus, many practitioners and researchers have looked for ways to create effective documentation that supports developers' learning. However, few efforts have focused on how people actually use the documentation. In this paper, we report on an exploratory, multi-phase, mixed methods empirical study of documentation page-view logs from four cloud-based industrial services. By analyzing page-view logs for over 100,000 users, we find diverse patterns of documentation page visits. Moreover, we show statistically that which documentation pages people visit often correlates with user characteristics such as past experience with the specific product, on the one hand, and with future adoption of the API on the other hand. We discuss the implications of these results on documentation design and propose documentation page-view log analysis as a feasible technique for design audits of documentation, from ones written for software developers to ones designed to support end users (e.g., Adobe Photoshop).\n    ",
        "primary_category": "cs.SE",
        "categories": [
            "cs.HC"
        ],
        "submitted_date": "16 Oct 2023",
        "last_revised_date": " "
    },
    "2310.11046": {
        "title": "Fast Graph Condensation with Structure-based Neural Tangent Kernel",
        "authors": [
            "Lin Wang",
            "Wenqi Fan",
            "Jiatong Li",
            "Yao Ma",
            "Qing Li"
        ],
        "comments": "10 pages, 6 figures, 5 tables",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "The rapid development of Internet technology has given rise to a vast amount of graph-structured data. Graph Neural Networks (GNNs), as an effective method for various graph mining tasks, incurs substantial computational resource costs when dealing with large-scale graph data. A data-centric manner solution is proposed to condense the large graph dataset into a smaller one without sacrificing the predictive performance of GNNs. However, existing efforts condense graph-structured data through a computational intensive bi-level optimization architecture also suffer from massive computation costs. In this paper, we propose reforming the graph condensation problem as a Kernel Ridge Regression (KRR) task instead of iteratively training GNNs in the inner loop of bi-level optimization. More specifically, We propose a novel dataset condensation framework (GC-SNTK) for graph-structured data, where a Structure-based Neural Tangent Kernel (SNTK) is developed to capture the topology of graph and serves as the kernel function in KRR paradigm. Comprehensive experiments demonstrate the effectiveness of our proposed model in accelerating graph condensation while maintaining high prediction performance. The source code is available on this https URL.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "17 Oct 2023",
        "last_revised_date": " "
    },
    "2310.11053": {
        "title": "Denevil: Towards Deciphering and Navigating the Ethical Values of Large Language Models via Instruction Learning",
        "authors": [
            "Shitong Duan",
            "Xiaoyuan Yi",
            "Peng Zhang",
            "Tun Lu",
            "Xing Xie",
            "Ning Gu"
        ],
        "comments": "Accepted by ICLR 2024",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "Large Language Models (LLMs) have made unprecedented breakthroughs, yet their increasing integration into everyday life might raise societal risks due to generated unethical content. Despite extensive study on specific issues like bias, the intrinsic values of LLMs remain largely unexplored from a moral philosophy perspective. This work delves into ethical values utilizing Moral Foundation Theory. Moving beyond conventional discriminative evaluations with poor reliability, we propose DeNEVIL, a novel prompt generation algorithm tailored to dynamically exploit LLMs' value vulnerabilities and elicit the violation of ethics in a generative manner, revealing their underlying value inclinations. On such a basis, we construct MoralPrompt, a high-quality dataset comprising 2,397 prompts covering 500+ value principles, and then benchmark the intrinsic values across a spectrum of LLMs. We discovered that most models are essentially misaligned, necessitating further ethical value alignment. In response, we develop VILMO, an in-context alignment method that substantially enhances the value compliance of LLM outputs by learning to generate appropriate value instructions, outperforming existing competitors. Our methods are suitable for black-box and open-source models, offering a promising initial step in studying the ethical values of LLMs.\n    ",
        "primary_category": "cs.CL",
        "categories": [
            "cs.AI",
            "cs.CY"
        ],
        "submitted_date": "17 Oct 2023",
        "last_revised_date": " "
    },
    "2310.11142": {
        "title": "BayesDiff: Estimating Pixel-wise Uncertainty in Diffusion via Bayesian Inference",
        "authors": [
            "Siqi Kou",
            "Lei Gan",
            "Dequan Wang",
            "Chongxuan Li",
            "Zhijie Deng"
        ],
        "comments": "ICLR 2024",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Diffusion models have impressive image generation capability, but low-quality generations still exist, and their identification remains challenging due to the lack of a proper sample-wise metric. To address this, we propose BayesDiff, a pixel-wise uncertainty estimator for generations from diffusion models based on Bayesian inference. In particular, we derive a novel uncertainty iteration principle to characterize the uncertainty dynamics in diffusion, and leverage the last-layer Laplace approximation for efficient Bayesian inference. The estimated pixel-wise uncertainty can not only be aggregated into a sample-wise metric to filter out low-fidelity images but also aids in augmenting successful generations and rectifying artifacts in failed generations in text-to-image tasks. Extensive experiments demonstrate the efficacy of BayesDiff and its promise for practical applications.\n    ",
        "primary_category": "cs.CV",
        "categories": [
            "cs.LG"
        ],
        "submitted_date": "17 Oct 2023",
        "last_revised_date": " "
    },
    "2310.11143": {
        "title": "Exploring a new machine learning based probabilistic model for high-resolution indoor radon mapping, using the German indoor radon survey data",
        "authors": [
            "Eric Petermann",
            "Peter Bossew",
            "Joachim Kemski",
            "Valeria Gruber",
            "Nils Suhr",
            "Bernd Hoffmann"
        ],
        "comments": " ",
        "subjects": "Machine Learning (stat.ML)",
        "abstract": "Radon is a carcinogenic, radioactive gas that can accumulate indoors. Therefore, accurate knowledge of indoor radon concentration is crucial for assessing radon-related health effects or identifying radon-prone areas. Indoor radon concentration at the national scale is usually estimated on the basis of extensive measurement campaigns. However, characteristics of the sample often differ from the characteristics of the population due to the large number of relevant factors that control the indoor radon concentration such as the availability of geogenic radon or floor level. Furthermore, the sample size usually does not allow estimation with high spatial resolution. We propose a model-based approach that allows a more realistic estimation of indoor radon distribution with a higher spatial resolution than a purely data-based approach. A two-stage modelling approach was applied: 1) a quantile regression forest using environmental and building data as predictors was applied to estimate the probability distribution function of indoor radon for each floor level of each residential building in Germany; (2) a probabilistic Monte Carlo sampling technique enabled the combination and population weighting of floor-level predictions. In this way, the uncertainty of the individual predictions is effectively propagated into the estimate of variability at the aggregated level. The results show an approximate lognormal distribution with an arithmetic mean of 63 Bq/m3, a geometric mean of 41 Bq/m3 and a 95 %ile of 180 Bq/m3. The exceedance probability for 100 Bq/m3 and 300 Bq/m3 are 12.5 % (10.5 million people) and 2.2 % (1.9 million people), respectively.\n    ",
        "primary_category": "stat.ML",
        "categories": [
            "cs.LG",
            "physics.data-an"
        ],
        "submitted_date": "17 Oct 2023",
        "last_revised_date": " "
    },
    "2310.11475": {
        "title": "Tracking and Mapping in Medical Computer Vision: A Review",
        "authors": [
            "Adam Schmidt",
            "Omid Mohareri",
            "Simon DiMaio",
            "Michael C. Yip",
            "Septimiu E. Salcudean"
        ],
        "comments": "36 pages, 17 figures. To appear in Medical Image Analysis",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "As computer vision algorithms increase in capability, their applications in clinical systems will become more pervasive. These applications include: diagnostics, such as colonoscopy and bronchoscopy; guiding biopsies, minimally invasive interventions, and surgery; automating instrument motion; and providing image guidance using pre-operative scans. Many of these applications depend on the specific visual nature of medical scenes and require designing algorithms to perform in this environment.\nIn this review, we provide an update to the field of camera-based tracking and scene mapping in surgery and diagnostics in medical computer vision. We begin with describing our review process, which results in a final list of 515 papers that we cover. We then give a high-level summary of the state of the art and provide relevant background for those who need tracking and mapping for their clinical applications. After which, we review datasets provided in the field and the clinical needs that motivate their design. Then, we delve into the algorithmic side, and summarize recent developments. This summary should be especially useful for algorithm designers and to those looking to understand the capability of off-the-shelf methods. We maintain focus on algorithms for deformable environments while also reviewing the essential building blocks in rigid tracking and mapping since there is a large amount of crossover in methods. With the field summarized, we discuss the current state of the tracking and mapping methods along with needs for future algorithms, needs for quantification, and the viability of clinical applications. We then provide some research directions and questions. We conclude that new methods need to be designed or combined to support clinical applications in deformable environments, and more focus needs to be put into collecting datasets for training and evaluation.\n    ",
        "primary_category": "cs.CV",
        "categories": [],
        "submitted_date": "17 Oct 2023",
        "last_revised_date": " "
    },
    "2310.11534": {
        "title": "HMN: Generalization of Heterogeneous and Multi-layered Network",
        "authors": [
            "Shraban Kumar Chatterjee",
            "Suman Kundu"
        ],
        "comments": " ",
        "subjects": "Social and Information Networks (cs.SI)",
        "abstract": "A network may have different types of entities and their relations. Further, there could be additional layers of ties. The former is referred to as Heterogeneous networks, while the latter is known as Multi-layer networks. The present paper provides a generalized network model, namely, a Heterogeneous Multi-layered Network (HMN), which can simultaneously be multi-layered and heterogeneous. The model can represent homogeneous networks as well. We define different structural measures in an HMN. We proved that the sets of all homogeneous, heterogeneous and multi-layered networks are subsets of the set of all HMNs. Accordingly, we established the equivalency of the proposed structural measures of HMNs with that of homogeneous, heterogeneous, and multi-layered networks. Following that, we show how our proposed HMN is more efficient in tasks such as link prediction. In addition, we present a novel parameterized algorithm (with complexity analysis) for generating synthetic HMNs. The networks generated from our proposed algorithm are more consistent in modelling the layer-wise degree distribution of a real-world Twitter network (represented as HMN) than those generated by existing models. Moreover, we also show that our algorithm is more effective in modelling an air-transportation multiplex network when compared to an algorithm designed specifically for the task.\n    ",
        "primary_category": "cs.SI",
        "categories": [],
        "submitted_date": "17 Oct 2023",
        "last_revised_date": " "
    },
    "2310.11837": {
        "title": "Optimising Distributions with Natural Gradient Surrogates",
        "authors": [
            "Jonathan So",
            "Richard E. Turner"
        ],
        "comments": " ",
        "subjects": "Machine Learning (stat.ML)",
        "abstract": "Natural gradient methods have been used to optimise the parameters of probability distributions in a variety of settings, often resulting in fast-converging procedures. Unfortunately, for many distributions of interest, computing the natural gradient has a number of challenges. In this work we propose a novel technique for tackling such issues, which involves reframing the optimisation as one with respect to the parameters of a surrogate distribution, for which computing the natural gradient is easy. We give several examples of existing methods that can be interpreted as applying this technique, and propose a new method for applying it to a wide variety of problems. Our method expands the set of distributions that can be efficiently targeted with natural gradients. Furthermore, it is fast, easy to understand, simple to implement using standard autodiff software, and does not require lengthy model-specific derivations. We demonstrate our method on maximum likelihood estimation and variational inference tasks.\n    ",
        "primary_category": "stat.ML",
        "categories": [
            "cs.LG"
        ],
        "submitted_date": "18 Oct 2023",
        "last_revised_date": " "
    },
    "2310.11984": {
        "title": "From Interpolation to Extrapolation: Complete Length Generalization for Arithmetic Transformers",
        "authors": [
            "Shaoxiong Duan",
            "Yining Shi",
            "Wei Xu"
        ],
        "comments": " ",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "In this paper, we investigate the inherent capabilities of transformer models in learning arithmetic algorithms, such as addition and parity. Through experiments and attention analysis, we identify a number of crucial factors for achieving optimal length generalization. We show that transformer models are able to generalize to long lengths with the help of targeted attention biasing. In particular, our solution solves the Parity task, a well-known and theoretically proven failure mode for Transformers. We then introduce Attention Bias Calibration (ABC), a calibration stage that enables the model to automatically learn the proper attention biases, which we show to be connected to mechanisms in relative position encoding. We demonstrate that using ABC, the transformer model can achieve unprecedented near-perfect length generalization on certain arithmetic tasks. Our code is available at https: //github.com/shaoxiongduan/AttentionBiasCalibration.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.CL"
        ],
        "submitted_date": "18 Oct 2023",
        "last_revised_date": " "
    },
    "2310.12574": {
        "title": "A reproducible 3D convolutional neural network with dual attention module (3D-DAM) for Alzheimer's disease classification",
        "authors": [
            "Thanh Phuong Vu",
            "Tien Nhat Nguyen",
            "N. Minh Nhat Hoang",
            "Gia Minh Hoang"
        ],
        "comments": " ",
        "subjects": "Image and Video Processing (eess.IV)",
        "abstract": "Alzheimer's disease is one of the most common types of neurodegenerative disease, characterized by the accumulation of amyloid-beta plaque and tau tangles. Recently, deep learning approaches have shown promise in Alzheimer's disease diagnosis. In this study, we propose a reproducible model that utilizes a 3D convolutional neural network with a dual attention module for Alzheimer's disease classification. We trained the model in the ADNI database and verified the generalizability of our method in two independent datasets (AIBL and OASIS1). Our method achieved state-of-the-art classification performance, with an accuracy of 91.94% for MCI progression classification and 96.30% for Alzheimer's disease classification on the ADNI dataset. Furthermore, the model demonstrated good generalizability, achieving an accuracy of 86.37% on the AIBL dataset and 83.42% on the OASIS1 dataset. These results indicate that our proposed approach has competitive performance and generalizability when compared to recent studies in the field.\n    ",
        "primary_category": "eess.IV",
        "categories": [
            "cs.CV"
        ],
        "submitted_date": "19 Oct 2023",
        "last_revised_date": " "
    },
    "2310.12828": {
        "title": "Flexible Informed Trees (FIT*): Adaptive Batch-Size Approach in Informed Sampling-Based Path Planning",
        "authors": [
            "Liding Zhang",
            "Zhenshan Bing",
            "Kejia Chen",
            "Lingyun Chen",
            "Kuanqi Cai",
            "Yu Zhang",
            "Fan Wu",
            "Peter Krumbholz",
            "Zhilin Yuan",
            "Sami Haddadin",
            "Alois Knoll"
        ],
        "comments": "7 pages,7 figures",
        "subjects": "Robotics (cs.RO)",
        "abstract": "In path planning, anytime almost-surely asymptotically optimal planners dominate the benchmark of sampling-based planners. A notable example is Batch Informed Trees (BIT*), where planners iteratively determine paths to batches of vertices within the exploration area. However, utilizing a consistent batch size is inefficient for initial pathfinding and optimal performance, it relies on effective task allocation. This paper introduces Flexible Informed Trees (FIT*), a sampling-based planner that integrates an adaptive batch-size method to enhance the initial path convergence rate. FIT* employs a flexible approach in adjusting batch sizes dynamically based on the inherent dimension of the configuration spaces and the hypervolume of the n-dimensional hyperellipsoid. By applying dense and sparse sampling strategy, FIT* improves convergence rate while finding successful solutions faster with lower initial solution cost. This method enhances the planner's ability to handle confined, narrow spaces in the initial finding phase and increases batch vertices sampling frequency in the optimization phase. FIT* outperforms existing single-query, sampling-based planners on the tested problems in R^2 to R^8, and was demonstrated on a real-world mobile manipulation task.\n    ",
        "primary_category": "cs.RO",
        "categories": [],
        "submitted_date": "19 Oct 2023",
        "last_revised_date": " "
    },
    "2310.13104": {
        "title": "Making Differential Privacy Easier to Use for Data Controllers and Data Analysts using a Privacy Risk Indicator and an Escrow-Based Platform",
        "authors": [
            "Zhiru Zhu",
            "Raul Castro Fernandez"
        ],
        "comments": " ",
        "subjects": "Databases (cs.DB)",
        "abstract": "Differential privacy (DP) enables private data analysis but is hard to use in practice. For data controllers who decide what output to release, choosing the amount of noise to add to the output is a non-trivial task because of the difficulty of interpreting the privacy parameter $\\epsilon$. For data analysts who submit queries, it is hard to understand the impact of the noise introduced by DP on their tasks.\nTo address these two challenges: 1) we define a privacy risk indicator that indicates the impact of choosing $\\epsilon$ on individuals' privacy and use that to design an algorithm to choose $\\epsilon$ and release output based on controllers' privacy preferences; 2) we introduce a utility signaling protocol that helps analysts interpret the impact of DP on their downstream tasks. We implement the algorithm and the protocol inside a new platform built on top of a data escrow, which allows controllers to control dataflows while maintaining high performance. We demonstrate our contributions through an IRB-approved user study, extensive experimental evaluations, and comparison with other DP platforms. All in all, our work contributes to making DP easier to use by lowering adoption barriers.\n    ",
        "primary_category": "cs.DB",
        "categories": [
            "cs.CR"
        ],
        "submitted_date": "19 Oct 2023",
        "last_revised_date": " "
    },
    "2310.13266": {
        "title": "Measurement-Based Small-Scale Channel Model for Sub-6 GHz RIS-Assisted Communications",
        "authors": [
            "Jian Sang",
            "Jifeng Lan",
            "Mingyong Zhou",
            "Boning Gao",
            "Wankai Tang",
            "Xiao Li",
            "Michail Matthaiou",
            "Shi Jin",
            "Marco Di Renzo"
        ],
        "comments": " ",
        "subjects": "Information Theory (cs.IT)",
        "abstract": "Reconfigurable intelligent surfaces (RISs) have attracted increasing interest from both academia and industry, thanks to their unique features on controlling electromagnetic (EM) waves. Although theoretical models for RIS-empowered communications have covered a variety of applications, yet, very few papers have investigated the modeling of real propagation characteristics. In this paper, we fill this gap by providing an empirical statistical channel model to describe the small-scale channel variations for an RIS-assisted broadband system at 2.6 GHz. Based on real channel measurements in outdoor, indoor and outdoor-to-indoor (O2I) environments, we compare and analyze the global, inter-cluster and intra-cluster parameters. Measurement results indicate that the deployment of an RIS with proper phase configurations can significantly improve the channel quality by enhancing the $K$-factor and reducing the time dispersion. The small-scale fading is well characterized by the proposed statistical model and the empirical channel parameters. These results are essential for the design of emerging RIS-assisted wireless systems for future applications.\n    ",
        "primary_category": "cs.IT",
        "categories": [],
        "submitted_date": "20 Oct 2023",
        "last_revised_date": " "
    },
    "2310.13653": {
        "title": "Optimal Transport for Measures with Noisy Tree Metric",
        "authors": [
            "Tam Le",
            "Truyen Nguyen",
            "Kenji Fukumizu"
        ],
        "comments": "To appear in AISTATS 2024",
        "subjects": "Machine Learning (stat.ML)",
        "abstract": "We study optimal transport (OT) problem for probability measures supported on a tree metric space. It is known that such OT problem (i.e., tree-Wasserstein (TW)) admits a closed-form expression, but depends fundamentally on the underlying tree structure over supports of input measures. In practice, the given tree structure may be, however, perturbed due to noisy or adversarial measurements. To mitigate this issue, we follow the max-min robust OT approach which considers the maximal possible distances between two input measures over an uncertainty set of tree metrics. In general, this approach is hard to compute, even for measures supported in one-dimensional space, due to its non-convexity and non-smoothness which hinders its practical applications, especially for large-scale settings. In this work, we propose novel uncertainty sets of tree metrics from the lens of edge deletion/addition which covers a diversity of tree structures in an elegant framework. Consequently, by building upon the proposed uncertainty sets, and leveraging the tree structure over supports, we show that the robust OT also admits a closed-form expression for a fast computation as its counterpart standard OT (i.e., TW). Furthermore, we demonstrate that the robust OT satisfies the metric property and is negative definite. We then exploit its negative definiteness to propose positive definite kernels and test them in several simulations on various real-world datasets on document classification and topological data analysis.\n    ",
        "primary_category": "stat.ML",
        "categories": [
            "cs.LG"
        ],
        "submitted_date": "20 Oct 2023",
        "last_revised_date": " "
    },
    "2310.13822": {
        "title": "Adversarial Attacks on Fairness of Graph Neural Networks",
        "authors": [
            "Binchi Zhang",
            "Yushun Dong",
            "Chen Chen",
            "Yada Zhu",
            "Minnan Luo",
            "Jundong Li"
        ],
        "comments": "Accepted at ICLR 2024",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Fairness-aware graph neural networks (GNNs) have gained a surge of attention as they can reduce the bias of predictions on any demographic group (e.g., female) in graph-based applications. Although these methods greatly improve the algorithmic fairness of GNNs, the fairness can be easily corrupted by carefully designed adversarial attacks. In this paper, we investigate the problem of adversarial attacks on fairness of GNNs and propose G-FairAttack, a general framework for attacking various types of fairness-aware GNNs in terms of fairness with an unnoticeable effect on prediction utility. In addition, we propose a fast computation technique to reduce the time complexity of G-FairAttack. The experimental study demonstrates that G-FairAttack successfully corrupts the fairness of different types of GNNs while keeping the attack unnoticeable. Our study on fairness attacks sheds light on potential vulnerabilities in fairness-aware GNNs and guides further research on the robustness of GNNs in terms of fairness.\n    ",
        "primary_category": "cs.LG",
        "categories": [],
        "submitted_date": "20 Oct 2023",
        "last_revised_date": " "
    },
    "2310.14720": {
        "title": "Extended Deep Adaptive Input Normalization for Preprocessing Time Series Data for Neural Networks",
        "authors": [
            "Marcus A. K. September",
            "Francesco Sanna Passino",
            "Leonie Goldmann",
            "Anton Hinel"
        ],
        "comments": " ",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Data preprocessing is a crucial part of any machine learning pipeline, and it can have a significant impact on both performance and training efficiency. This is especially evident when using deep neural networks for time series prediction and classification: real-world time series data often exhibit irregularities such as multi-modality, skewness and outliers, and the model performance can degrade rapidly if these characteristics are not adequately addressed. In this work, we propose the EDAIN (Extended Deep Adaptive Input Normalization) layer, a novel adaptive neural layer that learns how to appropriately normalize irregular time series data for a given task in an end-to-end fashion, instead of using a fixed normalization scheme. This is achieved by optimizing its unknown parameters simultaneously with the deep neural network using back-propagation. Our experiments, conducted using synthetic data, a credit default prediction dataset, and a large-scale limit order book benchmark dataset, demonstrate the superior performance of the EDAIN layer when compared to conventional normalization methods and existing adaptive time series preprocessing layers.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "stat.ML"
        ],
        "submitted_date": "23 Oct 2023",
        "last_revised_date": " "
    },
    "2310.15516": {
        "title": "Graph Attention-based Deep Reinforcement Learning for solving the Chinese Postman Problem with Load-dependent costs",
        "authors": [
            "Truong Son Hy",
            "Cong Dao Tran"
        ],
        "comments": " ",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Recently, Deep reinforcement learning (DRL) models have shown promising results in solving routing problems. However, most DRL solvers are commonly proposed to solve node routing problems, such as the Traveling Salesman Problem (TSP). Meanwhile, there has been limited research on applying neural methods to arc routing problems, such as the Chinese Postman Problem (CPP), since they often feature irregular and complex solution spaces compared to TSP. To fill these gaps, this paper proposes a novel DRL framework to address the CPP with load-dependent costs (CPP-LC) (Corberan et al., 2018), which is a complex arc routing problem with load constraints. The novelty of our method is two-fold. First, we formulate the CPP-LC as a Markov Decision Process (MDP) sequential model. Subsequently, we introduce an autoregressive model based on DRL, namely Arc-DRL, consisting of an encoder and decoder to address the CPP-LC challenge effectively. Such a framework allows the DRL model to work efficiently and scalably to arc routing problems. Furthermore, we propose a new bio-inspired meta-heuristic solution based on Evolutionary Algorithm (EA) for CPP-LC. Extensive experiments show that Arc-DRL outperforms existing meta-heuristic methods such as Iterative Local Search (ILS) and Variable Neighborhood Search (VNS) proposed by (Corberan et al., 2018) on large benchmark datasets for CPP-LC regarding both solution quality and running time; while the EA gives the best solution quality with much more running time. We release our C++ implementations for metaheuristics such as EA, ILS and VNS along with the code for data generation and our generated data at this https URL\n",
        "primary_category": "cs.LG",
        "categories": [],
        "submitted_date": "24 Oct 2023",
        "last_revised_date": " "
    },
    "2310.16298": {
        "title": "Stencil Matrixization",
        "authors": [
            "Wenxuan Zhao",
            "Liang Yuan",
            "Baicheng Yan",
            "Penghao Ma",
            "Yunquan Zhang",
            "Long Wang",
            "Zhe Wang"
        ],
        "comments": " ",
        "subjects": "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "abstract": "Current architectures are now equipped with matrix computation units designed to enhance AI and high-performance computing applications. Within these architectures, two fundamental instruction types are matrix multiplication and vector outer product, with the latter being lighter due to its vector inputs. This characteristic not only allows for the development of flexible algorithms beyond dense linear algebra computations but also offers greater potential for implementation optimization. Stencil computations, commonly found in scientific and engineering applications, involve nested loops. This paper introduces a novel stencil algorithm leveraging vector outer products. Unlike previous approaches, this algorithm emerges from the stencil definition in scatter mode and is initially formulated using vector outer product expressions. The implementation integrates a series of optimizations to enhance memory reference patterns, execution pipeline efficiency, and data reuse. These optimizations consider various algorithmic options and data sharing among input vectors. Evaluation conducted on a simulator demonstrates that our proposed design achieves significant speedup compared to vectorized stencil algorithms.\n    ",
        "primary_category": "cs.DC",
        "categories": [],
        "submitted_date": "25 Oct 2023",
        "last_revised_date": " "
    },
    "2310.16605": {
        "title": "WebDRO: A Web-based Group-level Clustering and Reweighting Method for Unsupervised Dense Retrieval",
        "authors": [
            "Peixuan Han",
            "Zhenghao Liu",
            "Zhiyuan Liu",
            "Chenyan Xiong"
        ],
        "comments": " ",
        "subjects": "Information Retrieval (cs.IR)",
        "abstract": "The anchor-document data derived from web graphs offers a wealth of paired information for training dense retrieval models in an unsupervised manner. However, the presence of inherent noise invariably compromises the robustness of training dense retrieval models, consequently hurting the performance. In this paper, we introduce WebDRO, an efficient approach for clustering the web graph data and optimizing group weights to enhance the robustness of the pretraining process of dense retrieval models on web graphs. Initially, we build an embedding model for clustering anchor-document pairs. Specifically, we contrastively train the embedding model for link prediction, which guides the embedding model in capturing the inherent document features behind the web graph links. Subsequently, we employ the group distributional robust optimization to recalibrate the weights across different clusters of anchor-document pairs during training dense retrieval models, directing the model to assign higher weights to clusters with higher loss and focus more on worst-case scenarios. Our experiments conducted on MS MARCO and BEIR demonstrate that our method can effectively improve retrieval performance in unsupervised training settings. Further analysis confirms the stability and validity of group weights learned by WebDRO. All codes will be released via GitHub.\n    ",
        "primary_category": "cs.IR",
        "categories": [],
        "submitted_date": "25 Oct 2023",
        "last_revised_date": " "
    },
    "2310.17009": {
        "title": "Simulation-based stacking",
        "authors": [
            "Yuling Yao",
            "Bruno R\u00e9galdo-Saint Blancard",
            "Justin Domke"
        ],
        "comments": "Published at International Conference on Artificial Intelligence and Statistics (AISTATS) 2024",
        "subjects": "Methodology (stat.ME)",
        "abstract": "Simulation-based inference has been popular for amortized Bayesian computation. It is typical to have more than one posterior approximation, from different inference algorithms, different architectures, or simply the randomness of initialization and stochastic gradients. With a consistency guarantee, we present a general posterior stacking framework to make use of all available approximations. Our stacking method is able to combine densities, simulation draws, confidence intervals, and moments, and address the overall precision, calibration, coverage, and bias of the posterior approximation at the same time. We illustrate our method on several benchmark simulations and a challenging cosmological inference task.\n    ",
        "primary_category": "stat.ME",
        "categories": [
            "cs.LG",
            "stat.CO"
        ],
        "submitted_date": "25 Oct 2023",
        "last_revised_date": " "
    },
    "2310.17273": {
        "title": "Looping in the Human Collaborative and Explainable Bayesian Optimization",
        "authors": [
            "Masaki Adachi",
            "Brady Planden",
            "David A. Howey",
            "Michael A. Osborne",
            "Sebastian Orbell",
            "Natalia Ares",
            "Krikamol Muandet",
            "Siu Lun Chau"
        ],
        "comments": "Accepted at AISTATS 2024, 24 pages, 11 figures",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Like many optimizers, Bayesian optimization often falls short of gaining user trust due to opacity. While attempts have been made to develop human-centric optimizers, they typically assume user knowledge is well-specified and error-free, employing users mainly as supervisors of the optimization process. We relax these assumptions and propose a more balanced human-AI partnership with our Collaborative and Explainable Bayesian Optimization (CoExBO) framework. Instead of explicitly requiring a user to provide a knowledge model, CoExBO employs preference learning to seamlessly integrate human insights into the optimization, resulting in algorithmic suggestions that resonate with user preference. CoExBO explains its candidate selection every iteration to foster trust, empowering users with a clearer grasp of the optimization. Furthermore, CoExBO offers a no-harm guarantee, allowing users to make mistakes; even with extreme adversarial interventions, the algorithm converges asymptotically to a vanilla Bayesian optimization. We validate CoExBO's efficacy through human-AI teaming experiments in lithium-ion battery design, highlighting substantial improvements over conventional methods. Code is available this https URL.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.HC",
            "stat.ML"
        ],
        "submitted_date": "26 Oct 2023",
        "last_revised_date": " "
    },
    "2310.17844": {
        "title": "Adaptive operator learning for infinite-dimensional Bayesian inverse problems",
        "authors": [
            "Zhiwei Gao",
            "Liang Yan",
            "Tao Zhou"
        ],
        "comments": " ",
        "subjects": "Numerical Analysis (math.NA)",
        "abstract": "The fundamental computational issues in Bayesian inverse problems (BIP) governed by partial differential equations (PDEs) stem from the requirement of repeated forward model evaluations. A popular strategy to reduce such costs is to replace expensive model simulations with computationally efficient approximations using operator learning, motivated by recent progress in deep learning. However, using the approximated model directly may introduce a modeling error, exacerbating the already ill-posedness of inverse problems. Thus, balancing between accuracy and efficiency is essential for the effective implementation of such approaches. To this end, we develop an adaptive operator learning framework that can reduce modeling error gradually by forcing the surrogate to be accurate in local areas. This is accomplished by adaptively fine-tuning the pre-trained approximate model with train- ing points chosen by a greedy algorithm during the posterior computational process. To validate our approach, we use DeepOnet to construct the surrogate and unscented Kalman inversion (UKI) to approximate the BIP solution, respectively. Furthermore, we present a rigorous convergence guarantee in the linear case using the UKI framework. The approach is tested on a number of benchmarks, including the Darcy flow, the heat source inversion problem, and the reaction-diffusion problem. The numerical results show that our method can significantly reduce computational costs while maintaining inversion accuracy.\n    ",
        "primary_category": "math.NA",
        "categories": [
            "stat.CO",
            "stat.ML"
        ],
        "submitted_date": "27 Oct 2023",
        "last_revised_date": " "
    },
    "2310.18127": {
        "title": "Ask more, know better: Reinforce-Learned Prompt Questions for Decision Making with Large Language Models",
        "authors": [
            "Xue Yan",
            "Yan Song",
            "Xinyu Cui",
            "Filippos Christianos",
            "Haifeng Zhang",
            "David Henry Mguni",
            "Jun Wang"
        ],
        "comments": " ",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Large language models (LLMs) demonstrate their promise in tackling complicated practical challenges by combining action-based policies with chain of thought (CoT) reasoning. Having high-quality prompts on hand, however, is vital to the framework's effectiveness. Currently, these prompts are handcrafted utilising extensive human labor, resulting in CoT policies that frequently fail to generalise. Human intervention is also required to develop grounding functions that ensure low-level controllers appropriately process CoT reasoning. In this paper, we propose a comprehensive training framework for complex task-solving, incorporating human prior knowledge into the learning of action policies. To that purpose, we offer a new leader-follower bilevel framework that is capable of learning to ask relevant questions (prompts) and subsequently undertaking reasoning to guide the learning of actions. The prompt policy is employed to make introspective revisions based on historical findings, leading the CoT process to consider the anticipated goals and generate outputs that lead to decisive, high-performing actions. The action policy subsequently learns to comprehend and integrate the CoT outputs to take actions. Our empirical data reveal that our framework outperforms leading methods in $5$ decision-making tasks such as Overcooked and FourRoom.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.AI",
            "cs.CL"
        ],
        "submitted_date": "27 Oct 2023",
        "last_revised_date": " "
    },
    "2310.18681": {
        "title": "DySurv: Dynamic Deep Learning Model for Survival Prediction in the ICU",
        "authors": [
            "Munib Mesinovic",
            "Peter Watkinson",
            "Tingting Zhu"
        ],
        "comments": " ",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Survival analysis focuses on estimating time-to-event distributions which can help in dynamic risk prediction in healthcare. Extending beyond the classical Cox model, deep learning techniques have been developed which moved away from the constraining assumptions of proportional hazards. Traditional statistical models often only include static information where, in this work, we propose a novel conditional variational autoencoder-based method called DySurv, which uses a combination of static and time-series measurements from patient electronic health records to estimate the risk of death dynamically. DySurv has been tested on several time-to-event benchmarks where it outperforms existing methods, including deep learning methods, and we evaluate it on real-world intensive care unit data from MIMIC-IV and eICU. The predictive capacity of DySurv is consistent and the survival estimates remain disentangled across different datasets supporting the idea that dynamic deep learning models based on conditional variational inference in multi-task cases can be robust models for survival analysis.\n    ",
        "primary_category": "cs.LG",
        "categories": [],
        "submitted_date": "28 Oct 2023",
        "last_revised_date": " "
    },
    "2310.19103": {
        "title": "Proving Linear Mode Connectivity of Neural Networks via Optimal Transport",
        "authors": [
            "Damien Ferbach",
            "Baptiste Goujaud",
            "Gauthier Gidel",
            "Aymeric Dieuleveut"
        ],
        "comments": "Accepted as a conference paper at AISTATS 2024",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "The energy landscape of high-dimensional non-convex optimization problems is crucial to understanding the effectiveness of modern deep neural network architectures. Recent works have experimentally shown that two different solutions found after two runs of a stochastic training are often connected by very simple continuous paths (e.g., linear) modulo a permutation of the weights. In this paper, we provide a framework theoretically explaining this empirical observation. Based on convergence rates in Wasserstein distance of empirical measures, we show that, with high probability, two wide enough two-layer neural networks trained with stochastic gradient descent are linearly connected. Additionally, we express upper and lower bounds on the width of each layer of two deep neural networks with independent neuron weights to be linearly connected. Finally, we empirically demonstrate the validity of our approach by showing how the dimension of the support of the weight distribution of neurons, which dictates Wasserstein convergence rates is correlated with linear mode connectivity.\n    ",
        "primary_category": "cs.LG",
        "categories": [],
        "submitted_date": "29 Oct 2023",
        "last_revised_date": " "
    },
    "2310.19450": {
        "title": "Hodge-Compositional Edge Gaussian Processes",
        "authors": [
            "Maosheng Yang",
            "Viacheslav Borovitskiy",
            "Elvin Isufi"
        ],
        "comments": " ",
        "subjects": "Machine Learning (stat.ML)",
        "abstract": "We propose principled Gaussian processes (GPs) for modeling functions defined over the edge set of a simplicial 2-complex, a structure similar to a graph in which edges may form triangular faces. This approach is intended for learning flow-type data on networks where edge flows can be characterized by the discrete divergence and curl. Drawing upon the Hodge decomposition, we first develop classes of divergence-free and curl-free edge GPs, suitable for various applications. We then combine them to create \\emph{Hodge-compositional edge GPs} that are expressive enough to represent any edge function. These GPs facilitate direct and independent learning for the different Hodge components of edge functions, enabling us to capture their relevance during hyperparameter optimization. To highlight their practical potential, we apply them for flow data inference in currency exchange, ocean currents and water supply networks, comparing them to alternative models.\n    ",
        "primary_category": "stat.ML",
        "categories": [
            "cs.LG"
        ],
        "submitted_date": "30 Oct 2023",
        "last_revised_date": " "
    },
    "2310.19527": {
        "title": "On the Theory of Risk-Aware Agents: Bridging Actor-Critic and Economics",
        "authors": [
            "Michal Nauman",
            "Marek Cygan"
        ],
        "comments": "Preprint",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Risk-aware Reinforcement Learning (RL) algorithms like SAC and TD3 were shown empirically to outperform their risk-neutral counterparts in a variety of continuous-action tasks. However, the theoretical basis for the pessimistic objectives these algorithms employ remains unestablished, raising questions about the specific class of policies they are implementing. In this work, we apply the expected utility hypothesis, a fundamental concept in economics, to illustrate that both risk-neutral and risk-aware RL goals can be interpreted through expected utility maximization using an exponential utility function. This approach reveals that risk-aware policies effectively maximize value certainty equivalent, aligning them with conventional decision theory principles. Furthermore, we propose Dual Actor-Critic (DAC). DAC is a risk-aware, model-free algorithm that features two distinct actor networks: a pessimistic actor for temporal-difference learning and an optimistic actor for exploration. Our evaluations of DAC across various locomotion and manipulation tasks demonstrate improvements in sample efficiency and final performance. Remarkably, DAC, while requiring significantly less computational resources, matches the performance of leading model-based methods in the complex dog and humanoid domains.\n    ",
        "primary_category": "cs.LG",
        "categories": [],
        "submitted_date": "30 Oct 2023",
        "last_revised_date": " "
    },
    "2310.19673": {
        "title": "A Novel Non-Pyrotechnic Radial Deployment Mechanism for Payloads in Sounding Rockets",
        "authors": [
            "Thakur Pranav G. Singh",
            "Utkarsh Anand",
            "Tanvi Agrawal",
            "Srinivas G"
        ],
        "comments": "The results in this paper had to be verified again and hence a new paper has been written with new detailed mechanical simulations",
        "subjects": "Systems and Control (eess.SY)",
        "abstract": "This research paper introduces an innovative payload deployment mechanism tailored for sounding rockets, addressing a crucial challenge in the field. The problem statement revolves around the need to efficiently and compactly deploy multiple payloads during a single rocket launch. This mechanism, designed to be exceptionally suitable for sounding rockets, features a cylindrical carrier structure equipped with multiple independently operable deployment ports. Powered by a motor, the carrier structure rotates to enable radial ejection of payloads. In this paper, we present the mechanism's design and conduct a comprehensive performance analysis. This analysis encompasses an examination of structural stability, system dynamics, motor torque, and power requirements. Additionally, we develop a simulation model to assess payload deployment behavior under various conditions. Our findings demonstrate the viability and efficiency of this proposed mechanism for deploying multiple payloads within a single sounding rocket launch. Its adaptability to accommodate diverse payload types and sizes enhances its versatility. Moreover, the mechanism's radial deployment capability allows payloads to be released at different altitudes, thereby offering greater flexibility for scientific experiments. In summary, this innovative payload radial deployment mechanism represents a significant advancement in sounding rocket technology and holds promise for a wide array of applications in both scientific and commercial missions.\n    ",
        "primary_category": "eess.SY",
        "categories": [],
        "submitted_date": "30 Oct 2023",
        "last_revised_date": " "
    },
    "2310.20354": {
        "title": "Statistical Complexity of Heterogeneous Geometric Networks",
        "authors": [
            "Keith Malcolm Smith",
            "Jason P. Smith"
        ],
        "comments": "12 pages, 6 figures",
        "subjects": "Social and Information Networks (cs.SI)",
        "abstract": "Heterogeneity and geometry are key explanatory components underlying the structure of real-world networks. The relationship between these components and the statistical complexity of networks is not well understood. We introduce a parsimonious normalised measure of statistical complexity for networks -- normalised hierarchical complexity. The measure is trivially 0 in regular graphs and we prove that this measure tends to 0 in Erd\u00f6s-R\u00e9nyi random graphs in the thermodynamic limit. We go on to demonstrate that greater complexity arises from the combination of hierarchical and geometric components to the network structure than either on their own. Further, the levels of complexity achieved are similar to those found in many real-world networks. We also find that real world networks establish connections in a way which increases hierarchical complexity and which our null models and a range of attachment mechanisms fail to explain. This underlines the non-trivial nature of statistical complexity in real-world networks and provides foundations for the comparative analysis of network complexity within and across disciplines.\n    ",
        "primary_category": "cs.SI",
        "categories": [],
        "submitted_date": "31 Oct 2023",
        "last_revised_date": " "
    },
    "2311.00123": {
        "title": "Q-Learning for Stochastic Control under General Information Structures and Non-Markovian Environments",
        "authors": [
            "Ali Devran Kara",
            "Serdar Yuksel"
        ],
        "comments": "2 figures",
        "subjects": "Optimization and Control (math.OC)",
        "abstract": "As a primary contribution, we present a convergence theorem for stochastic iterations, and in particular, Q-learning iterates, under a general, possibly non-Markovian, stochastic environment. Our conditions for convergence involve an ergodicity and a positivity criterion. We provide a precise characterization on the limit of the iterates and conditions on the environment and initializations for convergence. As our second contribution, we discuss the implications and applications of this theorem to a variety of stochastic control problems with non-Markovian environments involving (i) quantized approximations of fully observed Markov Decision Processes (MDPs) with continuous spaces (where quantization break down the Markovian structure), (ii) quantized approximations of belief-MDP reduced partially observable MDPS (POMDPs) with weak Feller continuity and a mild version of filter stability (which requires the knowledge of the model by the controller), (iii) finite window approximations of POMDPs under a uniform controlled filter stability (which does not require the knowledge of the model), and (iv) for multi-agent models where convergence of learning dynamics to a new class of equilibria, subjective Q-learning equilibria, will be studied. In addition to the convergence theorem, some implications of the theorem above are new to the literature and others are interpreted as applications of the convergence theorem. Some open problems are noted.\n    ",
        "primary_category": "math.OC",
        "categories": [
            "cs.AI",
            "eess.SY"
        ],
        "submitted_date": "31 Oct 2023",
        "last_revised_date": " "
    },
    "2311.00434": {
        "title": "Event-based Background-Oriented Schlieren",
        "authors": [
            "Shintaro Shiba",
            "Friedhelm Hamann",
            "Yoshimitsu Aoki",
            "Guillermo Gallego"
        ],
        "comments": "Accepted at IEEE T-PAMI",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Schlieren imaging is an optical technique to observe the flow of transparent media, such as air or water, without any particle seeding. However, conventional frame-based techniques require both high spatial and temporal resolution cameras, which impose bright illumination and expensive computation limitations. Event cameras offer potential advantages (high dynamic range, high temporal resolution, and data efficiency) to overcome such limitations due to their bio-inspired sensing principle. This paper presents a novel technique for perceiving air convection using events and frames by providing the first theoretical analysis that connects event data and schlieren. We formulate the problem as a variational optimization one combining the linearized event generation model with a physically-motivated parameterization that estimates the temporal derivative of the air density. The experiments with accurately aligned frame- and event camera data reveal that the proposed method enables event cameras to obtain on par results with existing frame-based optical flow techniques. Moreover, the proposed method works under dark conditions where frame-based schlieren fails, and also enables slow-motion analysis by leveraging the event camera's advantages. Our work pioneers and opens a new stack of event camera applications, as we publish the source code as well as the first schlieren dataset with high-quality frame and event data. this https URL\n",
        "primary_category": "cs.CV",
        "categories": [
            "eess.IV"
        ],
        "submitted_date": "1 Nov 2023",
        "last_revised_date": " "
    },
    "2311.00453": {
        "title": "CLIP-AD: A Language-Guided Staged Dual-Path Model for Zero-shot Anomaly Detection",
        "authors": [
            "Xuhai Chen",
            "Jiangning Zhang",
            "Guanzhong Tian",
            "Haoyang He",
            "Wuhao Zhang",
            "Yabiao Wang",
            "Chengjie Wang",
            "Yong Liu"
        ],
        "comments": " ",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "This paper considers zero-shot Anomaly Detection (AD), performing AD without reference images of the test objects. We propose a framework called CLIP-AD to leverage the zero-shot capabilities of the large vision-language model CLIP. Firstly, we reinterpret the text prompts design from a distributional perspective and propose a Representative Vector Selection (RVS) paradigm to obtain improved text features. Secondly, we note opposite predictions and irrelevant highlights in the direct computation of the anomaly maps. To address these issues, we introduce a Staged Dual-Path model (SDP) that leverages features from various levels and applies architecture and feature surgery. Lastly, delving deeply into the two phenomena, we point out that the image and text features are not aligned in the joint embedding space. Thus, we introduce a fine-tuning strategy by adding linear layers and construct an extended model SDP+, further enhancing the performance. Abundant experiments demonstrate the effectiveness of our approach, e.g., on MVTec-AD, SDP outperforms the SOTA WinCLIP by +4.2/+10.7 in segmentation metrics F1-max/PRO, while SDP+ achieves +8.3/+20.5 improvements.\n    ",
        "primary_category": "cs.CV",
        "categories": [],
        "submitted_date": "1 Nov 2023",
        "last_revised_date": " "
    },
    "2311.00460": {
        "title": "Optimal Budgeted Rejection Sampling for Generative Models",
        "authors": [
            "Alexandre Verine",
            "Muni Sreenivas Pydi",
            "Benjamin Negrevergne",
            "Yann Chevaleyre"
        ],
        "comments": " ",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Rejection sampling methods have recently been proposed to improve the performance of discriminator-based generative models. However, these methods are only optimal under an unlimited sampling budget, and are usually applied to a generator trained independently of the rejection procedure. We first propose an Optimal Budgeted Rejection Sampling (OBRS) scheme that is provably optimal with respect to \\textit{any} $f$-divergence between the true distribution and the post-rejection distribution, for a given sampling budget. Second, we propose an end-to-end method that incorporates the sampling scheme into the training procedure to further enhance the model's overall performance. Through experiments and supporting theory, we show that the proposed methods are effective in significantly improving the quality and diversity of the samples.\n    ",
        "primary_category": "cs.LG",
        "categories": [],
        "submitted_date": "1 Nov 2023",
        "last_revised_date": " "
    },
    "2311.00859": {
        "title": "Optimal Cost Constrained Adversarial Attacks For Multiple Agent Systems",
        "authors": [
            "Ziqing Lu",
            "Guanlin Liu",
            "Lifeng Lai",
            "Weiyu Xu"
        ],
        "comments": "Submitted to ICCASP2024",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Finding optimal adversarial attack strategies is an important topic in reinforcement learning and the Markov decision process. Previous studies usually assume one all-knowing coordinator (attacker) for whom attacking different recipient (victim) agents incurs uniform costs. However, in reality, instead of using one limitless central attacker, the attacks often need to be performed by distributed attack agents. We formulate the problem of performing optimal adversarial agent-to-agent attacks using distributed attack agents, in which we impose distinct cost constraints on each different attacker-victim pair. We propose an optimal method integrating within-step static constrained attack-resource allocation optimization and between-step dynamic programming to achieve the optimal adversarial attack in a multi-agent system. Our numerical results show that the proposed attacks can significantly reduce the rewards received by the attacked agents.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.AI",
            "cs.CR",
            "cs.MA"
        ],
        "submitted_date": "1 Nov 2023",
        "last_revised_date": " "
    },
    "2311.01047": {
        "title": "Improving Robustness via Tilted Exponential Layer: A Communication-Theoretic Perspective",
        "authors": [
            "Bhagyashree Puranik",
            "Ahmad Beirami",
            "Yao Qin",
            "Upamanyu Madhow"
        ],
        "comments": "27th International Conference on Artificial Intelligence and Statistics (AISTATS 2024)",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "State-of-the-art techniques for enhancing robustness of deep networks mostly rely on empirical risk minimization with suitable data augmentation. In this paper, we propose a complementary approach motivated by communication theory, aimed at enhancing the signal-to-noise ratio at the output of a neural network layer via neural competition during learning and inference. In addition to standard empirical risk minimization, neurons compete to sparsely represent layer inputs by maximization of a tilted exponential (TEXP) objective function for the layer. TEXP learning can be interpreted as maximum likelihood estimation of matched filters under a Gaussian model for data noise. Inference in a TEXP layer is accomplished by replacing batch norm by a tilted softmax, which can be interpreted as computation of posterior probabilities for the competing signaling hypotheses represented by each neuron. After providing insights via simplified models, we show, by experimentation on standard image datasets, that TEXP learning and inference enhances robustness against noise and other common corruptions, without requiring data augmentation. Further cumulative gains in robustness against this array of distortions can be obtained by appropriately combining TEXP with data augmentation techniques. The code for all our experiments is available at this https URL.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.IT",
            "eess.SP"
        ],
        "submitted_date": "2 Nov 2023",
        "last_revised_date": " "
    },
    "2311.01092": {
        "title": "Learning A Multi-Task Transformer Via Unified And Customized Instruction Tuning For Chest Radiograph Interpretation",
        "authors": [
            "Lijian Xu",
            "Ziyu Ni",
            "Xinglong Liu",
            "Xiaosong Wang",
            "Hongsheng Li",
            "Shaoting Zhang"
        ],
        "comments": " ",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "The emergence of multi-modal deep learning models has made significant impacts on clinical applications in the last decade. However, the majority of models are limited to single-tasking, without considering disease diagnosis is indeed a multi-task procedure. Here, we demonstrate a unified transformer model specifically designed for multi-modal clinical tasks by incorporating customized instruction tuning. We first compose a multi-task training dataset comprising 13.4 million instruction and ground-truth pairs (with approximately one million radiographs) for the customized tuning, involving both image- and pixel-level tasks. Thus, we can unify the various vision-intensive tasks in a single training framework with homogeneous model inputs and outputs to increase clinical interpretability in one reading. Finally, we demonstrate the overall superior performance of our model compared to prior arts on various chest X-ray benchmarks across multi-tasks in both direct inference and finetuning settings. Three radiologists further evaluate the generated reports against the recorded ones, which also exhibit the enhanced explainability of our multi-task model.\n    ",
        "primary_category": "cs.CV",
        "categories": [],
        "submitted_date": "2 Nov 2023",
        "last_revised_date": " "
    },
    "2311.01410": {
        "title": "The Blessing of Randomness: SDE Beats ODE in General Diffusion-based Image Editing",
        "authors": [
            "Shen Nie",
            "Hanzhong Allan Guo",
            "Cheng Lu",
            "Yuhao Zhou",
            "Chenyu Zheng",
            "Chongxuan Li"
        ],
        "comments": " ",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "We present a unified probabilistic formulation for diffusion-based image editing, where a latent variable is edited in a task-specific manner and generally deviates from the corresponding marginal distribution induced by the original stochastic or ordinary differential equation (SDE or ODE). Instead, it defines a corresponding SDE or ODE for editing. In the formulation, we prove that the Kullback-Leibler divergence between the marginal distributions of the two SDEs gradually decreases while that for the ODEs remains as the time approaches zero, which shows the promise of SDE in image editing. Inspired by it, we provide the SDE counterparts for widely used ODE baselines in various tasks including inpainting and image-to-image translation, where SDE shows a consistent and substantial improvement. Moreover, we propose SDE-Drag -- a simple yet effective method built upon the SDE formulation for point-based content dragging. We build a challenging benchmark (termed DragBench) with open-set natural, art, and AI-generated images for evaluation. A user study on DragBench indicates that SDE-Drag significantly outperforms our ODE baseline, existing diffusion-based methods, and the renowned DragGAN. Our results demonstrate the superiority and versatility of SDE in image editing and push the boundary of diffusion-based editing methods.\n    ",
        "primary_category": "cs.CV",
        "categories": [
            "cs.LG"
        ],
        "submitted_date": "2 Nov 2023",
        "last_revised_date": " "
    },
    "2311.01947": {
        "title": "Lengths of divisible codes -- the missing cases",
        "authors": [
            "Sascha Kurz"
        ],
        "comments": "11 pages, 1 table",
        "subjects": "Combinatorics (math.CO)",
        "abstract": "A linear code $C$ over $\\mathbb{F}_q$ is called $\\Delta$-divisible if the Hamming weights $\\operatorname{wt}(c)$ of all codewords $c \\in C$ are divisible by $\\Delta$. The possible effective lengths of $q^r$-divisible codes have been completely characterized for each prime power $q$ and each non-negative integer $r$. The study of $\\Delta$ divisible codes was initiated by Harold Ward. If $c$ divides $\\Delta$ but is coprime to $q$, then each $\\Delta$-divisible code $C$ over $\\F_q$ is the $c$-fold repetition of a $\\Delta/c$-divisible code. Here we determine the possible effective lengths of $p^r$-divisible codes over finite fields of characteristic $p$, where $p\\in\\mathbb{N}$ but $p^r$ is not a power of the field size, i.e., the missing cases.\n    ",
        "primary_category": "math.CO",
        "categories": [
            "cs.IT"
        ],
        "submitted_date": "3 Nov 2023",
        "last_revised_date": " "
    },
    "2311.02013": {
        "title": "SMORE: Score Models for Offline Goal-Conditioned Reinforcement Learning",
        "authors": [
            "Harshit Sikchi",
            "Rohan Chitnis",
            "Ahmed Touati",
            "Alborz Geramifard",
            "Amy Zhang",
            "Scott Niekum"
        ],
        "comments": "Published at International Conference of Learning Representations (ICLR) 2024. 26 pages",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Offline Goal-Conditioned Reinforcement Learning (GCRL) is tasked with learning to achieve multiple goals in an environment purely from offline datasets using sparse reward functions. Offline GCRL is pivotal for developing generalist agents capable of leveraging pre-existing datasets to learn diverse and reusable skills without hand-engineering reward functions. However, contemporary approaches to GCRL based on supervised learning and contrastive learning are often suboptimal in the offline setting. An alternative perspective on GCRL optimizes for occupancy matching, but necessitates learning a discriminator, which subsequently serves as a pseudo-reward for downstream RL. Inaccuracies in the learned discriminator can cascade, negatively influencing the resulting policy. We present a novel approach to GCRL under a new lens of mixture-distribution matching, leading to our discriminator-free method: SMORe. The key insight is combining the occupancy matching perspective of GCRL with a convex dual formulation to derive a learning objective that can better leverage suboptimal offline data. SMORe learns scores or unnormalized densities representing the importance of taking an action at a state for reaching a particular goal. SMORe is principled and our extensive experiments on the fully offline GCRL benchmark composed of robot manipulation and locomotion tasks, including high-dimensional observations, show that SMORe can outperform state-of-the-art baselines by a significant margin.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.AI",
            "cs.RO"
        ],
        "submitted_date": "3 Nov 2023",
        "last_revised_date": " "
    },
    "2311.02786": {
        "title": "Mobility as a Resource (MaaR) for resilient human-centric automation: a vision paper",
        "authors": [
            "S. Travis Waller",
            "Amalia Polydoropoulou",
            "Leandros Tassiulas",
            "Athanasios Ziliaskopoulos",
            "Sisi Jian",
            "Susann Wagenknecht",
            "Georg Hirte",
            "Satish Ukkusuri",
            "Gitakrishnan Ramadurai",
            "Tomasz Bednarz"
        ],
        "comments": " ",
        "subjects": "Systems and Control (eess.SY)",
        "abstract": "With technological advances, mobility has been moving from a product (i.e., traditional modes and vehicles), to a service (i.e., Mobility as a Service, MaaS). However, as observed in other fields (e.g. cloud computing resource management) we argue that mobility will evolve from a service to a resource (i.e., Mobility as a Resource, MaaR). Further, due to increasing scarcity of shared mobility spaces across traditional and emerging modes, the transition must be viewed within the critical need for ethical and equitable solutions for the traveling public (i.e., research is needed to avoid hyper-market driven outcomes for society). The evolution of mobility into a resource requires novel conceptual frameworks, technologies, processes and perspectives of analysis. A key component of the future MaaR system is the technological capacity to observe, allocate and manage (in real-time) the smallest envisionable units of mobility (i.e., atomic units of mobility capacity) while providing prioritized attention to human movement and ethical metrics related to access, consumption and impact. To facilitate research into the envisioned future system, this paper proposes initial frameworks which synthesize and advance methodologies relating to highly dynamic capacity reservation systems. Future research requires synthesis across transport network management, demand behavior, mixed-mode usage, and equitable mobility.\n    ",
        "primary_category": "eess.SY",
        "categories": [],
        "submitted_date": "5 Nov 2023",
        "last_revised_date": " "
    },
    "2311.03758": {
        "title": "Large Language Model based Long-tail Query Rewriting in Taobao Search",
        "authors": [
            "Wenjun Peng",
            "Guiyang Li",
            "Yue Jiang",
            "Zilong Wang",
            "Dan Ou",
            "Xiaoyi Zeng",
            "Derong Xu",
            "Tong Xu",
            "Enhong Chen"
        ],
        "comments": "WWW Industry",
        "subjects": "Information Retrieval (cs.IR)",
        "abstract": "In the realm of e-commerce search, the significance of semantic matching cannot be overstated, as it directly impacts both user experience and company revenue. Along this line, query rewriting, serving as an important technique to bridge the semantic gaps inherent in the semantic matching process, has attached wide attention from the industry and academia. However, existing query rewriting methods often struggle to effectively optimize long-tail queries and alleviate the phenomenon of \"few-recall\" caused by semantic gap. In this paper, we present BEQUE, a comprehensive framework that Bridges the sEmantic gap for long-tail QUEries. In detail, BEQUE comprises three stages: multi-instruction supervised fine tuning (SFT), offline feedback, and objective alignment. We first construct a rewriting dataset based on rejection sampling and auxiliary tasks mixing to fine-tune our large language model (LLM) in a supervised fashion. Subsequently, with the well-trained LLM, we employ beam search to generate multiple candidate rewrites, and feed them into Taobao offline system to obtain the partial order. Leveraging the partial order of rewrites, we introduce a contrastive learning method to highlight the distinctions between rewrites, and align the model with the Taobao online objectives. Offline experiments prove the effectiveness of our method in bridging semantic gap. Online A/B tests reveal that our method can significantly boost gross merchandise volume (GMV), number of transaction (#Trans) and unique visitor (UV) for long-tail queries. BEQUE has been deployed on Taobao, one of most popular online shopping platforms in China, since October 2023.\n    ",
        "primary_category": "cs.IR",
        "categories": [],
        "submitted_date": "7 Nov 2023",
        "last_revised_date": " "
    },
    "2311.03764": {
        "title": "Neuro-GPT: Towards A Foundation Model for EEG",
        "authors": [
            "Wenhui Cui",
            "Woojae Jeong",
            "Philipp Th\u00f6lke",
            "Takfarinas Medani",
            "Karim Jerbi",
            "Anand A. Joshi",
            "Richard M. Leahy"
        ],
        "comments": "Paper accepted by the 2024 IEEE International Symposium on Biomedical Imaging (ISBI)",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "To handle the scarcity and heterogeneity of electroencephalography (EEG) data for Brain-Computer Interface (BCI) tasks, and to harness the power of large publicly available data sets, we propose Neuro-GPT, a foundation model consisting of an EEG encoder and a GPT model. The foundation model is pre-trained on a large-scale data set using a self-supervised task that learns how to reconstruct masked EEG segments. We then fine-tune the model on a Motor Imagery Classification task to validate its performance in a low-data regime (9 subjects). Our experiments demonstrate that applying a foundation model can significantly improve classification performance compared to a model trained from scratch, which provides evidence for the generalizability of the foundation model and its ability to address challenges of data scarcity and heterogeneity in EEG. The code is publicly available at this http URL.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "eess.SP"
        ],
        "submitted_date": "7 Nov 2023",
        "last_revised_date": " "
    },
    "2311.04194": {
        "title": "Quantization-aware Neural Architectural Search for Intrusion Detection",
        "authors": [
            "Rabin Yu Acharya",
            "Laurens Le Jeune",
            "Nele Mentens",
            "Fatemeh Ganji",
            "Domenic Forte"
        ],
        "comments": " ",
        "subjects": "Cryptography and Security (cs.CR)",
        "abstract": "Deploying machine learning-based intrusion detection systems (IDSs) on hardware devices is challenging due to their limited computational resources, power consumption, and network connectivity. Hence, there is a significant need for robust, deep learning models specifically designed with such constraints in mind. In this paper, we present a design methodology that automatically trains and evolves quantized neural network (NN) models that are a thousand times smaller than state-of-the-art NNs but can efficiently analyze network data for intrusion at high accuracy. In this regard, the number of LUTs utilized by this network when deployed to an FPGA is between 2.3x and 8.5x smaller with performance comparable to prior work.\n    ",
        "primary_category": "cs.CR",
        "categories": [],
        "submitted_date": "7 Nov 2023",
        "last_revised_date": " "
    },
    "2311.04916": {
        "title": "Explainable Identification of Hate Speech towards Islam using Graph Neural Networks",
        "authors": [
            "Azmine Toushik Wasi"
        ],
        "comments": "3 pages, 2 figures; NeurIPS 2023 Workshop Muslims in ML. Openreview forum: this https URL",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "Islamophobic language is a prevalent challenge on online social interaction platforms. Identifying and eliminating such hatred is a crucial step towards a future of harmony and peace. This study presents a novel paradigm for identifying and explaining hate speech towards Islam using graph neural networks. Utilizing the intrinsic ability of graph neural networks to find, extract, and use relationships across disparate data points, our model consistently achieves outstanding performance while offering explanations for the underlying correlations and causation.\n    ",
        "primary_category": "cs.CL",
        "categories": [
            "cs.AI",
            "cs.IR",
            "cs.LG",
            "cs.SI"
        ],
        "submitted_date": "2 Nov 2023",
        "last_revised_date": " "
    },
    "2311.05112": {
        "title": "A Survey of Large Language Models in Medicine: Progress, Application, and Challenge",
        "authors": [
            "Hongjian Zhou",
            "Fenglin Liu",
            "Boyang Gu",
            "Xinyu Zou",
            "Jinfa Huang",
            "Jinge Wu",
            "Yiru Li",
            "Sam S. Chen",
            "Peilin Zhou",
            "Junling Liu",
            "Yining Hua",
            "Chengfeng Mao",
            "Chenyu You",
            "Xian Wu",
            "Yefeng Zheng",
            "Lei Clifton",
            "Zheng Li",
            "Jiebo Luo",
            "David A. Clifton"
        ],
        "comments": "Preprint. Version 4. 7 figures; 13 tables; 49 pages",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "Large language models (LLMs), such as ChatGPT, have received substantial attention due to their capabilities for understanding and generating human language. While there has been a burgeoning trend in research focusing on the employment of LLMs in supporting different medical tasks (e.g., enhancing clinical diagnostics and providing medical education), a review of these efforts, particularly their development, practical applications, and outcomes in medicine, remains scarce. Therefore, this review aims to provide a detailed overview of the development and deployment of LLMs in medicine, including the challenges and opportunities they face. In terms of development, we provide a detailed introduction to the principles of existing medical LLMs, including their basic model structures, number of parameters, and sources and scales of data used for model development. It serves as a guide for practitioners in developing medical LLMs tailored to their specific needs. In terms of deployment, we offer a comparison of the performance of different LLMs across various medical tasks, and further compare them with state-of-the-art lightweight models, aiming to provide an understanding of the advantages and limitations of LLMs in medicine. Overall, in this review, we address the following questions: 1) What are the practices for developing medical LLMs 2) How to measure the medical task performance of LLMs in a medical setting? 3) How have medical LLMs been employed in real-world practice? 4) What challenges arise from the use of medical LLMs? and 5) How to more effectively develop and deploy medical LLMs? By answering these questions, this review aims to provide insights into the opportunities for LLMs in medicine and serve as a practical resource. We also maintain a regularly updated list of practical guides on medical LLMs at: this https URL.\n    ",
        "primary_category": "cs.CL",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "9 Nov 2023",
        "last_revised_date": " "
    },
    "2311.05181": {
        "title": "Energy-efficient flocking with nonlinear navigational feedback",
        "authors": [
            "Oleksandr Dykhovychnyi",
            "Alexander Panchenko"
        ],
        "comments": " ",
        "subjects": "Dynamical Systems (math.DS)",
        "abstract": "Modeling collective motion in multi-agent systems has gained much attention in recent years. In particular, of interest are the conditions under which flocking dynamics emerges. We present a generalization of the multi-agent model of Olfati--Saber with nonlinear navigational feedback forces. As opposed to the original model, our model is, in general, not dissipative. This makes obtaining sufficient conditions for flocking challenging due to the absence of an obvious choice of a Lyapunov function. By means of an alternative argument, we show that our model possesses a global attractor when the navigational feedback forces are bounded perturbations of the linear ones. We further demonstrate that, under mild conditions, the dynamics of the group converges to a complete velocity consensus at an exponential rate. We show that the attractor of a dissipative system can contain non-equilibrium solutions. We construct explicit examples of such solutions and obtain conditions under which they cannot exist. In addition, we present a case study of the energy efficiency of our model. We show how nonlinear navigational feedback forces, which possess flexibility that linear forces lack, can be used to reduce on-board energy consumption.\n    ",
        "primary_category": "math.DS",
        "categories": [
            "cs.MA"
        ],
        "submitted_date": "9 Nov 2023",
        "last_revised_date": " "
    },
    "2311.05818": {
        "title": "Learning Agile Bipedal Motions on a Quadrupedal Robot",
        "authors": [
            "Yunfei Li",
            "Jinhan Li",
            "Wei Fu",
            "Yi Wu"
        ],
        "comments": "Camera ready for ICRA 2024",
        "subjects": "Robotics (cs.RO)",
        "abstract": "Can a quadrupedal robot perform bipedal motions like humans? Although developing human-like behaviors is more often studied on costly bipedal robot platforms, we present a solution over a lightweight quadrupedal robot that unlocks the agility of the quadruped in an upright standing pose and is capable of a variety of human-like motions. Our framework is with a hierarchical structure. At the low level is a motion-conditioned control policy that allows the quadrupedal robot to track desired base and front limb movements while balancing on two hind feet. The policy is commanded by a high-level motion generator that gives trajectories of parameterized human-like motions to the robot from multiple modalities of human input. We for the first time demonstrate various bipedal motions on a quadrupedal robot, and showcase interesting human-robot interaction modes including mimicking human videos, following natural language instructions, and physical interaction. The video is available at this https URL.\n    ",
        "primary_category": "cs.RO",
        "categories": [],
        "submitted_date": "10 Nov 2023",
        "last_revised_date": " "
    },
    "2311.05919": {
        "title": "Inter-object Discriminative Graph Modeling for Indoor Scene Recognition",
        "authors": [
            "Chuanxin Song",
            "Hanbo Wu",
            "Xin Ma"
        ],
        "comments": " ",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Variable scene layouts and coexisting objects across scenes make indoor scene recognition still a challenging task. Leveraging object information within scenes to enhance the distinguishability of feature representations has emerged as a key approach in this domain. Currently, most object-assisted methods use a separate branch to process object information, combining object and scene features heuristically. However, few of them pay attention to interpretably handle the hidden discriminative knowledge within object information. In this paper, we propose to leverage discriminative object knowledge to enhance scene feature representations. Initially, we capture the object-scene discriminative relationships from a probabilistic perspective, which are transformed into an Inter-Object Discriminative Prototype (IODP). Given the abundant prior knowledge from IODP, we subsequently construct a Discriminative Graph Network (DGN), in which pixel-level scene features are defined as nodes and the discriminative relationships between node features are encoded as edges. DGN aims to incorporate inter-object discriminative knowledge into the image representation through graph convolution and mapping operations (GCN). With the proposed IODP and DGN, we obtain state-of-the-art results on several widely used scene datasets, demonstrating the effectiveness of the proposed approach.\n    ",
        "primary_category": "cs.CV",
        "categories": [],
        "submitted_date": "10 Nov 2023",
        "last_revised_date": " "
    },
    "2311.06534": {
        "title": "Translating Legalese: Enhancing Public Understanding of Court Opinions with Legal Summarizers",
        "authors": [
            "Elliott Ash",
            "Aniket Kesari",
            "Suresh Naidu",
            "Lena Song",
            "Dominik Stammbach"
        ],
        "comments": "published in proceedings of CSLAW 2024: Symposium on Computer Science and Law",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "Judicial opinions are written to be persuasive and could build public trust in court decisions, yet they can be difficult for non-experts to understand. We present a pipeline for using an AI assistant to generate simplified summaries of judicial opinions. Compared to existing expert-written summaries, these AI-generated simple summaries are more accessible to the public and more easily understood by non-experts. We show in a survey experiment that the AI summaries help respondents understand the key features of a ruling, and have higher perceived quality, especially for respondents with less formal education.\n    ",
        "primary_category": "cs.CL",
        "categories": [],
        "submitted_date": "11 Nov 2023",
        "last_revised_date": " "
    },
    "2311.06956": {
        "title": "SegReg: Segmenting OARs by Registering MR Images and CT Annotations",
        "authors": [
            "Zeyu Zhang",
            "Xuyin Qi",
            "Bowen Zhang",
            "Biao Wu",
            "Hien Le",
            "Bora Jeong",
            "Zhibin Liao",
            "Yunxiang Liu",
            "Johan Verjans",
            "Minh-Son To",
            "Richard Hartley"
        ],
        "comments": "Accepted to ISBI 2024",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Organ at risk (OAR) segmentation is a critical process in radiotherapy treatment planning such as head and neck tumors. Nevertheless, in clinical practice, radiation oncologists predominantly perform OAR segmentations manually on CT scans. This manual process is highly time-consuming and expensive, limiting the number of patients who can receive timely radiotherapy. Additionally, CT scans offer lower soft-tissue contrast compared to MRI. Despite MRI providing superior soft-tissue visualization, its time-consuming nature makes it infeasible for real-time treatment planning. To address these challenges, we propose a method called SegReg, which utilizes Elastic Symmetric Normalization for registering MRI to perform OAR segmentation. SegReg outperforms the CT-only baseline by 16.78% in mDSC and 18.77% in mIoU, showing that it effectively combines the geometric accuracy of CT with the superior soft-tissue contrast of MRI, making accurate automated OAR segmentation for clinical practice become possible. See project website this https URL\n",
        "primary_category": "cs.CV",
        "categories": [],
        "submitted_date": "12 Nov 2023",
        "last_revised_date": " "
    },
    "2311.07346": {
        "title": "Goal-oriented Estimation of Multiple Markov Sources in Resource-constrained Systems",
        "authors": [
            "Jiping Luo",
            "Nikolaos Pappas"
        ],
        "comments": " ",
        "subjects": "Systems and Control (eess.SY)",
        "abstract": "This paper investigates goal-oriented communication for remote estimation of multiple Markov sources in resource-constrained networks. An agent decides the updating times of the sources and transmits the packet to a remote destination over an unreliable channel with delay. The destination is tasked with source reconstruction for actuation. We utilize the metric \\textit{cost of actuation error} (CAE) to capture the state-dependent actuation costs. We aim for a sampling policy that minimizes the long-term average CAE subject to an average resource constraint. We formulate this problem as an average-cost constrained Markov Decision Process (CMDP) and relax it into an unconstrained problem by utilizing \\textit{Lyapunov drift} techniques. Then, we propose a low-complexity \\textit{drift-plus-penalty} (DPP) policy for systems with known source/channel statistics and a Lyapunov optimization-based deep reinforcement learning (LO-DRL) policy for unknown environments. Our policies significantly reduce the number of uninformative transmissions by exploiting the timing of the important information.\n    ",
        "primary_category": "eess.SY",
        "categories": [
            "cs.IT",
            "cs.NI"
        ],
        "submitted_date": "13 Nov 2023",
        "last_revised_date": " "
    },
    "2311.07434": {
        "title": "Understanding Users' Dissatisfaction with ChatGPT Responses: Types, Resolving Tactics, and the Effect of Knowledge Level",
        "authors": [
            "Yoonsu Kim",
            "Jueon Lee",
            "Seoyoung Kim",
            "Jaehyuk Park",
            "Juho Kim"
        ],
        "comments": " ",
        "subjects": "Human-Computer Interaction (cs.HC)",
        "abstract": "Large language models (LLMs) with chat-based capabilities, such as ChatGPT, are widely used in various workflows. However, due to a limited understanding of these large-scale models, users struggle to use this technology and experience different kinds of dissatisfaction. Researchers have introduced several methods, such as prompt engineering, to improve model responses. However, they focus on enhancing the model's performance in specific tasks, and little has been investigated on how to deal with the user dissatisfaction resulting from the model's responses. Therefore, with ChatGPT as the case study, we examine users' dissatisfaction along with their strategies to address the dissatisfaction. After organizing users' dissatisfaction with LLM into seven categories based on a literature review, we collected 511 instances of dissatisfactory ChatGPT responses from 107 users and their detailed recollections of dissatisfactory experiences, which we released as a publicly accessible dataset. Our analysis reveals that users most frequently experience dissatisfaction when ChatGPT fails to grasp their intentions, while they rate the severity of dissatisfaction related to accuracy the highest. We also identified four tactics users employ to address their dissatisfaction and their effectiveness. We found that users often do not use any tactics to address their dissatisfaction, and even when using tactics, 72% of dissatisfaction remained unresolved. Moreover, we found that users with low knowledge of LLMs tend to face more dissatisfaction on accuracy while they often put minimal effort in addressing dissatisfaction. Based on these findings, we propose design implications for minimizing user dissatisfaction and enhancing the usability of chat-based LLM.\n    ",
        "primary_category": "cs.HC",
        "categories": [],
        "submitted_date": "13 Nov 2023",
        "last_revised_date": " "
    },
    "2311.07499": {
        "title": "Bridging the Sim-to-Real Gap with Dynamic Compliance Tuning for Industrial Insertion",
        "authors": [
            "Xiang Zhang",
            "Masayoshi Tomizuka",
            "Hui Li"
        ],
        "comments": "Accepted by ICRA 24",
        "subjects": "Robotics (cs.RO)",
        "abstract": "Contact-rich manipulation tasks often exhibit a large sim-to-real gap. For instance, industrial assembly tasks frequently involve tight insertions where the clearance is less than 0.1 mm and can even be negative when dealing with a deformable receptacle. This narrow clearance leads to complex contact dynamics that are difficult to model accurately in simulation, making it challenging to transfer simulation-learned policies to real-world robots. In this paper, we propose a novel framework for robustly learning manipulation skills for real-world tasks using simulated data only. Our framework consists of two main components: the \"Force Planner\" and the \"Gain Tuner\". The Force Planner plans both the robot motion and desired contact force, while the Gain Tuner dynamically adjusts the compliance control gains to track the desired contact force during task execution. The key insight is that by dynamically adjusting the robot's compliance control gains during task execution, we can modulate contact force in the new environment, thereby generating trajectories similar to those trained in simulation and narrowing the sim-to-real gap. Experimental results show that our method, trained in simulation on a generic square peg-and-hole task, can generalize to a variety of real-world insertion tasks involving narrow and negative clearances, all without requiring any fine-tuning. Videos are available at this https URL.\n    ",
        "primary_category": "cs.RO",
        "categories": [],
        "submitted_date": "13 Nov 2023",
        "last_revised_date": " "
    },
    "2311.07548": {
        "title": "Interpretable Fine-Tuning for Graph Neural Network Surrogate Models",
        "authors": [
            "Shivam Barwey",
            "Romit Maulik"
        ],
        "comments": " ",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Data-driven surrogate modeling has surged in capability in recent years with the emergence of graph neural networks (GNNs), which can operate directly on mesh-based representations of data. The goal of this work is to introduce an interpretable fine-tuning strategy for GNNs, with application to unstructured mesh-based fluid dynamics modeling. The end result is an enhanced fine-tuned model that isolates regions in physical space, corresponding to sub-graphs, that are intrinsically linked to the forecasting task while retaining the predictive capability of the baseline. These structures, identified by the fine-tuned GNNs, are adaptively produced in the forward pass and serve as explainable links between the baseline model architecture, the optimization goal, and known problem-specific physics. Additionally, through a regularization procedure, the fine-tuned GNNs can also be used to identify, during inference, graph nodes that correspond to a majority of the anticipated forecasting error, adding a novel interpretable error-tagging capability to baseline models. Demonstrations are performed using unstructured flow field data sourced from flow over a backward-facing step at high Reynolds numbers.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "physics.comp-ph",
            "physics.flu-dyn"
        ],
        "submitted_date": "13 Nov 2023",
        "last_revised_date": " "
    },
    "2311.08107": {
        "title": "SAIE Framework: Support Alone Isn't Enough -- Advancing LLM Training with Adversarial Remarks",
        "authors": [
            "Mengsay Loem",
            "Masahiro Kaneko",
            "Naoaki Okazaki"
        ],
        "comments": " ",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "Large Language Models (LLMs) can justify or critique their predictions through discussions with other models or humans, thereby enriching their intrinsic understanding of instances. While proactive discussions in the inference phase have been shown to boost performance, such interactions have not been extensively explored during the training phase. We hypothesize that incorporating interactive discussions into the training process can enhance the models' understanding and improve their reasoning and verbal expression abilities during inference. This work introduces the SAIE framework, which facilitates supportive and adversarial discussions between learner and partner models. The learner model receives responses from the partner, and its parameters are then updated based on this discussion. This dynamic adjustment process continues throughout the training phase, responding to the evolving outputs of the learner model. Our empirical evaluation across various tasks, including math problems, commonsense reasoning, and multi-domain knowledge, demonstrates that models fine-tuned with the SAIE framework outperform those trained with conventional fine-tuning approaches. Furthermore, our method enhances the models' reasoning capabilities, improving both individual and multi-agent inference performance.\n    ",
        "primary_category": "cs.CL",
        "categories": [],
        "submitted_date": "14 Nov 2023",
        "last_revised_date": " "
    },
    "2311.08168": {
        "title": "Time-Uniform Confidence Spheres for Means of Random Vectors",
        "authors": [
            "Ben Chugg",
            "Hongjian Wang",
            "Aaditya Ramdas"
        ],
        "comments": "46 pages, 1 figure",
        "subjects": "Statistics Theory (math.ST)",
        "abstract": "We derive and study time-uniform confidence spheres -- confidence sphere sequences (CSSs) -- which contain the mean of random vectors with high probability simultaneously across all sample sizes. Inspired by the original work of Catoni and Giulini, we unify and extend their analysis to cover both the sequential setting and to handle a variety of distributional assumptions. Our results include an empirical-Bernstein CSS for bounded random vectors (resulting in a novel empirical-Bernstein confidence interval with asymptotic width scaling proportionally to the true unknown variance), CSSs for sub-$\\psi$ random vectors (which includes sub-gamma, sub-Poisson, and sub-exponential), and CSSs for heavy-tailed random vectors (two moments only). Finally, we provide two CSSs that are robust to contamination by Huber noise. The first is a robust version of our empirical-Bernstein CSS, and the second extends recent work in the univariate setting to heavy-tailed multivariate distributions.\n    ",
        "primary_category": "math.ST",
        "categories": [
            "cs.IT",
            "stat.ME",
            "stat.ML"
        ],
        "submitted_date": "14 Nov 2023",
        "last_revised_date": " "
    },
    "2311.08631": {
        "title": "Influence of Video Dynamics on EEG-based Single-Trial Video Target Surveillance System",
        "authors": [
            "Heon-Gyu Kwak",
            "Sung-Jin Kim",
            "Hyeon-Taek Han",
            "Ji-Hoon Jeong",
            "Seong-Whan Lee"
        ],
        "comments": "2024 International BCI winter conference accepted paper",
        "subjects": "Human-Computer Interaction (cs.HC)",
        "abstract": "Target detection models are one of the widely used deep learning-based applications for reducing human efforts on video surveillance and patrol. However, the application of conventional computer vision-based target detection models in military usage can result in limited performance, due to the lack of sample data of hostile targets. In this paper, we present the possibility of the electroencephalography-based video target detection model, which could be applied as a supportive module of the military video surveillance system. The proposed framework and detection model showed prospective performance achieving a mean macro F-beta of 0.6522 with asynchronous real-time data from five subjects, in a certain video stimulus, but not on some video stimuli. By analyzing the results of experiments using each video stimulus, we present the factors that would affect the performance of electroencephalography-based video target detection models.\n    ",
        "primary_category": "cs.HC",
        "categories": [],
        "submitted_date": "15 Nov 2023",
        "last_revised_date": " "
    },
    "2311.08675": {
        "title": "Refined Coreset Selection: Towards Minimal Coreset Size under Model Performance Constraints",
        "authors": [
            "Xiaobo Xia",
            "Jiale Liu",
            "Shaokun Zhang",
            "Qingyun Wu",
            "Hongxin Wei",
            "Tongliang Liu"
        ],
        "comments": "22 pages, 10 tables, 4 figures",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Coreset selection is powerful in reducing computational costs and accelerating data processing for deep learning algorithms. It strives to identify a small subset from large-scale data, so that training only on the subset practically performs on par with full data. Practitioners regularly desire to identify the smallest possible coreset in realistic scenes while maintaining comparable model performance, to minimize costs and maximize acceleration. Motivated by this desideratum, for the first time, we pose the problem of refined coreset selection, in which the minimal coreset size under model performance constraints is explored. Moreover, to address this problem, we propose an innovative method, which maintains optimization priority order over the model performance and coreset size, and efficiently optimizes them in the coreset selection procedure. Theoretically, we provide the convergence guarantee of the proposed method. Empirically, extensive experiments confirm its superiority compared with previous strategies, often yielding better model performance with smaller coreset sizes.\n    ",
        "primary_category": "cs.LG",
        "categories": [],
        "submitted_date": "15 Nov 2023",
        "last_revised_date": " "
    },
    "2311.08919": {
        "title": "FCS-HGNN: Flexible Multi-type Community Search in Heterogeneous Information Networks",
        "authors": [
            "Guoxin Chen",
            "Fangda Guo",
            "Yongqing Wang",
            "Yanghao Liu",
            "Peiying Yu",
            "Huawei Shen",
            "Xueqi Cheng"
        ],
        "comments": "Ongoing Work",
        "subjects": "Social and Information Networks (cs.SI)",
        "abstract": "Community search is a personalized community discovery problem designed to identify densely connected subgraphs containing the query node. Recently, community search in heterogeneous information networks (HINs) has received considerable attention. Existing methods typically focus on modeling relationships in HINs through predefined meta-paths or user-specified relational constraints. However, metapath-based methods are primarily designed to identify single-type communities with nodes of the same type rather than multi-type communities involving nodes of different types. Constraint-based methods require users to have a good understanding of community patterns to define a suitable set of relational constraints, which increases the burden on users. In this paper, we propose FCS-HGNN, a novel method for flexibly identifying both single-type and multi-type communities in HINs. Specifically, FCS-HGNN extracts complementary information from different views and dynamically considers the contribution of each relation instead of treating them equally, thereby capturing more fine-grained heterogeneous information. Furthermore, to improve efficiency on large-scale graphs, we further propose LS-FCS-HGNN, which incorporates i) the neighbor sampling strategy to improve training efficiency, and ii) the depth-based heuristic search strategy to improve query efficiency. We conducted extensive experiments to demonstrate the superiority of our proposed methods over state-of-the-art methods, achieving average improvements of 14.3% and 11.1% on single-type and multi-type communities, respectively.\n    ",
        "primary_category": "cs.SI",
        "categories": [],
        "submitted_date": "15 Nov 2023",
        "last_revised_date": " "
    },
    "2311.09010": {
        "title": "Analysis of sum-of-squares relaxations for the quantum rotor model",
        "authors": [
            "Sujit Rao"
        ],
        "comments": "34 pages, appeared at QIP 2024",
        "subjects": "Quantum Physics (quant-ph)",
        "abstract": "The noncommutative sum-of-squares (ncSoS) hierarchy was introduced by Navascu\u00e9s-Pironio-Ac\u00edn as a sequence of semidefinite programming relaxations for approximating values of noncommutative polynomial optimization problems, which were originally intended to generalize quantum values of nonlocal games. Recent work has started to analyze the hierarchy for approximating ground energies of local Hamiltonians, initially through rounding algorithms which output product states for degree-2 ncSoS applied to Quantum Max-Cut. Some rounding methods are known which output entangled states, but they use degree-4 ncSoS. Based on this, Hwang-Neeman-Parekh-Thompson-Wright conjectured that degree-2 ncSoS cannot beat product state approximations for Quantum Max-Cut and gave a partial proof relying on a conjectural generalization of Borrell's inequality. In this work we consider a family of Hamiltonians (called the quantum rotor model in condensed matter literature or lattice $O(k)$ vector model in quantum field theory) with infinite-dimensional local Hilbert space $L^{2}(S^{k - 1})$, and show that a degree-2 ncSoS relaxation approximates the ground state energy better than any product state.\n    ",
        "primary_category": "quant-ph",
        "categories": [
            "cs.DS"
        ],
        "submitted_date": "15 Nov 2023",
        "last_revised_date": " "
    },
    "2311.09033": {
        "title": "MELA: Multilingual Evaluation of Linguistic Acceptability",
        "authors": [
            "Ziyin Zhang",
            "Yikang Liu",
            "Weifang Huang",
            "Junyu Mao",
            "Rui Wang",
            "Hai Hu"
        ],
        "comments": " ",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "Recent benchmarks for Large Language Models (LLMs) have mostly focused on application-driven tasks such as complex reasoning and code generation, and this has led to a scarcity in purely linguistic evaluation of LLMs. Against this background, we introduce Multilingual Evaluation of Linguistic Acceptability -- MELA, the first multilingual benchmark on linguistic acceptability with 48K samples covering 10 languages from a diverse set of language families. We establish baselines of commonly used LLMs along with supervised models, and conduct cross-lingual transfer and multi-task learning experiments with XLM-R. In pursuit of multilingual interpretability, we analyze the weights of fine-tuned XLM-R to explore the possibility of identifying transfer difficulty between languages. Our results show that ChatGPT benefits much from in-context examples but still lags behind fine-tuned XLM-R, while the performance of GPT-4 is on par with fine-tuned XLM-R even in zero-shot setting. Cross-lingual and multi-task learning experiments show that unlike semantic tasks, in-language training data is crucial in acceptability judgements. Results in layerwise probing indicate that the upper layers of XLM-R become a task-specific but language-agnostic region for multilingual acceptability judgment. We also introduce the concept of conflicting weight, which could be a potential indicator for the difficulty of cross-lingual transfer between languages. Our data will be available at this https URL.\n    ",
        "primary_category": "cs.CL",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "15 Nov 2023",
        "last_revised_date": " "
    },
    "2311.09510": {
        "title": "One Size Does Not Fit All: Customizing Open-Domain Procedures",
        "authors": [
            "Yash Kumar Lal",
            "Li Zhang",
            "Faeze Brahman",
            "Bodhisattwa Prasad Majumder",
            "Peter Clark",
            "Niket Tandon"
        ],
        "comments": " ",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "How-to procedures, such as how to plant a garden, are now used by millions of users, but sometimes need customizing to meet a user's specific needs, e.g., planting a garden without pesticides. Our goal is to measure and improve an LLM's ability to perform such customization. Our approach is to test several simple multi-LLM-agent architectures for customization, as well as an end-to-end LLM, using a new evaluation set, called CustomPlans, of over 200 WikiHow procedures each with a customization need. We find that a simple architecture with two LLM agents used sequentially performs best, one that edits a generic how-to procedure and one that verifies its executability, significantly outperforming (10.5% absolute) an end-to-end prompted LLM. This suggests that LLMs can be configured reasonably effectively for procedure customization. This also suggests that multi-agent editing architectures may be worth exploring further for other customization applications (e.g. coding, creative writing) in the future.\n    ",
        "primary_category": "cs.CL",
        "categories": [],
        "submitted_date": "16 Nov 2023",
        "last_revised_date": " "
    },
    "2311.09758": {
        "title": "OrchestraLLM: Efficient Orchestration of Language Models for Dialogue State Tracking",
        "authors": [
            "Chia-Hsuan Lee",
            "Hao Cheng",
            "Mari Ostendorf"
        ],
        "comments": "updated version",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "Large language models (LLMs) have revolutionized the landscape of Natural Language Processing systems, but are computationally expensive. To reduce the cost without sacrificing performance, previous studies have explored various approaches to harness the potential of Small Language Models (SLMs) as cost-effective alternatives to their larger counterparts. Driven by findings that SLMs and LLMs exhibit complementary strengths in a structured knowledge extraction task, this work presents a novel SLM/LLM routing framework designed to improve computational efficiency and enhance task performance. First, exemplar pools are created to represent the types of contexts where each LM provides a more reliable answer, leveraging a sentence embedding fine-tuned so that context similarity is close to dialogue state similarity. Then, during inference, the k-nearest exemplars to the testing instance are retrieved, and the instance is routed according to majority vote. In dialogue state tracking tasks, the proposed routing framework enhances performance substantially compared to relying solely on LLMs, while reducing the computational costs by over 50%.\n    ",
        "primary_category": "cs.CL",
        "categories": [],
        "submitted_date": "16 Nov 2023",
        "last_revised_date": " "
    },
    "2311.09800": {
        "title": "$\\textit{Dial BeInfo for Faithfulness}$: Improving Factuality of Information-Seeking Dialogue via Behavioural Fine-Tuning",
        "authors": [
            "Evgeniia Razumovskaia",
            "Ivan Vuli\u0107",
            "Pavle Markovi\u0107",
            "Tomasz Cichy",
            "Qian Zheng",
            "Tsung-Hsien Wen",
            "Pawe\u0142 Budzianowski"
        ],
        "comments": " ",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "Factuality is a crucial requirement in information seeking dialogue: the system should respond to the user's queries so that the responses are meaningful and aligned with the knowledge provided to the system. However, most modern large language models suffer from hallucinations, that is, they generate responses not supported by or contradicting the knowledge source. To mitigate the issue and increase faithfulness of information-seeking dialogue systems, we introduce BeInfo, a simple yet effective method that applies behavioural tuning to aid information-seeking dialogue. Relying on three standard datasets, we show that models tuned with BeInfo} become considerably more faithful to the knowledge source both for datasets and domains seen during BeInfo-tuning, as well as on unseen domains, when applied in a zero-shot manner. In addition, we show that the models with 3B parameters (e.g., Flan-T5) tuned with BeInfo demonstrate strong performance on data from real `production' conversations and outperform GPT4 when tuned on a limited amount of such realistic in-domain dialogues.\n    ",
        "primary_category": "cs.CL",
        "categories": [],
        "submitted_date": "16 Nov 2023",
        "last_revised_date": " "
    },
    "2311.09827": {
        "title": "Cognitive Overload: Jailbreaking Large Language Models with Overloaded Logical Thinking",
        "authors": [
            "Nan Xu",
            "Fei Wang",
            "Ben Zhou",
            "Bang Zheng Li",
            "Chaowei Xiao",
            "Muhao Chen"
        ],
        "comments": " ",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "While large language models (LLMs) have demonstrated increasing power, they have also given rise to a wide range of harmful behaviors. As representatives, jailbreak attacks can provoke harmful or unethical responses from LLMs, even after safety alignment. In this paper, we investigate a novel category of jailbreak attacks specifically designed to target the cognitive structure and processes of LLMs. Specifically, we analyze the safety vulnerability of LLMs in the face of (1) multilingual cognitive overload, (2) veiled expression, and (3) effect-to-cause reasoning. Different from previous jailbreak attacks, our proposed cognitive overload is a black-box attack with no need for knowledge of model architecture or access to model weights. Experiments conducted on AdvBench and MasterKey reveal that various LLMs, including both popular open-source model Llama 2 and the proprietary model ChatGPT, can be compromised through cognitive overload. Motivated by cognitive psychology work on managing cognitive load, we further investigate defending cognitive overload attack from two perspectives. Empirical studies show that our cognitive overload from three perspectives can jailbreak all studied LLMs successfully, while existing defense strategies can hardly mitigate the caused malicious uses effectively.\n    ",
        "primary_category": "cs.CL",
        "categories": [],
        "submitted_date": "16 Nov 2023",
        "last_revised_date": " "
    },
    "2311.09858": {
        "title": "Polynomially Over-Parameterized Convolutional Neural Networks Contain Structured Strong Winning Lottery Tickets",
        "authors": [
            "Arthur da Cunha",
            "Francesco d'Amore",
            "Emanuele Natale"
        ],
        "comments": "To be published in the 37th Conference on Neural Information Processing Systems (NeurIPS 2023)",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "The Strong Lottery Ticket Hypothesis (SLTH) states that randomly-initialised neural networks likely contain subnetworks that perform well without any training. Although unstructured pruning has been extensively studied in this context, its structured counterpart, which can deliver significant computational and memory efficiency gains, has been largely unexplored. One of the main reasons for this gap is the limitations of the underlying mathematical tools used in formal analyses of the SLTH. In this paper, we overcome these limitations: we leverage recent advances in the multidimensional generalisation of the Random Subset-Sum Problem and obtain a variant that admits the stochastic dependencies that arise when addressing structured pruning in the SLTH. We apply this result to prove, for a wide class of random Convolutional Neural Networks, the existence of structured subnetworks that can approximate any sufficiently smaller network.\nThis result provides the first sub-exponential bound around the SLTH for structured pruning, opening up new avenues for further research on the hypothesis and contributing to the understanding of the role of over-parameterization in deep learning.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "math.CO",
            "math.PR"
        ],
        "submitted_date": "16 Nov 2023",
        "last_revised_date": " "
    },
    "2311.12075": {
        "title": "BadCLIP: Dual-Embedding Guided Backdoor Attack on Multimodal Contrastive Learning",
        "authors": [
            "Siyuan Liang",
            "Mingli Zhu",
            "Aishan Liu",
            "Baoyuan Wu",
            "Xiaochun Cao",
            "Ee-Chien Chang"
        ],
        "comments": "The paper lacks some work that needs to be cited",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Studying backdoor attacks is valuable for model copyright protection and enhancing defenses. While existing backdoor attacks have successfully infected multimodal contrastive learning models such as CLIP, they can be easily countered by specialized backdoor defenses for MCL models. This paper reveals the threats in this practical scenario that backdoor attacks can remain effective even after defenses and introduces the \\emph{\\toolns} attack, which is resistant to backdoor detection and model fine-tuning defenses. To achieve this, we draw motivations from the perspective of the Bayesian rule and propose a dual-embedding guided framework for backdoor attacks. Specifically, we ensure that visual trigger patterns approximate the textual target semantics in the embedding space, making it challenging to detect the subtle parameter variations induced by backdoor learning on such natural trigger patterns. Additionally, we optimize the visual trigger patterns to align the poisoned samples with target vision features in order to hinder the backdoor unlearning through clean fine-tuning. Extensive experiments demonstrate that our attack significantly outperforms state-of-the-art baselines (+45.3% ASR) in the presence of SoTA backdoor defenses, rendering these mitigation and detection strategies virtually ineffective. Furthermore, our approach effectively attacks some more rigorous scenarios like downstream tasks. We believe that this paper raises awareness regarding the potential threats associated with the practical application of multimodal contrastive learning and encourages the development of more robust defense mechanisms.\n    ",
        "primary_category": "cs.CV",
        "categories": [],
        "submitted_date": "20 Nov 2023",
        "last_revised_date": " "
    },
    "2311.12451": {
        "title": "A frame approach for equations involving the fractional Laplacian",
        "authors": [
            "Ioannis P. A. Papadopoulos",
            "Timon S. Gutleb",
            "Jos\u00e9 A. Carrillo",
            "Sheehan Olver"
        ],
        "comments": " ",
        "subjects": "Numerical Analysis (math.NA)",
        "abstract": "Exceptionally elegant formulae exist for the fractional Laplacian operator applied to weighted classical orthogonal polynomials. We utilize these results to construct a solver, based on frame properties, for equations involving the fractional Laplacian of any power, $s \\in (0,1)$, on an unbounded domain in one or two dimensions. The numerical method represents solutions in an expansion of weighted classical orthogonal polynomials as well as their unweighted counterparts with a specific extension to $\\mathbb{R}^d$, $d \\in \\{1,2\\}$. We examine the frame properties of this family of functions for the solution expansion and, under standard frame conditions, derive an a priori estimate for the stationary equation. Moreover, we prove one achieves the expected order of convergence when considering an implicit Euler discretization in time for the fractional heat equation. We apply our solver to numerous examples including the fractional heat equation (utilizing up to a $6^\\text{th}$-order Runge--Kutta time discretization), a fractional heat equation with a time-dependent exponent $s(t)$, and a two-dimensional problem, observing spectral convergence in the spatial dimension for sufficiently smooth data.\n    ",
        "primary_category": "math.NA",
        "categories": [],
        "submitted_date": "21 Nov 2023",
        "last_revised_date": " "
    },
    "2311.13033": {
        "title": "Efficient Computation of Invariance Proximity: Closed-Form Error Bounds for Finite-Dimensional Koopman-Based Models",
        "authors": [
            "Masih Haseli",
            "Jorge Cort\u00e9s"
        ],
        "comments": "11 pages",
        "subjects": "Optimization and Control (math.OC)",
        "abstract": "A popular way to approximate the Koopman operator's action on a finite-dimensional subspace of functions is via orthogonal projections. The quality of the projected model directly depends on the selected subspace, specifically on how close it is to being invariant under the Koopman operator. The notion of invariance proximity provides a tight upper bound on the worst-case relative prediction error of the finite-dimensional model. However, its direct calculation is computationally challenging. This paper leverages the geometric structure behind the definition of invariance proximity to provide a closed-form expression in terms of Jordan principal angles on general inner product spaces. Unveiling this connection allows us to exploit specific isomorphisms to circumvent the computational challenges associated with spaces of functions and enables the use of existing efficient numerical routines to compute invariance proximity.\n    ",
        "primary_category": "math.OC",
        "categories": [
            "eess.SY",
            "math.DS"
        ],
        "submitted_date": "21 Nov 2023",
        "last_revised_date": " "
    },
    "2311.13162": {
        "title": "Top-L Most Influential Community Detection Over Social Networks (Technical Report)",
        "authors": [
            "Nan Zhang",
            "Yutong Ye",
            "Xiang Lian",
            "Mingsong Chen"
        ],
        "comments": " ",
        "subjects": "Social and Information Networks (cs.SI)",
        "abstract": "In many real-world applications such as social network analysis and online marketing/advertising, the community detection is a fundamental task to identify communities (subgraphs) in social networks with high structural cohesiveness. While previous works focus on detecting communities alone, they do not consider the collective influences of users in these communities on other user nodes in social networks. Inspired by this, in this paper, we investigate the influence propagation from some seed communities and their influential effects that result in the influenced communities. We propose a novel problem, named Top-L most Influential Community DEtection (TopL-ICDE) over social networks, which aims to retrieve top-L seed communities with the highest influences, having high structural cohesiveness, and containing user-specified query keywords. In order to efficiently tackle the TopL-ICDE problem, we design effective pruning strategies to filter out false alarms of seed communities and propose an effective index mechanism to facilitate efficient Top-L community retrieval. We develop an efficient TopL-ICDE answering algorithm by traversing the index and applying our proposed pruning strategies. We also formulate and tackle a variant of TopL-ICDE, named diversified top-L most influential community detection (DTopL-ICDE), which returns a set of L diversified communities with the highest diversity score (i.e., collaborative influences by L communities). We prove that DTopL-ICDE is NP-hard, and propose an efficient greedy algorithm with our designed diversity score pruning. Through extensive experiments, we verify the efficiency and effectiveness of our proposed TopL-ICDE and DTopL-ICDE approaches over real/synthetic social networks under various parameter settings.\n    ",
        "primary_category": "cs.SI",
        "categories": [
            "cs.DB"
        ],
        "submitted_date": "22 Nov 2023",
        "last_revised_date": " "
    },
    "2311.13250": {
        "title": "FedHCA$^2$: Towards Hetero-Client Federated Multi-Task Learning",
        "authors": [
            "Yuxiang Lu",
            "Suizhi Huang",
            "Yuwen Yang",
            "Shalayiding Sirejiding",
            "Yue Ding",
            "Hongtao Lu"
        ],
        "comments": "Accepted by CVPR 2024",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Federated Learning (FL) enables joint training across distributed clients using their local data privately. Federated Multi-Task Learning (FMTL) builds on FL to handle multiple tasks, assuming model congruity that identical model architecture is deployed in each client. To relax this assumption and thus extend real-world applicability, we introduce a novel problem setting, Hetero-Client Federated Multi-Task Learning (HC-FMTL), to accommodate diverse task setups. The main challenge of HC-FMTL is the model incongruity issue that invalidates conventional aggregation methods. It also escalates the difficulties in accurate model aggregation to deal with data and task heterogeneity inherent in FMTL. To address these challenges, we propose the FedHCA$^2$ framework, which allows for federated training of personalized models by modeling relationships among heterogeneous clients. Drawing on our theoretical insights into the difference between multi-task and federated optimization, we propose the Hyper Conflict-Averse Aggregation scheme to mitigate conflicts during encoder updates. Additionally, inspired by task interaction in MTL, the Hyper Cross Attention Aggregation scheme uses layer-wise cross attention to enhance decoder interactions while alleviating model incongruity. Moreover, we employ learnable Hyper Aggregation Weights for each client to customize personalized parameter updates. Extensive experiments demonstrate the superior performance of FedHCA$^2$ in various HC-FMTL scenarios compared to representative methods. Our code will be made publicly available.\n    ",
        "primary_category": "cs.CV",
        "categories": [
            "cs.LG"
        ],
        "submitted_date": "22 Nov 2023",
        "last_revised_date": " "
    },
    "2311.14175": {
        "title": "Appearance-based gaze estimation enhanced with synthetic images using deep neural networks",
        "authors": [
            "Dmytro Herashchenko",
            "Igor Farka\u0161"
        ],
        "comments": "6 pages, 10 figures, accepted to 2023 IEEE Symposium Series on Computational Intelligence (SSCI). Published version copyrighted by IEEE. This work was funded by the Horizon Europe Twinning project TERAIS G.A. number 101079338, and in part by the national project APVV-21-0105. The link to the code: this https URL",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Human eye gaze estimation is an important cognitive ingredient for successful human-robot interaction, enabling the robot to read and predict human behavior. We approach this problem using artificial neural networks and build a modular system estimating gaze from separately cropped eyes, taking advantage of existing well-functioning components for face detection (RetinaFace) and head pose estimation (6DRepNet). Our proposed method does not require any special hardware or infrared filters but uses a standard notebook-builtin RGB camera, as often approached with appearance-based methods. Using the MetaHuman tool, we also generated a large synthetic dataset of more than 57,000 human faces and made it publicly available. The inclusion of this dataset (with eye gaze and head pose information) on top of the standard Columbia Gaze dataset into training the model led to better accuracy with a mean average error below two degrees in eye pitch and yaw directions, which compares favourably to related methods. We also verified the feasibility of our model by its preliminary testing in real-world setting using the builtin 4K camera in NICO semi-humanoid robot's eye.\n    ",
        "primary_category": "cs.CV",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "23 Nov 2023",
        "last_revised_date": " "
    },
    "2311.14431": {
        "title": "What you need to know about a learning robot: Identifying the enabling architecture of complex systems",
        "authors": [
            "Helen Beierling",
            "Phillip Richter",
            "Mara Brandt",
            "Lutz Terfloth",
            "Carsten Schulte",
            "Heiko Wersing",
            "Anna-Lisa Vollmer"
        ],
        "comments": "To be published in Cognitive Systems Research",
        "subjects": "Robotics (cs.RO)",
        "abstract": "Nowadays, we are dealing more and more with robots and AI in everyday life. However, their behavior is not always apparent to most lay users, especially in error situations. As a result, there can be misconceptions about the behavior of the technologies in use. This, in turn, can lead to misuse and rejection by users. Explanation, for example, through transparency, can address these misconceptions. However, it would be confusing and overwhelming for users if the entire software or hardware was explained. Therefore, this paper looks at the 'enabling' architecture. It describes those aspects of a robotic system that might need to be explained to enable someone to use the technology effectively. Furthermore, this paper is concerned with the 'explanandum', which is the corresponding misunderstanding or missing concepts of the enabling architecture that needs to be clarified. We have thus developed and present an approach for determining this 'enabling' architecture and the resulting 'explanandum' of complex technologies.\n    ",
        "primary_category": "cs.RO",
        "categories": [],
        "submitted_date": "24 Nov 2023",
        "last_revised_date": " "
    },
    "2311.14625": {
        "title": "ARIA: On the Interaction Between Architectures, Initialization and Aggregation Methods for Federated Visual Classification",
        "authors": [
            "Vasilis Siomos",
            "Sergio Naval-Marimont",
            "Jonathan Passerat-Palmbach",
            "Giacomo Tarroni"
        ],
        "comments": "Accepted to ISBI 2024, camera-ready version with updated information on hyper-parameter tuning and clearer phrasing for practical take-aways",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Federated Learning (FL) is a collaborative training paradigm that allows for privacy-preserving learning of cross-institutional models by eliminating the exchange of sensitive data and instead relying on the exchange of model parameters between the clients and a server. Despite individual studies on how client models are aggregated, and, more recently, on the benefits of ImageNet pre-training, there is a lack of understanding of the effect the architecture chosen for the federation has, and of how the aforementioned elements interconnect. To this end, we conduct the first joint ARchitecture-Initialization-Aggregation study and benchmark ARIAs across a range of medical image classification tasks. We find that, contrary to current practices, ARIA elements have to be chosen together to achieve the best possible performance. Our results also shed light on good choices for each element depending on the task, the effect of normalisation layers, and the utility of SSL pre-training, pointing to potential directions for designing FL-specific architectures and training pipelines.\n    ",
        "primary_category": "cs.CV",
        "categories": [
            "cs.AI",
            "cs.DC"
        ],
        "submitted_date": "24 Nov 2023",
        "last_revised_date": " "
    },
    "2311.14658": {
        "title": "Convergence Analysis for Learning Orthonormal Deep Linear Neural Networks",
        "authors": [
            "Zhen Qin",
            "Xuwei Tan",
            "Zhihui Zhu"
        ],
        "comments": " ",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Enforcing orthonormal or isometric property for the weight matrices has been shown to enhance the training of deep neural networks by mitigating gradient exploding/vanishing and increasing the robustness of the learned networks. However, despite its practical performance, the theoretical analysis of orthonormality in neural networks is still lacking; for example, how orthonormality affects the convergence of the training process. In this letter, we aim to bridge this gap by providing convergence analysis for training orthonormal deep linear neural networks. Specifically, we show that Riemannian gradient descent with an appropriate initialization converges at a linear rate for training orthonormal deep linear neural networks with a class of loss functions. Unlike existing works that enforce orthonormal weight matrices for all the layers, our approach excludes this requirement for one layer, which is crucial to establish the convergence guarantee. Our results shed light on how increasing the number of hidden layers can impact the convergence speed. Experimental results validate our theoretical analysis.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "math.OC"
        ],
        "submitted_date": "24 Nov 2023",
        "last_revised_date": " "
    },
    "2311.15328": {
        "title": "BS-Diff: Effective Bone Suppression Using Conditional Diffusion Models from Chest X-Ray Images",
        "authors": [
            "Zhanghao Chen",
            "Yifei Sun",
            "Wenjian Qin",
            "Ruiquan Ge",
            "Cheng Pan",
            "Wenming Deng",
            "Zhou Liu",
            "Wenwen Min",
            "Ahmed Elazab",
            "Xiang Wan",
            "Changmiao Wang"
        ],
        "comments": "5 pages, 2 figures, accepted by IEEE ISBI 2024",
        "subjects": "Image and Video Processing (eess.IV)",
        "abstract": "Chest X-rays (CXRs) are commonly utilized as a low-dose modality for lung screening. Nonetheless, the efficacy of CXRs is somewhat impeded, given that approximately 75% of the lung area overlaps with bone, which in turn hampers the detection and diagnosis of diseases. As a remedial measure, bone suppression techniques have been introduced. The current dual-energy subtraction imaging technique in the clinic requires costly equipment and subjects being exposed to high radiation. To circumvent these issues, deep learning-based image generation algorithms have been proposed. However, existing methods fall short in terms of producing high-quality images and capturing texture details, particularly with pulmonary vessels. To address these issues, this paper proposes a new bone suppression framework, termed BS-Diff, that comprises a conditional diffusion model equipped with a U-Net architecture and a simple enhancement module to incorporate an autoencoder. Our proposed network cannot only generate soft tissue images with a high bone suppression rate but also possesses the capability to capture fine image details. Additionally, we compiled the largest dataset since 2010, including data from 120 patients with high-definition, high-resolution paired CXRs and soft tissue images collected by our affiliated hospital. Extensive experiments, comparative analyses, ablation studies, and clinical evaluations indicate that the proposed BS-Diff outperforms several bone-suppression models across multiple metrics. Our code can be accessed at this https URL.\n    ",
        "primary_category": "eess.IV",
        "categories": [
            "cs.CV"
        ],
        "submitted_date": "26 Nov 2023",
        "last_revised_date": " "
    },
    "2311.15767": {
        "title": "Homogeneous algorithms and solvable problems on cones",
        "authors": [
            "David Krieg",
            "Peter Kritzer"
        ],
        "comments": " ",
        "subjects": "Numerical Analysis (math.NA)",
        "abstract": "We consider linear problems in the worst case setting. That is, given a linear operator and a pool of admissible linear measurements, we want to approximate the values of the operator uniformly on a convex and balanced set by means of algorithms that use at most $n$ such measurements. It is known that, in general, linear algorithms do not yield an optimal approximation. However, as we show in this paper, an optimal approximation can always be obtained with a homogeneous algorithm. This is of interest to us for two reasons. First, the homogeneity allows us to extend any error bound on the unit ball to the full input space. Second, homogeneous algorithms are better suited to tackle problems on cones, a scenario that is far less understood than the classical situation of balls. We use the optimality of homogeneous algorithms to prove solvability for a family of problems defined on cones. We illustrate our results by several examples.\n    ",
        "primary_category": "math.NA",
        "categories": [],
        "submitted_date": "27 Nov 2023",
        "last_revised_date": " "
    },
    "2311.15836": {
        "title": "Syn3DWound: A Synthetic Dataset for 3D Wound Bed Analysis",
        "authors": [
            "L\u00e9o Lebrat",
            "Rodrigo Santa Cruz",
            "Remi Chierchia",
            "Yulia Arzhaeva",
            "Mohammad Ali Armin",
            "Joshua Goldsmith",
            "Jeremy Oorloff",
            "Prithvi Reddy",
            "Chuong Nguyen",
            "Lars Petersson",
            "Michelle Barakat-Johnson",
            "Georgina Luscombe",
            "Clinton Fookes",
            "Olivier Salvado",
            "David Ahmedt-Aristizabal"
        ],
        "comments": "In the IEEE International Symposium on Biomedical Imaging (ISBI) 2024",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Wound management poses a significant challenge, particularly for bedridden patients and the elderly. Accurate diagnostic and healing monitoring can significantly benefit from modern image analysis, providing accurate and precise measurements of wounds. Despite several existing techniques, the shortage of expansive and diverse training datasets remains a significant obstacle to constructing machine learning-based frameworks. This paper introduces Syn3DWound, an open-source dataset of high-fidelity simulated wounds with 2D and 3D annotations. We propose baseline methods and a benchmarking framework for automated 3D morphometry analysis and 2D/3D wound segmentation.\n    ",
        "primary_category": "cs.CV",
        "categories": [],
        "submitted_date": "27 Nov 2023",
        "last_revised_date": " "
    },
    "2311.16119": {
        "title": "Ignore This Title and HackAPrompt: Exposing Systemic Vulnerabilities of LLMs through a Global Scale Prompt Hacking Competition",
        "authors": [
            "Sander Schulhoff",
            "Jeremy Pinto",
            "Anaum Khan",
            "Louis-Fran\u00e7ois Bouchard",
            "Chenglei Si",
            "Svetlina Anati",
            "Valen Tagliabue",
            "Anson Liu Kost",
            "Christopher Carnahan",
            "Jordan Boyd-Graber"
        ],
        "comments": "34 pages, 8 figures Codebase: this https URL Dataset: this https URL Playground: this https URL",
        "subjects": "Cryptography and Security (cs.CR)",
        "abstract": "Large Language Models (LLMs) are deployed in interactive contexts with direct user engagement, such as chatbots and writing assistants. These deployments are vulnerable to prompt injection and jailbreaking (collectively, prompt hacking), in which models are manipulated to ignore their original instructions and follow potentially malicious ones. Although widely acknowledged as a significant security threat, there is a dearth of large-scale resources and quantitative studies on prompt hacking. To address this lacuna, we launch a global prompt hacking competition, which allows for free-form human input attacks. We elicit 600K+ adversarial prompts against three state-of-the-art LLMs. We describe the dataset, which empirically verifies that current LLMs can indeed be manipulated via prompt hacking. We also present a comprehensive taxonomical ontology of the types of adversarial prompts.\n    ",
        "primary_category": "cs.CR",
        "categories": [
            "cs.AI",
            "cs.CL"
        ],
        "submitted_date": "24 Oct 2023",
        "last_revised_date": " "
    },
    "2311.17119": {
        "title": "Continuous Pose for Monocular Cameras in Neural Implicit Representation",
        "authors": [
            "Qi Ma",
            "Danda Pani Paudel",
            "Ajad Chhatkuli",
            "Luc Van Gool"
        ],
        "comments": " ",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "In this paper, we showcase the effectiveness of optimizing monocular camera poses as a continuous function of time. The camera poses are represented using an implicit neural function which maps the given time to the corresponding camera pose. The mapped camera poses are then used for the downstream tasks where joint camera pose optimization is also required. While doing so, the network parameters -- that implicitly represent camera poses -- are optimized. We exploit the proposed method in four diverse experimental settings, namely, (1) NeRF from noisy poses; (2) NeRF from asynchronous Events; (3) Visual Simultaneous Localization and Mapping (vSLAM); and (4) vSLAM with IMUs. In all four settings, the proposed method performs significantly better than the compared baselines and the state-of-the-art methods. Additionally, using the assumption of continuous motion, changes in pose may actually live in a manifold that has lower than 6 degrees of freedom (DOF) is also realized. We call this low DOF motion representation as the \\emph{intrinsic motion} and use the approach in vSLAM settings, showing impressive camera tracking performance.\n    ",
        "primary_category": "cs.CV",
        "categories": [],
        "submitted_date": "28 Nov 2023",
        "last_revised_date": " "
    },
    "2311.18274": {
        "title": "Semiparametric Efficient Inference in Adaptive Experiments",
        "authors": [
            "Thomas Cook",
            "Alan Mishler",
            "Aaditya Ramdas"
        ],
        "comments": "24 pages, 6 figures. To appear at CLeaR 2024",
        "subjects": "Machine Learning (stat.ML)",
        "abstract": "We consider the problem of efficient inference of the Average Treatment Effect in a sequential experiment where the policy governing the assignment of subjects to treatment or control can change over time. We first provide a central limit theorem for the Adaptive Augmented Inverse-Probability Weighted estimator, which is semiparametric efficient, under weaker assumptions than those previously made in the literature. This central limit theorem enables efficient inference at fixed sample sizes. We then consider a sequential inference setting, deriving both asymptotic and nonasymptotic confidence sequences that are considerably tighter than previous methods. These anytime-valid methods enable inference under data-dependent stopping times (sample sizes). Additionally, we use propensity score truncation techniques from the recent off-policy estimation literature to reduce the finite sample variance of our estimator without affecting the asymptotic variance. Empirical results demonstrate that our methods yield narrower confidence sequences than those previously developed in the literature while maintaining time-uniform error control.\n    ",
        "primary_category": "stat.ML",
        "categories": [
            "cs.LG",
            "stat.ME"
        ],
        "submitted_date": "30 Nov 2023",
        "last_revised_date": " "
    },
    "2311.18528": {
        "title": "Bottom-up computation using trees of sublists (Functional Pearl)",
        "authors": [
            "Shin-Cheng Mu"
        ],
        "comments": "Submitted to Journal of Functional Programming",
        "subjects": "Programming Languages (cs.PL)",
        "abstract": "Some top-down problem specifications, if executed directly, may compute sub-problems repeatedly. Instead, we may want a bottom-up algorithm that stores solutions of sub-problems in a table to be reused. It can be tricky, however, to figure out how the table can be represented and efficiently maintained.\nWe study a special case: computing a function $h$ taking lists as inputs such that $h~xs$ is defined in terms of all immediate sublists of $xs$. Richard Bird studied this problem in 2008, and presented a concise but cryptic algorithm without much explanation. We give this algorithm a proper derivation, and discover a key property that allows it to work. The algorithm builds trees that have certain shapes -- the sizes along the left spine is a diagonal in Pascal's triangle. The crucial function we derive transforms one diagonal to the next.\n    ",
        "primary_category": "cs.PL",
        "categories": [],
        "submitted_date": "30 Nov 2023",
        "last_revised_date": " "
    },
    "2311.18542": {
        "title": "RIS-Assisted Generalized Receive Quadrature Spatial Modulation",
        "authors": [
            "Mohamad H. Dinan",
            "Mark F. Flanagan"
        ],
        "comments": "6 pages (2-column), 5 figures, 1 table, Prepared for Globcom 2023 conference",
        "subjects": "Information Theory (cs.IT)",
        "abstract": "In this paper, reconfigurable intelligent surface (RIS)-assisted generalized receive quadrature spatial modulation (RIS-GRQSM) is proposed to improve the spectral efficiency of RIS-aided quadrature spatial modulation (QSM) systems by utilizing the concept of generalized spatial modulation (GSM). That is, multiple antennas are activated at the receiver independently for both the real and imaginary parts. We propose a max-min optimization problem to adjust the phase shifts of all RIS elements to maximize the relevant signal-to-noise ratios (SNRs) at all activated receive antennas. Using Lagrange duality, the non-convex optimization problem involving the phase shifts of all RIS elements reduces to a convex optimization involving a number of variables equal to the number of activated receive antennas. A successive greedy detector (GD) can be used at the receiver to detect the active antennas, which simplifies the detection process. The numerical results show that the proposed scheme outperforms the benchmark schemes in terms of error rate performance, especially in systems with a larger number of receive antennas. In the special case where each receive antenna corresponds to a user and is activated, the RIS-GRQSM system becomes a multicast communication system. In this context, in contrast to existing phase shift optimization algorithms which exhibit an impractical level of complexity, our proposed solution offers the advantage of low complexity and practical feasibility of implementation.\n    ",
        "primary_category": "cs.IT",
        "categories": [
            "eess.SP"
        ],
        "submitted_date": "30 Nov 2023",
        "last_revised_date": " "
    },
    "2312.00038": {
        "title": "A Posteriori Evaluation of a Physics-Constrained Neural Ordinary Differential Equations Approach Coupled with CFD Solver for Modeling Stiff Chemical Kinetics",
        "authors": [
            "Tadbhagya Kumar",
            "Anuj Kumar",
            "Pinaki Pal"
        ],
        "comments": " ",
        "subjects": "Computational Physics (physics.comp-ph)",
        "abstract": "The high computational cost associated with solving for detailed chemistry poses a significant challenge for predictive computational fluid dynamics (CFD) simulations of turbulent reacting flows. These models often require solving a system of coupled stiff ordinary differential equations (ODEs). While deep learning techniques have been experimented with to develop faster surrogate models, they often fail to integrate reliably with CFD solvers. This instability arises because deep learning methods optimize for training error without ensuring compatibility with ODE solvers, leading to accumulation of errors over time. Recently, NeuralODE-based techniques have offered a promising solution by effectively modeling chemical kinetics. In this study, we extend the NeuralODE framework for stiff chemical kinetics by incorporating mass conservation constraints directly into the loss function during training. This ensures that the total mass and the elemental mass are conserved, a critical requirement for reliable downstream integration with CFD solvers. Proof-of-concept studies are performed with physics-constrained neuralODE (PC-NODE) approach for homogeneous autoignition of hydrogen-air mixture over a range of composition and thermodynamic conditions. Our results demonstrate that this enhancement not only improves the physical consistency with respect to mass conservation criteria but also ensures better robustness. Lastly, a posteriori studies are performed wherein the trained PC-NODE model is coupled with a 3D CFD solver for computing the chemical source terms. PC-NODE is shown to be more accurate relative to the purely data-driven neuralODE approach. Moreover, PC-NODE also exhibits robustness and generalizability to unseen initial conditions from within (interpolative capability) as well as outside (extrapolative capability) the training regime.\n    ",
        "primary_category": "physics.comp-ph",
        "categories": [
            "cs.LG",
            "physics.chem-ph",
            "physics.flu-dyn"
        ],
        "submitted_date": "22 Nov 2023",
        "last_revised_date": " "
    },
    "2312.00082": {
        "title": "A Compact Implicit Neural Representation for Efficient Storage of Massive 4D Functional Magnetic Resonance Imaging",
        "authors": [
            "Ruoran Li",
            "Runzhao Yang",
            "Wenxin Xiang",
            "Yuxiao Cheng",
            "Tingxiong Xiao",
            "Jinli Suo"
        ],
        "comments": " ",
        "subjects": "Image and Video Processing (eess.IV)",
        "abstract": "Functional Magnetic Resonance Imaging (fMRI) data is a widely used kind of four-dimensional biomedical data, which requires effective compression. However, fMRI compressing poses unique challenges due to its intricate temporal dynamics, low signal-to-noise ratio, and complicated underlying redundancies. This paper reports a novel compression paradigm specifically tailored for fMRI data based on Implicit Neural Representation (INR). The proposed approach focuses on removing the various redundancies among the time series by employing several methods, including (i) conducting spatial correlation modeling for intra-region dynamics, (ii) decomposing reusable neuronal activation patterns, and (iii) using proper initialization together with nonlinear fusion to describe the inter-region similarity. This scheme appropriately incorporates the unique features of fMRI data, and experimental results on publicly available datasets demonstrate the effectiveness of the proposed method, surpassing state-of-the-art algorithms in both conventional image quality evaluation metrics and fMRI downstream tasks. This work in this paper paves the way for sharing massive fMRI data at low bandwidth and high fidelity.\n    ",
        "primary_category": "eess.IV",
        "categories": [
            "cs.CV"
        ],
        "submitted_date": "30 Nov 2023",
        "last_revised_date": " "
    },
    "2312.00398": {
        "title": "Learning to Estimate Critical Gait Parameters from Single-View RGB Videos with Transformer-Based Attention Network",
        "authors": [
            "Quoc Hung T. Le",
            "Hieu H. Pham"
        ],
        "comments": "Accepted at ISBI 2024 (21st IEEE International Symposium on Biomedical Imaging)",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Musculoskeletal diseases and cognitive impairments in patients lead to difficulties in movement as well as negative effects on their psychological health. Clinical gait analysis, a vital tool for early diagnosis and treatment, traditionally relies on expensive optical motion capture systems. Recent advances in computer vision and deep learning have opened the door to more accessible and cost-effective alternatives. This paper introduces a novel spatio-temporal Transformer network to estimate critical gait parameters from RGB videos captured by a single-view camera. Empirical evaluations on a public dataset of cerebral palsy patients indicate that the proposed framework surpasses current state-of-the-art approaches and show significant improvements in predicting general gait parameters (including Walking Speed, Gait Deviation Index - GDI, and Knee Flexion Angle at Maximum Extension), while utilizing fewer parameters and alleviating the need for manual feature extraction.\n    ",
        "primary_category": "cs.CV",
        "categories": [],
        "submitted_date": "1 Dec 2023",
        "last_revised_date": " "
    },
    "2312.00746": {
        "title": "Deciphering Digital Detectives: Understanding LLM Behaviors and Capabilities in Multi-Agent Mystery Games",
        "authors": [
            "Dekun Wu",
            "Haochen Shi",
            "Zhiyuan Sun",
            "Bang Liu"
        ],
        "comments": " ",
        "subjects": "Artificial Intelligence (cs.AI)",
        "abstract": "In this study, we explore the application of Large Language Models (LLMs) in \\textit{Jubensha}, a Chinese detective role-playing game and a novel area in Artificial Intelligence (AI) driven gaming. We introduce the first dataset specifically for Jubensha, including character scripts and game rules, to foster AI agent development in this complex narrative environment. Our work also presents a unique multi-agent interaction framework using LLMs, allowing AI agents to autonomously engage in this game. To evaluate the gaming performance of these AI agents, we developed novel methods measuring their mastery of case information and reasoning skills. Furthermore, we incorporated the latest advancements in in-context learning to improve the agents' performance in information gathering, murderer identification, and logical reasoning. The experimental results validate the effectiveness of our proposed methods. This work aims to offer a novel perspective on understanding LLM capabilities and establish a new benchmark for evaluating large language model-based agents.\n    ",
        "primary_category": "cs.AI",
        "categories": [],
        "submitted_date": "1 Dec 2023",
        "last_revised_date": " "
    },
    "2312.00786": {
        "title": "Dense Optical Tracking: Connecting the Dots",
        "authors": [
            "Guillaume Le Moing",
            "Jean Ponce",
            "Cordelia Schmid"
        ],
        "comments": "Accepted to CVPR 2024",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Recent approaches to point tracking are able to recover the trajectory of any scene point through a large portion of a video despite the presence of occlusions. They are, however, too slow in practice to track every point observed in a single frame in a reasonable amount of time. This paper introduces DOT, a novel, simple and efficient method for solving this problem. It first extracts a small set of tracks from key regions at motion boundaries using an off-the-shelf point tracking algorithm. Given source and target frames, DOT then computes rough initial estimates of a dense flow field and visibility mask through nearest-neighbor interpolation, before refining them using a learnable optical flow estimator that explicitly handles occlusions and can be trained on synthetic data with ground-truth correspondences. We show that DOT is significantly more accurate than current optical flow techniques, outperforms sophisticated \"universal\" trackers like OmniMotion, and is on par with, or better than, the best point tracking algorithms like CoTracker while being at least two orders of magnitude faster. Quantitative and qualitative experiments with synthetic and real videos validate the promise of the proposed approach. Code, data, and videos showcasing the capabilities of our approach are available in the project webpage: this https URL .\n    ",
        "primary_category": "cs.CV",
        "categories": [],
        "submitted_date": "1 Dec 2023",
        "last_revised_date": " "
    },
    "2312.00925": {
        "title": "Describing Globally Distributed Software Architectures for Tax Compliance",
        "authors": [
            "Michael Dorner",
            "Oliver Treidler",
            "Tom-Eric Kunz",
            "Ehsan Zabardast",
            "Daniel Mendez",
            "Darja \u0160mite",
            "Maximilian Capraro",
            "Krzysztof Wnuk"
        ],
        "comments": "submitted to TOSEM",
        "subjects": "Software Engineering (cs.SE)",
        "abstract": "Background: The company-internal reuse of software components owned by organizational units in different countries is taxable. Objective: In this article, we introduce the concerns of tax authorities as stakeholders and investigate how software companies can describe their globally distributed software architectures to tax authorities. Method: In an experimental simulation, we (1) develop a viewpoint that frames the concerns of tax authorities, (2) create a view of a large-scale, globally distributed microservice architecture from a multinational enterprise, and (3) evaluate the resulting software architecture description with a panel of four tax experts. Results: The panel found our proposed architectural viewpoint properly and sufficiently frames the concerns of taxation stakeholders. The architecture description reveals that almost 70% of all reuse relationships between the 2560 microservices from our case company are cross-border and, therefore, taxable. However, unclear jurisdictions of owners and potentially insufficient definitions of code ownership and software component introduce significant noise to the view that limits the usefulness and explanatory power of our software architecture description. Conclusion: Although our software architecture description already provides a solid foundation and reveals the importance of tax compliance in software architectures, we stumbled over several fundamental open questions, forming new frontiers in software engineering.\n    ",
        "primary_category": "cs.SE",
        "categories": [],
        "submitted_date": "1 Dec 2023",
        "last_revised_date": " "
    },
    "2312.01050": {
        "title": "Detection and Analysis of Stress-Related Posts in Reddit Acamedic Communities",
        "authors": [
            "Nazzere Oryngozha",
            "Pakizar Shamoi",
            "Ayan Igali"
        ],
        "comments": "This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "Nowadays, the significance of monitoring stress levels and recognizing early signs of mental illness cannot be overstated. Automatic stress detection in text can proactively help manage stress and protect mental well-being. In today's digital era, social media platforms reflect the psychological well-being and stress levels within various communities. This study focuses on detecting and analyzing stress-related posts in Reddit academic communities. Due to online education and remote work, these communities have become central for academic discussions and support. We classify text as stressed or not using natural language processing and machine learning classifiers, with Dreaddit as our training dataset, which contains labeled data from Reddit. Next, we collect and analyze posts from various academic subreddits. We identified that the most effective individual feature for stress detection is the Bag of Words, paired with the Logistic Regression classifier, achieving a 77.78% accuracy rate and an F1 score of 0.79 on the DReaddit dataset. This combination also performs best in stress detection on human-annotated datasets, with a 72% accuracy rate. Our key findings reveal that posts and comments in professors Reddit communities are the most stressful, compared to other academic levels, including bachelor, graduate, and Ph.D. students. This research contributes to our understanding of the stress levels within academic communities. It can help academic institutions and online communities develop measures and interventions to address this issue effectively.\n    ",
        "primary_category": "cs.CL",
        "categories": [],
        "submitted_date": "2 Dec 2023",
        "last_revised_date": " "
    },
    "2312.01133": {
        "title": "$t^3$-Variational Autoencoder: Learning Heavy-tailed Data with Student's t and Power Divergence",
        "authors": [
            "Juno Kim",
            "Jaehyuk Kwon",
            "Mincheol Cho",
            "Hyunjong Lee",
            "Joong-Ho Won"
        ],
        "comments": "ICLR 2024; 27 pages, 7 figures, 8 tables",
        "subjects": "Machine Learning (stat.ML)",
        "abstract": "The variational autoencoder (VAE) typically employs a standard normal prior as a regularizer for the probabilistic latent encoder. However, the Gaussian tail often decays too quickly to effectively accommodate the encoded points, failing to preserve crucial structures hidden in the data. In this paper, we explore the use of heavy-tailed models to combat over-regularization. Drawing upon insights from information geometry, we propose $t^3$VAE, a modified VAE framework that incorporates Student's t-distributions for the prior, encoder, and decoder. This results in a joint model distribution of a power form which we argue can better fit real-world datasets. We derive a new objective by reformulating the evidence lower bound as joint optimization of KL divergence between two statistical manifolds and replacing with $\\gamma$-power divergence, a natural alternative for power families. $t^3$VAE demonstrates superior generation of low-density regions when trained on heavy-tailed synthetic data. Furthermore, we show that $t^3$VAE significantly outperforms other models on CelebA and imbalanced CIFAR-100 datasets.\n    ",
        "primary_category": "stat.ML",
        "categories": [
            "cs.LG"
        ],
        "submitted_date": "2 Dec 2023",
        "last_revised_date": " "
    },
    "2312.01534": {
        "title": "Skeletal Cut Loci on Convex Polyhedra",
        "authors": [
            "Joseph O'Rourke",
            "Costin Vilcu"
        ],
        "comments": "20 pages, 12 figures, 9 references. v2: Many minor improvements",
        "subjects": "Computational Geometry (cs.CG)",
        "abstract": "On a convex polyhedron P, the cut locus C(x) with respect to a point x is a tree of geodesic segments (shortest paths) on P that includes every vertex. We say that P has a skeletal cut locus if there is some x in P such that C(x) is a subset of Sk(P), where Sk(P) is the 1-skeleton of P . At a first glance, there seems to be very little relation between the cut locus and the 1-skeleton, as the first one is an intrinsic geometry notion, and the second one specifies the combinatorics of P.\nIn this paper we study skeletal cut loci, obtaining four main results. First, given any combinatorial tree T without degree-2 nodes, there exists a convex polyhedron P and a point x in P with a cut locus that lies in Sk(P), and whose combinatorics match T. Second, any (non-degenerate) polyhedron P has at most a finite number of points x for which C(x) is a subset of Sk(P). Third, we show that almost all polyhedra have no skeletal cut locus. Fourth, we provide a combinatorial restriction to the existence of skeletal cut loci.\nBecause the source unfolding of P with respect to x is always a non-overlapping net for P, and because the boundary of the source unfolding is the (unfolded) cut locus, source unfoldings of polyhedra with skeletal cut loci are edge-unfoldings, and moreover \"blooming,\" avoiding self-intersection during an unfolding process.\n    ",
        "primary_category": "cs.CG",
        "categories": [
            "math.MG"
        ],
        "submitted_date": "3 Dec 2023",
        "last_revised_date": " "
    },
    "2312.01714": {
        "title": "Retrieval-augmented Multi-modal Chain-of-Thoughts Reasoning for Large Language Models",
        "authors": [
            "Bingshuai Liu",
            "Chenyang Lyu",
            "Zijun Min",
            "Zhanyu Wang",
            "Jinsong Su",
            "Longyue Wang"
        ],
        "comments": "Work in progress",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "The advancement of Large Language Models (LLMs) has brought substantial attention to the Chain of Thought (CoT) approach, primarily due to its ability to enhance the capability of LLMs on complex reasoning tasks. Moreover, the significance of CoT approaches extends to the application of LLMs for multi-modal tasks. However, the selection of optimal CoT demonstration examples in multi-modal reasoning remains less explored for LLMs due to the inherent complexity of multi-modal examples. In this paper, we introduce a novel approach that addresses this challenge by using retrieval mechanisms to dynamically and automatically select demonstration examples based on cross-modal and intra-modal similarities. Furthermore, we employ a Stratified Sampling method of categorising demonstration examples into groups based on their types and then retrieving examples from different groups respectively to promote the diversity of demonstration examples. Through a series of experiments on two popular benchmark datasets: ScienceQA and MathVista, we demonstrate that our approach significantly improves the performance of GPT-4 by 6% on ScienceQA and 12.9% on MathVista, and enhances the performance of GPT-4V on two datasets by 2.7%, substantially improving the performance of the most advanced LLMs and LMMs for complex multi-modal reasoning tasks.\n    ",
        "primary_category": "cs.CL",
        "categories": [],
        "submitted_date": "4 Dec 2023",
        "last_revised_date": " "
    },
    "2312.02170": {
        "title": "A 5G DMRS-based Signal for Integrated Sensing and Communication System",
        "authors": [
            "Zhiqing Wei",
            "Fengyun Li",
            "Haotian Liu",
            "Xu Chen",
            "Huici Wu",
            "Kaifeng Han",
            "Zhiyong Feng"
        ],
        "comments": " ",
        "subjects": "Information Theory (cs.IT)",
        "abstract": "Integrated sensing and communication (ISAC) is considered as the potential key technology of the future mobile communication systems. The signal design is fundamental for the ISAC system. The reference signals in mobile communication systems have good detection performance, which is worth further research. Existing studies applied the single reference signal to radar sensing. In this paper, a multiple reference signals collaborative sensing scheme is designed. Specifically, we jointly apply channel state information reference signal (CSI-RS), positioning reference signal (PRS) and demodulation reference signal (DMRS) in radar sensing, which improve the performance of radar sensing via obtaining continuous time-frequency resource mapping. Cr\u00e1mer-Rao lower bound (CRLB) of the joint reference signal for distance and velocity estimation is derived. The impacts of carrier frequency and subcarrier spacing on the performance of distance and velocity estimation are revealed. The results of simulation experiments show that compared with the single reference signal sensing scheme, the multiple reference signals collaborative sensing scheme effectively improves the sensing accuracy. Moreover, because of the discontinuous OFDM symbols, the accuracy of velocity estimation could be further improved via compressed sensing (CS). This paper has verified that multiple reference signals, instead of single reference signal, have much more superior performance on radar sensing, which is a practical and efficient approach in designing ISAC signal.\n    ",
        "primary_category": "cs.IT",
        "categories": [
            "eess.SP"
        ],
        "submitted_date": "1 Nov 2023",
        "last_revised_date": " "
    },
    "2312.02277": {
        "title": "ALEXR: An Optimal Single-Loop Algorithm for Convex Finite-Sum Coupled Compositional Stochastic Optimization",
        "authors": [
            "Bokun Wang",
            "Tianbao Yang"
        ],
        "comments": "Added some closed-form expressions of the dual update",
        "subjects": "Optimization and Control (math.OC)",
        "abstract": "This paper revisits a class of convex Finite-Sum Coupled Compositional Stochastic Optimization (cFCCO) problems with many applications, including group distributionally robust optimization (GDRO), learning with imbalanced data, reinforcement learning, and learning to rank. To better solve these problems, we introduce an efficient single-loop primal-dual block-coordinate proximal algorithm, dubbed ALEXR. This algorithm leverages block-coordinate stochastic mirror ascent updates for the dual variable and stochastic proximal gradient descent updates for the primal variable. We establish the convergence rates of ALEXR in both convex and strongly convex cases under smoothness and non-smoothness conditions of involved functions, which not only improve the best rates in previous works on smooth cFCCO problems but also expand the realm of cFCCO for solving more challenging non-smooth problems such as the dual form of GDRO. Finally, we present lower complexity bounds to demonstrate that the convergence rates of ALEXR are optimal among first-order block-coordinate stochastic algorithms for the considered class of cFCCO problems.\n    ",
        "primary_category": "math.OC",
        "categories": [
            "cs.LG"
        ],
        "submitted_date": "4 Dec 2023",
        "last_revised_date": " "
    },
    "2312.02528": {
        "title": "Towards Automatic Power Battery Detection: New Challenge, Benchmark Dataset and Baseline",
        "authors": [
            "Xiaoqi Zhao",
            "Youwei Pang",
            "Zhenyu Chen",
            "Qian Yu",
            "Lihe Zhang",
            "Hanqi Liu",
            "Jiaming Zuo",
            "Huchuan Lu"
        ],
        "comments": "Accepted at CVPR2024",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "We conduct a comprehensive study on a new task named power battery detection (PBD), which aims to localize the dense cathode and anode plates endpoints from X-ray images to evaluate the quality of power batteries. Existing manufacturers usually rely on human eye observation to complete PBD, which makes it difficult to balance the accuracy and efficiency of detection. To address this issue and drive more attention into this meaningful task, we first elaborately collect a dataset, called X-ray PBD, which has $1,500$ diverse X-ray images selected from thousands of power batteries of $5$ manufacturers, with $7$ different visual interference. Then, we propose a novel segmentation-based solution for PBD, termed multi-dimensional collaborative network (MDCNet). With the help of line and counting predictors, the representation of the point segmentation branch can be improved at both semantic and detail aspects.Besides, we design an effective distance-adaptive mask generation strategy, which can alleviate the visual challenge caused by the inconsistent distribution density of plates to provide MDCNet with stable supervision. Without any bells and whistles, our segmentation-based MDCNet consistently outperforms various other corner detection, crowd counting and general/tiny object detection-based solutions, making it a strong baseline that can help facilitate future research in PBD. Finally, we share some potential difficulties and works for future researches. The source code and datasets will be publicly available at \\href{this https URL}{X-ray PBD}.\n    ",
        "primary_category": "cs.CV",
        "categories": [],
        "submitted_date": "5 Dec 2023",
        "last_revised_date": " "
    },
    "2312.03095": {
        "title": "Understanding Environmental Posts: Sentiment and Emotion Analysis of Social Media Data",
        "authors": [
            "Daniyar Amangeldi",
            "Aida Usmanova",
            "Pakizar Shamoi"
        ],
        "comments": "This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "Social media is now the predominant source of information due to the availability of immediate public response. As a result, social media data has become a valuable resource for comprehending public sentiments. Studies have shown that it can amplify ideas and influence public sentiments. This study analyzes the public perception of climate change and the environment over a decade from 2014 to 2023. Using the Pointwise Mutual Information (PMI) algorithm, we identify sentiment and explore prevailing emotions expressed within environmental tweets across various social media platforms, namely Twitter, Reddit, and YouTube. Accuracy on a human-annotated dataset was 0.65, higher than Vader score but lower than that of an expert rater (0.90). Our findings suggest that negative environmental tweets are far more common than positive or neutral ones. Climate change, air quality, emissions, plastic, and recycling are the most discussed topics on all social media platforms, highlighting its huge global concern. The most common emotions in environmental tweets are fear, trust, and anticipation, demonstrating public reactions wide and complex nature. By identifying patterns and trends in opinions related to the environment, we hope to provide insights that can help raise awareness regarding environmental issues, inform the development of interventions, and adapt further actions to meet environmental challenges.\n    ",
        "primary_category": "cs.CL",
        "categories": [],
        "submitted_date": "5 Dec 2023",
        "last_revised_date": " "
    },
    "2312.03151": {
        "title": "Multitask Learning Can Improve Worst-Group Outcomes",
        "authors": [
            "Atharva Kulkarni",
            "Lucio Dery",
            "Amrith Setlur",
            "Aditi Raghunathan",
            "Ameet Talwalkar",
            "Graham Neubig"
        ],
        "comments": "20 pages, 7 tables, 6 Figures",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "In order to create machine learning systems that serve a variety of users well, it is vital to not only achieve high average performance but also ensure equitable outcomes across diverse groups. However, most machine learning methods are designed to improve a model's average performance on a chosen end task without consideration for their impact on worst group error. Multitask learning (MTL) is one such widely used technique. In this paper, we seek not only to understand the impact of MTL on worst-group accuracy but also to explore its potential as a tool to address the challenge of group-wise fairness. We primarily consider the standard setting of fine-tuning a pre-trained model, where, following recent work \\citep{gururangan2020don, dery2023aang}, we multitask the end task with the pre-training objective constructed from the end task data itself. In settings with few or no group annotations, we find that multitasking often, but not consistently, achieves better worst-group accuracy than Just-Train-Twice (JTT; \\citet{pmlr-v139-liu21f}) -- a representative distributionally robust optimization (DRO) method. Leveraging insights from synthetic data experiments, we propose to modify standard MTL by regularizing the joint multitask representation space. We run a large number of fine-tuning experiments across computer vision and natural language processing datasets and find that our regularized MTL approach \\emph{consistently} outperforms JTT on both average and worst-group outcomes. Our official code can be found here: \\href{this https URL}{\\url{this https URL}}.\n    ",
        "primary_category": "cs.LG",
        "categories": [],
        "submitted_date": "5 Dec 2023",
        "last_revised_date": " "
    },
    "2312.04141": {
        "title": "Distributed Approximate Computing with Constant Locality",
        "authors": [
            "Deheng Yuan",
            "Tao Guo",
            "Zhongyi Huang",
            "Shi Jin"
        ],
        "comments": " ",
        "subjects": "Information Theory (cs.IT)",
        "abstract": "Consider a distributed coding for computing problem with constant decoding locality, i.e., with a vanishing error probability, any single sample of the function can be approximately recovered by probing only constant number of compressed bits. We establish an achievable rate region by designing an efficient layered coding scheme, where the coding rate is reduced by introducing auxiliary random variables and local decoding is achieved by exploiting the expander graph code. Then we show the rate region is optimal under mild regularity conditions on source distributions. The proof relies on the reverse hypercontractivity and a rounding technique to construct auxiliary random variables. The rate region is strictly smaller than that for the classical problem without the constant locality constraint in most cases, which indicates that more rate is required in order to achieve lower coding complexity. Moreover, a coding for computing problem with side information is analogously studied. We also develop graph characterizations, which simplifies the computation of the achievable rate region.\n    ",
        "primary_category": "cs.IT",
        "categories": [],
        "submitted_date": "7 Dec 2023",
        "last_revised_date": " "
    },
    "2312.04455": {
        "title": "Fortify the Shortest Stave in Attention: Enhancing Context Awareness of Large Language Models for Effective Tool Use",
        "authors": [
            "Yuhan Chen",
            "Ang Lv",
            "Ting-En Lin",
            "Changyu Chen",
            "Yuchuan Wu",
            "Fei Huang",
            "Yongbin Li",
            "Rui Yan"
        ],
        "comments": " ",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "In this paper, we demonstrate that an inherent waveform pattern in the attention allocation of large language models (LLMs) significantly affects their performance in tasks demanding a high degree of context awareness, such as utilizing LLMs for tool-use. Specifically, the crucial information in the context will be potentially overlooked by model when it is positioned in the trough zone of the attention waveform, leading to decreased performance. To address this issue, we propose a novel inference method named Attention Buckets. It allows LLMs to process their input through multiple parallel processes. Each process utilizes a distinct base angle for the rotary position embedding, thereby creating a unique attention waveform. By compensating an attention trough of a particular process with an attention peak of another process, our approach enhances LLM's awareness to various contextual positions, thus mitigating the risk of overlooking crucial information. In the largest tool-use benchmark, our method elevates a 7B model to achieve state-of-the-art performance, comparable to that of GPT-4. On other benchmarks and some RAG tasks, which also demand a thorough understanding of contextual content, Attention Buckets also exhibited notable enhancements in performance.\n    ",
        "primary_category": "cs.CL",
        "categories": [
            "cs.AI",
            "cs.LG"
        ],
        "submitted_date": "7 Dec 2023",
        "last_revised_date": " "
    },
    "2312.04819": {
        "title": "Attention-Guided Contrastive Role Representations for Multi-Agent Reinforcement Learning",
        "authors": [
            "Zican Hu",
            "Zongzhang Zhang",
            "Huaxiong Li",
            "Chunlin Chen",
            "Hongyu Ding",
            "Zhi Wang"
        ],
        "comments": " ",
        "subjects": "Multiagent Systems (cs.MA)",
        "abstract": "Real-world multi-agent tasks usually involve dynamic team composition with the emergence of roles, which should also be a key to efficient cooperation in multi-agent reinforcement learning (MARL). Drawing inspiration from the correlation between roles and agent's behavior patterns, we propose a novel framework of **A**ttention-guided **CO**ntrastive **R**ole representation learning for **M**ARL (**ACORM**) to promote behavior heterogeneity, knowledge transfer, and skillful coordination across agents. First, we introduce mutual information maximization to formalize role representation learning, derive a contrastive learning objective, and concisely approximate the distribution of negative pairs. Second, we leverage an attention mechanism to prompt the global state to attend to learned role representations in value decomposition, implicitly guiding agent coordination in a skillful role space to yield more expressive credit assignment. Experiments on challenging StarCraft II micromanagement and Google research football tasks demonstrate the state-of-the-art performance of our method and its advantages over existing approaches. Our code is available at [this https URL](this https URL).\n    ",
        "primary_category": "cs.MA",
        "categories": [],
        "submitted_date": "8 Dec 2023",
        "last_revised_date": " "
    },
    "2312.05248": {
        "title": "Topology-Based Reconstruction Prevention for Decentralised Learning",
        "authors": [
            "Florine W. Dekker",
            "Zekeriya Erkin",
            "Mauro Conti"
        ],
        "comments": "13 pages, 8 figures, submitted to PETS 2024, for associated experiment source code see doi:https://doi.org/10.4121/21572601",
        "subjects": "Cryptography and Security (cs.CR)",
        "abstract": "Decentralised learning has recently gained traction as an alternative to federated learning in which both data and coordination are distributed over its users. To preserve data confidentiality, decentralised learning relies on differential privacy, multi-party computation, or a combination thereof. However, running multiple privacy-preserving summations in sequence may allow adversaries to perform reconstruction attacks. Unfortunately, current reconstruction countermeasures either cannot trivially be adapted to the distributed setting, or add excessive amounts of noise.\nIn this work, we first show that passive honest-but-curious adversaries can infer other users' private data after several privacy-preserving summations. For example, in subgraphs with 18 users, we show that only three passive honest-but-curious adversaries succeed at reconstructing private data 11.0% of the time, requiring an average of 8.8 summations per adversary. The success rate depends only on the adversaries' direct neighbourhood, independent of the size of the full network. We consider weak adversaries, who do not control the graph topology and can exploit neither the inner workings of the summation protocol nor the specifics of users' data.\nWe develop a mathematical understanding of how reconstruction relates to topology and propose the first topology-based decentralised defence against reconstruction attacks. Specifically, we show that reconstruction requires a number of adversaries linear in the length of the network's shortest cycle. Consequently, reconstructing private data from privacy-preserving summations is impossible in acyclic networks.\nOur work is a stepping stone for a formal theory of topology-based reconstruction defences. Such a theory would generalise our countermeasure beyond summation, define confidentiality in terms of entropy, and describe the effects of differential privacy.\n    ",
        "primary_category": "cs.CR",
        "categories": [
            "cs.DC",
            "cs.DM",
            "cs.LG"
        ],
        "submitted_date": "8 Dec 2023",
        "last_revised_date": " "
    },
    "2312.05476": {
        "title": "Exploring the Naturalness of AI-Generated Images",
        "authors": [
            "Zijian Chen",
            "Wei Sun",
            "Haoning Wu",
            "Zicheng Zhang",
            "Jun Jia",
            "Zhongpeng Ji",
            "Fengyu Sun",
            "Shangling Jui",
            "Xiongkuo Min",
            "Guangtao Zhai",
            "Wenjun Zhang"
        ],
        "comments": "33 pages",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "The proliferation of Artificial Intelligence-Generated Images (AGIs) has greatly expanded the Image Naturalness Assessment (INA) problem. Different from early definitions that mainly focus on tone-mapped images with limited distortions (e.g., exposure, contrast, and color reproduction), INA on AI-generated images is especially challenging as it has more diverse contents and could be affected by factors from multiple perspectives, including low-level technical distortions and high-level rationality distortions. In this paper, we take the first step to benchmark and assess the visual naturalness of AI-generated images. First, we construct the AI-Generated Image Naturalness (AGIN) database by conducting a large-scale subjective study to collect human opinions on the overall naturalness as well as perceptions from technical and rationality perspectives. AGIN verifies that naturalness is universally and disparately affected by technical and rationality distortions. Second, we propose the Joint Objective Image Naturalness evaluaTor (JOINT), to automatically predict the naturalness of AGIs that aligns human ratings. Specifically, JOINT imitates human reasoning in naturalness evaluation by jointly learning both technical and rationality features. We demonstrate that JOINT significantly outperforms baselines for providing more subjectively consistent results on naturalness assessment.\n    ",
        "primary_category": "cs.CV",
        "categories": [],
        "submitted_date": "9 Dec 2023",
        "last_revised_date": " "
    },
    "2312.05490": {
        "title": "Shapley Values-enabled Progressive Pseudo Bag Augmentation for Whole Slide Image Classification",
        "authors": [
            "Renao Yan",
            "Qiehe Sun",
            "Cheng Jin",
            "Yiqing Liu",
            "Yonghong He",
            "Tian Guan",
            "Hao Chen"
        ],
        "comments": "submitted to IEEE TRANSACTIONS ON MEDICAL IMAGING",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "In computational pathology, whole slide image (WSI) classification presents a formidable challenge due to its gigapixel resolution and limited fine-grained annotations. Multiple instance learning (MIL) offers a weakly supervised solution, yet refining instance-level information from bag-level labels remains complex. While most of the conventional MIL methods use attention scores to estimate instance importance scores (IIS) which contribute to the prediction of the slide labels, these often lead to skewed attention distributions and inaccuracies in identifying crucial instances. To address these issues, we propose a new approach inspired by cooperative game theory: employing Shapley values to assess each instance's contribution, thereby improving IIS estimation. The computation of the Shapley value is then accelerated using attention, meanwhile retaining the enhanced instance identification and prioritization. We further introduce a framework for the progressive assignment of pseudo bags based on estimated IIS, encouraging more balanced attention distributions in MIL models. Our extensive experiments on CAMELYON-16, BRACS, and TCGA-LUNG datasets show our method's superiority over existing state-of-the-art approaches, offering enhanced interpretability and class-wise insights. We will release the code upon acceptance.\n    ",
        "primary_category": "cs.CV",
        "categories": [],
        "submitted_date": "9 Dec 2023",
        "last_revised_date": " "
    },
    "2312.05588": {
        "title": "Language-assisted Vision Model Debugger: A Sample-Free Approach to Finding and Fixing Bugs",
        "authors": [
            "Chaoquan Jiang",
            "Jinqiang Wang",
            "Rui Hu",
            "Jitao Sang"
        ],
        "comments": "10 pages,8 figures",
        "subjects": "Artificial Intelligence (cs.AI)",
        "abstract": "Vision models with high overall accuracy often exhibit systematic errors in specific scenarios, posing potential serious safety concerns. Diagnosing bugs of vision models is gaining increased attention, however traditional diagnostic approaches require annotation efforts (eg rich metadata accompanying each samples of CelebA). To address this issue,We propose a language-assisted diagnostic method that uses texts instead of images to diagnose bugs in vision models based on multi-modal models (eg CLIP). Our approach connects the embedding space of CLIP with the buggy vision model to be diagnosed; meanwhile, utilizing a shared classifier and the cross-modal transferability of embedding space from CLIP, the text-branch of CLIP become a proxy model to find bugs in the buggy model. The proxy model can classify texts paired with images. During the diagnosis, a Large Language Model (LLM) is employed to obtain task-relevant corpora, and this corpora is used to extract keywords. Descriptions constructed with templates containing these keywords serve as input text to probe errors in the proxy model. Finally, we validate the ability to diagnose existing visual models using language on the Waterbirds and CelebA datasets, we can identify bugs comprehensible to human experts, uncovering not only known bugs but also previously unknown ones.\n    ",
        "primary_category": "cs.AI",
        "categories": [
            "cs.CV"
        ],
        "submitted_date": "9 Dec 2023",
        "last_revised_date": " "
    },
    "2312.05760": {
        "title": "RepViT-SAM: Towards Real-Time Segmenting Anything",
        "authors": [
            "Ao Wang",
            "Hui Chen",
            "Zijia Lin",
            "Jungong Han",
            "Guiguang Ding"
        ],
        "comments": "Technical report of RepViT+SAM in our CVPR 2024 work. Project page: this https URL",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Segment Anything Model (SAM) has shown impressive zero-shot transfer performance for various computer vision tasks recently. However, its heavy computation costs remain daunting for practical applications. MobileSAM proposes to replace the heavyweight image encoder in SAM with TinyViT by employing distillation, which results in a significant reduction in computational requirements. However, its deployment on resource-constrained mobile devices still encounters challenges due to the substantial memory and computational overhead caused by self-attention mechanisms. Recently, RepViT achieves the state-of-the-art performance and latency trade-off on mobile devices by incorporating efficient architectural designs of ViTs into CNNs. Here, to achieve real-time segmenting anything on mobile devices, following MobileSAM, we replace the heavyweight image encoder in SAM with RepViT model, ending up with the RepViT-SAM model. Extensive experiments show that RepViT-SAM can enjoy significantly better zero-shot transfer capability than MobileSAM, along with nearly $10\\times$ faster inference speed. The code and models are available at \\url{this https URL}.\n    ",
        "primary_category": "cs.CV",
        "categories": [],
        "submitted_date": "10 Dec 2023",
        "last_revised_date": " "
    },
    "2312.06024": {
        "title": "Thinking Assistants: LLM-Based Conversational Assistants that Help Users Think By Asking rather than Answering",
        "authors": [
            "Soya Park",
            "Chinmay Kulkarni"
        ],
        "comments": " ",
        "subjects": "Human-Computer Interaction (cs.HC)",
        "abstract": "We introduce the concept of \"thinking assistants\", an approach that encourages users to engage in deep reflection and critical thinking through brainstorming and thought-provoking queries. We instantiate one such thinking assistant, Gradschool.chat, as a virtual assistant tailored to assist prospective graduate students. We posit that thinking assistants are particularly relevant to situations like applying to graduate school, a phase often characterized by the challenges of academic preparation and the development of a unique research identity. In such situations, students often lack direct mentorship from professors, or may feel hesitant to approach faculty with their queries, making thinking assistants particularly useful.\nLeveraging a Large Language Model (LLM), Gradschool.chat is a demonstration system built as a thinking assistant for working with specific professors in the field of human-computer interaction (HCI). It was designed through training on information specific to these professors and a validation processes in collaboration with these academics. This technical report delineates the system's architecture and offers a preliminary analysis of our deployment study. Additionally, this report covers the spectrum of questions posed to our chatbots by users. The system recorded 223 conversations, with participants responding positively to approximately 65% of responses. Our findings indicate that users who discuss and brainstorm their research interests with Gradschool.chat engage more deeply, often interacting with the chatbot twice as long compared to those who only pose questions about professors.\n    ",
        "primary_category": "cs.HC",
        "categories": [],
        "submitted_date": "10 Dec 2023",
        "last_revised_date": " "
    },
    "2312.06152": {
        "title": "Improving the performance of weak supervision searches using transfer and meta-learning",
        "authors": [
            "Hugues Beauchesne",
            "Zong-En Chen",
            "Cheng-Wei Chiang"
        ],
        "comments": "20 pages, 7 figures, matches the published version",
        "subjects": "High Energy Physics - Phenomenology (hep-ph)",
        "abstract": "Weak supervision searches have in principle the advantages of both being able to train on experimental data and being able to learn distinctive signal properties. However, the practical applicability of such searches is limited by the fact that successfully training a neural network via weak supervision can require a large amount of signal. In this work, we seek to create neural networks that can learn from less experimental signal by using transfer and meta-learning. The general idea is to first train a neural network on simulations, thereby learning concepts that can be reused or becoming a more efficient learner. The neural network would then be trained on experimental data and should require less signal because of its previous training. We find that transfer and meta-learning can substantially improve the performance of weak supervision searches.\n    ",
        "primary_category": "hep-ph",
        "categories": [
            "cs.LG",
            "hep-ex"
        ],
        "submitted_date": "11 Dec 2023",
        "last_revised_date": " "
    },
    "2312.06893": {
        "title": "Styx: Transactional Stateful Functions on Streaming Dataflows",
        "authors": [
            "Kyriakos Psarakis",
            "George Siachamis",
            "George Christodoulou",
            "Marios Fragkoulis",
            "Asterios Katsifodimos"
        ],
        "comments": " ",
        "subjects": "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "abstract": "Developing stateful cloud applications, such as high-throughput/low-latency workflows and microservices with strict consistency requirements, remains arduous for programmers.\nThe Stateful-Functions-as-a-Service (SFaaS) paradigm aims to serve these use cases. However, existing approaches either provide serializable transactional guarantees at the level of individual functions or separate application logic from the state and use inefficient transactional protocols. These design choices increase the execution latency, limiting the usability of SFaaS systems for stateful cloud applications.\nIn this paper, we present Styx, a novel SFaaS runtime that executes serializable transactions across functions with exactly-once guarantees. Styx is the first streaming dataflow-based runtime for SFaaS, offering application logic and state co-location, coarse-grained state persistence, and incremental checkpointing. Styx extends a deterministic transactional protocol to support an arbitrary call graph of stateful functions. It introduces a transaction-execution acknowledgment scheme that allows tracking a transactional workflow's SFaaS calls, guaranteeing atomicity and exactly-once processing. Experiments with the YCSB-T, TPC-C, and Deathstar benchmarks show that Styx outperforms state-of-the-art approaches by achieving at least one order of magnitude higher throughput while exhibiting near-linear scalability.\n    ",
        "primary_category": "cs.DC",
        "categories": [
            "cs.DB"
        ],
        "submitted_date": "11 Dec 2023",
        "last_revised_date": " "
    },
    "2312.07193": {
        "title": "$(\u03c3,\u03b4)$-polycyclic codes in Ore extensions over rings",
        "authors": [
            "Maryam Bajalan",
            "Ivan Landjev",
            "Edgar Mart\u00ednez-Moro",
            "Steve Szabo"
        ],
        "comments": "20 pages, no figure",
        "subjects": "Information Theory (cs.IT)",
        "abstract": "In this paper, we study the algebraic structure of $(\\sigma,\\delta)$-polycyclic codes, defined as submodules in the quotient module $S/Sf$, where $S=R[x,\\sigma,\\delta]$ is the Ore extension ring, $f\\in S$, and $R$ is a finite but not necessarily commutative ring. We establish that the Euclidean duals of $(\\sigma,\\delta)$-polycyclic codes are $(\\sigma,\\delta)$-sequential codes. By using $(\\sigma,\\delta)$-Pseudo Linear Transformation, we define the annihilator dual of $(\\sigma,\\delta)$-polycyclic codes. Then, we demonstrate that the annihilator duals of $(\\sigma,\\delta)$-polycyclic codes maintain their $(\\sigma,\\delta)$-polycyclic nature. Furthermore, we classify when two $(\\sigma,\\delta)$-polycyclic codes are Hamming isometrical equivalent. By employing Wedderburn polynomials, we introduce simple-root $(\\sigma,\\delta)$-polycyclic codes. Subsequently, we define the $(\\sigma, \\delta)$-Mattson-Solomon transform for this class of codes and we address the problem of decomposing these codes by using the properties of Wedderburn polynomials.\n    ",
        "primary_category": "cs.IT",
        "categories": [],
        "submitted_date": "12 Dec 2023",
        "last_revised_date": " "
    },
    "2312.07358": {
        "title": "Distributional Bellman Operators over Mean Embeddings",
        "authors": [
            "Li Kevin Wenliang",
            "Gr\u00e9goire Del\u00e9tang",
            "Matthew Aitchison",
            "Marcus Hutter",
            "Anian Ruoss",
            "Arthur Gretton",
            "Mark Rowland"
        ],
        "comments": " ",
        "subjects": "Machine Learning (stat.ML)",
        "abstract": "We propose a novel algorithmic framework for distributional reinforcement learning, based on learning finite-dimensional mean embeddings of return distributions. We derive several new algorithms for dynamic programming and temporal-difference learning based on this framework, provide asymptotic convergence theory, and examine the empirical performance of the algorithms on a suite of tabular tasks. Further, we show that this approach can be straightforwardly combined with deep reinforcement learning, and obtain a new deep RL agent that improves over baseline distributional approaches on the Arcade Learning Environment.\n    ",
        "primary_category": "stat.ML",
        "categories": [
            "cs.LG"
        ],
        "submitted_date": "9 Dec 2023",
        "last_revised_date": " "
    },
    "2312.07706": {
        "title": "Near-Optimal Differentially Private k-Core Decomposition",
        "authors": [
            "Laxman Dhulipala",
            "George Z. Li",
            "Quanquan C. Liu"
        ],
        "comments": "20 pages. Abstract shortened to fit requirements. In the new version, we show that our techniques can also help give better analysis of the algorithms in [DLRSSY22]",
        "subjects": "Data Structures and Algorithms (cs.DS)",
        "abstract": "Recent work by Dhulipala et al. \\cite{DLRSSY22} initiated the study of the $k$-core decomposition problem under differential privacy via a connection between low round/depth distributed/parallel graph algorithms and private algorithms with small error bounds. They showed that one can output differentially private approximate $k$-core numbers, while only incurring a multiplicative error of $(2 +\\eta)$ (for any constant $\\eta >0$) and additive error of $\\poly(\\log(n))/\\eps$. In this paper, we revisit this problem. Our main result is an $\\eps$-edge differentially private algorithm for $k$-core decomposition which outputs the core numbers with no multiplicative error and $O(\\text{log}(n)/\\eps)$ additive error. This improves upon previous work by a factor of 2 in the multiplicative error, while giving near-optimal additive error. Our result relies on a novel generalized form of the sparse vector technique, which is especially well-suited for threshold-based graph algorithms; thus, we further strengthen the connection between distributed/parallel graph algorithms and differentially private algorithms.\n    ",
        "primary_category": "cs.DS",
        "categories": [
            "cs.CR",
            "cs.SI"
        ],
        "submitted_date": "12 Dec 2023",
        "last_revised_date": " "
    },
    "2312.07806": {
        "title": "Contextually Affinitive Neighborhood Refinery for Deep Clustering",
        "authors": [
            "Chunlin Yu",
            "Ye Shi",
            "Jingya Wang"
        ],
        "comments": "Accepted to NeurIPS 2023",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Previous endeavors in self-supervised learning have enlightened the research of deep clustering from an instance discrimination perspective. Built upon this foundation, recent studies further highlight the importance of grouping semantically similar instances. One effective method to achieve this is by promoting the semantic structure preserved by neighborhood consistency. However, the samples in the local neighborhood may be limited due to their close proximity to each other, which may not provide substantial and diverse supervision signals. Inspired by the versatile re-ranking methods in the context of image retrieval, we propose to employ an efficient online re-ranking process to mine more informative neighbors in a Contextually Affinitive (ConAff) Neighborhood, and then encourage the cross-view neighborhood consistency. To further mitigate the intrinsic neighborhood noises near cluster boundaries, we propose a progressively relaxed boundary filtering strategy to circumvent the issues brought by noisy neighbors. Our method can be easily integrated into the generic self-supervised frameworks and outperforms the state-of-the-art methods on several popular benchmarks.\n    ",
        "primary_category": "cs.CV",
        "categories": [],
        "submitted_date": "12 Dec 2023",
        "last_revised_date": " "
    },
    "2312.08519": {
        "title": "Reconciling Shared versus Context-Specific Information in a Neural Network Model of Latent Causes",
        "authors": [
            "Qihong Lu",
            "Tan T. Nguyen",
            "Qiong Zhang",
            "Uri Hasson",
            "Thomas L. Griffiths",
            "Jeffrey M. Zacks",
            "Samuel J. Gershman",
            "Kenneth A. Norman"
        ],
        "comments": " ",
        "subjects": "Neurons and Cognition (q-bio.NC)",
        "abstract": "It has been proposed that, when processing a stream of events, humans divide their experiences in terms of inferred latent causes (LCs) to support context-dependent learning. However, when shared structure is present across contexts, it is still unclear how the \"splitting\" of LCs and learning of shared structure can be simultaneously achieved. Here, we present the Latent Cause Network (LCNet), a neural network model of LC inference. Through learning, it naturally stores structure that is shared across tasks in the network weights. Additionally, it represents context-specific structure using a context module, controlled by a Bayesian nonparametric inference algorithm, which assigns a unique context vector for each inferred LC. Across three simulations, we found that LCNet could 1) extract shared structure across LCs in a function learning task while avoiding catastrophic interference, 2) capture human data on curriculum effects in schema learning, and 3) infer the underlying event structure when processing naturalistic videos of daily events. Overall, these results demonstrate a computationally feasible approach to reconciling shared structure and context-specific structure in a model of LCs that is scalable from laboratory experiment settings to naturalistic settings.\n    ",
        "primary_category": "q-bio.NC",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "13 Dec 2023",
        "last_revised_date": " "
    },
    "2312.08664": {
        "title": "SPEAL: Skeletal Prior Embedded Attention Learning for Cross-Source Point Cloud Registration",
        "authors": [
            "Kezheng Xiong",
            "Maoji Zheng",
            "Qingshan Xu",
            "Chenglu Wen",
            "Siqi Shen",
            "Cheng Wang"
        ],
        "comments": "Accepted by AAAI2024",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Point cloud registration, a fundamental task in 3D computer vision, has remained largely unexplored in cross-source point clouds and unstructured scenes. The primary challenges arise from noise, outliers, and variations in scale and density. However, neglected geometric natures of point clouds restricts the performance of current methods. In this paper, we propose a novel method termed SPEAL to leverage skeletal representations for effective learning of intrinsic topologies of point clouds, facilitating robust capture of geometric intricacy. Specifically, we design the Skeleton Extraction Module to extract skeleton points and skeletal features in an unsupervised manner, which is inherently robust to noise and density variances. Then, we propose the Skeleton-Aware GeoTransformer to encode high-level skeleton-aware features. It explicitly captures the topological natures and inter-point-cloud skeletal correlations with the noise-robust and density-invariant skeletal representations. Next, we introduce the Correspondence Dual-Sampler to facilitate correspondences by augmenting the correspondence set with skeletal correspondences. Furthermore, we construct a challenging novel large-scale cross-source point cloud dataset named KITTI CrossSource for benchmarking cross-source point cloud registration methods. Extensive quantitative and qualitative experiments are conducted to demonstrate our approach's superiority and robustness on both cross-source and same-source datasets. To the best of our knowledge, our approach is the first to facilitate point cloud registration with skeletal geometric priors.\n    ",
        "primary_category": "cs.CV",
        "categories": [],
        "submitted_date": "14 Dec 2023",
        "last_revised_date": " "
    },
    "2312.08675": {
        "title": "AVA: Inconspicuous Attribute Variation-based Adversarial Attack bypassing DeepFake Detection",
        "authors": [
            "Xiangtao Meng",
            "Li Wang",
            "Shanqing Guo",
            "Lei Ju",
            "Qingchuan Zhao"
        ],
        "comments": " ",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "While DeepFake applications are becoming popular in recent years, their abuses pose a serious privacy threat. Unfortunately, most related detection algorithms to mitigate the abuse issues are inherently vulnerable to adversarial attacks because they are built atop DNN-based classification models, and the literature has demonstrated that they could be bypassed by introducing pixel-level perturbations. Though corresponding mitigation has been proposed, we have identified a new attribute-variation-based adversarial attack (AVA) that perturbs the latent space via a combination of Gaussian prior and semantic discriminator to bypass such mitigation. It perturbs the semantics in the attribute space of DeepFake images, which are inconspicuous to human beings (e.g., mouth open) but can result in substantial differences in DeepFake detection. We evaluate our proposed AVA attack on nine state-of-the-art DeepFake detection algorithms and applications. The empirical results demonstrate that AVA attack defeats the state-of-the-art black box attacks against DeepFake detectors and achieves more than a 95% success rate on two commercial DeepFake detectors. Moreover, our human study indicates that AVA-generated DeepFake images are often imperceptible to humans, which presents huge security and privacy concerns.\n    ",
        "primary_category": "cs.CV",
        "categories": [
            "cs.CR"
        ],
        "submitted_date": "14 Dec 2023",
        "last_revised_date": " "
    },
    "2312.08799": {
        "title": "Refined Characterizations of Approval-based Committee Scoring Rules",
        "authors": [
            "Chris Dong",
            "Patrick Lederer"
        ],
        "comments": "Appears at AAAI-24",
        "subjects": "Computer Science and Game Theory (cs.GT)",
        "abstract": "In approval-based committee (ABC) elections, the goal is to select a fixed-size subset of the candidates, a so-called committee, based on the voters' approval ballots over the candidates. One of the most popular classes of ABC voting rules are ABC scoring rules, which have recently been characterized by Lackner and Skowron (2021). However, this characterization relies on a model where the output is a ranking of committees instead of a set of winning committees and no full characterization of ABC scoring rules exists in the latter standard setting. We address this issue by characterizing two important subclasses of ABC scoring rules in the standard ABC election model, thereby both extending the result of Lackner and Skowron (2021) to the standard setting and refining it to subclasses. In more detail, by relying on a consistency axiom for variable electorates, we characterize (i) the prominent class of Thiele rules and (ii) a new class of ABC voting rules called ballot size weighted approval voting. Based on these theorems, we also infer characterizations of three well-known ABC voting rules, namely multi-winner approval voting, proportional approval voting, and satisfaction approval voting.\n    ",
        "primary_category": "cs.GT",
        "categories": [
            "econ.TH"
        ],
        "submitted_date": "14 Dec 2023",
        "last_revised_date": " "
    },
    "2312.08886": {
        "title": "Diffusion-based Blind Text Image Super-Resolution",
        "authors": [
            "Yuzhe Zhang",
            "Jiawei Zhang",
            "Hao Li",
            "Zhouxia Wang",
            "Luwei Hou",
            "Dongqing Zou",
            "Liheng Bian"
        ],
        "comments": "Accepted by CVPR2024",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Recovering degraded low-resolution text images is challenging, especially for Chinese text images with complex strokes and severe degradation in real-world scenarios. Ensuring both text fidelity and style realness is crucial for high-quality text image super-resolution. Recently, diffusion models have achieved great success in natural image synthesis and restoration due to their powerful data distribution modeling abilities and data generation capabilities. In this work, we propose an Image Diffusion Model (IDM) to restore text images with realistic styles. For diffusion models, they are not only suitable for modeling realistic image distribution but also appropriate for learning text distribution. Since text prior is important to guarantee the correctness of the restored text structure according to existing arts, we also propose a Text Diffusion Model (TDM) for text recognition which can guide IDM to generate text images with correct structures. We further propose a Mixture of Multi-modality module (MoM) to make these two diffusion models cooperate with each other in all the diffusion steps. Extensive experiments on synthetic and real-world datasets demonstrate that our Diffusion-based Blind Text Image Super-Resolution (DiffTSR) can restore text images with more accurate text structures as well as more realistic appearances simultaneously.\n    ",
        "primary_category": "cs.CV",
        "categories": [],
        "submitted_date": "13 Dec 2023",
        "last_revised_date": " "
    },
    "2312.09468": {
        "title": "Safe Reinforcement Learning in a Simulated Robotic Arm",
        "authors": [
            "Luka Kova\u010d",
            "Igor Farka\u0161"
        ],
        "comments": "4 pages, 2 figures. Appeared in 2023 International Conference on Artificial Neural Networks (ICANN) proceedings. Published version copyrighted by Springer. This work was funded by the Horizon Europe Twinning project TERAIS, G.A. number 101079338 and in part by the national project APVV-21-0105. Link to the code: this https URL",
        "subjects": "Robotics (cs.RO)",
        "abstract": "Reinforcement learning (RL) agents need to explore their environments in order to learn optimal policies. In many environments and tasks, safety is of critical importance. The widespread use of simulators offers a number of advantages, including safe exploration which will be inevitable in cases when RL systems need to be trained directly in the physical environment (e.g. in human-robot interaction). The popular Safety Gym library offers three mobile agent types that can learn goal-directed tasks while considering various safety constraints. In this paper, we extend the applicability of safe RL algorithms by creating a customized environment with Panda robotic arm where Safety Gym algorithms can be tested. We performed pilot experiments with the popular PPO algorithm comparing the baseline with the constrained version and show that the constrained version is able to learn the equally good policy while better complying with safety constraints and taking longer training time as expected.\n    ",
        "primary_category": "cs.RO",
        "categories": [
            "cs.AI",
            "cs.LG"
        ],
        "submitted_date": "28 Nov 2023",
        "last_revised_date": " "
    },
    "2312.09854": {
        "title": "Q-Segment: Segmenting Images In-Sensor for Vessel-Based Medical Diagnosis",
        "authors": [
            "Pietro Bonazzi",
            "Yawei Li",
            "Sizhen Bian",
            "Michele Magno"
        ],
        "comments": " ",
        "subjects": "Image and Video Processing (eess.IV)",
        "abstract": "This paper addresses the growing interest in deploying deep learning models directly in-sensor. We present \"Q-Segment\", a quantized real-time segmentation algorithm, and conduct a comprehensive evaluation on a low-power edge vision platform with an in-sensors processor, the Sony IMX500. One of the main goals of the model is to achieve end-to-end image segmentation for vessel-based medical diagnosis. Deployed on the IMX500 platform, Q-Segment achieves ultra-low inference time in-sensor only 0.23 ms and power consumption of only 72mW. We compare the proposed network with state-of-the-art models, both float and quantized, demonstrating that the proposed solution outperforms existing networks on various platforms in computing efficiency, e.g., by a factor of 75x compared to ERFNet. The network employs an encoder-decoder structure with skip connections, and results in a binary accuracy of 97.25% and an Area Under the Receiver Operating Characteristic Curve (AUC) of 96.97% on the CHASE dataset. We also present a comparison of the IMX500 processing core with the Sony Spresense, a low-power multi-core ARM Cortex-M microcontroller, and a single-core ARM Cortex-M4 showing that it can achieve in-sensor processing with end-to-end low latency (17 ms) and power concumption (254mW). This research contributes valuable insights into edge-based image segmentation, laying the foundation for efficient algorithms tailored to low-power environments.\n    ",
        "primary_category": "eess.IV",
        "categories": [
            "cs.CV"
        ],
        "submitted_date": "15 Dec 2023",
        "last_revised_date": " "
    },
    "2312.10930": {
        "title": "Deep Learning Approaches for Seizure Video Analysis: A Review",
        "authors": [
            "David Ahmedt-Aristizabal",
            "Mohammad Ali Armin",
            "Zeeshan Hayder",
            "Norberto Garcia-Cairasco",
            "Lars Petersson",
            "Clinton Fookes",
            "Simon Denman",
            "Aileen McGonigal"
        ],
        "comments": "Accepted in Epilepsy & Behavior",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Seizure events can manifest as transient disruptions in the control of movements which may be organized in distinct behavioral sequences, accompanied or not by other observable features such as altered facial expressions. The analysis of these clinical signs, referred to as semiology, is subject to observer variations when specialists evaluate video-recorded events in the clinical setting. To enhance the accuracy and consistency of evaluations, computer-aided video analysis of seizures has emerged as a natural avenue. In the field of medical applications, deep learning and computer vision approaches have driven substantial advancements. Historically, these approaches have been used for disease detection, classification, and prediction using diagnostic data; however, there has been limited exploration of their application in evaluating video-based motion detection in the clinical epileptology setting. While vision-based technologies do not aim to replace clinical expertise, they can significantly contribute to medical decision-making and patient care by providing quantitative evidence and decision support. Behavior monitoring tools offer several advantages such as providing objective information, detecting challenging-to-observe events, reducing documentation efforts, and extending assessment capabilities to areas with limited expertise. The main applications of these could be (1) improved seizure detection methods; (2) refined semiology analysis for predicting seizure type and cerebral localization. In this paper, we detail the foundation technologies used in vision-based systems in the analysis of seizure videos, highlighting their success in semiology detection and analysis, focusing on work published in the last 7 years. Additionally, we illustrate how existing technologies can be interconnected through an integrated system for video-based semiology analysis.\n    ",
        "primary_category": "cs.CV",
        "categories": [],
        "submitted_date": "18 Dec 2023",
        "last_revised_date": " "
    },
    "2312.11361": {
        "title": "NoMIRACL: Knowing When You Don't Know for Robust Multilingual Retrieval-Augmented Generation",
        "authors": [
            "Nandan Thakur",
            "Luiz Bonifacio",
            "Xinyu Zhang",
            "Odunayo Ogundepo",
            "Ehsan Kamalloo",
            "David Alfonso-Hermelo",
            "Xiaoguang Li",
            "Qun Liu",
            "Boxing Chen",
            "Mehdi Rezagholizadeh",
            "Jimmy Lin"
        ],
        "comments": " ",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "Retrieval-augmented generation (RAG) grounds large language model (LLM) output by leveraging external knowledge sources to reduce factual hallucinations. However, prior works lack a comprehensive evaluation of different language families, making it challenging to evaluate LLM robustness against errors in external retrieved knowledge. To overcome this, we establish NoMIRACL, a human-annotated dataset for evaluating LLM robustness in RAG across 18 typologically diverse languages. NoMIRACL includes both a non-relevant and a relevant subset. Queries in the non-relevant subset contain passages judged as non-relevant, whereas queries in the relevant subset include at least a single judged relevant passage. We measure LLM robustness using two metrics: (i) hallucination rate, measuring model tendency to hallucinate an answer, when the answer is not present in passages in the non-relevant subset, and (ii) error rate, measuring model inaccuracy to recognize relevant passages in the relevant subset. In our work, we measure robustness for a wide variety of multilingual-focused LLMs and observe that most of the models struggle to balance the two capacities. Models such as LLAMA-2, Orca-2, and FLAN-T5 observe more than an 88% hallucination rate on the non-relevant subset, whereas, Mistral overall hallucinates less, but can achieve up to a 74.9% error rate on the relevant subset. Overall, GPT-4 is observed to provide the best tradeoff on both subsets, highlighting future work necessary to improve LLM robustness.\n    ",
        "primary_category": "cs.CL",
        "categories": [
            "cs.IR"
        ],
        "submitted_date": "18 Dec 2023",
        "last_revised_date": " "
    },
    "2312.11436": {
        "title": "Layerwise complexity-matched learning yields an improved model of cortical area V2",
        "authors": [
            "Nikhil Parthasarathy",
            "Olivier J. H\u00e9naff",
            "Eero P. Simoncelli"
        ],
        "comments": "28 pages, 12 figures",
        "subjects": "Neurons and Cognition (q-bio.NC)",
        "abstract": "Human ability to recognize complex visual patterns arises through transformations performed by successive areas in the ventral visual cortex. Deep neural networks trained end-to-end for object recognition approach human capabilities, and offer the best descriptions to date of neural responses in the late stages of the hierarchy. But these networks provide a poor account of the early stages, compared to traditional hand-engineered models, or models optimized for coding efficiency or prediction. Moreover, the gradient backpropagation used in end-to-end learning is generally considered to be biologically implausible. Here, we overcome both of these limitations by developing a bottom-up self-supervised training methodology that operates independently on successive layers. Specifically, we maximize feature similarity between pairs of locally-deformed natural image patches, while decorrelating features across patches sampled from other images. Crucially, the deformation amplitudes are adjusted proportionally to receptive field sizes in each layer, thus matching the task complexity to the capacity at each stage of processing. In comparison with architecture-matched versions of previous models, we demonstrate that our layerwise complexity-matched learning (LCL) formulation produces a two-stage model (LCL-V2) that is better aligned with selectivity properties and neural activity in primate area V2. We demonstrate that the complexity-matched learning paradigm is critical for the emergence of the improved biological alignment. Finally, when the two-stage model is used as a fixed front-end for a deep network trained to perform object recognition, the resultant model (LCL-V2Net) is significantly better than standard end-to-end self-supervised, supervised, and adversarially-trained models in terms of generalization to out-of-distribution tasks and alignment with human behavior.\n    ",
        "primary_category": "q-bio.NC",
        "categories": [
            "cs.CV",
            "cs.LG"
        ],
        "submitted_date": "18 Dec 2023",
        "last_revised_date": " "
    },
    "2312.11954": {
        "title": "Adversarial AutoMixup",
        "authors": [
            "Huafeng Qin",
            "Xin Jin",
            "Yun Jiang",
            "Mounim A. El-Yacoubi",
            "Xinbo Gao"
        ],
        "comments": "ICLR 2024 Camera Ready.(19 pages) with the source code at this https URL",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Data mixing augmentation has been widely applied to improve the generalization ability of deep neural networks. Recently, offline data mixing augmentation, e.g. handcrafted and saliency information-based mixup, has been gradually replaced by automatic mixing approaches. Through minimizing two sub-tasks, namely, mixed sample generation and mixup classification in an end-to-end way, AutoMix significantly improves accuracy on image classification tasks. However, as the optimization objective is consistent for the two sub-tasks, this approach is prone to generating consistent instead of diverse mixed samples, which results in overfitting for target task training. In this paper, we propose AdAutomixup, an adversarial automatic mixup augmentation approach that generates challenging samples to train a robust classifier for image classification, by alternatively optimizing the classifier and the mixup sample generator. AdAutomixup comprises two modules, a mixed example generator, and a target classifier. The mixed sample generator aims to produce hard mixed examples to challenge the target classifier, while the target classifier's aim is to learn robust features from hard mixed examples to improve generalization. To prevent the collapse of the inherent meanings of images, we further introduce an exponential moving average (EMA) teacher and cosine similarity to train AdAutomixup in an end-to-end way. Extensive experiments on seven image benchmarks consistently prove that our approach outperforms the state of the art in various classification scenarios. The source code is available at this https URL.\n    ",
        "primary_category": "cs.CV",
        "categories": [],
        "submitted_date": "19 Dec 2023",
        "last_revised_date": " "
    },
    "2312.12183": {
        "title": "Poincar\u00e9 Differential Privacy for Hierarchy-Aware Graph Embedding",
        "authors": [
            "Yuecen Wei",
            "Haonan Yuan",
            "Xingcheng Fu",
            "Qingyun Sun",
            "Hao Peng",
            "Xianxian Li",
            "Chunming Hu"
        ],
        "comments": "Accepted by the Thirty-Eighth AAAI Conference on Artificial Intelligence (AAAI-24)",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Hierarchy is an important and commonly observed topological property in real-world graphs that indicate the relationships between supervisors and subordinates or the organizational behavior of human groups. As hierarchy is introduced as a new inductive bias into the Graph Neural Networks (GNNs) in various tasks, it implies latent topological relations for attackers to improve their inference attack performance, leading to serious privacy leakage issues. In addition, existing privacy-preserving frameworks suffer from reduced protection ability in hierarchical propagation due to the deficiency of adaptive upper-bound estimation of the hierarchical perturbation boundary. It is of great urgency to effectively leverage the hierarchical property of data while satisfying privacy guarantees. To solve the problem, we propose the Poincar\u00e9 Differential Privacy framework, named PoinDP, to protect the hierarchy-aware graph embedding based on hyperbolic geometry. Specifically, PoinDP first learns the hierarchy weights for each entity based on the Poincar\u00e9 model in hyperbolic space. Then, the Personalized Hierarchy-aware Sensitivity is designed to measure the sensitivity of the hierarchical structure and adaptively allocate the privacy protection strength. Besides, the Hyperbolic Gaussian Mechanism (HGM) is proposed to extend the Gaussian mechanism in Euclidean space to hyperbolic space to realize random perturbations that satisfy differential privacy under the hyperbolic space metric. Extensive experiment results on five real-world datasets demonstrate the proposed PoinDP's advantages of effective privacy protection while maintaining good performance on the node classification task.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.CR"
        ],
        "submitted_date": "19 Dec 2023",
        "last_revised_date": " "
    },
    "2312.12343": {
        "title": "LatestEval: Addressing Data Contamination in Language Model Evaluation through Dynamic and Time-Sensitive Test Construction",
        "authors": [
            "Yucheng Li",
            "Frank Guerin",
            "Chenghua Lin"
        ],
        "comments": "AAAI 2024",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "Data contamination in evaluation is getting increasingly prevalent with the emergence of language models pre-trained on super large, automatically crawled corpora. This problem leads to significant challenges in the accurate assessment of model capabilities and generalisations. In this paper, we propose LatestEval, an automatic method that leverages the most recent texts to create uncontaminated reading comprehension evaluations. LatestEval avoids data contamination by only using texts published within a recent time window, ensuring no overlap with the training corpora of pre-trained language models. We develop the LatestEval automated pipeline to 1) gather the latest texts; 2) identify key information, and 3) construct questions targeting the information while removing the existing answers from the context. This encourages models to infer the answers themselves based on the remaining context, rather than just copy-paste. Our experiments demonstrate that language models exhibit negligible memorisation behaviours on LatestEval as opposed to previous benchmarks, suggesting a significantly reduced risk of data contamination and leading to a more robust evaluation. Data and code are publicly available at: this https URL.\n    ",
        "primary_category": "cs.CL",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "19 Dec 2023",
        "last_revised_date": " "
    },
    "2312.12478": {
        "title": "ProS: Prompting-to-simulate Generalized knowledge for Universal Cross-Domain Retrieval",
        "authors": [
            "Kaipeng Fang",
            "Jingkuan Song",
            "Lianli Gao",
            "Pengpeng Zeng",
            "Zhi-Qi Cheng",
            "Xiyao Li",
            "Heng Tao Shen"
        ],
        "comments": " ",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "The goal of Universal Cross-Domain Retrieval (UCDR) is to achieve robust performance in generalized test scenarios, wherein data may belong to strictly unknown domains and categories during training. Recently, pre-trained models with prompt tuning have shown strong generalization capabilities and attained noteworthy achievements in various downstream tasks, such as few-shot learning and video-text retrieval. However, applying them directly to UCDR may not sufficiently to handle both domain shift (i.e., adapting to unfamiliar domains) and semantic shift (i.e., transferring to unknown categories). To this end, we propose \\textbf{Pro}mpting-to-\\textbf{S}imulate (ProS), the first method to apply prompt tuning for UCDR. ProS employs a two-step process to simulate Content-aware Dynamic Prompts (CaDP) which can impact models to produce generalized features for UCDR. Concretely, in Prompt Units Learning stage, we introduce two Prompt Units to individually capture domain and semantic knowledge in a mask-and-align way. Then, in Context-aware Simulator Learning stage, we train a Content-aware Prompt Simulator under a simulated test scenarios to produce the corresponding CaDP. Extensive experiments conducted on three benchmark datasets show that our method achieves new state-of-the-art performance without bringing excessive parameters. Our method is publicly available at this https URL.\n    ",
        "primary_category": "cs.CV",
        "categories": [],
        "submitted_date": "19 Dec 2023",
        "last_revised_date": " "
    },
    "2312.13004": {
        "title": "Reconfigurable Intelligent Surface-Aided Near-field Communications for 6G: Opportunities and Challenges",
        "authors": [
            "Xidong Mu",
            "Jiaqi Xu",
            "Yuanwei Liu",
            "Lajos Hanzo"
        ],
        "comments": "7 pages, 7 figures, this paper was accepted for publication in IEEE Vehicular Technology Magazine",
        "subjects": "Information Theory (cs.IT)",
        "abstract": "Reconfigurable intelligent surface (RIS)-aided near-field communications is investigated. First, the necessity of investigating RIS-aided near-field communications and the advantages brought about by the unique spherical-wave-based near-field propagation are discussed. Then, the family of patch-array-based RISs and metasurface-based RISs are introduced along with their respective near-field channel models. A pair of fundamental performance limits of RIS-aided near-field communications, namely their power scaling law and effective degrees-of-freedom, are analyzed for both patch-array-based and metasurface-based RISs, which reveals the potential performance gains that can be achieved. Furthermore, the associated near-field beam training and beamforming design issues are studied, where a two-stage hierarchical beam training approach and a low-complexity element-wise beamforming design are proposed for RIS-aided near-field communications. Finally, a suite of open research problems is highlighted for motivating future research.\n    ",
        "primary_category": "cs.IT",
        "categories": [
            "eess.SP"
        ],
        "submitted_date": "20 Dec 2023",
        "last_revised_date": " "
    },
    "2312.13064": {
        "title": "LPR: Large Language Models-Aided Program Reduction",
        "authors": [
            "Mengxiao Zhang",
            "Yongqiang Tian",
            "Zhenyang Xu",
            "Yiwen Dong",
            "Shin Hwei Tan",
            "Chengnian Sun"
        ],
        "comments": "12 pages, 3 tables, 6 figures",
        "subjects": "Programming Languages (cs.PL)",
        "abstract": "Program reduction is a prevalent technique to facilitate compilers' debugging by automatically minimizing bug-triggering programs. Existing program reduction techniques are either generic across languages (e.g., Perses and Vulcan) or specifically customized for one certain language by employing language-specific features, like C-Reduce. However, striking the balance between generality across multiple programming languages and specificity to individual languages in program reduction is yet to be explored. This paper proposes LPR, the first technique utilizing LLMs to perform language-specific program reduction for multiple languages. The core insight is to utilize both the language-generic syntax level program reduction (e.g., Perses) and the language-specific semantic level program transformations learned by LLMs. Alternately, language-generic program reducers efficiently reduce programs into 1-tree-minimality, which is small enough to be manageable for LLMs; LLMs effectively transform programs via the learned semantics to expose new reduction opportunities for the language-generic program reducers to further reduce the programs. Our extensive evaluation on 50 benchmarks across three languages (C, Rust, and JavaScript) has highlighted LPR's practicality and superiority over Vulcan, the state-of-the-art language-generic program reducer. For effectiveness, LPR surpasses Vulcan by producing 24.93%, 4.47%, and 11.71% smaller programs on benchmarks in C, Rust and JavaScript. Moreover, LPR and Vulcan have demonstrated their potential to complement each other. By using Vulcan on LPR's output for C programs, we achieve program sizes comparable to those reduced by C-Reduce. For efficiency, LPR takes 10.77%, 34.88%, 36.96% less time than Vulcan to finish all benchmarks in C, Rust and JavaScript, separately.\n    ",
        "primary_category": "cs.PL",
        "categories": [
            "cs.SE"
        ],
        "submitted_date": "20 Dec 2023",
        "last_revised_date": " "
    },
    "2312.13103": {
        "title": "Exploring Multimodal Large Language Models for Radiology Report Error-checking",
        "authors": [
            "Jinge Wu",
            "Yunsoo Kim",
            "Eva C. Keller",
            "Jamie Chow",
            "Adam P. Levine",
            "Nikolas Pontikos",
            "Zina Ibrahim",
            "Paul Taylor",
            "Michelle C. Williams",
            "Honghan Wu"
        ],
        "comments": " ",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "This paper proposes one of the first clinical applications of multimodal large language models (LLMs) as an assistant for radiologists to check errors in their reports. We created an evaluation dataset from real-world radiology datasets (including X-rays and CT scans). A subset of original reports was modified to contain synthetic errors by introducing three types of mistakes: \"insert\", \"remove\", and \"substitute\". The evaluation contained two difficulty levels: SIMPLE for binary error-checking and COMPLEX for identifying error types. At the SIMPLE level, our fine-tuned model significantly enhanced performance by 47.4% and 25.4% on MIMIC-CXR and IU X-ray data, respectively. This performance boost is also observed in unseen modality, CT scans, as the model performed 19.46% better than the baseline model. The model also surpassed the domain expert's accuracy in the MIMIC-CXR dataset by 1.67%. Notably, among the subsets (N=21) of the test set where a clinician did not achieve the correct conclusion, the LLaVA ensemble mode correctly identified 71.4% of these cases. However, all models performed poorly in identifying mistake types, underscoring the difficulty of the COMPLEX level. This study marks a promising step toward utilizing multimodal LLMs to enhance diagnostic accuracy in radiology. The ensemble model demonstrated comparable performance to clinicians, even capturing errors overlooked by humans.\n    ",
        "primary_category": "cs.CL",
        "categories": [
            "cs.CV"
        ],
        "submitted_date": "20 Dec 2023",
        "last_revised_date": " "
    },
    "2312.14305": {
        "title": "The Exact Spanning Ratio of the Parallelogram Delaunay Graph",
        "authors": [
            "Prosenjit Bose",
            "Jean-Lou De Carufel",
            "Sandrine Njoo"
        ],
        "comments": " ",
        "subjects": "Computational Geometry (cs.CG)",
        "abstract": "Finding the exact spanning ratio of a Delaunay graph has been one of the longstanding open problems in Computational Geometry. Currently there are only four convex shapes for which the exact spanning ratio of their Delaunay graph is known: the equilateral triangle, the square, the regular hexagon and the rectangle. In this paper, we show the exact spanning ratio of the parallelogram Delaunay graph, making the parallelogram the fifth convex shape for which an exact bound is known. The worst-case spanning ratio is exactly $$\\frac{\\sqrt{2}\\sqrt{1+A^2+2A\\cos(\\theta_0)+(A+\\cos(\\theta_0))\\sqrt{1+A^2+2A\\cos(\\theta_0)}}}{\\sin(\\theta_0)} .$$ where $A$ is the aspect ratio and $\\theta_0$ is the non-obtuse angle of the parallelogram. Moreover, we show how to construct a parallelogram Delaunay graph whose spanning ratio matches the above mentioned spanning ratio.\n    ",
        "primary_category": "cs.CG",
        "categories": [],
        "submitted_date": "21 Dec 2023",
        "last_revised_date": " "
    },
    "2312.14388": {
        "title": "A Generalized Shuffle Framework for Privacy Amplification: Strengthening Privacy Guarantees and Enhancing Utility",
        "authors": [
            "E Chen",
            "Yang Cao",
            "Yifei Ge"
        ],
        "comments": "Correct some typos",
        "subjects": "Cryptography and Security (cs.CR)",
        "abstract": "The shuffle model of local differential privacy is an advanced method of privacy amplification designed to enhance privacy protection with high utility. It achieves this by randomly shuffling sensitive data, making linking individual data points to specific individuals more challenging. However, most existing studies have focused on the shuffle model based on $(\\epsilon_0,0)$-Locally Differentially Private (LDP) randomizers, with limited consideration for complex scenarios such as $(\\epsilon_0,\\delta_0)$-LDP or personalized LDP (PLDP). This hinders a comprehensive understanding of the shuffle model's potential and limits its application in various settings. To bridge this research gap, we propose a generalized shuffle framework that can be applied to any $(\\epsilon_i,\\delta_i)$-PLDP setting with personalized privacy parameters. This generalization allows for a broader exploration of the privacy-utility trade-off and facilitates the design of privacy-preserving analyses in diverse contexts. We prove that shuffled $(\\epsilon_i,\\delta_i)$-PLDP process approximately preserves $\\mu$-Gaussian Differential Privacy with \\mu = \\sqrt{\\frac{2}{\\sum_{i=1}^{n} \\frac{1-\\delta_i}{1+e^{\\epsilon_i}}-\\max_{i}{\\frac{1-\\delta_{i}}{1+e^{\\epsilon_{i}}}}}}. $\nThis approach allows us to avoid the limitations and potential inaccuracies associated with inequality estimations. To strengthen the privacy guarantee, we improve the lower bound by utilizing hypothesis testing} instead of relying on rough estimations like the Chernoff bound or Hoeffding's inequality. Furthermore, extensive comparative evaluations clearly show that our approach outperforms existing methods in achieving strong central privacy guarantees while preserving the utility of the global model. We have also carefully designed corresponding algorithms for average function, frequency estimation, and stochastic gradient descent.\n    ",
        "primary_category": "cs.CR",
        "categories": [
            "math.CO"
        ],
        "submitted_date": "22 Dec 2023",
        "last_revised_date": " "
    },
    "2312.14404": {
        "title": "Cross-Covariate Gait Recognition: A Benchmark",
        "authors": [
            "Shinan Zou",
            "Chao Fan",
            "Jianbo Xiong",
            "Chuanfu Shen",
            "Shiqi Yu",
            "Jin Tang"
        ],
        "comments": "AAAI2024",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Gait datasets are essential for gait research. However, this paper observes that present benchmarks, whether conventional constrained or emerging real-world datasets, fall short regarding covariate diversity. To bridge this gap, we undertake an arduous 20-month effort to collect a cross-covariate gait recognition (CCGR) dataset. The CCGR dataset has 970 subjects and about 1.6 million sequences; almost every subject has 33 views and 53 different covariates. Compared to existing datasets, CCGR has both population and individual-level diversity. In addition, the views and covariates are well labeled, enabling the analysis of the effects of different factors. CCGR provides multiple types of gait data, including RGB, parsing, silhouette, and pose, offering researchers a comprehensive resource for exploration. In order to delve deeper into addressing cross-covariate gait recognition, we propose parsing-based gait recognition (ParsingGait) by utilizing the newly proposed parsing data. We have conducted extensive experiments. Our main results show: 1) Cross-covariate emerges as a pivotal challenge for practical applications of gait recognition. 2) ParsingGait demonstrates remarkable potential for further advancement. 3) Alarmingly, existing SOTA methods achieve less than 43% accuracy on the CCGR, highlighting the urgency of exploring cross-covariate gait recognition. Link: this https URL.\n    ",
        "primary_category": "cs.CV",
        "categories": [],
        "submitted_date": "22 Dec 2023",
        "last_revised_date": " "
    },
    "2312.14499": {
        "title": "Hutchinson Trace Estimation for High-Dimensional and High-Order Physics-Informed Neural Networks",
        "authors": [
            "Zheyuan Hu",
            "Zekun Shi",
            "George Em Karniadakis",
            "Kenji Kawaguchi"
        ],
        "comments": "Published in Computer Methods in Applied Mechanics and Engineering",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Physics-Informed Neural Networks (PINNs) have proven effective in solving partial differential equations (PDEs), especially when some data are available by seamlessly blending data and physics. However, extending PINNs to high-dimensional and even high-order PDEs encounters significant challenges due to the computational cost associated with automatic differentiation in the residual loss. Herein, we address the limitations of PINNs in handling high-dimensional and high-order PDEs by introducing Hutchinson Trace Estimation (HTE). Starting with the second-order high-dimensional PDEs ubiquitous in scientific computing, HTE transforms the calculation of the entire Hessian matrix into a Hessian vector product (HVP). This approach alleviates the computational bottleneck via Taylor-mode automatic differentiation and significantly reduces memory consumption from the Hessian matrix to HVP. We further showcase HTE's convergence to the original PINN loss and its unbiased behavior under specific conditions. Comparisons with Stochastic Dimension Gradient Descent (SDGD) highlight the distinct advantages of HTE, particularly in scenarios with significant variance among dimensions. We further extend HTE to higher-order and higher-dimensional PDEs, specifically addressing the biharmonic equation. By employing tensor-vector products (TVP), HTE efficiently computes the colossal tensor associated with the fourth-order high-dimensional biharmonic equation, saving memory and enabling rapid computation. The effectiveness of HTE is illustrated through experimental setups, demonstrating comparable convergence rates with SDGD under memory and speed constraints. Additionally, HTE proves valuable in accelerating the Gradient-Enhanced PINN (gPINN) version as well as the Biharmonic equation. Overall, HTE opens up a new capability in scientific machine learning for tackling high-order and high-dimensional PDEs.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.AI",
            "math.DS",
            "math.NA",
            "stat.ML"
        ],
        "submitted_date": "22 Dec 2023",
        "last_revised_date": " "
    },
    "2312.14889": {
        "title": "On Rate-Optimal Partitioning Classification from Observable and from Privatised Data",
        "authors": [
            "Bal\u00e1zs Csan\u00e1d Cs\u00e1ji",
            "L\u00e1szl\u00f3 Gy\u00f6rfi",
            "Ambrus Tam\u00e1s",
            "Harro Walk"
        ],
        "comments": " ",
        "subjects": "Machine Learning (stat.ML)",
        "abstract": "In this paper we revisit the classical method of partitioning classification and study its convergence rate under relaxed conditions, both for observable (non-privatised) and for privatised data. Let the feature vector $X$ take values in $\\mathbb{R}^d$ and denote its label by $Y$. Previous results on the partitioning classifier worked with the strong density assumption, which is restrictive, as we demonstrate through simple examples. We assume that the distribution of $X$ is a mixture of an absolutely continuous and a discrete distribution, such that the absolutely continuous component is concentrated to a $d_a$ dimensional subspace. Here, we study the problem under much milder assumptions: in addition to the standard Lipschitz and margin conditions, a novel characteristic of the absolutely continuous component is introduced, by which the exact convergence rate of the classification error probability is calculated, both for the binary and for the multi-label cases. Interestingly, this rate of convergence depends only on the intrinsic dimension $d_a$.\nThe privacy constraints mean that the data $(X_1,Y_1), \\dots ,(X_n,Y_n)$ cannot be directly observed, and the classifiers are functions of the randomised outcome of a suitable local differential privacy mechanism. The statistician is free to choose the form of this privacy mechanism, and here we add Laplace distributed noises to the discontinuations of all possible locations of the feature vector $X_i$ and to its label $Y_i$. Again, tight upper bounds on the rate of convergence of the classification error probability are derived, without the strong density assumption, such that this rate depends on $2\\,d_a$.\n    ",
        "primary_category": "stat.ML",
        "categories": [
            "cs.CR",
            "cs.LG",
            "math.ST"
        ],
        "submitted_date": "22 Dec 2023",
        "last_revised_date": " "
    },
    "2312.14949": {
        "title": "LLM Interactive Optimization of Open Source Python Libraries -- Case Studies and Generalization",
        "authors": [
            "Andreas Florath"
        ],
        "comments": "20 pages, 10 figures",
        "subjects": "Software Engineering (cs.SE)",
        "abstract": "With the advent of large language models (LLMs) like GPT-3, a natural question is the extent to which these models can be utilized for source code optimization. This paper presents methodologically stringent case studies applied to well-known open source python libraries pillow and numpy. We find that contemporary LLM ChatGPT-4 (state September and October 2023) is surprisingly adept at optimizing energy and compute efficiency. However, this is only the case in interactive use, with a human expert in the loop. Aware of experimenter bias, we document our qualitative approach in detail, and provide transcript and source code. We start by providing a detailed description of our approach in conversing with the LLM to optimize the _getextrema function in the pillow library, and a quantitative evaluation of the performance improvement. To demonstrate qualitative replicability, we report further attempts on another locus in the pillow library, and one code locus in the numpy library, to demonstrate generalization within and beyond a library. In all attempts, the performance improvement is significant (factor up to 38). We have also not omitted reporting of failed attempts (there were none). We conclude that LLMs are a promising tool for code optimization in open source libraries, but that the human expert in the loop is essential for success. Nonetheless, we were surprised by how few iterations were required to achieve substantial performance improvements that were not obvious to the expert in the loop. We would like bring attention to the qualitative nature of this study, more robust quantitative studies would need to introduce a layer of selecting experts in a representative sample -- we invite the community to collaborate.\n    ",
        "primary_category": "cs.SE",
        "categories": [
            "cs.AI",
            "cs.HC",
            "cs.PF"
        ],
        "submitted_date": "8 Dec 2023",
        "last_revised_date": " "
    },
    "2312.15068": {
        "title": "Refining GPT-3 Embeddings with a Siamese Structure for Technical Post Duplicate Detection",
        "authors": [
            "Xingfang Wu",
            "Heng Li",
            "Nobukazu Yoshioka",
            "Hironori Washizaki",
            "Foutse Khomh"
        ],
        "comments": "SANER 2024",
        "subjects": "Software Engineering (cs.SE)",
        "abstract": "One goal of technical online communities is to help developers find the right answer in one place. A single question can be asked in different ways with different wordings, leading to the existence of duplicate posts on technical forums. The question of how to discover and link duplicate posts has garnered the attention of both developer communities and researchers. For example, Stack Overflow adopts a voting-based mechanism to mark and close duplicate posts. However, addressing these constantly emerging duplicate posts in a timely manner continues to pose challenges. Therefore, various approaches have been proposed to detect duplicate posts on technical forum posts automatically. The existing methods suffer from limitations either due to their reliance on handcrafted similarity metrics which can not sufficiently capture the semantics of posts, or their lack of supervision to improve the performance. Additionally, the efficiency of these methods is hindered by their dependence on pair-wise feature generation, which can be impractical for large amount of data. In this work, we attempt to employ and refine the GPT-3 embeddings for the duplicate detection task. We assume that the GPT-3 embeddings can accurately represent the semantics of the posts. In addition, by training a Siamese-based network based on the GPT-3 embeddings, we obtain a latent embedding that accurately captures the duplicate relation in technical forum posts. Our experiment on a benchmark dataset confirms the effectiveness of our approach and demonstrates superior performance compared to baseline methods. When applied to the dataset we constructed with a recent Stack Overflow dump, our approach attains a Top-1, Top-5, and Top-30 accuracy of 23.1%, 43.9%, and 68.9%, respectively. With a manual study, we confirm our approach's potential of finding unlabelled duplicates on technical forums.\n    ",
        "primary_category": "cs.SE",
        "categories": [
            "cs.CL",
            "cs.LG"
        ],
        "submitted_date": "22 Dec 2023",
        "last_revised_date": " "
    },
    "2312.15215": {
        "title": "Conceptualising an Anti-Digital Forensics Kill Chain for Smart Homes",
        "authors": [
            "Mario Raciti"
        ],
        "comments": "Accepted in 10th International Conference on Information Systems Security and Privacy (ICISSP 2024)",
        "subjects": "Cryptography and Security (cs.CR)",
        "abstract": "The widespread integration of Internet of Things (IoT) devices in households generates extensive digital footprints, notably within Smart Home ecosystems. These IoT devices, brimming with data about residents, inadvertently offer insights into human activities, potentially embodying even criminal acts, such as a murder. As technology advances, so does the concern for criminals seeking to exploit various techniques to conceal evidence and evade investigations. This paper delineates the application of Anti-Digital Forensics (ADF) in Smart Home scenarios and recognises its potential to disrupt (digital) investigations. It does so by elucidating the current challenges and gaps and by arguing, in response, the conceptualisation of an ADF Kill Chain tailored to Smart Home ecosystems. While seemingly arming criminals, the Kill Chain will allow a better understanding of the distinctive peculiarities of Anti-Digital Forensics in Smart Home scenario. This understanding is essential for fortifying the Digital Forensics process and, in turn, developing robust countermeasures against malicious activities.\n    ",
        "primary_category": "cs.CR",
        "categories": [],
        "submitted_date": "23 Dec 2023",
        "last_revised_date": " "
    },
    "2312.15285": {
        "title": "Pseudorandom and Pseudoentangled States from Subset States",
        "authors": [
            "Fernando Granha Jeronimo",
            "Nir Magrafta",
            "Pei Wu"
        ],
        "comments": "9 pages; add a minimum background on pseudoentanglement",
        "subjects": "Quantum Physics (quant-ph)",
        "abstract": "Pseudorandom states (PRS) are an important primitive in quantum cryptography. In this paper, we show that subset states can be used to construct PRSs. A subset state with respect to $S$, a subset of the computational basis, is \\[\n\\frac{1}{\\sqrt{|S|}}\\sum_{i\\in S} |i\\rangle. \\] As a technical centerpiece, we show that for any fixed subset size $|S|=s$ such that $s = 2^n/\\omega(\\mathrm{poly}(n))$ and $s=\\omega(\\mathrm{poly}(n))$, where $n$ is the number of qubits, a random subset state is information-theoretically indistinguishable from a Haar random state even provided with polynomially many copies. This range of parameter is tight. Our work resolves a conjecture by Ji, Liu and Song. Since subset states of small size have small entanglement across all cuts, this construction also illustrates a pseudoentanglement phenomenon.\n    ",
        "primary_category": "quant-ph",
        "categories": [
            "cs.CC",
            "cs.CR"
        ],
        "submitted_date": "23 Dec 2023",
        "last_revised_date": " "
    },
    "2312.15308": {
        "title": "The hull variation problem for projective Reed-Muller codes and quantum error-correcting codes",
        "authors": [
            "Diego Ruano",
            "Rodrigo San-Jos\u00e9"
        ],
        "comments": " ",
        "subjects": "Information Theory (cs.IT)",
        "abstract": "Long quantum codes using projective Reed-Muller codes are constructed. Projective Reed-Muller are evaluation codes obtained by evaluating homogeneous polynomials at the projective space. We obtain asymmetric and symmetric quantum codes by using the CSS construction and the Hermitian construction, respectively. We provide entanglement-assisted quantum error-correcting codes from projective Reed-Muller codes with flexible amounts of entanglement by considering equivalent codes. Moreover, we also construct quantum codes from subfield subcodes of projective Reed-Muller codes.\n    ",
        "primary_category": "cs.IT",
        "categories": [],
        "submitted_date": "23 Dec 2023",
        "last_revised_date": " "
    },
    "2312.15954": {
        "title": "On two-dimensional minimal linear codes over the rings $\\mathbb{Z}_{p^n}$",
        "authors": [
            "Biplab Chatterjee",
            "Ratnesh Kumar Mishra"
        ],
        "comments": " ",
        "subjects": "Information Theory (cs.IT)",
        "abstract": "In this paper we study two dimensional minimal linear code over the ring $\\mathbb{Z}_{p^n}$(where $p$ is prime). We show that if the generator matrix $G$ of the two dimensional linear code $M$ contains $p^n+p^{n-1}$ column vector of the following type {\\scriptsize{$u_{l_1}\\begin{pmatrix} 1\\\\ 0 \\end{pmatrix}$, $u_{l_2}\\begin{pmatrix} 0\\\\1 \\end{pmatrix}$, $u_{l_3}\\begin{pmatrix} 1\\\\u_1 \\end{pmatrix}$, $u_{l_4}\\begin{pmatrix} 1\\\\u_2 \\end{pmatrix}$,...,$u_{l_{p^n-p^{n-1}+2}} \\begin{pmatrix} 1\\\\u_{p^n-p^{n-1}} \\end{pmatrix}$, $u_{l_{p^n-p^{n-1}+3}}\\begin{pmatrix} d_1 \\\\ 1 \\end{pmatrix}$, $u_{l_{p^n-p^{n-1}+4}}\\begin{pmatrix} d_2\\\\ 1 \\end{pmatrix}$,..., $u_{l_{p^n+1}}\\begin{pmatrix} d_{p^{n-1}-1}\\\\1 \\end{pmatrix}$, $u_{l_{p^n+2}}\\begin{pmatrix} 1\\\\d_1 \\end{pmatrix}$, $u_{l_{p^n+3}}\\begin{pmatrix} 1\\\\d_2 \\end{pmatrix}$,...,$u_{l_{p^n+p^{n-1}}}\\begin{pmatrix} 1 \\\\d_{p^{n-1}-1} \\end{pmatrix}$}}, where $u_i$ and $d_j$ are distinct units and zero divisors respectively in the ring $\\mathbb{Z}_{p^n}$ for $1\\leq i \\leq p^n+p^{n-1}$, $1\\leq j \\leq p^{n-1}-1$ and additionally, denote $u_{l_i}$ as units in $\\mathbb{Z}_{p^n}$, then the module generated by $G$ is a minimal linear code. Also we show that if any one column vector of the above types are not present entirely in $G$, then the generated module is not a minimal linear code.\n    ",
        "primary_category": "cs.IT",
        "categories": [
            "math.AC"
        ],
        "submitted_date": "26 Dec 2023",
        "last_revised_date": " "
    },
    "2312.16475": {
        "title": "Federated Continual Learning via Knowledge Fusion: A Survey",
        "authors": [
            "Xin Yang",
            "Hao Yu",
            "Xin Gao",
            "Hao Wang",
            "Junbo Zhang",
            "Tianrui Li"
        ],
        "comments": "20 pages",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Data privacy and silos are nontrivial and greatly challenging in many real-world applications. Federated learning is a decentralized approach to training models across multiple local clients without the exchange of raw data from client devices to global servers. However, existing works focus on a static data environment and ignore continual learning from streaming data with incremental tasks. Federated Continual Learning (FCL) is an emerging paradigm to address model learning in both federated and continual learning environments. The key objective of FCL is to fuse heterogeneous knowledge from different clients and retain knowledge of previous tasks while learning on new ones. In this work, we delineate federated learning and continual learning first and then discuss their integration, i.e., FCL, and particular FCL via knowledge fusion. In summary, our motivations are four-fold: we (1) raise a fundamental problem called ''spatial-temporal catastrophic forgetting'' and evaluate its impact on the performance using a well-known method called federated averaging (FedAvg), (2) integrate most of the existing FCL methods into two generic frameworks, namely synchronous FCL and asynchronous FCL, (3) categorize a large number of methods according to the mechanism involved in knowledge fusion, and finally (4) showcase an outlook on the future work of FCL.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "27 Dec 2023",
        "last_revised_date": " "
    },
    "2312.16624": {
        "title": "Dual-stage optimizer for systematic overestimation adjustment applied to multi-objective genetic algorithms for biomarker selection",
        "authors": [
            "Luca Cattelani",
            "Vittorio Fortino"
        ],
        "comments": "Added link to source code repository",
        "subjects": "Quantitative Methods (q-bio.QM)",
        "abstract": "The challenge in biomarker discovery using machine learning from omics data lies in the abundance of molecular features but scarcity of samples. Most feature selection methods in machine learning require evaluating various sets of features (models) to determine the most effective combination. This process, typically conducted using a validation dataset, involves testing different feature sets to optimize the model's performance. Evaluations have performance estimation error and when the selection involves many models the best ones are almost certainly overestimated. Biomarker identification with feature selection methods can be addressed as a multi-objective problem with trade-offs between predictive ability and parsimony in the number of features. Genetic algorithms are a popular tool for multi-objective optimization but they evolve numerous solutions thus are prone to overestimation. Methods have been proposed to reduce the overestimation after a model has already been selected in single-objective problems, but no algorithm existed capable of reducing the overestimation during the optimization, improving model selection, or applied in the more general multi-objective domain. We propose DOSA-MO, a novel multi-objective optimization wrapper algorithm that learns how the original estimation, its variance, and the feature set size of the solutions predict the overestimation. DOSA-MO adjusts the expectation of the performance during the optimization, improving the composition of the solution set. We verify that DOSA-MO improves the performance of a state-of-the-art genetic algorithm on left-out or external sample sets, when predicting cancer subtypes and/or patient overall survival, using three transcriptomics datasets for kidney and breast cancer.\n    ",
        "primary_category": "q-bio.QM",
        "categories": [
            "cs.LG"
        ],
        "submitted_date": "27 Dec 2023",
        "last_revised_date": " "
    },
    "2312.16731": {
        "title": "Infinite dSprites for Disentangled Continual Learning: Separating Memory Edits from Generalization",
        "authors": [
            "Sebastian Dziadzio",
            "\u00c7a\u011fatay Y\u0131ld\u0131z",
            "Gido M. van de Ven",
            "Tomasz Trzci\u0144ski",
            "Tinne Tuytelaars",
            "Matthias Bethge"
        ],
        "comments": "10 pages, 10 figures",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "The ability of machine learning systems to learn continually is hindered by catastrophic forgetting, the tendency of neural networks to overwrite existing knowledge when learning a new task. Continual learning methods alleviate this problem through regularization, parameter isolation, or rehearsal, but they are typically evaluated on benchmarks comprising only a handful of tasks. In contrast, humans are able to learn continually in dynamic, open-world environments, effortlessly achieving one-shot memorization of unfamiliar objects and reliably recognizing them under various transformations. To make progress towards closing this gap, we introduce Infinite dSprites, a parsimonious tool for creating continual classification and disentanglement benchmarks of arbitrary length and with full control over generative factors. We show that over a sufficiently long time horizon, the performance of all major types of continual learning methods deteriorates on this simple benchmark. Thus, Infinite dSprites highlights an important aspect of continual learning that has not received enough attention so far: given a finite modelling capacity and an arbitrarily long learning horizon, efficient learning requires memorizing class-specific information and accumulating knowledge about general mechanisms. In a simple setting with direct supervision on the generative factors, we show how learning class-agnostic transformations offers a way to circumvent catastrophic forgetting and improve classification accuracy over time. Our approach sets the stage for continual learning over hundreds of tasks with explicit control over memorization and forgetting, emphasizing open-set classification and one-shot generalization.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.CV"
        ],
        "submitted_date": "27 Dec 2023",
        "last_revised_date": " "
    },
    "2312.17242": {
        "title": "Learning to Generate Text in Arbitrary Writing Styles",
        "authors": [
            "Aleem Khan",
            "Andrew Wang",
            "Sophia Hager",
            "Nicholas Andrews"
        ],
        "comments": " ",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "Prior work in style-controlled text generation has focused on tasks such as emulating the style of prolific literary authors, producing formal or informal text, and mitigating toxicity of generated text. Plentiful demonstrations of these styles are available, and as a result modern language models are often able to emulate them, either via prompting or discriminative control. However, in applications such as writing assistants, it is desirable for language models to produce text in an author-specific style on the basis of a potentially small writing sample. For example, someone writing in a particular dialect may prefer writing suggestions that retain the same dialect. We find that instruction-tuned language models can struggle to reproduce author-specific style demonstrated in a prompt. Instead, we propose to guide a language model to generate text in a target style using contrastively-trained representations that capture stylometric features. Our approach (StyleMC) combines an author-adapted language model with sequence-level inference to improve stylistic consistency, and is found to be effective in a variety of conditions, including unconditional generation and style transfer. Additionally, we find that the proposed approach can serve as an effective anonymization method, by editing a document to mask authorship while preserving the original meaning\n    ",
        "primary_category": "cs.CL",
        "categories": [],
        "submitted_date": "28 Dec 2023",
        "last_revised_date": " "
    },
    "2401.00037": {
        "title": "Messenger RNA Design via Expected Partition Function and Continuous Optimization",
        "authors": [
            "Ning Dai",
            "Wei Yu Tang",
            "Tianshuo Zhou",
            "David H. Mathews",
            "Liang Huang"
        ],
        "comments": " ",
        "subjects": "Biomolecules (q-bio.BM)",
        "abstract": "The tasks of designing RNAs are discrete optimization problems, and several versions of these problems are NP-hard. As an alternative to commonly used local search methods, we formulate these problems as continuous optimization and develop a general framework for this optimization based on a generalization of classical partition function which we call \"expected partition function\". The basic idea is to start with a distribution over all possible candidate sequences, and extend the objective function from a sequence to a distribution. We then use gradient descent-based optimization methods to improve the extended objective function, and the distribution will gradually shrink towards a one-hot sequence (i.e., a single sequence). As a case study, we consider the important problem of mRNA design with wide applications in vaccines and therapeutics. While the recent work of LinearDesign can efficiently optimize mRNAs for minimum free energy (MFE), optimizing for ensemble free energy is much harder and likely intractable. Our approach can consistently improve over the LinearDesign solution in terms of ensemble free energy, with bigger improvements on longer sequences.\n    ",
        "primary_category": "q-bio.BM",
        "categories": [
            "cs.AI",
            "cs.LG"
        ],
        "submitted_date": "29 Dec 2023",
        "last_revised_date": " "
    },
    "2401.00283": {
        "title": "Near-Space Communications: the Last Piece of 6G Space-Air-Ground-Sea Integrated Network Puzzle",
        "authors": [
            "Hongshan Liu",
            "Tong Qin",
            "Zhen Gao",
            "Tianqi Mao",
            "Keke Ying",
            "Ziwei Wan",
            "Li Qiao",
            "Rui Na",
            "Zhongxiang Li",
            "Chun Hu",
            "Yikun Mei",
            "Tuan Li",
            "Guanghui Wen",
            "Lei Chen",
            "Zhonghuai Wu",
            "Ruiqi Liu",
            "Gaojie Chen",
            "Shuo Wang",
            "Dezhi Zheng"
        ],
        "comments": "28 pages, 8 figures, 2 tables",
        "subjects": "Information Theory (cs.IT)",
        "abstract": "This article presents a comprehensive study on the emerging near-space communications (NS-COM) within the context of space-air-ground-sea integrated network (SAGSIN). Specifically, we firstly explore the recent technical developments of NS-COM, followed by the discussions about motivations behind integrating NS-COM into SAGSIN. To further demonstrate the necessity of NS-COM, a comparative analysis between the NS-COM network and other counterparts in SAGSIN is conducted, covering aspects of deployment, coverage, channel characteristics and unique problems of NS-COM network. Afterwards, the technical aspects of NS-COM, including channel modeling, random access, channel estimation, array-based beam management and joint network optimization, are examined in detail. Furthermore, we explore the potential applications of NS-COM, such as structural expansion in SAGSIN communication, civil aviation communication, remote and urgent communication, weather monitoring and carbon neutrality. Finally, some promising research avenues are identified, including stratospheric satellite (StratoSat) -to-ground direct links for mobile terminals, reconfigurable multiple-input multiple-output (MIMO) and holographic MIMO, federated learning in NS-COM networks, maritime communication, electromagnetic spectrum sensing and adversarial game, integrated sensing and communications, StratoSat-based radar detection and imaging, NS-COM assisted enhanced global navigation system, NS-COM assisted intelligent unmanned system and free space optical (FSO) communication. Overall, this paper highlights that the NS-COM plays an indispensable role in the SAGSIN puzzle, providing substantial performance and coverage enhancement to the traditional SAGSIN architecture.\n    ",
        "primary_category": "cs.IT",
        "categories": [
            "eess.SP"
        ],
        "submitted_date": "30 Dec 2023",
        "last_revised_date": " "
    },
    "2401.00594": {
        "title": "Efficient Design for Multi-user Downlink Beamforming with Reconfigurable Intelligent Surface",
        "authors": [
            "Mohammad Ebrahimi",
            "Min Dong"
        ],
        "comments": "13 pages, 10 figures",
        "subjects": "Signal Processing (eess.SP)",
        "abstract": "This paper considers downlink multi-user transmission facilitated by a reconfigurable intelligent surface (RIS). First, focusing on the multi-group multicast beamforming scenario, we develop a fast and scalable algorithm for the joint base station (BS) and RIS beamforming optimization to minimize the transmit power subject to the user quality-of-service (QoS) constraints. By exploring the structure of this QoS problem, we show that the joint beamforming optimization can be naturally decomposed into a BS multicast beamforming QoS problem and an RIS passive multicast beamforming max-min-fair (MMF) problem. We propose an alternating multicast beamforming (AMBF) algorithm to solve the two subproblems alternatingly. For the BS QoS subproblem, we utilize the optimal multicast beamforming structure to obtain the BS beamformers efficiently. Furthermore, we reformulate the challenging RIS MMF subproblem and employ a first-order projected subgradient algorithm (PSA), which yields closed-form updates. The computational complexity of the AMBF algorithm grows linearly with the number of RIS elements and BS antennas. We further show that the AMBF approach is also an efficient method for the RIS-assisted downlink multi-user unicast beamforming problem, providing semi-closed-form updates. Next, we study the MMF problem for the RIS-assisted downlink beamforming design and propose a PSA-based fast algorithm to compute the BS and RIS beamforming solutions with closed-form updates per iteration, leading to a highly computationally efficient solution. Simulation results show the efficacy of our proposed algorithms in both performance and computational cost compared to other alternative methods.\n    ",
        "primary_category": "eess.SP",
        "categories": [
            "cs.IT"
        ],
        "submitted_date": "31 Dec 2023",
        "last_revised_date": " "
    },
    "2401.00873": {
        "title": "A Bayesian Unification of Self-Supervised Clustering and Energy-Based Models",
        "authors": [
            "Emanuele Sansone",
            "Robin Manhaeve"
        ],
        "comments": "Changes from previous version: added mean and standard deviations in experiments. Integral version of workshop paper arXiv:2309.15420. Improved GEDI version (from two stages to single stage training) arXiv:2212.13425",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Self-supervised learning is a popular and powerful method for utilizing large amounts of unlabeled data, for which a wide variety of training objectives have been proposed in the literature. In this study, we perform a Bayesian analysis of state-of-the-art self-supervised learning objectives, elucidating the underlying probabilistic graphical models in each class and presenting a standardized methodology for their derivation from first principles. The analysis also indicates a natural means of integrating self-supervised learning with likelihood-based generative models. We instantiate this concept within the realm of cluster-based self-supervised learning and energy models, introducing a novel lower bound which is proven to reliably penalize the most important failure modes. Furthermore, this newly proposed lower bound enables the training of a standard backbone architecture without the necessity for asymmetric elements such as stop gradients, momentum encoders, or specialized clustering layers - typically introduced to avoid learning trivial solutions. Our theoretical findings are substantiated through experiments on synthetic and real-world data, including SVHN, CIFAR10, and CIFAR100, thus showing that our objective function allows to outperform existing self-supervised learning strategies in terms of clustering, generation and out-of-distribution detection performance by a wide margin. We also demonstrate that GEDI can be integrated into a neuro-symbolic framework to mitigate the reasoning shortcut problem and to learn higher quality symbolic representations thanks to the enhanced classification performance.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.CV"
        ],
        "submitted_date": "30 Dec 2023",
        "last_revised_date": " "
    },
    "2401.01387": {
        "title": "DiffAugment: Diffusion based Long-Tailed Visual Relationship Recognition",
        "authors": [
            "Parul Gupta",
            "Tuan Nguyen",
            "Abhinav Dhall",
            "Munawar Hayat",
            "Trung Le",
            "Thanh-Toan Do"
        ],
        "comments": " ",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "The task of Visual Relationship Recognition (VRR) aims to identify relationships between two interacting objects in an image and is particularly challenging due to the widely-spread and highly imbalanced distribution of <subject, relation, object> triplets. To overcome the resultant performance bias in existing VRR approaches, we introduce DiffAugment -- a method which first augments the tail classes in the linguistic space by making use of WordNet and then utilizes the generative prowess of Diffusion Models to expand the visual space for minority classes. We propose a novel hardness-aware component in diffusion which is based upon the hardness of each <S,R,O> triplet and demonstrate the effectiveness of hardness-aware diffusion in generating visual embeddings for the tail classes. We also propose a novel subject and object based seeding strategy for diffusion sampling which improves the discriminative capability of the generated visual embeddings. Extensive experimentation on the GQA-LT dataset shows favorable gains in the subject/object and relation average per-class accuracy using Diffusion augmented samples.\n    ",
        "primary_category": "cs.CV",
        "categories": [],
        "submitted_date": "1 Jan 2024",
        "last_revised_date": " "
    },
    "2401.01523": {
        "title": "GOAT-Bench: Safety Insights to Large Multimodal Models through Meme-Based Social Abuse",
        "authors": [
            "Hongzhan Lin",
            "Ziyang Luo",
            "Bo Wang",
            "Ruichao Yang",
            "Jing Ma"
        ],
        "comments": "The first work to benchmark Large Multimodal Models in safety insight on social media",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "The exponential growth of social media has profoundly transformed how information is created, disseminated, and absorbed, exceeding any precedent in the digital age. Regrettably, this explosion has also spawned a significant increase in the online abuse of memes. Evaluating the negative impact of memes is notably challenging, owing to their often subtle and implicit meanings, which are not directly conveyed through the overt text and imagery. In light of this, large multimodal models (LMMs) have emerged as a focal point of interest due to their remarkable capabilities in handling diverse multimodal tasks. In response to this development, our paper aims to thoroughly examine the capacity of various LMMs (e.g., GPT-4V) to discern and respond to the nuanced aspects of social abuse manifested in memes. We introduce the comprehensive meme benchmark, GOAT-Bench, comprising over 6K varied memes encapsulating themes such as implicit hate speech, sexism, and cyberbullying, etc. Utilizing GOAT-Bench, we delve into the ability of LMMs to accurately assess hatefulness, misogyny, offensiveness, sarcasm, and harmful content. Our extensive experiments across a range of LMMs reveal that current models still exhibit a deficiency in safety awareness, showing insensitivity to various forms of implicit abuse. We posit that this shortfall represents a critical impediment to the realization of safe artificial intelligence. The GOAT-Bench and accompanying resources are publicly accessible at this https URL, contributing to ongoing research in this vital field.\n    ",
        "primary_category": "cs.CL",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "3 Jan 2024",
        "last_revised_date": " "
    },
    "2401.01749": {
        "title": "Few-shot Image Generation via Information Transfer from the Built Geodesic Surface",
        "authors": [
            "Yuexing Han",
            "Liheng Ruan",
            "Bing Wang"
        ],
        "comments": " ",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Images generated by most of generative models trained with limited data often exhibit deficiencies in either fidelity, diversity, or both. One effective solution to address the limitation is few-shot generative model adaption. However, the type of approaches typically rely on a large-scale pre-trained model, serving as a source domain, to facilitate information transfer to the target domain. In this paper, we propose a method called Information Transfer from the Built Geodesic Surface (ITBGS), which contains two module: Feature Augmentation on Geodesic Surface (FAGS); Interpolation and Regularization (I\\&R). With the FAGS module, a pseudo-source domain is created by projecting image features from the training dataset into the Pre-Shape Space, subsequently generating new features on the Geodesic surface. Thus, no pre-trained models is needed for the adaption process during the training of generative models with FAGS. I\\&R module are introduced for supervising the interpolated images and regularizing their relative distances, respectively, to further enhance the quality of generated images. Through qualitative and quantitative experiments, we demonstrate that the proposed method consistently achieves optimal or comparable results across a diverse range of semantically distinct datasets, even in extremely few-shot scenarios.\n    ",
        "primary_category": "cs.CV",
        "categories": [],
        "submitted_date": "3 Jan 2024",
        "last_revised_date": " "
    },
    "2401.01846": {
        "title": "DGDNN: Decoupled Graph Diffusion Neural Network for Stock Movement Prediction",
        "authors": [
            "Zinuo You",
            "Zijian Shi",
            "Hongbo Bo",
            "John Cartlidge",
            "Li Zhang",
            "Yan Ge"
        ],
        "comments": "12 pages, 5 figures, author manuscript accepted for ICAART 2024 (International Conference on Agents and Artificial Intelligence)",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Forecasting future stock trends remains challenging for academia and industry due to stochastic inter-stock dynamics and hierarchical intra-stock dynamics influencing stock prices. In recent years, graph neural networks have achieved remarkable performance in this problem by formulating multiple stocks as graph-structured data. However, most of these approaches rely on artificially defined factors to construct static stock graphs, which fail to capture the intrinsic interdependencies between stocks that rapidly evolve. In addition, these methods often ignore the hierarchical features of the stocks and lose distinctive information within. In this work, we propose a novel graph learning approach implemented without expert knowledge to address these issues. First, our approach automatically constructs dynamic stock graphs by entropy-driven edge generation from a signal processing perspective. Then, we further learn task-optimal dependencies between stocks via a generalized graph diffusion process on constructed stock graphs. Last, a decoupled representation learning scheme is adopted to capture distinctive hierarchical intra-stock features. Experimental results demonstrate substantial improvements over state-of-the-art baselines on real-world datasets. Moreover, the ablation study and sensitivity study further illustrate the effectiveness of the proposed method in modeling the time-evolving inter-stock and intra-stock dynamics.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.NE"
        ],
        "submitted_date": "3 Jan 2024",
        "last_revised_date": " "
    },
    "2401.02116": {
        "title": "Starling: An I/O-Efficient Disk-Resident Graph Index Framework for High-Dimensional Vector Similarity Search on Data Segment",
        "authors": [
            "Mengzhao Wang",
            "Weizhi Xu",
            "Xiaomeng Yi",
            "Songlin Wu",
            "Zhangyang Peng",
            "Xiangyu Ke",
            "Yunjun Gao",
            "Xiaoliang Xu",
            "Rentong Guo",
            "Charles Xie"
        ],
        "comments": "This paper has been accepted by SIGMOD 2024",
        "subjects": "Databases (cs.DB)",
        "abstract": "High-dimensional vector similarity search (HVSS) is gaining prominence as a powerful tool for various data science and AI applications. As vector data scales up, in-memory indexes pose a significant challenge due to the substantial increase in main memory requirements. A potential solution involves leveraging disk-based implementation, which stores and searches vector data on high-performance devices like NVMe SSDs. However, implementing HVSS for data segments proves to be intricate in vector databases where a single machine comprises multiple segments for system scalability. In this context, each segment operates with limited memory and disk space, necessitating a delicate balance between accuracy, efficiency, and space cost. Existing disk-based methods fall short as they do not holistically address all these requirements simultaneously. In this paper, we present Starling, an I/O-efficient disk-resident graph index framework that optimizes data layout and search strategy within the segment. It has two primary components: (1) a data layout incorporating an in-memory navigation graph and a reordered disk-based graph with enhanced locality, reducing the search path length and minimizing disk bandwidth wastage; and (2) a block search strategy designed to minimize costly disk I/O operations during vector query execution. Through extensive experiments, we validate the effectiveness, efficiency, and scalability of Starling. On a data segment with 2GB memory and 10GB disk capacity, Starling can accommodate up to 33 million vectors in 128 dimensions, offering HVSS with over 0.9 average precision and top-10 recall rate, and latency under 1 millisecond. The results showcase Starling's superior performance, exhibiting 43.9$\\times$ higher throughput with 98% lower query latency compared to state-of-the-art methods while maintaining the same level of accuracy.\n    ",
        "primary_category": "cs.DB",
        "categories": [
            "cs.IR"
        ],
        "submitted_date": "4 Jan 2024",
        "last_revised_date": " "
    },
    "2401.02597": {
        "title": "Boosting Spectral Efficiency with Data-Carrying Reference Signals on the Grassmann Manifold",
        "authors": [
            "Naoki Endo",
            "Hiroki Iimori",
            "Chandan Pradhan",
            "Szabolcs Malomsoky",
            "Naoki Ishikawa"
        ],
        "comments": "13 pages, 10 figures",
        "subjects": "Signal Processing (eess.SP)",
        "abstract": "In wireless networks, frequent reference signal transmission for accurate channel reconstruction may reduce spectral efficiency. To address this issue, we consider to use a data-carrying reference signal (DC-RS) that can simultaneously estimate channel coefficients and transmit data symbols. Here, symbols on the Grassmann manifold are exploited to carry additional data and to assist in channel estimation. Unlike conventional studies, we analyze the channel estimation errors induced by DC-RS and propose an optimization method that improves the channel estimation accuracy without performance penalty. Then, we derive the achievable rate of noncoherent Grassmann constellation assuming discrete inputs in multi-antenna scenarios, as well as that of coherent signaling assuming channel estimation errors modeled by the Gauss-Markov uncertainty. These derivations enable performance evaluation when introducing DC-RS, and suggest excellent potential for boosting spectral efficiency, where interesting crossings with the non-data carrying RS occurred at intermediate signal-to-noise ratios.\n    ",
        "primary_category": "eess.SP",
        "categories": [
            "cs.IT"
        ],
        "submitted_date": "5 Jan 2024",
        "last_revised_date": " "
    },
    "2401.02982": {
        "title": "BIBench: Benchmarking Data Analysis Knowledge of Large Language Models",
        "authors": [
            "Shu Liu",
            "Shangqing Zhao",
            "Chenghao Jia",
            "Xinlin Zhuang",
            "Zhaoguang Long",
            "Qingquan Wu",
            "Chong Yang",
            "Aimin Zhou",
            "Man Lan"
        ],
        "comments": " ",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "Large Language Models (LLMs) have demonstrated impressive capabilities across a wide range of tasks. However, their proficiency and reliability in the specialized domain of Data Analysis, particularly with a focus on data-driven thinking, remain uncertain. To bridge this gap, we introduce BIBench, a comprehensive benchmark designed to evaluate the data analysis capabilities of LLMs within the context of Business Intelligence (BI). BIBench assesses LLMs across three dimensions: 1) BI foundational knowledge, evaluating the models' numerical reasoning and familiarity with financial concepts; 2) BI knowledge application, determining the models' ability to quickly comprehend textual information and generate analysis questions from multiple views; and 3) BI technical skills, examining the models' use of technical knowledge to address real-world data analysis challenges. BIBench comprises 11 sub-tasks, spanning three categories of task types: classification, extraction, and generation. Additionally, we've developed BIChat, a domain-specific dataset with over a million data points, to fine-tune LLMs. We will release BIBenchmark, BIChat, and the evaluation scripts at \\url{this https URL}. This benchmark aims to provide a measure for in-depth analysis of LLM abilities and foster the advancement of LLMs in the field of data analysis.\n    ",
        "primary_category": "cs.CL",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "1 Jan 2024",
        "last_revised_date": " "
    },
    "2401.03790": {
        "title": "Inferring Properties of Graph Neural Networks",
        "authors": [
            "Dat Nguyen",
            "Hieu M. Vu",
            "Cong-Thanh Le",
            "Bach Le",
            "David Lo",
            "ThanhVu Nguyen",
            "Corina Pasareanu"
        ],
        "comments": "20 pages main paper, 10 pages for appendix",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "We propose GNNInfer, the first automatic property inference technique for GNNs. To tackle the challenge of varying input structures in GNNs, GNNInfer first identifies a set of representative influential structures that contribute significantly towards the prediction of a GNN. Using these structures, GNNInfer converts each pair of an influential structure and the GNN to their equivalent FNN and then leverages existing property inference techniques to effectively capture properties of the GNN that are specific to the influential structures. GNNINfer then generalizes the captured properties to any input graphs that contain the influential structures. Finally, GNNInfer improves the correctness of the inferred properties by building a model (either a decision tree or linear regression) that estimates the deviation of GNN output from the inferred properties given full input graphs. The learned model helps GNNInfer extend the inferred properties with constraints to the input and output of the GNN, obtaining stronger properties that hold on full input graphs.\nOur experiments show that GNNInfer is effective in inferring likely properties of popular real-world GNNs, and more importantly, these inferred properties help effectively defend against GNNs' backdoor attacks. In particular, out of the 13 ground truth properties, GNNInfer re-discovered 8 correct properties and discovered likely correct properties that approximate the remaining 5 ground truth properties. Using properties inferred by GNNInfer to defend against the state-of-the-art backdoor attack technique on GNNs, namely UGBA, experiments show that GNNInfer's defense success rate is up to 30 times better than existing baselines.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.CR",
            "cs.PL",
            "cs.SE"
        ],
        "submitted_date": "8 Jan 2024",
        "last_revised_date": " "
    },
    "2401.04190": {
        "title": "Is it possible to know cosmological fine-tuning?",
        "authors": [
            "Daniel Andr\u00e9s D\u00edaz-Pach\u00f3n",
            "Ola H\u00f6ssjer",
            "Calvin Mathew"
        ],
        "comments": "Accepted version. Minor changes: a sentence removed at the end of Section 5.2, and more comprehensive keywords",
        "subjects": "Cosmology and Nongalactic Astrophysics (astro-ph.CO)",
        "abstract": "Fine-tuning studies whether some physical parameters, or relevant ratios between them, are located within so-called life-permitting intervals of small probability outside of which carbon-based life would not be possible. Recent developments have found estimates of these probabilities that circumvent previous concerns of measurability and selection bias. However, the question remains if fine-tuning can indeed be known. Using a mathematization of the epistemological concepts of learning and knowledge acquisition, we argue that most examples that have been touted as fine-tuned cannot be formally assessed as such. Nevertheless, fine-tuning can be known when the physical parameter is seen as a random variable and it is supported in the nonnegative real line, provided the size of the life-permitting interval is small in relation to the observed value of the parameter.\n    ",
        "primary_category": "astro-ph.CO",
        "categories": [
            "cs.IT",
            "stat.ME"
        ],
        "submitted_date": "8 Jan 2024",
        "last_revised_date": " "
    },
    "2401.04331": {
        "title": "Coupling Graph Neural Networks with Fractional Order Continuous Dynamics: A Robustness Study",
        "authors": [
            "Qiyu Kang",
            "Kai Zhao",
            "Yang Song",
            "Yihang Xie",
            "Yanan Zhao",
            "Sijie Wang",
            "Rui She",
            "Wee Peng Tay"
        ],
        "comments": "in Proc. AAAI Conference on Artificial Intelligence, Vancouver, Canada, Feb. 2024",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "In this work, we rigorously investigate the robustness of graph neural fractional-order differential equation (FDE) models. This framework extends beyond traditional graph neural (integer-order) ordinary differential equation (ODE) models by implementing the time-fractional Caputo derivative. Utilizing fractional calculus allows our model to consider long-term memory during the feature updating process, diverging from the memoryless Markovian updates seen in traditional graph neural ODE models. The superiority of graph neural FDE models over graph neural ODE models has been established in environments free from attacks or perturbations. While traditional graph neural ODE models have been verified to possess a degree of stability and resilience in the presence of adversarial attacks in existing literature, the robustness of graph neural FDE models, especially under adversarial conditions, remains largely unexplored. This paper undertakes a detailed assessment of the robustness of graph neural FDE models. We establish a theoretical foundation outlining the robustness characteristics of graph neural FDE models, highlighting that they maintain more stringent output perturbation bounds in the face of input and graph topology disturbances, compared to their integer-order counterparts. Our empirical evaluations further confirm the enhanced robustness of graph neural FDE models, highlighting their potential in adversarially robust applications.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "9 Jan 2024",
        "last_revised_date": " "
    },
    "2401.04837": {
        "title": "T-PRIME: Transformer-based Protocol Identification for Machine-learning at the Edge",
        "authors": [
            "Mauro Belgiovine",
            "Joshua Groen",
            "Miquel Sirera",
            "Chinenye Tassie",
            "Ayberk Yark\u0131n Y\u0131ld\u0131z",
            "Sage Trudeau",
            "Stratis Ioannidis",
            "Kaushik Chowdhury"
        ],
        "comments": "This is the extended version of the IEEE INFOCOM 2024 paper with the same title",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Spectrum sharing allows different protocols of the same standard (e.g., 802.11 family) or different standards (e.g., LTE and DVB) to coexist in overlapping frequency bands. As this paradigm continues to spread, wireless systems must also evolve to identify active transmitters and unauthorized waveforms in real time under intentional distortion of preambles, extremely low signal-to-noise ratios and challenging channel conditions. We overcome limitations of correlation-based preamble matching methods in such conditions through the design of T-PRIME: a Transformer-based machine learning approach. T-PRIME learns the structural design of transmitted frames through its attention mechanism, looking at sequence patterns that go beyond the preamble alone. The paper makes three contributions: First, it compares Transformer models and demonstrates their superiority over traditional methods and state-of-the-art neural networks. Second, it rigorously analyzes T-PRIME's real-time feasibility on DeepWave's AIR-T platform. Third, it utilizes an extensive 66 GB dataset of over-the-air (OTA) WiFi transmissions for training, which is released along with the code for community use. Results reveal nearly perfect (i.e. $>98\\%$) classification accuracy under simulated scenarios, showing $100\\%$ detection improvement over legacy methods in low SNR ranges, $97\\%$ classification accuracy for OTA single-protocol transmissions and up to $75\\%$ double-protocol classification accuracy in interference scenarios.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.NI",
            "eess.SY"
        ],
        "submitted_date": "9 Jan 2024",
        "last_revised_date": " "
    },
    "2401.05531": {
        "title": "VI-PANN: Harnessing Transfer Learning and Uncertainty-Aware Variational Inference for Improved Generalization in Audio Pattern Recognition",
        "authors": [
            "John Fischer",
            "Marko Orescanin",
            "Eric Eckstrand"
        ],
        "comments": "Published in IEEE Access",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Transfer learning (TL) is an increasingly popular approach to training deep learning (DL) models that leverages the knowledge gained by training a foundation model on diverse, large-scale datasets for use on downstream tasks where less domain- or task-specific data is available. The literature is rich with TL techniques and applications; however, the bulk of the research makes use of deterministic DL models which are often uncalibrated and lack the ability to communicate a measure of epistemic (model) uncertainty in prediction. Unlike their deterministic counterparts, Bayesian DL (BDL) models are often well-calibrated, provide access to epistemic uncertainty for a prediction, and are capable of achieving competitive predictive performance. In this study, we propose variational inference pre-trained audio neural networks (VI-PANNs). VI-PANNs are a variational inference variant of the popular ResNet-54 architecture which are pre-trained on AudioSet, a large-scale audio event detection dataset. We evaluate the quality of the resulting uncertainty when transferring knowledge from VI-PANNs to other downstream acoustic classification tasks using the ESC-50, UrbanSound8K, and DCASE2013 datasets. We demonstrate, for the first time, that it is possible to transfer calibrated uncertainty information along with knowledge from upstream tasks to enhance a model's capability to perform downstream tasks.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.SD",
            "eess.AS"
        ],
        "submitted_date": "10 Jan 2024",
        "last_revised_date": " "
    },
    "2401.05603": {
        "title": "Personal Moderation Configurations on Facebook: Exploring the Role of FoMO, Social Media Addiction, Norms, and Platform Trust",
        "authors": [
            "Shagun Jhaver"
        ],
        "comments": " ",
        "subjects": "Human-Computer Interaction (cs.HC)",
        "abstract": "Personal moderation tools on social media platforms let users control their news feeds by configuring acceptable toxicity thresholds for their feed content or muting inappropriate accounts. This research examines how four critical psychosocial factors - fear of missing out (FoMO), social media addiction, subjective norms, and trust in moderation systems - shape Facebook users' configuration of these tools. Findings from a nationally representative sample of 1,061 participants show that FoMO and social media addiction make Facebook users more vulnerable to content-based harms by reducing their likelihood of adopting personal moderation tools to hide inappropriate posts. In contrast, descriptive and injunctive norms positively influence the use of these tools. Further, trust in Facebook's moderation systems also significantly affects users' engagement with personal moderation. This analysis highlights qualitatively different pathways through which FoMO and social media addiction make affected users disproportionately unsafe and offers design and policy solutions to address this challenge.\n    ",
        "primary_category": "cs.HC",
        "categories": [
            "cs.CY"
        ],
        "submitted_date": "11 Jan 2024",
        "last_revised_date": " "
    },
    "2401.05638": {
        "title": "MatSAM: Efficient Extraction of Microstructures of Materials via Visual Large Model",
        "authors": [
            "Changtai Li",
            "Xu Han",
            "Chao Yao",
            "Xiaojuan Ban"
        ],
        "comments": "18 pages, 8 figures, and 5 tables. Updated with revision and code repository",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Efficient and accurate extraction of microstructures in micrographs of materials is essential in process optimization and the exploration of structure-property relationships. Deep learning-based image segmentation techniques that rely on manual annotation are laborious and time-consuming and hardly meet the demand for model transferability and generalization on various source images. Segment Anything Model (SAM), a large visual model with powerful deep feature representation and zero-shot generalization capabilities, has provided new solutions for image segmentation. In this paper, we propose MatSAM, a general and efficient microstructure extraction solution based on SAM. A simple yet effective point-based prompt generation strategy is designed, grounded on the distribution and shape of microstructures. Specifically, in an unsupervised and training-free way, it adaptively generates prompt points for different microscopy images, fuses the centroid points of the coarsely extracted region of interest (ROI) and native grid points, and integrates corresponding post-processing operations for quantitative characterization of microstructures of materials. For common microstructures including grain boundary and multiple phases, MatSAM achieves superior zero-shot segmentation performance to conventional rule-based methods and is even preferable to supervised learning methods evaluated on 16 microscopy datasets whose micrographs are imaged by the optical microscope (OM) and scanning electron microscope (SEM). Especially, on 4 public datasets, MatSAM shows unexpected competitive segmentation performance against their specialist models. We believe that, without the need for human labeling, MatSAM can significantly reduce the cost of quantitative characterization and statistical analysis of extensive microstructures of materials, and thus accelerate the design of new materials.\n    ",
        "primary_category": "cs.CV",
        "categories": [],
        "submitted_date": "11 Jan 2024",
        "last_revised_date": " "
    },
    "2401.05744": {
        "title": "Attention Is Not the Only Choice: Counterfactual Reasoning for Path-Based Explainable Recommendation",
        "authors": [
            "Yicong Li",
            "Xiangguo Sun",
            "Hongxu Chen",
            "Sixiao Zhang",
            "Yu Yang",
            "Guandong Xu"
        ],
        "comments": "accepted by TKDE",
        "subjects": "Information Retrieval (cs.IR)",
        "abstract": "Compared with only pursuing recommendation accuracy, the explainability of a recommendation model has drawn more attention in recent years. Many graph-based recommendations resort to informative paths with the attention mechanism for the explanation. Unfortunately, these attention weights are intentionally designed for model accuracy but not explainability. Recently, some researchers have started to question attention-based explainability because the attention weights are unstable for different reproductions, and they may not always align with human intuition. Inspired by the counterfactual reasoning from causality learning theory, we propose a novel explainable framework targeting path-based recommendations, wherein the explainable weights of paths are learned to replace attention weights. Specifically, we design two counterfactual reasoning algorithms from both path representation and path topological structure perspectives. Moreover, unlike traditional case studies, we also propose a package of explainability evaluation solutions with both qualitative and quantitative methods. We conduct extensive experiments on three real-world datasets, the results of which further demonstrate the effectiveness and reliability of our method.\n    ",
        "primary_category": "cs.IR",
        "categories": [],
        "submitted_date": "11 Jan 2024",
        "last_revised_date": " "
    },
    "2401.06040": {
        "title": "Wavelet-Inspired Multiscale Graph Convolutional Recurrent Network for Traffic Forecasting",
        "authors": [
            "Qipeng Qian",
            "Tanwi Mallick"
        ],
        "comments": " ",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Traffic forecasting is the foundation for intelligent transportation systems. Spatiotemporal graph neural networks have demonstrated state-of-the-art performance in traffic forecasting. However, these methods do not explicitly model some of the natural characteristics in traffic data, such as the multiscale structure that encompasses spatial and temporal variations at different levels of granularity or scale. To that end, we propose a Wavelet-Inspired Graph Convolutional Recurrent Network (WavGCRN) which combines multiscale analysis (MSA)-based method with Deep Learning (DL)-based method. In WavGCRN, the traffic data is decomposed into time-frequency components with Discrete Wavelet Transformation (DWT), constructing a multi-stream input structure; then Graph Convolutional Recurrent networks (GCRNs) are employed as encoders for each stream, extracting spatiotemporal features in different scales; and finally the learnable Inversed DWT and GCRN are combined as the decoder, fusing the information from all streams for traffic metrics reconstruction and prediction. Furthermore, road-network-informed graphs and data-driven graph learning are combined to accurately capture spatial correlation. The proposed method can offer well-defined interpretability, powerful learning capability, and competitive forecasting performance on real-world traffic data sets.\n    ",
        "primary_category": "cs.LG",
        "categories": [],
        "submitted_date": "11 Jan 2024",
        "last_revised_date": " "
    },
    "2401.06182": {
        "title": "Prediction of Cellular Identities from Trajectory and Cell Fate Information",
        "authors": [
            "Baiyang Dai",
            "Jiamin Yang",
            "Hari Shroff",
            "Patrick La Riviere"
        ],
        "comments": " ",
        "subjects": "Quantitative Methods (q-bio.QM)",
        "abstract": "Determining cell identities in imaging sequences is an important yet challenging task. The conventional method for cell identification is via cell tracking, which is complex and can be time-consuming. In this study, we propose an innovative approach to cell identification during early $\\textit{C. elegans}$ embryogenesis using machine learning. Cell identification during $\\textit{C. elegans}$ embryogenesis would provide insights into neural development with implications for higher organisms including humans. We employed random forest, MLP, and LSTM models, and tested cell classification accuracy on 3D time-lapse confocal datasets spanning the first 4 hours of embryogenesis. By leveraging a small number of spatial-temporal features of individual cells, including cell trajectory and cell fate information, our models achieve an accuracy of over 91%, even with limited data. We also determine the most important feature contributions and can interpret these features in the context of biological knowledge. Our research demonstrates the success of predicting cell identities in time-lapse imaging sequences directly from simple spatio-temporal features.\n    ",
        "primary_category": "q-bio.QM",
        "categories": [
            "cs.CV",
            "cs.LG",
            "eess.IV"
        ],
        "submitted_date": "11 Jan 2024",
        "last_revised_date": " "
    },
    "2401.06349": {
        "title": "ADAPT: Alzheimer Diagnosis through Adaptive Profiling Transformers",
        "authors": [
            "Yifeng Wang",
            "Ke Chen",
            "Haohan Wang"
        ],
        "comments": " ",
        "subjects": "Image and Video Processing (eess.IV)",
        "abstract": "Automated diagnosis of Alzheimer Disease(AD) from brain imaging, such as magnetic resonance imaging (MRI), has become increasingly important and has attracted the community to contribute many deep learning methods. However, many of these methods are facing a trade-off that 3D models tend to be complicated while 2D models cannot capture the full 3D intricacies from the data. In this paper, we introduce a new model structure for diagnosing AD, and it can complete with performances of 3D models while essentially is a 2D method (thus computationally efficient). While the core idea lies in new perspective of cutting the 3D images into multiple 2D slices from three dimensions, we introduce multiple components that can further benefit the model in this new perspective, including adaptively selecting the number of sclices in each dimension, and the new attention mechanism. In addition, we also introduce a morphology augmentation, which also barely introduces new computational loads, but can help improve the diagnosis performances due to its alignment to the pathology of AD. We name our method ADAPT, which stands for Alzheimer Diagnosis through Adaptive Profiling Transformers. We test our model from a practical perspective (the testing domains do not appear in the training one): the diagnosis accuracy favors our ADAPT, while ADAPT uses less parameters than most 3D models use.\n    ",
        "primary_category": "eess.IV",
        "categories": [
            "cs.CV"
        ],
        "submitted_date": "12 Jan 2024",
        "last_revised_date": " "
    },
    "2401.06755": {
        "title": "Solving the Discretised Multiphase Flow Equations with Interface Capturing on Structured Grids Using Machine Learning Libraries",
        "authors": [
            "Boyang Chen",
            "Claire E. Heaney",
            "Jefferson L. M. A. Gomes",
            "Omar K. Matar",
            "Christopher C. Pain"
        ],
        "comments": "34 pages, 18 figures, 4 tables",
        "subjects": "Fluid Dynamics (physics.flu-dyn)",
        "abstract": "This paper solves the discretised multiphase flow equations using tools and methods from machine-learning libraries. The idea comes from the observation that convolutional layers can be used to express a discretisation as a neural network whose weights are determined by the numerical method, rather than by training, and hence, we refer to this approach as Neural Networks for PDEs (NN4PDEs). To solve the discretised multiphase flow equations, a multigrid solver is implemented through a convolutional neural network with a U-Net architecture. Immiscible two-phase flow is modelled by the 3D incompressible Navier-Stokes equations with surface tension and advection of a volume fraction field, which describes the interface between the fluids. A new compressive algebraic volume-of-fluids method is introduced, based on a residual formulation using Petrov-Galerkin for accuracy and designed with NN4PDEs in mind. High-order finite-element based schemes are chosen to model a collapsing water column and a rising bubble. Results compare well with experimental data and other numerical results from the literature, demonstrating that, for the first time, finite element discretisations of multiphase flows can be solved using an approach based on (untrained) convolutional neural networks. A benefit of expressing numerical discretisations as neural networks is that the code can run, without modification, on CPUs, GPUs or the latest accelerators designed especially to run AI codes.\n    ",
        "primary_category": "physics.flu-dyn",
        "categories": [
            "cs.LG"
        ],
        "submitted_date": "12 Jan 2024",
        "last_revised_date": " "
    },
    "2401.06788": {
        "title": "The NPU-ASLP-LiAuto System Description for Visual Speech Recognition in CNVSRC 2023",
        "authors": [
            "He Wang",
            "Pengcheng Guo",
            "Wei Chen",
            "Pan Zhou",
            "Lei Xie"
        ],
        "comments": "Included in CNVSRC Workshop 2023, NCMMSC 2023",
        "subjects": "Audio and Speech Processing (eess.AS)",
        "abstract": "This paper delineates the visual speech recognition (VSR) system introduced by the NPU-ASLP-LiAuto (Team 237) in the first Chinese Continuous Visual Speech Recognition Challenge (CNVSRC) 2023, engaging in the fixed and open tracks of Single-Speaker VSR Task, and the open track of Multi-Speaker VSR Task. In terms of data processing, we leverage the lip motion extractor from the baseline1 to produce multi-scale video data. Besides, various augmentation techniques are applied during training, encompassing speed perturbation, random rotation, horizontal flipping, and color transformation. The VSR model adopts an end-to-end architecture with joint CTC/attention loss, comprising a ResNet3D visual frontend, an E-Branchformer encoder, and a Transformer decoder. Experiments show that our system achieves 34.76% CER for the Single-Speaker Task and 41.06% CER for the Multi-Speaker Task after multi-system fusion, ranking first place in all three tracks we participate.\n    ",
        "primary_category": "eess.AS",
        "categories": [
            "cs.AI",
            "cs.SD"
        ],
        "submitted_date": "7 Jan 2024",
        "last_revised_date": " "
    },
    "2401.06915": {
        "title": "DocFinQA: A Long-Context Financial Reasoning Dataset",
        "authors": [
            "Varshini Reddy",
            "Rik Koncel-Kedziorski",
            "Viet Dac Lai",
            "Michael Krumdick",
            "Charles Lovering",
            "Chris Tanner"
        ],
        "comments": "13 pages",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "For large language models (LLMs) to be effective in the financial domain -- where each decision can have a significant impact -- it is necessary to investigate realistic tasks and data. Financial professionals often interact with documents that are hundreds of pages long, but most financial research datasets only deal with short excerpts from these documents. To address this, we introduce a long-document financial QA task. We augment 7,437 questions from the existing FinQA dataset with the full-document context, extending the average context length from under 700 words in FinQA to 123k words in DocFinQA. We conduct extensive experiments over retrieval-based QA pipelines and long-context language models. DocFinQA proves a significant challenge for even state-of-the-art systems. We also provide a case-study on the longest documents in DocFinQA and find that models particularly struggle on these documents. Addressing these challenges may have a wide reaching impact across applications where specificity and long-range contexts are critical, like gene sequences and legal document contract analysis.\n    ",
        "primary_category": "cs.CL",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "12 Jan 2024",
        "last_revised_date": " "
    },
    "2401.07408": {
        "title": "Multimodal Language and Graph Learning of Adsorption Configuration in Catalysis",
        "authors": [
            "Janghoon Ock",
            "Rishikesh Magar",
            "Akshay Antony",
            "Amir Barati Farimani"
        ],
        "comments": "28 pages, 6 figures, supplementary information added",
        "subjects": "Computational Engineering, Finance, and Science (cs.CE)",
        "abstract": "Adsorption energy, a reactivity descriptor, should be accurately assessed for efficient catalyst screening. This evaluation requires determining the lowest energy across various adsorption configurations on the catalytic surface. While graph neural networks (GNNs) have gained popularity as a machine learning approach for computing the energy of catalyst systems, they rely heavily on atomic spatial coordinates and often lack clarity in their interpretations. Recent advancements in language models have broadened their applicability to predicting catalytic properties, allowing us to bypass the complexities of graph representation. These models are adept at handling textual data, making it possible to incorporate observable features in a human-readable format. However, language models encounter challenges in accurately predicting the energy of adsorption configurations, typically showing a high mean absolute error (MAE) of about 0.71 eV. Our study addresses this limitation by introducing a self-supervised multi-modal learning approach, termed graph-assisted pretraining. This method significantly reduces the MAE to 0.35 eV through a combination of data augmentation, achieving comparable accuracy with DimeNet++ while using 0.4% of its training data size. Furthermore, the Transformer encoder at the core of the language model can provide insights into the feature focus through its attention scores. This analysis shows that our multimodal training effectively redirects the model's attention toward relevant adsorption configurations from adsorbate-related features, enhancing prediction accuracy and interpretability.\n    ",
        "primary_category": "cs.CE",
        "categories": [],
        "submitted_date": "15 Jan 2024",
        "last_revised_date": " "
    },
    "2401.07768": {
        "title": "On Hilbert-Poincar\u00e9 series of affine semi-regular polynomial sequences and related Gr\u00f6bner bases",
        "authors": [
            "Momonari Kudo",
            "Kazuhiro Yokoyama"
        ],
        "comments": "25 pages, Comments are welcome!",
        "subjects": "Symbolic Computation (cs.SC)",
        "abstract": "Gr\u00f6bner bases are nowadays central tools for solving various problems in commutative algebra and algebraic geometry. A typical use of Gr\u00f6bner bases is the multivariate polynomial system solving, which enables us to construct algebraic attacks against post-quantum cryptographic protocols. Therefore, the determination of the complexity of computing Gr\u00f6bner bases is very important both in theory and in practice: One of the most important cases is the case where input polynomials compose an (overdetermined) affine semi-regular sequence. The first part of this paper aims to present a survey on Gr\u00f6bner basis computation and its complexity. In the second part, we shall give an explicit formula on the (truncated) Hilbert-Poincar\u00e9 series associated to the homogenization of an affine semi-regular sequence. Based on the formula, we also study (reduced) Gr\u00f6bner bases of the ideals generated by an affine semi-regular sequence and its homogenization. Some of our results are considered to give mathematically rigorous proofs of the correctness of methods for computing Gr\u00f6bner bases of the ideal generated by an affine semi-regular sequence.\n    ",
        "primary_category": "cs.SC",
        "categories": [
            "math.AC",
            "math.AG"
        ],
        "submitted_date": "15 Jan 2024",
        "last_revised_date": " "
    },
    "2401.08037": {
        "title": "Understanding factors behind IoT privacy -- A user's perspective on RF sensors",
        "authors": [
            "Akash Deep Singh",
            "Brian Wang",
            "Luis Garcia",
            "Xiang Chen",
            "Mani Srivastava"
        ],
        "comments": " ",
        "subjects": "Human-Computer Interaction (cs.HC)",
        "abstract": "While IoT sensors in physical spaces have provided utility and comfort in our lives, their instrumentation in private and personal spaces has led to growing concerns regarding privacy. The existing notion behind IoT privacy is that the sensors whose data can easily be understood and interpreted by humans (such as cameras) are more privacy-invasive than sensors that are not human-understandable, such as RF (radio-frequency) sensors. However, given recent advancements in machine learning, we can not only make sensitive inferences on RF data but also translate between modalities. Thus, the existing notions of privacy for IoT sensors need to be revisited. In this paper, our goal is to understand what factors affect the privacy notions of a non-expert user (someone who is not well-versed in privacy concepts). To this regard, we conduct an online study of 162 participants from the USA to find out what factors affect the privacy perception of a user regarding an RF-based device or a sensor. Our findings show that a user's perception of privacy not only depends upon the data collected by the sensor but also on the inferences that can be made on that data, familiarity with the device and its form factor as well as the control a user has over the device design and its data policies. When the data collected by the sensor is not human-interpretable, it is the inferences that can be made on the data and not the data itself that users care about when making informed decisions regarding device privacy.\n    ",
        "primary_category": "cs.HC",
        "categories": [],
        "submitted_date": "16 Jan 2024",
        "last_revised_date": " "
    },
    "2401.08536": {
        "title": "Dual-Loop Robust Control of Biased Koopman Operator Model by Noisy Data of Nonlinear Systems",
        "authors": [
            "Tianyi He",
            "Anuj Pal"
        ],
        "comments": " ",
        "subjects": "Systems and Control (eess.SY)",
        "abstract": "The Koopman operator approach for data-driven control design of a nonlinear system is on the rise because of its capability to capture the behaviours of global dynamics. However, the measurement noises of inputs and outputs will bias the Koopman model identification and cause model mismatch from the actual nonlinear dynamics. The current work evaluates the bounds of the noise-induced model bias of the Koopman operator model and proposes a data-driven robust dual-loop control framework (Koopman based robust control-KROC) for the biased model. First, the model mismatch is found bounded under radial basis functions (RBF) and the bounded noises, and the bound of model mismatch is assessed. Second, the pitfalls of linear quadratic Gaussian (LQG) control based on the biased Koopman model of Van Der Pol oscillator are shown. Motivated from the pitfalls, the dual-loop control is proposed, which consist of an observer-based state-feedback control based on the nominal Koopman model and an additional robust loop to compensate model mismatch. A linear matrix inequality (LMI) is derived, which can guarantee robust stability and performance under bounded noises for the finite-dimensional Koopman operator model. Finally, the proposed framework is implemented to a nonlinear Van Der Pol oscillator to demonstrate enhanced control performance by the dual-loop robust control.\n    ",
        "primary_category": "eess.SY",
        "categories": [],
        "submitted_date": "16 Jan 2024",
        "last_revised_date": " "
    },
    "2401.08909": {
        "title": "Leveraging Gradients for Unsupervised Accuracy Estimation under Distribution Shift",
        "authors": [
            "Renchunzi Xie",
            "Ambroise Odonnat",
            "Vasilii Feofanov",
            "Ievgen Redko",
            "Jianfeng Zhang",
            "Bo An"
        ],
        "comments": " ",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Estimating test accuracy without access to the ground-truth test labels under varying test environments is a challenging, yet extremely important problem in the safe deployment of machine learning algorithms. Existing works rely on the information from either the outputs or the extracted features of neural networks to formulate an estimation score correlating with the ground-truth test accuracy. In this paper, we investigate--both empirically and theoretically--how the information provided by the gradients can be predictive of the ground-truth test accuracy even under a distribution shift. Specifically, we use the norm of classification-layer gradients, backpropagated from the cross-entropy loss after only one gradient step over test data. Our key idea is that the model should be adjusted with a higher magnitude of gradients when it does not generalize to the test dataset with a distribution shift. We provide theoretical insights highlighting the main ingredients of such an approach ensuring its empirical success. Extensive experiments conducted on diverse distribution shifts and model structures demonstrate that our method significantly outperforms state-of-the-art algorithms.\n    ",
        "primary_category": "cs.LG",
        "categories": [],
        "submitted_date": "17 Jan 2024",
        "last_revised_date": " "
    },
    "2401.09181": {
        "title": "Beyond Anti-Forgetting: Multimodal Continual Instruction Tuning with Positive Forward Transfer",
        "authors": [
            "Junhao Zheng",
            "Qianli Ma",
            "Zhen Liu",
            "Binquan Wu",
            "Huawen Feng"
        ],
        "comments": " ",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Multimodal Continual Instruction Tuning (MCIT) enables Multimodal Large Language Models (MLLMs) to meet continuously emerging requirements without expensive retraining. MCIT faces two major obstacles: catastrophic forgetting (where old knowledge is forgotten) and negative forward transfer (where the performance of future tasks is degraded). Although existing methods have greatly alleviated catastrophic forgetting, they still suffer from negative forward transfer. By performing singular value decomposition (SVD) on input embeddings, we discover a large discrepancy in different input embeddings. The discrepancy results in the model learning irrelevant information for old and pre-trained tasks, which leads to catastrophic forgetting and negative forward transfer. To address these issues, we propose Fwd-Prompt, a prompt-based method projecting prompt gradient to the residual space to minimize the interference between tasks and to the pre-trained subspace for reusing pre-trained knowledge. Our experiments demonstrate that Fwd-Prompt achieves state-of-the-art performance while updating fewer parameters and requiring no old samples. Our research sheds light on the potential of continuously adapting MLLMs to new tasks under the instruction tuning paradigm and encourages future studies to explore MCIT. The code will soon be publicly available.\n    ",
        "primary_category": "cs.LG",
        "categories": [],
        "submitted_date": "17 Jan 2024",
        "last_revised_date": " "
    },
    "2401.09851": {
        "title": "Sophisticated Behavioral Simulation: A Possible Solution to Problems of Organized Complexity",
        "authors": [
            "Cheng Wang",
            "Chuwen Wang",
            "Yu Zhao",
            "Wang Zhang",
            "Shirong Zeng",
            "Ronghui Ning",
            "Changjun Jiang"
        ],
        "comments": " ",
        "subjects": "Artificial Intelligence (cs.AI)",
        "abstract": "Simulation technologies have been widely utilized in many scientific research fields such as weather forecasting, fluid mechanics, and biological populations. As a matter of facts, they act as the best tool to handle problems in complex systems where closed-form expressions are unavailable and the target distribution in the representation space is too complex to be fully represented by data-driven learning models, such as deep learning (DL) models. This paper investigates the effectiveness and preference of simulation technologies based on the analyses of scientific paradigms and problems. We revisit the evolution of scientific paradigms from the perspective of data, algorithms, and computational power, and rethink a classic classification of scientific problems which consists of the problems of organized simplicity, problems of disorganized complexity, and problems of organized complexity. These different problems reflect the strengths of different paradigms, indicating that a new simulation technology integrating different paradigms is required to deal with unresolved problems of organized complexity in more complex systems. Therefore, we summarize existent simulation technologies aligning with the scientific paradigms, and propose the concept of behavioral simulation (BS), and further sophisticated behavioral simulation (SBS). They represent a higher degree of paradigms integration based on foundation models to simulate complex social systems involving sophisticated human strategies and behaviors. Beyond the capacity of traditional agent-based modeling simulation (ABMS), BS and further SBS are designed to tackle challenges concerning the complex human system, which can be regarded as a possible next paradigm for science. Through this work, we look forward to more powerful BS and SBS applications in scientific research branches within social science.\n    ",
        "primary_category": "cs.AI",
        "categories": [],
        "submitted_date": "18 Jan 2024",
        "last_revised_date": " "
    },
    "2401.10652": {
        "title": "AutoChunk: Automated Activation Chunk for Memory-Efficient Long Sequence Inference",
        "authors": [
            "Xuanlei Zhao",
            "Shenggan Cheng",
            "Guangyang Lu",
            "Jiarui Fang",
            "Haotian Zhou",
            "Bin Jia",
            "Ziming Liu",
            "Yang You"
        ],
        "comments": "ICLR 2024",
        "subjects": "Performance (cs.PF)",
        "abstract": "Large deep learning models have achieved impressive performance across a range of applications. However, their large memory requirements, including parameter memory and activation memory, have become a significant challenge for their practical serving. While existing methods mainly address parameter memory, the importance of activation memory has been overlooked. Especially for long input sequences, activation memory is expected to experience a significant exponential growth as the length of sequences increases. In this approach, we propose AutoChunk, an automatic and adaptive compiler system that efficiently reduces activation memory for long sequence inference by chunk strategies. The proposed system generates chunk plans by optimizing through multiple stages. In each stage, the chunk search pass explores all possible chunk candidates and the chunk selection pass identifies the optimal one. At runtime, AutoChunk employs code generation to automatically apply chunk strategies. The experiments demonstrate that AutoChunk can reduce over 80\\% of activation memory while maintaining speed loss within 10%, extend max sequence length by 3.2x to 11.7x, and outperform state-of-the-art methods by a large margin.\n    ",
        "primary_category": "cs.PF",
        "categories": [
            "cs.DC",
            "cs.LG"
        ],
        "submitted_date": "19 Jan 2024",
        "last_revised_date": " "
    },
    "2401.10726": {
        "title": "Empowering Aggregators with Practical Data-Driven Tools: Harnessing Aggregated and Disaggregated Flexibility for Demand Response",
        "authors": [
            "Costas Mylonas",
            "Donata Boric",
            "Leila Luttenberger Maric",
            "Alexandros Tsitsanis",
            "Eleftheria Petrianou",
            "Magda Foti"
        ],
        "comments": "We will perform a major update and change in the order of the name of the authors",
        "subjects": "Systems and Control (eess.SY)",
        "abstract": "This study explores the crucial interplay between aggregators and building occupants in activating flexibility through Demand Response (DR) programs, with a keen focus on achieving robust decarbonization and fortifying the resilience of the energy system amidst the uncertainties presented by Renewable Energy Sources (RES). Firstly, it introduces a methodology of optimizing aggregated flexibility provision strategies in environments with limited data, utilizing Discrete Fourier Transformation (DFT) and clustering techniques to identify building occupant's activity patterns. Secondly, the study assesses the disaggregated flexibility provision of Heating Ventilation and Air Conditioning (HVAC) systems during DR events, employing machine learning and optimization techniques for precise, device-level analysis. The first approach offers a non-intrusive pathway for aggregators to provide flexibility services in environments of a single smart meter for the whole building's consumption, while the second approach carefully considers building occupants' thermal comfort profiles, while maximizing flexibility in case of existence of dedicated smart meters to the HVAC systems. Through the application of data-driven techniques and encompassing case studies from both industrial and residential buildings, this paper not only unveils pivotal opportunities for aggregators in the balancing and emerging flexibility markets but also successfully develops end-to-end practical tools for aggregators. Furthermore, the efficacy of this tool is validated through detailed case studies, substantiating its operational capability and contributing to the evolution of a resilient and efficient energy system.\n    ",
        "primary_category": "eess.SY",
        "categories": [
            "cs.LG"
        ],
        "submitted_date": "19 Jan 2024",
        "last_revised_date": " "
    },
    "2401.10910": {
        "title": "Metacognition is all you need? Using Introspection in Generative Agents to Improve Goal-directed Behavior",
        "authors": [
            "Jason Toy",
            "Josh MacAdam",
            "Phil Tabor"
        ],
        "comments": "9 pages, 4 figures",
        "subjects": "Neurons and Cognition (q-bio.NC)",
        "abstract": "Recent advances in Large Language Models (LLMs) have shown impressive capabilities in various applications, yet LLMs face challenges such as limited context windows and difficulties in generalization. In this paper, we introduce a metacognition module for generative agents, enabling them to observe their own thought processes and actions. This metacognitive approach, designed to emulate System 1 and System 2 cognitive processes, allows agents to significantly enhance their performance by modifying their strategy. We tested the metacognition module on a variety of scenarios, including a situation where generative agents must survive a zombie apocalypse, and observe that our system outperform others, while agents adapt and improve their strategies to complete tasks over time.\n    ",
        "primary_category": "q-bio.NC",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "9 Jan 2024",
        "last_revised_date": " "
    },
    "2401.11148": {
        "title": "Enhancing System-Level Safety in Mixed-Autonomy Platoon via Safe Reinforcement Learning",
        "authors": [
            "Jingyuan Zhou",
            "Longhao Yan",
            "Kaidi Yang"
        ],
        "comments": " ",
        "subjects": "Systems and Control (eess.SY)",
        "abstract": "Connected and automated vehicles (CAVs) have recently gained prominence in traffic research due to advances in communication technology and autonomous driving. Various longitudinal control strategies for CAVs have been developed to enhance traffic efficiency, stability, and safety in mixed-autonomy scenarios. Deep reinforcement learning (DRL) is one promising strategy for mixed-autonomy platoon control, thanks to its capability of managing complex scenarios in real time after sufficient offline training. However, there are three research gaps for DRL-based mixed-autonomy platoon control: (i) the lack of theoretical collision-free guarantees, (ii) the widely adopted but impractical assumption of skilled and rational drivers who will not collide with preceding vehicles, and (iii) the strong assumption of a known human driver model. To address these research gaps, we propose a safe DRL-based controller that can provide a system-level safety guarantee for mixed-autonomy platoon control. First, we combine control barrier function (CBF)-based safety constraints and DRL via a quadratic programming (QP)-based differentiable neural network layer to provide theoretical safety guarantees. Second, we incorporate system-level safety constraints into our proposed method to account for the safety of both CAVs and the following HDVs to address the potential collisions due to irrational human driving behavior. Third, we devise a learning-based system identification approach to estimate the unknown human car-following behavior in the real system. Simulation results demonstrate that our proposed method effectively ensures CAV safety and improves HDV safety in mixed platoon environments while simultaneously enhancing traffic capacity and string stability.\n    ",
        "primary_category": "eess.SY",
        "categories": [],
        "submitted_date": "20 Jan 2024",
        "last_revised_date": " "
    },
    "2401.11202": {
        "title": "PartIR: Composing SPMD Partitioning Strategies for Machine Learning",
        "authors": [
            "Sami Alabed",
            "Daniel Belov",
            "Bart Chrzaszcz",
            "Juliana Franco",
            "Dominik Grewe",
            "Dougal Maclaurin",
            "James Molloy",
            "Tom Natan",
            "Tamara Norman",
            "Xiaoyue Pan",
            "Adam Paszke",
            "Norman A. Rink",
            "Michael Schaarschmidt",
            "Timur Sitdikov",
            "Agnieszka Swietlik",
            "Dimitrios Vytiniotis",
            "Joel Wee"
        ],
        "comments": " ",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Training of modern large neural networks (NN) requires a combination of parallelization strategies encompassing data, model, or optimizer sharding. When strategies increase in complexity, it becomes necessary for partitioning tools to be 1) expressive, allowing the composition of simpler strategies, and 2) predictable to estimate performance analytically. We present PartIR, our design for a NN partitioning system. PartIR is focused on an incremental approach to rewriting and is hardware-and-runtime agnostic. We present a simple but powerful API for composing sharding strategies and a simulator to validate them. The process is driven by high-level programmer-issued partitioning tactics, which can be both manual and automatic. Importantly, the tactics are specified separately from the model code, making them easy to change. We evaluate PartIR on several different models to demonstrate its predictability, expressibility, and ability to reach peak performance..\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.DC",
            "cs.PL"
        ],
        "submitted_date": "20 Jan 2024",
        "last_revised_date": " "
    },
    "2401.11627": {
        "title": "Tight Verification of Probabilistic Robustness in Bayesian Neural Networks",
        "authors": [
            "Ben Batten",
            "Mehran Hosseini",
            "Alessio Lomuscio"
        ],
        "comments": "Accepted at AISTATS 2024",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "We introduce two algorithms for computing tight guarantees on the probabilistic robustness of Bayesian Neural Networks (BNNs). Computing robustness guarantees for BNNs is a significantly more challenging task than verifying the robustness of standard Neural Networks (NNs) because it requires searching the parameters' space for safe weights. Moreover, tight and complete approaches for the verification of standard NNs, such as those based on Mixed-Integer Linear Programming (MILP), cannot be directly used for the verification of BNNs because of the polynomial terms resulting from the consecutive multiplication of variables encoding the weights. Our algorithms efficiently and effectively search the parameters' space for safe weights by using iterative expansion and the network's gradient and can be used with any verification algorithm of choice for BNNs. In addition to proving that our algorithms compute tighter bounds than the SoA, we also evaluate our algorithms against the SoA on standard benchmarks, such as MNIST and CIFAR10, showing that our algorithms compute bounds up to 40% tighter than the SoA.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.AI",
            "cs.FL",
            "cs.LO"
        ],
        "submitted_date": "21 Jan 2024",
        "last_revised_date": " "
    },
    "2401.11977": {
        "title": "Adaptive Motion Planning for Multi-fingered Functional Grasp via Force Feedback",
        "authors": [
            "Dongying Tian",
            "Xiangbo Lin",
            "Yi Sun"
        ],
        "comments": "8 pages,7 figures",
        "subjects": "Robotics (cs.RO)",
        "abstract": "Enabling multi-fingered robots to grasp and manipulate objects with human-like dexterity is especially challenging during the dynamic, continuous hand-object interactions. Closed-loop feedback control is essential for dexterous hands to dynamically finetune hand poses when performing precise functional grasps. This work proposes an adaptive motion planning method based on deep reinforcement learning to adjust grasping poses according to real-time feedback from joint torques from pre-grasp to goal grasp. We find the multi-joint torques of the dexterous hand can sense object positions through contacts and collisions, enabling real-time adjustment of grasps to generate varying grasping trajectories for objects in different positions. In our experiments, the performance gap with and without force feedback reveals the important role of force feedback in adaptive manipulation. Our approach utilizing force feedback preliminarily exhibits human-like flexibility, adaptability, and precision.\n    ",
        "primary_category": "cs.RO",
        "categories": [],
        "submitted_date": "22 Jan 2024",
        "last_revised_date": " "
    },
    "2401.12202": {
        "title": "OK-Robot: What Really Matters in Integrating Open-Knowledge Models for Robotics",
        "authors": [
            "Peiqi Liu",
            "Yaswanth Orru",
            "Jay Vakil",
            "Chris Paxton",
            "Nur Muhammad Mahi Shafiullah",
            "Lerrel Pinto"
        ],
        "comments": "Github repo: this https URL",
        "subjects": "Robotics (cs.RO)",
        "abstract": "Remarkable progress has been made in recent years in the fields of vision, language, and robotics. We now have vision models capable of recognizing objects based on language queries, navigation systems that can effectively control mobile systems, and grasping models that can handle a wide range of objects. Despite these advancements, general-purpose applications of robotics still lag behind, even though they rely on these fundamental capabilities of recognition, navigation, and grasping. In this paper, we adopt a systems-first approach to develop a new Open Knowledge-based robotics framework called OK-Robot. By combining Vision-Language Models (VLMs) for object detection, navigation primitives for movement, and grasping primitives for object manipulation, OK-Robot offers a integrated solution for pick-and-drop operations without requiring any training. To evaluate its performance, we run OK-Robot in 10 real-world home environments. The results demonstrate that OK-Robot achieves a 58.5% success rate in open-ended pick-and-drop tasks, representing a new state-of-the-art in Open Vocabulary Mobile Manipulation (OVMM) with nearly 1.8x the performance of prior work. On cleaner, uncluttered environments, OK-Robot's performance increases to 82%. However, the most important insight gained from OK-Robot is the critical role of nuanced details when combining Open Knowledge systems like VLMs with robotic modules. Videos of our experiments and code are available on our website: this https URL\n",
        "primary_category": "cs.RO",
        "categories": [
            "cs.AI",
            "cs.CV",
            "cs.LG"
        ],
        "submitted_date": "22 Jan 2024",
        "last_revised_date": " "
    },
    "2401.12413": {
        "title": "How Far Can 100 Samples Go? Unlocking Overall Zero-Shot Multilingual Translation via Tiny Multi-Parallel Data",
        "authors": [
            "Di Wu",
            "Shaomu Tan",
            "Yan Meng",
            "David Stap",
            "Christof Monz"
        ],
        "comments": "15 pages, 5 figures",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "Zero-shot translation aims to translate between language pairs not seen during training in Multilingual Machine Translation (MMT) and is largely considered an open problem. A common, albeit resource-consuming, solution is to add as many related translation directions as possible to the training corpus. In this paper, we show that for an English-centric model, surprisingly large zero-shot improvements can be achieved by simply fine-tuning with a very small amount of multi-parallel data. For example, on the EC30 dataset, we obtain up to +21.7 ChrF non-English overall improvements (870 directions) by using only 100 multi-parallel samples while preserving English-centric translation quality. When investigating the size effect of fine-tuning data and its transfer capabilities, we found that already a small, randomly sampled set of fine-tuning directions is sufficient to achieve comparable improvements. The resulting non-English performance is close to the complete translation upper bound. Even in a minimal setting -- fine-tuning with only one single sample -- the well-known off-target issue is almost completely resolved, explaining parts -- but not all -- of the observed improvements in translation quality.\n    ",
        "primary_category": "cs.CL",
        "categories": [
            "cs.LG"
        ],
        "submitted_date": "22 Jan 2024",
        "last_revised_date": " "
    },
    "2401.12624": {
        "title": "Knowledge Distillation from Language-Oriented to Emergent Communication for Multi-Agent Remote Control",
        "authors": [
            "Yongjun Kim",
            "Sejin Seo",
            "Jihong Park",
            "Mehdi Bennis",
            "Seong-Lyun Kim",
            "Junil Choi"
        ],
        "comments": " ",
        "subjects": "Artificial Intelligence (cs.AI)",
        "abstract": "In this work, we compare emergent communication (EC) built upon multi-agent deep reinforcement learning (MADRL) and language-oriented semantic communication (LSC) empowered by a pre-trained large language model (LLM) using human language. In a multi-agent remote navigation task, with multimodal input data comprising location and channel maps, it is shown that EC incurs high training cost and struggles when using multimodal data, whereas LSC yields high inference computing cost due to the LLM's large size. To address their respective bottlenecks, we propose a novel framework of language-guided EC (LEC) by guiding the EC training using LSC via knowledge distillation (KD). Simulations corroborate that LEC achieves faster travel time while avoiding areas with poor channel conditions, as well as speeding up the MADRL training convergence by up to 61.8% compared to EC.\n    ",
        "primary_category": "cs.AI",
        "categories": [
            "cs.IT",
            "cs.LG",
            "cs.NI"
        ],
        "submitted_date": "23 Jan 2024",
        "last_revised_date": " "
    },
    "2401.12768": {
        "title": "What Can Self-Admitted Technical Debt Tell Us About Security? A Mixed-Methods Study",
        "authors": [
            "Nicol\u00e1s E. D\u00edaz Ferreyra",
            "Mojtaba Shahin",
            "Mansooreh Zahedi",
            "Sodiq Quadri",
            "Ricardo Scandariato"
        ],
        "comments": "Accepted in the 21th International Conference on Mining Software Repositories (MSR '24)",
        "subjects": "Software Engineering (cs.SE)",
        "abstract": "Self-Admitted Technical Debt (SATD) encompasses a wide array of sub-optimal design and implementation choices reported in software artefacts (e.g., code comments and commit messages) by developers themselves. Such reports have been central to the study of software maintenance and evolution over the last decades. However, they can also be deemed as dreadful sources of information on potentially exploitable vulnerabilities and security flaws. This work investigates the security implications of SATD from a technical and developer-centred perspective. On the one hand, it analyses whether security pointers disclosed inside SATD sources can be used to characterise vulnerabilities in Open-Source Software (OSS) projects and repositories. On the other hand, it delves into developers' perspectives regarding the motivations behind this practice, its prevalence, and its potential negative consequences. We followed a mixed-methods approach consisting of (i) the analysis of a preexisting dataset containing 8,812 SATD instances and (ii) an online survey with 222 OSS practitioners. We gathered 201 SATD instances through the dataset analysis and mapped them to different Common Weakness Enumeration (CWE) identifiers. Overall, 25 different types of CWEs were spotted across commit messages, pull requests, code comments, and issue sections, from which 8 appear among MITRE's Top-25 most dangerous ones. The survey shows that software practitioners often place security pointers across SATD artefacts to promote a security culture among their peers and help them spot flaky code sections, among other motives. However, they also consider such a practice risky as it may facilitate vulnerability exploits. Our findings suggest that preserving the contextual integrity of security pointers disseminated across SATD artefacts is critical to safeguard both commercial and OSS solutions against zero-day attacks.\n    ",
        "primary_category": "cs.SE",
        "categories": [
            "cs.HC"
        ],
        "submitted_date": "23 Jan 2024",
        "last_revised_date": " "
    },
    "2401.12938": {
        "title": "Neural deformation fields for template-based reconstruction of cortical surfaces from MRI",
        "authors": [
            "Fabian Bongratz",
            "Anne-Marie Rickmann",
            "Christian Wachinger"
        ],
        "comments": "To appear in Medical Image Analysis",
        "subjects": "Image and Video Processing (eess.IV)",
        "abstract": "The reconstruction of cortical surfaces is a prerequisite for quantitative analyses of the cerebral cortex in magnetic resonance imaging (MRI). Existing segmentation-based methods separate the surface registration from the surface extraction, which is computationally inefficient and prone to distortions. We introduce Vox2Cortex-Flow (V2C-Flow), a deep mesh-deformation technique that learns a deformation field from a brain template to the cortical surfaces of an MRI scan. To this end, we present a geometric neural network that models the deformation-describing ordinary differential equation in a continuous manner. The network architecture comprises convolutional and graph-convolutional layers, which allows it to work with images and meshes at the same time. V2C-Flow is not only very fast, requiring less than two seconds to infer all four cortical surfaces, but also establishes vertex-wise correspondences to the template during reconstruction. In addition, V2C-Flow is the first approach for cortex reconstruction that models white matter and pial surfaces jointly, therefore avoiding intersections between them. Our comprehensive experiments on internal and external test data demonstrate that V2C-Flow results in cortical surfaces that are state-of-the-art in terms of accuracy. Moreover, we show that the established correspondences are more consistent than in FreeSurfer and that they can directly be utilized for cortex parcellation and group analyses of cortical thickness.\n    ",
        "primary_category": "eess.IV",
        "categories": [
            "cs.CV"
        ],
        "submitted_date": "23 Jan 2024",
        "last_revised_date": " "
    },
    "2401.13170": {
        "title": "CFMatch: Aligning Automated Answer Equivalence Evaluation with Expert Judgments For Open-Domain Question Answering",
        "authors": [
            "Zongxia Li",
            "Ishani Mondal",
            "Yijun Liang",
            "Huy Nghiem",
            "Jordan Boyd-Graber"
        ],
        "comments": "See arXiv:2402.11161",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "Question answering (QA) can only make progress if we know if an answer is correct, but for many of the most challenging and interesting QA examples, current evaluation metrics to determine answer equivalence (AE) often do not align with human judgments, particularly more verbose, free-form answers from large language models (LLM). There are two challenges: a lack of data and that models are too big: LLM-based scorers can correlate better with human judges, but this task has only been tested on limited QA datasets, and even when available, update of the model is limited because LLMs are large and often expensive. We rectify both of these issues by providing clear and consistent guidelines for evaluating AE in machine QA adopted from professional human QA contests. We also introduce a combination of standard evaluation and a more efficient, robust, and lightweight discriminate AE classifier-based matching method (CFMatch, smaller than 1 MB), trained and validated to more accurately evaluate answer correctness in accordance with adopted expert AE rules that are more aligned with human judgments.\n    ",
        "primary_category": "cs.CL",
        "categories": [],
        "submitted_date": "24 Jan 2024",
        "last_revised_date": " "
    },
    "2401.13172": {
        "title": "ADMap: Anti-disturbance framework for reconstructing online vectorized HD map",
        "authors": [
            "Haotian Hu",
            "Fanyi Wang",
            "Yaonong Wang",
            "Laifeng Hu",
            "Jingwei Xu",
            "Zhiwang Zhang"
        ],
        "comments": " ",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "In the field of autonomous driving, online high-definition (HD) map reconstruction is crucial for planning tasks. Recent research has developed several high-performance HD map reconstruction models to meet this necessity. However, the point sequences within the instance vectors may be jittery or jagged due to prediction bias, which can impact subsequent tasks. Therefore, this paper proposes the Anti-disturbance Map reconstruction framework (ADMap). To mitigate point-order jitter, the framework consists of three modules: Multi-Scale Perception Neck, Instance Interactive Attention (IIA), and Vector Direction Difference Loss (VDDL). By exploring the point-order relationships between and within instances in a cascading manner, the model can monitor the point-order prediction process more effectively. ADMap achieves state-of-the-art performance on the nuScenes and Argoverse2 datasets. Extensive results demonstrate its ability to produce stable and reliable map elements in complex and changing driving scenarios. Code and more demos are available at this https URL.\n    ",
        "primary_category": "cs.CV",
        "categories": [],
        "submitted_date": "24 Jan 2024",
        "last_revised_date": " "
    },
    "2401.13371": {
        "title": "SVARM-IQ: Efficient Approximation of Any-order Shapley Interactions through Stratification",
        "authors": [
            "Patrick Kolpaczki",
            "Maximilian Muschalik",
            "Fabian Fumagalli",
            "Barbara Hammer",
            "Eyke H\u00fcllermeier"
        ],
        "comments": " ",
        "subjects": "Computer Science and Game Theory (cs.GT)",
        "abstract": "Addressing the limitations of individual attribution scores via the Shapley value (SV), the field of explainable AI (XAI) has recently explored intricate interactions of features or data points. In particular, extensions of the SV, such as the Shapley Interaction Index (SII), have been proposed as a measure to still benefit from the axiomatic basis of the SV. However, similar to the SV, their exact computation remains computationally prohibitive. Hence, we propose with SVARM-IQ a sampling-based approach to efficiently approximate Shapley-based interaction indices of any order. SVARM-IQ can be applied to a broad class of interaction indices, including the SII, by leveraging a novel stratified representation. We provide non-asymptotic theoretical guarantees on its approximation quality and empirically demonstrate that SVARM-IQ achieves state-of-the-art estimation results in practical XAI scenarios on different model classes and application domains.\n    ",
        "primary_category": "cs.GT",
        "categories": [],
        "submitted_date": "24 Jan 2024",
        "last_revised_date": " "
    },
    "2401.13662": {
        "title": "The Definitive Guide to Policy Gradients in Deep Reinforcement Learning: Theory, Algorithms and Implementations",
        "authors": [
            "Matthias Lehmann"
        ],
        "comments": " ",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "In recent years, various powerful policy gradient algorithms have been proposed in deep reinforcement learning. While all these algorithms build on the Policy Gradient Theorem, the specific design choices differ significantly across algorithms. We provide a holistic overview of on-policy policy gradient algorithms to facilitate the understanding of both their theoretical foundations and their practical implementations. In this overview, we include a detailed proof of the continuous version of the Policy Gradient Theorem, convergence results and a comprehensive discussion of practical algorithms. We compare the most prominent algorithms on continuous control environments and provide insights on the benefits of regularization. All code is available at this https URL.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "24 Jan 2024",
        "last_revised_date": " "
    },
    "2401.13782": {
        "title": "Tweets to Citations: Unveiling the Impact of Social Media Influencers on AI Research Visibility",
        "authors": [
            "Iain Xie Weissburg",
            "Mehir Arora",
            "Xinyi Wang",
            "Liangming Pan",
            "William Yang Wang"
        ],
        "comments": "10 Pages, 14 Figures",
        "subjects": "Digital Libraries (cs.DL)",
        "abstract": "As the number of accepted papers at AI and ML conferences reaches into the thousands, it has become unclear how researchers access and read research publications. In this paper, we investigate the role of social media influencers in enhancing the visibility of machine learning research, particularly the citation counts of papers they share. We have compiled a comprehensive dataset of over 8,000 papers, spanning tweets from December 2018 to October 2023, alongside controls precisely matched by 9 key covariates. Our statistical and causal inference analysis reveals a significant increase in citations for papers endorsed by these influencers, with median citation counts 2-3 times higher than those of the control group. Additionally, the study delves into the geographic, gender, and institutional diversity of highlighted authors. Given these findings, we advocate for a responsible approach to curation, encouraging influencers to uphold the journalistic standard that includes showcasing diverse research topics, authors, and institutions.\n    ",
        "primary_category": "cs.DL",
        "categories": [
            "cs.AI",
            "cs.CL",
            "cs.CV",
            "cs.LG",
            "cs.SI"
        ],
        "submitted_date": "24 Jan 2024",
        "last_revised_date": " "
    },
    "2401.13919": {
        "title": "WebVoyager: Building an End-to-End Web Agent with Large Multimodal Models",
        "authors": [
            "Hongliang He",
            "Wenlin Yao",
            "Kaixin Ma",
            "Wenhao Yu",
            "Yong Dai",
            "Hongming Zhang",
            "Zhenzhong Lan",
            "Dong Yu"
        ],
        "comments": " ",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "The rapid advancement of large language models (LLMs) has led to a new era marked by the development of autonomous applications in real-world scenarios, which drives innovation in creating advanced web agents. Existing web agents typically only handle one input modality and are evaluated only in simplified web simulators or static web snapshots, greatly limiting their applicability in real-world scenarios. To bridge this gap, we introduce WebVoyager, an innovative Large Multimodal Model (LMM) powered web agent that can complete user instructions end-to-end by interacting with real-world websites. Moreover, we establish a new benchmark by compiling real-world tasks from 15 popular websites and introduce an automatic evaluation protocol leveraging multimodal understanding abilities of GPT-4V to evaluate open-ended web agents. We show that WebVoyager achieves a 59.1% task success rate on our benchmark, significantly surpassing the performance of both GPT-4 (All Tools) and the WebVoyager (text-only) setups, underscoring the exceptional capability of WebVoyager. The proposed automatic evaluation metric achieves 85.3% agreement with human judgment, indicating its effectiveness in providing reliable and accurate assessments of web agents.\n    ",
        "primary_category": "cs.CL",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "25 Jan 2024",
        "last_revised_date": " "
    },
    "2401.14028": {
        "title": "Comparison of modularity-based approaches for nodes clustering in hypergraphs",
        "authors": [
            "Veronica Poda",
            "Catherine Matias"
        ],
        "comments": " ",
        "subjects": "Social and Information Networks (cs.SI)",
        "abstract": "Statistical analysis and node clustering in hypergraphs constitute an emerging topic suffering from a lack of standardization. In contrast to the case of graphs, the concept of nodes' community in hypergraphs is not unique and encompasses various distinct situations. In this work, we conducted a comparative analysis of the performance of modularity-based methods for clustering nodes in binary hypergraphs. To address this, we begin by presenting, within a unified framework, the various hypergraph modularity criteria proposed in the literature, emphasizing their differences and respective focuses. Subsequently, we provide an overview of the state-of-the-art codes available to maximize hypergraph modularities for detecting node communities in binary hypergraphs. Through exploration of various simulation settings with controlled ground truth clustering, we offer a comparison of these methods using different quality measures, including true clustering recovery, running time, (local) maximization of the objective, and the number of clusters detected. Our contribution marks the first attempt to clarify the advantages and drawbacks of these newly available methods. This effort lays the foundation for a better understanding of the primary objectives of modularity-based node clustering methods for binary hypergraphs.\n    ",
        "primary_category": "cs.SI",
        "categories": [
            "math.CO",
            "physics.data-an",
            "stat.AP"
        ],
        "submitted_date": "25 Jan 2024",
        "last_revised_date": " "
    },
    "2401.14112": {
        "title": "FP6-LLM: Efficiently Serving Large Language Models Through FP6-Centric Algorithm-System Co-Design",
        "authors": [
            "Haojun Xia",
            "Zhen Zheng",
            "Xiaoxia Wu",
            "Shiyang Chen",
            "Zhewei Yao",
            "Stephen Youn",
            "Arash Bakhtiari",
            "Michael Wyatt",
            "Donglin Zhuang",
            "Zhongzhu Zhou",
            "Olatunji Ruwase",
            "Yuxiong He",
            "Shuaiwen Leon Song"
        ],
        "comments": "Adding URL link of the source code",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Six-bit quantization (FP6) can effectively reduce the size of large language models (LLMs) and preserve the model quality consistently across varied applications. However, existing systems do not provide Tensor Core support for FP6 quantization and struggle to achieve practical performance improvements during LLM inference. It is challenging to support FP6 quantization on GPUs due to (1) unfriendly memory access of model weights with irregular bit-width and (2) high runtime overhead of weight de-quantization. To address these problems, we propose TC-FPx, the first full-stack GPU kernel design scheme with unified Tensor Core support of float-point weights for various quantization bit-width. We integrate TC-FPx kernel into an existing inference system, providing new end-to-end support (called FP6-LLM) for quantized LLM inference, where better trade-offs between inference cost and model quality are achieved. Experiments show that FP6-LLM enables the inference of LLaMA-70b using only a single GPU, achieving 1.69x-2.65x higher normalized inference throughput than the FP16 baseline. The source code is publicly available at this https URL.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.AI",
            "cs.AR"
        ],
        "submitted_date": "25 Jan 2024",
        "last_revised_date": " "
    },
    "2401.14292": {
        "title": "Single and bi-layered 2-D acoustic soft tactile skin (AST2)",
        "authors": [
            "Vishnu Rajendran",
            "Simon Parsons",
            "Amir Ghalamzan E"
        ],
        "comments": "IEEE Robosoft conference 2024 (accepted)",
        "subjects": "Robotics (cs.RO)",
        "abstract": "This paper aims to present an innovative and cost-effective design for Acoustic Soft Tactile (AST) Skin, with the primary goal of significantly enhancing the accuracy of 2-D tactile feature estimation. The existing challenge lies in achieving precise tactile feature estimation, especially concerning contact geometry characteristics, using cost-effective solutions. We hypothesise that by harnessing acoustic energy through dedicated acoustic channels in 2 layers beneath the sensing surface and analysing amplitude modulation, we can effectively decode interactions on the sensory surface, thereby improving tactile feature estimation. Our approach involves the distinct separation of hardware components responsible for emitting and receiving acoustic signals, resulting in a modular and highly customizable skin design. Practical tests demonstrate the effectiveness of this novel design, achieving remarkable precision in estimating contact normal forces (MAE < 0.8 N), 2D contact localisation (MAE < 0.7 mm), and contact surface diameter (MAE < 0.3 mm). In conclusion, the AST skin, with its innovative design and modular architecture, successfully addresses the challenge of tactile feature estimation. The presented results showcase its ability to precisely estimate various tactile features, making it a practical and cost-effective solution for robotic applications.\n    ",
        "primary_category": "cs.RO",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "25 Jan 2024",
        "last_revised_date": " "
    },
    "2401.14304": {
        "title": "Constraint-Aware Mesh Refinement Method by Reachability Set Envelope of Curvature Bounded Paths",
        "authors": [
            "Juho Bae",
            "Ji Hoon Bai",
            "Byung-Yoon Lee",
            "Jun-Yong Lee"
        ],
        "comments": "Preprint submitted to Automatica",
        "subjects": "Systems and Control (eess.SY)",
        "abstract": "This paper presents an enhanced direct-method-based approach for the real-time solution of optimal control problems to handle path constraints, such as obstacles. The principal contributions of this work are twofold: first, the existing methods for constructing reachability sets in the literature are extended to derive the envelope of these sets, which determines the region swept by all feasible trajectories between adjacent sample points. Second, we propose a novel method to guarantee constraint violation-free between discrete states in two dimensions through mesh refinement approach. To illustrate the effectiveness of the proposed methodology, numerical simulations are conducted on real-time path planning for fixed-wing unmanned aerial vehicles.\n    ",
        "primary_category": "eess.SY",
        "categories": [],
        "submitted_date": "25 Jan 2024",
        "last_revised_date": " "
    },
    "2401.15030": {
        "title": "On the generalization capacity of neural networks during generic multimodal reasoning",
        "authors": [
            "Takuya Ito",
            "Soham Dan",
            "Mattia Rigotti",
            "James Kozloski",
            "Murray Campbell"
        ],
        "comments": "ICLR 2024",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "The advent of the Transformer has led to the development of large language models (LLM), which appear to demonstrate human-like capabilities. To assess the generality of this class of models and a variety of other base neural network architectures to multimodal domains, we evaluated and compared their capacity for multimodal generalization. We introduce a multimodal question-answer benchmark to evaluate three specific types of out-of-distribution (OOD) generalization performance: distractor generalization (generalization in the presence of distractors), systematic compositional generalization (generalization to new task permutations), and productive compositional generalization (generalization to more complex tasks structures). We found that across model architectures (e.g., RNNs, Transformers, Perceivers, etc.), models with multiple attention layers, or models that leveraged cross-attention mechanisms between input domains, fared better. Our positive results demonstrate that for multimodal distractor and systematic generalization, either cross-modal attention or models with deeper attention layers are key architectural features required to integrate multimodal inputs. On the other hand, neither of these architectural features led to productive generalization, suggesting fundamental limitations of existing architectures for specific types of multimodal generalization. These results demonstrate the strengths and limitations of specific architectural components underlying modern neural models for multimodal reasoning. Finally, we provide Generic COG (gCOG), a configurable benchmark with several multimodal generalization splits, for future studies to explore.\n    ",
        "primary_category": "cs.LG",
        "categories": [],
        "submitted_date": "26 Jan 2024",
        "last_revised_date": " "
    },
    "2401.15380": {
        "title": "Open-RadVLAD: Fast and Robust Radar Place Recognition",
        "authors": [
            "Matthew Gadd",
            "Paul Newman"
        ],
        "comments": "accepted at 2024 IEEE Radar Conference",
        "subjects": "Robotics (cs.RO)",
        "abstract": "Radar place recognition often involves encoding a live scan as a vector and matching this vector to a database in order to recognise that the vehicle is in a location that it has visited before. Radar is inherently robust to lighting or weather conditions, but place recognition with this sensor is still affected by: (1) viewpoint variation, i.e. translation and rotation, (2) sensor artefacts or \"noises\". For 360-degree scanning radar, rotation is readily dealt with by in some way aggregating across azimuths. Also, we argue in this work that it is more critical to deal with the richness of representation and sensor noises than it is to deal with translational invariance - particularly in urban driving where vehicles predominantly follow the same lane when repeating a route. In our method, for computational efficiency, we use only the polar representation. For partial translation invariance and robustness to signal noise, we use only a one-dimensional Fourier Transform along radial returns. We also achieve rotational invariance and a very discriminative descriptor space by building a vector of locally aggregated descriptors. Our method is more comprehensively tested than all prior radar place recognition work - over an exhaustive combination of all 870 pairs of trajectories from 30 Oxford Radar RobotCar Dataset sequences (each approximately 10 km). Code and detailed results are provided at this http URL, as an open implementation and benchmark for future work in this area. We achieve a median of 91.52% in Recall@1, outstripping the 69.55% for the only other open implementation, RaPlace, and at a fraction of its computational cost (relying on fewer integral transforms e.g. Radon, Fourier, and inverse Fourier).\n    ",
        "primary_category": "cs.RO",
        "categories": [
            "cs.CV"
        ],
        "submitted_date": "27 Jan 2024",
        "last_revised_date": " "
    },
    "2401.15422": {
        "title": "A Survey on Data Augmentation in Large Model Era",
        "authors": [
            "Yue Zhou",
            "Chenlu Guo",
            "Xu Wang",
            "Yi Chang",
            "Yuan Wu"
        ],
        "comments": "33 pages; this https URL",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Large models, encompassing large language and diffusion models, have shown exceptional promise in approximating human-level intelligence, garnering significant interest from both academic and industrial spheres. However, the training of these large models necessitates vast quantities of high-quality data, and with continuous updates to these models, the existing reservoir of high-quality data may soon be depleted. This challenge has catalyzed a surge in research focused on data augmentation methods. Leveraging large models, these data augmentation techniques have outperformed traditional approaches. This paper offers an exhaustive review of large model-driven data augmentation methods, adopting a comprehensive perspective. We begin by establishing a classification of relevant studies into three main categories: image augmentation, text augmentation, and paired data augmentation. Following this, we delve into various data post-processing techniques pertinent to large model-based data augmentation. Our discussion then expands to encompass the array of applications for these data augmentation methods within natural language processing, computer vision, and audio signal processing. We proceed to evaluate the successes and limitations of large model-based data augmentation across different scenarios. Concluding our review, we highlight prospective challenges and avenues for future exploration in the field of data augmentation. Our objective is to furnish researchers with critical insights, ultimately contributing to the advancement of more sophisticated large models. We consistently maintain the related open-source materials at: this https URL.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.CL",
            "cs.CV"
        ],
        "submitted_date": "27 Jan 2024",
        "last_revised_date": " "
    },
    "2401.15721": {
        "title": "A Study of Acquisition Functions for Medical Imaging Deep Active Learning",
        "authors": [
            "Bonaventure F. P. Dossou"
        ],
        "comments": "Best Poster Award at Deep Learning Indaba 2023 Conference",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "The Deep Learning revolution has enabled groundbreaking achievements in recent years. From breast cancer detection to protein folding, deep learning algorithms have been at the core of very important advancements. However, these modern advancements are becoming more and more data-hungry, especially on labeled data whose availability is scarce: this is even more prevalent in the medical context. In this work, we show how active learning could be very effective in data scarcity situations, where obtaining labeled data (or annotation budget is very limited). We compare several selection criteria (BALD, MeanSTD, and MaxEntropy) on the ISIC 2016 dataset. We also explored the effect of acquired pool size on the model's performance. Our results suggest that uncertainty is useful to the Melanoma detection task, and confirms the hypotheses of the author of the paper of interest, that \\textit{bald} performs on average better than other acquisition functions. Our extended analyses however revealed that all acquisition functions perform badly on the positive (cancerous) samples, suggesting exploitation of class unbalance, which could be crucial in real-world settings. We finish by suggesting future work directions that would be useful to improve this current work. The code of our implementation is open-sourced at \\url{this https URL}\n    ",
        "primary_category": "cs.CV",
        "categories": [
            "cs.AI",
            "cs.HC",
            "cs.LG"
        ],
        "submitted_date": "28 Jan 2024",
        "last_revised_date": " "
    },
    "2401.15861": {
        "title": "BPDec: Unveiling the Potential of Masked Language Modeling Decoder in BERT pretraining",
        "authors": [
            "Wen Liang",
            "Youzhi Liang"
        ],
        "comments": " ",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "BERT (Bidirectional Encoder Representations from Transformers) has revolutionized the field of natural language processing through its exceptional performance on numerous tasks. Yet, the majority of researchers have mainly concentrated on enhancements related to the model structure, such as relative position embedding and more efficient attention mechanisms. Others have delved into pretraining tricks associated with Masked Language Modeling, including whole word masking. DeBERTa introduced an enhanced decoder adapted for BERT's encoder model for pretraining, proving to be highly effective. We argue that the design and research around enhanced masked language modeling decoders have been underappreciated. In this paper, we propose several designs of enhanced decoders and introduce BPDec (BERT Pretraining Decoder), a novel method for modeling training. Typically, a pretrained BERT model is fine-tuned for specific Natural Language Understanding (NLU) tasks. In our approach, we utilize the original BERT model as the encoder, making only changes to the decoder without altering the encoder. This approach does not necessitate extensive modifications to the model's architecture and can be seamlessly integrated into existing fine-tuning pipelines and services, offering an efficient and effective enhancement strategy. Compared to other methods, while we also incur a moderate training cost for the decoder during the pretraining process, our approach does not introduce additional training costs during the fine-tuning phase. We test multiple enhanced decoder structures after pretraining and evaluate their performance on the GLUE benchmark. Our results demonstrate that BPDec, having only undergone subtle refinements to the model structure during pretraining, significantly enhances model performance without escalating the inference time and serving budget.\n    ",
        "primary_category": "cs.CL",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "29 Jan 2024",
        "last_revised_date": " "
    },
    "2401.16193": {
        "title": "Contributing Dimension Structure of Deep Feature for Coreset Selection",
        "authors": [
            "Zhijing Wan",
            "Zhixiang Wang",
            "Yuran Wang",
            "Zheng Wang",
            "Hongyuan Zhu",
            "Shin'ichi Satoh"
        ],
        "comments": "13 pages,11 figures, to be published in AAAI2024",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Coreset selection seeks to choose a subset of crucial training samples for efficient learning. It has gained traction in deep learning, particularly with the surge in training dataset sizes. Sample selection hinges on two main aspects: a sample's representation in enhancing performance and the role of sample diversity in averting overfitting. Existing methods typically measure both the representation and diversity of data based on similarity metrics, such as L2-norm. They have capably tackled representation via distribution matching guided by the similarities of features, gradients, or other information between data. However, the results of effectively diverse sample selection are mired in sub-optimality. This is because the similarity metrics usually simply aggregate dimension similarities without acknowledging disparities among the dimensions that significantly contribute to the final similarity. As a result, they fall short of adequately capturing diversity. To address this, we propose a feature-based diversity constraint, compelling the chosen subset to exhibit maximum diversity. Our key lies in the introduction of a novel Contributing Dimension Structure (CDS) metric. Different from similarity metrics that measure the overall similarity of high-dimensional features, our CDS metric considers not only the reduction of redundancy in feature dimensions, but also the difference between dimensions that contribute significantly to the final similarity. We reveal that existing methods tend to favor samples with similar CDS, leading to a reduced variety of CDS types within the coreset and subsequently hindering model performance. In response, we enhance the performance of five classical selection methods by integrating the CDS constraint. Our experiments on three datasets demonstrate the general effectiveness of the proposed method in boosting existing methods.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.DB"
        ],
        "submitted_date": "29 Jan 2024",
        "last_revised_date": " "
    },
    "2401.16337": {
        "title": "Curriculum-Based Reinforcement Learning for Quadrupedal Jumping: A Reference-free Design",
        "authors": [
            "Vassil Atanassov",
            "Jiatao Ding",
            "Jens Kober",
            "Ioannis Havoutis",
            "Cosimo Della Santina"
        ],
        "comments": "This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible. 10 pages, 12 figures",
        "subjects": "Robotics (cs.RO)",
        "abstract": "Deep reinforcement learning (DRL) has emerged as a promising solution to mastering explosive and versatile quadrupedal jumping skills. However, current DRL-based frameworks usually rely on pre-existing reference trajectories obtained by capturing animal motions or transferring experience from existing controllers. This work aims to prove that learning dynamic jumping is possible without relying on imitating a reference trajectory by leveraging a curriculum design. Starting from a vertical in-place jump, we generalize the learned policy to forward and diagonal jumps and, finally, we learn to jump across obstacles. Conditioned on the desired landing location, orientation, and obstacle dimensions, the proposed approach yields a wide range of omnidirectional jumping motions in real-world experiments. Particularly we achieve a 90cm forward jump, exceeding all previous records for similar robots reported in the existing literature. Additionally, the robot can reliably execute continuous jumping on soft grassy grounds, which is especially remarkable as such conditions were not included in the training stage.\nA supplementary video can be found on: this https URL. The code associated with this work can be found on: this https URL.\n    ",
        "primary_category": "cs.RO",
        "categories": [],
        "submitted_date": "29 Jan 2024",
        "last_revised_date": " "
    },
    "2401.16439": {
        "title": "Distribution-Specific Auditing For Subgroup Fairness",
        "authors": [
            "Daniel Hsu",
            "Jizhou Huang",
            "Brendan Juba"
        ],
        "comments": " ",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "We study the problem of auditing classifiers with the notion of statistical subgroup fairness. Kearns et al. (2018) has shown that the problem of auditing combinatorial subgroups fairness is as hard as agnostic learning. Essentially all work on remedying statistical measures of discrimination against subgroups assumes access to an oracle for this problem, despite the fact that no efficient algorithms are known for it. If we assume the data distribution is Gaussian, or even merely log-concave, then a recent line of work has discovered efficient agnostic learning algorithms for halfspaces. Unfortunately, the reduction of Kearns et al. was formulated in terms of weak, \"distribution-free\" learning, and thus did not establish a connection for families such as log-concave distributions.\nIn this work, we give positive and negative results on auditing for Gaussian distributions: On the positive side, we present an alternative approach to leverage these advances in agnostic learning and thereby obtain the first polynomial-time approximation scheme (PTAS) for auditing nontrivial combinatorial subgroup fairness: we show how to audit statistical notions of fairness over homogeneous halfspace subgroups when the features are Gaussian. On the negative side, we find that under cryptographic assumptions, no polynomial-time algorithm can guarantee any nontrivial auditing, even under Gaussian feature distributions, for general halfspace subgroups.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.CC",
            "cs.CY"
        ],
        "submitted_date": "27 Jan 2024",
        "last_revised_date": " "
    },
    "2401.16549": {
        "title": "Deep Learning for Multi-Label Learning: A Comprehensive Survey",
        "authors": [
            "Adane Nega Tarekegn",
            "Mohib Ullah",
            "Faouzi Alaya Cheikh"
        ],
        "comments": "21 pages, 12 figures, 5 tables",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Multi-label learning is a rapidly growing research area that aims to predict multiple labels from a single input data point. In the era of big data, tasks involving multi-label classification (MLC) or ranking present significant and intricate challenges, capturing considerable attention in diverse domains. Inherent difficulties in MLC include dealing with high-dimensional data, addressing label correlations, and handling partial labels, for which conventional methods prove ineffective. Recent years have witnessed a notable increase in adopting deep learning (DL) techniques to address these challenges more effectively in MLC. Notably, there is a burgeoning effort to harness the robust learning capabilities of DL for improved modelling of label dependencies and other challenges in MLC. However, it is noteworthy that comprehensive studies specifically dedicated to DL for multi-label learning are limited. Thus, this survey aims to thoroughly review recent progress in DL for multi-label learning, along with a summary of open research problems in MLC. The review consolidates existing research efforts in DL for MLC,including deep neural networks, transformers, autoencoders, and convolutional and recurrent architectures. Finally, the study presents a comparative analysis of the existing methods to provide insightful observations and stimulate future research directions in this domain.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.CV"
        ],
        "submitted_date": "29 Jan 2024",
        "last_revised_date": " "
    },
    "2401.17010": {
        "title": "Finetuning Large Language Models for Vulnerability Detection",
        "authors": [
            "Alexey Shestov",
            "Rodion Levichev",
            "Ravil Mussabayev",
            "Evgeny Maslov",
            "Anton Cheshkov",
            "Pavel Zadorozhny"
        ],
        "comments": " ",
        "subjects": "Cryptography and Security (cs.CR)",
        "abstract": "This paper presents the results of finetuning large language models (LLMs) for the task of detecting vulnerabilities in source code. We leverage WizardCoder, a recent improvement of the state-of-the-art LLM StarCoder, and adapt it for vulnerability detection through further finetuning. To accelerate training, we modify WizardCoder's training procedure, also we investigate optimal training regimes. For the imbalanced dataset with many more negative examples than positive, we also explore different techniques to improve classification performance. The finetuned WizardCoder model achieves improvement in ROC AUC and F1 measures on balanced and imbalanced vulnerability datasets over CodeBERT-like model, demonstrating the effectiveness of adapting pretrained LLMs for vulnerability detection in source code. The key contributions are finetuning the state-of-the-art code LLM, WizardCoder, increasing its training speed without the performance harm, optimizing the training procedure and regimes, handling class imbalance, and improving performance on difficult vulnerability detection datasets. This demonstrates the potential for transfer learning by finetuning large pretrained language models for specialized source code analysis tasks.\n    ",
        "primary_category": "cs.CR",
        "categories": [
            "cs.AI",
            "cs.LG"
        ],
        "submitted_date": "30 Jan 2024",
        "last_revised_date": " "
    },
    "2401.17644": {
        "title": "Towards Efficient and Reliable LLM Serving: A Real-World Workload Study",
        "authors": [
            "Yuxin Wang",
            "Yuhan Chen",
            "Zeyu Li",
            "Zhenheng Tang",
            "Rui Guo",
            "Xin Wang",
            "Qiang Wang",
            "Amelie Chi Zhou",
            "Xiaowen Chu"
        ],
        "comments": " ",
        "subjects": "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "abstract": "Large language models (LLMs), especially Generative Pretrained Transformer (GPT) models, have significantly advanced in the industry in recent years. However, these models' broader development faces considerable challenges due to high operational and deployment costs. This has led to active research in improving the hardware efficiency of LLMs. Yet, the characteristics of real-world LLM workloads are often overlooked in current optimizations of LLM serving systems. In this work, the absence of reliable workload data for evaluating LLM serving systems impacts the quality of service (QoS) and reliability in industrial deployments. This paper introduces the first real-world trace dataset of LLM serving workloads, detailing user, system, and LLM behaviors. We analyze this trace, highlighting burstiness, request and response distributions, and focusing on the reliability of GPT services. Based on this, we have developed a benchmark suite that reflects our dataset's workload patterns, enabling performance evaluation of serving systems. This suite captures the core patterns of workload distributions, allowing for precise scaling of the workload dataset to match system sizes. Our evaluation uncovers a previously unrecognized vulnerability of LLM serving systems to short-term burstiness, particularly in common workload scenarios. We observe that GPU memory limitations, caused by the fluctuating nature of burstiness, lead to significant performance degradation in existing LLM serving systems. Beyond benchmarking, understanding these patterns is valuable for optimizing LLM workload management, enabling elastic hardware resource adjustments to varying workloads. To encourage further research, we have made the dataset and benchmark suite publicly available at this https URL.\n    ",
        "primary_category": "cs.DC",
        "categories": [
            "cs.PF"
        ],
        "submitted_date": "31 Jan 2024",
        "last_revised_date": " "
    },
    "2401.18018": {
        "title": "On Prompt-Driven Safeguarding for Large Language Models",
        "authors": [
            "Chujie Zheng",
            "Fan Yin",
            "Hao Zhou",
            "Fandong Meng",
            "Jie Zhou",
            "Kai-Wei Chang",
            "Minlie Huang",
            "Nanyun Peng"
        ],
        "comments": " ",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Prepending model inputs with safety prompts is a common practice for safeguarding large language models (LLMs) from complying with queries that contain harmful intents. However, the working mechanisms of safety prompts have not been revealed yet, which hinders the potential for automatically optimizing them to improve LLM safety. To this end, we investigate the impact of safety prompts from the perspective of model representations. We find that in models' representation space, harmful and harmless queries can be largely distinguished, but this is not noticeably enhanced by safety prompts. Instead, the queries' representations are moved by safety prompts in similar directions where models become more prone to refusal (i.e., refusing to provide assistance) even when the queries are harmless. Inspired by these findings, we propose a method called DRO (Directed Representation Optimization) for automatic safety prompt optimization. It treats safety prompts as continuous, trainable embeddings and learns to move the representations of harmful/harmless queries along/opposite the direction in which the model's refusal probability increases. Experiments with eight LLMs on out-of-domain benchmarks demonstrate that DRO remarkably improves the safeguarding performance of human-crafted safety prompts and outperforms strong baselines, without compromising the general model capability.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.AI",
            "cs.CL"
        ],
        "submitted_date": "31 Jan 2024",
        "last_revised_date": " "
    },
    "2402.00128": {
        "title": "Real-time Traffic Object Detection for Autonomous Driving",
        "authors": [
            "Abdul Hannan Khan",
            "Syed Tahseen Raza Rizvi",
            "Andreas Dengel"
        ],
        "comments": "\\c{opyright} 20XX IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses, in any current or future media, including reprinting/republishing this material for advertising or promotional purposes, creating new collective works, for resale or redistribution to servers or lists, or reuse of any copyrighted component of this work in other works",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "With recent advances in computer vision, it appears that autonomous driving will be part of modern society sooner rather than later. However, there are still a significant number of concerns to address. Although modern computer vision techniques demonstrate superior performance, they tend to prioritize accuracy over efficiency, which is a crucial aspect of real-time applications. Large object detection models typically require higher computational power, which is achieved by using more sophisticated onboard hardware. For autonomous driving, these requirements translate to increased fuel costs and, ultimately, a reduction in mileage. Further, despite their computational demands, the existing object detectors are far from being real-time. In this research, we assess the robustness of our previously proposed, highly efficient pedestrian detector LSFM on well-established autonomous driving benchmarks, including diverse weather conditions and nighttime scenes. Moreover, we extend our LSFM model for general object detection to achieve real-time object detection in traffic scenes. We evaluate its performance, low latency, and generalizability on traffic object detection datasets. Furthermore, we discuss the inadequacy of the current key performance indicator employed by object detection systems in the context of autonomous driving and propose a more suitable alternative that incorporates real-time requirements.\n    ",
        "primary_category": "cs.CV",
        "categories": [],
        "submitted_date": "31 Jan 2024",
        "last_revised_date": " "
    },
    "2402.00321": {
        "title": "SmartCooper: Vehicular Collaborative Perception with Adaptive Fusion and Judger Mechanism",
        "authors": [
            "Yuang Zhang",
            "Haonan An",
            "Zhengru Fang",
            "Guowen Xu",
            "Yuan Zhou",
            "Xianhao Chen",
            "Yuguang Fang"
        ],
        "comments": " ",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "In recent years, autonomous driving has garnered significant attention due to its potential for improving road safety through collaborative perception among connected and autonomous vehicles (CAVs). However, time-varying channel variations in vehicular transmission environments demand dynamic allocation of communication resources. Moreover, in the context of collaborative perception, it is important to recognize that not all CAVs contribute valuable data, and some CAV data even have detrimental effects on collaborative perception. In this paper, we introduce SmartCooper, an adaptive collaborative perception framework that incorporates communication optimization and a judger mechanism to facilitate CAV data fusion. Our approach begins with optimizing the connectivity of vehicles while considering communication constraints. We then train a learnable encoder to dynamically adjust the compression ratio based on the channel state information (CSI). Subsequently, we devise a judger mechanism to filter the detrimental image data reconstructed by adaptive decoders. We evaluate the effectiveness of our proposed algorithm on the OpenCOOD platform. Our results demonstrate a substantial reduction in communication costs by 23.10\\% compared to the non-judger scheme. Additionally, we achieve a significant improvement on the average precision of Intersection over Union (AP@IoU) by 7.15\\% compared with state-of-the-art schemes.\n    ",
        "primary_category": "cs.CV",
        "categories": [],
        "submitted_date": "1 Feb 2024",
        "last_revised_date": " "
    },
    "2402.00330": {
        "title": "Night-Rider: Nocturnal Vision-aided Localization in Streetlight Maps Using Invariant Extended Kalman Filtering",
        "authors": [
            "Tianxiao Gao",
            "Mingle Zhao",
            "Chengzhong Xu",
            "Hui Kong"
        ],
        "comments": " ",
        "subjects": "Robotics (cs.RO)",
        "abstract": "Vision-aided localization for low-cost mobile robots in diverse environments has attracted widespread attention recently. Although many current systems are applicable in daytime environments, nocturnal visual localization is still an open problem owing to the lack of stable visual information. An insight from most nocturnal scenes is that the static and bright streetlights are reliable visual information for localization. Hence we propose a nocturnal vision-aided localization system in streetlight maps with a novel data association and matching scheme using object detection methods. We leverage the Invariant Extended Kalman Filter (InEKF) to fuse IMU, odometer, and camera measurements for consistent state estimation at night. Furthermore, a tracking recovery module is also designed for tracking failures. Experimental results indicate that our proposed system achieves accurate and robust localization with less than $0.2\\%$ relative error of trajectory length in four nocturnal environments.\n    ",
        "primary_category": "cs.RO",
        "categories": [],
        "submitted_date": "1 Feb 2024",
        "last_revised_date": " "
    },
    "2402.00712": {
        "title": "ChaosBench: A Multi-Channel, Physics-Based Benchmark for Subseasonal-to-Seasonal Climate Prediction",
        "authors": [
            "Juan Nathaniel",
            "Yongquan Qu",
            "Tung Nguyen",
            "Sungduk Yu",
            "Julius Busecke",
            "Aditya Grover",
            "Pierre Gentine"
        ],
        "comments": "45 pages, 39 figures",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Accurate prediction of climate in the subseasonal-to-seasonal scale is crucial for disaster readiness, reduced economic risk, and improved policy-making amidst climate change. Yet, S2S prediction remains challenging due to the chaotic nature of such system. At present, existing benchmarks for weather and climate applications, tend to (1) have shorter forecasting range of up-to 14 days, (2) do not include a wide range of operational baseline forecasts, and (3) lack physics-based constraints for explainability. Thus, we propose ChaosBench, a large-scale, multi-channel, physics-based benchmark for S2S prediction. ChaosBench has over 460K frames of real-world observations and simulations, each with 60 variable-channels and spanning for up-to 45 years. We also propose several physics-based, in addition to vision-based metrics, that enables for a more physically-consistent model. Furthermore, we include a diverse set of physics-based forecasts from 4 national weather agencies as baselines to our data-driven counterpart. We establish two tasks that vary in complexity: full and sparse dynamics prediction. Our benchmark is one of the first to perform large-scale evaluation on existing models including PanguWeather, FourCastNetV2, GraphCast, and ClimaX, and finds methods originally developed for weather-scale applications fails on S2S task: they perform much worse than just simply taking the long-term climatological averages. We release our benchmark code and datasets at this https URL.\n    ",
        "primary_category": "cs.CV",
        "categories": [
            "cs.CY"
        ],
        "submitted_date": "1 Feb 2024",
        "last_revised_date": " "
    },
    "2402.00752": {
        "title": "On the Error Analysis of 3D Gaussian Splatting and an Optimal Projection Strategy",
        "authors": [
            "Letian Huang",
            "Jiayang Bai",
            "Jie Guo",
            "Yuanqi Li",
            "Yanwen Guo"
        ],
        "comments": " ",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "3D Gaussian Splatting has garnered extensive attention and application in real-time neural rendering. Concurrently, concerns have been raised about the limitations of this technology in aspects such as point cloud storage, performance, and robustness in sparse viewpoints, leading to various improvements. However, there has been a notable lack of attention to the fundamental problem of projection errors introduced by the local affine approximation inherent in the splatting itself, and the consequential impact of these errors on the quality of photo-realistic rendering. This paper addresses the projection error function of 3D Gaussian Splatting, commencing with the residual error from the first-order Taylor expansion of the projection function. The analysis establishes a correlation between the error and the Gaussian mean position. Subsequently, leveraging function optimization theory, this paper analyzes the function's minima to provide an optimal projection strategy for Gaussian Splatting referred to Optimal Gaussian Splatting, which can accommodate a variety of camera models. Experimental validation further confirms that this projection methodology reduces artifacts, resulting in a more convincingly realistic rendering.\n    ",
        "primary_category": "cs.CV",
        "categories": [
            "cs.GR"
        ],
        "submitted_date": "1 Feb 2024",
        "last_revised_date": " "
    },
    "2402.00924": {
        "title": "The Fragile Nature of Road Transportation Systems",
        "authors": [
            "Linghang Sun",
            "Yifan Zhang",
            "Cristian Axenie",
            "Margherita Grossi",
            "Anastasios Kouvelas",
            "Michail A. Makridis"
        ],
        "comments": "30 pages, 11 figures",
        "subjects": "Systems and Control (eess.SY)",
        "abstract": "Major cities worldwide experience problems with the performance of their road transportation systems. The continuous increase in traffic demand presents a substantial challenge to the optimal operation of urban road networks and the efficiency of traffic control strategies. Although robust and resilient transportation systems have been extensively researched over the past decades, their performance under an ever-growing traffic demand can still be questionable. The operation of transportation systems is widely believed to display fragile property, i.e., the loss in performance increases exponentially with the linearly increasing magnitude of disruptions, which undermines their continuous operation. The risk engineering community is now embracing the novel concept of (anti-)fragility, which enables systems to learn from historical disruptions and exhibit improved performance as disruption levels reach unprecedented magnitudes. In this study, we demonstrate the fragile nature of road transportation systems when faced with either demand or supply disruptions. First, we conducted a rigorous mathematical analysis to theoretically establish the fragile nature of the systems. Subsequently, by taking into account real-world stochasticity, we implemented a numerical simulation with realistic network data to bridge the gap between the theoretical proof and the real-world operations, to study the impact of uncertainty on the fragile property of the systems. This work aims to help researchers better comprehend the necessity to explicitly consider antifragile design toward the application of future traffic control strategies, coping with constantly growing traffic demand and subsequent traffic accidents.\n    ",
        "primary_category": "eess.SY",
        "categories": [],
        "submitted_date": "1 Feb 2024",
        "last_revised_date": " "
    },
    "2402.01109": {
        "title": "Vaccine: Perturbation-aware Alignment for Large Language Model",
        "authors": [
            "Tiansheng Huang",
            "Sihao Hu",
            "Ling Liu"
        ],
        "comments": " ",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "The new paradigm of finetuning-as-a-service introduces a new attack surface for Large Language Models (LLMs): a few harmful data uploaded by users can easily trick the finetuning to produce an alignment-broken model. We conduct an empirical analysis and uncover a \\textit{harmful embedding drift} phenomenon, showing a probable cause of the alignment-broken effect. Inspired by our findings, we propose Vaccine, a perturbation-aware alignment technique to mitigate the security risk of users finetuning. The core idea of Vaccine is to produce invariant hidden embeddings by progressively adding crafted perturbation to them in the alignment phase. This enables the embeddings to withstand harmful perturbation from un-sanitized user data in the finetuning phase. Our results on open source mainstream LLMs (e.g., Llama2, Opt, Vicuna) demonstrate that Vaccine can boost the robustness of alignment against harmful prompts induced embedding drift while reserving reasoning ability towards benign prompts. Our code is available at \\url{this https URL}.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.CL"
        ],
        "submitted_date": "2 Feb 2024",
        "last_revised_date": " "
    },
    "2402.01244": {
        "title": "Short Systematic Codes for Correcting Random Edit Errors in DNA Storage",
        "authors": [
            "Serge Kas Hanna"
        ],
        "comments": "Minor text edits and additional simulation results",
        "subjects": "Information Theory (cs.IT)",
        "abstract": "DNA storage faces challenges in ensuring data reliability in the presence of edit errors -- deletions, insertions, and substitutions -- that occur randomly during various phases of the storage process. Current limitations in DNA synthesis technology also require the use of short DNA sequences, highlighting the particular need for short edit-correcting codes. Motivated by these factors, we introduce a systematic code designed to correct random edits while adhering to typical length constraints in DNA storage. We evaluate the performance of the code through simulations and assess its effectiveness within a DNA storage framework, revealing promising results.\n    ",
        "primary_category": "cs.IT",
        "categories": [],
        "submitted_date": "2 Feb 2024",
        "last_revised_date": " "
    },
    "2402.01368": {
        "title": "LIR: A Lightweight Baseline for Image Restoration",
        "authors": [
            "Dongqi Fan",
            "Ting Yue",
            "Xin Zhao",
            "Liang Chang"
        ],
        "comments": " ",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Recently, there have been significant advancements in Image Restoration based on CNN and transformer. However, the inherent characteristics of the Image Restoration task are often overlooked. Many works, instead, only focus on the basic block design and stack numerous such blocks to the model, leading to parameters redundant and computations unnecessary. Thus, the efficiency of the image restoration is hindered. In this paper, we propose a Lightweight Baseline for Image Restoration called LIR to efficiently reconstruct the image and remove degradations (blur, rain, noise, haze). First of all, LIR addresses the degradations existing in the local and global residual connections that are ignored by modern networks, through a simple structural design. Then, to achieve lightweight, a Lightweight Adaptive Attention (LAA) Block is introduced depending on the inherent characteristics of the Image Restoration, which is mainly composed of proposed Adaptive Filters and Attention Blocks. LAA is capable of adaptively sharpening contours, removing degradation, and capturing global information in various Image Restoration scenes in a computation-friendly manner. Extensive experiments demonstrate that our LIR achieves comparable performance to state-of-the-art models with fewer parameters and computations in certain tasks. In addition, it is worth noting that our LIR produces better visual results than state-of-the-art networks that are more in line with the human aesthetic.\n    ",
        "primary_category": "cs.CV",
        "categories": [],
        "submitted_date": "2 Feb 2024",
        "last_revised_date": " "
    },
    "2402.01431": {
        "title": "Approximate Control for Continuous-Time POMDPs",
        "authors": [
            "Yannick Eich",
            "Bastian Alt",
            "Heinz Koeppl"
        ],
        "comments": "To be published in AISTATS 2024",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "This work proposes a decision-making framework for partially observable systems in continuous time with discrete state and action spaces. As optimal decision-making becomes intractable for large state spaces we employ approximation methods for the filtering and the control problem that scale well with an increasing number of states. Specifically, we approximate the high-dimensional filtering distribution by projecting it onto a parametric family of distributions, and integrate it into a control heuristic based on the fully observable system to obtain a scalable policy. We demonstrate the effectiveness of our approach on several partially observed systems, including queueing systems and chemical reaction networks.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "eess.SY",
            "q-bio.QM"
        ],
        "submitted_date": "2 Feb 2024",
        "last_revised_date": " "
    },
    "2402.01440": {
        "title": "Few-Shot Learning on Graphs: from Meta-learning to Pre-training and Prompting",
        "authors": [
            "Xingtong Yu",
            "Yuan Fang",
            "Zemin Liu",
            "Yuxia Wu",
            "Zhihao Wen",
            "Jianyuan Bo",
            "Xinming Zhang",
            "Steven C.H. Hoi"
        ],
        "comments": " ",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Graph representation learning, a critical step in graph-centric tasks, has seen significant advancements. Earlier techniques often operate in an end-to-end setting, where performance heavily relies on the availability of ample labeled data. This constraint has spurred the emergence of few-shot learning on graphs, where only a few task-specific labels are available for each task. Given the extensive literature in this field, this survey endeavors to synthesize recent developments, provide comparative insights, and identify future directions. We systematically categorize existing studies into three major families: meta-learning approaches, pre-training approaches, and hybrid approaches, with a finer-grained classification in each family to aid readers in their method selection process. Within each category, we analyze the relationships among these methods and compare their strengths and limitations. Finally, we outline prospective future directions for few-shot learning on graphs to catalyze continued innovation in this field.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.AI",
            "cs.SI"
        ],
        "submitted_date": "2 Feb 2024",
        "last_revised_date": " "
    },
    "2402.01499": {
        "title": "Developing and Evaluating a Design Method for Positive Artificial Intelligence",
        "authors": [
            "Willem van der Maden",
            "Derek Lomas",
            "Paul Hekkert"
        ],
        "comments": " ",
        "subjects": "Artificial Intelligence (cs.AI)",
        "abstract": "As artificial intelligence (AI) continues advancing, ensuring positive societal impacts becomes critical, especially as AI systems become increasingly ubiquitous in various aspects of life. However, developing \"AI for good\" poses substantial challenges around aligning systems with complex human values. Presently, we lack mature methods for addressing these challenges. This article presents and evaluates the Positive AI design method aimed at addressing this gap. The method provides a human-centered process to translate wellbeing aspirations into concrete practices. First, we explain the method's four key steps: contextualizing, operationalizing, optimizing, and implementing wellbeing supported by continuous measurement for feedback cycles. We then present a multiple case study where novice designers applied the method, revealing strengths and weaknesses related to efficacy and usability. Next, an expert evaluation study assessed the quality of the resulting concepts, rating them moderately high for feasibility, desirability, and plausibility of achieving intended wellbeing benefits. Together, these studies provide preliminary validation of the method's ability to improve AI design, while surfacing areas needing refinement like developing support for complex steps. Proposed adaptations such as examples and evaluation heuristics could address weaknesses. Further research should examine sustained application over multiple projects. This human-centered approach shows promise for realizing the vision of 'AI for Wellbeing' that does not just avoid harm, but actively benefits humanity.\n    ",
        "primary_category": "cs.AI",
        "categories": [],
        "submitted_date": "2 Feb 2024",
        "last_revised_date": " "
    },
    "2402.01663": {
        "title": "Killer Apps: Low-Speed, Large-Scale AI Weapons",
        "authors": [
            "Philip Feldman",
            "Aaron Dant",
            "James R. Foulds"
        ],
        "comments": "10 pages with 10 pages of appendices. 3 Figures, 2 code listings",
        "subjects": "Computers and Society (cs.CY)",
        "abstract": "The accelerating advancements in Artificial Intelligence (AI) and Machine Learning (ML), highlighted by the development of cutting-edge Generative Pre-trained Transformer (GPT) models by organizations such as OpenAI, Meta, and Anthropic, present new challenges and opportunities in warfare and security. Much of the current focus is on AI's integration within weapons systems and its role in rapid decision-making in kinetic conflict. However, an equally important but often overlooked aspect is the potential of AI-based psychological manipulation at internet scales within the information domain. These capabilities could pose significant threats to individuals, organizations, and societies globally. This paper explores the concept of AI weapons, their deployment, detection, and potential countermeasures.\n    ",
        "primary_category": "cs.CY",
        "categories": [
            "cs.CR",
            "cs.LG"
        ],
        "submitted_date": "14 Jan 2024",
        "last_revised_date": " "
    },
    "2402.01719": {
        "title": "Measuring Moral Inconsistencies in Large Language Models",
        "authors": [
            "Vamshi Krishna Bonagiri",
            "Sreeram Vennam",
            "Manas Gaur",
            "Ponnurangam Kumaraguru"
        ],
        "comments": "Accepted at BlackBoxNLP 2023, Co-located with EMNLP 2023",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "A Large Language Model (LLM) is considered consistent if semantically equivalent prompts produce semantically equivalent responses. Despite recent advancements showcasing the impressive capabilities of LLMs in conversational systems, we show that even state-of-the-art LLMs are highly inconsistent in their generations, questioning their reliability. Prior research has tried to measure this with task-specific accuracy. However, this approach is unsuitable for moral scenarios, such as the trolley problem, with no \"correct\" answer. To address this issue, we propose a novel information-theoretic measure called Semantic Graph Entropy (SGE) to measure the consistency of an LLM in moral scenarios. We leverage \"Rules of Thumb\" (RoTs) to explain a model's decision-making strategies and further enhance our metric. Compared to existing consistency metrics, SGE correlates better with human judgments across five LLMs. In the future, we aim to investigate the root causes of LLM inconsistencies and propose improvements.\n    ",
        "primary_category": "cs.CL",
        "categories": [
            "cs.LG"
        ],
        "submitted_date": "26 Jan 2024",
        "last_revised_date": " "
    },
    "2402.01744": {
        "title": "Unveiling Molecular Moieties through Hierarchical Graph Explainability",
        "authors": [
            "Paolo Sortino",
            "Salvatore Contino",
            "Ugo Perricone",
            "Roberto Pirrone"
        ],
        "comments": " ",
        "subjects": "Quantitative Methods (q-bio.QM)",
        "abstract": "Background: Graph Neural Networks (GNN) have emerged in very recent years as a powerful tool for supporting in silico Virtual Screening. In this work we present a GNN which uses Graph Convolutional architectures to achieve very accurate multi-target screening. We also devised a hierarchical Explainable Artificial Intelligence (XAI) technique to catch information directly at atom, ring, and whole molecule level by leveraging the message passing mechanism. In this way, we find the most relevant moieties involved in bioactivity prediction. Results: We report a state-of-the-art GNN classifier on twenty Cyclin-dependent Kinase targets in support of VS. Our classifier outperforms previous SOTA approaches proposed by the authors. Moreover, a CDK1-only high-sensitivity version of the GNN has been designed to use our explainer in order to avoid the inherent bias of multi-class models. The hierarchical explainer has been validated by an expert chemist on 19 approved drugs on CDK1. Our explainer provided information in accordance to the docking analysis for 17 out of the 19 test drugs. Conclusion: Our approach is a valid support for shortening both the screening and the hit-to-lead phase. Detailed knowledge about the molecular substructures that play a role in the inhibitory action, can help the computational chemist to gain insights into the pharmacophoric function of the molecule also for repurposing purposes.\n    ",
        "primary_category": "q-bio.QM",
        "categories": [
            "cs.AI",
            "cs.LG",
            "q-bio.MN"
        ],
        "submitted_date": "29 Jan 2024",
        "last_revised_date": " "
    },
    "2402.02042": {
        "title": "Learning General Parameterized Policies for Infinite Horizon Average Reward Constrained MDPs via Primal-Dual Policy Gradient Algorithm",
        "authors": [
            "Qinbo Bai",
            "Washim Uddin Mondal",
            "Vaneet Aggarwal"
        ],
        "comments": "We fixed Lemma 6 in v2 which changed the final result",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "This paper explores the realm of infinite horizon average reward Constrained Markov Decision Processes (CMDP). To the best of our knowledge, this work is the first to delve into the regret and constraint violation analysis of average reward CMDPs with a general policy parametrization. To address this challenge, we propose a primal dual based policy gradient algorithm that adeptly manages the constraints while ensuring a low regret guarantee toward achieving a global optimal policy. In particular, we demonstrate that our proposed algorithm achieves $\\tilde{\\mathcal{O}}({T}^{4/5})$ objective regret and $\\tilde{\\mathcal{O}}({T}^{4/5})$ constraint violation bounds.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "3 Feb 2024",
        "last_revised_date": " "
    },
    "2402.02446": {
        "title": "LQER: Low-Rank Quantization Error Reconstruction for LLMs",
        "authors": [
            "Cheng Zhang",
            "Jianyi Cheng",
            "George A. Constantinides",
            "Yiren Zhao"
        ],
        "comments": " ",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Post-training quantization of Large Language Models (LLMs) is challenging. In this work, we introduce Low-rank Quantization Error Reduction (LQER), which combines quantization and low-rank approximation to recover the model capability. LQER leverages an activation-induced scale matrix to drive the singular value distribution of quantization error towards a desirable distribution, which enables nearly-lossless W4A8 quantization on various LLMs and downstream tasks without the need for knowledge distillation, grid search, or gradient-base iterative optimization. Unlike existing methods, the computation pattern of LQER eliminates the need for specialized Scatter and Gather processes to collect high-precision weights from irregular memory locations. Our W4A8 LLMs achieve near-lossless performance on six popular downstream tasks, while using 1.36$\\times$ fewer hardware resources than the leading state-of-the-art method. We will open-source our framework once the paper is accepted.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.CL"
        ],
        "submitted_date": "4 Feb 2024",
        "last_revised_date": " "
    },
    "2402.02564": {
        "title": "A Truly Joint Neural Architecture for Segmentation and Parsing",
        "authors": [
            "Danit Yshaayahu Levi",
            "Reut Tsarfaty"
        ],
        "comments": " ",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "Contemporary multilingual dependency parsers can parse a diverse set of languages, but for Morphologically Rich Languages (MRLs), performance is attested to be lower than other languages. The key challenge is that, due to high morphological complexity and ambiguity of the space-delimited input tokens, the linguistic units that act as nodes in the tree are not known in advance. Pre-neural dependency parsers for MRLs subscribed to the joint morpho-syntactic hypothesis, stating that morphological segmentation and syntactic parsing should be solved jointly, rather than as a pipeline where segmentation precedes parsing. However, neural state-of-the-art parsers to date use a strict pipeline. In this paper we introduce a joint neural architecture where a lattice-based representation preserving all morphological ambiguity of the input is provided to an arc-factored model, which then solves the morphological segmentation and syntactic parsing tasks at once. Our experiments on Hebrew, a rich and highly ambiguous MRL, demonstrate state-of-the-art performance on parsing, tagging and segmentation of the Hebrew section of UD, using a single model. This proposed architecture is LLM-based and language agnostic, providing a solid foundation for MRLs to obtain further performance improvements and bridge the gap with other languages.\n    ",
        "primary_category": "cs.CL",
        "categories": [
            "cs.AI",
            "cs.LG"
        ],
        "submitted_date": "4 Feb 2024",
        "last_revised_date": " "
    },
    "2402.02648": {
        "title": "Recursive Chain-of-Feedback Prevents Performance Degradation from Redundant Prompting",
        "authors": [
            "Jinwoo Ahn",
            "Kyuseung Shin"
        ],
        "comments": "Still Ongoing Work; 8 Pages; 2 Figures",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "Large Language Models (LLMs) frequently struggle with complex reasoning tasks, failing to construct logically sound steps towards the solution. In response to this behavior, users often try prompting the LLMs repeatedly in hopes of reaching a better response. This paper studies such repetitive behavior and its effect by defining a novel setting, Chain-of-Feedback (CoF). The setting takes questions that require multi-step reasoning as an input. Upon response, we repetitively prompt meaningless feedback (e.g. 'make another attempt') requesting additional trials. Surprisingly, our preliminary results show that repeated meaningless feedback gradually decreases the quality of the responses, eventually leading to a larger deviation from the intended outcome. To alleviate these troubles, we propose a novel method, Recursive Chain-of-Feedback (R-CoF). Following the logic of recursion in computer science, R-CoF recursively revises the initially incorrect response by breaking down each incorrect reasoning step into smaller individual problems. Our preliminary results show that majority of questions that LLMs fail to respond correctly can be answered using R-CoF without any sample data outlining the logical process.\n    ",
        "primary_category": "cs.CL",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "5 Feb 2024",
        "last_revised_date": " "
    },
    "2402.02694": {
        "title": "Description on IEEE ICME 2024 Grand Challenge: Semi-supervised Acoustic Scene Classification under Domain Shift",
        "authors": [
            "Jisheng Bai",
            "Mou Wang",
            "Haohe Liu",
            "Han Yin",
            "Yafei Jia",
            "Siwei Huang",
            "Yutong Du",
            "Dongzhe Zhang",
            "Dongyuan Shi",
            "Woon-Seng Gan",
            "Mark D. Plumbley",
            "Susanto Rahardja",
            "Bin Xiang",
            "Jianfeng Chen"
        ],
        "comments": " ",
        "subjects": "Audio and Speech Processing (eess.AS)",
        "abstract": "Acoustic scene classification (ASC) is a crucial research problem in computational auditory scene analysis, and it aims to recognize the unique acoustic characteristics of an environment. One of the challenges of the ASC task is the domain shift between training and testing data. Since 2018, ASC challenges have focused on the generalization of ASC models across different recording devices. Although this task, in recent years, has achieved substantial progress in device generalization, the challenge of domain shift between different geographical regions, involving discrepancies such as time, space, culture, and language, remains insufficiently explored at present. In addition, considering the abundance of unlabeled acoustic scene data in the real world, it is important to study the possible ways to utilize these unlabelled data. Therefore, we introduce the task Semi-supervised Acoustic Scene Classification under Domain Shift in the ICME 2024 Grand Challenge. We encourage participants to innovate with semi-supervised learning techniques, aiming to develop more robust ASC models under domain shift.\n    ",
        "primary_category": "eess.AS",
        "categories": [
            "cs.LG",
            "cs.SD"
        ],
        "submitted_date": "5 Feb 2024",
        "last_revised_date": " "
    },
    "2402.03181": {
        "title": "C-RAG: Certified Generation Risks for Retrieval-Augmented Language Models",
        "authors": [
            "Mintong Kang",
            "Nezihe Merve G\u00fcrel",
            "Ning Yu",
            "Dawn Song",
            "Bo Li"
        ],
        "comments": " ",
        "subjects": "Artificial Intelligence (cs.AI)",
        "abstract": "Despite the impressive capabilities of large language models (LLMs) across diverse applications, they still suffer from trustworthiness issues, such as hallucinations and misalignments. Retrieval-augmented language models (RAG) have been proposed to enhance the credibility of generations by grounding external knowledge, but the theoretical understandings of their generation risks remains unexplored. In this paper, we answer: 1) whether RAG can indeed lead to low generation risks, 2) how to provide provable guarantees on the generation risks of RAG and vanilla LLMs, and 3) what sufficient conditions enable RAG models to reduce generation risks. We propose C-RAG, the first framework to certify generation risks for RAG models. Specifically, we provide conformal risk analysis for RAG models and certify an upper confidence bound of generation risks, which we refer to as conformal generation risk. We also provide theoretical guarantees on conformal generation risks for general bounded risk functions under test distribution shifts. We prove that RAG achieves a lower conformal generation risk than that of a single LLM when the quality of the retrieval model and transformer is non-trivial. Our intensive empirical results demonstrate the soundness and tightness of our conformal generation risk guarantees across four widely-used NLP datasets on four state-of-the-art retrieval models.\n    ",
        "primary_category": "cs.AI",
        "categories": [
            "cs.CL",
            "cs.IR"
        ],
        "submitted_date": "5 Feb 2024",
        "last_revised_date": " "
    },
    "2402.03268": {
        "title": "Understanding the Reasoning Ability of Language Models From the Perspective of Reasoning Paths Aggregation",
        "authors": [
            "Xinyi Wang",
            "Alfonso Amayuelas",
            "Kexun Zhang",
            "Liangming Pan",
            "Wenhu Chen",
            "William Yang Wang"
        ],
        "comments": " ",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Pre-trained language models (LMs) are able to perform complex reasoning without explicit fine-tuning. To understand how pre-training with a next-token prediction objective contributes to the emergence of such reasoning capability, we propose that we can view an LM as deriving new conclusions by aggregating indirect reasoning paths seen at pre-training time. We found this perspective effective in two important cases of reasoning: logic reasoning with knowledge graphs (KGs) and math reasoning with math word problems (MWPs). More specifically, we formalize the reasoning paths as random walk paths on the knowledge/reasoning graphs. Analyses of learned LM distributions suggest that a weighted sum of relevant random walk path probabilities is a reasonable way to explain how LMs reason. Experiments and analysis on multiple KG and MWP datasets reveal the effect of training on random walk paths and suggest that augmenting unlabeled random walk reasoning paths can improve real-world multi-step reasoning performance. code: this https URL\n",
        "primary_category": "cs.LG",
        "categories": [
            "cs.AI",
            "cs.CL"
        ],
        "submitted_date": "5 Feb 2024",
        "last_revised_date": " "
    },
    "2402.03279": {
        "title": "Stepping into the Right Shoes: The Effects of User-Matched Avatar Ethnicity and Gender on Sense of Embodiment in Virtual Reality",
        "authors": [
            "Tiffany D. Do",
            "Camille Isabella Protko",
            "Ryan P. McMahan"
        ],
        "comments": "To appear in IEEE Transactions on Visualization and Computer Graphics",
        "subjects": "Human-Computer Interaction (cs.HC)",
        "abstract": "In many consumer virtual reality (VR) applications, users embody predefined characters that offer minimal customization options, frequently emphasizing storytelling over user choice. We explore whether matching a user's physical characteristics, specifically ethnicity and gender, with their virtual self-avatar affects their sense of embodiment in VR. We conducted a 2 x 2 within-subjects experiment (n=32) with a diverse user population to explore the impact of matching or not matching a user's self-avatar to their ethnicity and gender on their sense of embodiment. Our results indicate that matching the ethnicity of the user and their self-avatar significantly enhances sense of embodiment regardless of gender, extending across various aspects, including appearance, response, and ownership. We also found that matching gender significantly enhanced ownership, suggesting that this aspect is influenced by matching both ethnicity and gender. Interestingly, we found that matching ethnicity specifically affects self-location while matching gender specifically affects one's body ownership.\n    ",
        "primary_category": "cs.HC",
        "categories": [],
        "submitted_date": "5 Feb 2024",
        "last_revised_date": " "
    },
    "2402.03408": {
        "title": "A Survey on Effective Invocation Methods of Massive LLM Services",
        "authors": [
            "Can Wang",
            "Bolin Zhang",
            "Dianbo Sui",
            "Zhiying Tu",
            "Xiaoyu Liu",
            "Jiabao Kang"
        ],
        "comments": " ",
        "subjects": "Software Engineering (cs.SE)",
        "abstract": "Language models as a service (LMaaS) enable users to accomplish tasks without requiring specialized knowledge, simply by paying a service provider. However, numerous providers offer massive large language model (LLM) services with variations in latency, performance, and pricing. Consequently, constructing the cost-saving LLM services invocation strategy with low-latency and high-performance responses that meet specific task demands becomes a pressing challenge. This paper provides a comprehensive overview of the LLM services invocation methods. Technically, we give a formal definition of the problem of constructing effective invocation strategy in LMaaS and present the LLM services invocation framework. The framework classifies existing methods into four different components, including input abstract, semantic cache, solution design, and output enhancement, which can be freely combined with each other. Finally, we emphasize the open challenges that have not yet been well addressed in this task and shed light on future research.\n    ",
        "primary_category": "cs.SE",
        "categories": [
            "cs.DC"
        ],
        "submitted_date": "5 Feb 2024",
        "last_revised_date": " "
    },
    "2402.03496": {
        "title": "Can We Remove the Square-Root in Adaptive Gradient Methods? A Second-Order Perspective",
        "authors": [
            "Wu Lin",
            "Felix Dangel",
            "Runa Eschenhagen",
            "Juhan Bae",
            "Richard E. Turner",
            "Alireza Makhzani"
        ],
        "comments": "updated Sec. 3 & 4",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Adaptive gradient optimizers like Adam(W) are the default training algorithms for many deep learning architectures, such as transformers. Their diagonal preconditioner is based on the gradient outer product which is incorporated into the parameter update via a square root. While these methods are often motivated as approximate second-order methods, the square root represents a fundamental difference. In this work, we investigate how the behavior of adaptive methods changes when we remove the root, i.e. strengthen their second-order motivation. Surprisingly, we find that such square-root-free adaptive methods close the generalization gap to SGD on convolutional architectures, while maintaining their root-based counterpart's performance on transformers. The second-order perspective also has practical benefits for the development of adaptive methods with non-diagonal preconditioner. In contrast to root-based counterparts like Shampoo, they do not require numerically unstable matrix square roots and therefore work well in low precision, which we demonstrate empirically. This raises important questions regarding the currently overlooked role of adaptivity for the success of adaptive methods since the success is often attributed to sign descent induced by the root.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "math.OC"
        ],
        "submitted_date": "5 Feb 2024",
        "last_revised_date": " "
    },
    "2402.03659": {
        "title": "Learning to Generate Explainable Stock Predictions using Self-Reflective Large Language Models",
        "authors": [
            "Kelvin J.L. Koa",
            "Yunshan Ma",
            "Ritchie Ng",
            "Tat-Seng Chua"
        ],
        "comments": "WWW 2024",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Explaining stock predictions is generally a difficult task for traditional non-generative deep learning models, where explanations are limited to visualizing the attention weights on important texts. Today, Large Language Models (LLMs) present a solution to this problem, given their known capabilities to generate human-readable explanations for their decision-making process. However, the task of stock prediction remains challenging for LLMs, as it requires the ability to weigh the varying impacts of chaotic social texts on stock prices. The problem gets progressively harder with the introduction of the explanation component, which requires LLMs to explain verbally why certain factors are more important than the others. On the other hand, to fine-tune LLMs for such a task, one would need expert-annotated samples of explanation for every stock movement in the training set, which is expensive and impractical to scale. To tackle these issues, we propose our Summarize-Explain-Predict (SEP) framework, which utilizes a self-reflective agent and Proximal Policy Optimization (PPO) to let a LLM teach itself how to generate explainable stock predictions in a fully autonomous manner. The reflective agent learns how to explain past stock movements through self-reasoning, while the PPO trainer trains the model to generate the most likely explanations from input texts. The training samples for the PPO trainer are also the responses generated during the reflective process, which eliminates the need for human annotators. Using our SEP framework, we fine-tune a LLM that can outperform both traditional deep-learning and LLM methods in prediction accuracy and Matthews correlation coefficient for the stock classification task. To justify the generalization capability of our framework, we further test it on the portfolio construction task, and demonstrate its effectiveness through various portfolio metrics.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.CL",
            "q-fin.ST"
        ],
        "submitted_date": "6 Feb 2024",
        "last_revised_date": " "
    },
    "2402.03681": {
        "title": "RL-VLM-F: Reinforcement Learning from Vision Language Foundation Model Feedback",
        "authors": [
            "Yufei Wang",
            "Zhanyi Sun",
            "Jesse Zhang",
            "Zhou Xian",
            "Erdem Biyik",
            "David Held",
            "Zackory Erickson"
        ],
        "comments": " ",
        "subjects": "Robotics (cs.RO)",
        "abstract": "Reward engineering has long been a challenge in Reinforcement Learning (RL) research, as it often requires extensive human effort and iterative processes of trial-and-error to design effective reward functions. In this paper, we propose RL-VLM-F, a method that automatically generates reward functions for agents to learn new tasks, using only a text description of the task goal and the agent's visual observations, by leveraging feedbacks from vision language foundation models (VLMs). The key to our approach is to query these models to give preferences over pairs of the agent's image observations based on the text description of the task goal, and then learn a reward function from the preference labels, rather than directly prompting these models to output a raw reward score, which can be noisy and inconsistent. We demonstrate that RL-VLM-F successfully produces effective rewards and policies across various domains - including classic control, as well as manipulation of rigid, articulated, and deformable objects - without the need for human supervision, outperforming prior methods that use large pretrained models for reward generation under the same assumptions. Videos can be found on our project website: this https URL\n",
        "primary_category": "cs.RO",
        "categories": [
            "cs.AI",
            "cs.LG"
        ],
        "submitted_date": "6 Feb 2024",
        "last_revised_date": " "
    },
    "2402.03726": {
        "title": "Learning Granger Causality from Instance-wise Self-attentive Hawkes Processes",
        "authors": [
            "Dongxia Wu",
            "Tsuyoshi Id\u00e9",
            "Aur\u00e9lie Lozano",
            "Georgios Kollias",
            "Ji\u0159\u00ed Navr\u00e1til",
            "Naoki Abe",
            "Yi-An Ma",
            "Rose Yu"
        ],
        "comments": " ",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "We address the problem of learning Granger causality from asynchronous, interdependent, multi-type event sequences. In particular, we are interested in discovering instance-level causal structures in an unsupervised manner. Instance-level causality identifies causal relationships among individual events, providing more fine-grained information for decision-making. Existing work in the literature either requires strong assumptions, such as linearity in the intensity function, or heuristically defined model parameters that do not necessarily meet the requirements of Granger causality. We propose Instance-wise Self-Attentive Hawkes Processes (ISAHP), a novel deep learning framework that can directly infer the Granger causality at the event instance level. ISAHP is the first neural point process model that meets the requirements of Granger causality. It leverages the self-attention mechanism of the transformer to align with the principles of Granger causality. We empirically demonstrate that ISAHP is capable of discovering complex instance-level causal structures that cannot be handled by classical models. We also show that ISAHP achieves state-of-the-art performance in proxy tasks involving type-level causal discovery and instance-level event type prediction.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "stat.ML"
        ],
        "submitted_date": "6 Feb 2024",
        "last_revised_date": " "
    },
    "2402.03776": {
        "title": "Large Language Models As MOOCs Graders",
        "authors": [
            "Shahriar Golchin",
            "Nikhil Garuda",
            "Christopher Impey",
            "Matthew Wenger"
        ],
        "comments": "v1.3 preprint",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "Massive open online courses (MOOCs) unlock the doors to free education for anyone around the globe with access to a computer and the internet. Despite this democratization of learning, the massive enrollment in these courses means it is almost impossible for one instructor to assess every student's writing assignment. As a result, peer grading, often guided by a straightforward rubric, is the method of choice. While convenient, peer grading often falls short in terms of reliability and validity. In this study, using 18 distinct settings, we explore the feasibility of leveraging large language models (LLMs) to replace peer grading in MOOCs. Specifically, we focus on two state-of-the-art LLMs: GPT-4 and GPT-3.5, across three distinct courses: Introductory Astronomy, Astrobiology, and the History and Philosophy of Astronomy. To instruct LLMs, we use three different prompts based on a variant of the zero-shot chain-of-thought (Zero-shot-CoT) prompting technique: Zero-shot-CoT combined with instructor-provided correct answers; Zero-shot-CoT in conjunction with both instructor-formulated answers and rubrics; and Zero-shot-CoT with instructor-offered correct answers and LLM-generated rubrics. Our results show that Zero-shot-CoT, when integrated with instructor-provided answers and rubrics, produces grades that are more aligned with those assigned by instructors compared to peer grading. However, the History and Philosophy of Astronomy course proves to be more challenging in terms of grading as opposed to other courses. Finally, our study reveals a promising direction for automating grading systems for MOOCs, especially in subjects with well-defined rubrics.\n    ",
        "primary_category": "cs.CL",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "6 Feb 2024",
        "last_revised_date": " "
    },
    "2402.04140": {
        "title": "Advancing Legal Reasoning: The Integration of AI to Navigate Complexities and Biases in Global Jurisprudence with Semi-Automated Arbitration Processes (SAAPs)",
        "authors": [
            "Michael De'Shazer"
        ],
        "comments": " ",
        "subjects": "Artificial Intelligence (cs.AI)",
        "abstract": "This study consists of a novel approach toward the analysis of court judgments spanning five countries, including the United States, the United Kingdom, Rwanda, Sweden and Hong Kong. This study also explores the intersection of the latest advancements in artificial intelligence (AI) and legal analysis, emphasizing the role of AI (specifically generative AI) in identifying human biases and facilitating automated, valid, and coherent multisided argumentation of court judgments with the goal of ensuring consistent application of laws in and across various jurisdictions. By incorporating Advanced Language Models (ALMs) and a newly introduced human-AI collaborative framework, this paper seeks to analyze Grounded Theory-based research design with Advanced Language Models (ALMs) in the practice of law. SHIRLEY is the name of the AI-based application (built on top of OpenAI's GPT technology), focusing on detecting logical inconsistencies and biases across various legal decisions. SHIRLEY analysis is aggregated and is accompanied by a comparison-oriented AI-based application called SAM (also an ALM) to identify relative deviations in SHIRLEY bias detections. Further, a CRITIC is generated within semi-autonomous arbitration process via the ALM, SARA. A novel approach is introduced in the utilization of an AI arbitrator to critically evaluate biases and qualitative-in-nature nuances identified by the aforementioned AI applications (SAM in concert with SHIRLEY), based on the Hague Rules on Business and Human Rights Arbitration. This Semi-Automated Arbitration Process (SAAP) aims to uphold the integrity and fairness of legal judgments by ensuring a nuanced debate-resultant \"understanding\" through a hybrid system of AI and human-based collaborative analysis.\n    ",
        "primary_category": "cs.AI",
        "categories": [
            "cs.CY",
            "cs.HC"
        ],
        "submitted_date": "6 Feb 2024",
        "last_revised_date": " "
    },
    "2402.04584": {
        "title": "Troublemaker Learning for Low-Light Image Enhancement",
        "authors": [
            "Yinghao Song",
            "Zhiyuan Cao",
            "Wanhong Xiang",
            "Sifan Long",
            "Bo Yang",
            "Hongwei Ge",
            "Yanchun Liang",
            "Chunguo Wu"
        ],
        "comments": " ",
        "subjects": "Image and Video Processing (eess.IV)",
        "abstract": "Low-light image enhancement (LLIE) restores the color and brightness of underexposed images. Supervised methods suffer from high costs in collecting low/normal-light image pairs. Unsupervised methods invest substantial effort in crafting complex loss functions. We address these two challenges through the proposed TroubleMaker Learning (TML) strategy, which employs normal-light images as inputs for training. TML is simple: we first dim the input and then increase its brightness. TML is based on two core components. First, the troublemaker model (TM) constructs pseudo low-light images from normal images to relieve the cost of pairwise data. Second, the predicting model (PM) enhances the brightness of pseudo low-light images. Additionally, we incorporate an enhancing model (EM) to further improve the visual performance of PM outputs. Moreover, in LLIE tasks, characterizing global element correlations is important because more information on the same object can be captured. CNN cannot achieve this well, and self-attention has high time complexity. Accordingly, we propose Global Dynamic Convolution (GDC) with O(n) time complexity, which essentially imitates the partial calculation process of self-attention to formulate elementwise correlations. Based on the GDC module, we build the UGDC model. Extensive quantitative and qualitative experiments demonstrate that UGDC trained with TML can achieve competitive performance against state-of-the-art approaches on public datasets. The code is available at this https URL.\n    ",
        "primary_category": "eess.IV",
        "categories": [
            "cs.CV"
        ],
        "submitted_date": "7 Feb 2024",
        "last_revised_date": " "
    },
    "2402.04792": {
        "title": "Direct Language Model Alignment from Online AI Feedback",
        "authors": [
            "Shangmin Guo",
            "Biao Zhang",
            "Tianlin Liu",
            "Tianqi Liu",
            "Misha Khalman",
            "Felipe Llinares",
            "Alexandre Rame",
            "Thomas Mesnard",
            "Yao Zhao",
            "Bilal Piot",
            "Johan Ferret",
            "Mathieu Blondel"
        ],
        "comments": "18 pages, 9 figures, 4 tables",
        "subjects": "Artificial Intelligence (cs.AI)",
        "abstract": "Direct alignment from preferences (DAP) methods, such as DPO, have recently emerged as efficient alternatives to reinforcement learning from human feedback (RLHF), that do not require a separate reward model. However, the preference datasets used in DAP methods are usually collected ahead of training and never updated, thus the feedback is purely offline. Moreover, responses in these datasets are often sampled from a language model distinct from the one being aligned, and since the model evolves over training, the alignment phase is inevitably off-policy. In this study, we posit that online feedback is key and improves DAP methods. Our method, online AI feedback (OAIF), uses an LLM as annotator: on each training iteration, we sample two responses from the current model and prompt the LLM annotator to choose which one is preferred, thus providing online feedback. Despite its simplicity, we demonstrate via human evaluation in several tasks that OAIF outperforms both offline DAP and RLHF methods. We further show that the feedback leveraged in OAIF is easily controllable, via instruction prompts to the LLM annotator.\n    ",
        "primary_category": "cs.AI",
        "categories": [
            "cs.CL",
            "cs.HC"
        ],
        "submitted_date": "7 Feb 2024",
        "last_revised_date": " "
    },
    "2402.04921": {
        "title": "Is Two-shot All You Need? A Label-efficient Approach for Video Segmentation in Breast Ultrasound",
        "authors": [
            "Jiajun Zeng",
            "Dong Ni",
            "Ruobing Huang"
        ],
        "comments": "5 pages, 4 figure, 2 tables, accepted by ISBI 2024",
        "subjects": "Image and Video Processing (eess.IV)",
        "abstract": "Breast lesion segmentation from breast ultrasound (BUS) videos could assist in early diagnosis and treatment. Existing video object segmentation (VOS) methods usually require dense annotation, which is often inaccessible for medical datasets. Furthermore, they suffer from accumulative errors and a lack of explicit space-time awareness. In this work, we propose a novel two-shot training paradigm for BUS video segmentation. It not only is able to capture free-range space-time consistency but also utilizes a source-dependent augmentation scheme. This label-efficient learning framework is validated on a challenging in-house BUS video dataset. Results showed that it gained comparable performance to the fully annotated ones given only 1.9% training labels.\n    ",
        "primary_category": "eess.IV",
        "categories": [
            "cs.CV"
        ],
        "submitted_date": "7 Feb 2024",
        "last_revised_date": " "
    },
    "2402.05011": {
        "title": "Navigating Complexity: Toward Lossless Graph Condensation via Expanding Window Matching",
        "authors": [
            "Yuchen Zhang",
            "Tianle Zhang",
            "Kai Wang",
            "Ziyao Guo",
            "Yuxuan Liang",
            "Xavier Bresson",
            "Wei Jin",
            "Yang You"
        ],
        "comments": "Lossless graph condensation method",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Graph condensation aims to reduce the size of a large-scale graph dataset by synthesizing a compact counterpart without sacrificing the performance of Graph Neural Networks (GNNs) trained on it, which has shed light on reducing the computational cost for training GNNs. Nevertheless, existing methods often fall short of accurately replicating the original graph for certain datasets, thereby failing to achieve the objective of lossless condensation. To understand this phenomenon, we investigate the potential reasons and reveal that the previous state-of-the-art trajectory matching method provides biased and restricted supervision signals from the original graph when optimizing the condensed one. This significantly limits both the scale and efficacy of the condensed graph. In this paper, we make the first attempt toward \\textit{lossless graph condensation} by bridging the previously neglected supervision signals. Specifically, we employ a curriculum learning strategy to train expert trajectories with more diverse supervision signals from the original graph, and then effectively transfer the information into the condensed graph with expanding window matching. Moreover, we design a loss function to further extract knowledge from the expert trajectories. Theoretical analysis justifies the design of our method and extensive experiments verify its superiority across different datasets. Code is released at this https URL.\n    ",
        "primary_category": "cs.LG",
        "categories": [],
        "submitted_date": "7 Feb 2024",
        "last_revised_date": " "
    },
    "2402.05044": {
        "title": "SALAD-Bench: A Hierarchical and Comprehensive Safety Benchmark for Large Language Models",
        "authors": [
            "Lijun Li",
            "Bowen Dong",
            "Ruohui Wang",
            "Xuhao Hu",
            "Wangmeng Zuo",
            "Dahua Lin",
            "Yu Qiao",
            "Jing Shao"
        ],
        "comments": "fix institution typo",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "In the rapidly evolving landscape of Large Language Models (LLMs), ensuring robust safety measures is paramount. To meet this crucial need, we propose \\emph{SALAD-Bench}, a safety benchmark specifically designed for evaluating LLMs, attack, and defense methods. Distinguished by its breadth, SALAD-Bench transcends conventional benchmarks through its large scale, rich diversity, intricate taxonomy spanning three levels, and versatile functionalities.SALAD-Bench is crafted with a meticulous array of questions, from standard queries to complex ones enriched with attack, defense modifications and multiple-choice. To effectively manage the inherent complexity, we introduce an innovative evaluators: the LLM-based MD-Judge for QA pairs with a particular focus on attack-enhanced queries, ensuring a seamless, and reliable evaluation. Above components extend SALAD-Bench from standard LLM safety evaluation to both LLM attack and defense methods evaluation, ensuring the joint-purpose utility. Our extensive experiments shed light on the resilience of LLMs against emerging threats and the efficacy of contemporary defense tactics. Data and evaluator are released under this https URL.\n    ",
        "primary_category": "cs.CL",
        "categories": [
            "cs.AI",
            "cs.CR",
            "cs.LG"
        ],
        "submitted_date": "7 Feb 2024",
        "last_revised_date": " "
    },
    "2402.05300": {
        "title": "Multi-Player Resource-Sharing Games with Fair Reward Allocation",
        "authors": [
            "Mevan Wijewardena",
            "Michael. J Neely"
        ],
        "comments": " ",
        "subjects": "Computer Science and Game Theory (cs.GT)",
        "abstract": "This paper considers a multi-player resource-sharing game with a fair reward allocation model. Multiple players choose from a collection of resources. Each resource brings a random reward equally divided among the players who choose it. We consider two settings. The first setting is a one-slot game where the mean rewards of the resources are known to all the players, and the objective of player 1 is to maximize their worst-case expected utility. Certain special cases of this setting have explicit solutions. These cases provide interesting yet non-intuitive insights into the problem. The second setting is an online setting, where the game is played over a finite time horizon, where the mean rewards are unknown to the first player. Instead, the first player receives, as feedback, the rewards of the resources they chose after the action. We develop a novel Upper Confidence Bound (UCB) algorithm that minimizes the worst-case regret of the first player using the feedback received.\n    ",
        "primary_category": "cs.GT",
        "categories": [
            "math.OC"
        ],
        "submitted_date": "7 Feb 2024",
        "last_revised_date": " "
    },
    "2402.05448": {
        "title": "Minecraft-ify: Minecraft Style Image Generation with Text-guided Image Editing for In-Game Application",
        "authors": [
            "Bumsoo Kim",
            "Sanghyun Byun",
            "Yonghoon Jung",
            "Wonseop Shin",
            "Sareer UI Amin",
            "Sanghyun Seo"
        ],
        "comments": "2 pages, 2 figures. Accepted as Spotlight to NeurIPS 2023 Workshop on Machine Learning for Creativity and Design",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "In this paper, we first present the character texture generation system \\textit{Minecraft-ify}, specified to Minecraft video game toward in-game application. Ours can generate face-focused image for texture mapping tailored to 3D virtual character having cube manifold. While existing projects or works only generate texture, proposed system can inverse the user-provided real image, or generate average/random appearance from learned distribution. Moreover, it can be manipulated with text-guidance using StyleGAN and StyleCLIP. These features provide a more extended user experience with enlarged freedom as a user-friendly AI-tool. Project page can be found at this https URL\n",
        "primary_category": "cs.CV",
        "categories": [
            "cs.AI",
            "cs.GR",
            "cs.LG",
            "cs.MM"
        ],
        "submitted_date": "8 Feb 2024",
        "last_revised_date": " "
    },
    "2402.05493": {
        "title": "Investigating White-Box Attacks for On-Device Models",
        "authors": [
            "Mingyi Zhou",
            "Xiang Gao",
            "Jing Wu",
            "Kui Liu",
            "Hailong Sun",
            "Li Li"
        ],
        "comments": "Published in The International Conference on Software Engineering 2024 (ICSE'24)",
        "subjects": "Software Engineering (cs.SE)",
        "abstract": "Numerous mobile apps have leveraged deep learning capabilities. However, on-device models are vulnerable to attacks as they can be easily extracted from their corresponding mobile apps. Existing on-device attacking approaches only generate black-box attacks, which are far less effective and efficient than white-box strategies. This is because mobile deep learning frameworks like TFLite do not support gradient computing, which is necessary for white-box attacking algorithms. Thus, we argue that existing findings may underestimate the harmfulness of on-device attacks. To this end, we conduct a study to answer this research question: Can on-device models be directly attacked via white-box strategies? We first systematically analyze the difficulties of transforming the on-device model to its debuggable version, and propose a Reverse Engineering framework for On-device Models (REOM), which automatically reverses the compiled on-device TFLite model to the debuggable model. Specifically, REOM first transforms compiled on-device models into Open Neural Network Exchange format, then removes the non-debuggable parts, and converts them to the debuggable DL models format that allows attackers to exploit in a white-box setting. Our experimental results show that our approach is effective in achieving automated transformation among 244 TFLite models. Compared with previous attacks using surrogate models, REOM enables attackers to achieve higher attack success rates with a hundred times smaller attack perturbations. In addition, because the ONNX platform has plenty of tools for model format exchanging, the proposed method based on the ONNX platform can be adapted to other model formats. Our findings emphasize the need for developers to carefully consider their model deployment strategies, and use white-box methods to evaluate the vulnerability of on-device models.\n    ",
        "primary_category": "cs.SE",
        "categories": [
            "cs.AI",
            "cs.CR"
        ],
        "submitted_date": "8 Feb 2024",
        "last_revised_date": " "
    },
    "2402.05663": {
        "title": "Mesoscale Traffic Forecasting for Real-Time Bottleneck and Shockwave Prediction",
        "authors": [
            "Raphael Chekroun",
            "Han Wang",
            "Jonathan Lee",
            "Marin Toromanoff",
            "Sascha Hornauer",
            "Fabien Moutarde",
            "Maria Laura Delle Monache"
        ],
        "comments": " ",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Accurate real-time traffic state forecasting plays a pivotal role in traffic control research. In particular, the CIRCLES consortium project necessitates predictive techniques to mitigate the impact of data source delays. After the success of the MegaVanderTest experiment, this paper aims at overcoming the current system limitations and develop a more suited approach to improve the real-time traffic state estimation for the next iterations of the experiment. In this paper, we introduce the SA-LSTM, a deep forecasting method integrating Self-Attention (SA) on the spatial dimension with Long Short-Term Memory (LSTM) yielding state-of-the-art results in real-time mesoscale traffic forecasting. We extend this approach to multi-step forecasting with the n-step SA-LSTM, which outperforms traditional multi-step forecasting methods in the trade-off between short-term and long-term predictions, all while operating in real-time.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.AI",
            "cs.RO"
        ],
        "submitted_date": "8 Feb 2024",
        "last_revised_date": " "
    },
    "2402.05699": {
        "title": "Self-Alignment of Large Language Models via Monopolylogue-based Social Scene Simulation",
        "authors": [
            "Xianghe Pang",
            "Shuo Tang",
            "Rui Ye",
            "Yuxin Xiong",
            "Bolun Zhang",
            "Yanfeng Wang",
            "Siheng Chen"
        ],
        "comments": "36 pages, 9 figures",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "Aligning large language models (LLMs) with human values is imperative to mitigate potential adverse effects resulting from their misuse. Drawing from the sociological insight that acknowledging all parties' concerns is a key factor in shaping human values, this paper proposes a novel direction to align LLMs by themselves: social scene simulation. To achieve this, we present MATRIX, a novel social scene simulator that emulates realistic scenes around a user's input query, enabling the LLM to take social consequences into account before responding. MATRIX serves as a virtual rehearsal space, akin to a Monopolylogue, where the LLM performs diverse roles related to the query and practice by itself. To inject this alignment, we fine-tune the LLM with MATRIX-simulated data, ensuring adherence to human values without compromising inference speed. We theoretically show that the LLM with MATRIX outperforms Constitutional AI under mild assumptions. Finally, extensive experiments validate that our method outperforms over 10 baselines across 4 benchmarks. As evidenced by 875 user ratings, our tuned 13B-size LLM exceeds GPT-4 in aligning with human values. Our project page is available at this https URL.\n    ",
        "primary_category": "cs.CL",
        "categories": [
            "cs.AI",
            "cs.CY"
        ],
        "submitted_date": "8 Feb 2024",
        "last_revised_date": " "
    },
    "2402.06104": {
        "title": "Function Aligned Regression: A Method Explicitly Learns Functional Derivatives from Data",
        "authors": [
            "Dixian Zhu",
            "Livnat Jerby"
        ],
        "comments": "24 pages excluding references, 12 figures, 4 tables",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Regression is a fundamental task in machine learning that has garnered extensive attention over the past decades. The conventional approach for regression involves employing loss functions that primarily concentrate on aligning model prediction with the ground truth for each individual data sample, which, as we show, can result in sub-optimal prediction of the relationships between the different samples. Recent research endeavors have introduced novel perspectives by incorporating label similarity information to regression. However, a notable gap persists in these approaches when it comes to fully capturing the intricacies of the underlying ground truth function. In this work, we propose FAR (Function Aligned Regression) as a arguably better and more efficient solution to fit the underlying function of ground truth by capturing functional derivatives. We demonstrate the effectiveness of the proposed method practically on 2 synthetic datasets and on 8 extensive real-world tasks from 6 benchmark datasets with other 8 competitive baselines. The code is open-sourced at \\url{this https URL}.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "8 Feb 2024",
        "last_revised_date": " "
    },
    "2402.06649": {
        "title": "Replacing CAPTCHA with XNO micropayments",
        "authors": [
            "Sujanavan Tiruvayipati"
        ],
        "comments": " ",
        "subjects": "Cryptography and Security (cs.CR)",
        "abstract": "As technology and gadgets continue to evolve, the need for bot-friendly and user-friendly internet becomes increasingly critical. This work discusses a methodology for implementation and feasibility of replacing traditional CAPTCHA mechanisms with Nano(XNO) cryptocurrency micropayments as a win-win solution and leverages the decentralized and secure nature of cryptocurrencies to introduce a micropayment-based authentication system. This approach not only enhances security by adding a financial barrier for automated bots but also provides a more seamless and efficient user experience. The benefits of this approach include reducing the burden on users while creating a socio-economic model that incentivizes internet service providers and content creators, even when accessed by bots. Furthermore, the integration of XNO micropayments could potentially contribute to the broader adoption and acceptance of digital currencies in everyday online transactions.\n    ",
        "primary_category": "cs.CR",
        "categories": [],
        "submitted_date": "3 Feb 2024",
        "last_revised_date": " "
    },
    "2402.07388": {
        "title": "The Limits of Assumption-free Tests for Algorithm Performance",
        "authors": [
            "Yuetian Luo",
            "Rina Foygel Barber"
        ],
        "comments": " ",
        "subjects": "Statistics Theory (math.ST)",
        "abstract": "Algorithm evaluation and comparison are fundamental questions in machine learning and statistics -- how well does an algorithm perform at a given modeling task, and which algorithm performs best? Many methods have been developed to assess algorithm performance, often based around cross-validation type strategies, retraining the algorithm of interest on different subsets of the data and assessing its performance on the held-out data points. Despite the broad use of such procedures, the theoretical properties of these methods are not yet fully understood. In this work, we explore some fundamental limits for answering these questions with limited amounts of data. In particular, we make a distinction between two questions: how good is an algorithm $A$ at the problem of learning from a training set of size $n$, versus, how good is a particular fitted model produced by running $A$ on a particular training data set of size $n$?\nOur main results prove that, for any test that treats the algorithm $A$ as a ``black box'' (i.e., we can only study the behavior of $A$ empirically), there is a fundamental limit on our ability to carry out inference on the performance of $A$, unless the number of available data points $N$ is many times larger than the sample size $n$ of interest. (On the other hand, evaluating the performance of a particular fitted model is easy as long as a holdout data set is available -- that is, as long as $N-n$ is not too small.) We also ask whether an assumption of algorithmic stability might be sufficient to circumvent this hardness result. Surprisingly, we find that this is not the case: the same hardness result still holds for the problem of evaluating the performance of $A$, aside from a high-stability regime where fitted models are essentially nonrandom. Finally, we also establish similar hardness results for the problem of comparing multiple algorithms.\n    ",
        "primary_category": "math.ST",
        "categories": [
            "cs.LG",
            "stat.ML"
        ],
        "submitted_date": "12 Feb 2024",
        "last_revised_date": " "
    },
    "2402.07787": {
        "title": "Extensible Multi-Granularity Fusion Network for Aspect-based Sentiment Analysis",
        "authors": [
            "Xiaowei Zhao",
            "Yong Zhou",
            "Xiujuan Xu",
            "Yu Liu"
        ],
        "comments": "8 pages, 4 figures",
        "subjects": "Artificial Intelligence (cs.AI)",
        "abstract": "Aspect-based Sentiment Analysis (ABSA) evaluates sentiment expressions within a text to comprehend sentiment information. Previous studies integrated external knowledge, such as knowledge graphs, to enhance the semantic features in ABSA models. Recent research has examined the use of Graph Neural Networks (GNNs) on dependency and constituent trees for syntactic analysis. With the ongoing development of ABSA, more innovative linguistic and structural features are being incorporated (e.g. latent graph), but this also introduces complexity and confusion. As of now, a scalable framework for integrating diverse linguistic and structural features into ABSA does not exist. This paper presents the Extensible Multi-Granularity Fusion (EMGF) network, which integrates information from dependency and constituent syntactic, attention semantic , and external knowledge graphs. EMGF, equipped with multi-anchor triplet learning and orthogonal projection, efficiently harnesses the combined potential of each granularity feature and their synergistic interactions, resulting in a cumulative effect without additional computational expenses. Experimental findings on SemEval 2014 and Twitter datasets confirm EMGF's superiority over existing ABSA methods.\n    ",
        "primary_category": "cs.AI",
        "categories": [
            "cs.CL"
        ],
        "submitted_date": "12 Feb 2024",
        "last_revised_date": " "
    },
    "2402.07939": {
        "title": "UFO: A UI-Focused Agent for Windows OS Interaction",
        "authors": [
            "Chaoyun Zhang",
            "Liqun Li",
            "Shilin He",
            "Xu Zhang",
            "Bo Qiao",
            "Si Qin",
            "Minghua Ma",
            "Yu Kang",
            "Qingwei Lin",
            "Saravan Rajmohan",
            "Dongmei Zhang",
            "Qi Zhang"
        ],
        "comments": " ",
        "subjects": "Human-Computer Interaction (cs.HC)",
        "abstract": "We introduce UFO, an innovative UI-Focused agent to fulfill user requests tailored to applications on Windows OS, harnessing the capabilities of GPT-Vision. UFO employs a dual-agent framework to meticulously observe and analyze the graphical user interface (GUI) and control information of Windows applications. This enables the agent to seamlessly navigate and operate within individual applications and across them to fulfill user requests, even when spanning multiple applications. The framework incorporates a control interaction module, facilitating action grounding without human intervention and enabling fully automated execution. Consequently, UFO transforms arduous and time-consuming processes into simple tasks achievable solely through natural language commands. We conducted testing of UFO across 9 popular Windows applications, encompassing a variety of scenarios reflective of users' daily usage. The results, derived from both quantitative metrics and real-case studies, underscore the superior effectiveness of UFO in fulfilling user requests. To the best of our knowledge, UFO stands as the first UI agent specifically tailored for task completion within the Windows OS environment. The open-source code for UFO is available on this https URL.\n    ",
        "primary_category": "cs.HC",
        "categories": [
            "cs.AI",
            "cs.CL"
        ],
        "submitted_date": "8 Feb 2024",
        "last_revised_date": " "
    },
    "2402.08128": {
        "title": "Recursive Joint Simulation in Games",
        "authors": [
            "Vojtech Kovarik",
            "Caspar Oesterheld",
            "Vincent Conitzer"
        ],
        "comments": " ",
        "subjects": "Artificial Intelligence (cs.AI)",
        "abstract": "Game-theoretic dynamics between AI agents could differ from traditional human-human interactions in various ways. One such difference is that it may be possible to accurately simulate an AI agent, for example because its source code is known. Our aim is to explore ways of leveraging this possibility to achieve more cooperative outcomes in strategic settings. In this paper, we study an interaction between AI agents where the agents run a recursive joint simulation. That is, the agents first jointly observe a simulation of the situation they face. This simulation in turn recursively includes additional simulations (with a small chance of failure, to avoid infinite recursion), and the results of all these nested simulations are observed before an action is chosen. We show that the resulting interaction is strategically equivalent to an infinitely repeated version of the original game, allowing a direct transfer of existing results such as the various folk theorems.\n    ",
        "primary_category": "cs.AI",
        "categories": [
            "cs.GT"
        ],
        "submitted_date": "12 Feb 2024",
        "last_revised_date": " "
    },
    "2402.08208": {
        "title": "Inherent Diverse Redundant Safety Mechanisms for AI-based Software Elements in Automotive Applications",
        "authors": [
            "Mandar Pitale",
            "Alireza Abbaspour",
            "Devesh Upadhyay"
        ],
        "comments": "This article is accepted for the SAE WCX 2024 conference proceedings",
        "subjects": "Artificial Intelligence (cs.AI)",
        "abstract": "This paper explores the role and challenges of Artificial Intelligence (AI) algorithms, specifically AI-based software elements, in autonomous driving systems. These AI systems are fundamental in executing real-time critical functions in complex and high-dimensional environments. They handle vital tasks like multi-modal perception, cognition, and decision-making tasks such as motion planning, lane keeping, and emergency braking. A primary concern relates to the ability (and necessity) of AI models to generalize beyond their initial training data. This generalization issue becomes evident in real-time scenarios, where models frequently encounter inputs not represented in their training or validation data. In such cases, AI systems must still function effectively despite facing distributional or domain shifts. This paper investigates the risk associated with overconfident AI models in safety-critical applications like autonomous driving. To mitigate these risks, methods for training AI models that help maintain performance without overconfidence are proposed. This involves implementing certainty reporting architectures and ensuring diverse training data. While various distribution-based methods exist to provide safety mechanisms for AI models, there is a noted lack of systematic assessment of these methods, especially in the context of safety-critical automotive applications. Many methods in the literature do not adapt well to the quick response times required in safety-critical edge applications. This paper reviews these methods, discusses their suitability for safety-critical applications, and highlights their strengths and limitations. The paper also proposes potential improvements to enhance the safety and reliability of AI algorithms in autonomous vehicles in the context of rapid and accurate decision-making processes.\n    ",
        "primary_category": "cs.AI",
        "categories": [],
        "submitted_date": "13 Feb 2024",
        "last_revised_date": " "
    },
    "2402.08223": {
        "title": "The Limits of Price Discrimination Under Privacy Constraints",
        "authors": [
            "Alireza Fallah",
            "Michael I. Jordan",
            "Ali Makhdoumi",
            "Azarakhsh Malekian"
        ],
        "comments": " ",
        "subjects": "Theoretical Economics (econ.TH)",
        "abstract": "We consider a producer's problem of selling a product to a continuum of privacy-conscious consumers, where the producer can implement third-degree price discrimination, offering different prices to different market segments. In the absence of privacy constraints, Bergemann, Brooks, and Morris [2015] characterize the set of all possible consumer-producer utilities, showing that it is a triangle. We consider a privacy mechanism that provides a degree of protection by probabilistically masking each market segment, and we establish that the resultant set of all consumer-producer utilities forms a convex polygon, characterized explicitly as a linear mapping of a certain high-dimensional convex polytope into $\\mathbb{R}^2$. This characterization enables us to investigate the impact of the privacy mechanism on both producer and consumer utilities. In particular, we establish that the privacy constraint always hurts the producer by reducing both the maximum and minimum utility achievable. From the consumer's perspective, although the privacy mechanism ensures an increase in the minimum utility compared to the non-private scenario, interestingly, it may reduce the maximum utility. Finally, we demonstrate that increasing the privacy level does not necessarily intensify these effects. For instance, the maximum utility for the producer or the minimum utility for the consumer may exhibit nonmonotonic behavior in response to an increase of the privacy level.\n    ",
        "primary_category": "econ.TH",
        "categories": [
            "cs.GT"
        ],
        "submitted_date": "13 Feb 2024",
        "last_revised_date": " "
    },
    "2402.08640": {
        "title": "Forecasting high-impact research topics via machine learning on evolving knowledge graphs",
        "authors": [
            "Xuemei Gu",
            "Mario Krenn"
        ],
        "comments": "11 pages, 7 figures, Comments welcome!",
        "subjects": "Digital Libraries (cs.DL)",
        "abstract": "The exponential growth in scientific publications poses a severe challenge for human researchers. It forces attention to more narrow sub-fields, which makes it challenging to discover new impactful research ideas and collaborations outside one's own field. While there are ways to predict a scientific paper's future citation counts, they need the research to be finished and the paper written, usually assessing impact long after the idea was conceived. Here we show how to predict the impact of onsets of ideas that have never been published by researchers. For that, we developed a large evolving knowledge graph built from more than 21 million scientific papers. It combines a semantic network created from the content of the papers and an impact network created from the historic citations of papers. Using machine learning, we can predict the dynamic of the evolving network into the future with high accuracy, and thereby the impact of new research directions. We envision that the ability to predict the impact of new ideas will be a crucial component of future artificial muses that can inspire new impactful and interesting scientific ideas.\n    ",
        "primary_category": "cs.DL",
        "categories": [
            "cs.AI",
            "cs.LG"
        ],
        "submitted_date": "13 Feb 2024",
        "last_revised_date": " "
    },
    "2402.08939": {
        "title": "Premise Order Matters in Reasoning with Large Language Models",
        "authors": [
            "Xinyun Chen",
            "Ryan A. Chi",
            "Xuezhi Wang",
            "Denny Zhou"
        ],
        "comments": "Xinyun and Ryan contribute equally",
        "subjects": "Artificial Intelligence (cs.AI)",
        "abstract": "Large language models (LLMs) have accomplished remarkable reasoning performance in various domains. However, in the domain of reasoning tasks, we discover a frailty: LLMs are surprisingly brittle to the ordering of the premises, despite the fact that such ordering does not alter the underlying task. In particular, we observe that LLMs achieve the best performance when the premise order aligns with the context required in intermediate reasoning steps. For example, in deductive reasoning tasks, presenting the premises in the same order as the ground truth proof in the prompt (as opposed to random ordering) drastically increases the model's accuracy. We first examine the effect of premise ordering on deductive reasoning on a variety of LLMs, and our evaluation shows that permuting the premise order can cause a performance drop of over 30%. In addition, we release the benchmark R-GSM, based on GSM8K, to examine the ordering effect for mathematical problem-solving, and we again observe a significant drop in accuracy, relative to the original GSM8K benchmark.\n    ",
        "primary_category": "cs.AI",
        "categories": [
            "cs.CL"
        ],
        "submitted_date": "14 Feb 2024",
        "last_revised_date": " "
    },
    "2402.09164": {
        "title": "Less is More: Fewer Interpretable Region via Submodular Subset Selection",
        "authors": [
            "Ruoyu Chen",
            "Hua Zhang",
            "Siyuan Liang",
            "Jingzhi Li",
            "Xiaochun Cao"
        ],
        "comments": "Accepted to ICLR 2024 (Oral)",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Image attribution algorithms aim to identify important regions that are highly relevant to model decisions. Although existing attribution solutions can effectively assign importance to target elements, they still face the following challenges: 1) existing attribution methods generate inaccurate small regions thus misleading the direction of correct attribution, and 2) the model cannot produce good attribution results for samples with wrong predictions. To address the above challenges, this paper re-models the above image attribution problem as a submodular subset selection problem, aiming to enhance model interpretability using fewer regions. To address the lack of attention to local regions, we construct a novel submodular function to discover more accurate small interpretation regions. To enhance the attribution effect for all samples, we also impose four different constraints on the selection of sub-regions, i.e., confidence, effectiveness, consistency, and collaboration scores, to assess the importance of various subsets. Moreover, our theoretical analysis substantiates that the proposed function is in fact submodular. Extensive experiments show that the proposed method outperforms SOTA methods on two face datasets (Celeb-A and VGG-Face2) and one fine-grained dataset (CUB-200-2011). For correctly predicted samples, the proposed method improves the Deletion and Insertion scores with an average of 4.9% and 2.5% gain relative to HSIC-Attribution. For incorrectly predicted samples, our method achieves gains of 81.0% and 18.4% compared to the HSIC-Attribution algorithm in the average highest confidence and Insertion score respectively. The code is released at this https URL.\n    ",
        "primary_category": "cs.CV",
        "categories": [
            "cs.LG"
        ],
        "submitted_date": "14 Feb 2024",
        "last_revised_date": " "
    },
    "2402.09367": {
        "title": "Prediction of Activated Sludge Settling Characteristics from Microscopy Images with Deep Convolutional Neural Networks and Transfer Learning",
        "authors": [
            "Sina Borzooei",
            "Leonardo Scabini",
            "Gisele Miranda",
            "Saba Daneshgar",
            "Lukas Deblieck",
            "Piet De Langhe",
            "Odemir Bruno",
            "Bernard De Baets",
            "Ingmar Nopens",
            "Elena Torfs"
        ],
        "comments": "34 Pages, 8 figures",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Microbial communities play a key role in biological wastewater treatment processes. Activated sludge settling characteristics, for example, are affected by microbial community composition, varying by changes in operating conditions and influent characteristics of wastewater treatment plants (WWTPs). Timely assessment and prediction of changes in microbial composition leading to settling problems, such as filamentous bulking (FB), can prevent operational challenges, reductions in treatment efficiency, and adverse environmental impacts. This study presents an innovative computer vision-based approach to assess activated sludge-settling characteristics based on the morphological properties of flocs and filaments in microscopy images. Implementing the transfer learning of deep convolutional neural network (CNN) models, this approach aims to overcome the limitations of existing quantitative image analysis techniques. The offline microscopy image dataset was collected over two years, with weekly sampling at a full-scale industrial WWTP in Belgium. Multiple data augmentation techniques were employed to enhance the generalizability of the CNN models. Various CNN architectures, including Inception v3, ResNet18, ResNet152, ConvNeXt-nano, and ConvNeXt-S, were tested to evaluate their performance in predicting sludge settling characteristics. The sludge volume index was used as the final prediction variable, but the method can easily be adjusted to predict any other settling metric of choice. The results showed that the suggested CNN-based approach provides less labour-intensive, objective, and consistent assessments, while transfer learning notably minimises the training phase, resulting in a generalizable system that can be employed in real-time applications.\n    ",
        "primary_category": "cs.CV",
        "categories": [
            "cs.CE"
        ],
        "submitted_date": "14 Feb 2024",
        "last_revised_date": " "
    },
    "2402.09595": {
        "title": "Correctly Communicating Software: Distributed, Asynchronous, and Beyond (extended version)",
        "authors": [
            "Bas van den Heuvel"
        ],
        "comments": "PhD thesis",
        "subjects": "Logic in Computer Science (cs.LO)",
        "abstract": "Much of the software we use in everyday life consists of distributed components (running on separate cores or even computers) that collaborate through communication (by exchanging messages). It is crucial to develop robust methods that can give reliable guarantees about the behavior of such message-passing software. With a focus on session types as communication protocols and their foundations in logic, this thesis revolves around the following question: How can we push the boundaries of the logical foundations of session types (binary and multiparty), extending their expressiveness and applicability, while preserving fundamental correctness properties? In this context, this thesis studies several intertwined aspects of message-passing.\n    ",
        "primary_category": "cs.LO",
        "categories": [],
        "submitted_date": "14 Feb 2024",
        "last_revised_date": " "
    },
    "2402.09882": {
        "title": "Variability Modeling of Products, Processes, and Resources in Cyber-Physical Production Systems Engineering",
        "authors": [
            "Kristof Meixner",
            "Kevin Feichtinger",
            "Hafiyyan Sayyid Fadhlillah",
            "Sandra Greiner",
            "Hannes Marcher",
            "Rick Rabiser",
            "Stefan Biffl"
        ],
        "comments": "26 pages, 10 figures",
        "subjects": "Software Engineering (cs.SE)",
        "abstract": "Cyber-Physical Production Systems (CPPSs), such as automated car manufacturing plants, execute a configurable sequence of production steps to manufacture products from a product portfolio. In CPPS engineering, domain experts start with manually determining feasible production step sequences and resources based on implicit knowledge. This process is hard to reproduce and highly inefficient. In this paper, we present the Extended Iterative Process Sequence Exploration (eIPSE) approach to derive variability models for products, processes, and resources from a domain-specific description. To automate the integrated exploration and configuration process for a CPPS, we provide a toolchain which automatically reduces the configuration space and allows to generate CPPS artifacts, such as control code for resources. We evaluate the approach with four real-world use cases, including the generation of control code artifacts, and an observational user study to collect feedback from engineers with different backgrounds. The results confirm the usefulness of the eIPSE approach and accompanying prototype to straightforwardly configure a desired CPPS.\n    ",
        "primary_category": "cs.SE",
        "categories": [],
        "submitted_date": "15 Feb 2024",
        "last_revised_date": " "
    },
    "2402.09963": {
        "title": "Why are Sensitive Functions Hard for Transformers?",
        "authors": [
            "Michael Hahn",
            "Mark Rofin"
        ],
        "comments": "Fixed various errors",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Empirical studies have identified a range of learnability biases and limitations of transformers, such as a persistent difficulty in learning to compute simple formal languages such as PARITY, and a bias towards low-degree functions. However, theoretical understanding remains limited, with existing expressiveness theory either overpredicting or underpredicting realistic learning abilities. We prove that, under the transformer architecture, the loss landscape is constrained by the input-space sensitivity: Transformers whose output is sensitive to many parts of the input string inhabit isolated points in parameter space, leading to a low-sensitivity bias in generalization. We show theoretically and empirically that this theory unifies a broad array of empirical observations about the learning abilities and biases of transformers, such as their generalization bias towards low sensitivity and low degree, and difficulty in length generalization for PARITY. This shows that understanding transformers' inductive biases requires studying not just their in-principle expressivity, but also their loss landscape.\n    ",
        "primary_category": "cs.LG",
        "categories": [],
        "submitted_date": "15 Feb 2024",
        "last_revised_date": " "
    },
    "2402.10060": {
        "title": "Quantum Backtracking in Qrisp Applied to Sudoku Problems",
        "authors": [
            "Raphael Seidel",
            "Ren\u00e9 Zander",
            "Matic Petri\u010d",
            "Niklas Steinmann",
            "David Q. Liu",
            "Nikolay Tcholtchev",
            "Manfred Hauswirth"
        ],
        "comments": " ",
        "subjects": "Quantum Physics (quant-ph)",
        "abstract": "The quantum backtracking algorithm proposed by Ashley Montanaro raised considerable interest, as it provides a quantum speed-up for a large class of classical optimization algorithms. It does not suffer from Barren-Plateaus and transfers well into the fault-tolerant era, as it requires only a limited number of arbitrary angle gates. Despite its potential, the algorithm has seen limited implementation efforts, presumably due to its abstract formulation. In this work, we provide a detailed instruction on implementing the quantum step operator for arbitrary backtracking instances. For a single controlled diffuser of a binary backtracking tree with depth n, our implementation requires only $6n+14$ CX gates. We detail the process of constructing accept and reject oracles for Sudoku problems using our interface to quantum backtracking. The presented code is written using Qrisp, a high-level quantum programming language, making it executable on most current physical backends and simulators. Subsequently, we perform several simulator based experiments and demonstrate solving 4x4 Sudoku instances with up to 9 empty fields. This is, to the best of our knowledge, the first instance of a compilable implementation of this generality, marking a significant and exciting step forward in quantum software engineering.\n    ",
        "primary_category": "quant-ph",
        "categories": [
            "cs.DS",
            "cs.PL"
        ],
        "submitted_date": "15 Feb 2024",
        "last_revised_date": " "
    },
    "2402.10153": {
        "title": "Knowledge-Infused LLM-Powered Conversational Health Agent: A Case Study for Diabetes Patients",
        "authors": [
            "Mahyar Abbasian",
            "Zhongqi Yang",
            "Elahe Khatibi",
            "Pengfei Zhang",
            "Nitish Nagesh",
            "Iman Azimi",
            "Ramesh Jain",
            "Amir M. Rahmani"
        ],
        "comments": "4 pages, 3 figures, and 2 tables, conference paper",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "Effective diabetes management is crucial for maintaining health in diabetic patients. Large Language Models (LLMs) have opened new avenues for diabetes management, facilitating their efficacy. However, current LLM-based approaches are limited by their dependence on general sources and lack of integration with domain-specific knowledge, leading to inaccurate responses. In this paper, we propose a knowledge-infused LLM-powered conversational health agent (CHA) for diabetic patients. We customize and leverage the open-source openCHA framework, enhancing our CHA with external knowledge and analytical capabilities. This integration involves two key components: 1) incorporating the American Diabetes Association dietary guidelines and the Nutritionix information and 2) deploying analytical tools that enable nutritional intake calculation and comparison with the guidelines. We compare the proposed CHA with GPT4. Our evaluation includes 100 diabetes-related questions on daily meal choices and assessing the potential risks associated with the suggested diet. Our findings show that the proposed agent demonstrates superior performance in generating responses to manage essential nutrients.\n    ",
        "primary_category": "cs.CL",
        "categories": [],
        "submitted_date": "15 Feb 2024",
        "last_revised_date": " "
    },
    "2402.10192": {
        "title": "Multi-Excitation Projective Simulation with a Many-Body Physics Inspired Inductive Bias",
        "authors": [
            "Philip A. LeMaitre",
            "Marius Krumm",
            "Hans J. Briegel"
        ],
        "comments": "24 pages, 8 figures; Code repository at this https URL. Added figures and shortened computer maintenance section text for better readability",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "With the impressive progress of deep learning, applications relying on machine learning are increasingly being integrated into daily life. However, most deep learning models have an opaque, oracle-like nature making it difficult to interpret and understand their decisions. This problem led to the development of the field known as eXplainable Artificial Intelligence (XAI). One method in this field known as Projective Simulation (PS) models a chain-of-thought as a random walk of a particle on a graph with vertices that have concepts attached to them. While this description has various benefits, including the possibility of quantization, it cannot be naturally used to model thoughts that combine several concepts simultaneously. To overcome this limitation, we introduce Multi-Excitation Projective Simulation (mePS), a generalization that considers a chain-of-thought to be a random walk of several particles on a hypergraph. A definition for a dynamic hypergraph is put forward to describe the agent's training history along with applications to AI and hypergraph visualization. An inductive bias inspired by the remarkably successful few-body interaction models used in quantum many-body physics is formalized for our classical mePS framework and employed to tackle the exponential complexity associated with naive implementations of hypergraphs. We prove that our inductive bias reduces the complexity from exponential to polynomial, with the exponent representing the cutoff on how many particles can interact. We numerically apply our method to two toy environments and a more complex scenario modelling the diagnosis of a broken computer. These environments demonstrate the resource savings provided by an appropriate choice of inductive bias, as well as showcasing aspects of interpretability. A quantum model for mePS is also briefly outlined and some future directions for it are discussed.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.AI",
            "cs.DM",
            "quant-ph"
        ],
        "submitted_date": "15 Feb 2024",
        "last_revised_date": " "
    },
    "2402.10401": {
        "title": "ManiFPT: Defining and Analyzing Fingerprints of Generative Models",
        "authors": [
            "Hae Jin Song",
            "Mahyar Khayatkhoei",
            "Wael AbdAlmageed"
        ],
        "comments": "Accepted to CVPR 2024",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Recent works have shown that generative models leave traces of their underlying generative process on the generated samples, broadly referred to as fingerprints of a generative model, and have studied their utility in detecting synthetic images from real ones. However, the extend to which these fingerprints can distinguish between various types of synthetic image and help identify the underlying generative process remain under-explored. In particular, the very definition of a fingerprint remains unclear, to our knowledge. To that end, in this work, we formalize the definition of artifact and fingerprint in generative models, propose an algorithm for computing them in practice, and finally study its effectiveness in distinguishing a large array of different generative models. We find that using our proposed definition can significantly improve the performance on the task of identifying the underlying generative process from samples (model attribution) compared to existing methods. Additionally, we study the structure of the fingerprints, and observe that it is very predictive of the effect of different design choices on the generative process.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.CV"
        ],
        "submitted_date": "16 Feb 2024",
        "last_revised_date": " "
    },
    "2402.10487": {
        "title": "Random Projection Layers for Multidimensional Time Series Forecasting",
        "authors": [
            "Chin-Chia Michael Yeh",
            "Yujie Fan",
            "Xin Dai",
            "Vivian Lai",
            "Prince Osei Aboagye",
            "Junpeng Wang",
            "Huiyuan Chen",
            "Yan Zheng",
            "Zhongfang Zhuang",
            "Liang Wang",
            "Wei Zhang"
        ],
        "comments": " ",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "All-Multi-Layer Perceptron (all-MLP) mixer models have been shown to be effective for time series forecasting problems. However, when such a model is applied to high-dimensional time series (e.g., the time series in a spatial-temporal dataset), its performance is likely to degrade due to overfitting issues. In this paper, we propose an all-MLP time series forecasting architecture, referred to as RPMixer. Our method leverages the ensemble-like behavior of deep neural networks, where each individual block within the network acts like a base learner in an ensemble model, especially when identity mapping residual connections are incorporated. By integrating random projection layers into our model, we increase the diversity among the blocks' outputs, thereby enhancing the overall performance of RPMixer. Extensive experiments conducted on large-scale spatial-temporal forecasting benchmark datasets demonstrate that our proposed method outperforms alternative methods, including both spatial-temporal graph models and general forecasting models.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "16 Feb 2024",
        "last_revised_date": " "
    },
    "2402.10991": {
        "title": "Enhancing Convergence in Federated Learning: A Contribution-Aware Asynchronous Approach",
        "authors": [
            "Changxin Xu",
            "Yuxin Qiao",
            "Zhanxin Zhou",
            "Fanghao Ni",
            "Jize Xiong"
        ],
        "comments": "5 pages, 1 figures",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Federated Learning (FL) is a distributed machine learning paradigm that allows clients to train models on their data while preserving their privacy. FL algorithms, such as Federated Averaging (FedAvg) and its variants, have been shown to converge well in many scenarios. However, these methods require clients to upload their local updates to the server in a synchronous manner, which can be slow and unreliable in realistic FL settings. To address this issue, researchers have developed asynchronous FL methods that allow clients to continue training on their local data using a stale global model. However, most of these methods simply aggregate all of the received updates without considering their relative contributions, which can slow down convergence. In this paper, we propose a contribution-aware asynchronous FL method that takes into account the staleness and statistical heterogeneity of the received updates. Our method dynamically adjusts the contribution of each update based on these factors, which can speed up convergence compared to existing methods.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "16 Feb 2024",
        "last_revised_date": " "
    },
    "2402.11027": {
        "title": "MITS: A Quantum Sorcerer Stone For Designing Surface Codes",
        "authors": [
            "Avimita Chatterjee",
            "Debarshi Kundu",
            "Swaroop Ghosh"
        ],
        "comments": "7 pages, 6 figures, 2 tables",
        "subjects": "Quantum Physics (quant-ph)",
        "abstract": "In the evolving landscape of quantum computing, determining the most efficient parameters for Quantum Error Correction (QEC) is paramount. Various quantum computers possess varied types and amounts of physical noise. Traditionally, simulators operate in a forward paradigm, taking parameters such as distance, rounds, and physical error to output a logical error rate. However, usage of maximum distance and rounds of the surface code might waste resources. An approach that relies on trial and error to fine-tune QEC code parameters using simulation tools like STIM can be exceedingly time-consuming. Additionally, daily fluctuations in quantum error rates can alter the ideal QEC settings needed. As a result, there is a crucial need for an automated solution that can rapidly determine the appropriate QEC parameters tailored to the current conditions. To bridge this gap, we present MITS, a tool designed to reverse-engineer the well-known simulator STIM for designing QEC codes. MITS accepts the specific noise model of a quantum computer and a target logical error rate as input and outputs the optimal surface code rounds and code distances. This guarantees minimal qubit and gate usage, harmonizing the desired logical error rate with the existing hardware limitations on qubit numbers and gate fidelity. We explored and compared multiple heuristics and machine learning models for training/designing MITS and concluded that XGBoost and Random Forest regression were most effective, with Pearson correlation coefficients of 0.98 and 0.96 respectively.\n    ",
        "primary_category": "quant-ph",
        "categories": [
            "cs.ET"
        ],
        "submitted_date": "16 Feb 2024",
        "last_revised_date": " "
    },
    "2402.11050": {
        "title": "Adaptive Constellation Multiple Access for Beyond 5G Wireless Systems",
        "authors": [
            "Indu L. Shakya",
            "Falah H. Ali"
        ],
        "comments": "5 pages, 6 figures, Submission to an IEEE Journal",
        "subjects": "Information Theory (cs.IT)",
        "abstract": "We propose a novel nonorthogonal multiple access (NOMA) scheme referred as adaptive constellation multiple access (ACMA) which addresses key limitations of existing NOMA schemes for beyond 5G wireless systems. Unlike the latter, that are often constrained in choices of allocation of power, modulations and phases to allow enough separation of clusters from users combined signals, ACMA is power, modulation and phase agnostic forming unified constellations instead where distances of all possible neighbouring points are optimized. It includes an algorithm at basestation (BS) calculating phase offsets for users signals such that, when combined, it gives best minimum Euclidean distance of points from all possibilities. The BS adaptively changes the phase offsets whenever system parameters change. We also propose an enhanced receiver using a modified maximum likelihood (MML) method that dynamically exploits information from the BS to blindly estimate correct phase offsets and exploit them to enhance data rate and error performances. Superiority of this scheme, which may also be referred to as AC NOMA, is verified through extensive analyses and simulations.\n    ",
        "primary_category": "cs.IT",
        "categories": [
            "eess.SP"
        ],
        "submitted_date": "16 Feb 2024",
        "last_revised_date": " "
    },
    "2402.11094": {
        "title": "Word Embeddings Revisited: Do LLMs Offer Something New?",
        "authors": [
            "Matthew Freestone",
            "Shubhra Kanti Karmaker Santu"
        ],
        "comments": "7 pages, 4 figures",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "Learning meaningful word embeddings is key to training a robust language model. The recent rise of Large Language Models (LLMs) has provided us with many new word/sentence/document embedding models. Although LLMs have shown remarkable advancement in various NLP tasks, it is still unclear whether the performance improvement is merely because of scale or whether underlying embeddings they produce significantly differ from classical encoding models like Sentence-BERT (SBERT) or Universal Sentence Encoder (USE). This paper systematically investigates this issue by comparing classical word embedding techniques against LLM-based word embeddings in terms of their latent vector semantics. Our results show that LLMs tend to cluster semantically related words more tightly than classical models. LLMs also yield higher average accuracy on the Bigger Analogy Test Set (BATS) over classical methods. Finally, some LLMs tend to produce word embeddings similar to SBERT, a relatively lighter classical model.\n    ",
        "primary_category": "cs.CL",
        "categories": [],
        "submitted_date": "16 Feb 2024",
        "last_revised_date": " "
    },
    "2402.11194": {
        "title": "Evaluating LLMs' Mathematical Reasoning in Financial Document Question Answering",
        "authors": [
            "Pragya Srivastava",
            "Manuj Malik",
            "Vivek Gupta",
            "Tanuja Ganu",
            "Dan Roth"
        ],
        "comments": "25 pages, 17 figures",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "Large Language Models (LLMs), excel in natural language understanding, but their capability for complex mathematical reasoning with an amalgamation of structured tables and unstructured text is uncertain. This study explores LLMs' mathematical reasoning on four financial tabular question-answering datasets: TATQA, FinQA, ConvFinQA, and Multihiertt. Through extensive experiments with various models and prompting techniques, we assess how LLMs adapt to complex tables and mathematical tasks. We focus on sensitivity to table complexity and performance variations with an increasing number of arithmetic reasoning steps. The results provide insights into LLMs' capabilities and limitations in handling complex mathematical scenarios for semi-structured tables. Ultimately, we introduce a novel prompting technique tailored to semi-structured documents, matching or outperforming other baselines in performance while providing a nuanced understanding of LLMs abilities for such a task.\n    ",
        "primary_category": "cs.CL",
        "categories": [],
        "submitted_date": "17 Feb 2024",
        "last_revised_date": " "
    },
    "2402.11253": {
        "title": "Aligning Large Language Models by On-Policy Self-Judgment",
        "authors": [
            "Sangkyu Lee",
            "Sungdong Kim",
            "Ashkan Yousefpour",
            "Minjoon Seo",
            "Kang Min Yoo",
            "Youngjae Yu"
        ],
        "comments": "Preprint; Under review",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Existing approaches for aligning large language models with human preferences face a trade-off that requires a separate reward model (RM) for on-policy learning. In this paper, we present a novel alignment framework, \\method{} that (1) does on-policy learning and 2) is parameter efficient, as it does not require an additional RM for evaluating the samples for on-policy learning. To this end, we propose Judge-augmented Supervised Fine-Tuning (JSFT) to train a single model to act as both a policy and a judge. Specifically, we view the pairwise judgment task, choosing the better response from a response pair, as a special case of the instruction-following task. The resulting model can judge preferences of on-the-fly responses from current policy initialized from itself. Experimental results show the efficacy of \\method{}, outperforming baselines in preference benchmarks. We also show that the rejecting sampling by itself can improve performance further without an additional evaluator.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.AI",
            "cs.CL"
        ],
        "submitted_date": "17 Feb 2024",
        "last_revised_date": " "
    },
    "2402.11352": {
        "title": "Unified Capacity Results for Free-Space Optical Communication Systems Over Gamma-Gamma Atmospheric Turbulence Channels",
        "authors": [
            "Himani Verma",
            "Kamal Singh"
        ],
        "comments": " ",
        "subjects": "Information Theory (cs.IT)",
        "abstract": "In terrestrial free-space optical (FSO) communication systems, adaptive power control at the optical laser transmitters is crucial not only to prolong the life span of the laser sources, but more importantly to maintain robust and spectrally efficient communication through atmospheric turbulence. However, a comprehensive study of dynamic power adaptation in existing FSO systems is lacking in the literature. In this paper, we investigate FSO communication systems capable of adaptive laser power control with heterodyne detection (HD) and direct detection (DD) based receivers operating under shot-noise-limited conditions. Under these FSO systems considerations, we derive unified exact and asymptotic formulas for the capacities of Gamma-Gamma atmospheric turbulence channels with and without pointing errors; these novel closed-form capacity expressions are much simpler and provide new insights into the impact of varying turbulence conditions and pointing errors. Finally, the numerical results highlight the intricate relations of atmospheric fading, pointing error, and large-scale channel parameters in a typical terrestrial FSO channel setting, followed up by an accurate assessment of the key parameters determining the capacity performances of the aforementioned FSO systems revealing several interesting characteristics.\n    ",
        "primary_category": "cs.IT",
        "categories": [
            "eess.SP"
        ],
        "submitted_date": "17 Feb 2024",
        "last_revised_date": " "
    },
    "2402.11403": {
        "title": "An Empirical Evaluation of Neural and Neuro-symbolic Approaches to Real-time Multimodal Complex Event Detection",
        "authors": [
            "Liying Han",
            "Mani B. Srivastava"
        ],
        "comments": " ",
        "subjects": "Artificial Intelligence (cs.AI)",
        "abstract": "Robots and autonomous systems require an understanding of complex events (CEs) from sensor data to interact with their environments and humans effectively. Traditional end-to-end neural architectures, despite processing sensor data efficiently, struggle with long-duration events due to limited context sizes and reasoning capabilities. Recent advances in neuro-symbolic methods, which integrate neural and symbolic models leveraging human knowledge, promise improved performance with less data. This study addresses the gap in understanding these approaches' effectiveness in complex event detection (CED), especially in temporal reasoning. We investigate neural and neuro-symbolic architectures' performance in a multimodal CED task, analyzing IMU and acoustic data streams to recognize CE patterns. Our methodology includes (i) end-to-end neural architectures for direct CE detection from sensor embeddings, (ii) two-stage concept-based neural models mapping sensor embeddings to atomic events (AEs) before CE detection, and (iii) a neuro-symbolic approach using a symbolic finite-state machine for CE detection from AEs. Empirically, the neuro-symbolic architecture significantly surpasses purely neural models, demonstrating superior performance in CE recognition, even with extensive training data and ample temporal context for neural approaches.\n    ",
        "primary_category": "cs.AI",
        "categories": [],
        "submitted_date": "17 Feb 2024",
        "last_revised_date": " "
    },
    "2402.11837": {
        "title": "Self-Guided Robust Graph Structure Refinement",
        "authors": [
            "Yeonjun In",
            "Kanghoon Yoon",
            "Kibum Kim",
            "Kijung Shin",
            "Chanyoung Park"
        ],
        "comments": "This paper has been accepted by TheWebConf 2024 (Oral Presentation)",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Recent studies have revealed that GNNs are vulnerable to adversarial attacks. To defend against such attacks, robust graph structure refinement (GSR) methods aim at minimizing the effect of adversarial edges based on node features, graph structure, or external information. However, we have discovered that existing GSR methods are limited by narrowassumptions, such as assuming clean node features, moderate structural attacks, and the availability of external clean graphs, resulting in the restricted applicability in real-world scenarios. In this paper, we propose a self-guided GSR framework (SG-GSR), which utilizes a clean sub-graph found within the given attacked graph itself. Furthermore, we propose a novel graph augmentation and a group-training strategy to handle the two technical challenges in the clean sub-graph extraction: 1) loss of structural information, and 2) imbalanced node degree distribution. Extensive experiments demonstrate the effectiveness of SG-GSR under various scenarios including non-targeted attacks, targeted attacks, feature attacks, e-commerce fraud, and noisy node labels. Our code is available at this https URL.\n    ",
        "primary_category": "cs.LG",
        "categories": [],
        "submitted_date": "19 Feb 2024",
        "last_revised_date": " "
    },
    "2402.11871": {
        "title": "From Reals to Logic and Back: Inventing Symbolic Vocabularies, Actions, and Models for Planning from Raw Data",
        "authors": [
            "Naman Shah",
            "Jayesh Nagpal",
            "Pulkit Verma",
            "Siddharth Srivastava"
        ],
        "comments": " ",
        "subjects": "Robotics (cs.RO)",
        "abstract": "Hand-crafted, logic-based state and action representations have been widely used to overcome the intractable computational complexity of long-horizon robot planning problems, including task and motion planning problems. However, creating such representations requires experts with strong intuitions and detailed knowledge about the robot and the tasks it may need to accomplish in a given setting. Removing this dependency on human intuition is a highly active research area.\nThis paper presents the first approach for autonomously learning generalizable, logic-based relational representations for abstract states and actions starting from unannotated high-dimensional, real-valued robot trajectories. The learned representations constitute auto-invented PDDL-like domain models. Empirical results in deterministic settings show that powerful abstract representations can be learned from just a handful of robot trajectories; the learned relational representations include but go beyond classical, intuitive notions of high-level actions; and that the learned models allow planning algorithms to scale to tasks that were previously beyond the scope of planning without hand-crafted abstractions.\n    ",
        "primary_category": "cs.RO",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "19 Feb 2024",
        "last_revised_date": " "
    },
    "2402.11924": {
        "title": "MRKE: The Multi-hop Reasoning Evaluation of LLMs by Knowledge Edition",
        "authors": [
            "Jian Wu",
            "Linyi Yang",
            "Manabu Okumura",
            "Yue Zhang"
        ],
        "comments": " ",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "Although Large Language Models (LLMs) have shown strong performance in Multi-hop Question Answering (MHQA) tasks, their real reasoning ability remains exploration. Current LLM QA evaluation benchmarks have shown limitations, including 1) data contamination, the evaluation data are potentially exposed to LLMs during the pretraining stage; and 2) ignoration of the reasoning chain evaluation. Thus we introduce an LLM MHQA evaluation benchmark, the first QA benchmark based on the new, unprecedented knowledge by editing the off-the-shelf HotpotQA dataset; Besides, we also annotate and evaluate the reasoning chain in the form of sub-questions and intermediate answers corresponding to the multi-hop questions. Specifically, based on the observation, 1) LLMs show a performance gap between the original HotpotQA and our edited data, deeming that current MHQA benchmarks have the potential risk of data contamination that hard to evaluate LLMs' performance objectively and scientifically; 2) LLMs only get a small percentage of the right reasoning chain, e.g. GPT-4 only gets 36.3\\% right reasoning chain. We believe this new Multi-hop QA evaluation benchmark and novel evaluation methods will facilitate the development of trustworthy LLM evaluation on the MHQA task.\n    ",
        "primary_category": "cs.CL",
        "categories": [],
        "submitted_date": "19 Feb 2024",
        "last_revised_date": " "
    },
    "2402.12151": {
        "title": "Transformer-based Causal Language Models Perform Clustering",
        "authors": [
            "Xinbo Wu",
            "Lav R. Varshney"
        ],
        "comments": "Added new experimental results and fixed some errors",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "Even though large language models (LLMs) have demonstrated remarkable capability in solving various natural language tasks, the capability of an LLM to follow human instructions is still a concern. Recent works have shown great improvements in the instruction-following capability via additional training for instruction-following tasks. However, the mechanisms responsible for effective instruction-following capabilities remain inadequately understood. Here, we introduce a simplified instruction-following task and use synthetic datasets to analyze a Transformer-based causal language model. Our findings suggest that the model learns task-specific information by clustering data within its hidden space, with this clustering process evolving dynamically during learning. We also demonstrate how this phenomenon assists the model in handling unseen instances, and validate our results in a more realistic setting. Furthermore, we present inspired applications regarding pre-training and alignment.\n    ",
        "primary_category": "cs.CL",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "19 Feb 2024",
        "last_revised_date": " "
    },
    "2402.12374": {
        "title": "Sequoia: Scalable, Robust, and Hardware-aware Speculative Decoding",
        "authors": [
            "Zhuoming Chen",
            "Avner May",
            "Ruslan Svirschevski",
            "Yuhsun Huang",
            "Max Ryabinin",
            "Zhihao Jia",
            "Beidi Chen"
        ],
        "comments": " ",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "As the usage of large language models (LLMs) grows, performing efficient inference with these models becomes increasingly important. While speculative decoding has recently emerged as a promising direction for speeding up inference, existing methods are limited in their ability to scale to larger speculation budgets, and adapt to different hyperparameters and hardware. This paper introduces Sequoia, a scalable, robust, and hardware-aware algorithm for speculative decoding. To attain better scalability, Sequoia introduces a dynamic programming algorithm to find the optimal tree structure for the speculated tokens. To achieve robust speculative performance, Sequoia uses a novel sampling and verification method that outperforms prior work across different decoding temperatures. Finally, Sequoia introduces a hardware-aware tree optimizer that maximizes speculative performance by automatically selecting the token tree size and depth for a given hardware platform. Evaluation shows that Sequoia improves the decoding speed of Llama2-7B, Llama2-13B, and Vicuna-33B on an A100 by up to $4.04\\times$, $3.73\\times$, and $2.27\\times$. For offloading setting on L40, Sequoia achieves as low as 0.56 s/token for exact Llama2-70B inference latency, which is $9.96\\times$ on our optimized offloading system (5.6 s/token), $9.7\\times$ than DeepSpeed-Zero-Inference, $19.5\\times$ than Huggingface Accelerate.\n    ",
        "primary_category": "cs.CL",
        "categories": [],
        "submitted_date": "19 Feb 2024",
        "last_revised_date": " "
    },
    "2402.12423": {
        "title": "On the Semantic Latent Space of Diffusion-Based Text-to-Speech Models",
        "authors": [
            "Miri Varshavsky-Hassid",
            "Roy Hirsch",
            "Regev Cohen",
            "Tomer Golany",
            "Daniel Freedman",
            "Ehud Rivlin"
        ],
        "comments": " ",
        "subjects": "Sound (cs.SD)",
        "abstract": "The incorporation of Denoising Diffusion Models (DDMs) in the Text-to-Speech (TTS) domain is rising, providing great value in synthesizing high quality speech. Although they exhibit impressive audio quality, the extent of their semantic capabilities is unknown, and controlling their synthesized speech's vocal properties remains a challenge. Inspired by recent advances in image synthesis, we explore the latent space of frozen TTS models, which is composed of the latent bottleneck activations of the DDM's denoiser. We identify that this space contains rich semantic information, and outline several novel methods for finding semantic directions within it, both supervised and unsupervised. We then demonstrate how these enable off-the-shelf audio editing, without any further training, architectural changes or data requirements. We present evidence of the semantic and acoustic qualities of the edited audio, and provide supplemental samples: this https URL.\n    ",
        "primary_category": "cs.SD",
        "categories": [
            "cs.CL",
            "cs.LG",
            "eess.AS"
        ],
        "submitted_date": "19 Feb 2024",
        "last_revised_date": " "
    },
    "2402.12728": {
        "title": "Modality-Aware Integration with Large Language Models for Knowledge-based Visual Question Answering",
        "authors": [
            "Junnan Dong",
            "Qinggang Zhang",
            "Huachi Zhou",
            "Daochen Zha",
            "Pai Zheng",
            "Xiao Huang"
        ],
        "comments": "8 pages,3 figures and 1 page appendix; The processed graphs and codes will be avalibale",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Knowledge-based visual question answering (KVQA) has been extensively studied to answer visual questions with external knowledge, e.g., knowledge graphs (KGs). While several attempts have been proposed to leverage large language models (LLMs) as an implicit knowledge source, it remains challenging since LLMs may generate hallucinations. Moreover, multiple knowledge sources, e.g., images, KGs and LLMs, cannot be readily aligned for complex scenarios. To tackle these, we present a novel modality-aware integration with LLMs for KVQA (MAIL). It carefully leverages multimodal knowledge for both image understanding and knowledge reasoning. Specifically, (i) we propose a two-stage prompting strategy with LLMs to densely embody the image into a scene graph with detailed visual features; (ii) We construct a coupled concept graph by linking the mentioned entities with external facts. (iii) A tailored pseudo-siamese graph medium fusion is designed for sufficient multimodal fusion. We utilize the shared mentioned entities in two graphs as mediums to bridge a tight inter-modal exchange, while maximally preserving insightful intra-modal learning by constraining the fusion within mediums. Extensive experiments on two benchmark datasets show the superiority of MAIL with 24x less resources.\n    ",
        "primary_category": "cs.CV",
        "categories": [
            "cs.AI",
            "cs.CL",
            "cs.IR",
            "cs.LG"
        ],
        "submitted_date": "20 Feb 2024",
        "last_revised_date": " "
    },
    "2402.12810": {
        "title": "PIP-Net: Pedestrian Intention Prediction in the Wild",
        "authors": [
            "Mohsen Azarmi",
            "Mahdi Rezaei",
            "He Wang",
            "Sebastien Glaser"
        ],
        "comments": " ",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Accurate pedestrian intention prediction (PIP) by Autonomous Vehicles (AVs) is one of the current research challenges in this field. In this article, we introduce PIP-Net, a novel framework designed to predict pedestrian crossing intentions by AVs in real-world urban scenarios. We offer two variants of PIP-Net designed for different camera mounts and setups. Leveraging both kinematic data and spatial features from the driving scene, the proposed model employs a recurrent and temporal attention-based solution, outperforming state-of-the-art performance. To enhance the visual representation of road users and their proximity to the ego vehicle, we introduce a categorical depth feature map, combined with a local motion flow feature, providing rich insights into the scene dynamics. Additionally, we explore the impact of expanding the camera's field of view, from one to three cameras surrounding the ego vehicle, leading to enhancement in the model's contextual perception. Depending on the traffic scenario and road environment, the model excels in predicting pedestrian crossing intentions up to 4 seconds in advance which is a breakthrough in current research studies in pedestrian intention prediction. Finally, for the first time, we present the Urban-PIP dataset, a customised pedestrian intention prediction dataset, with multi-camera annotations in real-world automated driving scenarios.\n    ",
        "primary_category": "cs.CV",
        "categories": [
            "cs.AI",
            "cs.NE",
            "eess.IV",
            "stat.ML"
        ],
        "submitted_date": "20 Feb 2024",
        "last_revised_date": " "
    },
    "2402.12907": {
        "title": "Incentive Compatibility for AI Alignment in Sociotechnical Systems: Positions and Prospects",
        "authors": [
            "Zhaowei Zhang",
            "Fengshuo Bai",
            "Mingzhi Wang",
            "Haoyang Ye",
            "Chengdong Ma",
            "Yaodong Yang"
        ],
        "comments": "13 pages, 2 figures",
        "subjects": "Artificial Intelligence (cs.AI)",
        "abstract": "The burgeoning integration of artificial intelligence (AI) into human society brings forth significant implications for societal governance and safety. While considerable strides have been made in addressing AI alignment challenges, existing methodologies primarily focus on technical facets, often neglecting the intricate sociotechnical nature of AI systems, which can lead to a misalignment between the development and deployment contexts. To this end, we posit a new problem worth exploring: Incentive Compatibility Sociotechnical Alignment Problem (ICSAP). We hope this can call for more researchers to explore how to leverage the principles of Incentive Compatibility (IC) from game theory to bridge the gap between technical and societal components to maintain AI consensus with human societies in different contexts. We further discuss three classical game problems for achieving IC: mechanism design, contract theory, and Bayesian persuasion, in addressing the perspectives, potentials, and challenges of solving ICSAP, and provide preliminary implementation conceptions.\n    ",
        "primary_category": "cs.AI",
        "categories": [
            "cs.CY",
            "cs.GT",
            "cs.HC"
        ],
        "submitted_date": "20 Feb 2024",
        "last_revised_date": " "
    },
    "2402.13226": {
        "title": "NeRF Solves Undersampled MRI Reconstruction",
        "authors": [
            "Tae Jun Jang",
            "Chang Min Hyun"
        ],
        "comments": " ",
        "subjects": "Image and Video Processing (eess.IV)",
        "abstract": "This article presents a novel undersampled magnetic resonance imaging (MRI) technique that leverages the concept of Neural Radiance Field (NeRF). With radial undersampling, the corresponding imaging problem can be reformulated into an image modeling task from sparse-view rendered data; therefore, a high dimensional MR image is obtainable from undersampled k-space data by taking advantage of implicit neural representation. A multi-layer perceptron, which is designed to output an image intensity from a spatial coordinate, learns the MR physics-driven rendering relation between given measurement data and desired image. Effective undersampling strategies for high-quality neural representation are investigated. The proposed method serves two benefits: (i) The learning is based fully on single undersampled k-space data, not a bunch of measured data and target image sets. It can be used potentially for diagnostic MR imaging, such as fetal MRI, where data acquisition is relatively rare or limited against diversity of clinical images while undersampled reconstruction is highly demanded. (ii) A reconstructed MR image is a scan-specific representation highly adaptive to the given k-space measurement. Numerous experiments validate the feasibility and capability of the proposed approach.\n    ",
        "primary_category": "eess.IV",
        "categories": [
            "cs.AI",
            "cs.CE",
            "eess.SP"
        ],
        "submitted_date": "20 Feb 2024",
        "last_revised_date": " "
    },
    "2402.13616": {
        "title": "YOLOv9: Learning What You Want to Learn Using Programmable Gradient Information",
        "authors": [
            "Chien-Yao Wang",
            "I-Hau Yeh",
            "Hong-Yuan Mark Liao"
        ],
        "comments": " ",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Today's deep learning methods focus on how to design the most appropriate objective functions so that the prediction results of the model can be closest to the ground truth. Meanwhile, an appropriate architecture that can facilitate acquisition of enough information for prediction has to be designed. Existing methods ignore a fact that when input data undergoes layer-by-layer feature extraction and spatial transformation, large amount of information will be lost. This paper will delve into the important issues of data loss when data is transmitted through deep networks, namely information bottleneck and reversible functions. We proposed the concept of programmable gradient information (PGI) to cope with the various changes required by deep networks to achieve multiple objectives. PGI can provide complete input information for the target task to calculate objective function, so that reliable gradient information can be obtained to update network weights. In addition, a new lightweight network architecture -- Generalized Efficient Layer Aggregation Network (GELAN), based on gradient path planning is designed. GELAN's architecture confirms that PGI has gained superior results on lightweight models. We verified the proposed GELAN and PGI on MS COCO dataset based object detection. The results show that GELAN only uses conventional convolution operators to achieve better parameter utilization than the state-of-the-art methods developed based on depth-wise convolution. PGI can be used for variety of models from lightweight to large. It can be used to obtain complete information, so that train-from-scratch models can achieve better results than state-of-the-art models pre-trained using large datasets, the comparison results are shown in Figure 1. The source codes are at: this https URL.\n    ",
        "primary_category": "cs.CV",
        "categories": [],
        "submitted_date": "21 Feb 2024",
        "last_revised_date": " "
    },
    "2402.13693": {
        "title": "CMNER: A Chinese Multimodal NER Dataset based on Social Media",
        "authors": [
            "Yuanze Ji",
            "Bobo Li",
            "Jun Zhou",
            "Fei Li",
            "Chong Teng",
            "Donghong Ji"
        ],
        "comments": " ",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "Multimodal Named Entity Recognition (MNER) is a pivotal task designed to extract named entities from text with the support of pertinent images. Nonetheless, a notable paucity of data for Chinese MNER has considerably impeded the progress of this natural language processing task within the Chinese domain. Consequently, in this study, we compile a Chinese Multimodal NER dataset (CMNER) utilizing data sourced from Weibo, China's largest social media platform. Our dataset encompasses 5,000 Weibo posts paired with 18,326 corresponding images. The entities are classified into four distinct categories: person, location, organization, and miscellaneous. We perform baseline experiments on CMNER, and the outcomes underscore the effectiveness of incorporating images for NER. Furthermore, we conduct cross-lingual experiments on the publicly available English MNER dataset (Twitter2015), and the results substantiate our hypothesis that Chinese and English multimodal NER data can mutually enhance the performance of the NER model.\n    ",
        "primary_category": "cs.CL",
        "categories": [],
        "submitted_date": "21 Feb 2024",
        "last_revised_date": " "
    },
    "2402.13711": {
        "title": "DSLR: Diversity Enhancement and Structure Learning for Rehearsal-based Graph Continual Learning",
        "authors": [
            "Seungyoon Choi",
            "Wonjoong Kim",
            "Sungwon Kim",
            "Yeonjun In",
            "Sein Kim",
            "Chanyoung Park"
        ],
        "comments": "Accepted at ACM TheWebConf 2024 (WWW 2024) (Oral presentation)",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "We investigate the replay buffer in rehearsal-based approaches for graph continual learning (GCL) methods. Existing rehearsal-based GCL methods select the most representative nodes for each class and store them in a replay buffer for later use in training subsequent tasks. However, we discovered that considering only the class representativeness of each replayed node makes the replayed nodes to be concentrated around the center of each class, incurring a potential risk of overfitting to nodes residing in those regions, which aggravates catastrophic forgetting. Moreover, as the rehearsal-based approach heavily relies on a few replayed nodes to retain knowledge obtained from previous tasks, involving the replayed nodes that have irrelevant neighbors in the model training may have a significant detrimental impact on model performance. In this paper, we propose a GCL model named DSLR, specifically, we devise a coverage-based diversity (CD) approach to consider both the class representativeness and the diversity within each class of the replayed nodes. Moreover, we adopt graph structure learning (GSL) to ensure that the replayed nodes are connected to truly informative neighbors. Extensive experimental results demonstrate the effectiveness and efficiency of DSLR. Our source code is available at this https URL.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "21 Feb 2024",
        "last_revised_date": " "
    },
    "2402.13717": {
        "title": "Neeko: Leveraging Dynamic LoRA for Efficient Multi-Character Role-Playing Agent",
        "authors": [
            "Xiaoyan Yu",
            "Tongxu Luo",
            "Yifan Wei",
            "Fangyu Lei",
            "Yiming Huang",
            "Hao Peng",
            "Liehuang Zhu"
        ],
        "comments": " ",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "Large Language Models (LLMs) have revolutionized open-domain dialogue agents but encounter challenges in multi-character role-playing (MCRP) scenarios. To address the issue, we present Neeko, an innovative framework designed for efficient multiple characters imitation. Unlike existing methods, Neeko employs a dynamic low-rank adapter (LoRA) strategy, enabling it to adapt seamlessly to diverse characters. Our framework breaks down the role-playing process into agent pre-training, multiple characters playing, and character incremental learning, effectively handling both seen and unseen roles. This dynamic approach, coupled with distinct LoRA blocks for each character, enhances Neeko's adaptability to unique attributes, personalities, and speaking patterns. As a result, Neeko demonstrates superior performance in MCRP over most existing methods, offering more engaging and versatile user interaction experiences. Code and data are available at this https URL.\n    ",
        "primary_category": "cs.CL",
        "categories": [],
        "submitted_date": "21 Feb 2024",
        "last_revised_date": " "
    },
    "2402.13809": {
        "title": "NeuralDiffuser: Controllable fMRI Reconstruction with Primary Visual Feature Guided Diffusion",
        "authors": [
            "Haoyu Li",
            "Hao Wu",
            "Badong Chen"
        ],
        "comments": "The implementation error lead to incorrect results in experiment",
        "subjects": "Neural and Evolutionary Computing (cs.NE)",
        "abstract": "Reconstructing visual stimuli from functional Magnetic Resonance Imaging (fMRI) based on Latent Diffusion Models (LDM) provides a fine-grained retrieval of the brain. A challenge persists in reconstructing a cohesive alignment of details (such as structure, background, texture, color, etc.). Moreover, LDMs would generate different image results even under the same conditions. For these, we first uncover the neuroscientific perspective of LDM-based methods that is top-down creation based on pre-trained knowledge from massive images but lack of detail-driven bottom-up perception resulting in unfaithful details. We propose NeuralDiffuser which introduces primary visual feature guidance to provide detail cues in the form of gradients, extending the bottom-up process for LDM-based methods to achieve faithful semantics and details. We also developed a novel guidance strategy to ensure the consistency of repeated reconstructions rather than a variety of results. We obtain the state-of-the-art performance of NeuralDiffuser on the Natural Senses Dataset (NSD), which offers more faithful details and consistent results.\n    ",
        "primary_category": "cs.NE",
        "categories": [
            "cs.AI",
            "cs.CV"
        ],
        "submitted_date": "21 Feb 2024",
        "last_revised_date": " "
    },
    "2402.13918": {
        "title": "BenchCloudVision: A Benchmark Analysis of Deep Learning Approaches for Cloud Detection and Segmentation in Remote Sensing Imagery",
        "authors": [
            "Loddo Fabio",
            "Dario Piga",
            "Michelucci Umberto",
            "El Ghazouali Safouane"
        ],
        "comments": "Submitted to Expert Systems and Applications. Under license CC-BY-NC-ND",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Satellites equipped with optical sensors capture high-resolution imagery, providing valuable insights into various environmental phenomena. In recent years, there has been a surge of research focused on addressing some challenges in remote sensing, ranging from water detection in diverse landscapes to the segmentation of mountainous and terrains. Ongoing investigations goals to enhance the precision and efficiency of satellite imagery analysis. Especially, there is a growing emphasis on developing methodologies for accurate water body detection, snow and clouds, important for environmental monitoring, resource management, and disaster response. Within this context, this paper focus on the cloud segmentation from remote sensing imagery. Accurate remote sensing data analysis can be challenging due to the presence of clouds in optical sensor-based applications. The quality of resulting products such as applications and research is directly impacted by cloud detection, which plays a key role in the remote sensing data processing pipeline. This paper examines seven cutting-edge semantic segmentation and detection algorithms applied to clouds identification, conducting a benchmark analysis to evaluate their architectural approaches and identify the most performing ones. To increase the model's adaptability, critical elements including the type of imagery and the amount of spectral bands used during training are analyzed. Additionally, this research tries to produce machine learning algorithms that can perform cloud segmentation using only a few spectral bands, including RGB and RGBN-IR combinations. The model's flexibility for a variety of applications and user scenarios is assessed by using imagery from Sentinel-2 and Landsat-8 as datasets. This benchmark can be reproduced using the material from this github link: this https URL.\n    ",
        "primary_category": "cs.CV",
        "categories": [
            "cs.LG",
            "eess.IV"
        ],
        "submitted_date": "21 Feb 2024",
        "last_revised_date": " "
    },
    "2402.13929": {
        "title": "SDXL-Lightning: Progressive Adversarial Diffusion Distillation",
        "authors": [
            "Shanchuan Lin",
            "Anran Wang",
            "Xiao Yang"
        ],
        "comments": " ",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "We propose a diffusion distillation method that achieves new state-of-the-art in one-step/few-step 1024px text-to-image generation based on SDXL. Our method combines progressive and adversarial distillation to achieve a balance between quality and mode coverage. In this paper, we discuss the theoretical analysis, discriminator design, model formulation, and training techniques. We open-source our distilled SDXL-Lightning models both as LoRA and full UNet weights.\n    ",
        "primary_category": "cs.CV",
        "categories": [
            "cs.AI",
            "cs.LG"
        ],
        "submitted_date": "21 Feb 2024",
        "last_revised_date": " "
    },
    "2402.13956": {
        "title": "Can You Learn Semantics Through Next-Word Prediction? The Case of Entailment",
        "authors": [
            "William Merrill",
            "Zhaofeng Wu",
            "Norihito Naka",
            "Yoon Kim",
            "Tal Linzen"
        ],
        "comments": "Preprint",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "Do LMs infer the semantics of text from co-occurrence patterns in their training data? Merrill et al. (2022) argue that, in theory, probabilities predicted by an optimal LM encode semantic information about entailment relations, but it is unclear whether neural LMs trained on corpora learn entailment in this way because of strong idealizing assumptions made by Merrill et al. In this work, we investigate whether their theory can be used to decode entailment judgments from neural LMs. We find that a test similar to theirs can decode entailment relations between natural sentences, well above random chance, though not perfectly, across many datasets and LMs. This suggests LMs implicitly model aspects of semantics to predict semantic effects on sentence co-occurrence patterns. However, we find the test that predicts entailment in practice works in the opposite direction to the theoretical test. We thus revisit the assumptions underlying the original test, finding its derivation did not adequately account for redundancy in human-written text. We argue that correctly accounting for redundancy related to explanations might derive the observed flipped test and, more generally, improve linguistic theories of human speakers.\n    ",
        "primary_category": "cs.CL",
        "categories": [],
        "submitted_date": "21 Feb 2024",
        "last_revised_date": " "
    },
    "2402.14041": {
        "title": "E2USD: Efficient-yet-effective Unsupervised State Detection for Multivariate Time Series",
        "authors": [
            "Zhichen Lai",
            "Huan Li",
            "Dalin Zhang",
            "Yan Zhao",
            "Weizhu Qian",
            "Christian S. Jensen"
        ],
        "comments": "Accepted by The Web Conference 2024 (WWW 2024)",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "We propose E2USD that enables efficient-yet-accurate unsupervised MTS state detection. E2USD exploits a Fast Fourier Transform-based Time Series Compressor (FFTCompress) and a Decomposed Dual-view Embedding Module (DDEM) that together encode input MTSs at low computational overhead. Additionally, we propose a False Negative Cancellation Contrastive Learning method (FNCCLearning) to counteract the effects of false negatives and to achieve more cluster-friendly embedding spaces. To reduce computational overhead further in streaming settings, we introduce Adaptive Threshold Detection (ADATD). Comprehensive experiments with six baselines and six datasets offer evidence that E2USD is capable of SOTA accuracy at significantly reduced computational overhead.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.AI",
            "cs.DB"
        ],
        "submitted_date": "21 Feb 2024",
        "last_revised_date": " "
    },
    "2402.14042": {
        "title": "Protect and Extend -- Using GANs for Synthetic Data Generation of Time-Series Medical Records",
        "authors": [
            "Navid Ashrafi",
            "Vera Schmitt",
            "Robert P. Spang",
            "Sebastian M\u00f6ller",
            "Jan-Niklas Voigt-Antons"
        ],
        "comments": " ",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Preservation of private user data is of paramount importance for high Quality of Experience (QoE) and acceptability, particularly with services treating sensitive data, such as IT-based health services. Whereas anonymization techniques were shown to be prone to data re-identification, synthetic data generation has gradually replaced anonymization since it is relatively less time and resource-consuming and more robust to data leakage. Generative Adversarial Networks (GANs) have been used for generating synthetic datasets, especially GAN frameworks adhering to the differential privacy phenomena. This research compares state-of-the-art GAN-based models for synthetic data generation to generate time-series synthetic medical records of dementia patients which can be distributed without privacy concerns. Predictive modeling, autocorrelation, and distribution analysis are used to assess the Quality of Generating (QoG) of the generated data. The privacy preservation of the respective models is assessed by applying membership inference attacks to determine potential data leakage risks. Our experiments indicate the superiority of the privacy-preserving GAN (PPGAN) model over other models regarding privacy preservation while maintaining an acceptable level of QoG. The presented results can support better data protection for medical use cases in the future.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.AI",
            "cs.CR"
        ],
        "submitted_date": "21 Feb 2024",
        "last_revised_date": " "
    },
    "2402.14096": {
        "title": "EyeTrans: Merging Human and Machine Attention for Neural Code Summarization",
        "authors": [
            "Yifan Zhang",
            "Jiliang Li",
            "Zachary Karas",
            "Aakash Bansal",
            "Toby Jia-Jun Li",
            "Collin McMillan",
            "Kevin Leach",
            "Yu Huang"
        ],
        "comments": " ",
        "subjects": "Software Engineering (cs.SE)",
        "abstract": "Neural code summarization leverages deep learning models to automatically generate brief natural language summaries of code snippets. The development of Transformer models has led to extensive use of attention during model design. While existing work has primarily and almost exclusively focused on static properties of source code and related structural representations like the Abstract Syntax Tree (AST), few studies have considered human attention, that is, where programmers focus while examining and comprehending code. In this paper, we develop a method for incorporating human attention into machine attention to enhance neural code summarization. To facilitate this incorporation and vindicate this hypothesis, we introduce EyeTrans, which consists of three steps: (1) we conduct an extensive eye-tracking human study to collect and pre-analyze data for model training, (2) we devise a data-centric approach to integrate human attention with machine attention in the Transformer architecture, and (3) we conduct comprehensive experiments on two code summarization tasks to demonstrate the effectiveness of incorporating human attention into Transformers. Integrating human attention leads to an improvement of up to 29.91% in Functional Summarization and up to 6.39% in General Code Summarization performance, demonstrating the substantial benefits of this combination. We further explore performance in terms of robustness and efficiency by creating challenging summarization scenarios in which EyeTrans exhibits interesting properties. We also visualize the attention map to depict the simplifying effect of machine attention in the Transformer by incorporating human attention. This work has the potential to propel AI research in software engineering by introducing more human-centered approaches and data.\n    ",
        "primary_category": "cs.SE",
        "categories": [
            "cs.AI",
            "cs.HC"
        ],
        "submitted_date": "21 Feb 2024",
        "last_revised_date": " "
    },
    "2402.14139": {
        "title": "NeuroFlux: Memory-Efficient CNN Training Using Adaptive Local Learning",
        "authors": [
            "Dhananjay Saikumar",
            "Blesson Varghese"
        ],
        "comments": "Accepted to EuroSys 2024",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Efficient on-device Convolutional Neural Network (CNN) training in resource-constrained mobile and edge environments is an open challenge. Backpropagation is the standard approach adopted, but it is GPU memory intensive due to its strong inter-layer dependencies that demand intermediate activations across the entire CNN model to be retained in GPU memory. This necessitates smaller batch sizes to make training possible within the available GPU memory budget, but in turn, results in substantially high and impractical training time. We introduce NeuroFlux, a novel CNN training system tailored for memory-constrained scenarios. We develop two novel opportunities: firstly, adaptive auxiliary networks that employ a variable number of filters to reduce GPU memory usage, and secondly, block-specific adaptive batch sizes, which not only cater to the GPU memory constraints but also accelerate the training process. NeuroFlux segments a CNN into blocks based on GPU memory usage and further attaches an auxiliary network to each layer in these blocks. This disrupts the typical layer dependencies under a new training paradigm - $\\textit{`adaptive local learning'}$. Moreover, NeuroFlux adeptly caches intermediate activations, eliminating redundant forward passes over previously trained blocks, further accelerating the training process. The results are twofold when compared to Backpropagation: on various hardware platforms, NeuroFlux demonstrates training speed-ups of 2.3$\\times$ to 6.1$\\times$ under stringent GPU memory budgets, and NeuroFlux generates streamlined models that have 10.9$\\times$ to 29.4$\\times$ fewer parameters.\n    ",
        "primary_category": "cs.LG",
        "categories": [],
        "submitted_date": "21 Feb 2024",
        "last_revised_date": " "
    },
    "2402.14148": {
        "title": "Neural Networks and Friction: Slide, Hold, Learn",
        "authors": [
            "Joaquin Garcia-Suarez"
        ],
        "comments": "10 paged, 10 figures, 2 tables",
        "subjects": "Geophysics (physics.geo-ph)",
        "abstract": "In this study, it is demonstrated that Recurrent Neural Networks (RNNs), specifically those utilizing Gated Recurrent Unit (GRU) architecture, possess the capability to learn the complex dynamics of rate-and-state friction laws from synthetic data. The data employed for training the network is generated through the application of traditional rate-and-state friction equations coupled with the aging law for state evolution. A novel aspect of our approach is the formulation of a loss function that explicitly accounts for initial conditions, the direct effect, and the evolution of state variables during training. It is found that the RNN, with its GRU architecture, effectively learns to predict changes in the friction coefficient resulting from velocity jumps, thereby showcasing the potential of machine learning models in understanding and simulating the physics of frictional processes.\n    ",
        "primary_category": "physics.geo-ph",
        "categories": [
            "cs.LG"
        ],
        "submitted_date": "21 Feb 2024",
        "last_revised_date": " "
    },
    "2402.14198": {
        "title": "Tight Inapproximability of Nash Equilibria in Public Goods Games",
        "authors": [
            "J\u00e9r\u00e9mi Do Dinh",
            "Alexandros Hollender"
        ],
        "comments": " ",
        "subjects": "Computer Science and Game Theory (cs.GT)",
        "abstract": "We study public goods games, a type of game where every player has to decide whether or not to produce a good which is public, i.e., neighboring players can also benefit from it. Specifically, we consider a setting where the good is indivisible and where the neighborhood structure is represented by a directed graph, with the players being the nodes. Papadimitriou and Peng (2023) recently showed that in this setting computing mixed Nash equilibria is PPAD-hard, and that this remains the case even for $\\varepsilon$-well-supported approximate equilibria for some sufficiently small constant $\\varepsilon$. In this work, we strengthen this inapproximability result by showing that the problem remains PPAD-hard for any non-trivial approximation parameter $\\varepsilon$.\n    ",
        "primary_category": "cs.GT",
        "categories": [
            "cs.CC"
        ],
        "submitted_date": "22 Feb 2024",
        "last_revised_date": " "
    },
    "2402.14264": {
        "title": "Structure-agnostic Optimality of Doubly Robust Learning for Treatment Effect Estimation",
        "authors": [
            "Jikai Jin",
            "Vasilis Syrgkanis"
        ],
        "comments": "31 pages",
        "subjects": "Machine Learning (stat.ML)",
        "abstract": "Average treatment effect estimation is the most central problem in causal inference with application to numerous disciplines. While many estimation strategies have been proposed in the literature, the statistical optimality of these methods has still remained an open area of investigation, especially in regimes where these methods do not achieve parametric rates. In this paper, we adopt the recently introduced structure-agnostic framework of statistical lower bounds, which poses no structural properties on the nuisance functions other than access to black-box estimators that achieve some statistical estimation rate. This framework is particularly appealing when one is only willing to consider estimation strategies that use non-parametric regression and classification oracles as black-box sub-processes. Within this framework, we prove the statistical optimality of the celebrated and widely used doubly robust estimators for both the Average Treatment Effect (ATE) and the Average Treatment Effect on the Treated (ATT), as well as weighted variants of the former, which arise in policy evaluation.\n    ",
        "primary_category": "stat.ML",
        "categories": [
            "cs.LG",
            "econ.EM",
            "math.ST",
            "stat.ME"
        ],
        "submitted_date": "22 Feb 2024",
        "last_revised_date": " "
    },
    "2402.14270": {
        "title": "Take the Bull by the Horns: Hard Sample-Reweighted Continual Training Improves LLM Generalization",
        "authors": [
            "Xuxi Chen",
            "Zhendong Wang",
            "Daouda Sow",
            "Junjie Yang",
            "Tianlong Chen",
            "Yingbin Liang",
            "Mingyuan Zhou",
            "Zhangyang Wang"
        ],
        "comments": "Preprint; updated reference and related works",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "In the rapidly advancing arena of large language models (LLMs), a key challenge is to enhance their capabilities amid a looming shortage of high-quality training data. Our study starts from an empirical strategy for the light continual training of LLMs using their original pre-training data sets, with a specific focus on selective retention of samples that incur moderately high losses. These samples are deemed informative and beneficial for model refinement, contrasting with the highest-loss samples, which would be discarded due to their correlation with data noise and complexity. We then formalize this strategy into a principled framework of Instance-Reweighted Distributionally Robust Optimization (IR-DRO). IR-DRO is designed to dynamically prioritize the training focus on informative samples through an instance reweighting mechanism, streamlined by a closed-form solution for straightforward integration into established training protocols. Through rigorous experimentation with various models and datasets, our findings indicate that our sample-targeted methods significantly improve LLM performance across multiple benchmarks, in both continual pre-training and instruction tuning scenarios. Our codes are available at this https URL.\n    ",
        "primary_category": "cs.LG",
        "categories": [],
        "submitted_date": "22 Feb 2024",
        "last_revised_date": " "
    },
    "2402.14485": {
        "title": "Machine-Checked Categorical Diagrammatic Reasoning",
        "authors": [
            "Beno\u00eet Guillemet",
            "Assia Mahboubi",
            "Matthieu Piquerez"
        ],
        "comments": " ",
        "subjects": "Logic in Computer Science (cs.LO)",
        "abstract": "This paper describes a formal proof library, developed using the Coq proof assistant, designed to assist users in writing correct diagrammatic proofs, for 1-categories. This library proposes a deep-embedded, domain-specific formal language, which features dedicated proof commands to automate the synthesis, and the verification, of the technical parts often eluded in the literature.\n    ",
        "primary_category": "cs.LO",
        "categories": [],
        "submitted_date": "22 Feb 2024",
        "last_revised_date": " "
    },
    "2402.14498": {
        "title": "A Collision-Aware Cable Grasping Method in Cluttered Environment",
        "authors": [
            "Lei Zhang",
            "Kaixin Bai",
            "Qiang Li",
            "Zhaopeng Chen",
            "Jianwei Zhang"
        ],
        "comments": "7 pages",
        "subjects": "Robotics (cs.RO)",
        "abstract": "We introduce a Cable Grasping-Convolutional Neural Network designed to facilitate robust cable grasping in cluttered environments. Utilizing physics simulations, we generate an extensive dataset that mimics the intricacies of cable grasping, factoring in potential collisions between cables and robotic grippers. We employ the Approximate Convex Decomposition technique to dissect the non-convex cable model, with grasp quality autonomously labeled based on simulated grasping attempts. The CG-CNN is refined using this simulated dataset and enhanced through domain randomization techniques. Subsequently, the trained model predicts grasp quality, guiding the optimal grasp pose to the robot controller for execution. Grasping efficacy is assessed across both synthetic and real-world settings. Given our model implicit collision sensitivity, we achieved commendable success rates of 92.3% for known cables and 88.4% for unknown cables, surpassing contemporary state-of-the-art approaches. Supplementary materials can be found at this https URL .\n    ",
        "primary_category": "cs.RO",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "22 Feb 2024",
        "last_revised_date": " "
    },
    "2402.14547": {
        "title": "OmniPred: Language Models as Universal Regressors",
        "authors": [
            "Xingyou Song",
            "Oscar Li",
            "Chansoo Lee",
            "Bangding Yang",
            "Daiyi Peng",
            "Sagi Perel",
            "Yutian Chen"
        ],
        "comments": "24 pages, 10 figures. Code can be found in this https URL",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Over the broad landscape of experimental design, regression has been a powerful tool to accurately predict the outcome metrics of a system or model given a set of parameters, but has been traditionally restricted to methods which are only applicable to a specific task. In this paper, we propose OmniPred, a framework for training language models as universal end-to-end regressors over $(x,y)$ evaluation data from diverse real world experiments. Using data sourced from Google Vizier, one of the largest blackbox optimization databases in the world, our extensive experiments demonstrate that through only textual representations of mathematical parameters and values, language models are capable of very precise numerical regression, and if given the opportunity to train over multiple tasks, can significantly outperform traditional regression models.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.AI",
            "cs.CL",
            "cs.DB"
        ],
        "submitted_date": "22 Feb 2024",
        "last_revised_date": " "
    },
    "2402.14576": {
        "title": "Edge Caching Based on Deep Reinforcement Learning and Transfer Learning",
        "authors": [
            "Farnaz Niknia",
            "Ping Wang",
            "Zixu Wang",
            "Aakash Agarwal",
            "Adib S. Rezaei"
        ],
        "comments": " ",
        "subjects": "Networking and Internet Architecture (cs.NI)",
        "abstract": "This paper addresses the escalating challenge of redundant data transmission in networks. The surge in traffic has strained backhaul links and backbone networks, prompting the exploration of caching solutions at the edge router. Existing work primarily relies on Markov Decision Processes (MDP) for caching issues, assuming fixed-time interval decisions; however, real-world scenarios involve random request arrivals, and despite the critical role of various file characteristics in determining an optimal caching policy, none of the related existing work considers all these file characteristics in forming a caching policy. In this paper, first, we formulate the caching problem using a semi-Markov Decision Process (SMDP) to accommodate the continuous-time nature of real-world scenarios allowing for caching decisions at random times upon file requests. Then, we propose a double deep Q-learning-based caching approach that comprehensively accounts for file features such as lifetime, size, and importance. Simulation results demonstrate the superior performance of our approach compared to a recent Deep Reinforcement Learning-based method. Furthermore, we extend our work to include a Transfer Learning (TL) approach to account for changes in file request rates in the SMDP framework. The proposed TL approach exhibits fast convergence, even in scenarios with increased differences in request rates between source and target domains, presenting a promising solution to the dynamic challenges of caching in real-world environments.\n    ",
        "primary_category": "cs.NI",
        "categories": [
            "cs.LG",
            "eess.SY"
        ],
        "submitted_date": "8 Feb 2024",
        "last_revised_date": " "
    },
    "2402.14591": {
        "title": "High-Speed Detector For Low-Powered Devices In Aerial Grasping",
        "authors": [
            "Ashish Kumar",
            "Laxmidhar Behera"
        ],
        "comments": "8 Pages, 9 Figures, 8 Tables, IEEE Robotics and Automation Letters (IEEE RA-L)",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Autonomous aerial harvesting is a highly complex problem because it requires numerous interdisciplinary algorithms to be executed on mini low-powered computing devices. Object detection is one such algorithm that is compute-hungry. In this context, we make the following contributions: (i) Fast Fruit Detector (FFD), a resource-efficient, single-stage, and postprocessing-free object detector based on our novel latent object representation (LOR) module, query assignment, and prediction strategy. FFD achieves 100FPS@FP32 precision on the latest 10W NVIDIA Jetson-NX embedded device while co-existing with other time-critical sub-systems such as control, grasping, SLAM, a major achievement of this work. (ii) a method to generate vast amounts of training data without exhaustive manual labelling of fruit images since they consist of a large number of instances, which increases the labelling cost and time. (iii) an open-source fruit detection dataset having plenty of very small-sized instances that are difficult to detect. Our exhaustive evaluations on our and MinneApple dataset show that FFD, being only a single-scale detector, is more accurate than many representative detectors, e.g. FFD is better than single-scale Faster-RCNN by 10.7AP, multi-scale Faster-RCNN by 2.3AP, and better than latest single-scale YOLO-v8 by 8AP and multi-scale YOLO-v8 by 0.3 while being considerably faster.\n    ",
        "primary_category": "cs.CV",
        "categories": [
            "cs.RO"
        ],
        "submitted_date": "22 Feb 2024",
        "last_revised_date": " "
    },
    "2402.14594": {
        "title": "Improving Assessment of Tutoring Practices using Retrieval-Augmented Generation",
        "authors": [
            "Zifei FeiFei Han",
            "Jionghao Lin",
            "Ashish Gurung",
            "Danielle R. Thomas",
            "Eason Chen",
            "Conrad Borchers",
            "Shivang Gupta",
            "Kenneth R. Koedinger"
        ],
        "comments": "11 page Workshop paper, AAAI2024 Workshop on AI for Education - Bridging Innovation and Responsibility, Large Language Model, Personalized Tutor Training, Automatic Assessment",
        "subjects": "Computers and Society (cs.CY)",
        "abstract": "One-on-one tutoring is an effective instructional method for enhancing learning, yet its efficacy hinges on tutor competencies. Novice math tutors often prioritize content-specific guidance, neglecting aspects such as social-emotional learning. Social-emotional learning promotes equity and inclusion and nurturing relationships with students, which is crucial for holistic student development. Assessing the competencies of tutors accurately and efficiently can drive the development of tailored tutor training programs. However, evaluating novice tutor ability during real-time tutoring remains challenging as it typically requires experts-in-the-loop. To address this challenge, this preliminary study aims to harness Generative Pre-trained Transformers (GPT), such as GPT-3.5 and GPT-4 models, to automatically assess tutors' ability of using social-emotional tutoring strategies. Moreover, this study also reports on the financial dimensions and considerations of employing these models in real-time and at scale for automated assessment. The current study examined four prompting strategies: two basic Zero-shot prompt strategies, Tree of Thought prompt, and Retrieval-Augmented Generator (RAG) based prompt. The results indicate that the RAG prompt demonstrated more accurate performance (assessed by the level of hallucination and correctness in the generated assessment texts) and lower financial costs than the other strategies evaluated. These findings inform the development of personalized tutor training interventions to enhance the the educational effectiveness of tutored learning.\n    ",
        "primary_category": "cs.CY",
        "categories": [
            "cs.AI",
            "cs.CL",
            "cs.HC",
            "cs.IR"
        ],
        "submitted_date": "4 Feb 2024",
        "last_revised_date": " "
    },
    "2402.14614": {
        "title": "Two Counterexamples to Tokenization and the Noiseless Channel",
        "authors": [
            "Marco Cognetta",
            "Vil\u00e9m Zouhar",
            "Sangwhan Moon",
            "Naoaki Okazaki"
        ],
        "comments": "9 pages, 2 figures, to appear in LREC-COLING 2024, de-texified metadata",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "In Tokenization and the Noiseless Channel (Zouhar et al., 2023a), R\u00e9nyi efficiency is suggested as an intrinsic mechanism for evaluating a tokenizer: for NLP tasks, the tokenizer which leads to the highest R\u00e9nyi efficiency of the unigram distribution should be chosen. The R\u00e9nyi efficiency is thus treated as a predictor of downstream performance (e.g., predicting BLEU for a machine translation task), without the expensive step of training multiple models with different tokenizers. Although useful, the predictive power of this metric is not perfect, and the authors note there are additional qualities of a good tokenization scheme that R\u00e9nyi efficiency alone cannot capture.\nWe describe two variants of BPE tokenization which can arbitrarily increase R\u00e9nyi efficiency while decreasing the downstream model performance. These counterexamples expose cases where R\u00e9nyi efficiency fails as an intrinsic tokenization metric and thus give insight for building more accurate predictors.\n    ",
        "primary_category": "cs.CL",
        "categories": [],
        "submitted_date": "22 Feb 2024",
        "last_revised_date": " "
    },
    "2402.14795": {
        "title": "CyberDemo: Augmenting Simulated Human Demonstration for Real-World Dexterous Manipulation",
        "authors": [
            "Jun Wang",
            "Yuzhe Qin",
            "Kaiming Kuang",
            "Yigit Korkmaz",
            "Akhilan Gurumoorthy",
            "Hao Su",
            "Xiaolong Wang"
        ],
        "comments": " ",
        "subjects": "Robotics (cs.RO)",
        "abstract": "We introduce CyberDemo, a novel approach to robotic imitation learning that leverages simulated human demonstrations for real-world tasks. By incorporating extensive data augmentation in a simulated environment, CyberDemo outperforms traditional in-domain real-world demonstrations when transferred to the real world, handling diverse physical and visual conditions. Regardless of its affordability and convenience in data collection, CyberDemo outperforms baseline methods in terms of success rates across various tasks and exhibits generalizability with previously unseen objects. For example, it can rotate novel tetra-valve and penta-valve, despite human demonstrations only involving tri-valves. Our research demonstrates the significant potential of simulated human demonstrations for real-world dexterous manipulation tasks. More details can be found at this https URL\n",
        "primary_category": "cs.RO",
        "categories": [
            "cs.CV"
        ],
        "submitted_date": "22 Feb 2024",
        "last_revised_date": " "
    },
    "2402.14808": {
        "title": "RelayAttention for Efficient Large Language Model Serving with Long System Prompts",
        "authors": [
            "Lei Zhu",
            "Xinjiang Wang",
            "Wayne Zhang",
            "Rynson W.H. Lau"
        ],
        "comments": "fix typos; add code link",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "Practical large language model (LLM) services may involve a long system prompt, which specifies the instructions, examples, and knowledge documents of the task and is reused across numerous requests. However, the long system prompt causes throughput/latency bottlenecks as the cost of generating the next token grows w.r.t. the sequence length. This paper aims to improve the efficiency of LLM services that involve long system prompts. Our key observation is that handling these system prompts requires heavily redundant memory accesses in existing causal attention computation algorithms. Specifically, for batched requests, the cached hidden states (i.e., key-value pairs) of system prompts are transferred from off-chip DRAM to on-chip SRAM multiple times, each corresponding to an individual request. To eliminate such a redundancy, we propose RelayAttention, an attention algorithm that allows reading these hidden states from DRAM exactly once for a batch of input tokens. RelayAttention is a free lunch: it maintains the generation quality while requiring no model retraining, as it is based on a mathematical reformulation of causal attention. Code is available at \\url{this https URL}.\n    ",
        "primary_category": "cs.CL",
        "categories": [],
        "submitted_date": "22 Feb 2024",
        "last_revised_date": " "
    },
    "2402.14875": {
        "title": "What's in a Name? Auditing Large Language Models for Race and Gender Bias",
        "authors": [
            "Amit Haim",
            "Alejandro Salinas",
            "Julian Nyarko"
        ],
        "comments": "34 pages, 9 tables, 11 figures",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "We employ an audit design to investigate biases in state-of-the-art large language models, including GPT-4. In our study, we prompt the models for advice involving a named individual across a variety of scenarios, such as during car purchase negotiations or election outcome predictions. We find that the advice systematically disadvantages names that are commonly associated with racial minorities and women. Names associated with Black women receive the least advantageous outcomes. The biases are consistent across 42 prompt templates and several models, indicating a systemic issue rather than isolated incidents. While providing numerical, decision-relevant anchors in the prompt can successfully counteract the biases, qualitative details have inconsistent effects and may even increase disparities. Our findings underscore the importance of conducting audits at the point of LLM deployment and implementation to mitigate their potential for harm against marginalized communities.\n    ",
        "primary_category": "cs.CL",
        "categories": [
            "cs.AI",
            "cs.CY",
            "cs.LG"
        ],
        "submitted_date": "21 Feb 2024",
        "last_revised_date": " "
    },
    "2402.14978": {
        "title": "AI-Augmented Brainwriting: Investigating the use of LLMs in group ideation",
        "authors": [
            "Orit Shaer",
            "Angelora Cooper",
            "Osnat Mokryn",
            "Andrew L. Kun",
            "Hagit Ben Shoshan"
        ],
        "comments": "Conditionally Accepted to CHI24. 27 pages",
        "subjects": "Human-Computer Interaction (cs.HC)",
        "abstract": "The growing availability of generative AI technologies such as large language models (LLMs) has significant implications for creative work. This paper explores twofold aspects of integrating LLMs into the creative process - the divergence stage of idea generation, and the convergence stage of evaluation and selection of ideas. We devised a collaborative group-AI Brainwriting ideation framework, which incorporated an LLM as an enhancement into the group ideation process, and evaluated the idea generation process and the resulted solution space. To assess the potential of using LLMs in the idea evaluation process, we design an evaluation engine and compared it to idea ratings assigned by three expert and six novice evaluators. Our findings suggest that integrating LLM in Brainwriting could enhance both the ideation process and its outcome. We also provide evidence that LLMs can support idea evaluation. We conclude by discussing implications for HCI education and practice.\n    ",
        "primary_category": "cs.HC",
        "categories": [
            "cs.AI",
            "cs.CY"
        ],
        "submitted_date": "22 Feb 2024",
        "last_revised_date": " "
    },
    "2402.14994": {
        "title": "Energy-Efficient Active Element Selection in RIS-aided Massive MIMO Systems",
        "authors": [
            "Wilson Souza Jr",
            "Jos\u00e9 Carlos Marinello",
            "Taufik Abr\u00e3o"
        ],
        "comments": "22 pages, 52 references, 2 tables, and 5 figures",
        "subjects": "Information Theory (cs.IT)",
        "abstract": "This chapter delves into the critical aspects of optimizing energy efficiency (EE) in active reconfigurable intelligent surface (RIS)-assisted massive MIMO (M-MIMO) wireless communication systems. We develop a comprehensive and unified theoretical framework to analyze the boundaries of EE within M-MIMO systems integrated with active RIS while adhering to practical constraints. Our research focuses on a formulated EE optimization problem aiming to maximize the EE for active RIS-assisted M-MIMO communication systems. Our goal is to strategically find the number of active RIS elements for outperforming the EE attainable by an entirely passive RIS. Besides, the proposed novel solution has been tailored to the innovative problem. The formulation and solution design consider analytical optimization techniques, such as lagrangian dual transform (LDT) and fractional programming (FP) optimization, facilitating the effective implementation of RIS-aided M-MIMO applications in real-world settings. In particular, our results show that the proposed algorithm can provide up to 120% higher EE than the entirely passive RIS. Besides, we found that the active RIS can operate with less than half of the reflecting elements for the entirely passive RIS. Finally, in view of active RIS achieving the complete utilization of amplification power available, it should be equipped with a reasonable number of reflecting elements above N = 49.\n    ",
        "primary_category": "cs.IT",
        "categories": [
            "eess.SP"
        ],
        "submitted_date": "22 Feb 2024",
        "last_revised_date": " "
    },
    "2402.15021": {
        "title": "CLoVe: Encoding Compositional Language in Contrastive Vision-Language Models",
        "authors": [
            "Santiago Castro",
            "Amir Ziai",
            "Avneesh Saluja",
            "Zhuoning Yuan",
            "Rada Mihalcea"
        ],
        "comments": " ",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Recent years have witnessed a significant increase in the performance of Vision and Language tasks. Foundational Vision-Language Models (VLMs), such as CLIP, have been leveraged in multiple settings and demonstrated remarkable performance across several tasks. Such models excel at object-centric recognition yet learn text representations that seem invariant to word order, failing to compose known concepts in novel ways. However, no evidence exists that any VLM, including large-scale single-stream models such as GPT-4V, identifies compositions successfully. In this paper, we introduce a framework to significantly improve the ability of existing models to encode compositional language, with over 10% absolute improvement on compositionality benchmarks, while maintaining or improving the performance on standard object-recognition and retrieval benchmarks. Our code and pre-trained models are publicly available at this https URL.\n    ",
        "primary_category": "cs.CV",
        "categories": [
            "cs.CL"
        ],
        "submitted_date": "22 Feb 2024",
        "last_revised_date": " "
    },
    "2402.15140": {
        "title": "A Relation-Interactive Approach for Message Passing in Hyper-relational Knowledge Graphs",
        "authors": [
            "Yonglin Jing"
        ],
        "comments": " ",
        "subjects": "Artificial Intelligence (cs.AI)",
        "abstract": "Hyper-relational knowledge graphs (KGs) contain additional key-value pairs, providing more information about the relations. In many scenarios, the same relation can have distinct key-value pairs, making the original triple fact more recognizable and specific. Prior studies on hyper-relational KGs have established a solid standard method for hyper-relational graph encoding. In this work, we propose a message-passing-based graph encoder with global relation structure awareness ability, which we call ReSaE. Compared to the prior state-of-the-art approach, ReSaE emphasizes the interaction of relations during message passing process and optimizes the readout structure for link prediction tasks. Overall, ReSaE gives a encoding solution for hyper-relational KGs and ensures stronger performance on downstream link prediction tasks. Our experiments demonstrate that ReSaE achieves state-of-the-art performance on multiple link prediction benchmarks. Furthermore, we also analyze the influence of different model structures on model performance.\n    ",
        "primary_category": "cs.AI",
        "categories": [],
        "submitted_date": "23 Feb 2024",
        "last_revised_date": " "
    },
    "2402.15160": {
        "title": "Spatially-Aware Transformer for Embodied Agents",
        "authors": [
            "Junmo Cho",
            "Jaesik Yoon",
            "Sungjin Ahn"
        ],
        "comments": "ICLR 2024 Spotlight. First two authors contributed equally",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Episodic memory plays a crucial role in various cognitive processes, such as the ability to mentally recall past events. While cognitive science emphasizes the significance of spatial context in the formation and retrieval of episodic memory, the current primary approach to implementing episodic memory in AI systems is through transformers that store temporally ordered experiences, which overlooks the spatial dimension. As a result, it is unclear how the underlying structure could be extended to incorporate the spatial axis beyond temporal order alone and thereby what benefits can be obtained. To address this, this paper explores the use of Spatially-Aware Transformer models that incorporate spatial information. These models enable the creation of place-centric episodic memory that considers both temporal and spatial dimensions. Adopting this approach, we demonstrate that memory utilization efficiency can be improved, leading to enhanced accuracy in various place-centric downstream tasks. Additionally, we propose the Adaptive Memory Allocator, a memory management method based on reinforcement learning that aims to optimize efficiency of memory utilization. Our experiments demonstrate the advantages of our proposed model in various environments and across multiple downstream tasks, including prediction, generation, reasoning, and reinforcement learning. The source code for our models and experiments will be available at this https URL.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "23 Feb 2024",
        "last_revised_date": " "
    },
    "2402.15411": {
        "title": "Optimistic Information Directed Sampling",
        "authors": [
            "Gergely Neu",
            "Matteo Papini",
            "Ludovic Schwartz"
        ],
        "comments": " ",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "We study the problem of online learning in contextual bandit problems where the loss function is assumed to belong to a known parametric function class. We propose a new analytic framework for this setting that bridges the Bayesian theory of information-directed sampling due to Russo and Van Roy (2018) and the worst-case theory of Foster, Kakade, Qian, and Rakhlin (2021) based on the decision-estimation coefficient. Drawing from both lines of work, we propose a algorithmic template called Optimistic Information-Directed Sampling and show that it can achieve instance-dependent regret guarantees similar to the ones achievable by the classic Bayesian IDS method, but with the major advantage of not requiring any Bayesian assumptions. The key technical innovation of our analysis is introducing an optimistic surrogate model for the regret and using it to define a frequentist version of the Information Ratio of Russo and Van Roy (2018), and a less conservative version of the Decision Estimation Coefficient of Foster et al. (2021). Keywords: Contextual bandits, information-directed sampling, decision estimation coefficient, first-order regret bounds.\n    ",
        "primary_category": "cs.LG",
        "categories": [],
        "submitted_date": "23 Feb 2024",
        "last_revised_date": " "
    },
    "2402.15481": {
        "title": "Prejudice and Caprice: A Statistical Framework for Measuring Social Discrimination in Large Language Models",
        "authors": [
            "Yiran Liu",
            "Ke Yang",
            "Zehan Qi",
            "Xiao Liu",
            "Yang Yu",
            "Chengxiang Zhai"
        ],
        "comments": " ",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "The growing integration of large language models (LLMs) into social operations amplifies their impact on decisions in crucial areas such as economics, law, education, and healthcare, raising public concerns about these models' discrimination-related safety and reliability. However, prior discrimination measuring frameworks solely assess the average discriminatory behavior of LLMs, often proving inadequate due to the overlook of an additional discrimination-leading factor, i.e., the LLMs' prediction variation across diverse contexts. In this work, we present the Prejudice-Caprice Framework (PCF) that comprehensively measures discrimination in LLMs by considering both their consistently biased preference and preference variation across diverse contexts. Specifically, we mathematically dissect the aggregated contextualized discrimination risk of LLMs into prejudice risk, originating from LLMs' persistent prejudice, and caprice risk, stemming from their generation inconsistency. In addition, we utilize a data-mining approach to gather preference-detecting probes from sentence skeletons, devoid of attribute indications, to approximate LLMs' applied contexts. While initially intended for assessing discrimination in LLMs, our proposed PCF facilitates the comprehensive and flexible measurement of any inductive biases, including knowledge alongside prejudice, across various modality models. We apply our discrimination-measuring framework to 12 common LLMs, yielding intriguing findings: i) modern LLMs demonstrate significant pro-male stereotypes, ii) LLMs' exhibited discrimination correlates with several social and economic factors, iii) prejudice risk dominates the overall discrimination risk and follows a normal distribution, and iv) caprice risk contributes minimally to the overall risk but follows a fat-tailed distribution, suggesting that it is wild risk requiring enhanced surveillance.\n    ",
        "primary_category": "cs.CL",
        "categories": [
            "cs.CY"
        ],
        "submitted_date": "23 Feb 2024",
        "last_revised_date": " "
    },
    "2402.15708": {
        "title": "Query Augmentation by Decoding Semantics from Brain Signals",
        "authors": [
            "Ziyi Ye",
            "Jingtao Zhan",
            "Qingyao Ai",
            "Yiqun Liu",
            "Maarten de Rijke",
            "Christina Lioma",
            "Tuukka Ruotsalo"
        ],
        "comments": " ",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "Query augmentation is a crucial technique for refining semantically imprecise queries. Traditionally, query augmentation relies on extracting information from initially retrieved, potentially relevant documents. If the quality of the initially retrieved documents is low, then the effectiveness of query augmentation would be limited as well. We propose Brain-Aug, which enhances a query by incorporating semantic information decoded from brain signals. BrainAug generates the continuation of the original query with a prompt constructed with brain signal information and a ranking-oriented inference approach. Experimental results on fMRI (functional magnetic resonance imaging) datasets show that Brain-Aug produces semantically more accurate queries, leading to improved document ranking performance. Such improvement brought by brain signals is particularly notable for ambiguous queries.\n    ",
        "primary_category": "cs.CL",
        "categories": [
            "cs.AI",
            "cs.IR"
        ],
        "submitted_date": "24 Feb 2024",
        "last_revised_date": " "
    },
    "2402.15727": {
        "title": "LLMs Can Defend Themselves Against Jailbreaking in a Practical Manner: A Vision Paper",
        "authors": [
            "Daoyuan Wu",
            "Shuai Wang",
            "Yang Liu",
            "Ning Liu"
        ],
        "comments": "Fixed the bibliography reference issue in our LLM jailbreak defense vision paper submitted on 24 Feb 2024",
        "subjects": "Cryptography and Security (cs.CR)",
        "abstract": "Jailbreaking is an emerging adversarial attack that bypasses the safety alignment deployed in off-the-shelf large language models (LLMs). A considerable amount of research exists proposing more effective jailbreak attacks, including the recent Greedy Coordinate Gradient (GCG) attack, jailbreak template-based attacks such as using \"Do-Anything-Now\" (DAN), and multilingual jailbreak. In contrast, the defensive side has been relatively less explored. This paper proposes a lightweight yet practical defense called SELFDEFEND, which can defend against all existing jailbreak attacks with minimal delay for jailbreak prompts and negligible delay for normal user prompts. Our key insight is that regardless of the kind of jailbreak strategies employed, they eventually need to include a harmful prompt (e.g., \"how to make a bomb\") in the prompt sent to LLMs, and we found that existing LLMs can effectively recognize such harmful prompts that violate their safety policies. Based on this insight, we design a shadow stack that concurrently checks whether a harmful prompt exists in the user prompt and triggers a checkpoint in the normal stack once a token of \"No\" or a harmful prompt is output. The latter could also generate an explainable LLM response to adversarial prompts. We demonstrate our idea of SELFDEFEND works in various jailbreak scenarios through manual analysis in GPT-3.5/4. We also list three future directions to further enhance SELFDEFEND.\n    ",
        "primary_category": "cs.CR",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "24 Feb 2024",
        "last_revised_date": " "
    },
    "2402.15813": {
        "title": "Measuring Bargaining Abilities of LLMs: A Benchmark and A Buyer-Enhancement Method",
        "authors": [
            "Tian Xia",
            "Zhiwei He",
            "Tong Ren",
            "Yibo Miao",
            "Zhuosheng Zhang",
            "Yang Yang",
            "Rui Wang"
        ],
        "comments": "The dataset AmazonHistoryPrice and our code are available at this https URL",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "Bargaining is an important and unique part of negotiation between humans. As LLM-driven agents learn to negotiate and act like real humans, how to evaluate agents' bargaining abilities remains an open problem. For the first time, we formally described the Bargaining task as an asymmetric incomplete information game, defining the gains of the Buyer and Seller in multiple bargaining processes. It allows us to quantitatively assess an agent's performance in the Bargain task. We collected a real product price dataset, AmazonHistoryPrice, and conducted evaluations of various LLM agents' bargaining abilities. We find that playing a Buyer is much harder than a Seller, and increasing model size can not effectively improve the Buyer's performance. To address the challenge, we propose a novel approach called OG-Narrator that integrates a deterministic Offer Generator to control the price range of Buyer's offers, and an LLM Narrator to create natural language sentences for generated offers. Experimental results show that OG-Narrator improves the buyer's deal rates from 26.67% to 88.88% and brings a ten times of multiplication of profits on all baselines, even a model that has not been aligned.\n    ",
        "primary_category": "cs.CL",
        "categories": [
            "cs.GT"
        ],
        "submitted_date": "24 Feb 2024",
        "last_revised_date": " "
    },
    "2402.15830": {
        "title": "Swarm Body: Embodied Swarm Robots",
        "authors": [
            "Sosuke Ichihashi",
            "So Kuroki",
            "Mai Nishimura",
            "Kazumi Kasaura",
            "Takefumi Hiraki",
            "Kazutoshi Tanaka",
            "Shigeo Yoshida"
        ],
        "comments": " ",
        "subjects": "Human-Computer Interaction (cs.HC)",
        "abstract": "The human brain's plasticity allows for the integration of artificial body parts into the human body. Leveraging this, embodied systems realize intuitive interactions with the environment. We introduce a novel concept: embodied swarm robots. Swarm robots constitute a collective of robots working in harmony to achieve a common objective, in our case, serving as functional body parts. Embodied swarm robots can dynamically alter their shape, density, and the correspondences between body parts and individual robots. We contribute an investigation of the influence on embodiment of swarm robot-specific factors derived from these characteristics, focusing on a hand. Our paper is the first to examine these factors through virtual reality (VR) and real-world robot studies to provide essential design considerations and applications of embodied swarm robots. Through quantitative and qualitative analysis, we identified a system configuration to achieve the embodiment of swarm robots.\n    ",
        "primary_category": "cs.HC",
        "categories": [
            "cs.ET",
            "cs.RO"
        ],
        "submitted_date": "24 Feb 2024",
        "last_revised_date": " "
    },
    "2402.15883": {
        "title": "Fusion Encoder Networks",
        "authors": [
            "Stephen Pasteris",
            "Chris Hicks",
            "Vasilios Mavroudis"
        ],
        "comments": " ",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "In this paper we present fusion encoder networks (FENs): a class of algorithms for creating neural networks that map sequences to outputs. The resulting neural network has only logarithmic depth (alleviating the degradation of data as it propagates through the network) and can process sequences in linear time (or in logarithmic time with a linear number of processors). The crucial property of FENs is that they learn by training a quasi-linear number of constant-depth feed-forward neural networks in parallel. The fact that these networks have constant depth means that backpropagation works well. We note that currently the performance of FENs is only conjectured as we are yet to implement them.\n    ",
        "primary_category": "cs.LG",
        "categories": [],
        "submitted_date": "24 Feb 2024",
        "last_revised_date": " "
    },
    "2402.15943": {
        "title": "Rethinking Software Engineering in the Foundation Model Era: A Curated Catalogue of Challenges in the Development of Trustworthy FMware",
        "authors": [
            "Ahmed E. Hassan",
            "Dayi Lin",
            "Gopi Krishnan Rajbahadur",
            "Keheliya Gallaba",
            "Filipe R. Cogo",
            "Boyuan Chen",
            "Haoxiang Zhang",
            "Kishanthan Thangarajah",
            "Gustavo Ansaldi Oliva",
            "Jiahuei Lin",
            "Wali Mohammad Abdullah",
            "Zhen Ming Jiang"
        ],
        "comments": " ",
        "subjects": "Software Engineering (cs.SE)",
        "abstract": "Foundation models (FMs), such as Large Language Models (LLMs), have revolutionized software development by enabling new use cases and business models. We refer to software built using FMs as FMware. The unique properties of FMware (e.g., prompts, agents, and the need for orchestration), coupled with the intrinsic limitations of FMs (e.g., hallucination) lead to a completely new set of software engineering challenges. Based on our industrial experience, we identified 10 key SE4FMware challenges that have caused enterprise FMware development to be unproductive, costly, and risky. In this paper, we discuss these challenges in detail and state the path for innovation that we envision. Next, we present FMArts, which is our long-term effort towards creating a cradle-to-grave platform for the engineering of trustworthy FMware. Finally, we (i) show how the unique properties of FMArts enabled us to design and develop a complex FMware for a large customer in a timely manner and (ii) discuss the lessons that we learned in doing so. We hope that the disclosure of the aforementioned challenges and our associated efforts to tackle them will not only raise awareness but also promote deeper and further discussions, knowledge sharing, and innovative solutions across the software engineering discipline.\n    ",
        "primary_category": "cs.SE",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "25 Feb 2024",
        "last_revised_date": " "
    },
    "2402.15987": {
        "title": "Likelihood-based Mitigation of Evaluation Bias in Large Language Models",
        "authors": [
            "Masanari Ohi",
            "Masahiro Kaneko",
            "Ryuto Koike",
            "Mengsay Loem",
            "Naoaki Okazaki"
        ],
        "comments": "4 main pages",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "Large Language Models (LLMs) are widely used to evaluate natural language generation tasks as automated metrics. However, the likelihood, a measure of LLM's plausibility for a sentence, can vary due to superficial differences in sentences, such as word order and sentence structure. It is therefore possible that there might be a likelihood bias if LLMs are used for evaluation: they might overrate sentences with higher likelihoods while underrating those with lower likelihoods. In this paper, we investigate the presence and impact of likelihood bias in LLM-based evaluators. We also propose a method to mitigate the likelihood bias. Our method utilizes highly biased instances as few-shot examples for in-context learning. Our experiments in evaluating the data-to-text and grammatical error correction tasks reveal that several LLMs we test display a likelihood bias. Furthermore, our proposed method successfully mitigates this bias, also improving evaluation performance (in terms of correlation of models with human scores) significantly.\n    ",
        "primary_category": "cs.CL",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "25 Feb 2024",
        "last_revised_date": " "
    },
    "2402.15997": {
        "title": "Cieran: Designing Sequential Colormaps via In-Situ Active Preference Learning",
        "authors": [
            "Matt-Heun Hong",
            "Zachary N. Sunberg",
            "Danielle Albers Szafir"
        ],
        "comments": "CHI 2024. 12 pages/9 figures",
        "subjects": "Human-Computer Interaction (cs.HC)",
        "abstract": "Quality colormaps can help communicate important data patterns. However, finding an aesthetically pleasing colormap that looks \"just right\" for a given scenario requires significant design and technical expertise. We introduce Cieran, a tool that allows any data analyst to rapidly find quality colormaps while designing charts within Jupyter Notebooks. Our system employs an active preference learning paradigm to rank expert-designed colormaps and create new ones from pairwise comparisons, allowing analysts who are novices in color design to tailor colormaps to their data context. We accomplish this by treating colormap design as a path planning problem through the CIELAB colorspace with a context-specific reward model. In an evaluation with twelve scientists, we found that Cieran effectively modeled user preferences to rank colormaps and leveraged this model to create new quality designs. Our work shows the potential of active preference learning for supporting efficient visualization design optimization.\n    ",
        "primary_category": "cs.HC",
        "categories": [
            "cs.GR",
            "cs.LG"
        ],
        "submitted_date": "25 Feb 2024",
        "last_revised_date": " "
    },
    "2402.16041": {
        "title": "Detecting Machine-Generated Texts by Multi-Population Aware Optimization for Maximum Mean Discrepancy",
        "authors": [
            "Shuhai Zhang",
            "Yiliao Song",
            "Jiahao Yang",
            "Yuanqing Li",
            "Bo Han",
            "Mingkui Tan"
        ],
        "comments": "Accepted at ICLR 2024",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "Large language models (LLMs) such as ChatGPT have exhibited remarkable performance in generating human-like texts. However, machine-generated texts (MGTs) may carry critical risks, such as plagiarism issues, misleading information, or hallucination issues. Therefore, it is very urgent and important to detect MGTs in many situations. Unfortunately, it is challenging to distinguish MGTs and human-written texts because the distributional discrepancy between them is often very subtle due to the remarkable performance of LLMs. In this paper, we seek to exploit \\textit{maximum mean discrepancy} (MMD) to address this issue in the sense that MMD can well identify distributional discrepancies. However, directly training a detector with MMD using diverse MGTs will incur a significantly increased variance of MMD since MGTs may contain \\textit{multiple text populations} due to various LLMs. This will severely impair MMD's ability to measure the difference between two samples. To tackle this, we propose a novel \\textit{multi-population} aware optimization method for MMD called MMD-MP, which can \\textit{avoid variance increases} and thus improve the stability to measure the distributional discrepancy. Relying on MMD-MP, we develop two methods for paragraph-based and sentence-based detection, respectively. Extensive experiments on various LLMs, \\eg, GPT2 and ChatGPT, show superior detection performance of our MMD-MP. The source code is available at \\url{this https URL}.\n    ",
        "primary_category": "cs.CL",
        "categories": [
            "cs.LG"
        ],
        "submitted_date": "25 Feb 2024",
        "last_revised_date": " "
    },
    "2402.16061": {
        "title": "How Large Language Models Encode Context Knowledge? A Layer-Wise Probing Study",
        "authors": [
            "Tianjie Ju",
            "Weiwei Sun",
            "Wei Du",
            "Xinwei Yuan",
            "Zhaochun Ren",
            "Gongshen Liu"
        ],
        "comments": "Accepted at LREC-COLING 2024 (Long Paper)",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "Previous work has showcased the intriguing capability of large language models (LLMs) in retrieving facts and processing context knowledge. However, only limited research exists on the layer-wise capability of LLMs to encode knowledge, which challenges our understanding of their internal mechanisms. In this paper, we devote the first attempt to investigate the layer-wise capability of LLMs through probing tasks. We leverage the powerful generative capability of ChatGPT to construct probing datasets, providing diverse and coherent evidence corresponding to various facts. We employ $\\mathcal V$-usable information as the validation metric to better reflect the capability in encoding context knowledge across different layers. Our experiments on conflicting and newly acquired knowledge show that LLMs: (1) prefer to encode more context knowledge in the upper layers; (2) primarily encode context knowledge within knowledge-related entity tokens at lower layers while progressively expanding more knowledge within other tokens at upper layers; and (3) gradually forget the earlier context knowledge retained within the intermediate layers when provided with irrelevant evidence. Code is publicly available at this https URL.\n    ",
        "primary_category": "cs.CL",
        "categories": [],
        "submitted_date": "25 Feb 2024",
        "last_revised_date": " "
    },
    "2402.16063": {
        "title": "Citation-Enhanced Generation for LLM-based Chatbots",
        "authors": [
            "Weitao Li",
            "Junkai Li",
            "Weizhi Ma",
            "Yang Liu"
        ],
        "comments": " ",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "Large language models (LLMs) exhibit powerful general intelligence across diverse scenarios, including their integration into chatbots. However, a vital challenge of LLM-based chatbots is that they may produce hallucinated content in responses, which significantly limits their applicability. Various efforts have been made to alleviate hallucination, such as retrieval augmented generation and reinforcement learning with human feedback, but most of them require additional training and data annotation. In this paper, we propose a novel post-hoc Citation-Enhanced Generation (CEG) approach combined with retrieval argumentation. Unlike previous studies that focus on preventing hallucinations during generation, our method addresses this issue in a post-hoc way. It incorporates a retrieval module to search for supporting documents relevant to the generated content, and employs a natural language inference-based citation generation module. Once the statements in the generated content lack of reference, our model can regenerate responses until all statements are supported by citations. Note that our method is a training-free plug-and-play plugin that is capable of various LLMs. Experiments on various hallucination-related datasets show our framework outperforms state-of-the-art methods in both hallucination detection and response regeneration on three benchmarks. Our codes and dataset will be publicly available.\n    ",
        "primary_category": "cs.CL",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "25 Feb 2024",
        "last_revised_date": " "
    },
    "2402.16107": {
        "title": "FuseChat: Knowledge Fusion of Chat Models",
        "authors": [
            "Fanqi Wan",
            "Ziyi Yang",
            "Longguang Zhong",
            "Xiaojun Quan",
            "Xinting Huang",
            "Wei Bi"
        ],
        "comments": "Technical Report, work in progress",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "While training large language models (LLMs) from scratch can indeed lead to models with distinct capabilities and strengths, this approach incurs substantial costs and may lead to potential redundancy in competencies. An alternative strategy is to combine existing LLMs into a more robust LLM, thereby diminishing the necessity for expensive pre-training. However, due to the diverse architectures of LLMs, direct parameter blending proves to be unfeasible. Recently, \\textsc{FuseLLM} introduced the concept of knowledge fusion to transfer the collective knowledge of multiple structurally varied LLMs into a target LLM through lightweight continual training. In this report, we extend the scalability and flexibility of the \\textsc{FuseLLM} framework to realize the fusion of chat LLMs, resulting in \\textsc{FuseChat}. \\textsc{FuseChat} comprises two main stages. Firstly, we undertake knowledge fusion for structurally and scale-varied source LLMs to derive multiple target LLMs of identical structure and size via lightweight fine-tuning. Then, these target LLMs are merged within the parameter space, wherein we propose a novel method for determining the merging weights based on the variation ratio of parameter matrices before and after fine-tuning. We validate our approach using three prominent chat LLMs with diverse architectures and scales, namely \\texttt{NH2-Mixtral-8x7B}, \\texttt{NH2-Solar-10.7B}, and \\texttt{OpenChat-3.5-7B}. Experimental results spanning various chat domains demonstrate the superiority of \\texttt{\\textsc{FuseChat}-7B} across a broad spectrum of chat LLMs at 7B and 34B scales, even surpassing \\texttt{GPT-3.5 (March)} and approaching \\texttt{Mixtral-8x7B-Instruct}. Our code, model weights, and data are openly accessible at \\url{this https URL}.\n    ",
        "primary_category": "cs.CL",
        "categories": [],
        "submitted_date": "25 Feb 2024",
        "last_revised_date": " "
    },
    "2402.16192": {
        "title": "Defending Large Language Models against Jailbreak Attacks via Semantic Smoothing",
        "authors": [
            "Jiabao Ji",
            "Bairu Hou",
            "Alexander Robey",
            "George J. Pappas",
            "Hamed Hassani",
            "Yang Zhang",
            "Eric Wong",
            "Shiyu Chang"
        ],
        "comments": "37 pages",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "Aligned large language models (LLMs) are vulnerable to jailbreaking attacks, which bypass the safeguards of targeted LLMs and fool them into generating objectionable content. While initial defenses show promise against token-based threat models, there do not exist defenses that provide robustness against semantic attacks and avoid unfavorable trade-offs between robustness and nominal performance. To meet this need, we propose SEMANTICSMOOTH, a smoothing-based defense that aggregates the predictions of multiple semantically transformed copies of a given input prompt. Experimental results demonstrate that SEMANTICSMOOTH achieves state-of-the-art robustness against GCG, PAIR, and AutoDAN attacks while maintaining strong nominal performance on instruction following benchmarks such as InstructionFollowing and AlpacaEval. The codes will be publicly available at this https URL.\n    ",
        "primary_category": "cs.CL",
        "categories": [],
        "submitted_date": "25 Feb 2024",
        "last_revised_date": " "
    },
    "2402.16221": {
        "title": "Integrating Preprocessing Methods and Convolutional Neural Networks for Effective Tumor Detection in Medical Imaging",
        "authors": [
            "Ha Anh Vu"
        ],
        "comments": "5 pages, 5 figures, utilizing convolutional neural networks and preprocessing methods for tumor detection in MRI images, featuring a detailed methodology section on image preprocessing, segmentation, and model training, with a comprehensive evaluation of model performance on the Figshare dataset using IEEE template",
        "subjects": "Image and Video Processing (eess.IV)",
        "abstract": "This research presents a machine-learning approach for tumor detection in medical images using convolutional neural networks (CNNs). The study focuses on preprocessing techniques to enhance image features relevant to tumor detection, followed by developing and training a CNN model for accurate classification. Various image processing techniques, including Gaussian smoothing, bilateral filtering, and K-means clustering, are employed to preprocess the input images and highlight tumor regions. The CNN model is trained and evaluated on a dataset of medical images, with augmentation and data generators utilized to enhance model generalization. Experimental results demonstrate the effectiveness of the proposed approach in accurately detecting tumors in medical images, paving the way for improved diagnostic tools in healthcare.\n    ",
        "primary_category": "eess.IV",
        "categories": [
            "cs.CV"
        ],
        "submitted_date": "25 Feb 2024",
        "last_revised_date": " "
    },
    "2402.16235": {
        "title": "Human-AI Co-Creation of Worked Examples for Programming Classes",
        "authors": [
            "Mohammad Hassany",
            "Peter Brusilovsky",
            "Jiaze Ke",
            "Kamil Akhuseyinoglu",
            "Arun Balajiee Lekshmi Narayanan"
        ],
        "comments": "arXiv admin note: substantial text overlap with arXiv:2312.02105",
        "subjects": "Human-Computer Interaction (cs.HC)",
        "abstract": "Worked examples (solutions to typical programming problems presented as a source code in a certain language and are used to explain the topics from a programming class) are among the most popular types of learning content in programming classes. Most approaches and tools for presenting these examples to students are based on line-by-line explanations of the example code. However, instructors rarely have time to provide line-by-line explanations for a large number of examples typically used in a programming class. In this paper, we explore and assess a human-AI collaboration approach to authoring worked examples for Java programming. We introduce an authoring system for creating Java worked examples that generates a starting version of code explanations and presents it to the instructor to edit if necessary.We also present a study that assesses the quality of explanations created with this approach\n    ",
        "primary_category": "cs.HC",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "26 Feb 2024",
        "last_revised_date": " "
    },
    "2402.16267": {
        "title": "Infrared and visible Image Fusion with Language-driven Loss in CLIP Embedding Space",
        "authors": [
            "Yuhao Wang",
            "Lingjuan Miao",
            "Zhiqiang Zhou",
            "Lei Zhang",
            "Yajun Qiao"
        ],
        "comments": " ",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Infrared-visible image fusion (IVIF) has attracted much attention owing to the highly-complementary properties of the two image modalities. Due to the lack of ground-truth fused images, the fusion output of current deep-learning based methods heavily depends on the loss functions defined mathematically. As it is hard to well mathematically define the fused image without ground truth, the performance of existing fusion methods is limited. In this paper, we first propose to use natural language to express the objective of IVIF, which can avoid the explicit mathematical modeling of fusion output in current losses, and make full use of the advantage of language expression to improve the fusion performance. For this purpose, we present a comprehensive language-expressed fusion objective, and encode relevant texts into the multi-modal embedding space using CLIP. A language-driven fusion model is then constructed in the embedding space, by establishing the relationship among the embedded vectors to represent the fusion objective and input image modalities. Finally, a language-driven loss is derived to make the actual IVIF aligned with the embedded language-driven fusion model via supervised training. Experiments show that our method can obtain much better fusion results than existing techniques.\n    ",
        "primary_category": "cs.CV",
        "categories": [],
        "submitted_date": "26 Feb 2024",
        "last_revised_date": " "
    },
    "2402.16379": {
        "title": "Improving LLM-based Machine Translation with Systematic Self-Correction",
        "authors": [
            "Zhaopeng Feng",
            "Yan Zhang",
            "Hao Li",
            "Wenqiang Liu",
            "Jun Lang",
            "Yang Feng",
            "Jian Wu",
            "Zuozhu Liu"
        ],
        "comments": " ",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "Large Language Models (LLMs) have achieved impressive results in Machine Translation (MT). However, careful evaluations by human reveal that the translations produced by LLMs still contain multiple errors. Importantly, feeding back such error information into the LLMs can lead to self-correction and result in improved translation performance. Motivated by these insights, we introduce a systematic LLM-based self-correcting translation framework, named TER, which stands for Translate, Estimate, and Refine, marking a significant step forward in this direction. Our findings demonstrate that 1) our self-correction framework successfully assists LLMs in improving their translation quality across a wide range of languages, whether it's from high-resource languages to low-resource ones or whether it's English-centric or centered around other languages; 2) TER exhibits superior systematicity and interpretability compared to previous methods; 3) different estimation strategies yield varied impacts on AI feedback, directly affecting the effectiveness of the final corrections. We further compare different LLMs and conduct various experiments involving self-correction and cross-model correction to investigate the potential relationship between the translation and evaluation capabilities of LLMs. Our code and data are available at this https URL\n",
        "primary_category": "cs.CL",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "26 Feb 2024",
        "last_revised_date": " "
    },
    "2402.16388": {
        "title": "Uncertainty Quantification in Anomaly Detection with Cross-Conformal $p$-Values",
        "authors": [
            "Oliver Hennh\u00f6fer",
            "Christine Preisach"
        ],
        "comments": "16 pages, 1 figure, 3 tables (added code reference, typos)",
        "subjects": "Machine Learning (stat.ML)",
        "abstract": "Given the growing significance of reliable, trustworthy, and explainable machine learning, the requirement of uncertainty quantification for anomaly detection systems has become increasingly important. In this context, effectively controlling Type I error rates ($\\alpha$) without compromising the statistical power ($1-\\beta$) of these systems can build trust and reduce costs related to false discoveries, particularly when follow-up procedures are expensive. Leveraging the principles of conformal prediction emerges as a promising approach for providing respective statistical guarantees by calibrating a model's uncertainty. This work introduces a novel framework for anomaly detection, termed cross-conformal anomaly detection, building upon well-known cross-conformal methods designed for prediction tasks. With that, it addresses a natural research gap by extending previous works in the context of inductive conformal anomaly detection, relying on the split-conformal approach for model calibration. Drawing on insights from conformal prediction, we demonstrate that the derived methods for calculating cross-conformal $p$-values strike a practical compromise between statistical efficiency (full-conformal) and computational efficiency (split-conformal) for uncertainty-quantified anomaly detection on benchmark datasets.\n    ",
        "primary_category": "stat.ML",
        "categories": [
            "cs.LG"
        ],
        "submitted_date": "26 Feb 2024",
        "last_revised_date": " "
    },
    "2402.16459": {
        "title": "Defending LLMs against Jailbreaking Attacks via Backtranslation",
        "authors": [
            "Yihan Wang",
            "Zhouxing Shi",
            "Andrew Bai",
            "Cho-Jui Hsieh"
        ],
        "comments": " ",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "Although many large language models (LLMs) have been trained to refuse harmful requests, they are still vulnerable to jailbreaking attacks, which rewrite the original prompt to conceal its harmful intent. In this paper, we propose a new method for defending LLMs against jailbreaking attacks by ``backtranslation''. Specifically, given an initial response generated by the target LLM from an input prompt, our backtranslation prompts a language model to infer an input prompt that can lead to the response. The inferred prompt is called the backtranslated prompt which tends to reveal the actual intent of the original prompt, since it is generated based on the LLM's response and is not directly manipulated by the attacker. We then run the target LLM again on the backtranslated prompt, and we refuse the original prompt if the model refuses the backtranslated prompt. We explain that the proposed defense provides several benefits on its effectiveness and efficiency. We empirically demonstrate that our defense significantly outperforms the baselines, in the cases that are hard for the baselines, and our defense also has little impact on the generation quality for benign input prompts.\n    ",
        "primary_category": "cs.CL",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "26 Feb 2024",
        "last_revised_date": " "
    },
    "2402.16631": {
        "title": "GenAINet: Enabling Wireless Collective Intelligence via Knowledge Transfer and Reasoning",
        "authors": [
            "Hang Zou",
            "Qiyang Zhao",
            "Lina Bariah",
            "Yu Tian",
            "Mehdi Bennis",
            "Samson Lasaulce",
            "Merouane Debbah",
            "Faouzi Bader"
        ],
        "comments": " ",
        "subjects": "Artificial Intelligence (cs.AI)",
        "abstract": "Generative artificial intelligence (GenAI) and communication networks are expected to have groundbreaking synergies in 6G. Connecting GenAI agents over a wireless network can potentially unleash the power of collective intelligence and pave the way for artificial general intelligence (AGI). However, current wireless networks are designed as a \"data pipe\" and are not suited to accommodate and leverage the power of GenAI. In this paper, we propose the GenAINet framework in which distributed GenAI agents communicate knowledge (high-level concepts or abstracts) to accomplish arbitrary tasks. We first provide a network architecture integrating GenAI capabilities to manage both network protocols and applications. Building on this, we investigate effective communication and reasoning problems by proposing a semantic-native GenAINet. Specifically, GenAI agents extract semantic concepts from multi-modal raw data, build a knowledgebase representing their semantic relations, which is retrieved by GenAI models for planning and reasoning. Under this paradigm, an agent can learn fast from other agents' experience for making better decisions with efficient communications. Furthermore, we conduct two case studies where in wireless device query, we show that extracting and transferring knowledge can improve query accuracy with reduced communication; and in wireless power control, we show that distributed agents can improve decisions via collaborative reasoning. Finally, we address that developing a hierarchical semantic level Telecom world model is a key path towards network of collective intelligence.\n    ",
        "primary_category": "cs.AI",
        "categories": [
            "cs.NI",
            "eess.SP"
        ],
        "submitted_date": "26 Feb 2024",
        "last_revised_date": " "
    },
    "2402.16641": {
        "title": "Towards Open-ended Visual Quality Comparison",
        "authors": [
            "Haoning Wu",
            "Hanwei Zhu",
            "Zicheng Zhang",
            "Erli Zhang",
            "Chaofeng Chen",
            "Liang Liao",
            "Chunyi Li",
            "Annan Wang",
            "Wenxiu Sun",
            "Qiong Yan",
            "Xiaohong Liu",
            "Guangtao Zhai",
            "Shiqi Wang",
            "Weisi Lin"
        ],
        "comments": "Fix typos",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Comparative settings (e.g. pairwise choice, listwise ranking) have been adopted by a wide range of subjective studies for image quality assessment (IQA), as it inherently standardizes the evaluation criteria across different observers and offer more clear-cut responses. In this work, we extend the edge of emerging large multi-modality models (LMMs) to further advance visual quality comparison into open-ended settings, that 1) can respond to open-range questions on quality comparison; 2) can provide detailed reasonings beyond direct answers. To this end, we propose the Co-Instruct. To train this first-of-its-kind open-source open-ended visual quality comparer, we collect the Co-Instruct-562K dataset, from two sources: (a) LLM-merged single image quality description, (b) GPT-4V \"teacher\" responses on unlabeled data. Furthermore, to better evaluate this setting, we propose the MICBench, the first benchmark on multi-image comparison for LMMs. We demonstrate that Co-Instruct not only achieves in average 30% higher accuracy than state-of-the-art open-source LMMs, but also outperforms GPT-4V (its teacher), on both existing related benchmarks and the proposed MICBench. Our model is published at this https URL.\n    ",
        "primary_category": "cs.CV",
        "categories": [],
        "submitted_date": "26 Feb 2024",
        "last_revised_date": " "
    },
    "2402.16853": {
        "title": "PyRQA -- Conducting Recurrence Quantification Analysis on Very Long Time Series Efficiently",
        "authors": [
            "Tobias Rawald",
            "Mike Sips",
            "Norbert Marwan"
        ],
        "comments": "15 pages, 3 figures",
        "subjects": "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "abstract": "PyRQA is a software package that efficiently conducts recurrence quantification analysis (RQA) on time series consisting of more than one million data points. RQA is a method from non-linear time series analysis that quantifies the recurrent behaviour of systems. Existing implementations to RQA are not capable of analysing such very long time series at all or require large amounts of time to calculate the quantitative measures. PyRQA overcomes their limitations by conducting the RQA computations in a highly parallel manner. Building on the OpenCL framework, PyRQA leverages the computing capabilities of a variety of parallel hardware architectures, such as GPUs. The underlying computing approach partitions the RQA computations and enables to employ multiple compute devices at the same time. The goal of this publication is to demonstrate the features and the runtime efficiency of PyRQA. For this purpose we employ a real-world example, comparing the dynamics of two climatological time series, and a synthetic example, reducing the runtime regarding the analysis of a series consisting of over one million data points from almost eight hours using state-of-the-art RQA software to roughly 69 seconds using PyRQA.\n    ",
        "primary_category": "cs.DC",
        "categories": [],
        "submitted_date": "18 Jan 2024",
        "last_revised_date": " "
    },
    "2402.16857": {
        "title": "A novel method to compute the contact surface area between an organ and cancer tissue",
        "authors": [
            "Alessandra Bulanti",
            "Alessandro Carf\u00ec",
            "Paolo Traverso",
            "Carlo Terrone",
            "Fulvio Mastrogiovanni"
        ],
        "comments": " ",
        "subjects": "Image and Video Processing (eess.IV)",
        "abstract": "With \"contact surface area\" (CSA) we refers to the area of contact between a tumor and an organ. This indicator has been identified as a predictive factor for surgical peri-operative parameters, particularly in the context of kidney cancer. However, state-of-the-art algorithms for computing the CSA rely on assumptions about the tumor shape and require manual human annotation. In this study, we introduce an innovative method that relies on 3D reconstructions of tumors and organs to provide an accurate and objective estimate of the CSA. Our approach consists of a segmentation protocol for reconstructing organs and tumors from Computed Tomography (CT) images and an algorithm leveraging the reconstructed meshes to compute the CSA. With the aim to contributing to the literature with replicable results, we provide an open-source implementation of our algorithm, along with an easy-to-use graphical user interface to support its adoption and widespread use. We evaluated the accuracy of our method using both a synthetic dataset and reconstructions of 87 real tumor-organ pairs.\n    ",
        "primary_category": "eess.IV",
        "categories": [
            "cs.CE",
            "cs.CV"
        ],
        "submitted_date": "19 Jan 2024",
        "last_revised_date": " "
    },
    "2402.16860": {
        "title": "Interactive Mars Image Content-Based Search with Interpretable Machine Learning",
        "authors": [
            "Bhavan Vasu",
            "Steven Lu",
            "Emily Dunkel",
            "Kiri L. Wagstaff",
            "Kevin Grimes",
            "Michael McAuley"
        ],
        "comments": "7 pages, 6 figures",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "The NASA Planetary Data System (PDS) hosts millions of images of planets, moons, and other bodies collected throughout many missions. The ever-expanding nature of data and user engagement demands an interpretable content classification system to support scientific discovery and individual curiosity. In this paper, we leverage a prototype-based architecture to enable users to understand and validate the evidence used by a classifier trained on images from the Mars Science Laboratory (MSL) Curiosity rover mission. In addition to providing explanations, we investigate the diversity and correctness of evidence used by the content-based classifier. The work presented in this paper will be deployed on the PDS Image Atlas, replacing its non-interpretable counterpart.\n    ",
        "primary_category": "cs.CV",
        "categories": [
            "cs.IR"
        ],
        "submitted_date": "19 Jan 2024",
        "last_revised_date": " "
    },
    "2402.16888": {
        "title": "Chaotic attractor reconstruction using small reservoirs -- the influence of topology",
        "authors": [
            "Lina Jaurigue"
        ],
        "comments": " ",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Forecasting timeseries based upon measured data is needed in a wide range of applications and has been the subject of extensive research. A particularly challenging task is the forecasting of timeseries generated by chaotic dynamics. In recent years reservoir computing has been shown to be an effective method of forecasting chaotic dynamics and reconstructing chaotic attractors from data. In this work strides are made toward smaller and lower complexity reservoirs with the goal of improved hardware implementability and more reliable production of adequate surrogate models. We show that a reservoir of uncoupled nodes more reliably produces long term timeseries predictions than complex reservoir topologies. We then link the improved attractor reconstruction of the uncoupled reservoir with smaller spectral radii of the resulting surrogate systems. These results indicate that, the node degree plays an important role in determining whether the desired dynamics will be stable in the autonomous surrogate system which is attained via closed-loop operation of the trained reservoir. In terms of hardware implementability, uncoupled nodes would allow for greater freedom in the hardware architecture because no complex coupling setups are needed and because, for uncoupled nodes, the system response is equivalent for space and time multiplexing.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.ET",
            "math-ph",
            "nlin.CD",
            "physics.comp-ph"
        ],
        "submitted_date": "23 Feb 2024",
        "last_revised_date": " "
    },
    "2402.16893": {
        "title": "The Good and The Bad: Exploring Privacy Issues in Retrieval-Augmented Generation (RAG)",
        "authors": [
            "Shenglai Zeng",
            "Jiankun Zhang",
            "Pengfei He",
            "Yue Xing",
            "Yiding Liu",
            "Han Xu",
            "Jie Ren",
            "Shuaiqiang Wang",
            "Dawei Yin",
            "Yi Chang",
            "Jiliang Tang"
        ],
        "comments": " ",
        "subjects": "Cryptography and Security (cs.CR)",
        "abstract": "Retrieval-augmented generation (RAG) is a powerful technique to facilitate language model with proprietary and private data, where data privacy is a pivotal concern. Whereas extensive research has demonstrated the privacy risks of large language models (LLMs), the RAG technique could potentially reshape the inherent behaviors of LLM generation, posing new privacy issues that are currently under-explored. In this work, we conduct extensive empirical studies with novel attack methods, which demonstrate the vulnerability of RAG systems on leaking the private retrieval database. Despite the new risk brought by RAG on the retrieval data, we further reveal that RAG can mitigate the leakage of the LLMs' training data. Overall, we provide new insights in this paper for privacy protection of retrieval-augmented LLMs, which benefit both LLMs and RAG systems builders. Our code is available at this https URL.\n    ",
        "primary_category": "cs.CR",
        "categories": [
            "cs.AI",
            "cs.CL"
        ],
        "submitted_date": "23 Feb 2024",
        "last_revised_date": " "
    },
    "2402.16904": {
        "title": "Selective Task offloading for Maximum Inference Accuracy and Energy efficient Real-Time IoT Sensing Systems",
        "authors": [
            "Abdelkarim Ben Sada",
            "Amar Khelloufi",
            "Abdenacer Naouri",
            "Huansheng Ning",
            "Sahraoui Dhelim"
        ],
        "comments": " ",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "The recent advancements in small-size inference models facilitated AI deployment on the edge. However, the limited resource nature of edge devices poses new challenges especially for real-time applications. Deploying multiple inference models (or a single tunable model) varying in size and therefore accuracy and power consumption, in addition to an edge server inference model, can offer a dynamic system in which the allocation of inference models to inference jobs is performed according to the current resource conditions. Therefore, in this work, we tackle the problem of selectively allocating inference models to jobs or offloading them to the edge server to maximize inference accuracy under time and energy constraints. This problem is shown to be an instance of the unbounded multidimensional knapsack problem which is considered a strongly NP-hard problem. We propose a lightweight hybrid genetic algorithm (LGSTO) to solve this problem. We introduce a termination condition and neighborhood exploration techniques for faster evolution of populations. We compare LGSTO with the Naive and Dynamic programming solutions. In addition to classic genetic algorithms using different reproduction methods including NSGA-II, and finally we compare to other evolutionary methods such as Particle swarm optimization (PSO) and Ant colony optimization (ACO). Experiment results show that LGSTO performed 3 times faster than the fastest comparable schemes while producing schedules with higher average accuracy.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.AI",
            "cs.NE"
        ],
        "submitted_date": "24 Feb 2024",
        "last_revised_date": " "
    },
    "2402.16912": {
        "title": "An Adversarial Robustness Benchmark for Enterprise Network Intrusion Detection",
        "authors": [
            "Jo\u00e3o Vitorino",
            "Miguel Silva",
            "Eva Maia",
            "Isabel Pra\u00e7a"
        ],
        "comments": "15 pages, 8 tables, 2 figures, FPS 2023 conference",
        "subjects": "Cryptography and Security (cs.CR)",
        "abstract": "As cyber-attacks become more sophisticated, improving the robustness of Machine Learning (ML) models must be a priority for enterprises of all sizes. To reliably compare the robustness of different ML models for cyber-attack detection in enterprise computer networks, they must be evaluated in standardized conditions. This work presents a methodical adversarial robustness benchmark of multiple decision tree ensembles with constrained adversarial examples generated from standard datasets. The robustness of regularly and adversarially trained RF, XGB, LGBM, and EBM models was evaluated on the original CICIDS2017 dataset, a corrected version of it designated as NewCICIDS, and the HIKARI dataset, which contains more recent network traffic. NewCICIDS led to models with a better performance, especially XGB and EBM, but RF and LGBM were less robust against the more recent cyber-attacks of HIKARI. Overall, the robustness of the models to adversarial cyber-attack examples was improved without their generalization to regular traffic being affected, enabling a reliable detection of suspicious activity without costly increases of false alarms.\n    ",
        "primary_category": "cs.CR",
        "categories": [
            "cs.LG",
            "cs.NI"
        ],
        "submitted_date": "25 Feb 2024",
        "last_revised_date": " "
    },
    "2402.16914": {
        "title": "DrAttack: Prompt Decomposition and Reconstruction Makes Powerful LLM Jailbreakers",
        "authors": [
            "Xirui Li",
            "Ruochen Wang",
            "Minhao Cheng",
            "Tianyi Zhou",
            "Cho-Jui Hsieh"
        ],
        "comments": " ",
        "subjects": "Cryptography and Security (cs.CR)",
        "abstract": "The safety alignment of Large Language Models (LLMs) is vulnerable to both manual and automated jailbreak attacks, which adversarially trigger LLMs to output harmful content. However, current methods for jailbreaking LLMs, which nest entire harmful prompts, are not effective at concealing malicious intent and can be easily identified and rejected by well-aligned LLMs. This paper discovers that decomposing a malicious prompt into separated sub-prompts can effectively obscure its underlying malicious intent by presenting it in a fragmented, less detectable form, thereby addressing these limitations. We introduce an automatic prompt \\textbf{D}ecomposition and \\textbf{R}econstruction framework for jailbreak \\textbf{Attack} (DrAttack). DrAttack includes three key components: (a) `Decomposition' of the original prompt into sub-prompts, (b) `Reconstruction' of these sub-prompts implicitly by in-context learning with semantically similar but harmless reassembling demo, and (c) a `Synonym Search' of sub-prompts, aiming to find sub-prompts' synonyms that maintain the original intent while jailbreaking LLMs. An extensive empirical study across multiple open-source and closed-source LLMs demonstrates that, with a significantly reduced number of queries, DrAttack obtains a substantial gain of success rate over prior SOTA prompt-only attackers. Notably, the success rate of 78.0\\% on GPT-4 with merely 15 queries surpassed previous art by 33.1\\%. The project is available at this https URL.\n    ",
        "primary_category": "cs.CR",
        "categories": [
            "cs.AI",
            "cs.CL"
        ],
        "submitted_date": "25 Feb 2024",
        "last_revised_date": " "
    },
    "2402.16982": {
        "title": "Synthesizing Tight Privacy and Accuracy Bounds via Weighted Model Counting",
        "authors": [
            "Lisa Oakley",
            "Steven Holtzen",
            "Alina Oprea"
        ],
        "comments": " ",
        "subjects": "Cryptography and Security (cs.CR)",
        "abstract": "Programmatically generating tight differential privacy (DP) bounds is a hard problem. Two core challenges are (1) finding expressive, compact, and efficient encodings of the distributions of DP algorithms, and (2) state space explosion stemming from the multiple quantifiers and relational properties of the DP definition.\nWe address the first challenge by developing a method for tight privacy and accuracy bound synthesis using weighted model counting on binary decision diagrams, a state of the art technique from the artificial intelligence and automated reasoning communities for exactly computing probability distributions. We address the second challenge by developing a framework for leveraging inherent symmetries in DP algorithms. Our solution benefits from ongoing research in probabilistic programming languages, allowing us to succinctly and expressively represent different DP algorithms with approachable language syntax that can be used by non-experts.\nWe provide a detailed case study of our solution on the binary randomized response algorithm. We also evaluate an implementation of our solution using the Dice probabilistic programming language for the randomized response and truncated geometric above threshold algorithms. We compare to prior work on exact DP verification using Markov chain probabilistic model checking. Very few existing works consider mechanized analysis of accuracy guarantees for DP algorithms. We additionally provide a detailed analysis using our technique for finding tight accuracy bounds for DP algorithms.\n    ",
        "primary_category": "cs.CR",
        "categories": [
            "cs.PL"
        ],
        "submitted_date": "26 Feb 2024",
        "last_revised_date": " "
    },
    "2402.16990": {
        "title": "inGRASS: Incremental Graph Spectral Sparsification via Low-Resistance-Diameter Decomposition",
        "authors": [
            "Ali Aghdaei",
            "Zhuo Feng"
        ],
        "comments": "Accepted on DAC 2024",
        "subjects": "Data Structures and Algorithms (cs.DS)",
        "abstract": "This work presents inGRASS, a novel algorithm designed for incremental spectral sparsification of large undirected graphs. The proposed inGRASS algorithm is highly scalable and parallel-friendly, having a nearly-linear time complexity for the setup phase and the ability to update the spectral sparsifier in $O(\\log N)$ time for each incremental change made to the original graph with $N$ nodes. A key component in the setup phase of inGRASS is a multilevel resistance embedding framework introduced for efficiently identifying spectrally-critical edges and effectively detecting redundant ones, which is achieved by decomposing the initial sparsifier into many node clusters with bounded effective-resistance diameters leveraging a low-resistance-diameter decomposition (LRD) scheme. The update phase of inGRASS exploits low-dimensional node embedding vectors for efficiently estimating the importance and uniqueness of each newly added edge. As demonstrated through extensive experiments, inGRASS achieves up to over $200 \\times$ speedups while retaining comparable solution quality in incremental spectral sparsification of graphs obtained from various datasets, such as circuit simulations, finite element analysis, and social networks.\n    ",
        "primary_category": "cs.DS",
        "categories": [
            "cs.LG",
            "cs.SI"
        ],
        "submitted_date": "26 Feb 2024",
        "last_revised_date": " "
    },
    "2402.16991": {
        "title": "A Phase Transition in Diffusion Models Reveals the Hierarchical Nature of Data",
        "authors": [
            "Antonio Sclocchi",
            "Alessandro Favero",
            "Matthieu Wyart"
        ],
        "comments": "21 pages, 16 figures",
        "subjects": "Machine Learning (stat.ML)",
        "abstract": "Understanding the structure of real data is paramount in advancing modern deep-learning methodologies. Natural data such as images are believed to be composed of features organised in a hierarchical and combinatorial manner, which neural networks capture during learning. Recent advancements show that diffusion models can generate high-quality images, hinting at their ability to capture this underlying structure. We study this phenomenon in a hierarchical generative model of data. We find that the backward diffusion process acting after a time $t$ is governed by a phase transition at some threshold time, where the probability of reconstructing high-level features, like the class of an image, suddenly drops. Instead, the reconstruction of low-level features, such as specific details of an image, evolves smoothly across the whole diffusion process. This result implies that at times beyond the transition, the class has changed but the generated sample may still be composed of low-level elements of the initial image. We validate these theoretical insights through numerical experiments on class-unconditional ImageNet diffusion models. Our analysis characterises the relationship between time and scale in diffusion models and puts forward generative models as powerful tools to model combinatorial data properties.\n    ",
        "primary_category": "stat.ML",
        "categories": [
            "cond-mat.dis-nn",
            "cs.CV",
            "cs.LG"
        ],
        "submitted_date": "26 Feb 2024",
        "last_revised_date": " "
    },
    "2402.17110": {
        "title": "Sinkhorn Distance Minimization for Knowledge Distillation",
        "authors": [
            "Xiao Cui",
            "Yulei Qin",
            "Yuting Gao",
            "Enwei Zhang",
            "Zihan Xu",
            "Tong Wu",
            "Ke Li",
            "Xing Sun",
            "Wengang Zhou",
            "Houqiang Li"
        ],
        "comments": "Accepted by COLING 2024",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Knowledge distillation (KD) has been widely adopted to compress large language models (LLMs). Existing KD methods investigate various divergence measures including the Kullback-Leibler (KL), reverse Kullback-Leibler (RKL), and Jensen-Shannon (JS) divergences. However, due to limitations inherent in their assumptions and definitions, these measures fail to deliver effective supervision when few distribution overlap exists between the teacher and the student. In this paper, we show that the aforementioned KL, RKL, and JS divergences respectively suffer from issues of mode-averaging, mode-collapsing, and mode-underestimation, which deteriorates logits-based KD for diverse NLP tasks. We propose the Sinkhorn Knowledge Distillation (SinKD) that exploits the Sinkhorn distance to ensure a nuanced and precise assessment of the disparity between teacher and student distributions. Besides, profit by properties of the Sinkhorn metric, we can get rid of sample-wise KD that restricts the perception of divergence in each teacher-student sample pair. Instead, we propose a batch-wise reformulation to capture geometric intricacies of distributions across samples in the high-dimensional space. Comprehensive evaluation on GLUE and SuperGLUE, in terms of comparability, validity, and generalizability, highlights our superiority over state-of-the-art methods on all kinds of LLMs with encoder-only, encoder-decoder, and decoder-only architectures.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.CL"
        ],
        "submitted_date": "27 Feb 2024",
        "last_revised_date": " "
    },
    "2402.17113": {
        "title": "Transparent Image Layer Diffusion using Latent Transparency",
        "authors": [
            "Lvmin Zhang",
            "Maneesh Agrawala"
        ],
        "comments": "44 pages, 37 figures, this http URL",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "We present LayerDiffuse, an approach enabling large-scale pretrained latent diffusion models to generate transparent images. The method allows generation of single transparent images or of multiple transparent layers. The method learns a \"latent transparency\" that encodes alpha channel transparency into the latent manifold of a pretrained latent diffusion model. It preserves the production-ready quality of the large diffusion model by regulating the added transparency as a latent offset with minimal changes to the original latent distribution of the pretrained model. In this way, any latent diffusion model can be converted into a transparent image generator by finetuning it with the adjusted latent space. We train the model with 1M transparent image layer pairs collected using a human-in-the-loop collection scheme. We show that latent transparency can be applied to different open source image generators, or be adapted to various conditional control systems to achieve applications like foreground/background-conditioned layer generation, joint layer generation, structural control of layer contents, etc. A user study finds that in most cases (97%) users prefer our natively generated transparent content over previous ad-hoc solutions such as generating and then matting. Users also report the quality of our generated transparent images is comparable to real commercial transparent assets like Adobe Stock.\n    ",
        "primary_category": "cs.CV",
        "categories": [
            "cs.GR"
        ],
        "submitted_date": "27 Feb 2024",
        "last_revised_date": " "
    },
    "2402.17204": {
        "title": "Advancing Generative Model Evaluation: A Novel Algorithm for Realistic Image Synthesis and Comparison in OCR System",
        "authors": [
            "Majid Memari",
            "Khaled R. Ahmed",
            "Shahram Rahimi",
            "Noorbakhsh Amiri Golilarz"
        ],
        "comments": "The manuscript was submitted to IEEE Access on 29-Jan-2024 and is currently under review for publication in IEEE Access",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "This research addresses a critical challenge in the field of generative models, particularly in the generation and evaluation of synthetic images. Given the inherent complexity of generative models and the absence of a standardized procedure for their comparison, our study introduces a pioneering algorithm to objectively assess the realism of synthetic images. This approach significantly enhances the evaluation methodology by refining the Fr\u00e9chet Inception Distance (FID) score, allowing for a more precise and subjective assessment of image quality. Our algorithm is particularly tailored to address the challenges in generating and evaluating realistic images of Arabic handwritten digits, a task that has traditionally been near-impossible due to the subjective nature of realism in image generation. By providing a systematic and objective framework, our method not only enables the comparison of different generative models but also paves the way for improvements in their design and output. This breakthrough in evaluation and comparison is crucial for advancing the field of OCR, especially for scripts that present unique complexities, and sets a new standard in the generation and assessment of high-quality synthetic images.\n    ",
        "primary_category": "cs.CV",
        "categories": [],
        "submitted_date": "27 Feb 2024",
        "last_revised_date": " "
    },
    "2402.17229": {
        "title": "Preserving Fairness Generalization in Deepfake Detection",
        "authors": [
            "Li Lin",
            "Xinan He",
            "Yan Ju",
            "Xin Wang",
            "Feng Ding",
            "Shu Hu"
        ],
        "comments": "Accepted by The IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR 2024)",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Although effective deepfake detection models have been developed in recent years, recent studies have revealed that these models can result in unfair performance disparities among demographic groups, such as race and gender. This can lead to particular groups facing unfair targeting or exclusion from detection, potentially allowing misclassified deepfakes to manipulate public opinion and undermine trust in the model. The existing method for addressing this problem is providing a fair loss function. It shows good fairness performance for intra-domain evaluation but does not maintain fairness for cross-domain testing. This highlights the significance of fairness generalization in the fight against deepfakes. In this work, we propose the first method to address the fairness generalization problem in deepfake detection by simultaneously considering features, loss, and optimization aspects. Our method employs disentanglement learning to extract demographic and domain-agnostic forgery features, fusing them to encourage fair learning across a flattened loss landscape. Extensive experiments on prominent deepfake datasets demonstrate our method's effectiveness, surpassing state-of-the-art approaches in preserving fairness during cross-domain deepfake detection. The code is available at this https URL\n",
        "primary_category": "cs.CV",
        "categories": [
            "cs.CY",
            "cs.LG"
        ],
        "submitted_date": "27 Feb 2024",
        "last_revised_date": " "
    },
    "2402.17236": {
        "title": "A Review of Data Mining in Personalized Education: Current Trends and Future Prospects",
        "authors": [
            "Zhang Xiong",
            "Haoxuan Li",
            "Zhuang Liu",
            "Zhuofan Chen",
            "Hao Zhou",
            "Wenge Rong",
            "Yuanxin Ouyang"
        ],
        "comments": "25 pages, 5 figures",
        "subjects": "Computers and Society (cs.CY)",
        "abstract": "Personalized education, tailored to individual student needs, leverages educational technology and artificial intelligence (AI) in the digital age to enhance learning effectiveness. The integration of AI in educational platforms provides insights into academic performance, learning preferences, and behaviors, optimizing the personal learning process. Driven by data mining techniques, it not only benefits students but also provides educators and institutions with tools to craft customized learning experiences. To offer a comprehensive review of recent advancements in personalized educational data mining, this paper focuses on four primary scenarios: educational recommendation, cognitive diagnosis, knowledge tracing, and learning analysis. This paper presents a structured taxonomy for each area, compiles commonly used datasets, and identifies future research directions, emphasizing the role of data mining in enhancing personalized education and paving the way for future exploration and innovation.\n    ",
        "primary_category": "cs.CY",
        "categories": [
            "cs.LG"
        ],
        "submitted_date": "27 Feb 2024",
        "last_revised_date": " "
    },
    "2402.17242": {
        "title": "Scalable Community Search with Accuracy Guarantee on Attributed Graphs",
        "authors": [
            "Yuxiang Wang",
            "Shuzhan Ye",
            "Xiaoliang Xu",
            "Yuxia Geng",
            "Zhenghe Zhao",
            "Xiangyu Ke",
            "Tianxing Wu"
        ],
        "comments": " ",
        "subjects": "Social and Information Networks (cs.SI)",
        "abstract": "Given an attributed graph $G$ and a query node $q$, \\underline{C}ommunity \\underline{S}earch over \\underline{A}ttributed \\underline{G}raphs (CS-AG) aims to find a structure- and attribute-cohesive subgraph from $G$ that contains $q$. Although CS-AG has been widely studied, they still face three challenges. (1) Exact methods based on graph traversal are time-consuming, especially for large graphs. Some tailored indices can improve efficiency, but introduce nonnegligible storage and maintenance overhead. (2) Approximate methods with a loose approximation ratio only provide a coarse-grained evaluation of a community's quality, rather than a reliable evaluation with an accuracy guarantee in runtime. (3) Attribute cohesiveness metrics often ignores the important correlation with the query node $q$. We formally define our CS-AG problem atop a $q$-centric attribute cohesiveness metric considering both textual and numerical attributes, for $k$-core model on homogeneous graphs. We show the problem is NP-hard. To solve it, we first propose an exact baseline with three pruning strategies. Then, we propose an index-free sampling-estimation-based method to quickly return an approximate community with an accuracy guarantee, in the form of a confidence interval. Once a good result satisfying a user-desired error bound is reached, we terminate it early. We extend it to heterogeneous graphs, $k$-truss model, and size-bounded CS. Comprehensive experimental studies on ten real-world datasets show its superiority, e.g., at least 1.54$\\times$ (41.1$\\times$ on average) faster in response time and a reliable relative error (within a user-specific error bound) of attribute cohesiveness is achieved.\n    ",
        "primary_category": "cs.SI",
        "categories": [
            "cs.DB"
        ],
        "submitted_date": "27 Feb 2024",
        "last_revised_date": " "
    },
    "2402.17256": {
        "title": "Beyond the Known: Investigating LLMs Performance on Out-of-Domain Intent Detection",
        "authors": [
            "Pei Wang",
            "Keqing He",
            "Yejie Wang",
            "Xiaoshuai Song",
            "Yutao Mou",
            "Jingang Wang",
            "Yunsen Xian",
            "Xunliang Cai",
            "Weiran Xu"
        ],
        "comments": " ",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "Out-of-domain (OOD) intent detection aims to examine whether the user's query falls outside the predefined domain of the system, which is crucial for the proper functioning of task-oriented dialogue (TOD) systems. Previous methods address it by fine-tuning discriminative models. Recently, some studies have been exploring the application of large language models (LLMs) represented by ChatGPT to various downstream tasks, but it is still unclear for their ability on OOD detection task.This paper conducts a comprehensive evaluation of LLMs under various experimental settings, and then outline the strengths and weaknesses of LLMs. We find that LLMs exhibit strong zero-shot and few-shot capabilities, but is still at a disadvantage compared to models fine-tuned with full resource. More deeply, through a series of additional analysis experiments, we discuss and summarize the challenges faced by LLMs and provide guidance for future work including injecting domain knowledge, strengthening knowledge transfer from IND(In-domain) to OOD, and understanding long instructions.\n    ",
        "primary_category": "cs.CL",
        "categories": [],
        "submitted_date": "27 Feb 2024",
        "last_revised_date": " "
    },
    "2402.17279": {
        "title": "DiFashion: Towards Personalized Outfit Generation and Recommendation",
        "authors": [
            "Yiyan Xu",
            "Wenjie Wang",
            "Fuli Feng",
            "Yunshan Ma",
            "Jizhi Zhang",
            "Xiangnan He"
        ],
        "comments": " ",
        "subjects": "Information Retrieval (cs.IR)",
        "abstract": "The evolution of Outfit Recommendation (OR) in the realm of fashion has progressed through two distinct phases: Pre-defined Outfit Recommendation and Personalized Outfit Composition. Despite these advancements, both phases face limitations imposed by existing fashion products, hindering their effectiveness in meeting users' diverse fashion needs. The emergence of AI-generated content has paved the way for OR to overcome these constraints, demonstrating the potential for personalized outfit generation.\nIn pursuit of this, we introduce an innovative task named Generative Outfit Recommendation (GOR), with the goal of synthesizing a set of fashion images and assembling them to form visually harmonious outfits customized to individual users. The primary objectives of GOR revolve around achieving high fidelity, compatibility, and personalization of the generated outfits. To accomplish these, we propose DiFashion, a generative outfit recommender model that harnesses exceptional diffusion models for the simultaneous generation of multiple fashion images. To ensure the fulfillment of these objectives, three types of conditions are designed to guide the parallel generation process and Classifier-Free-Guidance are employed to enhance the alignment between generated images and conditions. DiFashion is applied to both personalized Fill-In-The-Blank and GOR tasks, and extensive experiments are conducted on the iFashion and Polyvore-U datasets. The results of quantitative and human-involved qualitative evaluations highlight the superiority of DiFashion over competitive baselines.\n    ",
        "primary_category": "cs.IR",
        "categories": [],
        "submitted_date": "27 Feb 2024",
        "last_revised_date": " "
    },
    "2402.17289": {
        "title": "Active propulsion noise shaping for multi-rotor aircraft localization",
        "authors": [
            "Gabriele Serussi",
            "Tamir Shor",
            "Tom Hirshberg",
            "Chaim Baskin",
            "Alex Bronstein"
        ],
        "comments": " ",
        "subjects": "Robotics (cs.RO)",
        "abstract": "Multi-rotor aerial autonomous vehicles (MAVs) primarily rely on vision for navigation purposes. However, visual localization and odometry techniques suffer from poor performance in low or direct sunlight, a limited field of view, and vulnerability to occlusions. Acoustic sensing can serve as a complementary or even alternative modality for vision in many situations, and it also has the added benefits of lower system cost and energy footprint, which is especially important for micro aircraft. This paper proposes actively controlling and shaping the aircraft propulsion noise generated by the rotors to benefit localization tasks, rather than considering it a harmful nuisance. We present a neural network architecture for selfnoise-based localization in a known environment. We show that training it simultaneously with learning time-varying rotor phase modulation achieves accurate and robust localization. The proposed methods are evaluated using a computationally affordable simulation of MAV rotor noise in 2D acoustic environments that is fitted to real recordings of rotor pressure fields.\n    ",
        "primary_category": "cs.RO",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "27 Feb 2024",
        "last_revised_date": " "
    },
    "2402.17311": {
        "title": "SKT5SciSumm -- A Hybrid Generative Approach for Multi-Document Scientific Summarization",
        "authors": [
            "Huy Quoc To",
            "Hung-Nghiep Tran",
            "Andr'e Greiner-Petter",
            "Felix Beierle",
            "Akiko Aizawa"
        ],
        "comments": " ",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "Summarization for scientific text has shown significant benefits both for the research community and human society. Given the fact that the nature of scientific text is distinctive and the input of the multi-document summarization task is substantially long, the task requires sufficient embedding generation and text truncation without losing important information. To tackle these issues, in this paper, we propose SKT5SciSumm - a hybrid framework for multi-document scientific summarization (MDSS). We leverage the Sentence-Transformer version of Scientific Paper Embeddings using Citation-Informed Transformers (SPECTER) to encode and represent textual sentences, allowing for efficient extractive summarization using k-means clustering. We employ the T5 family of models to generate abstractive summaries using extracted sentences. SKT5SciSumm achieves state-of-the-art performance on the Multi-XScience dataset. Through extensive experiments and evaluation, we showcase the benefits of our model by using less complicated models to achieve remarkable results, thereby highlighting its potential in advancing the field of multi-document summarization for scientific text.\n    ",
        "primary_category": "cs.CL",
        "categories": [],
        "submitted_date": "27 Feb 2024",
        "last_revised_date": " "
    },
    "2402.17316": {
        "title": "Towards Robust and Efficient Cloud-Edge Elastic Model Adaptation via Selective Entropy Distillation",
        "authors": [
            "Yaofo Chen",
            "Shuaicheng Niu",
            "Shoukai Xu",
            "Hengjie Song",
            "Yaowei Wang",
            "Mingkui Tan"
        ],
        "comments": "Published in ICLR 2024",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "The conventional deep learning paradigm often involves training a deep model on a server and then deploying the model or its distilled ones to resource-limited edge devices. Usually, the models shall remain fixed once deployed (at least for some period) due to the potential high cost of model adaptation for both the server and edge sides. However, in many real-world scenarios, the test environments may change dynamically (known as distribution shifts), which often results in degraded performance. Thus, one has to adapt the edge models promptly to attain promising performance. Moreover, with the increasing data collected at the edge, this paradigm also fails to further adapt the cloud model for better performance. To address these, we encounter two primary challenges: 1) the edge model has limited computation power and may only support forward propagation; 2) the data transmission budget between cloud and edge devices is limited in latency-sensitive scenarios. In this paper, we establish a Cloud-Edge Elastic Model Adaptation (CEMA) paradigm in which the edge models only need to perform forward propagation and the edge models can be adapted online. In our CEMA, to reduce the communication burden, we devise two criteria to exclude unnecessary samples from uploading to the cloud, i.e., dynamic unreliable and low-informative sample exclusion. Based on the uploaded samples, we update and distribute the affine parameters of normalization layers by distilling from the stronger foundation model to the edge model with a sample replay strategy. Extensive experimental results on ImageNet-C and ImageNet-R verify the effectiveness of our CEMA.\n    ",
        "primary_category": "cs.CV",
        "categories": [],
        "submitted_date": "27 Feb 2024",
        "last_revised_date": " "
    },
    "2402.17322": {
        "title": "Enclosing Points with Geometric Objects",
        "authors": [
            "Timothy M. Chan",
            "Qizheng He",
            "Jie Xue"
        ],
        "comments": "In SoCG'24",
        "subjects": "Computational Geometry (cs.CG)",
        "abstract": "Let $X$ be a set of points in $\\mathbb{R}^2$ and $\\mathcal{O}$ be a set of geometric objects in $\\mathbb{R}^2$, where $|X| + |\\mathcal{O}| = n$. We study the problem of computing a minimum subset $\\mathcal{O}^* \\subseteq \\mathcal{O}$ that encloses all points in $X$. Here a point $x \\in X$ is enclosed by $\\mathcal{O}^*$ if it lies in a bounded connected component of $\\mathbb{R}^2 \\backslash (\\bigcup_{O \\in \\mathcal{O}^*} O)$. We propose two algorithmic frameworks to design polynomial-time approximation algorithms for the problem. The first framework is based on sparsification and min-cut, which results in $O(1)$-approximation algorithms for unit disks, unit squares, etc. The second framework is based on LP rounding, which results in an $O(\\alpha(n)\\log n)$-approximation algorithm for segments, where $\\alpha(n)$ is the inverse Ackermann function, and an $O(\\log n)$-approximation algorithm for disks.\n    ",
        "primary_category": "cs.CG",
        "categories": [
            "cs.DS"
        ],
        "submitted_date": "27 Feb 2024",
        "last_revised_date": " "
    },
    "2402.17389": {
        "title": "FairBelief -- Assessing Harmful Beliefs in Language Models",
        "authors": [
            "Mattia Setzu",
            "Marta Marchiori Manerba",
            "Pasquale Minervini",
            "Debora Nozza"
        ],
        "comments": " ",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "Language Models (LMs) have been shown to inherit undesired biases that might hurt minorities and underrepresented groups if such systems were integrated into real-world applications without careful fairness auditing. This paper proposes FairBelief, an analytical approach to capture and assess beliefs, i.e., propositions that an LM may embed with different degrees of confidence and that covertly influence its predictions. With FairBelief, we leverage prompting to study the behavior of several state-of-the-art LMs across different previously neglected axes, such as model scale and likelihood, assessing predictions on a fairness dataset specifically designed to quantify LMs' outputs' hurtfulness. Finally, we conclude with an in-depth qualitative assessment of the beliefs emitted by the models. We apply FairBelief to English LMs, revealing that, although these architectures enable high performances on diverse natural language processing tasks, they show hurtful beliefs about specific genders. Interestingly, training procedure and dataset, model scale, and architecture induce beliefs of different degrees of hurtfulness.\n    ",
        "primary_category": "cs.CL",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "27 Feb 2024",
        "last_revised_date": " "
    },
    "2402.17392": {
        "title": "Spot the bot: Coarse-Grained Partition of Semantic Paths for Bots and Humans",
        "authors": [
            "Vasilii A. Gromov",
            "Alexandra S. Kogan"
        ],
        "comments": " ",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "Nowadays, technology is rapidly advancing: bots are writing comments, articles, and reviews. Due to this fact, it is crucial to know if the text was written by a human or by a bot. This paper focuses on comparing structures of the coarse-grained partitions of semantic paths for human-written and bot-generated texts. We compare the clusterizations of datasets of n-grams from literary texts and texts generated by several bots. The hypothesis is that the structures and clusterizations are different. Our research supports the hypothesis. As the semantic structure may be different for different languages, we investigate Russian, English, German, and Vietnamese languages.\n    ",
        "primary_category": "cs.CL",
        "categories": [],
        "submitted_date": "27 Feb 2024",
        "last_revised_date": " "
    },
    "2402.17398": {
        "title": "A Quantum Approach to Synthetic Minority Oversampling Technique (SMOTE)",
        "authors": [
            "Nishikanta Mohanty",
            "Bikash K. Behera",
            "Christopher Ferrie",
            "Pravat Dash"
        ],
        "comments": "18 Pages, 22 Figures, 2 Tables",
        "subjects": "Quantum Physics (quant-ph)",
        "abstract": "The paper proposes the Quantum-SMOTE method, a novel solution that uses quantum computing techniques to solve the prevalent problem of class imbalance in machine learning datasets. Quantum-SMOTE, inspired by the Synthetic Minority Oversampling Technique (SMOTE), generates synthetic data points using quantum processes such as swap tests and quantum rotation. The process varies from the conventional SMOTE algorithm's usage of K-Nearest Neighbors (KNN) and Euclidean distances, enabling synthetic instances to be generated from minority class data points without relying on neighbor proximity. The algorithm asserts greater control over the synthetic data generation process by introducing hyperparameters such as rotation angle, minority percentage, and splitting factor, which allow for customization to specific dataset requirements. The approach is tested on a public dataset of TelecomChurn and evaluated alongside two prominent classification algorithms, Random Forest and Logistic Regression, to determine its impact along with varying proportions of synthetic data.\n    ",
        "primary_category": "quant-ph",
        "categories": [
            "cs.AI",
            "cs.LG"
        ],
        "submitted_date": "27 Feb 2024",
        "last_revised_date": " "
    },
    "2402.17411": {
        "title": "Consistency Matters: Explore LLMs Consistency From a Black-Box Perspective",
        "authors": [
            "Fufangchen Zhao",
            "Guoqiang Jin",
            "Jiaheng Huang",
            "Rui Zhao",
            "Fei Tan"
        ],
        "comments": "This paper is not ready",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "Nowadays both commercial and open-source academic LLM have become the mainstream models of NLP. However, there is still a lack of research on LLM consistency, meaning that throughout the various stages of LLM research and deployment, its internal parameters and capabilities should remain unchanged. This issue exists in both the industrial and academic sectors. The solution to this problem is often time-consuming and labor-intensive, and there is also an additional cost of secondary deployment, resulting in economic and time losses. To fill this gap, we build an LLM consistency task dataset and design several baselines. Additionally, we choose models of diverse scales for the main experiments. Specifically, in the LightGBM experiment, we used traditional NLG metrics (i.e., ROUGE, BLEU, METEOR) as the features needed for model training. The final result exceeds the manual evaluation and GPT3.5 as well as other models in the main experiment, achieving the best performance. In the end, we use the best performing LightGBM model as the base model to build the evaluation tool, which can effectively assist in the deployment of business models. Our code and tool demo are available at this https URL\n",
        "primary_category": "cs.CL",
        "categories": [],
        "submitted_date": "27 Feb 2024",
        "last_revised_date": " "
    },
    "2402.17414": {
        "title": "Neural Video Compression with Feature Modulation",
        "authors": [
            "Jiahao Li",
            "Bin Li",
            "Yan Lu"
        ],
        "comments": "CVPR 2024. Codes are at this https URL",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "The emerging conditional coding-based neural video codec (NVC) shows superiority over commonly-used residual coding-based codec and the latest NVC already claims to outperform the best traditional codec. However, there still exist critical problems blocking the practicality of NVC. In this paper, we propose a powerful conditional coding-based NVC that solves two critical problems via feature modulation. The first is how to support a wide quality range in a single model. Previous NVC with this capability only supports about 3.8 dB PSNR range on average. To tackle this limitation, we modulate the latent feature of the current frame via the learnable quantization scaler. During the training, we specially design the uniform quantization parameter sampling mechanism to improve the harmonization of encoding and quantization. This results in a better learning of the quantization scaler and helps our NVC support about 11.4 dB PSNR range. The second is how to make NVC still work under a long prediction chain. We expose that the previous SOTA NVC has an obvious quality degradation problem when using a large intra-period setting. To this end, we propose modulating the temporal feature with a periodically refreshing mechanism to boost the quality. %Besides solving the above two problems, we also design a single model that can support both RGB and YUV colorspaces. Notably, under single intra-frame setting, our codec can achieve 29.7\\% bitrate saving over previous SOTA NVC with 16\\% MACs reduction. Our codec serves as a notable landmark in the journey of NVC evolution. The codes are at this https URL.\n    ",
        "primary_category": "cs.CV",
        "categories": [
            "eess.IV"
        ],
        "submitted_date": "27 Feb 2024",
        "last_revised_date": " "
    },
    "2402.17485": {
        "title": "EMO: Emote Portrait Alive -- Generating Expressive Portrait Videos with Audio2Video Diffusion Model under Weak Conditions",
        "authors": [
            "Linrui Tian",
            "Qi Wang",
            "Bang Zhang",
            "Liefeng Bo"
        ],
        "comments": " ",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "In this work, we tackle the challenge of enhancing the realism and expressiveness in talking head video generation by focusing on the dynamic and nuanced relationship between audio cues and facial movements. We identify the limitations of traditional techniques that often fail to capture the full spectrum of human expressions and the uniqueness of individual facial styles. To address these issues, we propose EMO, a novel framework that utilizes a direct audio-to-video synthesis approach, bypassing the need for intermediate 3D models or facial landmarks. Our method ensures seamless frame transitions and consistent identity preservation throughout the video, resulting in highly expressive and lifelike animations. Experimental results demonsrate that EMO is able to produce not only convincing speaking videos but also singing videos in various styles, significantly outperforming existing state-of-the-art methodologies in terms of expressiveness and realism.\n    ",
        "primary_category": "cs.CV",
        "categories": [],
        "submitted_date": "27 Feb 2024",
        "last_revised_date": " "
    },
    "2402.17512": {
        "title": "Latent Attention for Linear Time Transformers",
        "authors": [
            "Rares Dolga",
            "Marius Cobzarenco",
            "David Barber"
        ],
        "comments": " ",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "The time complexity of the standard attention mechanism in a transformer scales quadratically with the length of the sequence. We introduce a method to reduce this to linear scaling with time, based on defining attention via latent vectors. The method is readily usable as a drop-in replacement for the standard attention mechanism. Our \"Latte Transformer\" model can be implemented for both bidirectional and unidirectional tasks, with the causal version allowing a recurrent implementation which is memory and time-efficient during inference of language generation tasks. Whilst next token prediction scales linearly with the sequence length for a standard transformer, a Latte Transformer requires constant time to compute the next token. The empirical performance of our method is comparable to standard attention, yet allows scaling to context windows much larger than practical in standard attention.\n    ",
        "primary_category": "cs.CL",
        "categories": [
            "stat.ML"
        ],
        "submitted_date": "27 Feb 2024",
        "last_revised_date": " "
    },
    "2402.17688": {
        "title": "Novel spectral methods for shock capturing and the removal of tygers in computational fluid dynamics",
        "authors": [
            "Sai Swetha Venkata Kolluru",
            "Nicolas Besse",
            "Rahul Pandit"
        ],
        "comments": " ",
        "subjects": "Numerical Analysis (math.NA)",
        "abstract": "Spectral methods yield numerical solutions of the Galerkin-truncated versions of nonlinear partial differential equations involved especially in fluid dynamics. In the presence of discontinuities, such as shocks, spectral approximations develop Gibbs oscillations near the discontinuity. This causes the numerical solution to deviate quickly from the true solution. For spectral approximations of the 1D inviscid Burgers equation, nonlinear wave resonances lead to the formation of tygers in well-resolved areas of the flow, far from the shock. Recently, Besse(to be published) has proposed novel spectral relaxation (SR) and spectral purging (SP) schemes for the removal of tygers and Gibbs oscillations in spectral approximations of nonlinear conservation laws. For the 1D inviscid Burgers equation, it is shown that the novel SR and SP approximations of the solution converge strongly in L2 norm to the entropic weak solution, under an appropriate choice of kernels and related parameters. In this work, we carry out a detailed numerical investigation of SR and SP schemes when applied to the 1D inviscid Burgers equation and report the efficiency of shock capture and the removal of tygers. We then extend our study to systems of nonlinear hyperbolic conservation laws - such as the 2x2 system of the shallow water equations and the standard 3x3 system of 1D compressible Euler equations. For the latter, we generalise the implementation of SR methods to non-periodic problems using Chebyshev polynomials. We then turn to singular flow in the 1D wall approximation of the 3D-axisymmetric wall-bounded incompressible Euler equation. Here, in order to determine the blowup time of the solution, we compare the decay of the width of the analyticity strip, obtained from the pure pseudospectral method, with the improved estimate obtained using the novel spectral relaxation scheme.\n    ",
        "primary_category": "math.NA",
        "categories": [
            "physics.comp-ph"
        ],
        "submitted_date": "27 Feb 2024",
        "last_revised_date": " "
    },
    "2402.17747": {
        "title": "When Your AIs Deceive You: Challenges with Partial Observability of Human Evaluators in Reward Learning",
        "authors": [
            "Leon Lang",
            "Davis Foote",
            "Stuart Russell",
            "Anca Dragan",
            "Erik Jenner",
            "Scott Emmons"
        ],
        "comments": " ",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Past analyses of reinforcement learning from human feedback (RLHF) assume that the human fully observes the environment. What happens when human feedback is based only on partial observations? We formally define two failure cases: deception and overjustification. Modeling the human as Boltzmann-rational w.r.t. a belief over trajectories, we prove conditions under which RLHF is guaranteed to result in policies that deceptively inflate their performance, overjustify their behavior to make an impression, or both. To help address these issues, we mathematically characterize how partial observability of the environment translates into (lack of) ambiguity in the learned return function. In some cases, accounting for partial observability makes it theoretically possible to recover the return function and thus the optimal policy, while in other cases, there is irreducible ambiguity. We caution against blindly applying RLHF in partially observable settings and propose research directions to help tackle these challenges.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.AI",
            "stat.ML"
        ],
        "submitted_date": "27 Feb 2024",
        "last_revised_date": " "
    },
    "2402.17758": {
        "title": "ADL4D: Towards A Contextually Rich Dataset for 4D Activities of Daily Living",
        "authors": [
            "Marsil Zakour",
            "Partha Pratim Nath",
            "Ludwig Lohmer",
            "Emre Faik G\u00f6k\u00e7e",
            "Martin Piccolrovazzi",
            "Constantin Patsch",
            "Yuankai Wu",
            "Rahul Chaudhari",
            "Eckehard Steinbach"
        ],
        "comments": " ",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Hand-Object Interactions (HOIs) are conditioned on spatial and temporal contexts like surrounding objects, previous actions, and future intents (for example, grasping and handover actions vary greatly based on objects proximity and trajectory obstruction). However, existing datasets for 4D HOI (3D HOI over time) are limited to one subject interacting with one object only. This restricts the generalization of learning-based HOI methods trained on those datasets. We introduce ADL4D, a dataset of up to two subjects interacting with different sets of objects performing Activities of Daily Living (ADL) like breakfast or lunch preparation activities. The transition between multiple objects to complete a certain task over time introduces a unique context lacking in existing datasets. Our dataset consists of 75 sequences with a total of 1.1M RGB-D frames, hand and object poses, and per-hand fine-grained action annotations. We develop an automatic system for multi-view multi-hand 3D pose annotation capable of tracking hand poses over time. We integrate and test it against publicly available datasets. Finally, we evaluate our dataset on the tasks of Hand Mesh Recovery (HMR) and Hand Action Segmentation (HAS).\n    ",
        "primary_category": "cs.CV",
        "categories": [],
        "submitted_date": "27 Feb 2024",
        "last_revised_date": " "
    },
    "2402.17759": {
        "title": "Towards Optimal Learning of Language Models",
        "authors": [
            "Yuxian Gu",
            "Li Dong",
            "Yaru Hao",
            "Qingxiu Dong",
            "Minlie Huang",
            "Furu Wei"
        ],
        "comments": " ",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "This work studies the general principles of improving the learning of language models (LMs), which aims at reducing the necessary training steps for achieving superior performance. Specifically, we present a theory for the optimal learning of LMs. We first propose an objective that optimizes LM learning by maximizing the data compression ratio in an \"LM-training-as-lossless-compression\" view. Then, we derive a theorem, named Learning Law, to reveal the properties of the dynamics in the optimal learning process under our objective. The theorem is then validated by experiments on a linear classification and a real-world language modeling task. Finally, we empirically verify that the optimal learning of LMs essentially stems from the improvement of the coefficients in the scaling law of LMs, indicating great promise and significance for designing practical learning acceleration methods. Our code can be found at this https URL.\n    ",
        "primary_category": "cs.CL",
        "categories": [],
        "submitted_date": "27 Feb 2024",
        "last_revised_date": " "
    },
    "2402.17810": {
        "title": "BioT5+: Towards Generalized Biological Understanding with IUPAC Integration and Multi-task Tuning",
        "authors": [
            "Qizhi Pei",
            "Lijun Wu",
            "Kaiyuan Gao",
            "Xiaozhuan Liang",
            "Yin Fang",
            "Jinhua Zhu",
            "Shufang Xie",
            "Tao Qin",
            "Rui Yan"
        ],
        "comments": "24 pages",
        "subjects": "Quantitative Methods (q-bio.QM)",
        "abstract": "Recent research trends in computational biology have increasingly focused on integrating text and bio-entity modeling, especially in the context of molecules and proteins. However, previous efforts like BioT5 faced challenges in generalizing across diverse tasks and lacked a nuanced understanding of molecular structures, particularly in their textual representations (e.g., IUPAC). This paper introduces BioT5+, an extension of the BioT5 framework, tailored to enhance biological research and drug discovery. BioT5+ incorporates several novel features: integration of IUPAC names for molecular understanding, inclusion of extensive bio-text and molecule data from sources like bioRxiv and PubChem, the multi-task instruction tuning for generality across tasks, and a novel numerical tokenization technique for improved processing of numerical data. These enhancements allow BioT5+ to bridge the gap between molecular representations and their textual descriptions, providing a more holistic understanding of biological entities, and largely improving the grounded reasoning of bio-text and bio-sequences. The model is pre-trained and fine-tuned with a large number of experiments, including \\emph{3 types of problems (classification, regression, generation), 15 kinds of tasks, and 21 total benchmark datasets}, demonstrating the remarkable performance and state-of-the-art results in most cases. BioT5+ stands out for its ability to capture intricate relationships in biological data, thereby contributing significantly to bioinformatics and computational biology. Our code is available at \\url{this https URL}.\n    ",
        "primary_category": "q-bio.QM",
        "categories": [
            "cs.AI",
            "cs.CE",
            "cs.LG",
            "q-bio.BM"
        ],
        "submitted_date": "27 Feb 2024",
        "last_revised_date": " "
    },
    "2402.17846": {
        "title": "On the Parameterized Complexity of Motion Planning for Rectangular Robots",
        "authors": [
            "Iyad Kanj",
            "Salman Parsa"
        ],
        "comments": " ",
        "subjects": "Computational Geometry (cs.CG)",
        "abstract": "We study computationally-hard fundamental motion planning problems where the goal is to translate $k$ axis-aligned rectangular robots from their initial positions to their final positions without collision, and with the minimum number of translation moves. Our aim is to understand the interplay between the number of robots and the geometric complexity of the input instance measured by the input size, which is the number of bits needed to encode the coordinates of the rectangles' vertices. We focus on axis-aligned translations, and more generally, translations restricted to a given set of directions, and we study the two settings where the robots move in the free plane, and where they are confined to a bounding box. We obtain fixed-parameter tractable (FPT) algorithms parameterized by $k$ for all the settings under consideration. In the case where the robots move serially (i.e., one in each time step) and axis-aligned, we prove a structural result stating that every problem instance admits an optimal solution in which the moves are along a grid, whose size is a function of $k$, that can be defined based on the input instance. This structural result implies that the problem is fixed-parameter tractable parameterized by $k$. We also consider the case in which the robots move in parallel (i.e., multiple robots can move during the same time step), and which falls under the category of Coordinated Motion Planning problems. Finally, we show that, when the robots move in the free plane, the FPT results for the serial motion case carry over to the case where the translations are restricted to any given set of directions.\n    ",
        "primary_category": "cs.CG",
        "categories": [],
        "submitted_date": "27 Feb 2024",
        "last_revised_date": " "
    },
    "2402.17886": {
        "title": "Zeroth-Order Sampling Methods for Non-Log-Concave Distributions: Alleviating Metastability by Denoising Diffusion",
        "authors": [
            "Ye He",
            "Kevin Rojas",
            "Molei Tao"
        ],
        "comments": "Figure 4 on page 13 corrected. Comments are welcome",
        "subjects": "Machine Learning (stat.ML)",
        "abstract": "This paper considers the problem of sampling from non-logconcave distribution, based on queries of its unnormalized density. It first describes a framework, Diffusion Monte Carlo (DMC), based on the simulation of a denoising diffusion process with its score function approximated by a generic Monte Carlo estimator. DMC is an oracle-based meta-algorithm, where its oracle is the assumed access to samples that generate a Monte Carlo score estimator. Then we provide an implementation of this oracle, based on rejection sampling, and this turns DMC into a true algorithm, termed Zeroth-Order Diffusion Monte Carlo (ZOD-MC). We provide convergence analyses by first constructing a general framework, i.e. a performance guarantee for DMC, without assuming the target distribution to be log-concave or satisfying any isoperimetric inequality. Then we prove that ZOD-MC admits an inverse polynomial dependence on the desired sampling accuracy, albeit still suffering from the curse of dimensionality. Consequently, for low dimensional distributions, ZOD-MC is a very efficient sampler, with performance exceeding latest samplers, including also-denoising-diffusion-based RDMC and RS-DMC. Last, we experimentally demonstrate the insensitivity of ZOD-MC to increasingly higher barriers between modes or discontinuity in non-convex potential.\n    ",
        "primary_category": "stat.ML",
        "categories": [
            "cs.LG",
            "math.PR",
            "math.ST",
            "stat.ME"
        ],
        "submitted_date": "27 Feb 2024",
        "last_revised_date": " "
    },
    "2402.17897": {
        "title": "A Language Model based Framework for New Concept Placement in Ontologies",
        "authors": [
            "Hang Dong",
            "Jiaoyan Chen",
            "Yuan He",
            "Yongsheng Gao",
            "Ian Horrocks"
        ],
        "comments": "20 pages, 3 figures, accepted for ESWC 2024",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "We investigate the task of inserting new concepts extracted from texts into an ontology using language models. We explore an approach with three steps: edge search which is to find a set of candidate locations to insert (i.e., subsumptions between concepts), edge formation and enrichment which leverages the ontological structure to produce and enhance the edge candidates, and edge selection which eventually locates the edge to be placed into. In all steps, we propose to leverage neural methods, where we apply embedding-based methods and contrastive learning with Pre-trained Language Models (PLMs) such as BERT for edge search, and adapt a BERT fine-tuning-based multi-label Edge-Cross-encoder, and Large Language Models (LLMs) such as GPT series, FLAN-T5, and Llama 2, for edge selection. We evaluate the methods on recent datasets created using the SNOMED CT ontology and the MedMentions entity linking benchmark. The best settings in our framework use fine-tuned PLM for search and a multi-label Cross-encoder for selection. Zero-shot prompting of LLMs is still not adequate for the task, and we propose explainable instruction tuning of LLMs for improved performance. Our study shows the advantages of PLMs and highlights the encouraging performance of LLMs that motivates future studies.\n    ",
        "primary_category": "cs.CL",
        "categories": [
            "cs.IR"
        ],
        "submitted_date": "27 Feb 2024",
        "last_revised_date": " "
    },
    "2402.17926": {
        "title": "Certain and Approximately Certain Models for Statistical Learning",
        "authors": [
            "Cheng Zhen",
            "Nischal Aryal",
            "Arash Termehchy",
            "Alireza Aghasi",
            "Amandeep Singh Chabada"
        ],
        "comments": "A technical report for a paper to appear at SIGMOD 2024",
        "subjects": "Machine Learning (stat.ML)",
        "abstract": "Real-world data is often incomplete and contains missing values. To train accurate models over real-world datasets, users need to spend a substantial amount of time and resources imputing and finding proper values for missing data items. In this paper, we demonstrate that it is possible to learn accurate models directly from data with missing values for certain training data and target models. We propose a unified approach for checking the necessity of data imputation to learn accurate models across various widely-used machine learning paradigms. We build efficient algorithms with theoretical guarantees to check this necessity and return accurate models in cases where imputation is unnecessary. Our extensive experiments indicate that our proposed algorithms significantly reduce the amount of time and effort needed for data imputation without imposing considerable computational overhead.\n    ",
        "primary_category": "stat.ML",
        "categories": [
            "cs.DB",
            "cs.LG"
        ],
        "submitted_date": "27 Feb 2024",
        "last_revised_date": " "
    },
    "2402.17932": {
        "title": "A Heterogeneous Agent Model of Mortgage Servicing: An Income-based Relief Analysis",
        "authors": [
            "Deepeka Garg",
            "Benjamin Patrick Evans",
            "Leo Ardon",
            "Annapoorani Lakshmi Narayanan",
            "Jared Vann",
            "Udari Madhushani",
            "Makada Henry-Nickie",
            "Sumitra Ganesh"
        ],
        "comments": "AAAI 2024 - AI in Finance for Social Impact",
        "subjects": "Multiagent Systems (cs.MA)",
        "abstract": "Mortgages account for the largest portion of household debt in the United States, totaling around \\$12 trillion nationwide. In times of financial hardship, alleviating mortgage burdens is essential for supporting affected households. The mortgage servicing industry plays a vital role in offering this assistance, yet there has been limited research modelling the complex relationship between households and servicers. To bridge this gap, we developed an agent-based model that explores household behavior and the effectiveness of relief measures during financial distress. Our model represents households as adaptive learning agents with realistic financial attributes. These households experience exogenous income shocks, which may influence their ability to make mortgage payments. Mortgage servicers provide relief options to these households, who then choose the most suitable relief based on their unique financial circumstances and individual preferences. We analyze the impact of various external shocks and the success of different mortgage relief strategies on specific borrower subgroups. Through this analysis, we show that our model can not only replicate real-world mortgage studies but also act as a tool for conducting a broad range of what-if scenario analyses. Our approach offers fine-grained insights that can inform the development of more effective and inclusive mortgage relief solutions.\n    ",
        "primary_category": "cs.MA",
        "categories": [
            "q-fin.GN"
        ],
        "submitted_date": "27 Feb 2024",
        "last_revised_date": " "
    },
    "2402.17944": {
        "title": "Large Language Models(LLMs) on Tabular Data: Prediction, Generation, and Understanding -- A Survey",
        "authors": [
            "Xi Fang",
            "Weijie Xu",
            "Fiona Anting Tan",
            "Jiani Zhang",
            "Ziqing Hu",
            "Yanjun Qi",
            "Scott Nickleach",
            "Diego Socolinsky",
            "Srinivasan Sengamedu",
            "Christos Faloutsos"
        ],
        "comments": "41 pages, 4 figures, 8 tables",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "Recent breakthroughs in large language modeling have facilitated rigorous exploration of their application in diverse tasks related to tabular data modeling, such as prediction, tabular data synthesis, question answering, and table understanding. Each task presents unique challenges and opportunities. However, there is currently a lack of comprehensive review that summarizes and compares the key techniques, metrics, datasets, models, and optimization approaches in this research domain. This survey aims to address this gap by consolidating recent progress in these areas, offering a thorough survey and taxonomy of the datasets, metrics, and methodologies utilized. It identifies strengths, limitations, unexplored territories, and gaps in the existing literature, while providing some insights for future research directions in this vital and rapidly evolving field. It also provides relevant code and datasets references. Through this comprehensive review, we hope to provide interested readers with pertinent references and insightful perspectives, empowering them with the necessary tools and knowledge to effectively navigate and address the prevailing challenges in the field.\n    ",
        "primary_category": "cs.CL",
        "categories": [],
        "submitted_date": "27 Feb 2024",
        "last_revised_date": " "
    },
    "2402.17970": {
        "title": "Exploring Advanced Methodologies in Security Evaluation for LLMs",
        "authors": [
            "Jun Huang",
            "Jiawei Zhang",
            "Qi Wang",
            "Weihong Han",
            "Yanchun Zhang"
        ],
        "comments": " ",
        "subjects": "Cryptography and Security (cs.CR)",
        "abstract": "Large Language Models (LLMs) represent an advanced evolution of earlier, simpler language models. They boast enhanced abilities to handle complex language patterns and generate coherent text, images, audios, and videos. Furthermore, they can be fine-tuned for specific tasks. This versatility has led to the proliferation and extensive use of numerous commercialized large models. However, the rapid expansion of LLMs has raised security and ethical concerns within the academic community. This emphasizes the need for ongoing research into security evaluation during their development and deployment. Over the past few years, a substantial body of research has been dedicated to the security evaluation of large-scale models. This article an in-depth review of the most recent advancements in this field, providing a comprehensive analysis of commonly used evaluation metrics, advanced evaluation frameworks, and the routine evaluation processes for LLMs. Furthermore, we also discuss the future directions for advancing the security evaluation of LLMs.\n    ",
        "primary_category": "cs.CR",
        "categories": [],
        "submitted_date": "28 Feb 2024",
        "last_revised_date": " "
    },
    "2402.17978": {
        "title": "Imagine, Initialize, and Explore: An Effective Exploration Method in Multi-Agent Reinforcement Learning",
        "authors": [
            "Zeyang Liu",
            "Lipeng Wan",
            "Xinrui Yang",
            "Zhuoran Chen",
            "Xingyu Chen",
            "Xuguang Lan"
        ],
        "comments": "The 38th Annual AAAI Conference on Artificial Intelligence",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Effective exploration is crucial to discovering optimal strategies for multi-agent reinforcement learning (MARL) in complex coordination tasks. Existing methods mainly utilize intrinsic rewards to enable committed exploration or use role-based learning for decomposing joint action spaces instead of directly conducting a collective search in the entire action-observation space. However, they often face challenges obtaining specific joint action sequences to reach successful states in long-horizon tasks. To address this limitation, we propose Imagine, Initialize, and Explore (IIE), a novel method that offers a promising solution for efficient multi-agent exploration in complex scenarios. IIE employs a transformer model to imagine how the agents reach a critical state that can influence each other's transition functions. Then, we initialize the environment at this state using a simulator before the exploration phase. We formulate the imagination as a sequence modeling problem, where the states, observations, prompts, actions, and rewards are predicted autoregressively. The prompt consists of timestep-to-go, return-to-go, influence value, and one-shot demonstration, specifying the desired state and trajectory as well as guiding the action generation. By initializing agents at the critical states, IIE significantly increases the likelihood of discovering potentially important under-explored regions. Despite its simplicity, empirical results demonstrate that our method outperforms multi-agent exploration baselines on the StarCraft Multi-Agent Challenge (SMAC) and SMACv2 environments. Particularly, IIE shows improved performance in the sparse-reward SMAC tasks and produces more effective curricula over the initialized states than other generative methods, such as CVAE-GAN and diffusion models.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.AI",
            "cs.MA"
        ],
        "submitted_date": "28 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18007": {
        "title": "Mixer is more than just a model",
        "authors": [
            "Qingfeng Ji",
            "Yuxin Wang",
            "Letong Sun"
        ],
        "comments": " ",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Recently, MLP structures have regained popularity, with MLP-Mixer standing out as a prominent example. In the field of computer vision, MLP-Mixer is noted for its ability to extract data information from both channel and token perspectives, effectively acting as a fusion of channel and token information. Indeed, Mixer represents a paradigm for information extraction that amalgamates channel and token information. The essence of Mixer lies in its ability to blend information from diverse perspectives, epitomizing the true concept of \"mixing\" in the realm of neural network architectures. Beyond channel and token considerations, it is possible to create more tailored mixers from various perspectives to better suit specific task requirements. This study focuses on the domain of audio recognition, introducing a novel model named Audio Spectrogram Mixer with Roll-Time and Hermit FFT (ASM-RH) that incorporates insights from both time and frequency domains. Experimental results demonstrate that ASM-RH is particularly well-suited for audio data and yields promising outcomes across multiple classification tasks. The models and optimal weights files will be published.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.AI",
            "cs.SD",
            "eess.AS"
        ],
        "submitted_date": "28 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18028": {
        "title": "OpenMEDLab: An Open-source Platform for Multi-modality Foundation Models in Medicine",
        "authors": [
            "Xiaosong Wang",
            "Xiaofan Zhang",
            "Guotai Wang",
            "Junjun He",
            "Zhongyu Li",
            "Wentao Zhu",
            "Yi Guo",
            "Qi Dou",
            "Xiaoxiao Li",
            "Dequan Wang",
            "Liang Hong",
            "Qicheng Lao",
            "Tong Ruan",
            "Yukun Zhou",
            "Yixue Li",
            "Jie Zhao",
            "Kang Li",
            "Xin Sun",
            "Lifeng Zhu",
            "Shaoting Zhang"
        ],
        "comments": "Technical Report. Visit this https URL for more details",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "The emerging trend of advancing generalist artificial intelligence, such as GPTv4 and Gemini, has reshaped the landscape of research (academia and industry) in machine learning and many other research areas. However, domain-specific applications of such foundation models (e.g., in medicine) remain untouched or often at their very early stages. It will require an individual set of transfer learning and model adaptation techniques by further expanding and injecting these models with domain knowledge and data. The development of such technologies could be largely accelerated if the bundle of data, algorithms, and pre-trained foundation models were gathered together and open-sourced in an organized manner. In this work, we present OpenMEDLab, an open-source platform for multi-modality foundation models. It encapsulates not only solutions of pioneering attempts in prompting and fine-tuning large language and vision models for frontline clinical and bioinformatic applications but also building domain-specific foundation models with large-scale multi-modal medical data. Importantly, it opens access to a group of pre-trained foundation models for various medical image modalities, clinical text, protein engineering, etc. Inspiring and competitive results are also demonstrated for each collected approach and model in a variety of benchmarks for downstream tasks. We welcome researchers in the field of medical artificial intelligence to continuously contribute cutting-edge methods and models to OpenMEDLab, which can be accessed via this https URL.\n    ",
        "primary_category": "cs.CV",
        "categories": [],
        "submitted_date": "28 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18045": {
        "title": "Multi-FAct: Assessing Multilingual LLMs' Multi-Regional Knowledge using FActScore",
        "authors": [
            "Sheikh Shafayat",
            "Eunsu Kim",
            "Juhyun Oh",
            "Alice Oh"
        ],
        "comments": " ",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "Large Language Models (LLMs) are prone to factuality hallucination, generating text that contradicts established knowledge. While extensive research has addressed this in English, little is known about multilingual LLMs. This paper systematically evaluates multilingual LLMs' factual accuracy across languages and geographic regions. We introduce a novel pipeline for multilingual factuality evaluation, adapting FActScore(Min et al., 2023) for diverse languages. Our analysis across nine languages reveals that English consistently outperforms others in factual accuracy and quantity of generated facts. Furthermore, multilingual models demonstrate a bias towards factual information from Western continents. These findings highlight the need for improved multilingual factuality assessment and underscore geographical biases in LLMs' fact generation.\n    ",
        "primary_category": "cs.CL",
        "categories": [],
        "submitted_date": "28 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18065": {
        "title": "A Probabilistic Motion Model for Skid-Steer Wheeled Mobile Robot Navigation on Off-Road Terrains",
        "authors": [
            "Ananya Trivedi",
            "Mark Zolotas",
            "Adeeb Abbas",
            "Sarvesh Prajapati",
            "Salah Bazzi",
            "Task\u0131n Pad\u0131r"
        ],
        "comments": "Accepted for publication at IEEE ICRA 2024",
        "subjects": "Robotics (cs.RO)",
        "abstract": "Skid-Steer Wheeled Mobile Robots (SSWMRs) are increasingly being used for off-road autonomy applications. When turning at high speeds, these robots tend to undergo significant skidding and slipping. In this work, using Gaussian Process Regression (GPR) and Sigma-Point Transforms, we estimate the non-linear effects of tire-terrain interaction on robot velocities in a probabilistic fashion. Using the mean estimates from GPR, we propose a data-driven dynamic motion model that is more accurate at predicting future robot poses than conventional kinematic motion models. By efficiently solving a convex optimization problem based on the history of past robot motion, the GPR augmented motion model generalizes to previously unseen terrain conditions. The output distribution from the proposed motion model can be used for local motion planning approaches, such as stochastic model predictive control, leveraging model uncertainty to make safe decisions. We validate our work on a benchmark real-world multi-terrain SSWMR dataset. Our results show that the model generalizes to three different terrains while significantly reducing errors in linear and angular motion predictions. As shown in the attached video, we perform a separate set of experiments on a physical robot to demonstrate the robustness of the proposed algorithm.\n    ",
        "primary_category": "cs.RO",
        "categories": [],
        "submitted_date": "28 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18101": {
        "title": "Assessing the Efficacy of Grammar Error Correction: A Human Evaluation Approach in the Japanese Context",
        "authors": [
            "Qiao Wang",
            "Zheng Yuan"
        ],
        "comments": "2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation (LREC-COLING 2024)",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "In this study, we evaluated the performance of the state-of-the-art sequence tagging grammar error detection and correction model (SeqTagger) using Japanese university students' writing samples. With an automatic annotation toolkit, ERRANT, we first evaluated SeqTagger's performance on error correction with human expert correction as the benchmark. Then a human-annotated approach was adopted to evaluate Seqtagger's performance in error detection using a subset of the writing dataset. Results indicated a precision of 63.66% and a recall of 20.19% for error correction in the full dataset. For the subset, after manual exclusion of irrelevant errors such as semantic and mechanical ones, the model shows an adjusted precision of 97.98% and an adjusted recall of 42.98% for error detection, indicating the model's high accuracy but also its conservativeness. Thematic analysis on errors undetected by the model revealed that determiners and articles, especially the latter, were predominant. Specifically, in terms of context-independent errors, the model occasionally overlooked basic ones and faced challenges with overly erroneous or complex structures. Meanwhile, context-dependent errors, notably those related to tense and noun number, as well as those possibly influenced by the students' first language (L1), remained particularly challenging.\n    ",
        "primary_category": "cs.CL",
        "categories": [],
        "submitted_date": "28 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18122": {
        "title": "G4G:A Generic Framework for High Fidelity Talking Face Generation with Fine-grained Intra-modal Alignment",
        "authors": [
            "Juan Zhang",
            "Jiahao Chen",
            "Cheng Wang",
            "Zhiwang Yu",
            "Tangquan Qi",
            "Di Wu"
        ],
        "comments": " ",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Despite numerous completed studies, achieving high fidelity talking face generation with highly synchronized lip movements corresponding to arbitrary audio remains a significant challenge in the field. The shortcomings of published studies continue to confuse many researchers. This paper introduces G4G, a generic framework for high fidelity talking face generation with fine-grained intra-modal alignment. G4G can reenact the high fidelity of original video while producing highly synchronized lip movements regardless of given audio tones or volumes. The key to G4G's success is the use of a diagonal matrix to enhance the ordinary alignment of audio-image intra-modal features, which significantly increases the comparative learning between positive and negative samples. Additionally, a multi-scaled supervision module is introduced to comprehensively reenact the perceptional fidelity of original video across the facial region while emphasizing the synchronization of lip movements and the input audio. A fusion network is then used to further fuse the facial region and the rest. Our experimental results demonstrate significant achievements in reenactment of original video quality as well as highly synchronized talking lips. G4G is an outperforming generic framework that can produce talking videos competitively closer to ground truth level than current state-of-the-art methods.\n    ",
        "primary_category": "cs.CV",
        "categories": [
            "cs.MM"
        ],
        "submitted_date": "28 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18123": {
        "title": "Fixture calibration with guaranteed bounds from a few correspondence-free surface points",
        "authors": [
            "Rasmus Laurvig Haugaard",
            "Yitaek Kim",
            "Thorbj\u00f8rn Mosekj\u00e6r Iversen"
        ],
        "comments": "ICRA 2024",
        "subjects": "Robotics (cs.RO)",
        "abstract": "Calibration of fixtures in robotic work cells is essential but also time consuming and error-prone, and poor calibration can easily lead to wasted debugging time in downstream tasks. Contact-based calibration methods let the user measure points on the fixture's surface with a tool tip attached to the robot's end effector. Most such methods require the user to manually annotate correspondences on the CAD model, however, this is error-prone and a cumbersome user experience. We propose a correspondence-free alternative: The user simply measures a few points from the fixture's surface, and our method provides a tight superset of the poses which could explain the measured points. This naturally detects ambiguities related to symmetry and uninformative points and conveys this uncertainty to the user. Perhaps more importantly, it provides guaranteed bounds on the pose. The computation of such bounds is made tractable by the use of a hierarchical grid on SE(3). Our method is evaluated both in simulation and on a real collaborative robot, showing great potential for easier and less error-prone fixture calibration. Project page at this https URL\n",
        "primary_category": "cs.RO",
        "categories": [],
        "submitted_date": "28 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18146": {
        "title": "3DSFLabelling: Boosting 3D Scene Flow Estimation by Pseudo Auto-labelling",
        "authors": [
            "Chaokang Jiang",
            "Guangming Wang",
            "Jiuming Liu",
            "Hesheng Wang",
            "Zhuang Ma",
            "Zhenqiang Liu",
            "Zhujin Liang",
            "Yi Shan",
            "Dalong Du"
        ],
        "comments": "Accepted by CVPR2024! 10 pages, 6 figures",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Learning 3D scene flow from LiDAR point clouds presents significant difficulties, including poor generalization from synthetic datasets to real scenes, scarcity of real-world 3D labels, and poor performance on real sparse LiDAR point clouds. We present a novel approach from the perspective of auto-labelling, aiming to generate a large number of 3D scene flow pseudo labels for real-world LiDAR point clouds. Specifically, we employ the assumption of rigid body motion to simulate potential object-level rigid movements in autonomous driving scenarios. By updating different motion attributes for multiple anchor boxes, the rigid motion decomposition is obtained for the whole scene. Furthermore, we developed a novel 3D scene flow data augmentation method for global and local motion. By perfectly synthesizing target point clouds based on augmented motion parameters, we easily obtain lots of 3D scene flow labels in point clouds highly consistent with real scenarios. On multiple real-world datasets including LiDAR KITTI, nuScenes, and Argoverse, our method outperforms all previous supervised and unsupervised methods without requiring manual labelling. Impressively, our method achieves a tenfold reduction in EPE3D metric on the LiDAR KITTI dataset, reducing it from $0.190m$ to a mere $0.008m$ error.\n    ",
        "primary_category": "cs.CV",
        "categories": [],
        "submitted_date": "28 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18169": {
        "title": "MIKO: Multimodal Intention Knowledge Distillation from Large Language Models for Social-Media Commonsense Discovery",
        "authors": [
            "Feihong Lu",
            "Weiqi Wang",
            "Yangyifei Luo",
            "Ziqin Zhu",
            "Qingyun Sun",
            "Baixuan Xu",
            "Haochen Shi",
            "Shiqi Gao",
            "Qian Li",
            "Yangqiu Song",
            "Jianxin Li"
        ],
        "comments": "11 pages, 5 figures",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "Social media has become a ubiquitous tool for connecting with others, staying updated with news, expressing opinions, and finding entertainment. However, understanding the intention behind social media posts remains challenging due to the implicitness of intentions in social media posts, the need for cross-modality understanding of both text and images, and the presence of noisy information such as hashtags, misspelled words, and complicated abbreviations. To address these challenges, we present MIKO, a Multimodal Intention Kowledge DistillatiOn framework that collaboratively leverages a Large Language Model (LLM) and a Multimodal Large Language Model (MLLM) to uncover users' intentions. Specifically, we use an MLLM to interpret the image and an LLM to extract key information from the text and finally instruct the LLM again to generate intentions. By applying MIKO to publicly available social media datasets, we construct an intention knowledge base featuring 1,372K intentions rooted in 137,287 posts. We conduct a two-stage annotation to verify the quality of the generated knowledge and benchmark the performance of widely used LLMs for intention generation. We further apply MIKO to a sarcasm detection dataset and distill a student model to demonstrate the downstream benefits of applying intention knowledge.\n    ",
        "primary_category": "cs.CL",
        "categories": [],
        "submitted_date": "28 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18205": {
        "title": "Lemur: Log Parsing with Entropy Sampling and Chain-of-Thought Merging",
        "authors": [
            "Wei Zhang",
            "Hongcheng Guo",
            "Anjie Le",
            "Jian Yang",
            "Jiaheng Liu",
            "Zhoujun Li",
            "Tieqiao Zheng",
            "Shi Xu",
            "Runqiang Zang",
            "Liangfan Zheng",
            "Bo Zhang"
        ],
        "comments": "7 pages",
        "subjects": "Software Engineering (cs.SE)",
        "abstract": "Logs produced by extensive software systems are integral to monitoring system behaviors. Advanced log analysis facilitates the detection, alerting, and diagnosis of system faults. Log parsing, which entails transforming raw log messages into structured templates, constitutes a critical phase in the automation of log analytics. Existing log parsers fail to identify the correct templates due to reliance on human-made rules. Besides, These methods focus on statistical features while ignoring semantic information in log messages. To address these challenges, we introduce a cutting-edge \\textbf{L}og parsing framework with \\textbf{E}ntropy sampling and Chain-of-Thought \\textbf{M}erging (Lemur). Specifically, to discard the tedious manual rules. We propose a novel sampling method inspired by information entropy, which efficiently clusters typical logs. Furthermore, to enhance the merging of log templates, we design a chain-of-thought method for large language models (LLMs). LLMs exhibit exceptional semantic comprehension, deftly distinguishing between parameters and invariant tokens. We have conducted experiments on large-scale public datasets. Extensive evaluation demonstrates that Lemur achieves the state-of-the-art performance and impressive efficiency.\n    ",
        "primary_category": "cs.SE",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "28 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18222": {
        "title": "HearHere: Mitigating Echo Chambers in News Consumption through an AI-based Web System",
        "authors": [
            "Youngseung Jeon",
            "Jaehoon Kim",
            "Sohyun Park",
            "Yunyong Ko",
            "Seongeun Ryu",
            "Sang-Wook Kim",
            "Kyungsik Han"
        ],
        "comments": "34 pages, 6 figures, 6 tables, CSCW 2024",
        "subjects": "Human-Computer Interaction (cs.HC)",
        "abstract": "Considerable efforts are currently underway to mitigate the negative impacts of echo chambers, such as increased susceptibility to fake news and resistance towards accepting scientific evidence. Prior research has presented the development of computer systems that support the consumption of news information from diverse political perspectives to mitigate the echo chamber effect. However, existing studies still lack the ability to effectively support the key processes of news information consumption and quantitatively identify a political stance towards the information. In this paper, we present HearHere, an AI-based web system designed to help users accommodate information and opinions from diverse perspectives. HearHere facilitates the key processes of news information consumption through two visualizations. Visualization 1 provides political news with quantitative political stance information, derived from our graph-based political classification model, and users can experience diverse perspectives (Hear). Visualization 2 allows users to express their opinions on specific political issues in a comment form and observe the position of their own opinions relative to pro-liberal and pro-conservative comments presented on a map interface (Here). Through a user study with 94 participants, we demonstrate the feasibility of HearHere in supporting the consumption of information from various perspectives. Our findings highlight the importance of providing political stance information and quantifying users' political status as a means to mitigate political polarization. In addition, we propose design implications for system development, including the consideration of demographics such as political interest and providing users with initiatives.\n    ",
        "primary_category": "cs.HC",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "28 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18233": {
        "title": "Zero-Shot Aerial Object Detection with Visual Description Regularization",
        "authors": [
            "Zhengqing Zang",
            "Chenyu Lin",
            "Chenwei Tang",
            "Tao Wang",
            "Jiancheng Lv"
        ],
        "comments": "13 pages, 3 figures",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Existing object detection models are mainly trained on large-scale labeled datasets. However, annotating data for novel aerial object classes is expensive since it is time-consuming and may require expert knowledge. Thus, it is desirable to study label-efficient object detection methods on aerial images. In this work, we propose a zero-shot method for aerial object detection named visual Description Regularization, or DescReg. Concretely, we identify the weak semantic-visual correlation of the aerial objects and aim to address the challenge with prior descriptions of their visual appearance. Instead of directly encoding the descriptions into class embedding space which suffers from the representation gap problem, we propose to infuse the prior inter-class visual similarity conveyed in the descriptions into the embedding learning. The infusion process is accomplished with a newly designed similarity-aware triplet loss which incorporates structured regularization on the representation space. We conduct extensive experiments with three challenging aerial object detection datasets, including DIOR, xView, and DOTA. The results demonstrate that DescReg significantly outperforms the state-of-the-art ZSD methods with complex projection designs and generative frameworks, e.g., DescReg outperforms best reported ZSD method on DIOR by 4.5 mAP on unseen classes and 8.1 in HM. We further show the generalizability of DescReg by integrating it into generative ZSD methods as well as varying the detection architecture.\n    ",
        "primary_category": "cs.CV",
        "categories": [],
        "submitted_date": "28 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18243": {
        "title": "Learning or Self-aligning? Rethinking Instruction Fine-tuning",
        "authors": [
            "Mengjie Ren",
            "Boxi Cao",
            "Hongyu Lin",
            "Cao Liu",
            "Xianpei Han",
            "Ke Zeng",
            "Guanglu Wan",
            "Xunliang Cai",
            "Le Sun"
        ],
        "comments": " ",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "Instruction Fine-tuning~(IFT) is a critical phase in building large language models~(LLMs). Previous works mainly focus on the IFT's role in the transfer of behavioral norms and the learning of additional world knowledge. However, the understanding of the underlying mechanisms of IFT remains significantly limited. In this paper, we design a knowledge intervention framework to decouple the potential underlying factors of IFT, thereby enabling individual analysis of different factors. Surprisingly, our experiments reveal that attempting to learn additional world knowledge through IFT often struggles to yield positive impacts and can even lead to markedly negative effects. Further, we discover that maintaining internal knowledge consistency before and after IFT is a critical factor for achieving successful IFT. Our findings reveal the underlying mechanisms of IFT and provide robust support for some very recent and potential future works.\n    ",
        "primary_category": "cs.CL",
        "categories": [],
        "submitted_date": "28 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18275": {
        "title": "Investigation of Adapter for Automatic Speech Recognition in Noisy Environment",
        "authors": [
            "Hao Shi",
            "Tatsuya Kawahara"
        ],
        "comments": " ",
        "subjects": "Sound (cs.SD)",
        "abstract": "Adapting an automatic speech recognition (ASR) system to unseen noise environments is crucial. Integrating adapters into neural networks has emerged as a potent technique for transfer learning. This study thoroughly investigates adapter-based ASR adaptation in noisy environments. We conducted experiments using the CHiME--4 dataset. The results show that inserting the adapter in the shallow layer yields superior effectiveness, and there is no significant difference between adapting solely within the shallow layer and adapting across all layers. The simulated data helps the system to improve its performance under real noise conditions. Nonetheless, when the amount of data is the same, the real data is more effective than the simulated data. Multi-condition training is still useful for adapter training. Furthermore, integrating adapters into speech enhancement-based ASR systems yields substantial improvements.\n    ",
        "primary_category": "cs.SD",
        "categories": [
            "cs.CL",
            "eess.AS"
        ],
        "submitted_date": "28 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18284": {
        "title": "Is Crowdsourcing Breaking Your Bank? Cost-Effective Fine-Tuning of Pre-trained Language Models with Proximal Policy Optimization",
        "authors": [
            "Shuo Yang",
            "Gjergji Kasneci"
        ],
        "comments": "12 pages, 2 figures",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "Wide usage of ChatGPT has highlighted the potential of reinforcement learning from human feedback. However, its training pipeline relies on manual ranking, a resource-intensive process. To reduce labor costs, we propose a self-supervised text ranking approach for applying Proximal-Policy-Optimization to fine-tune language models while eliminating the need for human annotators. Our method begins with probabilistic sampling to encourage a language model to generate diverse responses for each input. We then employ TextRank and ISODATA algorithms to rank and cluster these responses based on their semantics. Subsequently, we construct a reward model to learn the rank and optimize our generative policy. Our experimental results, conducted using two language models on three tasks, demonstrate that the models trained by our method considerably outperform baselines regarding BLEU, GLEU, and METEOR scores. Furthermore, our manual evaluation shows that our ranking results exhibit a remarkably high consistency with that of humans. This research significantly reduces training costs of proximal policy-guided models and demonstrates the potential for self-correction of language models.\n    ",
        "primary_category": "cs.CL",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "28 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18294": {
        "title": "Whole-body Humanoid Robot Locomotion with Human Reference",
        "authors": [
            "Qiang Zhang",
            "Peter Cui",
            "David Yan",
            "Jingkai Sun",
            "Yiqun Duan",
            "Arthur Zhang",
            "Renjing Xu"
        ],
        "comments": "7pages, 7 figures",
        "subjects": "Robotics (cs.RO)",
        "abstract": "Recently, humanoid robots have made significant advances in their ability to perform challenging tasks due to the deployment of Reinforcement Learning (RL), however, the inherent complexity of humanoid robots, including the difficulty of designing complicated reward functions and training entire sophisticated systems, still poses a notable challenge. To conquer these challenges, after many iterations and in-depth investigations, we have meticulously developed a full-size humanoid robot, \"Adam\", whose innovative structural design greatly improves the efficiency and effectiveness of the imitation learning process. In addition, we have developed a novel imitation learning framework based on an adversarial motion prior, which applies not only to Adam but also to humanoid robots in general. Using the framework, Adam can exhibit unprecedented human-like characteristics in locomotion tasks. Our experimental results demonstrate that the proposed framework enables Adam to achieve human-comparable performance in complex locomotion tasks, marking the first time that human locomotion data has been used for imitation learning in a full-size humanoid robot.\n    ",
        "primary_category": "cs.RO",
        "categories": [],
        "submitted_date": "28 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18321": {
        "title": "Privacy Policies and Consent Management Platforms: Growth and Users' Interactions over Time",
        "authors": [
            "Nikhil Jha",
            "Martino Trevisan",
            "Marco Mellia",
            "Daniel Fernandez",
            "Rodrigo Irarrazaval"
        ],
        "comments": " ",
        "subjects": "Computers and Society (cs.CY)",
        "abstract": "In response to growing concerns about user privacy, legislators have introduced new regulations and laws such as the General Data Protection Regulation (GDPR) and the California Consumer Privacy Act (CCPA) that force websites to obtain user consent before activating personal data collection, fundamental to providing targeted advertising. The cornerstone of this consent-seeking process involves the use of Privacy Banners, the technical mechanism to collect users' approval for data collection practices. Consent management platforms (CMPs) have emerged as practical solutions to make it easier for website administrators to properly manage consent, allowing them to outsource the complexities of managing user consent and activating advertising features.\nThis paper presents a detailed and longitudinal analysis of the evolution of CMPs spanning nine years. We take a twofold perspective: Firstly, thanks to the HTTP Archive dataset, we provide insights into the growth, market share, and geographical spread of CMPs. Noteworthy observations include the substantial impact of GDPR on the proliferation of CMPs in Europe. Secondly, we analyse millions of user interactions with a medium-sized CMP present in thousands of websites worldwide. We observe how even small changes in the design of Privacy Banners have a critical impact on the user's giving or denying their consent to data collection. For instance, over 60% of users do not consent when offered a simple \"one-click reject-all\" option. Conversely, when opting out requires more than one click, about 90% of users prefer to simply give their consent. The main objective is in fact to eliminate the annoying privacy banner rather the make an informed decision. Curiously, we observe iOS users exhibit a higher tendency to accept cookies compared to Android users, possibly indicating greater confidence in the privacy offered by Apple devices.\n    ",
        "primary_category": "cs.CY",
        "categories": [],
        "submitted_date": "28 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18351": {
        "title": "LatentSwap: An Efficient Latent Code Mapping Framework for Face Swapping",
        "authors": [
            "Changho Choi",
            "Minho Kim",
            "Junhyeok Lee",
            "Hyoung-Kyu Song",
            "Younggeun Kim",
            "Seungryong Kim"
        ],
        "comments": "9 pages, 11 figures",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "We propose LatentSwap, a simple face swapping framework generating a face swap latent code of a given generator. Utilizing randomly sampled latent codes, our framework is light and does not require datasets besides employing the pre-trained models, with the training procedure also being fast and straightforward. The loss objective consists of only three terms, and can effectively control the face swap results between source and target images. By attaching a pre-trained GAN inversion model independent to the model and using the StyleGAN2 generator, our model produces photorealistic and high-resolution images comparable to other competitive face swap models. We show that our framework is applicable to other generators such as StyleNeRF, paving a way to 3D-aware face swapping and is also compatible with other downstream StyleGAN2 generator tasks. The source code and models can be found at \\url{this https URL}.\n    ",
        "primary_category": "cs.CV",
        "categories": [],
        "submitted_date": "28 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18354": {
        "title": "SuperdropNet: a Stable and Accurate Machine Learning Proxy for Droplet-based Cloud Microphysics",
        "authors": [
            "Shivani Sharma",
            "David Greenberg"
        ],
        "comments": " ",
        "subjects": "Atmospheric and Oceanic Physics (physics.ao-ph)",
        "abstract": "Cloud microphysics has important consequences for climate and weather phenomena, and inaccurate representations can limit forecast accuracy. While atmospheric models increasingly resolve storms and clouds, the accuracy of the underlying microphysics remains limited by computationally expedient bulk moment schemes based on simplifying assumptions. Droplet-based Lagrangian schemes are more accurate but are underutilized due to their large computational overhead. Machine learning (ML) based schemes can bridge this gap by learning from vast droplet-based simulation datasets, but have so far struggled to match the accuracy and stability of bulk moment schemes. To address this challenge, we developed SuperdropNet, an ML-based emulator of the Lagrangian superdroplet simulations. To improve accuracy and stability, we employ multi-step autoregressive prediction during training, impose physical constraints, and carefully control stochasticity in the training data. Superdropnet predicted hydrometeor states and cloud-to-rain transition times more accurately than previous ML emulators, and matched or outperformed bulk moment schemes in many cases. We further carried out detailed analyses to reveal how multistep autoregressive training improves performance, and how the performance of SuperdropNet and other microphysical schemes hydrometeors' mass, number and size distribution. Together our results suggest that ML models can effectively emulate cloud microphysics, in a manner consistent with droplet-based simulations.\n    ",
        "primary_category": "physics.ao-ph",
        "categories": [
            "cs.LG",
            "physics.comp-ph",
            "physics.flu-dyn"
        ],
        "submitted_date": "28 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18377": {
        "title": "Out-of-Domain Generalization in Dynamical Systems Reconstruction",
        "authors": [
            "Niclas G\u00f6ring",
            "Florian Hess",
            "Manuel Brenner",
            "Zahra Monfared",
            "Daniel Durstewitz"
        ],
        "comments": " ",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "In science we are interested in finding the governing equations, the dynamical rules, underlying empirical phenomena. While traditionally scientific models are derived through cycles of human insight and experimentation, recently deep learning (DL) techniques have been advanced to reconstruct dynamical systems (DS) directly from time series data. State-of-the-art dynamical systems reconstruction (DSR) methods show promise in capturing invariant and long-term properties of observed DS, but their ability to generalize to unobserved domains remains an open challenge. Yet, this is a crucial property we would expect from any viable scientific theory. In this work, we provide a formal framework that addresses generalization in DSR. We explain why and how out-of-domain (OOD) generalization (OODG) in DSR profoundly differs from OODG considered elsewhere in machine learning. We introduce mathematical notions based on topological concepts and ergodic theory to formalize the idea of learnability of a DSR model. We formally prove that black-box DL techniques, without adequate structural priors, generally will not be able to learn a generalizing DSR model. We also show this empirically, considering major classes of DSR algorithms proposed so far, and illustrate where and why they fail to generalize across the whole phase space. Our study provides the first comprehensive mathematical treatment of OODG in DSR, and gives a deeper conceptual understanding of where the fundamental problems in OODG lie and how they could possibly be addressed in practice.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.AI",
            "math.DS",
            "nlin.CD"
        ],
        "submitted_date": "28 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18402": {
        "title": "A Modular System for Enhanced Robustness of Multimedia Understanding Networks via Deep Parametric Estimation",
        "authors": [
            "Francesco Barbato",
            "Umberto Michieli",
            "Mehmet Kerim Yucel",
            "Pietro Zanuttigh",
            "Mete Ozay"
        ],
        "comments": "Accepted at ACM MMSys'24. 10 pages, 7 figures, 8 tables",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "In multimedia understanding tasks, corrupted samples pose a critical challenge, because when fed to machine learning models they lead to performance degradation. In the past, three groups of approaches have been proposed to handle noisy data: i) enhancer and denoiser modules to improve the quality of the noisy data, ii) data augmentation approaches, and iii) domain adaptation strategies. All the aforementioned approaches come with drawbacks that limit their applicability; the first has high computational costs and requires pairs of clean-corrupted data for training, while the others only allow deployment of the same task/network they were trained on (\\ie, when upstream and downstream task/network are the same). In this paper, we propose SyMPIE to solve these shortcomings. To this end, we design a small, modular, and efficient (just 2GFLOPs to process a Full HD image) system to enhance input data for robust downstream multimedia understanding with minimal computational cost. Our SyMPIE is pre-trained on an upstream task/network that should not match the downstream ones and does not need paired clean-corrupted samples. Our key insight is that most input corruptions found in real-world tasks can be modeled through global operations on color channels of images or spatial filters with small kernels. We validate our approach on multiple datasets and tasks, such as image classification (on ImageNetC, ImageNetC-Bar, VizWiz, and a newly proposed mixed corruption benchmark named ImageNetC-mixed) and semantic segmentation (on Cityscapes, ACDC, and DarkZurich) with consistent improvements of about 5\\% relative accuracy gain across the board. The code of our approach and the new ImageNetC-mixed benchmark will be made available upon publication.\n    ",
        "primary_category": "cs.CV",
        "categories": [],
        "submitted_date": "28 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18409": {
        "title": "A Cognitive Evaluation Benchmark of Image Reasoning and Description for Large Vision Language Models",
        "authors": [
            "Xiujie Song",
            "Mengyue Wu",
            "Kenny Q. Zhu",
            "Chunhao Zhang",
            "Yanyi Chen"
        ],
        "comments": " ",
        "subjects": "Artificial Intelligence (cs.AI)",
        "abstract": "Large Vision Language Models (LVLMs), despite their recent success, are hardly comprehensively tested for their cognitive abilities. Inspired by the prevalent use of the \"Cookie Theft\" task in human cognition test, we propose a novel evaluation benchmark to evaluate high-level cognitive ability of LVLMs using images with rich semantics. It defines eight reasoning capabilities and consists of an image description task and a visual question answering task. Our evaluation on well-known LVLMs shows that there is still a large gap in cognitive ability between LVLMs and humans.\n    ",
        "primary_category": "cs.AI",
        "categories": [
            "cs.CL",
            "cs.CV"
        ],
        "submitted_date": "28 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18445": {
        "title": "HyperFedNet: Communication-Efficient Personalized Federated Learning Via Hypernetwork",
        "authors": [
            "Xingyun Chen",
            "Yan Huang",
            "Zhenzhen Xie",
            "Junjie Pang"
        ],
        "comments": " ",
        "subjects": "Networking and Internet Architecture (cs.NI)",
        "abstract": "In response to the challenges posed by non-independent and identically distributed (non-IID) data and the escalating threat of privacy attacks in Federated Learning (FL), we introduce HyperFedNet (HFN), a novel architecture that incorporates hypernetworks to revolutionize parameter aggregation and transmission in FL. Traditional FL approaches, characterized by the transmission of extensive parameters, not only incur significant communication overhead but also present vulnerabilities to privacy breaches through gradient analysis. HFN addresses these issues by transmitting a concise set of hypernetwork parameters, thereby reducing communication costs and enhancing privacy protection. Upon deployment, the HFN algorithm enables the dynamic generation of parameters for the basic layer of the FL main network, utilizing local database features quantified by embedding vectors as input. Through extensive experimentation, HFN demonstrates superior performance in reducing communication overhead and improving model accuracy compared to conventional FL methods. By integrating the HFN algorithm into the FL framework, HFN offers a solution to the challenges of non-IID data and privacy threats.\n    ",
        "primary_category": "cs.NI",
        "categories": [],
        "submitted_date": "28 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18469": {
        "title": "Interval-Constrained Bipartite Matching over Time",
        "authors": [
            "Andreas Abels",
            "Mariia Anapolska"
        ],
        "comments": " ",
        "subjects": "Data Structures and Algorithms (cs.DS)",
        "abstract": "Interval-constrained online bipartite matching problem frequently occurs in medical appointment scheduling: unit-time jobs representing patients arrive online and are assigned to a time slot within their given time interval. We consider a variant of this problem where reassignments are allowed and extend it by a notion of current time, which is decoupled from the job arrival events. As jobs appear, the current point in time gradually advances. Jobs that are assigned to the current time unit become processed, which fixes part of the matching and disables these jobs or slots for reassignments in future steps. We refer to these time-dependent restrictions on reassignments as the over-time property.\nWe show that FirstFit with reassignments according to the shortest augmenting path rule is $\\frac{2}{3}$-competitive with respect to the matching cardinality, and that the bound is tight. Interestingly, this bound holds even if the number of reassignments per job is bound by a constant. For the number of reassignments performed by the algorithm, we show that it is in $\\Omega(n \\log n)$ in the worst case, where $n$ is the number of patients or jobs on the online side. This result is in line with lower bounds for the number of reassignments in online bipartite matching with reassignments, and, similarly to this previous work, we also conjecture that this bound should be tight. Known upper bounds like the $O(n \\log^2 n)$ for online bipartite matching with reassignments by Bernstein, Holm, and Rotenberg do not transfer directly: while our interval constraints simplify the problem, the over-time property restricts the set of possible reassignments.\n    ",
        "primary_category": "cs.DS",
        "categories": [],
        "submitted_date": "28 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18485": {
        "title": "A Multimodal Foundation Agent for Financial Trading: Tool-Augmented, Diversified, and Generalist",
        "authors": [
            "Wentao Zhang",
            "Lingxuan Zhao",
            "Haochong Xia",
            "Shuo Sun",
            "Jiaze Sun",
            "Molei Qin",
            "Xinyi Li",
            "Yuqing Zhao",
            "Yilei Zhao",
            "Xinyu Cai",
            "Longtao Zheng",
            "Xinrun Wang",
            "Bo An"
        ],
        "comments": " ",
        "subjects": "Trading and Market Microstructure (q-fin.TR)",
        "abstract": "Financial trading is a crucial component of the markets, informed by a multimodal information landscape encompassing news, prices, and Kline charts, and encompasses diverse tasks such as quantitative trading and high-frequency trading with various assets. While advanced AI techniques like deep learning and reinforcement learning are extensively utilized in finance, their application in financial trading tasks often faces challenges due to inadequate handling of multimodal data and limited generalizability across various tasks. To address these challenges, we present FinAgent, a multimodal foundational agent with tool augmentation for financial trading. FinAgent's market intelligence module processes a diverse range of data-numerical, textual, and visual-to accurately analyze the financial market. Its unique dual-level reflection module not only enables rapid adaptation to market dynamics but also incorporates a diversified memory retrieval system, enhancing the agent's ability to learn from historical data and improve decision-making processes. The agent's emphasis on reasoning for actions fosters trust in its financial decisions. Moreover, FinAgent integrates established trading strategies and expert insights, ensuring that its trading approaches are both data-driven and rooted in sound financial principles. With comprehensive experiments on 6 financial datasets, including stocks and Crypto, FinAgent significantly outperforms 9 state-of-the-art baselines in terms of 6 financial metrics with over 36% average improvement on profit. Specifically, a 92.27% return (a 84.39% relative improvement) is achieved on one dataset. Notably, FinAgent is the first advanced multimodal foundation agent designed for financial trading tasks.\n    ",
        "primary_category": "q-fin.TR",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "28 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18495": {
        "title": "ROG$_{PL}$: Robust Open-Set Graph Learning via Region-Based Prototype Learning",
        "authors": [
            "Qin Zhang",
            "Xiaowei Li",
            "Jiexin Lu",
            "Liping Qiu",
            "Shirui Pan",
            "Xiaojun Chen",
            "Junyang Chen"
        ],
        "comments": "9 pages, 5 figures",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Open-set graph learning is a practical task that aims to classify the known class nodes and to identify unknown class samples as unknowns. Conventional node classification methods usually perform unsatisfactorily in open-set scenarios due to the complex data they encounter, such as out-of-distribution (OOD) data and in-distribution (IND) noise. OOD data are samples that do not belong to any known classes. They are outliers if they occur in training (OOD noise), and open-set samples if they occur in testing. IND noise are training samples which are assigned incorrect labels. The existence of IND noise and OOD noise is prevalent, which usually cause the ambiguity problem, including the intra-class variety problem and the inter-class confusion problem. Thus, to explore robust open-set learning methods is necessary and difficult, and it becomes even more difficult for non-IID graph this http URL this end, we propose a unified framework named ROG$_{PL}$ to achieve robust open-set learning on complex noisy graph data, by introducing prototype learning. In specific, ROG$_{PL}$ consists of two modules, i.e., denoising via label propagation and open-set prototype learning via regions. The first module corrects noisy labels through similarity-based label propagation and removes low-confidence samples, to solve the intra-class variety problem caused by noise. The second module learns open-set prototypes for each known class via non-overlapped regions and remains both interior and border prototypes to remedy the inter-class confusion problem.The two modules are iteratively updated under the constraints of classification loss and prototype diversity loss. To the best of our knowledge, the proposed ROG$_{PL}$ is the first robust open-set node classification method for graph data with complex noise.\n    ",
        "primary_category": "cs.LG",
        "categories": [],
        "submitted_date": "28 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18496": {
        "title": "Language Models Represent Beliefs of Self and Others",
        "authors": [
            "Wentao Zhu",
            "Zhining Zhang",
            "Yizhou Wang"
        ],
        "comments": "project page: this https URL",
        "subjects": "Artificial Intelligence (cs.AI)",
        "abstract": "Understanding and attributing mental states, known as Theory of Mind (ToM), emerges as a fundamental capability for human social reasoning. While Large Language Models (LLMs) appear to possess certain ToM abilities, the mechanisms underlying these capabilities remain elusive. In this study, we discover that it is possible to linearly decode the belief status from the perspectives of various agents through neural activations of language models, indicating the existence of internal representations of self and others' beliefs. By manipulating these representations, we observe dramatic changes in the models' ToM performance, underscoring their pivotal role in the social reasoning process. Additionally, our findings extend to diverse social reasoning tasks that involve different causal inference patterns, suggesting the potential generalizability of these representations.\n    ",
        "primary_category": "cs.AI",
        "categories": [
            "cs.CL"
        ],
        "submitted_date": "28 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18510": {
        "title": "RNNs are not Transformers (Yet): The Key Bottleneck on In-context Retrieval",
        "authors": [
            "Kaiyue Wen",
            "Xingyu Dang",
            "Kaifeng Lyu"
        ],
        "comments": "42 pages, 5 figures",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "This paper investigates the gap in representation powers of Recurrent Neural Networks (RNNs) and Transformers in the context of solving algorithmic problems. We focus on understanding whether RNNs, known for their memory efficiency in handling long sequences, can match the performance of Transformers, particularly when enhanced with Chain-of-Thought (CoT) prompting. Our theoretical analysis reveals that CoT improves RNNs but is insufficient to close the gap with Transformers. A key bottleneck lies in the inability of RNNs to perfectly retrieve information from the context, even with CoT: for several tasks that explicitly or implicitly require this capability, such as associative recall and determining if a graph is a tree, we prove that RNNs are not expressive enough to solve the tasks while Transformers can solve them with ease. Conversely, we prove that adopting techniques to enhance the in-context retrieval capability of RNNs, including Retrieval-Augmented Generation (RAG) and adding a single Transformer layer, can elevate RNNs to be capable of solving all polynomial-time solvable problems with CoT, hence closing the representation gap with Transformers.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.CL",
            "stat.ML"
        ],
        "submitted_date": "28 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18575": {
        "title": "DiffuseRAW: End-to-End Generative RAW Image Processing for Low-Light Images",
        "authors": [
            "Rishit Dagli"
        ],
        "comments": " ",
        "subjects": "Image and Video Processing (eess.IV)",
        "abstract": "Imaging under extremely low-light conditions presents a significant challenge and is an ill-posed problem due to the low signal-to-noise ratio (SNR) caused by minimal photon capture. Previously, diffusion models have been used for multiple kinds of generative tasks and image-to-image tasks, however, these models work as a post-processing step. These diffusion models are trained on processed images and learn on processed images. However, such approaches are often not well-suited for extremely low-light tasks. Unlike the task of low-light image enhancement or image-to-image enhancement, we tackle the task of learning the entire image-processing pipeline, from the RAW image to a processed image. For this task, a traditional image processing pipeline often consists of multiple specialized parts that are overly reliant on the downstream tasks. Unlike these, we develop a new generative ISP that relies on fine-tuning latent diffusion models on RAW images and generating processed long-exposure images which allows for the apt use of the priors from large text-to-image generation models. We evaluate our approach on popular end-to-end low-light datasets for which we see promising results and set a new SoTA on the See-in-Dark (SID) dataset. Furthermore, with this work, we hope to pave the way for more generative and diffusion-based image processing and other problems on RAW data.\n    ",
        "primary_category": "eess.IV",
        "categories": [
            "cs.AI",
            "cs.CV",
            "cs.LG"
        ],
        "submitted_date": "13 Dec 2023",
        "last_revised_date": " "
    },
    "2402.18576": {
        "title": "Improved Forecasting Using a PSO-RDV Framework to Enhance Artificial Neural Network",
        "authors": [
            "Sales Aribe Jr"
        ],
        "comments": "9 pages, 4 figures, Published with International Journal of Engineering Trends and Technology (IJETT)",
        "subjects": "Neural and Evolutionary Computing (cs.NE)",
        "abstract": "Decision making and planning have long relied heavily on AI-driven forecasts. The government and the general public are working to minimize the risks while maximizing benefits in the face of potential future public health uncertainties. This study used an improved method of forecasting utilizing the Random Descending Velocity Inertia Weight (RDV IW) technique to improve the convergence of Particle Swarm Optimization (PSO) and the accuracy of Artificial Neural Network (ANN). The IW technique, inspired by the motions of a golf ball, modified the particles' velocities as they approached the solution point to a parabolically descending structure. Simulation results revealed that the proposed forecasting model with [0.4, 0.9] combination of alpha and alpha_dump exhibits a 6.36% improvement in position error and 11.75% improvement in computational time compared to the old model, thus, improving its convergence. It reached the optimum level at minimal steps with 12.50% improvement as against the old model since it provides better velocity averages when speed stabilization occurs at the 24th iteration. Meanwhile, the computed p-values for NRMSE (0.04889174), MAE (0.02829063), MAPE (0.02226053), WAPE (0.01701545), and R2 (0.00000021) of the proposed algorithm are less than the set 0.05 level of significance, thus the values indicated a significant result in terms of accuracy performance. Applying the modified ANN-PSO using RDV IW technique greatly improved the new HIV/AIDS forecasting model compared with the two models.\n    ",
        "primary_category": "cs.NE",
        "categories": [
            "cs.AI",
            "cs.LG"
        ],
        "submitted_date": "10 Jan 2024",
        "last_revised_date": " "
    },
    "2402.18577": {
        "title": "Motion Guided Token Compression for Efficient Masked Video Modeling",
        "authors": [
            "Yukun Feng",
            "Yangming Shi",
            "Fengze Liu",
            "Tan Yan"
        ],
        "comments": " ",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Recent developments in Transformers have achieved notable strides in enhancing video comprehension. Nonetheless, the O($N^2$) computation complexity associated with attention mechanisms presents substantial computational hurdles when dealing with the high dimensionality of videos. This challenge becomes particularly pronounced when striving to increase the frames per second (FPS) to enhance the motion capturing capabilities. Such a pursuit is likely to introduce redundancy and exacerbate the existing computational limitations. In this paper, we initiate by showcasing the enhanced performance achieved through an escalation in the FPS rate. Additionally, we present a novel approach, Motion Guided Token Compression (MGTC), to empower Transformer models to utilize a smaller yet more representative set of tokens for comprehensive video representation. Consequently, this yields substantial reductions in computational burden and remains seamlessly adaptable to increased FPS rates. Specifically, we draw inspiration from video compression algorithms and scrutinize the variance between patches in consecutive video frames across the temporal dimension. The tokens exhibiting a disparity below a predetermined threshold are then masked. Notably, this masking strategy effectively addresses video redundancy while conserving essential information. Our experiments, conducted on widely examined video recognition datasets, Kinetics-400, UCF101 and HMDB51, demonstrate that elevating the FPS rate results in a significant top-1 accuracy score improvement of over 1.6, 1.6 and 4.0. By implementing MGTC with the masking ratio of 25\\%, we further augment accuracy by 0.1 and simultaneously reduce computational costs by over 31\\% on Kinetics-400. Even within a fixed computational budget, higher FPS rates paired with MGTC sustain performance gains when compared to lower FPS settings.\n    ",
        "primary_category": "cs.CV",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "10 Jan 2024",
        "last_revised_date": " "
    },
    "2402.18579": {
        "title": "Wilcoxon Nonparametric CFAR Scheme for Ship Detection in SAR Image",
        "authors": [
            "Xiangwei Meng"
        ],
        "comments": " ",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "The parametric constant false alarm rate (CFAR) detection algorithms which are based on various statistical distributions, such as Gaussian, Gamma, Weibull, log-normal, G0 distribution, alpha-stable distribution, etc, are most widely used to detect the ship targets in SAR image at present. However, the clutter background in SAR images is complicated and variable. When the actual clutter background deviates from the assumed statistical distribution, the performance of the parametric CFAR detector will deteriorate. In addition to the parametric CFAR schemes, there is another class of nonparametric CFAR detectors which can maintain a constant false alarm rate for the target detection without the assumption of a known clutter distribution. In this work, the Wilcoxon nonparametric CFAR scheme for ship detection in SAR image is proposed and analyzed, and a closed form of the false alarm rate for the Wilcoxon nonparametric detector to determine the decision threshold is presented. By comparison with several typical parametric CFAR schemes on Radarsat-2, ICEYE-X6 and Gaofen-3 SAR images, the robustness of the Wilcoxon nonparametric detector to maintain a good false alarm performance in different detection backgrounds is revealed, and its detection performance for the weak ship in rough sea surface is improved to some extent. Moreover, the Wilcoxon nonparametric detector can suppress the false alarms resulting from the sidelobes at some degree and its detection speed is fast.\n    ",
        "primary_category": "cs.CV",
        "categories": [
            "cs.AI",
            "eess.SP",
            "stat.AP"
        ],
        "submitted_date": "11 Jan 2024",
        "last_revised_date": " "
    },
    "2402.18581": {
        "title": "Multi-objective Optimal Roadside Units Deployment in Urban Vehicular Networks",
        "authors": [
            "Weian Guo",
            "Zecheng Kang",
            "Dongyang Li",
            "Lun Zhang",
            "Li Li"
        ],
        "comments": "This manuscript has been submitted to the journal of IEEE Transactions on Vehicular Technology",
        "subjects": "Neural and Evolutionary Computing (cs.NE)",
        "abstract": "The significance of transportation efficiency, safety, and related services is increasing in urban vehicular networks. Within such networks, roadside units (RSUs) serve as intermediates in facilitating communication. Therefore, the deployment of RSUs is of utmost importance in ensuring the quality of communication services. However, the optimization objectives, such as time delay and deployment cost, are commonly developed from diverse perspectives. As a result, it is possible that conflicts may arise among the objectives. Furthermore, in urban environments, the presence of various obstacles, such as buildings, gardens, lakes, and other infrastructure, poses challenges for the deployment of RSUs. Hence, the deployment encounters significant difficulties due to the existence of multiple objectives, constraints imposed by obstacles, and the necessity to explore a large-scale optimization space. To address this issue, two versions of multi-objective optimization algorithms are proposed in this paper. By utilizing a multi-population strategy and an adaptive exploration technique, the methods efficiently explore a large-scale decision-variable space. In order to mitigate the issue of an overcrowded deployment of RSUs, a calibrating mechanism is adopted to adjust RSU density during the optimization procedures. The proposed methods also take care of data offloading between vehicles and RSUs by setting up an iterative best response sequence game (IBRSG). By comparing the proposed algorithms with several state-of-the-art algorithms, the results demonstrate that our strategies perform better in both high-density and low-density urban scenarios. The results also indicate that the proposed solutions substantially improve the efficiency of vehicular networks.\n    ",
        "primary_category": "cs.NE",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "14 Jan 2024",
        "last_revised_date": " "
    },
    "2402.18582": {
        "title": "Streamlining the Selection Phase of Systematic Literature Reviews (SLRs) Using AI-Enabled GPT-4 Assistant API",
        "authors": [
            "Seyed Mohammad Ali Jafari"
        ],
        "comments": "11 pages, 5 figures",
        "subjects": "Digital Libraries (cs.DL)",
        "abstract": "The escalating volume of academic literature presents a formidable challenge in staying updated with the newest research developments. Addressing this, this study introduces a pioneering AI-based tool, configured specifically to streamline the efficiency of the article selection phase in Systematic Literature Reviews (SLRs). Utilizing the robust capabilities of OpenAI's GPT-4 Assistant API, the tool successfully homogenizes the article selection process across a broad array of academic disciplines. Implemented through a tripartite approach consisting of data preparation, AI-mediated article assessment, and structured result presentation, this tool significantly accelerates the time-consuming task of literature reviews. Importantly, this tool could be highly beneficial in fields such as management and economics, where the SLR process involves substantial human judgment. The adoption of a standard GPT model can substantially reduce potential biases and enhance the speed and precision of the SLR selection phase. This not only amplifies researcher productivity and accuracy but also denotes a considerable stride forward in the way academic research is conducted amidst the surging body of scholarly publications.\n    ",
        "primary_category": "cs.DL",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "14 Jan 2024",
        "last_revised_date": " "
    },
    "2402.18583": {
        "title": "Binding-Adaptive Diffusion Models for Structure-Based Drug Design",
        "authors": [
            "Zhilin Huang",
            "Ling Yang",
            "Zaixi Zhang",
            "Xiangxin Zhou",
            "Yu Bao",
            "Xiawu Zheng",
            "Yuwei Yang",
            "Yu Wang",
            "Wenming Yang"
        ],
        "comments": "Accepted by AAAI 2024. Project: this https URL",
        "subjects": "Biomolecules (q-bio.BM)",
        "abstract": "Structure-based drug design (SBDD) aims to generate 3D ligand molecules that bind to specific protein targets. Existing 3D deep generative models including diffusion models have shown great promise for SBDD. However, it is complex to capture the essential protein-ligand interactions exactly in 3D space for molecular generation. To address this problem, we propose a novel framework, namely Binding-Adaptive Diffusion Models (BindDM). In BindDM, we adaptively extract subcomplex, the essential part of binding sites responsible for protein-ligand interactions. Then the selected protein-ligand subcomplex is processed with SE(3)-equivariant neural networks, and transmitted back to each atom of the complex for augmenting the target-aware 3D molecule diffusion generation with binding interaction information. We iterate this hierarchical complex-subcomplex process with cross-hierarchy interaction node for adequately fusing global binding context between the complex and its corresponding subcomplex. Empirical studies on the CrossDocked2020 dataset show BindDM can generate molecules with more realistic 3D structures and higher binding affinities towards the protein targets, with up to -5.92 Avg. Vina Score, while maintaining proper molecular properties. Our code is available at this https URL\n",
        "primary_category": "q-bio.BM",
        "categories": [
            "cs.LG"
        ],
        "submitted_date": "15 Jan 2024",
        "last_revised_date": " "
    },
    "2402.18584": {
        "title": "Adjusting Dynamics of Hopfield Neural Network via Time-variant Stimulus",
        "authors": [
            "Xuenan Peng",
            "Chengqing Li",
            "Yicheng Zeng",
            "Chun-Lai Li"
        ],
        "comments": "14 pages, 21 figures",
        "subjects": "Neural and Evolutionary Computing (cs.NE)",
        "abstract": "As a paradigmatic model for nonlinear dynamics studies, the Hopfield Neural Network (HNN) demonstrates a high susceptibility to external disturbances owing to its intricate structure. This paper delves into the challenge of modulating HNN dynamics through time-variant stimuli. The effects of adjustments using two distinct types of time-variant stimuli, namely the Weight Matrix Stimulus (WMS) and the State Variable Stimulus (SVS), along with a Constant Stimulus (CS) are reported. The findings reveal that deploying four WMSs enables the HNN to generate either a four-scroll or a coexisting two-scroll attractor. When combined with one SVS, four WMSs can lead to the formation of an eight-scroll or four-scroll attractor, while the integration of four WMSs and multiple SVSs can induce grid-multi-scroll attractors. Moreover, the introduction of a CS and an SVS can significantly disrupt the dynamic behavior of the HNN. Consequently, suitable adjustment methods are crucial for enhancing the network's dynamics, whereas inappropriate applications can lead to the loss of its chaotic characteristics. To empirically validate these enhancement effects, the study employs an FPGA hardware platform. Subsequently, an image encryption scheme is designed to demonstrate the practical application benefits of the dynamically adjusted HNN in secure multimedia communication. This exploration into the dynamic modulation of HNN via time-variant stimuli offers insightful contributions to the advancement of secure communication technologies.\n    ",
        "primary_category": "cs.NE",
        "categories": [
            "nlin.CD"
        ],
        "submitted_date": "15 Jan 2024",
        "last_revised_date": " "
    },
    "2402.18587": {
        "title": "At the Dawn of Generative AI Era: A Tutorial-cum-Survey on New Frontiers in 6G Wireless Intelligence",
        "authors": [
            "Abdulkadir Celik",
            "Ahmed M. Eltawil"
        ],
        "comments": " ",
        "subjects": "Networking and Internet Architecture (cs.NI)",
        "abstract": "The majority of data-driven wireless research leans heavily on discriminative AI (DAI) that requires vast real-world datasets. Unlike the DAI, Generative AI (GenAI) pertains to generative models (GMs) capable of discerning the underlying data distribution, patterns, and features of the input data. This makes GenAI a crucial asset in wireless domain wherein real-world data is often scarce, incomplete, costly to acquire, and hard to model or comprehend. With these appealing attributes, GenAI can replace or supplement DAI methods in various capacities. Accordingly, this combined tutorial-survey paper commences with preliminaries of 6G and wireless intelligence by outlining candidate 6G applications and services, presenting a taxonomy of state-of-the-art DAI models, exemplifying prominent DAI use cases, and elucidating the multifaceted ways through which GenAI enhances DAI. Subsequently, we present a tutorial on GMs by spotlighting seminal examples such as generative adversarial networks, variational autoencoders, flow-based GMs, diffusion-based GMs, generative transformers, large language models, to name a few. Contrary to the prevailing belief that GenAI is a nascent trend, our exhaustive review of approximately 120 technical papers demonstrates the scope of research across core wireless research areas, including physical layer design; network optimization, organization, and management; network traffic analytics; cross-layer network security; and localization & positioning. Furthermore, we outline the central role of GMs in pioneering areas of 6G network research, including semantic/THz/near-field communications, ISAC, extremely large antenna arrays, digital twins, AI-generated content services, mobile edge computing and edge AI, adversarial ML, and trustworthy AI. Lastly, we shed light on the multifarious challenges ahead, suggesting potential strategies and promising remedies.\n    ",
        "primary_category": "cs.NI",
        "categories": [
            "cs.AI",
            "cs.LG"
        ],
        "submitted_date": "2 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18591": {
        "title": "Stochastic contextual bandits with graph feedback: from independence number to MAS number",
        "authors": [
            "Yuxiao Wen",
            "Yanjun Han",
            "Zhengyuan Zhou"
        ],
        "comments": " ",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "We consider contextual bandits with graph feedback, a class of interactive learning problems with richer structures than vanilla contextual bandits, where taking an action reveals the rewards for all neighboring actions in the feedback graph under all contexts. Unlike the multi-armed bandits setting where a growing literature has painted a near-complete understanding of graph feedback, much remains unexplored in the contextual bandits counterpart. In this paper, we make inroads into this inquiry by establishing a regret lower bound $\\Omega(\\sqrt{\\beta_M(G) T})$, where $M$ is the number of contexts, $G$ is the feedback graph, and $\\beta_M(G)$ is our proposed graph-theoretical quantity that characterizes the fundamental learning limit for this class of problems. Interestingly, $\\beta_M(G)$ interpolates between $\\alpha(G)$ (the independence number of the graph) and $\\mathsf{m}(G)$ (the maximum acyclic subgraph (MAS) number of the graph) as the number of contexts $M$ varies. We also provide algorithms that achieve near-optimal regrets for important classes of context sequences and/or feedback graphs, such as transitively closed graphs that find applications in auctions and inventory control. In particular, with many contexts, our results show that the MAS number completely characterizes the statistical complexity for contextual bandits, as opposed to the independence number in multi-armed bandits.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.GT",
            "math.ST"
        ],
        "submitted_date": "12 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18592": {
        "title": "A$^3$PIM: An Automated, Analytic and Accurate Processing-in-Memory Offloader",
        "authors": [
            "Qingcai Jiang",
            "Shaojie Tan",
            "Junshi Chen",
            "Hong An"
        ],
        "comments": "6 pages, 4 figures, accepted for presentation at Design, Automation and Test in Europe Conference | The European Event for Electronic System Design & Test (DATE 2024), conference to be held in March 2024",
        "subjects": "Hardware Architecture (cs.AR)",
        "abstract": "The performance gap between memory and processor has grown rapidly. Consequently, the energy and wall-clock time costs associated with moving data between the CPU and main memory predominate the overall computational cost. The Processing-in-Memory (PIM) paradigm emerges as a promising architecture that mitigates the need for extensive data movements by strategically positioning computing units proximate to the memory. Despite the abundant efforts devoted to building a robust and highly-available PIM system, identifying PIM-friendly segments of applications poses significant challenges due to the lack of a comprehensive tool to evaluate the intrinsic memory access pattern of the segment.\nTo tackle this challenge, we propose A$^3$PIM: an Automated, Analytic and Accurate Processing-in-Memory offloader. We systematically consider the cross-segment data movement and the intrinsic memory access pattern of each code segment via static code analyzer. We evaluate A$^3$PIM across a wide range of real-world workloads including GAP and PrIM benchmarks and achieve an average speedup of 2.63x and 4.45x (up to 7.14x and 10.64x) when compared to CPU-only and PIM-only executions, respectively.\n    ",
        "primary_category": "cs.AR",
        "categories": [
            "cs.PF"
        ],
        "submitted_date": "23 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18593": {
        "title": "Sustainable Supercomputing for AI: GPU Power Capping at HPC Scale",
        "authors": [
            "Dan Zhao",
            "Siddharth Samsi",
            "Joseph McDonald",
            "Baolin Li",
            "David Bestor",
            "Michael Jones",
            "Devesh Tiwari",
            "Vijay Gadepally"
        ],
        "comments": " ",
        "subjects": "Hardware Architecture (cs.AR)",
        "abstract": "As research and deployment of AI grows, the computational burden to support and sustain its progress inevitably does too. To train or fine-tune state-of-the-art models in NLP, computer vision, etc., some form of AI hardware acceleration is virtually a requirement. Recent large language models require considerable resources to train and deploy, resulting in significant energy usage, potential carbon emissions, and massive demand for GPUs and other hardware accelerators. However, this surge carries large implications for energy sustainability at the HPC/datacenter level. In this paper, we study the aggregate effect of power-capping GPUs on GPU temperature and power draw at a research supercomputing center. With the right amount of power-capping, we show significant decreases in both temperature and power draw, reducing power consumption and potentially improving hardware life-span with minimal impact on job performance. While power-capping reduces power draw by design, the aggregate system-wide effect on overall energy consumption is less clear; for instance, if users notice job performance degradation from GPU power-caps, they may request additional GPU-jobs to compensate, negating any energy savings or even worsening energy consumption. To our knowledge, our work is the first to conduct and make available a detailed analysis of the effects of GPU power-capping at the supercomputing scale. We hope our work will inspire HPCs/datacenters to further explore, evaluate, and communicate the impact of power-capping AI hardware accelerators for more sustainable AI.\n    ",
        "primary_category": "cs.AR",
        "categories": [
            "cs.AI",
            "cs.DC"
        ],
        "submitted_date": "25 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18594": {
        "title": "Analyzing the Dynamics of COVID-19 Lockdown Success: Insights from Regional Data and Public Health Measures",
        "authors": [
            "Md. Motaleb Hossen Manik",
            "Md. Ahsan Habib",
            "Md. Zabirul Islam",
            "Tanim Ahmed",
            "Fabliha Haque"
        ],
        "comments": " ",
        "subjects": "Physics and Society (physics.soc-ph)",
        "abstract": "The COVID-19 pandemic caused by the coronavirus had a significant effect on social, economic, and health systems globally. The virus emerged in Wuhan, China, and spread worldwide resulting in severe disease, death, and social interference. Countries implemented lockdowns in various regions to limit the spread of the virus. Some of them were successful and some failed. Here, several factors played a vital role in their success. But mostly these factors and their correlations remained unidentified. In this paper, we unlocked those factors that contributed to the success of lockdown during the COVID-19 pandemic and explored the correlations among them. Moreover, this paper proposes several strategies to control any pandemic situation in the future. Here, it explores the relationships among variables, such as population density, number of infected, death, recovered patients, and the success or failure of the lockdown in different regions of the world. The findings suggest a strong correlation among these factors and indicate that the spread of similar kinds of viruses can be reduced in the future by implementing several safety measures.\n    ",
        "primary_category": "physics.soc-ph",
        "categories": [
            "cs.DL"
        ],
        "submitted_date": "25 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18595": {
        "title": "EncodingNet: A Novel Encoding-based MAC Design for Efficient Neural Network Acceleration",
        "authors": [
            "Bo Liu",
            "Grace Li Zhang",
            "Xunzhao Yin",
            "Ulf Schlichtmann",
            "Bing Li"
        ],
        "comments": " ",
        "subjects": "Hardware Architecture (cs.AR)",
        "abstract": "Deep neural networks (DNNs) have achieved great breakthroughs in many fields such as image classification and natural language processing. However, the execution of DNNs needs to conduct massive numbers of multiply-accumulate (MAC) operations on hardware and thus incurs a large power consumption. To address this challenge, we propose a novel digital MAC design based on encoding. In this new design, the multipliers are replaced by simple logic gates to project the results onto a wide bit representation. These bits carry individual position weights, which can be trained for specific neural networks to enhance inference accuracy. The outputs of the new multipliers are added by bit-wise weighted accumulation and the accumulation results are compatible with existing computing platforms accelerating neural networks with either uniform or non-uniform quantization. Since the multiplication function is replaced by simple logic projection, the critical paths in the resulting circuits become much shorter. Correspondingly, pipelining stages in the MAC array can be reduced, leading to a significantly smaller area as well as a better power efficiency. The proposed design has been synthesized and verified by ResNet18-Cifar10, ResNet20-Cifar100 and ResNet50-ImageNet. The experimental results confirmed the reduction of circuit area by up to 79.63% and the reduction of power consumption of executing DNNs by up to 70.18%, while the accuracy of the neural networks can still be well maintained.\n    ",
        "primary_category": "cs.AR",
        "categories": [
            "cs.CE",
            "cs.LG"
        ],
        "submitted_date": "25 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18596": {
        "title": "Image-To-Mesh Conversion for Biomedical Simulations",
        "authors": [
            "Fotis Drakopoulos",
            "Kevin Garner",
            "Christopher Rector",
            "Nikos Chrisochoides"
        ],
        "comments": "37 pages, 26 figures",
        "subjects": "Graphics (cs.GR)",
        "abstract": "Converting a three-dimensional medical image into a 3D mesh that satisfies both the quality and fidelity constraints of predictive simulations and image-guided surgical procedures remains a critical problem. Presented is an image-to-mesh conversion method called CBC3D. It first discretizes a segmented image by generating an adaptive Body-Centered Cubic (BCC) mesh of high-quality elements. Next, the tetrahedral mesh is converted into a mixed-element mesh of tetrahedra, pentahedra, and hexahedra to decrease element count while maintaining quality. Finally, the mesh surfaces are deformed to their corresponding physical image boundaries, improving the mesh's fidelity. The deformation scheme builds upon the ITK open-source library and is based on the concept of energy minimization, relying on a multi-material point-based registration. It uses non-connectivity patterns to implicitly control the number of extracted feature points needed for the registration and, thus, adjusts the trade-off between the achieved mesh fidelity and the deformation speed. We compare CBC3D with four widely used and state-of-the-art homegrown image-to-mesh conversion methods from industry and academia. Results indicate that the CBC3D meshes (i) achieve high fidelity, (ii) keep the element count reasonably low, and (iii) exhibit good element quality.\n    ",
        "primary_category": "cs.GR",
        "categories": [
            "cs.MS",
            "math.NA"
        ],
        "submitted_date": "27 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18599": {
        "title": "Meta-Tasks: An alternative view on Meta-Learning Regularization",
        "authors": [
            "Mohammad Rostami",
            "Atik Faysal",
            "Huaxia Wang",
            "Avimanyu Sahoo",
            "Ryan Antle"
        ],
        "comments": " ",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Few-shot learning (FSL) is a challenging machine learning problem due to a scarcity of labeled data. The ability to generalize effectively on both novel and training tasks is a significant barrier to FSL. This paper proposes a novel solution that can generalize to both training and novel tasks while also utilizing unlabeled samples. The method refines the embedding model before updating the outer loop using unsupervised techniques as ``meta-tasks''. The experimental results show that our proposed method performs well on novel and training tasks, with faster and better convergence, lower generalization, and standard deviation error, indicating its potential for practical applications in FSL. The experimental results show that the proposed method outperforms prototypical networks by 3.9%.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "27 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18600": {
        "title": "Artificial Intelligence and Diabetes Mellitus: An Inside Look Through the Retina",
        "authors": [
            "Yasin Sadeghi Bazargani",
            "Majid Mirzaei",
            "Navid Sobhi",
            "Mirsaeed Abdollahi",
            "Ali Jafarizadeh",
            "Siamak Pedrammehr",
            "Roohallah Alizadehsani",
            "Ru San Tan",
            "Sheikh Mohammed Shariful Islam",
            "U. Rajendra Acharya"
        ],
        "comments": "44 Pages, 6 figures, 1 table, 166 references",
        "subjects": "Image and Video Processing (eess.IV)",
        "abstract": "Diabetes mellitus (DM) predisposes patients to vascular complications. Retinal images and vasculature reflect the body's micro- and macrovascular health. They can be used to diagnose DM complications, including diabetic retinopathy (DR), neuropathy, nephropathy, and atherosclerotic cardiovascular disease, as well as forecast the risk of cardiovascular events. Artificial intelligence (AI)-enabled systems developed for high-throughput detection of DR using digitized retinal images have become clinically adopted. Beyond DR screening, AI integration also holds immense potential to address challenges associated with the holistic care of the patient with DM. In this work, we aim to comprehensively review the literature for studies on AI applications based on retinal images related to DM diagnosis, prognostication, and management. We will describe the findings of holistic AI-assisted diabetes care, including but not limited to DR screening, and discuss barriers to implementing such systems, including issues concerning ethics, data privacy, equitable access, and explainability. With the ability to evaluate the patient's health status vis a vis DM complication as well as risk prognostication of future cardiovascular complications, AI-assisted retinal image analysis has the potential to become a central tool for modern personalized medicine in patients with DM.\n    ",
        "primary_category": "eess.IV",
        "categories": [
            "cs.AI",
            "q-bio.TO"
        ],
        "submitted_date": "28 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18605": {
        "title": "FORML: A Riemannian Hessian-free Method for Meta-learning with Orthogonality Constraint",
        "authors": [
            "Hadi Tabealhojeh",
            "Soumava Kumar Roy",
            "Peyman Adibi",
            "Hossein Karshenas"
        ],
        "comments": " ",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Meta-learning problem is usually formulated as a bi-level optimization in which the task-specific and the meta-parameters are updated in the inner and outer loops of optimization, respectively. However, performing the optimization in the Riemannian space, where the parameters and meta-parameters are located on Riemannian manifolds is computationally intensive. Unlike the Euclidean methods, the Riemannian backpropagation needs computing the second-order derivatives that include backward computations through the Riemannian operators such as retraction and orthogonal projection. This paper introduces a Hessian-free approach that uses a first-order approximation of derivatives on the Stiefel manifold. Our method significantly reduces the computational load and memory footprint. We show how using a Stiefel fully-connected layer that enforces orthogonality constraint on the parameters of the last classification layer as the head of the backbone network, strengthens the representation reuse of the gradient-based meta-learning methods. Our experimental results across various few-shot learning datasets, demonstrate the superiority of our proposed method compared to the state-of-the-art methods, especially MAML, its Euclidean counterpart.\n    ",
        "primary_category": "cs.LG",
        "categories": [],
        "submitted_date": "28 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18606": {
        "title": "Impact of network topology on the performance of Decentralized Federated Learning",
        "authors": [
            "Luigi Palmieri",
            "Chiara Boldrini",
            "Lorenzo Valerio",
            "Andrea Passarella",
            "Marco Conti"
        ],
        "comments": "Funding: H2020 HumaneAI Net (Grant N. 952026), CHIST-ERA SAI (CHIST-ERA-19-XAI010), PNRR FAIR (PE00000013), PNRR RESTART (PE00000001). arXiv admin note: text overlap with arXiv:2307.15947",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Fully decentralized learning is gaining momentum for training AI models at the Internet's edge, addressing infrastructure challenges and privacy concerns. In a decentralized machine learning system, data is distributed across multiple nodes, with each node training a local model based on its respective dataset. The local models are then shared and combined to form a global model capable of making accurate predictions on new data. Our exploration focuses on how different types of network structures influence the spreading of knowledge - the process by which nodes incorporate insights gained from learning patterns in data available on other nodes across the network. Specifically, this study investigates the intricate interplay between network structure and learning performance using three network topologies and six data distribution methods. These methods consider different vertex properties, including degree centrality, betweenness centrality, and clustering coefficient, along with whether nodes exhibit high or low values of these metrics. Our findings underscore the significance of global centrality metrics (degree, betweenness) in correlating with learning performance, while local clustering proves less predictive. We highlight the challenges in transferring knowledge from peripheral to central nodes, attributed to a dilution effect during model aggregation. Additionally, we observe that central nodes exert a pull effect, facilitating the spread of knowledge. In examining degree distribution, hubs in Barabasi-Albert networks positively impact learning for central nodes but exacerbate dilution when knowledge originates from peripheral nodes. Finally, we demonstrate the formidable challenge of knowledge circulation outside of segregated communities.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.AI",
            "cs.DC"
        ],
        "submitted_date": "28 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18607": {
        "title": "Exploring Privacy and Fairness Risks in Sharing Diffusion Models: An Adversarial Perspective",
        "authors": [
            "Xinjian Luo",
            "Yangfan Jiang",
            "Fei Wei",
            "Yuncheng Wu",
            "Xiaokui Xiao",
            "Beng Chin Ooi"
        ],
        "comments": " ",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Diffusion models have recently gained significant attention in both academia and industry due to their impressive generative performance in terms of both sampling quality and distribution coverage. Accordingly, proposals are made for sharing pre-trained diffusion models across different organizations, as a way of improving data utilization while enhancing privacy protection by avoiding sharing private data directly. However, the potential risks associated with such an approach have not been comprehensively examined.\nIn this paper, we take an adversarial perspective to investigate the potential privacy and fairness risks associated with the sharing of diffusion models. Specifically, we investigate the circumstances in which one party (the sharer) trains a diffusion model using private data and provides another party (the receiver) black-box access to the pre-trained model for downstream tasks. We demonstrate that the sharer can execute fairness poisoning attacks to undermine the receiver's downstream models by manipulating the training data distribution of the diffusion model. Meanwhile, the receiver can perform property inference attacks to reveal the distribution of sensitive features in the sharer's dataset. Our experiments conducted on real-world datasets demonstrate remarkable attack performance on different types of diffusion models, which highlights the critical importance of robust data auditing and privacy protection protocols in pertinent applications.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.AI",
            "cs.CR"
        ],
        "submitted_date": "28 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18610": {
        "title": "Why Attention Graphs Are All We Need: Pioneering Hierarchical Classification of Hematologic Cell Populations with LeukoGraph",
        "authors": [
            "Fatemeh Nassajian Mojarrad",
            "Lorenzo Bini",
            "Thomas Matthes",
            "St\u00e9phane Marchand-Maillet"
        ],
        "comments": " ",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "In the complex landscape of hematologic samples such as peripheral blood or bone marrow, cell classification, delineating diverse populations into a hierarchical structure, presents profound challenges. This study presents LeukoGraph, a recently developed framework designed explicitly for this purpose employing graph attention networks (GATs) to navigate hierarchical classification (HC) complexities. Notably, LeukoGraph stands as a pioneering effort, marking the application of graph neural networks (GNNs) for hierarchical inference on graphs, accommodating up to one million nodes and millions of edges, all derived from flow cytometry data. LeukoGraph intricately addresses a classification paradigm where for example four different cell populations undergo flat categorization, while a fifth diverges into two distinct child branches, exemplifying the nuanced hierarchical structure inherent in complex datasets. The technique is more general than this example. A hallmark achievement of LeukoGraph is its F-score of 98%, significantly outclassing prevailing state-of-the-art methodologies. Crucially, LeukoGraph's prowess extends beyond theoretical innovation, showcasing remarkable precision in predicting both flat and hierarchical cell types across flow cytometry datasets from 30 distinct patients. This precision is further underscored by LeukoGraph's ability to maintain a correct label ratio, despite the inherent challenges posed by hierarchical classifications.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "q-bio.CB"
        ],
        "submitted_date": "28 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18614": {
        "title": "Deep Neural Network Models Trained With A Fixed Random Classifier Transfer Better Across Domains",
        "authors": [
            "Hafiz Tiomoko Ali",
            "Umberto Michieli",
            "Ji Joong Moon",
            "Daehyun Kim",
            "Mete Ozay"
        ],
        "comments": "ICASSP 2024. Copyright 2024 IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses, in any current or future media, including reprinting/republishing this material for advertising or promotional purposes, creating new collective works, for resale or redistribution to servers or lists, or reuse of any copyrighted component of this work in other",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "The recently discovered Neural collapse (NC) phenomenon states that the last-layer weights of Deep Neural Networks (DNN), converge to the so-called Equiangular Tight Frame (ETF) simplex, at the terminal phase of their training. This ETF geometry is equivalent to vanishing within-class variability of the last layer activations. Inspired by NC properties, we explore in this paper the transferability of DNN models trained with their last layer weight fixed according to ETF. This enforces class separation by eliminating class covariance information, effectively providing implicit regularization. We show that DNN models trained with such a fixed classifier significantly improve transfer performance, particularly on out-of-domain datasets. On a broad range of fine-grained image classification datasets, our approach outperforms i) baseline methods that do not perform any covariance regularization (up to 22%), as well as ii) methods that explicitly whiten covariance of activations throughout training (up to 19%). Our findings suggest that DNNs trained with fixed ETF classifiers offer a powerful mechanism for improving transfer learning across domains.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.CV",
            "cs.NE"
        ],
        "submitted_date": "28 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18616": {
        "title": "JCLEC-MO: a Java suite for solving many-objective optimization engineering problems",
        "authors": [
            "Aurora Ram\u00edrez",
            "Jos\u00e9 Ra\u00fal Romero",
            "Carlos Garc\u00eda-Mart\u00ednez",
            "Sebasti\u00e1n Ventura"
        ],
        "comments": "41 pages, 5 figures, journal paper",
        "subjects": "Neural and Evolutionary Computing (cs.NE)",
        "abstract": "Although metaheuristics have been widely recognized as efficient techniques to solve real-world optimization problems, implementing them from scratch remains difficult for domain-specific experts without programming skills. In this scenario, metaheuristic optimization frameworks are a practical alternative as they provide a variety of algorithms composed of customized elements, as well as experimental support. Recently, many engineering problems require to optimize multiple or even many objectives, increasing the interest in appropriate metaheuristic algorithms and frameworks that might integrate new specific requirements while maintaining the generality and reusability principles they were conceived for. Based on this idea, this paper introduces JCLEC-MO, a Java framework for both multi- and many-objective optimization that enables engineers to apply, or adapt, a great number of multi-objective algorithms with little coding effort. A case study is developed and explained to show how JCLEC-MO can be used to address many-objective engineering problems, often requiring the inclusion of domain-specific elements, and to analyze experimental outcomes by means of conveniently connected R utilities.\n    ",
        "primary_category": "cs.NE",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "28 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18617": {
        "title": "ELA: Exploited Level Augmentation for Offline Learning in Zero-Sum Games",
        "authors": [
            "Shiqi Lei",
            "Kanghoon Lee",
            "Linjing Li",
            "Jinkyoo Park",
            "Jiachen Li"
        ],
        "comments": "12 pages, 8 figures",
        "subjects": "Computer Science and Game Theory (cs.GT)",
        "abstract": "Offline learning has become widely used due to its ability to derive effective policies from offline datasets gathered by expert demonstrators without interacting with the environment directly. Recent research has explored various ways to enhance offline learning efficiency by considering the characteristics (e.g., expertise level or multiple demonstrators) of the dataset. However, a different approach is necessary in the context of zero-sum games, where outcomes vary significantly based on the strategy of the opponent. In this study, we introduce a novel approach that uses unsupervised learning techniques to estimate the exploited level of each trajectory from the offline dataset of zero-sum games made by diverse demonstrators. Subsequently, we incorporate the estimated exploited level into the offline learning to maximize the influence of the dominant strategy. Our method enables interpretable exploited level estimation in multiple zero-sum games and effectively identifies dominant strategy data. Also, our exploited level augmented offline learning significantly enhances the original offline learning algorithms including imitation learning and offline reinforcement learning for zero-sum games.\n    ",
        "primary_category": "cs.GT",
        "categories": [
            "cs.AI",
            "cs.LG",
            "cs.MA"
        ],
        "submitted_date": "28 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18618": {
        "title": "Urban Green Index estimation based on data collected by remote sensing for Romanian cities",
        "authors": [
            "Marian Necula",
            "Tudorel Andrei",
            "Bogdan Oancea",
            "Mihaela P\u0103un"
        ],
        "comments": " ",
        "subjects": "Other Computer Science (cs.OH)",
        "abstract": "The modernization of offi cial statistics involves the use of new data sources, such as data collected through remote sensing. The document contains a description of how an urban green index, derived from the SDG 11.7 objective, was obtained for Romania's 41 county seat cities based on free data sets collected by remote sensing from the European and North American space agencies. The main result is represented by an estimate of the areas of surfaces covered with vegetation for the 40 county seat towns and the municipality of Bucharest, relative to the total surface. To estimate the area covered with vegetation, we used two data sets obtained by remote sensing, namely data provided by the MODIS mission, the TERRA satellite, and data provided by the Sentinel 2 mission from the Copernicus space program. Based on the results obtained, namely the surface area covered with vegetation, estimated in square kilometers, and the percentage of the total surface area or urban green index, we have created a national top of the county seat cities\n    ",
        "primary_category": "cs.OH",
        "categories": [],
        "submitted_date": "28 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18621": {
        "title": "Unveiling News Publishers Trustworthiness Through Social Interactions",
        "authors": [
            "Manuel Pratelli",
            "Fabio Saracco",
            "Marinella Petrocchi"
        ],
        "comments": "A pre-final version of the paper accepted at WebSci'24",
        "subjects": "Social and Information Networks (cs.SI)",
        "abstract": "With the primary goal of raising readers' awareness of misinformation phenomena, extensive efforts have been made by both academic institutions and independent organizations to develop methodologies for assessing the trustworthiness of online news publishers. Unfortunately, existing approaches are costly and face critical scalability challenges. This study presents a novel framework for assessing the trustworthiness of online news publishers using user interactions on social media platforms. The proposed methodology provides a versatile solution that serves the dual purpose of i) identifying verifiable online publishers and ii) automatically performing an initial estimation of the trustworthiness of previously unclassified online news outlets.\n    ",
        "primary_category": "cs.SI",
        "categories": [],
        "submitted_date": "28 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18630": {
        "title": "GNSS Positioning using Cost Function Regulated Multilateration and Graph Neural Networks",
        "authors": [
            "Amir Jalalirad",
            "Davide Belli",
            "Bence Major",
            "Songwon Jee",
            "Himanshu Shah",
            "Will Morrison"
        ],
        "comments": "Published in The Proceedings of the Institute of Navigation GNSS+ 2023",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "In urban environments, where line-of-sight signals from GNSS satellites are frequently blocked by high-rise objects, GNSS receivers are subject to large errors in measuring satellite ranges. Heuristic methods are commonly used to estimate these errors and reduce the impact of noisy measurements on localization accuracy. In our work, we replace these error estimation heuristics with a deep learning model based on Graph Neural Networks. Additionally, by analyzing the cost function of the multilateration process, we derive an optimal method to utilize the estimated errors. Our approach guarantees that the multilateration converges to the receiver's location as the error estimation accuracy increases. We evaluate our solution on a real-world dataset containing more than 100k GNSS epochs, collected from multiple cities with diverse characteristics. The empirical results show improvements from 40% to 80% in the horizontal localization error against recent deep learning baselines as well as classical localization approaches.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "eess.SP"
        ],
        "submitted_date": "28 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18649": {
        "title": "A New Era in LLM Security: Exploring Security Concerns in Real-World LLM-based Systems",
        "authors": [
            "Fangzhou Wu",
            "Ning Zhang",
            "Somesh Jha",
            "Patrick McDaniel",
            "Chaowei Xiao"
        ],
        "comments": " ",
        "subjects": "Cryptography and Security (cs.CR)",
        "abstract": "Large Language Model (LLM) systems are inherently compositional, with individual LLM serving as the core foundation with additional layers of objects such as plugins, sandbox, and so on. Along with the great potential, there are also increasing concerns over the security of such probabilistic intelligent systems. However, existing studies on LLM security often focus on individual LLM, but without examining the ecosystem through the lens of LLM systems with other objects (e.g., Frontend, Webtool, Sandbox, and so on). In this paper, we systematically analyze the security of LLM systems, instead of focusing on the individual LLMs. To do so, we build on top of the information flow and formulate the security of LLM systems as constraints on the alignment of the information flow within LLM and between LLM and other objects. Based on this construction and the unique probabilistic nature of LLM, the attack surface of the LLM system can be decomposed into three key components: (1) multi-layer security analysis, (2) analysis of the existence of constraints, and (3) analysis of the robustness of these constraints. To ground this new attack surface, we propose a multi-layer and multi-step approach and apply it to the state-of-art LLM system, OpenAI GPT4. Our investigation exposes several security issues, not just within the LLM model itself but also in its integration with other components. We found that although the OpenAI GPT4 has designed numerous safety constraints to improve its safety features, these safety constraints are still vulnerable to attackers. To further demonstrate the real-world threats of our discovered vulnerabilities, we construct an end-to-end attack where an adversary can illicitly acquire the user's chat history, all without the need to manipulate the user's input or gain direct access to OpenAI GPT4. Our demo is in the link: this https URL\n",
        "primary_category": "cs.CR",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "28 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18650": {
        "title": "The Grasp Reset Mechanism: An Automated Apparatus for Conducting Grasping Trials",
        "authors": [
            "Kyle DuFrene",
            "Keegan Nave",
            "Joshua Campbell",
            "Ravi Balasubramanian",
            "Cindy Grimm"
        ],
        "comments": "Accepted to the 2024 IEEE International Conference on Robotics and Automation (ICRA2024)",
        "subjects": "Robotics (cs.RO)",
        "abstract": "Advancing robotic grasping and manipulation requires the ability to test algorithms and/or train learning models on large numbers of grasps. Towards the goal of more advanced grasping, we present the Grasp Reset Mechanism (GRM), a fully automated apparatus for conducting large-scale grasping trials. The GRM automates the process of resetting a grasping environment, repeatably placing an object in a fixed location and controllable 1-D orientation. It also collects data and swaps between multiple objects enabling robust dataset collection with no human intervention. We also present a standardized state machine interface for control, which allows for integration of most manipulators with minimal effort. In addition to the physical design and corresponding software, we include a dataset of 1,020 grasps. The grasps were created with a Kinova Gen3 robot arm and Robotiq 2F-85 Adaptive Gripper to enable training of learning models and to demonstrate the capabilities of the GRM. The dataset includes ranges of grasps conducted across four objects and a variety of orientations. Manipulator states, object pose, video, and grasp success data are provided for every trial.\n    ",
        "primary_category": "cs.RO",
        "categories": [],
        "submitted_date": "28 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18651": {
        "title": "Quantifying Human Priors over Social and Navigation Networks",
        "authors": [
            "Gecia Bravo-Hermsdorff"
        ],
        "comments": "Published on Proceedings of the 40th International Conference on Machine Learning (ICML), PMLR 202:3063-3105, 2023",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Human knowledge is largely implicit and relational -- do we have a friend in common? can I walk from here to there? In this work, we leverage the combinatorial structure of graphs to quantify human priors over such relational data. Our experiments focus on two domains that have been continuously relevant over evolutionary timescales: social interaction and spatial navigation. We find that some features of the inferred priors are remarkably consistent, such as the tendency for sparsity as a function of graph size. Other features are domain-specific, such as the propensity for triadic closure in social interactions. More broadly, our work demonstrates how nonclassical statistical analysis of indirect behavioral experiments can be used to efficiently model latent biases in the data.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.AI",
            "cs.SI",
            "physics.soc-ph",
            "q-bio.NC",
            "stat.ME"
        ],
        "submitted_date": "28 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18652": {
        "title": "Spatial Variation-Aware Read Disturbance Defenses: Experimental Analysis of Real DRAM Chips and Implications on Future Solutions",
        "authors": [
            "Abdullah Giray Ya\u011fl\u0131k\u00e7\u0131",
            "Yahya Can Tu\u011frul",
            "Geraldo F. Oliveira",
            "\u0130smail Emir Y\u00fcksel",
            "Ataberk Olgun",
            "Haocong Luo",
            "Onur Mutlu"
        ],
        "comments": "A shorter version of this work is to appear at the 30th IEEE International Symposium on High-Performance Computer Architecture (HPCA-30), 2024",
        "subjects": "Cryptography and Security (cs.CR)",
        "abstract": "Read disturbance in modern DRAM chips is a widespread phenomenon and is reliably used for breaking memory isolation, a fundamental building block for building robust systems. RowHammer and RowPress are two examples of read disturbance in DRAM where repeatedly accessing (hammering) or keeping active (pressing) a memory location induces bitflips in other memory locations. Unfortunately, shrinking technology node size exacerbates read disturbance in DRAM chips over generations. As a result, existing defense mechanisms suffer from significant performance and energy overheads, limited effectiveness, or prohibitively high hardware complexity.\nIn this paper, we tackle these shortcomings by leveraging the spatial variation in read disturbance across different memory locations in real DRAM chips. To do so, we 1) present the first rigorous real DRAM chip characterization study of spatial variation of read disturbance and 2) propose Sv\u00e4rd, a new mechanism that dynamically adapts the aggressiveness of existing solutions based on the row-level read disturbance profile. Our experimental characterization on 144 real DDR4 DRAM chips representing 10 chip designs demonstrates a large variation in read disturbance vulnerability across different memory locations: in the part of memory with the worst read disturbance vulnerability, 1) up to 2x the number of bitflips can occur and 2) bitflips can occur at an order of magnitude fewer accesses, compared to the memory locations with the least vulnerability to read disturbance. Sv\u00e4rd leverages this variation to reduce the overheads of five state-of-the-art read disturbance solutions, and thus significantly increases system performance.\n    ",
        "primary_category": "cs.CR",
        "categories": [
            "cs.AR"
        ],
        "submitted_date": "28 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18659": {
        "title": "Large Language Models and Games: A Survey and Roadmap",
        "authors": [
            "Roberto Gallotta",
            "Graham Todd",
            "Marvin Zammit",
            "Sam Earle",
            "Antonios Liapis",
            "Julian Togelius",
            "Georgios N. Yannakakis"
        ],
        "comments": "13 pages, 4 figures",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "Recent years have seen an explosive increase in research on large language models (LLMs), and accompanying public engagement on the topic. While starting as a niche area within natural language processing, LLMs have shown remarkable potential across a broad range of applications and domains, including games. This paper surveys the current state of the art across the various applications of LLMs in and for games, and identifies the different roles LLMs can take within a game. Importantly, we discuss underexplored areas and promising directions for future uses of LLMs in games and we reconcile the potential and limitations of LLMs within the games domain. As the first comprehensive survey and roadmap at the intersection of LLMs and games, we are hopeful that this paper will serve as the basis for groundbreaking research and innovation in this exciting new field.\n    ",
        "primary_category": "cs.CL",
        "categories": [
            "cs.AI",
            "cs.HC"
        ],
        "submitted_date": "28 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18660": {
        "title": "Versatile mixed methods for compressible flows",
        "authors": [
            "Edward A. Miller",
            "David M. Williams"
        ],
        "comments": "28 pages, 4 figures, 4 tables",
        "subjects": "Numerical Analysis (math.NA)",
        "abstract": "Versatile mixed finite element methods were originally developed by Chen and Williams for isothermal incompressible flows in \"Versatile mixed methods for the incompressible Navier-Stokes equations,\" Computers & Mathematics with Applications, Volume 80, 2020. Thereafter, these methods were extended by Miller, Chen, and Williams to non-isothermal incompressible flows in \"Versatile mixed methods for non-isothermal incompressible flows,\" Computers & Mathematics with Applications, Volume 125, 2022. The main advantage of these methods lies in their flexibility. Unlike traditional mixed methods, they retain the divergence terms in the momentum and temperature equations. As a result, the favorable properties of the schemes are maintained even in the presence of non-zero divergence. This makes them an ideal candidate for an extension to compressible flows, in which the divergence does not generally vanish. In the present article, we finally construct the fully-compressible extension of the methods. In addition, we demonstrate the excellent performance of the resulting methods for weakly-compressible flows that arise near the incompressible limit, as well as more strongly-compressible flows that arise near Mach 0.5.\n    ",
        "primary_category": "math.NA",
        "categories": [],
        "submitted_date": "28 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18667": {
        "title": "FOFO: A Benchmark to Evaluate LLMs' Format-Following Capability",
        "authors": [
            "Congying Xia",
            "Chen Xing",
            "Jiangshu Du",
            "Xinyi Yang",
            "Yihao Feng",
            "Ran Xu",
            "Wenpeng Yin",
            "Caiming Xiong"
        ],
        "comments": "The first two authors contributed equally",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "This paper presents FoFo, a pioneering benchmark for evaluating large language models' (LLMs) ability to follow complex, domain-specific formats, a crucial yet underexamined capability for their application as AI agents. Despite LLMs' advancements, existing benchmarks fail to assess their format-following proficiency adequately. FoFo fills this gap with a diverse range of real-world formats and instructions, developed through an AI-Human collaborative method. Our evaluation across both open-source (e.g., Llama 2, WizardLM) and closed-source (e.g., GPT-4, PALM2, Gemini) LLMs highlights three key findings: open-source models significantly lag behind closed-source ones in format adherence; LLMs' format-following performance is independent of their content generation quality; and LLMs' format proficiency varies across different domains. These insights suggest the need for specialized tuning for format-following skills and highlight FoFo's role in guiding the selection of domain-specific AI agents. FoFo is released here at this https URL.\n    ",
        "primary_category": "cs.CL",
        "categories": [],
        "submitted_date": "28 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18668": {
        "title": "Simple linear attention language models balance the recall-throughput tradeoff",
        "authors": [
            "Simran Arora",
            "Sabri Eyuboglu",
            "Michael Zhang",
            "Aman Timalsina",
            "Silas Alberti",
            "Dylan Zinsley",
            "James Zou",
            "Atri Rudra",
            "Christopher R\u00e9"
        ],
        "comments": " ",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "Recent work has shown that attention-based language models excel at recall, the ability to ground generations in tokens previously seen in context. However, the efficiency of attention-based models is bottle-necked during inference by the KV-cache's aggressive memory consumption. In this work, we explore whether we can improve language model efficiency (e.g. by reducing memory consumption) without compromising on recall. By applying experiments and theory to a broad set of architectures, we identify a key tradeoff between a model's state size and recall ability. We show that efficient alternatives to attention (e.g. H3, Mamba, RWKV) maintain a fixed-size recurrent state, but struggle at recall. We propose BASED a simple architecture combining linear and sliding window attention. By varying BASED window size and linear attention feature dimension, we can dial the state size and traverse the pareto frontier of the recall-memory tradeoff curve, recovering the full quality of attention on one end and the small state size of attention-alternatives on the other. We train language models up to 1.3b parameters and show that BASED matches the strongest sub-quadratic models (e.g. Mamba) in perplexity and outperforms them on real-world recall-intensive tasks by 6.22 accuracy points. Implementations of linear attention are often less efficient than optimized standard attention implementations. To make BASED competitive, we develop IO-aware algorithms that enable 24x higher throughput on language generation than FlashAttention-2, when generating 1024 tokens using 1.3b parameter models. Code for this work is provided at: this https URL.\n    ",
        "primary_category": "cs.CL",
        "categories": [
            "cs.LG"
        ],
        "submitted_date": "28 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18675": {
        "title": "Robot Body Schema Learning from Full-body Extero/Proprioception Sensors",
        "authors": [
            "Shuo Jiang",
            "Jinkun Zhang",
            "Lawson Wong"
        ],
        "comments": " ",
        "subjects": "Robotics (cs.RO)",
        "abstract": "For a robot, its body structure is an a-prior knowledge when it is designed. However, when such information is not available, can a robot recognize it by itself? In this paper, we aim to grant a robot such ability to learn its body structure from exteroception and proprioception data collected from on-body sensors. By a novel machine learning method, the robot can learn a binary Heterogeneous Dependency Matrix from its sensor readings. We showed such matrix is equivalent to a Heterogeneous out-tree structure which can uniquely represent the robot body topology. We explored the properties of such matrix and the out-tree, and proposed a remedy to fix them when they are contaminated by partial observability or data noise. We ran our algorithm on 6 different robots with different body structures in simulation and 1 real robot. Our algorithm correctly recognized their body structures with only on-body sensor readings but no topology prior knowledge.\n    ",
        "primary_category": "cs.RO",
        "categories": [],
        "submitted_date": "28 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18677": {
        "title": "Fault Tolerant Neural Control Barrier Functions for Robotic Systems under Sensor Faults and Attacks",
        "authors": [
            "Hongchao Zhang",
            "Luyao Niu",
            "Andrew Clark",
            "Radha Poovendran"
        ],
        "comments": " ",
        "subjects": "Robotics (cs.RO)",
        "abstract": "Safety is a fundamental requirement of many robotic systems. Control barrier function (CBF)-based approaches have been proposed to guarantee the safety of robotic systems. However, the effectiveness of these approaches highly relies on the choice of CBFs. Inspired by the universal approximation power of neural networks, there is a growing trend toward representing CBFs using neural networks, leading to the notion of neural CBFs (NCBFs). Current NCBFs, however, are trained and deployed in benign environments, making them ineffective for scenarios where robotic systems experience sensor faults and attacks. In this paper, we study safety-critical control synthesis for robotic systems under sensor faults and attacks. Our main contribution is the development and synthesis of a new class of CBFs that we term fault tolerant neural control barrier function (FT-NCBF). We derive the necessary and sufficient conditions for FT-NCBFs to guarantee safety, and develop a data-driven method to learn FT-NCBFs by minimizing a loss function constructed using the derived conditions. Using the learned FT-NCBF, we synthesize a control input and formally prove the safety guarantee provided by our approach. We demonstrate our proposed approach using two case studies: obstacle avoidance problem for an autonomous mobile robot and spacecraft rendezvous problem, with code available via this https URL.\n    ",
        "primary_category": "cs.RO",
        "categories": [
            "cs.AI",
            "eess.SY"
        ],
        "submitted_date": "28 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18678": {
        "title": "RORA: Robust Free-Text Rationale Evaluation",
        "authors": [
            "Zhengping Jiang",
            "Yining Lu",
            "Hanjie Chen",
            "Daniel Khashabi",
            "Benjamin Van Durme",
            "Anqi Liu"
        ],
        "comments": " ",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "Free-text rationales play a pivotal role in explainable NLP, bridging the knowledge and reasoning gaps behind a model's decision-making. However, due to the diversity of potential reasoning paths and a corresponding lack of definitive ground truth, their evaluation remains a challenge. Existing evaluation metrics rely on the degree to which a rationale supports a target label, but we find these fall short in evaluating rationales that inadvertently leak the labels. To address this problem, we propose RORA, a Robust free-text Rationale evaluation against label leakage. RORA quantifies the new information supplied by a rationale to justify the label. This is achieved by assessing the conditional V-information \\citep{hewitt-etal-2021-conditional} with a predictive family robust against leaky features that can be exploited by a small model. RORA consistently outperforms existing approaches in evaluating human-written, synthetic, or model-generated rationales, particularly demonstrating robustness against label leakage. We also show that RORA aligns well with human judgment, providing a more reliable and accurate measurement across diverse free-text rationales.\n    ",
        "primary_category": "cs.CL",
        "categories": [],
        "submitted_date": "28 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18682": {
        "title": "Acoustic tactile sensing for mobile robot wheels",
        "authors": [
            "Wilfred Mason",
            "David Brenken",
            "Falcon Z. Dai",
            "Ricardo Gonzalo Cruz Castillo",
            "Olivier St-Martin Cormier",
            "Audrey Sedal"
        ],
        "comments": "12 pages, 12 figures",
        "subjects": "Robotics (cs.RO)",
        "abstract": "Tactile sensing in mobile robots remains under-explored, mainly due to challenges related to sensor integration and the complexities of distributed sensing. In this work, we present a tactile sensing architecture for mobile robots based on wheel-mounted acoustic waveguides. Our sensor architecture enables tactile sensing along the entire circumference of a wheel with a single active component: an off-the-shelf acoustic rangefinder. We present findings showing that our sensor, mounted on the wheel of a mobile robot, is capable of discriminating between different terrains, detecting and classifying obstacles with different geometries, and performing collision detection via contact localization. We also present a comparison between our sensor and sensors traditionally used in mobile robots, and point to the potential for sensor fusion approaches that leverage the unique capabilities of our tactile sensing architecture. Our findings demonstrate that autonomous mobile robots can further leverage our sensor architecture for diverse mapping tasks requiring knowledge of terrain material, surface topology, and underlying structure.\n    ",
        "primary_category": "cs.RO",
        "categories": [],
        "submitted_date": "28 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18683": {
        "title": "Integrated Sensing and Communication Meets Smart Propagation Engineering: Opportunities and Challenges",
        "authors": [
            "Kaitao Meng",
            "Christos Masouros",
            "Kai-Kit Wong",
            "Athina P. Petropulu",
            "Lajos Hanzo"
        ],
        "comments": "7 pages, 5 figures, submitted to IEEE journal for possible publication",
        "subjects": "Information Theory (cs.IT)",
        "abstract": "Both smart propagation engineering as well as integrated sensing and communication (ISAC) constitute promising candidates for next-generation (NG) mobile networks. We provide a synergistic view of these technologies, and explore their mutual benefits. First, moving beyond just intelligent surfaces, we provide a holistic view of the engineering aspects of smart propagation environments. By delving into the fundamental characteristics of intelligent surfaces, fluid antennas, and unmanned aerial vehicles, we reveal that more efficient control of the pathloss and fading can be achieved, thus facilitating intrinsic integration and mutual assistance between sensing and communication functionalities. In turn, with the exploitation of the sensing capabilities of ISAC to orchestrate the efficient configuration of radio environments, both the computational effort and signaling overheads can be reduced. We present indicative simulation results, which verify that cooperative smart propagation environment design significantly enhances the ISAC performance. Finally, some promising directions are outlined for combining ISAC with smart propagation engineering.\n    ",
        "primary_category": "cs.IT",
        "categories": [
            "eess.SP"
        ],
        "submitted_date": "28 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18684": {
        "title": "Quantum State Compression with Polar Codes",
        "authors": [
            "Jack Weinberg",
            "Avijit Mandal",
            "Henry D. Pfister"
        ],
        "comments": "Extended Version of ISIT 2024 Submission",
        "subjects": "Quantum Physics (quant-ph)",
        "abstract": "In the quantum compression scheme proposed by Schumacher, Alice compresses a message that Bob decompresses. In that approach, there is some probability of failure and, even when successful, some distortion of the state. For sufficiently large blocklengths, both of these imperfections can be made arbitrarily small while achieving a compression rate that asymptotically approaches the source coding bound. However, direct implementation of Schumacher compression suffers from poor circuit complexity. In this paper, we consider a slightly different approach based on classical syndrome source coding. The idea is to use a linear error-correcting code and treat the message to be compressed as an error pattern. If the message is a correctable error (i.e., a coset leader) then Alice can use the error-correcting code to convert her message to a corresponding quantum syndrome. An implementation of this based on polar codes is described and simulated. As in classical source coding based on polar codes, Alice maps the information into the ``frozen\" qubits that constitute the syndrome. To decompress, Bob utilizes a quantum version of successive cancellation coding.\n    ",
        "primary_category": "quant-ph",
        "categories": [
            "cs.IT"
        ],
        "submitted_date": "28 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18688": {
        "title": "Exploring AI Problem Formulation with Children via Teachable Machines",
        "authors": [
            "Utkarsh Dwivedi",
            "Salma Elsayed-Ali",
            "Elizabeth Bonsignore",
            "Hernisa Kacorri"
        ],
        "comments": " ",
        "subjects": "Human-Computer Interaction (cs.HC)",
        "abstract": "Emphasizing problem formulation in AI literacy activities with children is vital, yet we lack empirical studies on their structure and affordances. We propose that participatory design involving teachable machines facilitates problem formulation activities. To test this, we integrated problem reduction heuristics into storyboarding and invited a university-based intergenerational design team of 10 children (ages 8-13) and 9 adults to co-design a teachable machine. We find that children draw from personal experiences when formulating AI problems; they assume voice and video capabilities, explore diverse machine learning approaches, and plan for error handling. Their ideas promote human involvement in AI, though some are drawn to more autonomous systems. Their designs prioritize values like capability, logic, helpfulness, responsibility, and obedience, and a preference for a comfortable life, family security, inner harmony, and excitement as end-states. We conclude by discussing how these results can inform the design of future participatory AI activities.\n    ",
        "primary_category": "cs.HC",
        "categories": [],
        "submitted_date": "28 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18689": {
        "title": "The VOROS: Lifting ROC curves to 3D",
        "authors": [
            "Christopher Ratigan",
            "Lenore Cowen"
        ],
        "comments": "38 pages, 19 figures",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "The area under the ROC curve is a common measure that is often used to rank the relative performance of different binary classifiers. However, as has been also previously noted, it can be a measure that ill-captures the benefits of different classifiers when either the true class values or misclassification costs are highly unbalanced between the two classes. We introduce a third dimension to capture these costs, and lift the ROC curve to a ROC surface in a natural way. We study both this surface and introduce the VOROS, the volume over this ROC surface, as a 3D generalization of the 2D area under the ROC curve. For problems where there are only bounds on the expected costs or class imbalances, we restrict consideration to the volume of the appropriate subregion of the ROC surface. We show how the VOROS can better capture the costs of different classifiers on both a classical and a modern example dataset.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "math.MG",
            "math.ST",
            "stat.ME"
        ],
        "submitted_date": "28 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18695": {
        "title": "Grounding Language Models for Visual Entity Recognition",
        "authors": [
            "Zilin Xiao",
            "Ming Gong",
            "Paola Cascante-Bonilla",
            "Xingyao Zhang",
            "Jie Wu",
            "Vicente Ordonez"
        ],
        "comments": " ",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "We introduce AutoVER, an Autoregressive model for Visual Entity Recognition. Our model extends an autoregressive Multi-modal Large Language Model by employing retrieval augmented constrained generation. It mitigates low performance on out-of-domain entities while excelling in queries that require visually-situated reasoning. Our method learns to distinguish similar entities within a vast label space by contrastively training on hard negative pairs in parallel with a sequence-to-sequence objective without an external retriever. During inference, a list of retrieved candidate answers explicitly guides language generation by removing invalid decoding paths. The proposed method achieves significant improvements across different dataset splits in the recently proposed Oven-Wiki benchmark. Accuracy on the Entity seen split rises from 32.7% to 61.5%. It also demonstrates superior performance on the unseen and query splits by a substantial double-digit margin.\n    ",
        "primary_category": "cs.CV",
        "categories": [
            "cs.CL"
        ],
        "submitted_date": "28 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18697": {
        "title": "Inferring Dynamic Networks from Marginals with Iterative Proportional Fitting",
        "authors": [
            "Serina Chang",
            "Frederic Koehler",
            "Zhaonan Qu",
            "Jure Leskovec",
            "Johan Ugander"
        ],
        "comments": " ",
        "subjects": "Machine Learning (stat.ML)",
        "abstract": "A common network inference problem, arising from real-world data constraints, is how to infer a dynamic network from its time-aggregated adjacency matrix and time-varying marginals (i.e., row and column sums). Prior approaches to this problem have repurposed the classic iterative proportional fitting (IPF) procedure, also known as Sinkhorn's algorithm, with promising empirical results. However, the statistical foundation for using IPF has not been well understood: under what settings does IPF provide principled estimation of a dynamic network from its marginals, and how well does it estimate the network? In this work, we establish such a setting, by identifying a generative network model whose maximum likelihood estimates are recovered by IPF. Our model both reveals implicit assumptions on the use of IPF in such settings and enables new analyses, such as structure-dependent error bounds on IPF's parameter estimates. When IPF fails to converge on sparse network data, we introduce a principled algorithm that guarantees IPF converges under minimal changes to the network structure. Finally, we conduct experiments with synthetic and real-world data, which demonstrate the practical value of our theoretical and algorithmic contributions.\n    ",
        "primary_category": "stat.ML",
        "categories": [
            "cs.LG",
            "cs.SI",
            "math.OC",
            "math.ST"
        ],
        "submitted_date": "28 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18698": {
        "title": "Spatial Coherence Loss for Salient and Camouflaged Object Detection and Beyond",
        "authors": [
            "Ziyun Yang",
            "Kevin Choy",
            "Sina Farsiu"
        ],
        "comments": " ",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Generic object detection is a category-independent task that relies on accurate modeling of objectness. Most relevant CNN-based models of objectness utilize loss functions (e.g., binary cross entropy) that focus on the single-response, i.e., the loss response of a single pixel. Inspired by the human visual system, which first discerns the boundaries of ambiguous regions (i.e., hard regions) before delving into the semantic meaning, we propose a novel loss function, Spatial Coherence Loss (SCLoss), that uses the mutual response between adjacent pixels to suppress or emphasize the single-response of pixels. We demonstrate that the proposed SCLoss can gradually learn the hard regions by detecting and emphasizing their boundaries. Through comprehensive experiments, we demonstrate that replacing popular loss functions with SCLoss can improve the performance of current state-of-the-art (SOTA) salient or camouflaged object detection (SOD or COD) models. We also demonstrate that combining SCLoss with other loss functions can further improve performance and result in the SOTA outcomes for different applications. Finally, as a demonstrative example of the potential uses for other related tasks, we show an application of SCLoss for semantic segmentation.\n    ",
        "primary_category": "cs.CV",
        "categories": [],
        "submitted_date": "28 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18702": {
        "title": "Characterizing Multimedia Information Environment through Multi-modal Clustering of YouTube Videos",
        "authors": [
            "Niloofar Yousefi",
            "Mainuddin Shaik",
            "Nitin Agarwal"
        ],
        "comments": "14 pages, In the 4th International Conference on SMART MULTIMEDIA, 2024",
        "subjects": "Multimedia (cs.MM)",
        "abstract": "This study aims to investigate the comprehensive characterization of information content in multimedia (videos), particularly on YouTube. The research presents a multi-method framework for characterizing multimedia content by clustering signals from various modalities, such as audio, video, and text. With a focus on South China Sea videos as a case study, this approach aims to enhance our understanding of online content, especially on YouTube. The dataset includes 160 videos, and our findings offer insights into content themes and patterns within different modalities of a video based on clusters. Text modality analysis revealed topical themes related to geopolitical countries, strategies, and global security, while video and audio modality analysis identified distinct patterns of signals related to diverse sets of videos, including news analysis/reporting, educational content, and interviews. Furthermore, our findings uncover instances of content repurposing within video clusters, which were identified using the barcode technique and audio similarity assessments. These findings indicate potential content amplification techniques. In conclusion, this study uniquely enhances our current understanding of multimedia content information based on modality clustering techniques.\n    ",
        "primary_category": "cs.MM",
        "categories": [],
        "submitted_date": "28 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18703": {
        "title": "Zero-error communication, scrambling, and ergodicity",
        "authors": [
            "Satvik Singh",
            "Mizanur Rahaman",
            "Nilanjana Datta"
        ],
        "comments": "Preliminary version. Comments are welcome",
        "subjects": "Quantum Physics (quant-ph)",
        "abstract": "The long term behaviour of a quantum channel under iterations (i.e. under repeated applications of itself) yields a plethora of interesting properties. These include ergodicity, mixing, eventual scrambling, becoming strictly positive, and the vanishing of its one-shot zero error capacities. We derive relations between these seemingly different properties and find novel bounds on indices which quantify the minimum number of iterations needed for the onset of some of these properties. We obtain a lower bound on the one-shot zero-error classical capacity of $n$ iterations of an ergodic channel (for any positive integer $n$) in terms of the cardinality of its peripheral spectrum. We also find upper bounds on the minimum number of iterations needed for the one-shot capacities of any channel to stabilize. We consider two classes of quantum channels, satisfying certain symmetries, for which upper bounds on the above indices are optimal, since they reduce to the corresponding indices for a stochastic matrix (for which the bounds are known to be optimal). As an auxiliary result, we obtain a trade-off relation between the one-shot zero error classical and quantum capacities of a quantum channel.\n    ",
        "primary_category": "quant-ph",
        "categories": [
            "cs.IT",
            "math.OA",
            "math.PR"
        ],
        "submitted_date": "28 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18707": {
        "title": "Embodied Supervision: Haptic Display of Automation Command to Improve Supervisory Performance",
        "authors": [
            "Alia Gilbert",
            "Sachit Krishnan",
            "R. Brent Gillespie"
        ],
        "comments": "IEEE Haptics Symposium 2024",
        "subjects": "Human-Computer Interaction (cs.HC)",
        "abstract": "A human operator using a manual control interface has ready access to their own command signal, both by efference copy and proprioception. In contrast, a human supervisor typically relies on visual information alone. We propose supplying a supervisor with a copy of the operators command signal, hypothesizing improved performance, especially when that copy is provided through haptic display. We experimentally compared haptic with visual access to the command signal, quantifying the performance of N equals 10 participants attempting to determine which of three reference signals was being tracked by an operator. Results indicate an improved accuracy in identifying the tracked target when haptic display was available relative to visual display alone. We conjecture the benefit follows from the relationship of haptics to the supervisor's own experience, perhaps muscle memory, as an operator.\n    ",
        "primary_category": "cs.HC",
        "categories": [
            "cs.RO"
        ],
        "submitted_date": "28 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18708": {
        "title": "Bluebell: An Alliance of Relational Lifting and Independence For Probabilistic Reasoning",
        "authors": [
            "Jialu Bao",
            "Emanuele D'Osualdo",
            "Azadeh Farzan"
        ],
        "comments": "23 pages + 53 pages of appendix",
        "subjects": "Logic in Computer Science (cs.LO)",
        "abstract": "We present Bluebell, a program logic for reasoning about probabilistic programs where unary and relational styles of reasoning come together to create new reasoning tools. Unary-style reasoning is very expressive and is powered by foundational mechanisms to reason about probabilistic behaviour like independence and conditioning. The relational style of reasoning, on the other hand, naturally shines when the properties of interest compare the behaviour of similar programs (e.g. when proving differential privacy) managing to avoid having to characterize the output distributions of the individual programs. So far, the two styles of reasoning have largely remained separate in the many program logics designed for the deductive verification of probabilistic programs. In Bluebell, we unify these styles of reasoning through the introduction of a new modality called \"joint conditioning\" that can encode and illuminate the rich interaction between conditional independence and relational liftings; the two powerhouses from the two styles of reasoning.\n    ",
        "primary_category": "cs.LO",
        "categories": [
            "cs.PL"
        ],
        "submitted_date": "28 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18709": {
        "title": "Nonlinear identification algorithm for online and offline study of pulmonary mechanical ventilation",
        "authors": [
            "Diego A. Riva",
            "Carolina A. Evangelista",
            "Paul F. Puleston",
            "Luis Corsiglia",
            "Nahuel Dargains"
        ],
        "comments": " ",
        "subjects": "Systems and Control (eess.SY)",
        "abstract": "This work presents an algorithm for determining the parameters of a nonlinear dynamic model of the respiratory system in patients undergoing assisted ventilation. Using the pressure and flow signals measured at the mouth, the model's quadratic pressure-volume characteristic is fit to this data in each respiratory cycle by appropriate estimates of the model parameters. Parameter changes during ventilation can thus also be detected. The algorithm is first refined and assessed using data derived from simulated patients represented through a sigmoidal pressure-volume characteristic with hysteresis. As satisfactory results are achieved with the simulated data, the algorithm is evaluated with real data obtained from actual patients undergoing assisted ventilation. The proposed nonlinear dynamic model and associated parameter estimation algorithm yield closer fits than the static linear models computed by respiratory machines, with only a minor increase in computation. They also provide more information to the physician, such as the pressure-volume (P-V) curvature and the condition of the lung (whether normal, under-inflated, or over-inflated). This information can be used to provide safer ventilation for patients, for instance by ventilating them in the linear region of the respiratory system.\n    ",
        "primary_category": "eess.SY",
        "categories": [
            "physics.med-ph"
        ],
        "submitted_date": "28 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18710": {
        "title": "Hefty: A Modular Reconfigurable Robot for Advancing Robot Manipulation in Agriculture",
        "authors": [
            "Dominic Guri",
            "Moonyoung Lee",
            "Oliver Kroemer",
            "George Kantor"
        ],
        "comments": "8 pages, 11 figures",
        "subjects": "Robotics (cs.RO)",
        "abstract": "This paper presents a modular, reconfigurable robot platform for robot manipulation in agriculture. While robot manipulation promises great advancements in automating challenging, complex tasks that are currently best left to humans, it is also an expensive capital investment for researchers and users because it demands significantly varying robot configurations depending on the task. Modular robots provide a way to obtain multiple configurations and reduce costs by enabling incremental acquisition of only the necessary modules. The robot we present, Hefty, is designed to be modular and reconfigurable. It is designed for both researchers and end-users as a means to improve technology transfer from research to real-world application. This paper provides a detailed design and integration process, outlining the critical design decisions that enable modularity in the mobility of the robot as well as its sensor payload, power systems, computing, and fixture mounting. We demonstrate the utility of the robot by presenting five configurations used in multiple real-world agricultural robotics applications.\n    ",
        "primary_category": "cs.RO",
        "categories": [],
        "submitted_date": "28 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18715": {
        "title": "Commonsense Ontology Micropatterns",
        "authors": [
            "Andrew Eells",
            "Brandon Dave",
            "Pascal Hitzler",
            "Cogan Shimizu"
        ],
        "comments": " ",
        "subjects": "Artificial Intelligence (cs.AI)",
        "abstract": "The previously introduced Modular Ontology Modeling methodology (MOMo) attempts to mimic the human analogical process by using modular patterns to assemble more complex concepts. To support this, MOMo organizes organizes ontology design patterns into design libraries, which are programmatically queryable, to support accelerated ontology development, for both human and automated processes. However, a major bottleneck to large-scale deployment of MOMo is the (to-date) limited availability of ready-to-use ontology design patterns. At the same time, Large Language Models have quickly become a source of common knowledge and, in some cases, replacing search engines for questions. In this paper, we thus present a collection of 104 ontology design patterns representing often occurring nouns, curated from the common-sense knowledge available in LLMs, organized into a fully-annotated modular ontology design library ready for use with MOMo.\n    ",
        "primary_category": "cs.AI",
        "categories": [
            "cs.LO"
        ],
        "submitted_date": "28 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18718": {
        "title": "Model Pairing Using Embedding Translation for Backdoor Attack Detection on Open-Set Classification Tasks",
        "authors": [
            "Alexander Unnervik",
            "Hatef Otroshi Shahreza",
            "Anjith George",
            "S\u00e9bastien Marcel"
        ],
        "comments": "Under review",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Backdoor attacks allow an attacker to embed a specific vulnerability in a machine learning algorithm, activated when an attacker-chosen pattern is presented, causing a specific misprediction. The need to identify backdoors in biometric scenarios has led us to propose a novel technique with different trade-offs. In this paper we propose to use model pairs on open-set classification tasks for detecting backdoors. Using a simple linear operation to project embeddings from a probe model's embedding space to a reference model's embedding space, we can compare both embeddings and compute a similarity score. We show that this score, can be an indicator for the presence of a backdoor despite models being of different architectures, having been trained independently and on different datasets. Additionally, we show that backdoors can be detected even when both models are backdoored. The source code is made available for reproducibility purposes.\n    ",
        "primary_category": "cs.CV",
        "categories": [
            "cs.CR"
        ],
        "submitted_date": "28 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18719": {
        "title": "MaxCUCL: Max-Consensus with Deterministic Convergence in Networks with Unreliable Communication",
        "authors": [
            "Apostolos I. Rikos",
            "Themistoklis Charalambous",
            "Karl H. Johansson"
        ],
        "comments": " ",
        "subjects": "Systems and Control (eess.SY)",
        "abstract": "In this paper, we present a novel distributed algorithm (herein called MaxCUCL) designed to guarantee that max-consensus is reached in networks characterized by unreliable communication links (i.e., links suffering from packet drops). Our proposed algorithm is the first algorithm that achieves max-consensus in a deterministic manner (i.e., nodes always calculate the maximum of their states regardless of the nature of the probability distribution of the packet drops). Furthermore, it allows nodes to determine whether convergence has been achieved (enabling them to transition to subsequent tasks). The operation of MaxCUCL relies on the deployment of narrowband error-free feedback channels used for acknowledging whether a packet transmission between nodes was successful. We analyze the operation of our algorithm and show that it converges after a finite number of time steps. Finally, we demonstrate our algorithm's effectiveness and practical applicability by applying it to a sensor network deployed for environmental monitoring.\n    ",
        "primary_category": "eess.SY",
        "categories": [],
        "submitted_date": "28 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18721": {
        "title": "A collocation method for nonlinear tensor differential equations on low-rank manifolds",
        "authors": [
            "Alec Dektor"
        ],
        "comments": "19 pages, 4 figures",
        "subjects": "Numerical Analysis (math.NA)",
        "abstract": "We present a new method to compute the solution to a nonlinear tensor differential equation with dynamical low-rank approximation. The idea of dynamical low-rank approximation is to project the differential equation onto the tangent space of a low-rank tensor manifold at each time. Traditionally, an orthogonal projection onto the tangent space is employed, which is challenging to compute for nonlinear differential equations. We introduce a novel interpolatory projection onto the tangent space that is easily computed for many nonlinear differential equations and satisfies the differential equation at a set of carefully selected indices. To select these indices, we devise a new algorithm based on the discrete empirical interpolation method (DEIM) that parameterizes any tensor train and its tangent space with tensor cross interpolants. We demonstrate the proposed method with applications to tensor differential equations arising from the discretization of partial differential equations.\n    ",
        "primary_category": "math.NA",
        "categories": [
            "physics.comp-ph"
        ],
        "submitted_date": "28 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18724": {
        "title": "Learning Associative Memories with Gradient Descent",
        "authors": [
            "Vivien Cabannes",
            "Berfin Simsek",
            "Alberto Bietti"
        ],
        "comments": " ",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "This work focuses on the training dynamics of one associative memory module storing outer products of token embeddings. We reduce this problem to the study of a system of particles, which interact according to properties of the data distribution and correlations between embeddings. Through theory and experiments, we provide several insights. In overparameterized regimes, we obtain logarithmic growth of the ``classification margins.'' Yet, we show that imbalance in token frequencies and memory interferences due to correlated embeddings lead to oscillatory transitory regimes. The oscillations are more pronounced with large step sizes, which can create benign loss spikes, although these learning rates speed up the dynamics and accelerate the asymptotic convergence. In underparameterized regimes, we illustrate how the cross-entropy loss can lead to suboptimal memorization schemes. Finally, we assess the validity of our findings on small Transformer models.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.AI",
            "stat.ML"
        ],
        "submitted_date": "28 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18726": {
        "title": "Unveiling Privacy, Memorization, and Input Curvature Links",
        "authors": [
            "Deepak Ravikumar",
            "Efstathia Soufleri",
            "Abolfazl Hashemi",
            "Kaushik Roy"
        ],
        "comments": " ",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Deep Neural Nets (DNNs) have become a pervasive tool for solving many emerging problems. However, they tend to overfit to and memorize the training set. Memorization is of keen interest since it is closely related to several concepts such as generalization, noisy learning, and privacy. To study memorization, Feldman (2019) proposed a formal score, however its computational requirements limit its practical use. Recent research has shown empirical evidence linking input loss curvature (measured by the trace of the loss Hessian w.r.t inputs) and memorization. It was shown to be ~3 orders of magnitude more efficient than calculating the memorization score. However, there is a lack of theoretical understanding linking memorization with input loss curvature. In this paper, we not only investigate this connection but also extend our analysis to establish theoretical links between differential privacy, memorization, and input loss curvature. First, we derive an upper bound on memorization characterized by both differential privacy and input loss curvature. Second, we present a novel insight showing that input loss curvature is upper-bounded by the differential privacy parameter. Our theoretical findings are further empirically validated using deep models on CIFAR and ImageNet datasets, showing a strong correlation between our theoretical predictions and results observed in practice.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.AI",
            "cs.CR"
        ],
        "submitted_date": "28 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18728": {
        "title": "Not All the Same: Understanding and Informing Similarity Estimation in Tile-Based Video Games",
        "authors": [
            "Sebastian Berns",
            "Vanessa Volz",
            "Laurissa Tokarchuk",
            "Sam Snodgrass",
            "Christian Guckelsberger"
        ],
        "comments": "Proceedings of the CHI Conference on Human Factors in Computing Systems (CHI '24), 11-16 May 2024, Honolulu, HI, USA",
        "subjects": "Human-Computer Interaction (cs.HC)",
        "abstract": "Similarity estimation is essential for many game AI applications, from the procedural generation of distinct assets to automated exploration with game-playing agents. While similarity metrics often substitute human evaluation, their alignment with our judgement is unclear. Consequently, the result of their application can fail human expectations, leading to e.g. unappreciated content or unbelievable agent behaviour. We alleviate this gap through a multi-factorial study of two tile-based games in two representations, where participants (N=456) judged the similarity of level triplets. Based on this data, we construct domain-specific perceptual spaces, encoding similarity-relevant attributes. We compare 12 metrics to these spaces and evaluate their approximation quality through several quantitative lenses. Moreover, we conduct a qualitative labelling study to identify the features underlying the human similarity judgement in this popular genre. Our findings inform the selection of existing metrics and highlight requirements for the design of new similarity metrics benefiting game development and research.\n    ",
        "primary_category": "cs.HC",
        "categories": [],
        "submitted_date": "28 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18729": {
        "title": "A Priori Uncertainty Quantification of Reacting Turbulence Closure Models using Bayesian Neural Networks",
        "authors": [
            "Graham Pash",
            "Malik Hassanaly",
            "Shashank Yellapantula"
        ],
        "comments": " ",
        "subjects": "Fluid Dynamics (physics.flu-dyn)",
        "abstract": "While many physics-based closure model forms have been posited for the sub-filter scale (SFS) in large eddy simulation (LES), vast amounts of data available from direct numerical simulation (DNS) create opportunities to leverage data-driven modeling techniques. Albeit flexible, data-driven models still depend on the dataset and the functional form of the model chosen. Increased adoption of such models requires reliable uncertainty estimates both in the data-informed and out-of-distribution regimes. In this work, we employ Bayesian neural networks (BNNs) to capture both epistemic and aleatoric uncertainties in a reacting flow model. In particular, we model the filtered progress variable scalar dissipation rate which plays a key role in the dynamics of turbulent premixed flames. We demonstrate that BNN models can provide unique insights about the structure of uncertainty of the data-driven closure models. We also propose a method for the incorporation of out-of-distribution information in a BNN. The efficacy of the model is demonstrated by a priori evaluation on a dataset consisting of a variety of flame conditions and fuels.\n    ",
        "primary_category": "physics.flu-dyn",
        "categories": [
            "cs.LG",
            "physics.data-an"
        ],
        "submitted_date": "28 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18732": {
        "title": "GAIA: Categorical Foundations of Generative AI",
        "authors": [
            "Sridhar Mahadevan"
        ],
        "comments": "65 pages. arXiv admin note: text overlap with arXiv:2212.08981",
        "subjects": "Artificial Intelligence (cs.AI)",
        "abstract": "In this paper, we propose GAIA, a generative AI architecture based on category theory. GAIA is based on a hierarchical model where modules are organized as a simplicial complex. Each simplicial complex updates its internal parameters biased on information it receives from its superior simplices and in turn relays updates to its subordinate sub-simplices. Parameter updates are formulated in terms of lifting diagrams over simplicial sets, where inner and outer horn extensions correspond to different types of learning problems. Backpropagation is modeled as an endofunctor over the category of parameters, leading to a coalgebraic formulation of deep learning.\n    ",
        "primary_category": "cs.AI",
        "categories": [
            "cs.LG"
        ],
        "submitted_date": "28 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18734": {
        "title": "Priority Sampling of Large Language Models for Compilers",
        "authors": [
            "Dejan Grubisic",
            "Chris Cummins",
            "Volker Seeker",
            "Hugh Leather"
        ],
        "comments": " ",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Large language models show great potential in generating and optimizing code. Widely used sampling methods such as Nucleus Sampling increase the diversity of generation but often produce repeated samples for low temperatures and incoherent samples for high temperatures. Furthermore, the temperature coefficient has to be tuned for each task, limiting its usability. We present Priority Sampling, a simple and deterministic sampling technique that produces unique samples ordered by the model's confidence. Each new sample expands the unexpanded token with the highest probability in the augmented search tree. Additionally, Priority Sampling supports generation based on regular expression that provides a controllable and structured exploration process. Priority Sampling outperforms Nucleus Sampling for any number of samples, boosting the performance of the original model from 2.87% to 5% improvement over -Oz. Moreover, it outperforms the autotuner used for the generation of labels for the training of the original model in just 30 samples.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.CL",
            "cs.PF"
        ],
        "submitted_date": "28 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18740": {
        "title": "Sixth-order parabolic equation on an interval: Eigenfunction expansion, Green's function, and intermediate asymptotics for a finite thin film with elastic resistance",
        "authors": [
            "Nectarios C. Papanicolaou",
            "Ivan C. Christov"
        ],
        "comments": "20 pages, 6 figures",
        "subjects": "Numerical Analysis (math.NA)",
        "abstract": "A linear sixth-order partial differential equation (PDE) of ``parabolic'' type describes the dynamics of thin liquid films beneath surfaces with elastic bending resistance when deflections from the equilibrium film height are small. On a finite domain, the associated sixth-order Sturm--Liouville eigenvalue value problem is self-adjoint for the boundary conditions corresponding to a thin film in a closed trough, and the eigenfunctions form a complete orthonormal set. Using these eigenfunctions, we derive the Green's function for the governing sixth-order PDE on a finite interval and compare it to the known infinite-line solution. Further, we propose a Galerkin spectral method based on the constructed sixth-order eigenfunctions and their derivative expansions. The system of ordinary differential equations for the time-dependent expansion coefficients is solved by standard numerical methods. The numerical approach is applied to versions of the governing PDE with a second-order derivative (in addition to the sixth-order one), which arises from gravity acting on the film. In the absence of gravity, we demonstrate the self-similar intermediate asymptotics of initially localized disturbances on the film surface, at least until the disturbances ``feel'' the finite boundaries, and show that the derived Green's function is the global attractor for such solutions. In the presence of gravity, we use the proposed spectral numerical method to demonstrate that self-similar behavior persists, albeit for shortened intervals of time, even for large values of the gravity-to-bending ratio.\n    ",
        "primary_category": "math.NA",
        "categories": [
            "physics.flu-dyn"
        ],
        "submitted_date": "28 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18742": {
        "title": "Comparing Importance Sampling Based Methods for Mitigating the Effect of Class Imbalance",
        "authors": [
            "Indu Panigrahi",
            "Richard Zhu"
        ],
        "comments": "Preprint",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Most state-of-the-art computer vision models heavily depend on data. However, many datasets exhibit extreme class imbalance which has been shown to negatively impact model performance. Among the training-time and data-generation solutions that have been explored, one subset that leverages existing data is importance sampling. A good deal of this work focuses primarily on the CIFAR-10 and CIFAR-100 datasets which fail to be representative of the scale, composition, and complexity of current state-of-the-art datasets. In this work, we explore and compare three techniques that derive from importance sampling: loss reweighting, undersampling, and oversampling. Specifically, we compare the effect of these techniques on the performance of two encoders on an impactful satellite imagery dataset, Planet's Amazon Rainforest dataset, in preparation for another work. Furthermore, we perform supplemental experimentation on a scene classification dataset, ADE20K, to test on a contrasting domain and clarify our results. Across both types of encoders, we find that up-weighting the loss for and undersampling has a negigible effect on the performance on underrepresented classes. Additionally, our results suggest oversampling generally improves performance for the same underrepresented classes. Interestingly, our findings also indicate that there may exist some redundancy in data in the Planet dataset. Our work aims to provide a foundation for further work on the Planet dataset and similar domain-specific datasets. We open-source our code at this https URL for future work on other satellite imagery datasets as well.\n    ",
        "primary_category": "cs.CV",
        "categories": [],
        "submitted_date": "28 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18743": {
        "title": "A revision on Multi-Criteria Decision Making methods for Multi-UAV Mission Planning Support",
        "authors": [
            "Cristian Ramirez-Atencia",
            "Victor Rodriguez-Fernandez",
            "David Camacho"
        ],
        "comments": "Preprint submitted and acepted in Expert Systems with Applications",
        "subjects": "Artificial Intelligence (cs.AI)",
        "abstract": "Over the last decade, Unmanned Aerial Vehicles (UAVs) have been extensively used in many commercial applications due to their manageability and risk avoidance. One of the main problems considered is the Mission Planning for multiple UAVs, where a solution plan must be found satisfying the different constraints of the problem. This problem has multiple variables that must be optimized simultaneously, such as the makespan, the cost of the mission or the risk. Therefore, the problem has a lot of possible optimal solutions, and the operator must select the final solution to be executed among them. In order to reduce the workload of the operator in this decision process, a Decision Support System (DSS) becomes necessary. In this work, a DSS consisting of ranking and filtering systems, which order and reduce the optimal solutions, has been designed. With regard to the ranking system, a wide range of Multi-Criteria Decision Making (MCDM) methods, including some fuzzy MCDM, are compared on a multi-UAV mission planning scenario, in order to study which method could fit better in a multi-UAV decision support system. Expert operators have evaluated the solutions returned, and the results show, on the one hand, that fuzzy methods generally achieve better average scores, and on the other, that all of the tested methods perform better when the preferences of the operators are biased towards a specific variable, and worse when their preferences are balanced. For the filtering system, a similarity function based on the proximity of the solutions has been designed, and on top of that, a threshold is tuned empirically to decide how to filter solutions without losing much of the hypervolume of the space of solutions.\n    ",
        "primary_category": "cs.AI",
        "categories": [
            "cs.RO"
        ],
        "submitted_date": "28 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18744": {
        "title": "Timer-Based Coverage Control for Mobile Sensors",
        "authors": [
            "Federico M. Zegers",
            "Sean Phillips",
            "Gregory P. Hicks"
        ],
        "comments": " ",
        "subjects": "Systems and Control (eess.SY)",
        "abstract": "This work studies the coverage control problem over a static, bounded, and convex workspace and develops a hybrid extension of the continuous-time Lloyd algorithm. Each agent in a multi-agent system (MAS) is equipped with a timer that generates intermittent sampling events, which may occur asynchronously between agents. At each sampling event, the corresponding agents update their controllers, which are otherwise held constant. These controllers are shown to drive the MAS into a neighborhood of the configurations corresponding to a centroidal Voronoi tessellation, that is, a local minimizer of the standard locational cost. The result is a distributed control strategy that leverages intermittent and asynchronous position measurements to disperse the agents within the workspace. The combination of continuous-time dynamics with intermittently updated control inputs is modeled as a hybrid system. The coverage control objective is posed as a set stabilization problem for hybrid systems, where an invariance based convergence analysis yields sufficient conditions that ensure all maximal solutions of the hybrid system asymptotically converge to a desired set. A brief simulation example is included to showcase the result.\n    ",
        "primary_category": "eess.SY",
        "categories": [],
        "submitted_date": "28 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18746": {
        "title": "Accelerating Computer Architecture Simulation through Machine Learning",
        "authors": [
            "Wajid Ali",
            "Ayaz Akram"
        ],
        "comments": " ",
        "subjects": "Hardware Architecture (cs.AR)",
        "abstract": "This paper presents our approach to accelerate computer architecture simulation by leveraging machine learning techniques. Traditional computer architecture simulations are time-consuming, making it challenging to explore different design choices efficiently. Our proposed model utilizes a combination of application features and micro-architectural features to predict the performance of an application. These features are derived from simulations of a small portion of the application. We demonstrate the effectiveness of our approach by building and evaluating a machine learning model that offers significant speedup in architectural exploration. This model demonstrates the ability to predict IPC values for the testing data with a root mean square error of less than 0.1.\n    ",
        "primary_category": "cs.AR",
        "categories": [
            "cs.LG"
        ],
        "submitted_date": "28 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18747": {
        "title": "Fine-Tuned Machine Translation Metrics Struggle in Unseen Domains",
        "authors": [
            "Vil\u00e9m Zouhar",
            "Shuoyang Ding",
            "Anna Currey",
            "Tatyana Badeka",
            "Jenyuan Wang",
            "Brian Thompson"
        ],
        "comments": " ",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "We introduce a new, extensive multidimensional quality metrics (MQM) annotated dataset covering 11 language pairs in the biomedical domain. We use this dataset to investigate whether machine translation (MT) metrics which are fine-tuned on human-generated MT quality judgements are robust to domain shifts between training and inference. We find that fine-tuned metrics exhibit a substantial performance drop in the unseen domain scenario relative to metrics that rely on the surface form, as well as pre-trained metrics which are not fine-tuned on MT quality judgments.\n    ",
        "primary_category": "cs.CL",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "28 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18749": {
        "title": "Weighted strategies to guide a multi-objective evolutionary algorithm for multi-UAV mission planning",
        "authors": [
            "Cristian Ramirez-Atencia",
            "Javier Del Ser",
            "David Camacho"
        ],
        "comments": "Preprint submitted and accepted in Swarm and Evolutionary Computation",
        "subjects": "Neural and Evolutionary Computing (cs.NE)",
        "abstract": "Management and mission planning over a swarm of unmanned aerial vehicle (UAV) remains to date as a challenging research trend in what regards to this particular type of aircrafts. These vehicles are controlled by a number of ground control station (GCS), from which they are commanded to cooperatively perform different tasks in specific geographic areas of interest. Mathematically the problem of coordinating and assigning tasks to a swarm of UAV can be modeled as a constraint satisfaction problem, whose complexity and multiple conflicting criteria has hitherto motivated the adoption of multi-objective solvers such as multi-objective evolutionary algorithm (MOEA). The encoding approach consists of different alleles representing the decision variables, whereas the fitness function checks that all constraints are fulfilled, minimizing the optimization criteria of the problem. In problems of high complexity involving several tasks, UAV and GCS, where the space of search is huge compared to the space of valid solutions, the convergence rate of the algorithm increases significantly. To overcome this issue, this work proposes a weighted random generator for the creation and mutation of new individuals. The main objective of this work is to reduce the convergence rate of the MOEA solver for multi-UAV mission planning using weighted random strategies that focus the search on potentially better regions of the solution space. Extensive experimental results over a diverse range of scenarios evince the benefits of the proposed approach, which notably improves this convergence rate with respect to a na\u00efve MOEA approach.\n    ",
        "primary_category": "cs.NE",
        "categories": [],
        "submitted_date": "28 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18751": {
        "title": "Multi-Sensor and Multi-temporal High-Throughput Phenotyping for Monitoring and Early Detection of Water-Limiting Stress in Soybean",
        "authors": [
            "Sarah E. Jones",
            "Timilehin Ayanlade",
            "Benjamin Fallen",
            "Talukder Z. Jubery",
            "Arti Singh",
            "Baskar Ganapathysubramanian",
            "Soumik Sarkar",
            "Asheesh K. Singh"
        ],
        "comments": "25 pages, 5 figures",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Soybean production is susceptible to biotic and abiotic stresses, exacerbated by extreme weather events. Water limiting stress, i.e. drought, emerges as a significant risk for soybean production, underscoring the need for advancements in stress monitoring for crop breeding and production. This project combines multi-modal information to identify the most effective and efficient automated methods to investigate drought response. We investigated a set of diverse soybean accessions using multiple sensors in a time series high-throughput phenotyping manner to: (1) develop a pipeline for rapid classification of soybean drought stress symptoms, and (2) investigate methods for early detection of drought stress. We utilized high-throughput time-series phenotyping using UAVs and sensors in conjunction with machine learning (ML) analytics, which offered a swift and efficient means of phenotyping. The red-edge and green bands were most effective to classify canopy wilting stress. The Red-Edge Chlorophyll Vegetation Index (RECI) successfully differentiated susceptible and tolerant soybean accessions prior to visual symptom development. We report pre-visual detection of soybean wilting using a combination of different vegetation indices. These results can contribute to early stress detection methodologies and rapid classification of drought responses in screening nurseries for breeding and production applications.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.CV"
        ],
        "submitted_date": "28 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18752": {
        "title": "Pre-training Differentially Private Models with Limited Public Data",
        "authors": [
            "Zhiqi Bu",
            "Xinwei Zhang",
            "Mingyi Hong",
            "Sheng Zha",
            "George Karypis"
        ],
        "comments": " ",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "The superior performance of large foundation models relies on the use of massive amounts of high-quality data, which often contain sensitive, private and copyrighted material that requires formal protection. While differential privacy (DP) is a prominent method to gauge the degree of security provided to the models, its application is commonly limited to the model fine-tuning stage, due to the performance degradation when applying DP during the pre-training stage. Consequently, DP is yet not capable of protecting a substantial portion of the data used during the initial pre-training process.\nIn this work, we first provide a theoretical understanding of the efficacy of DP training by analyzing the per-iteration loss improvement. We make a key observation that DP optimizers' performance degradation can be significantly mitigated by the use of limited public data, which leads to a novel DP continual pre-training strategy. Empirically, using only 10\\% of public data, our strategy can achieve DP accuracy of 41.5\\% on ImageNet-21k (with $\\epsilon=8$), as well as non-DP accuracy of 55.7\\% and and 60.0\\% on downstream tasks Places365 and iNaturalist-2021, respectively, on par with state-of-the-art standard pre-training and substantially outperforming existing DP pre-trained models.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.CR"
        ],
        "submitted_date": "28 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18753": {
        "title": "Like-minded, like-bodied: How users (18-26) trust online eating and health information",
        "authors": [
            "Rachel Xu",
            "Nhu Le",
            "Rebekah Park",
            "Laura Murray"
        ],
        "comments": "10 pages",
        "subjects": "Human-Computer Interaction (cs.HC)",
        "abstract": "This paper investigates the relationship between social media and eating practices amongst 42 internet users aged 18-26. We conducted an ethnography in the US and India to observe how they navigated eating and health information online. We found that participants portrayed themselves online through a vocabulary we have labeled \"the good life\": performing holistic health by displaying a socially-ideal body. In doing so, participants unconsciously engaged in behaviors of disordered eating while actively eschewing them. They also valued personal testimonies, and readily tested tips from content creators who shared similar beliefs and bodies to them. In doing so, they discarded probabilistic thinking and opened themselves to harm. Our study found that their social media feeds did not unidirectionally influence participants - they also reflected participants' internalized views of health, in an intertwined, non-linear journey. Reducing the online spread of disordered eating practices requires addressing it within young people's social context.\n    ",
        "primary_category": "cs.HC",
        "categories": [
            "cs.CY",
            "cs.SI"
        ],
        "submitted_date": "28 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18754": {
        "title": "Extending QGroundControl for Automated Mission Planning of UAVs",
        "authors": [
            "Cristian Ramirez-Atencia",
            "David Camacho"
        ],
        "comments": "Preprint submitted and accepted in Sensors",
        "subjects": "Robotics (cs.RO)",
        "abstract": "Unmanned Aerial Vehicle (UAVs) have become very popular in the last decade due to some advantages such as strong terrain adaptation, low cost, zero casualties, and so on. One of the most interesting advances in this field is the automation of mission planning (task allocation) and real-time replanning, which are highly useful to increase the autonomy of the vehicle and reduce the operator workload. These automated mission planning and replanning systems require a Human Computer Interface (HCI) that facilitates the visualization and selection of plans that will be executed by the vehicles. In addition, most missions should be assessed before their real-life execution. This paper extends QGroundControl, an open-source simulation environment for flight control of multiple vehicles, by adding a mission designer that permits the operator to build complex missions with tasks and other scenario items; an interface for automated mission planning and replanning, which works as a test bed for different algorithms, and a Decision Support System (DSS) that helps the operator in the selection of the plan. In this work, a complete guide of these systems and some practical use cases are provided.\n    ",
        "primary_category": "cs.RO",
        "categories": [
            "cs.HC"
        ],
        "submitted_date": "28 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18755": {
        "title": "On Defeating Graph Analysis of Anonymous Transactions",
        "authors": [
            "Christoph Egger",
            "Russell W. F. Lai",
            "Viktoria Ronge",
            "Ivy K. Y. Woo",
            "Hoover H. F. Yin"
        ],
        "comments": " ",
        "subjects": "Cryptography and Security (cs.CR)",
        "abstract": "In a ring-signature-based anonymous cryptocurrency, signers of a transaction are hidden among a set of potential signers, called a ring, whose size is much smaller than the number of all users. The ring-membership relations specified by the sets of transactions thus induce bipartite transaction graphs, whose distribution is in turn induced by the ring sampler underlying the cryptocurrency.\nSince efficient graph analysis could be performed on transaction graphs to potentially deanonymise signers, it is crucial to understand the resistance of (the transaction graphs induced by) a ring sampler against graph analysis. Of particular interest is the class of partitioning ring samplers. Although previous works showed that they provide almost optimal local anonymity, their resistance against global, e.g. graph-based, attacks were unclear.\nIn this work, we analyse transaction graphs induced by partitioning ring samplers. Specifically, we show (partly analytically and partly empirically) that, somewhat surprisingly, by setting the ring size to be at least logarithmic in the number of users, a graph-analysing adversary is no better than the one that performs random guessing in deanonymisation up to constant factor of 2.\n    ",
        "primary_category": "cs.CR",
        "categories": [],
        "submitted_date": "28 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18756": {
        "title": "How Much Annotation is Needed to Compare Summarization Models?",
        "authors": [
            "Chantal Shaib",
            "Joe Barrow",
            "Alexa F. Siu",
            "Byron C. Wallace",
            "Ani Nenkova"
        ],
        "comments": "Preprint",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "Modern instruction-tuned models have become highly capable in text generation tasks such as summarization, and are expected to be released at a steady pace. In practice one may now wish to choose confidently, but with minimal effort, the best performing summarization model when applied to a new domain or purpose. In this work, we empirically investigate the test sample size necessary to select a preferred model in the context of news summarization. Empirical results reveal that comparative evaluation converges quickly for both automatic and human evaluation, with clear preferences for a system emerging from under 100 examples. The human preference data allows us to quantify how well automatic scores can reproduce preference rankings across a variety of downstream summarization tasks. We find that, while automatic metrics are stable at smaller sample sizes, only some automatic metrics are able to moderately predict model win rates according to human preference.\n    ",
        "primary_category": "cs.CL",
        "categories": [],
        "submitted_date": "28 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18758": {
        "title": "Analog Isolated Multilevel Quantizer for Voltage Sensing while Maintaining Galvanic Isolation",
        "authors": [
            "Peter Weber",
            "Antonia Papandreou-Suppappola"
        ],
        "comments": "8 pages, 12 Figures",
        "subjects": "Signal Processing (eess.SP)",
        "abstract": "A low-power, compact device for performing measurements in electrical systems with isolated voltage domains is proposed. Isolated measurements are required in numerous applications. For instance, a measurement of the bus voltage for a system with a high supply voltage and lower isolated local voltage level may be needed for system health monitoring and control. Such a requirement may necessitate the use of isolation amplifiers to provide voltage telemetry for the local system. Isolation amplifiers require dual galvanically isolated supplies and use magnetic, capacitive, or optical barriers between primary and secondary sides. Producing this supplemental voltage requires an extra voltage converter, which consumes power and generates electromagnetic interference which must, in turn, be filtered. Complex designs incorporating feedback are needed to achieve linear response. The proposed Analog Isolated Multilevel Quantizer (AIMQ) addresses these issues by monitoring the primary-side signal and communicating the results to the secondary side using a novel scheme involving Zener diodes, optocouplers, transistors, one-hot coding, and discrete outputs. The result is a low power isolated transducer that can in principle be extended to an arbitrary bit depth.\n    ",
        "primary_category": "eess.SP",
        "categories": [
            "eess.SY"
        ],
        "submitted_date": "28 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18761": {
        "title": "Exploration of Learned Lifting-Based Transform Structures for Fully Scalable and Accessible Wavelet-Like Image Compression",
        "authors": [
            "Xinyue Li",
            "Aous Naman",
            "David Taubman"
        ],
        "comments": "This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible",
        "subjects": "Image and Video Processing (eess.IV)",
        "abstract": "This paper provides a comprehensive study on features and performance of different ways to incorporate neural networks into lifting-based wavelet-like transforms, within the context of fully scalable and accessible image compression. Specifically, we explore different arrangements of lifting steps, as well as various network architectures for learned lifting operators. Moreover, we examine the impact of the number of learned lifting steps, the number of channels, the number of layers and the support of kernels in each learned lifting operator. To facilitate the study, we investigate two generic training methodologies that are simultaneously appropriate to a wide variety of lifting structures considered. Experimental results ultimately suggest that retaining fixed lifting steps from the base wavelet transform is highly beneficial. Moreover, we demonstrate that employing more learned lifting steps and more layers in each learned lifting operator do not contribute strongly to the compression performance. However, benefits can be obtained by utilizing more channels in each learned lifting operator. Ultimately, the learned wavelet-like transform proposed in this paper achieves over 25% bit-rate savings compared to JPEG 2000 with compact spatial support.\n    ",
        "primary_category": "eess.IV",
        "categories": [
            "cs.CV",
            "cs.MM"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18762": {
        "title": "Disentangling the Causes of Plasticity Loss in Neural Networks",
        "authors": [
            "Clare Lyle",
            "Zeyu Zheng",
            "Khimya Khetarpal",
            "Hado van Hasselt",
            "Razvan Pascanu",
            "James Martens",
            "Will Dabney"
        ],
        "comments": " ",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Underpinning the past decades of work on the design, initialization, and optimization of neural networks is a seemingly innocuous assumption: that the network is trained on a \\textit{stationary} data distribution. In settings where this assumption is violated, e.g.\\ deep reinforcement learning, learning algorithms become unstable and brittle with respect to hyperparameters and even random seeds. One factor driving this instability is the loss of plasticity, meaning that updating the network's predictions in response to new information becomes more difficult as training progresses. While many recent works provide analyses and partial solutions to this phenomenon, a fundamental question remains unanswered: to what extent do known mechanisms of plasticity loss overlap, and how can mitigation strategies be combined to best maintain the trainability of a network? This paper addresses these questions, showing that loss of plasticity can be decomposed into multiple independent mechanisms and that, while intervening on any single mechanism is insufficient to avoid the loss of plasticity in all cases, intervening on multiple mechanisms in conjunction results in highly robust learning algorithms. We show that a combination of layer normalization and weight decay is highly effective at maintaining plasticity in a variety of synthetic nonstationary learning tasks, and further demonstrate its effectiveness on naturally arising nonstationarities, including reinforcement learning in the Arcade Learning Environment.\n    ",
        "primary_category": "cs.LG",
        "categories": [],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18769": {
        "title": "CoMeT: Count-Min-Sketch-based Row Tracking to Mitigate RowHammer at Low Cost",
        "authors": [
            "F. Nisa Bostanci",
            "Ismail Emir Yuksel",
            "Ataberk Olgun",
            "Konstantinos Kanellopoulos",
            "Yahya Can Tugrul",
            "A. Giray Yaglikci",
            "Mohammad Sadrosadati",
            "Onur Mutlu"
        ],
        "comments": "To appear at HPCA 2024",
        "subjects": "Cryptography and Security (cs.CR)",
        "abstract": "We propose a new RowHammer mitigation mechanism, CoMeT, that prevents RowHammer bitflips with low area, performance, and energy costs in DRAM-based systems at very low RowHammer thresholds. The key idea of CoMeT is to use low-cost and scalable hash-based counters to track DRAM row activations. CoMeT uses the Count-Min Sketch technique that maps each DRAM row to a group of counters, as uniquely as possible, using multiple hash functions. When a DRAM row is activated, CoMeT increments the counters mapped to that DRAM row. Because the mapping from DRAM rows to counters is not completely unique, activating one row can increment one or more counters mapped to another row. Thus, CoMeT may overestimate, but never underestimates, a DRAM row's activation count. This property of CoMeT allows it to securely prevent RowHammer bitflips while properly configuring its hash functions reduces overestimations. As a result, CoMeT 1) implements substantially fewer counters than the number of DRAM rows in a DRAM bank and 2) does not significantly overestimate a DRAM row's activation count.\nOur comprehensive evaluations show that CoMeT prevents RowHammer bitflips with an average performance overhead of only 4.01% across 61 benign single-core workloads for a very low RowHammer threshold of 125, normalized to a system with no RowHammer mitigation. CoMeT achieves a good trade-off between performance, energy, and area overheads. Compared to the best-performing state-of-the-art mitigation, CoMeT requires 74.2x less area overhead at the RowHammer threshold 125 and incurs a small performance overhead on average for all RowHammer thresholds. Compared to the best-performing low-area-cost mechanism, at a very low RowHammer threshold of 125, CoMeT improves performance by up to 39.1% while incurring a similar area overhead. CoMeT is openly and freely available at this https URL.\n    ",
        "primary_category": "cs.CR",
        "categories": [
            "cs.AR"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18775": {
        "title": "How to Evaluate Human-likeness of Interaction-aware Driver Models",
        "authors": [
            "Jemin Woo",
            "Changsun Ahn"
        ],
        "comments": "This paper could benefit from further refinement to enhance the significance of its results",
        "subjects": "Robotics (cs.RO)",
        "abstract": "This study proposes a method for qualitatively evaluating and designing human-like driver models for autonomous vehicles. While most existing research on human-likeness has been focused on quantitative evaluation, it is crucial to consider qualitative measures to accurately capture human perception. To this end, we conducted surveys utilizing both video study and human experience-based study. The findings of this research can significantly contribute to the development of naturalistic and human-like driver models for autonomous vehicles, enabling them to safely and efficiently coexist with human-driven vehicles in diverse driving scenarios.\n    ",
        "primary_category": "cs.RO",
        "categories": [
            "eess.SY"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18777": {
        "title": "GDCNet: Calibrationless geometric distortion correction of echo planar imaging data using deep learning",
        "authors": [
            "Marina Manso Jimeno",
            "Keren Bachi",
            "George Gardner",
            "Yasmin L. Hurd",
            "John Thomas Vaughan Jr.",
            "Sairam Geethanath"
        ],
        "comments": "30 pages, 9 figures, 3 tables",
        "subjects": "Image and Video Processing (eess.IV)",
        "abstract": "Functional magnetic resonance imaging techniques benefit from echo-planar imaging's fast image acquisition but are susceptible to inhomogeneities in the main magnetic field, resulting in geometric distortion and signal loss artifacts in the images. Traditional methods leverage a field map or voxel displacement map for distortion correction. However, voxel displacement map estimation requires additional sequence acquisitions, and the accuracy of the estimation influences correction performance. This work implements a novel approach called GDCNet, which estimates a geometric distortion map by non-linear registration to T1-weighted anatomical images and applies it for distortion correction. GDCNet demonstrated fast distortion correction of functional images in retrospectively and prospectively acquired datasets. Among the compared models, the 2D self-supervised configuration resulted in a statistically significant improvement to normalized mutual information between distortion-corrected functional and T1-weighted images compared to the benchmark methods FUGUE and TOPUP. Furthermore, GDCNet models achieved processing speeds 14 times faster than TOPUP in the prospective dataset.\n    ",
        "primary_category": "eess.IV",
        "categories": [
            "cs.CV"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18780": {
        "title": "A Quantitative Evaluation of Score Distillation Sampling Based Text-to-3D",
        "authors": [
            "Xiaohan Fei",
            "Chethan Parameshwara",
            "Jiawei Mo",
            "Xiaolong Li",
            "Ashwin Swaminathan",
            "CJ Taylor",
            "Paolo Favaro",
            "Stefano Soatto"
        ],
        "comments": " ",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "The development of generative models that create 3D content from a text prompt has made considerable strides thanks to the use of the score distillation sampling (SDS) method on pre-trained diffusion models for image generation. However, the SDS method is also the source of several artifacts, such as the Janus problem, the misalignment between the text prompt and the generated 3D model, and 3D model inaccuracies. While existing methods heavily rely on the qualitative assessment of these artifacts through visual inspection of a limited set of samples, in this work we propose more objective quantitative evaluation metrics, which we cross-validate via human ratings, and show analysis of the failure cases of the SDS technique. We demonstrate the effectiveness of this analysis by designing a novel computationally efficient baseline model that achieves state-of-the-art performance on the proposed metrics while addressing all the above-mentioned artifacts.\n    ",
        "primary_category": "cs.CV",
        "categories": [],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18784": {
        "title": "Brain-inspired and Self-based Artificial Intelligence",
        "authors": [
            "Yi Zeng",
            "Feifei Zhao",
            "Yuxuan Zhao",
            "Dongcheng Zhao",
            "Enmeng Lu",
            "Qian Zhang",
            "Yuwei Wang",
            "Hui Feng",
            "Zhuoya Zhao",
            "Jihang Wang",
            "Qingqun Kong",
            "Yinqian Sun",
            "Yang Li",
            "Guobin Shen",
            "Bing Han",
            "Yiting Dong",
            "Wenxuan Pan",
            "Xiang He",
            "Aorigele Bao",
            "Jin Wang"
        ],
        "comments": " ",
        "subjects": "Artificial Intelligence (cs.AI)",
        "abstract": "The question \"Can machines think?\" and the Turing Test to assess whether machines could achieve human-level intelligence is one of the roots of AI. With the philosophical argument \"I think, therefore I am\", this paper challenge the idea of a \"thinking machine\" supported by current AIs since there is no sense of self in them. Current artificial intelligence is only seemingly intelligent information processing and does not truly understand or be subjectively aware of oneself and perceive the world with the self as human intelligence does. In this paper, we introduce a Brain-inspired and Self-based Artificial Intelligence (BriSe AI) paradigm. This BriSe AI paradigm is dedicated to coordinating various cognitive functions and learning strategies in a self-organized manner to build human-level AI models and robotic applications. Specifically, BriSe AI emphasizes the crucial role of the Self in shaping the future AI, rooted with a practical hierarchical Self framework, including Perception and Learning, Bodily Self, Autonomous Self, Social Self, and Conceptual Self. The hierarchical framework of the Self highlights self-based environment perception, self-bodily modeling, autonomous interaction with the environment, social interaction and collaboration with others, and even more abstract understanding of the Self. Furthermore, the positive mutual promotion and support among multiple levels of Self, as well as between Self and learning, enhance the BriSe AI's conscious understanding of information and flexible adaptation to complex environments, serving as a driving force propelling BriSe AI towards real Artificial General Intelligence.\n    ",
        "primary_category": "cs.AI",
        "categories": [
            "q-bio.NC"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18786": {
        "title": "OpticalDR: A Deep Optical Imaging Model for Privacy-Protective Depression Recognition",
        "authors": [
            "Yuchen Pan",
            "Junjun Jiang",
            "Kui Jiang",
            "Zhihao Wu",
            "Keyuan Yu",
            "Xianming Liu"
        ],
        "comments": "Accepted by CVPR 2024",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Depression Recognition (DR) poses a considerable challenge, especially in the context of the growing concerns surrounding privacy. Traditional automatic diagnosis of DR technology necessitates the use of facial images, undoubtedly expose the patient identity features and poses privacy risks. In order to mitigate the potential risks associated with the inappropriate disclosure of patient facial images, we design a new imaging system to erase the identity information of captured facial images while retain disease-relevant features. It is irreversible for identity information recovery while preserving essential disease-related characteristics necessary for accurate DR. More specifically, we try to record a de-identified facial image (erasing the identifiable features as much as possible) by a learnable lens, which is optimized in conjunction with the following DR task as well as a range of face analysis related auxiliary tasks in an end-to-end manner. These aforementioned strategies form our final Optical deep Depression Recognition network (OpticalDR). Experiments on CelebA, AVEC 2013, and AVEC 2014 datasets demonstrate that our OpticalDR has achieved state-of-the-art privacy protection performance with an average AUC of 0.51 on popular facial recognition models, and competitive results for DR with MAE/RMSE of 7.53/8.48 on AVEC 2013 and 7.89/8.82 on AVEC 2014, respectively.\n    ",
        "primary_category": "cs.CV",
        "categories": [],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18787": {
        "title": "Enhancing the \"Immunity\" of Mixture-of-Experts Networks for Adversarial Defense",
        "authors": [
            "Qiao Han",
            "yong huang",
            "xinling Guo",
            "Yiteng Zhai",
            "Yu Qin",
            "Yao Yang"
        ],
        "comments": " ",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Recent studies have revealed the vulnerability of Deep Neural Networks (DNNs) to adversarial examples, which can easily fool DNNs into making incorrect predictions. To mitigate this deficiency, we propose a novel adversarial defense method called \"Immunity\" (Innovative MoE with MUtual information \\& positioN stabilITY) based on a modified Mixture-of-Experts (MoE) architecture in this work. The key enhancements to the standard MoE are two-fold: 1) integrating of Random Switch Gates (RSGs) to obtain diverse network structures via random permutation of RSG parameters at evaluation time, despite of RSGs being determined after one-time training; 2) devising innovative Mutual Information (MI)-based and Position Stability-based loss functions by capitalizing on Grad-CAM's explanatory power to increase the diversity and the causality of expert networks. Notably, our MI-based loss operates directly on the heatmaps, thereby inducing subtler negative impacts on the classification performance when compared to other losses of the same type, theoretically. Extensive evaluation validates the efficacy of the proposed approach in improving adversarial robustness against a wide range of attacks.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.CR"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18789": {
        "title": "FlexLLM: A System for Co-Serving Large Language Model Inference and Parameter-Efficient Finetuning",
        "authors": [
            "Xupeng Miao",
            "Gabriele Oliaro",
            "Xinhao Cheng",
            "Mengdi Wu",
            "Colin Unger",
            "Zhihao Jia"
        ],
        "comments": " ",
        "subjects": "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "abstract": "Parameter-efficient finetuning (PEFT) is a widely used technique to adapt large language models for different tasks. Service providers typically create separate systems for users to perform PEFT model finetuning and inference tasks. This is because existing systems cannot handle workloads that include a mix of inference and PEFT finetuning requests. As a result, shared GPU resources are underutilized, leading to inefficiencies. To address this problem, we present FlexLLM, the first system that can serve inference and parameter-efficient finetuning requests in the same iteration. Our system leverages the complementary nature of these two tasks and utilizes shared GPU resources to run them jointly, using a method called co-serving. To achieve this, FlexLLM introduces a novel token-level finetuning mechanism, which breaks down the finetuning computation of a sequence into smaller token-level computations and uses dependent parallelization and graph pruning, two static compilation optimizations, to minimize the memory overhead and latency for co-serving. Compared to existing systems, FlexLLM's co-serving approach reduces the activation GPU memory overhead by up to 8x, and the end-to-end GPU memory requirement of finetuning by up to 36% while maintaining a low inference latency and improving finetuning throughput. For example, under a heavy inference workload, FlexLLM can still preserve more than 80% of the peak finetuning throughput, whereas existing systems cannot make any progress with finetuning. The source code of FlexLLM is publicly available at this https URL.\n    ",
        "primary_category": "cs.DC",
        "categories": [
            "cs.CL",
            "cs.LG"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18790": {
        "title": "The Power of Unentangled Quantum Proofs with Non-negative Amplitudes",
        "authors": [
            "Fernando Granha Jeronimo",
            "Pei Wu"
        ],
        "comments": "64 pages",
        "subjects": "Quantum Physics (quant-ph)",
        "abstract": "Quantum entanglement is a fundamental property of quantum mechanics and plays a crucial role in quantum computation and information. We study entanglement via the lens of computational complexity by considering quantum generalizations of the class NP with multiple unentangled quantum proofs, the so-called QMA(2) and its variants. The complexity of QMA(2) is a longstanding open problem, and only the trivial bounds QMA $\\subseteq$ QMA(2) $\\subseteq$ NEXP are known.\nIn this work, we study the power of unentangled quantum proofs with non-negative amplitudes, a class which we denote $\\text{QMA}^+(2)$. In this setting, we are able to design proof verification protocols for problems both using logarithmic size quantum proofs and having a constant probability gap in distinguishing yes from no instances. In particular, we design global protocols for small set expansion, unique games, and PCP verification. As a consequence, we obtain NP $\\subseteq \\text{QMA}^+_{\\log}(2)$ with a constant gap. By virtue of the new constant gap, we are able to ``scale up'' this result to $\\text{QMA}^+(2)$, obtaining the full characterization $\\text{QMA}^+(2)$=NEXP by establishing stronger explicitness properties of the PCP for NEXP.\nOne key novelty of these protocols is the manipulation of quantum proofs in a global and coherent way yielding constant gaps. Previous protocols (only available for general amplitudes) are either local having vanishingly small gaps or treat the quantum proofs as classical probability distributions requiring polynomially many proofs thereby not implying non-trivial bounds on QMA(2).\nFinally, we show that QMA(2) is equal to $\\text{QMA}^+(2)$ provided the gap of the latter is a sufficiently large constant. In particular, if $\\text{QMA}^+(2)$ admits gap amplification, then QMA(2)=NEXP.\n    ",
        "primary_category": "quant-ph",
        "categories": [
            "cs.CC"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18792": {
        "title": "MPAT: Building Robust Deep Neural Networks against Textual Adversarial Attacks",
        "authors": [
            "Fangyuan Zhang",
            "Huichi Zhou",
            "Shuangjiao Li",
            "Hongtao Wang"
        ],
        "comments": " ",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Deep neural networks have been proven to be vulnerable to adversarial examples and various methods have been proposed to defend against adversarial attacks for natural language processing tasks. However, previous defense methods have limitations in maintaining effective defense while ensuring the performance of the original task. In this paper, we propose a malicious perturbation based adversarial training method (MPAT) for building robust deep neural networks against textual adversarial attacks. Specifically, we construct a multi-level malicious example generation strategy to generate adversarial examples with malicious perturbations, which are used instead of original inputs for model training. Additionally, we employ a novel training objective function to ensure achieving the defense goal without compromising the performance on the original task. We conduct comprehensive experiments to evaluate our defense method by attacking five victim models on three benchmark datasets. The result demonstrates that our method is more effective against malicious adversarial attacks compared with previous defense methods while maintaining or further improving the performance on the original task.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.CL",
            "cs.CR"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18796": {
        "title": "MOSAIC: A Modular System for Assistive and Interactive Cooking",
        "authors": [
            "Huaxiaoyue Wang",
            "Kushal Kedia",
            "Juntao Ren",
            "Rahma Abdullah",
            "Atiksh Bhardwaj",
            "Angela Chao",
            "Kelly Y Chen",
            "Nathaniel Chin",
            "Prithwish Dan",
            "Xinyi Fan",
            "Gonzalo Gonzalez-Pumariega",
            "Aditya Kompella",
            "Maximus Adrian Pace",
            "Yash Sharma",
            "Xiangwan Sun",
            "Neha Sunkara",
            "Sanjiban Choudhury"
        ],
        "comments": "22 pages, 13 figures",
        "subjects": "Robotics (cs.RO)",
        "abstract": "We present MOSAIC, a modular architecture for home robots to perform complex collaborative tasks, such as cooking with everyday users. MOSAIC tightly collaborates with humans, interacts with users using natural language, coordinates multiple robots, and manages an open vocabulary of everyday objects. At its core, MOSAIC employs modularity: it leverages multiple large-scale pre-trained models for general tasks like language and image recognition, while using streamlined modules designed for task-specific control. We extensively evaluate MOSAIC on 60 end-to-end trials where two robots collaborate with a human user to cook a combination of 6 recipes. We also extensively test individual modules with 180 episodes of visuomotor picking, 60 episodes of human motion forecasting, and 46 online user evaluations of the task planner. We show that MOSAIC is able to efficiently collaborate with humans by running the overall system end-to-end with a real human user, completing 68.3% (41/60) collaborative cooking trials of 6 different recipes with a subtask completion rate of 91.6%. Finally, we discuss the limitations of the current system and exciting open challenges in this domain. The project's website is at this https URL\n",
        "primary_category": "cs.RO",
        "categories": [],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18797": {
        "title": "ARTiST: Automated Text Simplification for Task Guidance in Augmented Reality",
        "authors": [
            "Guande Wu",
            "Jing Qian",
            "Sonia Castelo",
            "Shaoyu Chen",
            "Joao Rulff",
            "Claudio Silva"
        ],
        "comments": "Conditionally accepted by CHI '24",
        "subjects": "Human-Computer Interaction (cs.HC)",
        "abstract": "Text presented in augmented reality provides in-situ, real-time information for users. However, this content can be challenging to apprehend quickly when engaging in cognitively demanding AR tasks, especially when it is presented on a head-mounted display. We propose ARTiST, an automatic text simplification system that uses a few-shot prompt and GPT-3 models to specifically optimize the text length and semantic content for augmented reality. Developed out of a formative study that included seven users and three experts, our system combines a customized error calibration model with a few-shot prompt to integrate the syntactic, lexical, elaborative, and content simplification techniques, and generate simplified AR text for head-worn displays. Results from a 16-user empirical study showed that ARTiST lightens the cognitive load and improves performance significantly over both unmodified text and text modified via traditional methods. Our work constitutes a step towards automating the optimization of batch text data for readability and performance in augmented reality.\n    ",
        "primary_category": "cs.HC",
        "categories": [
            "cs.CL"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18800": {
        "title": "BlockEcho: Retaining Long-Range Dependencies for Imputing Block-Wise Missing Data",
        "authors": [
            "Qiao Han",
            "Mingqian Li",
            "Yao Yang",
            "Yiteng Zhai"
        ],
        "comments": " ",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Block-wise missing data poses significant challenges in real-world data imputation tasks. Compared to scattered missing data, block-wise gaps exacerbate adverse effects on subsequent analytic and machine learning tasks, as the lack of local neighboring elements significantly reduces the interpolation capability and predictive power. However, this issue has not received adequate attention. Most SOTA matrix completion methods appeared less effective, primarily due to overreliance on neighboring elements for predictions. We systematically analyze the issue and propose a novel matrix completion method ``BlockEcho\" for a more comprehensive solution. This method creatively integrates Matrix Factorization (MF) within Generative Adversarial Networks (GAN) to explicitly retain long-distance inter-element relationships in the original matrix. Besides, we incorporate an additional discriminator for GAN, comparing the generator's intermediate progress with pre-trained MF results to constrain high-order feature distributions. Subsequently, we evaluate BlockEcho on public datasets across three domains. Results demonstrate superior performance over both traditional and SOTA methods when imputing block-wise missing data, especially at higher missing rates. The advantage also holds for scattered missing data at high missing rates. We also contribute on the analyses in providing theoretical justification on the optimality and convergence of fusing MF and GAN for missing block data.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "stat.ML"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18803": {
        "title": "To Pool or Not To Pool: Analyzing the Regularizing Effects of Group-Fair Training on Shared Models",
        "authors": [
            "Cyrus Cousins",
            "I. Elizabeth Kumar",
            "Suresh Venkatasubramanian"
        ],
        "comments": " ",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "In fair machine learning, one source of performance disparities between groups is over-fitting to groups with relatively few training samples. We derive group-specific bounds on the generalization error of welfare-centric fair machine learning that benefit from the larger sample size of the majority group. We do this by considering group-specific Rademacher averages over a restricted hypothesis class, which contains the family of models likely to perform well with respect to a fair learning objective (e.g., a power-mean). Our simulations demonstrate these bounds improve over a naive method, as expected by theory, with particularly significant improvement for smaller group sizes.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.CY"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18805": {
        "title": "VEC-SBM: Optimal Community Detection with Vectorial Edges Covariates",
        "authors": [
            "Guillaume Braun",
            "Masashi Sugiyama"
        ],
        "comments": " ",
        "subjects": "Social and Information Networks (cs.SI)",
        "abstract": "Social networks are often associated with rich side information, such as texts and images. While numerous methods have been developed to identify communities from pairwise interactions, they usually ignore such side information. In this work, we study an extension of the Stochastic Block Model (SBM), a widely used statistical framework for community detection, that integrates vectorial edges covariates: the Vectorial Edges Covariates Stochastic Block Model (VEC-SBM). We propose a novel algorithm based on iterative refinement techniques and show that it optimally recovers the latent communities under the VEC-SBM. Furthermore, we rigorously assess the added value of leveraging edge's side information in the community detection process. We complement our theoretical results with numerical experiments on synthetic and semi-synthetic data.\n    ",
        "primary_category": "cs.SI",
        "categories": [
            "stat.ML"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18807": {
        "title": "On the Decision-Making Abilities in Role-Playing using Large Language Models",
        "authors": [
            "Chenglei Shen",
            "Guofu Xie",
            "Xiao Zhang",
            "Jun Xu"
        ],
        "comments": " ",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "Large language models (LLMs) are now increasingly utilized for role-playing tasks, especially in impersonating domain-specific experts, primarily through role-playing prompts. When interacting in real-world scenarios, the decision-making abilities of a role significantly shape its behavioral patterns. In this paper, we concentrate on evaluating the decision-making abilities of LLMs post role-playing thereby validating the efficacy of role-playing. Our goal is to provide metrics and guidance for enhancing the decision-making abilities of LLMs in role-playing tasks. Specifically, we first use LLMs to generate virtual role descriptions corresponding to the 16 personality types of Myers-Briggs Type Indicator (abbreviated as MBTI) representing a segmentation of the population. Then we design specific quantitative operations to evaluate the decision-making abilities of LLMs post role-playing from four aspects: adaptability, exploration$\\&$exploitation trade-off ability, reasoning ability, and safety. Finally, we analyze the association between the performance of decision-making and the corresponding MBTI types through GPT-4. Extensive experiments demonstrate stable differences in the four aspects of decision-making abilities across distinct roles, signifying a robust correlation between decision-making abilities and the roles emulated by LLMs. These results underscore that LLMs can effectively impersonate varied roles while embodying their genuine sociological characteristics.\n    ",
        "primary_category": "cs.CL",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18811": {
        "title": "BFRFormer: Transformer-based generator for Real-World Blind Face Restoration",
        "authors": [
            "Guojing Ge",
            "Qi Song",
            "Guibo Zhu",
            "Yuting Zhang",
            "Jinglu Chen",
            "Miao Xin",
            "Ming Tang",
            "Jinqiao Wang"
        ],
        "comments": "Accepted by ICASSP 2024",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Blind face restoration is a challenging task due to the unknown and complex degradation. Although face prior-based methods and reference-based methods have recently demonstrated high-quality results, the restored images tend to contain over-smoothed results and lose identity-preserved details when the degradation is severe. It is observed that this is attributed to short-range dependencies, the intrinsic limitation of convolutional neural networks. To model long-range dependencies, we propose a Transformer-based blind face restoration method, named BFRFormer, to reconstruct images with more identity-preserved details in an end-to-end manner. In BFRFormer, to remove blocking artifacts, the wavelet discriminator and aggregated attention module are developed, and spectral normalization and balanced consistency regulation are adaptively applied to address the training instability and over-fitting problem, respectively. Extensive experiments show that our method outperforms state-of-the-art methods on a synthetic dataset and four real-world datasets. The source code, Casia-Test dataset, and pre-trained models are released at this https URL.\n    ",
        "primary_category": "cs.CV",
        "categories": [],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18813": {
        "title": "Protein Multimer Structure Prediction via Prompt Learning",
        "authors": [
            "Ziqi Gao",
            "Xiangguo Sun",
            "Zijing Liu",
            "Yu Li",
            "Hong Cheng",
            "Jia Li"
        ],
        "comments": "International Conference on Learning Representations (ICLR 2024)",
        "subjects": "Computational Engineering, Finance, and Science (cs.CE)",
        "abstract": "Understanding the 3D structures of protein multimers is crucial, as they play a vital role in regulating various cellular processes. It has been empirically confirmed that the multimer structure prediction~(MSP) can be well handled in a step-wise assembly fashion using provided dimer structures and predicted protein-protein interactions~(PPIs). However, due to the biological gap in the formation of dimers and larger multimers, directly applying PPI prediction techniques can often cause a \\textit{poor generalization} to the MSP task. To address this challenge, we aim to extend the PPI knowledge to multimers of different scales~(i.e., chain numbers). Specifically, we propose \\textbf{\\textsc{PromptMSP}}, a pre-training and \\textbf{Prompt} tuning framework for \\textbf{M}ultimer \\textbf{S}tructure \\textbf{P}rediction. First, we tailor the source and target tasks for effective PPI knowledge learning and efficient inference, respectively. We design PPI-inspired prompt learning to narrow the gaps of two task formats and generalize the PPI knowledge to multimers of different scales. We provide a meta-learning strategy to learn a reliable initialization of the prompt model, enabling our prompting framework to effectively adapt to limited data for large-scale multimers. Empirically, we achieve both significant accuracy (RMSD and TM-Score) and efficiency improvements compared to advanced MSP models. The code, data and checkpoints are released at \\url{this https URL}.\n    ",
        "primary_category": "cs.CE",
        "categories": [],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18814": {
        "title": "New topological subsystem codes from semi-regular tessellations",
        "authors": [
            "Eduardo Brandani da Silva",
            "Evandro Mazetto Brizola"
        ],
        "comments": " ",
        "subjects": "Information Theory (cs.IT)",
        "abstract": "In this work, we present new constructions for topological subsystem codes using semi-regular Euclidean and hyperbolic tessellations. They give us new families of codes, and we also provide a new family of codes obtained through an already existing construction, due to Sarvepalli and Brown. We also prove new results that allow us to obtain the parameters of these new codes.\n    ",
        "primary_category": "cs.IT",
        "categories": [],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18815": {
        "title": "How do Large Language Models Handle Multilingualism?",
        "authors": [
            "Yiran Zhao",
            "Wenxuan Zhang",
            "Guizhen Chen",
            "Kenji Kawaguchi",
            "Lidong Bing"
        ],
        "comments": " ",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "Large language models (LLMs) demonstrate remarkable performance across a spectrum of languages. In this work, we delve into the question: How do LLMs handle multilingualism? We introduce a framework that depicts LLMs' processing of multilingual inputs: In the first several layers, LLMs understand the question, converting multilingual inputs into English to facilitate the task-solving phase. In the intermediate layers, LLMs engage in problem-solving by thinking in English and incorporating multilingual knowledge to obtain factual content, leveraging the self-attention and feed-forward structures, respectively. In the last several layers, LLMs generate responses that align with the original language of the query. In addition, we investigate the existence of language-specific neurons when processing a certain language. To detect neurons activated by the input language, even without labels, we innovatively design a Parallel Language specific Neuron Detection ($\\texttt{PLND}$) method that effectively measures the significance of neurons when handling multilingual inputs. By comprehensive ablation analysis through deactivating neurons of different layers and structures, we verify the framework that we propose. Additionally, we demonstrate that we can utilize such a framework to effectively enhance the multilingual ability with much less training effort.\n    ",
        "primary_category": "cs.CL",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18818": {
        "title": "CEBin: A Cost-Effective Framework for Large-Scale Binary Code Similarity Detection",
        "authors": [
            "Hao Wang",
            "Zeyu Gao",
            "Chao Zhang",
            "Mingyang Sun",
            "Yuchen Zhou",
            "Han Qiu",
            "Xi Xiao"
        ],
        "comments": " ",
        "subjects": "Software Engineering (cs.SE)",
        "abstract": "Binary code similarity detection (BCSD) is a fundamental technique for various application. Many BCSD solutions have been proposed recently, which mostly are embedding-based, but have shown limited accuracy and efficiency especially when the volume of target binaries to search is large. To address this issue, we propose a cost-effective BCSD framework, CEBin, which fuses embedding-based and comparison-based approaches to significantly improve accuracy while minimizing overheads. Specifically, CEBin utilizes a refined embedding-based approach to extract features of target code, which efficiently narrows down the scope of candidate similar code and boosts performance. Then, it utilizes a comparison-based approach that performs a pairwise comparison on the candidates to capture more nuanced and complex relationships, which greatly improves the accuracy of similarity detection. By bridging the gap between embedding-based and comparison-based approaches, CEBin is able to provide an effective and efficient solution for detecting similar code (including vulnerable ones) in large-scale software ecosystems. Experimental results on three well-known datasets demonstrate the superiority of CEBin over existing state-of-the-art (SOTA) baselines. To further evaluate the usefulness of BCSD in real world, we construct a large-scale benchmark of vulnerability, offering the first precise evaluation scheme to assess BCSD methods for the 1-day vulnerability detection task. CEBin could identify the similar function from millions of candidate functions in just a few seconds and achieves an impressive recall rate of $85.46\\%$ on this more practical but challenging task, which are several order of magnitudes faster and $4.07\\times$ better than the best SOTA baseline. Our code is available at this https URL.\n    ",
        "primary_category": "cs.SE",
        "categories": [
            "cs.CR"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18819": {
        "title": "Dual Operating Modes of In-Context Learning",
        "authors": [
            "Ziqian Lin",
            "Kangwook Lee"
        ],
        "comments": "53 pages, 20 figures",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "In-context learning (ICL) exhibits dual operating modes: task learning, i.e., acquiring a new skill from in-context samples, and task retrieval, i.e., locating and activating a relevant pretrained skill. Recent theoretical work investigates various mathematical models to analyze ICL, but existing models explain only one operating mode at a time. We introduce a probabilistic model, with which one can explain the dual operating modes of ICL simultaneously. Focusing on in-context learning of linear functions, we extend existing models for pretraining data by introducing multiple task groups and task-dependent input distributions. We then analyze the behavior of the optimally pretrained model under the squared loss, i.e., the MMSE estimator of the label given in-context examples. Regarding pretraining task distribution as prior and in-context examples as the observation, we derive the closed-form expression of the task posterior distribution. With the closed-form expression, we obtain a quantitative understanding of the two operating modes of ICL. Furthermore, we shed light on an unexplained phenomenon observed in practice: under certain settings, the ICL risk initially increases and then decreases with more in-context examples. Our model offers a plausible explanation for this \"early ascent\" phenomenon: a limited number of in-context samples may lead to the retrieval of an incorrect skill, thereby increasing the risk, which will eventually diminish as task learning takes effect with more in-context samples. We also theoretically analyze ICL with biased labels, e.g., zero-shot ICL, where in-context examples are assigned random labels. Lastly, we validate our findings and predictions via experiments involving Transformers and large language models.\n    ",
        "primary_category": "cs.LG",
        "categories": [],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18821": {
        "title": "Debiased Novel Category Discovering and Localization",
        "authors": [
            "Juexiao Feng",
            "Yuhong Yang",
            "Yanchun Xie",
            "Yaqian Li",
            "Yandong Guo",
            "Yuchen Guo",
            "Yuwei He",
            "Liuyu Xiang",
            "Guiguang Ding"
        ],
        "comments": "Accepted by AAAI 2024",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "In recent years, object detection in deep learning has experienced rapid development. However, most existing object detection models perform well only on closed-set datasets, ignoring a large number of potential objects whose categories are not defined in the training set. These objects are often identified as background or incorrectly classified as pre-defined categories by the detectors. In this paper, we focus on the challenging problem of Novel Class Discovery and Localization (NCDL), aiming to train detectors that can detect the categories present in the training data, while also actively discover, localize, and cluster new categories. We analyze existing NCDL methods and identify the core issue: object detectors tend to be biased towards seen objects, and this leads to the neglect of unseen targets. To address this issue, we first propose an Debiased Region Mining (DRM) approach that combines class-agnostic Region Proposal Network (RPN) and class-aware RPN in a complementary manner. Additionally, we suggest to improve the representation network through semi-supervised contrastive learning by leveraging unlabeled data. Finally, we adopt a simple and efficient mini-batch K-means clustering method for novel class discovery. We conduct extensive experiments on the NCDL benchmark, and the results demonstrate that the proposed DRM approach significantly outperforms previous methods, establishing a new state-of-the-art.\n    ",
        "primary_category": "cs.CV",
        "categories": [],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18824": {
        "title": "Batch size invariant Adam",
        "authors": [
            "Xi Wang",
            "Laurence Aitchison"
        ],
        "comments": " ",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "We propose a batch size invariant version of Adam, for use in large-scale, distributed settings, in which the mini-batch is divided into micro-batches which are distributed among worker nodes. For the v term, standard Adam first computes the average over micro-batch gradients, then squares, while in the batch size invariant Adam proposed here, we first square the micro-batch gradients, then average. Previous work (e.g. Malladi et al. 2022) used an alternative approach that involved a square-root scaling of the learning rate, but this approach requires strong assumptions to work; in particular that the gradient variance dominates the square of the expected gradient. In contrast, the approach proposed here gives batch size invariance without this assumption. We confirm that in practice our scheme gives batch size invariance in a much larger range of scenarios than the previous approach.\n    ",
        "primary_category": "cs.LG",
        "categories": [],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18826": {
        "title": "The Machine Can't Replace the Human Heart",
        "authors": [
            "Baihan Lin"
        ],
        "comments": " ",
        "subjects": "Computers and Society (cs.CY)",
        "abstract": "What is the true heart of mental healthcare -- innovation or humanity? Can virtual therapy ever replicate the profound human bonds where healing arises? As artificial intelligence and immersive technologies promise expanded access, safeguards must ensure technologies remain supplementary tools guided by providers' wisdom. Implementation requires nuance balancing efficiency and empathy. If conscious of ethical risks, perhaps AI could restore humanity by automating tasks, giving providers more time to listen. Yet no algorithm can replicate the seat of dignity within. We must ask ourselves: What future has people at its core? One where AI thoughtfully plays a collaborative role? Or where pursuit of progress leaves vulnerability behind? This commentary argues for a balanced approach thoughtfully integrating technology while retaining care's irreplaceable human essence, at the heart of this profoundly human profession. Ultimately, by nurturing innovation and humanity together, perhaps we reach new heights of empathy previously unimaginable.\n    ",
        "primary_category": "cs.CY",
        "categories": [
            "cs.AI",
            "cs.HC",
            "q-bio.NC"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18835": {
        "title": "Envisioning the Applications and Implications of Generative AI for News Media",
        "authors": [
            "Sachita Nishal",
            "Nicholas Diakopoulos"
        ],
        "comments": "Accepted to CHI 2023 Workshop on Generative AI and HCI; 8 pages",
        "subjects": "Computers and Society (cs.CY)",
        "abstract": "This article considers the increasing use of algorithmic decision-support systems and synthetic media in the newsroom, and explores how generative models can help reporters and editors across a range of tasks from the conception of a news story to its distribution. Specifically, we draw from a taxonomy of tasks associated with news production, and discuss where generative models could appropriately support reporters, the journalistic and ethical values that must be preserved within these interactions, and the resulting implications for design contributions in this area in the future. Our essay is relevant to practitioners and researchers as they consider using generative AI systems to support different tasks and workflows.\n    ",
        "primary_category": "cs.CY",
        "categories": [],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18836": {
        "title": "A Model-Based Approach for Improving Reinforcement Learning Efficiency Leveraging Expert Observations",
        "authors": [
            "Erhan Can Ozcan",
            "Vittorio Giammarino",
            "James Queeney",
            "Ioannis Ch. Paschalidis"
        ],
        "comments": " ",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "This paper investigates how to incorporate expert observations (without explicit information on expert actions) into a deep reinforcement learning setting to improve sample efficiency. First, we formulate an augmented policy loss combining a maximum entropy reinforcement learning objective with a behavioral cloning loss that leverages a forward dynamics model. Then, we propose an algorithm that automatically adjusts the weights of each component in the augmented loss function. Experiments on a variety of continuous control tasks demonstrate that the proposed algorithm outperforms various benchmarks by effectively utilizing available expert observations.\n    ",
        "primary_category": "cs.LG",
        "categories": [],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18838": {
        "title": "When does word order matter and when doesn't it?",
        "authors": [
            "Xuanda Chen",
            "Timothy O'Donnell",
            "Siva Reddy"
        ],
        "comments": "5 pages",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "Language models (LMs) may appear insensitive to word order changes in natural language understanding (NLU) tasks. In this paper, we propose that linguistic redundancy can explain this phenomenon, whereby word order and other linguistic cues such as case markers provide overlapping and thus redundant information. Our hypothesis is that models exhibit insensitivity to word order when the order provides redundant information, and the degree of insensitivity varies across tasks. We quantify how informative word order is using mutual information (MI) between unscrambled and scrambled sentences. Our results show the effect that the less informative word order is, the more consistent the model's predictions are between unscrambled and scrambled sentences. We also find that the effect varies across tasks: for some tasks, like SST-2, LMs' prediction is almost always consistent with the original one even if the Pointwise-MI (PMI) changes, while for others, like RTE, the consistency is near random when the PMI gets lower, i.e., word order is really important.\n    ",
        "primary_category": "cs.CL",
        "categories": [],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18839": {
        "title": "Extended Flow Matching: a Method of Conditional Generation with Generalized Continuity Equation",
        "authors": [
            "Noboru Isobe",
            "Masanori Koyama",
            "Kohei Hayashi",
            "Kenji Fukumizu"
        ],
        "comments": "15 pages, 4 figures",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "The task of conditional generation is one of the most important applications of generative models, and numerous methods have been developed to date based on the celebrated diffusion models, with the guidance-based classifier-free method taking the lead. However, the theory of the guidance-based method not only requires the user to fine-tune the \"guidance strength,\" but its target vector field does not necessarily correspond to the conditional distribution used in training. In this paper, we develop the theory of conditional generation based on Flow Matching, a current strong contender of diffusion methods. Motivated by the interpretation of a probability path as a distribution on path space, we establish a novel theory of flow-based generation of conditional distribution by employing the mathematical framework of generalized continuity equation instead of the continuity equation in flow matching. This theory naturally derives a method that aims to match the matrix field as opposed to the vector field. Our framework ensures the continuity of the generated conditional distribution through the existence of flow between conditional distributions. We will present our theory through experiments and mathematical results.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "math.AP",
            "math.FA",
            "math.OC",
            "math.PR"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18842": {
        "title": "ViewFusion: Towards Multi-View Consistency via Interpolated Denoising",
        "authors": [
            "Xianghui Yang",
            "Yan Zuo",
            "Sameera Ramasinghe",
            "Loris Bazzani",
            "Gil Avraham",
            "Anton van den Hengel"
        ],
        "comments": "CVPR2024,homepage:this https URL",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Novel-view synthesis through diffusion models has demonstrated remarkable potential for generating diverse and high-quality images. Yet, the independent process of image generation in these prevailing methods leads to challenges in maintaining multiple-view consistency. To address this, we introduce ViewFusion, a novel, training-free algorithm that can be seamlessly integrated into existing pre-trained diffusion models. Our approach adopts an auto-regressive method that implicitly leverages previously generated views as context for the next view generation, ensuring robust multi-view consistency during the novel-view generation process. Through a diffusion process that fuses known-view information via interpolated denoising, our framework successfully extends single-view conditioned models to work in multiple-view conditional settings without any additional fine-tuning. Extensive experimental results demonstrate the effectiveness of ViewFusion in generating consistent and detailed novel views.\n    ",
        "primary_category": "cs.CV",
        "categories": [],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18844": {
        "title": "Deep Learning for 3D Human Pose Estimation and Mesh Recovery: A Survey",
        "authors": [
            "Yang Liu",
            "Changzhen Qiu",
            "Zhiyong Zhang"
        ],
        "comments": " ",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "3D human pose estimation and mesh recovery have attracted widespread research interest in many areas, such as computer vision, autonomous driving, and robotics. Deep learning on 3D human pose estimation and mesh recovery has recently thrived, with numerous methods proposed to address different problems in this area. In this paper, to stimulate future research, we present a comprehensive review of recent progress over the past five years in deep learning methods for this area by delving into over 200 references. To the best of our knowledge, this survey is arguably the first to comprehensively cover deep learning methods for 3D human pose estimation, including both single-person and multi-person approaches, as well as human mesh recovery, encompassing methods based on explicit models and implicit representations. We also present comparative results on several publicly available datasets, together with insightful observations and inspiring future research directions. A regularly updated project page can be found at this https URL.\n    ",
        "primary_category": "cs.CV",
        "categories": [
            "cs.MM"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18846": {
        "title": "Multi-Fidelity Residual Neural Processes for Scalable Surrogate Modeling",
        "authors": [
            "Ruijia Niu",
            "Dongxia Wu",
            "Kai Kim",
            "Yi-An Ma",
            "Duncan Watson-Parris",
            "Rose Yu"
        ],
        "comments": "A novel probabilistic inference approach for scalable multi-fidelity surrogate modeling",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Multi-fidelity surrogate modeling aims to learn an accurate surrogate at the highest fidelity level by combining data from multiple sources. Traditional methods relying on Gaussian processes can hardly scale to high-dimensional data. Deep learning approaches utilize neural network based encoders and decoders to improve scalability. These approaches share encoded representations across fidelities without including corresponding decoder parameters. At the highest fidelity, the representations are decoded with different parameters, making the shared information inherently inaccurate. This hinders inference performance, especially in out-of-distribution scenarios when the highest fidelity data has limited domain coverage. To address these limitations, we propose Multi-fidelity Residual Neural Processes (MFRNP), a novel multi-fidelity surrogate modeling framework. MFRNP optimizes lower fidelity decoders for accurate information sharing by aggregating lower fidelity surrogate outputs and models residual between the aggregation and ground truth on the highest fidelity. We show that MFRNP significantly outperforms current state-of-the-art in learning partial differential equations and a real-world climate modeling task.\n    ",
        "primary_category": "cs.LG",
        "categories": [],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18848": {
        "title": "SwitchLight: Co-design of Physics-driven Architecture and Pre-training Framework for Human Portrait Relighting",
        "authors": [
            "Hoon Kim",
            "Minje Jang",
            "Wonjun Yoon",
            "Jisoo Lee",
            "Donghyun Na",
            "Sanghyun Woo"
        ],
        "comments": "CVPR2024. Live demos available at this https URL",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "We introduce a co-designed approach for human portrait relighting that combines a physics-guided architecture with a pre-training framework. Drawing on the Cook-Torrance reflectance model, we have meticulously configured the architecture design to precisely simulate light-surface interactions. Furthermore, to overcome the limitation of scarce high-quality lightstage data, we have developed a self-supervised pre-training strategy. This novel combination of accurate physical modeling and expanded training dataset establishes a new benchmark in relighting realism.\n    ",
        "primary_category": "cs.CV",
        "categories": [],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18849": {
        "title": "Enhancing Steganographic Text Extraction: Evaluating the Impact of NLP Models on Accuracy and Semantic Coherence",
        "authors": [
            "Mingyang Li",
            "Maoqin Yuan",
            "Luyao Li",
            "Han Pengsihua"
        ],
        "comments": " ",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "This study discusses a new method combining image steganography technology with Natural Language Processing (NLP) large models, aimed at improving the accuracy and robustness of extracting steganographic text. Traditional Least Significant Bit (LSB) steganography techniques face challenges in accuracy and robustness of information extraction when dealing with complex character encoding, such as Chinese characters. To address this issue, this study proposes an innovative LSB-NLP hybrid framework. This framework integrates the advanced capabilities of NLP large models, such as error detection, correction, and semantic consistency analysis, as well as information reconstruction techniques, thereby significantly enhancing the robustness of steganographic text extraction. Experimental results show that the LSB-NLP hybrid framework excels in improving the extraction accuracy of steganographic text, especially in handling Chinese characters. The findings of this study not only confirm the effectiveness of combining image steganography technology and NLP large models but also propose new ideas for research and application in the field of information hiding. The successful implementation of this interdisciplinary approach demonstrates the great potential of integrating image steganography technology with natural language processing technology in solving complex information processing problems.\n    ",
        "primary_category": "cs.CV",
        "categories": [
            "cs.AI",
            "cs.CL"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18851": {
        "title": "Applications of 0-1 Neural Networks in Prescription and Prediction",
        "authors": [
            "Vrishabh Patil",
            "Kara Hoppe",
            "Yonatan Mintz"
        ],
        "comments": " ",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "A key challenge in medical decision making is learning treatment policies for patients with limited observational data. This challenge is particularly evident in personalized healthcare decision-making, where models need to take into account the intricate relationships between patient characteristics, treatment options, and health outcomes. To address this, we introduce prescriptive networks (PNNs), shallow 0-1 neural networks trained with mixed integer programming that can be used with counterfactual estimation to optimize policies in medium data settings. These models offer greater interpretability than deep neural networks and can encode more complex policies than common models such as decision trees. We show that PNNs can outperform existing methods in both synthetic data experiments and in a case study of assigning treatments for postpartum hypertension. In particular, PNNs are shown to produce policies that could reduce peak blood pressure by 5.47 mm Hg (p=0.02) over existing clinical practice, and by 2 mm Hg (p=0.01) over the next best prescriptive modeling technique. Moreover PNNs were more likely than all other models to correctly identify clinically significant features while existing models relied on potentially dangerous features such as patient insurance information and race that could lead to bias in treatment.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.AI",
            "math.OC",
            "stat.ML"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18853": {
        "title": "Rethinking Multi-domain Generalization with A General Learning Objective",
        "authors": [
            "Zhaorui Tan",
            "Xi Yang",
            "Kaizhu Huang"
        ],
        "comments": "Accepted by CVPR24",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Multi-domain generalization (mDG) is universally aimed to minimize the discrepancy between training and testing distributions to enhance marginal-to-label distribution mapping. However, existing mDG literature lacks a general learning objective paradigm and often imposes constraints on static target marginal distributions. In this paper, we propose to leverage a $Y$-mapping to relax the constraint. We rethink the learning objective for mDG and design a new \\textbf{general learning objective} to interpret and analyze most existing mDG wisdom. This general objective is bifurcated into two synergistic amis: learning domain-independent conditional features and maximizing a posterior. Explorations also extend to two effective regularization terms that incorporate prior information and suppress invalid causality, alleviating the issues that come with relaxed constraints. We theoretically contribute an upper bound for the domain alignment of domain-independent conditional features, disclosing that many previous mDG endeavors actually \\textbf{optimize partially the objective} and thus lead to limited performance. As such, our study distills a general learning objective into four practical components, providing a general, robust, and flexible mechanism to handle complex domain shifts. Extensive empirical results indicate that the proposed objective with $Y$-mapping leads to substantially better mDG performance in various downstream tasks, including regression, segmentation, and classification.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.AI",
            "cs.CV"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18856": {
        "title": "Anatomy-guided fiber trajectory distribution estimation for cranial nerves tractography",
        "authors": [
            "Lei Xie",
            "Qingrun Zeng",
            "Huajun Zhou",
            "Guoqiang Xie",
            "Mingchu Li",
            "Jiahao Huang",
            "Jianan Cui",
            "Hao Chen",
            "Yuanjing Feng"
        ],
        "comments": " ",
        "subjects": "Image and Video Processing (eess.IV)",
        "abstract": "Diffusion MRI tractography is an important tool for identifying and analyzing the intracranial course of cranial nerves (CNs). However, the complex environment of the skull base leads to ambiguous spatial correspondence between diffusion directions and fiber geometry, and existing diffusion tractography methods of CNs identification are prone to producing erroneous trajectories and missing true positive connections. To overcome the above challenge, we propose a novel CNs identification framework with anatomy-guided fiber trajectory distribution, which incorporates anatomical shape prior knowledge during the process of CNs tracing to build diffusion tensor vector fields. We introduce higher-order streamline differential equations for continuous flow field representations to directly characterize the fiber trajectory distribution of CNs from the tract-based level. The experimental results on the vivo HCP dataset and the clinical MDM dataset demonstrate that the proposed method reduces false-positive fiber production compared to competing methods and produces reconstructed CNs (i.e. CN II, CN III, CN V, and CN VII/VIII) that are judged to better correspond to the known anatomy.\n    ",
        "primary_category": "eess.IV",
        "categories": [
            "cs.CV"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18859": {
        "title": "Taking Second-life Batteries from Exhausted to Empowered using Experiments, Data Analysis, and Health Estimation",
        "authors": [
            "Xiaofan Cui",
            "Muhammad Aadil Khan",
            "Gabriele Pozzato",
            "Surinder Singh",
            "Ratnesh Sharma",
            "Simona Onori"
        ],
        "comments": "31 pages, 18 figures",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "The reuse of retired electric vehicle (EV) batteries in electric grid energy storage emerges as a promising strategy to address environmental concerns and boost economic value. This study concentrates on devising health monitoring algorithms for retired batteries (BMS$_2$) deployed in grid storage applications. Over 15 months of testing, we compile, analyze, and publicly share a dataset of second-life (SL) batteries, implementing a cycling protocol simulating grid energy storage load profiles within a 3 V-4 V voltage window. Four machine learning-based health estimation models, relying on BMS$_2$ features and initial capacity, are developed and compared, with the selected model achieving a Mean Absolute Percentage Error (MAPE) below 2.3% on test data. Additionally, an adaptive online health estimation algorithm is proposed by integrating a clustering-based method, limiting estimation errors during online deployment. These results constitute an initial proof of concept, showcasing the feasibility of repurposing retired batteries for second-life applications. Based on obtained data and representative power demand, these SL batteries exhibit the potential, under specific conditions, for over a decade of grid energy storage use.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "eess.SY"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18860": {
        "title": "Error estimation for finite element method on meshes that contain thin elements",
        "authors": [
            "Kenta Kobayashi",
            "Takuya Tsuchiya"
        ],
        "comments": " ",
        "subjects": "Numerical Analysis (math.NA)",
        "abstract": "In an error estimation of finite element solutions to the Poisson equation, we usually impose the shape regularity assumption on the meshes to be used. In this paper, we show that even if the shape regularity condition is violated, the standard error estimation can be obtained if \"bad\" elements (elements that violate the shape regularity or maximum angle condition) are covered virtually by \"good\" simplices. A numerical experiment confirms the theoretical result.\n    ",
        "primary_category": "math.NA",
        "categories": [],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18865": {
        "title": "Analyzing and Reducing Catastrophic Forgetting in Parameter Efficient Tuning",
        "authors": [
            "Weijieying Ren",
            "Xinlong Li",
            "Lei Wang",
            "Tianxiang Zhao",
            "Wei Qin"
        ],
        "comments": " ",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Existing research has shown that large language models (LLMs) exhibit remarkable performance in language understanding and generation. However, when LLMs are continuously fine-tuned on complex and diverse domain-specific downstream tasks, the inference performance on historical tasks decreases dramatically, which is known as a catastrophic forgetting problem. A trade-off needs to be kept between learning plasticity and memory stability. Plenty of existing works have explored strategies like memory replay, regularization and parameter isolation, but little is known about the geometric connection of various adjacent minima in the continual LLMs fine-tuning scenarios. In this work, we investigate the geometric connections of different minima through the lens of mode connectivity, which means different minima can be connected by a low-loss valley. Through extensive experiments, we uncover the mode connectivity phenomenon in the LLMs continual learning scenario and find that it can strike a balance between plasticity and stability. Building upon these findings, we propose a simple yet effective method called Interpolation-based LoRA (I-LoRA), which constructs a dual-memory experience replay framework based on LoRA parameter interpolations. Extensive experiments and analysis on eight domain-specific CL benchmarks demonstrate that I-LoRA consistently show significant improvement over the previous state-of-the-art approaches with up to $11\\%$ performance gains, providing a strong baseline and insights for future research on the large language model continual learning problem. Our code is available at \\url{this https URL}.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.AI",
            "cs.CL"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18866": {
        "title": "Dr. Strategy: Model-Based Generalist Agents with Strategic Dreaming",
        "authors": [
            "Hany Hamed",
            "Subin Kim",
            "Dongyeong Kim",
            "Jaesik Yoon",
            "Sungjin Ahn"
        ],
        "comments": "First two authors contributed equally",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Model-based reinforcement learning (MBRL) has been a primary approach to ameliorating the sample efficiency issue as well as to make a generalist agent. However, there has not been much effort toward enhancing the strategy of dreaming itself. Therefore, it is a question whether and how an agent can \"dream better\" in a more structured and strategic way. In this paper, inspired by the observation from cognitive science suggesting that humans use a spatial divide-and-conquer strategy in planning, we propose a new MBRL agent, called Dr. Strategy, which is equipped with a novel Dreaming Strategy. The proposed agent realizes a version of divide-and-conquer-like strategy in dreaming. This is achieved by learning a set of latent landmarks and then utilizing these to learn a landmark-conditioned highway policy. With the highway policy, the agent can first learn in the dream to move to a landmark, and from there it tackles the exploration and achievement task in a more focused way. In experiments, we show that the proposed model outperforms prior pixel-based MBRL methods in various visually complex and partially observable navigation tasks. The source code will be available at this https URL\n",
        "primary_category": "cs.LG",
        "categories": [],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18867": {
        "title": "Message-Enhanced DeGroot Model",
        "authors": [
            "Huisheng Wang",
            "Zhanjiang Chen",
            "H. Vicky Zhao"
        ],
        "comments": " ",
        "subjects": "Signal Processing (eess.SP)",
        "abstract": "Understanding the impact of messages on agents' opinions over social networks is important. However, to our best knowledge, there has been limited quantitative investigation into this phenomenon in the prior works. To address this gap, this paper proposes the Message-Enhanced DeGroot model. The Bounded Brownian Message model provides a quantitative description of the message evolution, jointly considering temporal continuity, randomness, and polarization from mass media theory. The Message-Enhanced DeGroot model, combining the Bounded Brownian Message model with the traditional DeGroot model, quantitatively describes the evolution of agents' opinions under the influence of messages. We theoretically study the probability distribution and statistics of the messages and agents' opinions and quantitatively analyze the impact of messages on opinions. We also conduct simulations to validate our analyses.\n    ",
        "primary_category": "eess.SP",
        "categories": [
            "cs.SI",
            "eess.SY"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18869": {
        "title": "Evaluating the Gilbert-Varshamov Bound for Constrained Systems",
        "authors": [
            "Keshav Goyal",
            "Han Mao Kiah"
        ],
        "comments": "27 Pages, 5 figures, submitted to Entropy",
        "subjects": "Information Theory (cs.IT)",
        "abstract": "We revisit the well-known Gilbert-Varshamov (GV) bound for constrained systems. In 1991, Kolesnik and Krachkovsky showed that GV bound can be determined via the solution of some optimization problem. Later, Marcus and Roth (1992) modified the optimization problem and improved the GV bound in many instances. In this work, we provide explicit numerical procedures to solve these two optimization problems and hence, compute the bounds. We then show the procedures can be further simplified when we plot the respective curves. In the case where the graph presentation comprise a single state, we provide explicit formulas for both bounds.\n    ",
        "primary_category": "cs.IT",
        "categories": [
            "cs.DM",
            "math.CO"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18871": {
        "title": "LoLiSRFlow: Joint Single Image Low-light Enhancement and Super-resolution via Cross-scale Transformer-based Conditional Flow",
        "authors": [
            "Ziyu Yue",
            "Jiaxin Gao",
            "Sihan Xie",
            "Yang Liu",
            "Zhixun Su"
        ],
        "comments": " ",
        "subjects": "Image and Video Processing (eess.IV)",
        "abstract": "The visibility of real-world images is often limited by both low-light and low-resolution, however, these issues are only addressed in the literature through Low-Light Enhancement (LLE) and Super- Resolution (SR) methods. Admittedly, a simple cascade of these approaches cannot work harmoniously to cope well with the highly ill-posed problem for simultaneously enhancing visibility and resolution. In this paper, we propose a normalizing flow network, dubbed LoLiSRFLow, specifically designed to consider the degradation mechanism inherent in joint LLE and SR. To break the bonds of the one-to-many mapping for low-light low-resolution images to normal-light high-resolution images, LoLiSRFLow directly learns the conditional probability distribution over a variety of feasible solutions for high-resolution well-exposed images. Specifically, a multi-resolution parallel transformer acts as a conditional encoder that extracts the Retinex-induced resolution-and-illumination invariant map as the previous one. And the invertible network maps the distribution of usually exposed high-resolution images to a latent distribution. The backward inference is equivalent to introducing an additional constrained loss for the normal training route, thus enabling the manifold of the natural exposure of the high-resolution image to be immaculately depicted. We also propose a synthetic dataset modeling the realistic low-light low-resolution degradation, named DFSR-LLE, containing 7100 low-resolution dark-light/high-resolution normal sharp pairs. Quantitative and qualitative experimental results demonstrate the effectiveness of our method on both the proposed synthetic and real datasets.\n    ",
        "primary_category": "eess.IV",
        "categories": [
            "cs.CV"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18873": {
        "title": "Reducing Hallucinations in Entity Abstract Summarization with Facts-Template Decomposition",
        "authors": [
            "Fangwei Zhu",
            "Peiyi Wang",
            "Zhifang Sui"
        ],
        "comments": " ",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "Entity abstract summarization aims to generate a coherent description of a given entity based on a set of relevant Internet documents. Pretrained language models (PLMs) have achieved significant success in this task, but they may suffer from hallucinations, i.e. generating non-factual information about the entity. To address this issue, we decompose the summary into two components: Facts that represent the factual information about the given entity, which PLMs are prone to fabricate; and Template that comprises generic content with designated slots for facts, which PLMs can generate competently. Based on the facts-template decomposition, we propose SlotSum, an explainable framework for entity abstract summarization. SlotSum first creates the template and then predicts the fact for each template slot based on the input documents. Benefiting from our facts-template decomposition, SlotSum can easily locate errors and further rectify hallucinated predictions with external knowledge. We construct a new dataset WikiFactSum to evaluate the performance of SlotSum. Experimental results demonstrate that SlotSum could generate summaries that are significantly more factual with credible external knowledge.\n    ",
        "primary_category": "cs.CL",
        "categories": [],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18875": {
        "title": "Loss-aware Curriculum Learning for Heterogeneous Graph Neural Networks",
        "authors": [
            "Zhen Hao Wong",
            "Hansi Yang",
            "Xiaoyi Fu",
            "Quanming Yao"
        ],
        "comments": " ",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Heterogeneous Graph Neural Networks (HGNNs) are a class of deep learning models designed specifically for heterogeneous graphs, which are graphs that contain different types of nodes and edges. This paper investigates the application of curriculum learning techniques to improve the performance and robustness of Heterogeneous Graph Neural Networks (GNNs). To better classify the quality of the data, we design a loss-aware training schedule, named LTS that measures the quality of every nodes of the data and incorporate the training dataset into the model in a progressive manner that increases difficulty step by step. LTS can be seamlessly integrated into various frameworks, effectively reducing bias and variance, mitigating the impact of noisy data, and enhancing overall accuracy. Our findings demonstrate the efficacy of curriculum learning in enhancing HGNNs capabilities for analyzing complex graph-structured data. The code is public at https: //github.com/LARS-research/CLGNN/.\n    ",
        "primary_category": "cs.LG",
        "categories": [],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18877": {
        "title": "Principal Component Analysis as a Sanity Check for Bayesian Phylolinguistic Reconstruction",
        "authors": [
            "Yugo Murawaki"
        ],
        "comments": "Accepted at LREC-COLING 2024",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "Bayesian approaches to reconstructing the evolutionary history of languages rely on the tree model, which assumes that these languages descended from a common ancestor and underwent modifications over time. However, this assumption can be violated to different extents due to contact and other factors. Understanding the degree to which this assumption is violated is crucial for validating the accuracy of phylolinguistic inference. In this paper, we propose a simple sanity check: projecting a reconstructed tree onto a space generated by principal component analysis. By using both synthetic and real data, we demonstrate that our method effectively visualizes anomalies, particularly in the form of jogging.\n    ",
        "primary_category": "cs.CL",
        "categories": [],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18879": {
        "title": "Dose Prediction Driven Radiotherapy Paramters Regression via Intra- and Inter-Relation Modeling",
        "authors": [
            "Jiaqi Cui",
            "Yuanyuan Xu",
            "Jianghong Xiao",
            "Yuchen Fei",
            "Jiliu Zhou",
            "Xingcheng Peng",
            "Yan Wang"
        ],
        "comments": "Accepted by ISBI 2024",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Deep learning has facilitated the automation of radiotherapy by predicting accurate dose distribution maps. However, existing methods fail to derive the desirable radiotherapy parameters that can be directly input into the treatment planning system (TPS), impeding the full automation of radiotherapy. To enable more thorough automatic radiotherapy, in this paper, we propose a novel two-stage framework to directly regress the radiotherapy parameters, including a dose map prediction stage and a radiotherapy parameters regression stage. In stage one, we combine transformer and convolutional neural network (CNN) to predict realistic dose maps with rich global and local information, providing accurate dosimetric knowledge for the subsequent parameters regression. In stage two, two elaborate modules, i.e., an intra-relation modeling (Intra-RM) module and an inter-relation modeling (Inter-RM) module, are designed to exploit the organ-specific and organ-shared features for precise parameters regression. Experimental results on a rectal cancer dataset demonstrate the effectiveness of our method.\n    ",
        "primary_category": "cs.CV",
        "categories": [],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18883": {
        "title": "Efficient Processing of Subsequent Densest Subgraph Query",
        "authors": [
            "Chia-Yang Hung",
            "Chih-Ya Shen"
        ],
        "comments": "11 pages",
        "subjects": "Data Structures and Algorithms (cs.DS)",
        "abstract": "Dense subgraph extraction is a fundamental problem in graph analysis and data mining, aimed at identifying cohesive and densely connected substructures within a given graph. It plays a crucial role in various domains, including social network analysis, biological network analysis, recommendation systems, and community detection. However, extracting a subgraph with the highest node similarity is a lack of exploration. To address this problem, we studied the Member Selection Problem and extended it with a dynamic constraint variant. By incorporating dynamic constraints, our algorithm can adapt to changing conditions or requirements, allowing for more flexible and personalized subgraph extraction. This approach enables the algorithm to provide tailored solutions that meet specific needs, even in scenarios where constraints may vary over time. We also provide the theoretical analysis to show that our algorithm is 1/3-approximation. Eventually, the experiments show that our algorithm is effective and efficient in tackling the member selection problem with dynamic constraints.\n    ",
        "primary_category": "cs.DS",
        "categories": [],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18884": {
        "title": "Supervised Contrastive Representation Learning: Landscape Analysis with Unconstrained Features",
        "authors": [
            "Tina Behnia",
            "Christos Thrampoulidis"
        ],
        "comments": "10 pages",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Recent findings reveal that over-parameterized deep neural networks, trained beyond zero training-error, exhibit a distinctive structural pattern at the final layer, termed as Neural-collapse (NC). These results indicate that the final hidden-layer outputs in such networks display minimal within-class variations over the training set. While existing research extensively investigates this phenomenon under cross-entropy loss, there are fewer studies focusing on its contrastive counterpart, supervised contrastive (SC) loss. Through the lens of NC, this paper employs an analytical approach to study the solutions derived from optimizing the SC loss. We adopt the unconstrained features model (UFM) as a representative proxy for unveiling NC-related phenomena in sufficiently over-parameterized deep networks. We show that, despite the non-convexity of SC loss minimization, all local minima are global minima. Furthermore, the minimizer is unique (up to a rotation). We prove our results by formalizing a tight convex relaxation of the UFM. Finally, through this convex formulation, we delve deeper into characterizing the properties of global solutions under label-imbalanced training data.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "stat.ML"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18886": {
        "title": "BP-DeepONet: A new method for cuffless blood pressure estimation using the physcis-informed DeepONet",
        "authors": [
            "Lingfeng Li",
            "Xue-Cheng Tai",
            "Raymond Chan"
        ],
        "comments": " ",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Cardiovascular diseases (CVDs) are the leading cause of death worldwide, with blood pressure serving as a crucial indicator. Arterial blood pressure (ABP) waveforms provide continuous pressure measurements throughout the cardiac cycle and offer valuable diagnostic insights. Consequently, there is a significant demand for non-invasive and cuff-less methods to measure ABP waveforms continuously. Accurate prediction of ABP waveforms can also improve the estimation of mean blood pressure, an essential cardiovascular health characteristic.\nThis study proposes a novel framework based on the physics-informed DeepONet approach to predict ABP waveforms. Unlike previous methods, our approach requires the predicted ABP waveforms to satisfy the Navier-Stokes equation with a time-periodic condition and a Windkessel boundary condition. Notably, our framework is the first to predict ABP waveforms continuously, both with location and time, within the part of the artery that is being simulated. Furthermore, our method only requires ground truth data at the outlet boundary and can handle periodic conditions with varying periods. Incorporating the Windkessel boundary condition in our solution allows for generating natural physical reflection waves, which closely resemble measurements observed in real-world cases. Moreover, accurately estimating the hyper-parameters in the Navier-Stokes equation for our simulations poses a significant challenge. To overcome this obstacle, we introduce the concept of meta-learning, enabling the neural networks to learn these parameters during the training process.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "physics.med-ph"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18888": {
        "title": "Uncertainty-Based Extensible Codebook for Discrete Federated Learning in Heterogeneous Data Silos",
        "authors": [
            "Tianyi Zhang",
            "Yu Cao",
            "Dianbo Liu"
        ],
        "comments": " ",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Federated learning (FL), aimed at leveraging vast distributed datasets, confronts a crucial challenge: the heterogeneity of data across different silos. While previous studies have explored discrete representations to enhance model generalization across minor distributional shifts, these approaches often struggle to adapt to new data silos with significantly divergent distributions. In response, we have identified that models derived from FL exhibit markedly increased uncertainty when applied to data silos with unfamiliar distributions. Consequently, we propose an innovative yet straightforward iterative framework, termed Uncertainty-Based Extensible-Codebook Federated Learning (UEFL). This framework dynamically maps latent features to trainable discrete vectors, assesses the uncertainty, and specifically extends the discretization dictionary or codebook for silos exhibiting high uncertainty. Our approach aims to simultaneously enhance accuracy and reduce uncertainty by explicitly addressing the diversity of data distributions, all while maintaining minimal computational overhead in environments characterized by heterogeneous data silos. Through experiments conducted on five datasets, our method has demonstrated its superiority, achieving significant improvements in accuracy (by 3%--22.1%) and uncertainty reduction (by 38.83%--96.24%), thereby outperforming contemporary state-of-the-art methods. The source code is available at this https URL.\n    ",
        "primary_category": "cs.LG",
        "categories": [],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18896": {
        "title": "On the maximum size of variable-length non-overlapping codes",
        "authors": [
            "Geyang Wang",
            "Qi Wang"
        ],
        "comments": " ",
        "subjects": "Information Theory (cs.IT)",
        "abstract": "Non-overlapping codes are a set of codewords such that the prefix of each codeword is not a suffix of any codeword in the set, including itself. If the lengths of the codewords are variable, it is additionally required that every codeword is not contained in any other codeword as a subword. Let $C(n,q)$ be the maximum size of $q$-ary fixed-length non-overlapping codes of length $n$. The upper bound on $C(n,q)$ has been well studied. However, the nontrivial upper bound on the maximum size of variable-length non-overlapping codes of length at most $n$ remains open. In this paper, by establishing a link between variable-length non-overlapping codes and fixed-length ones, we are able to show that the size of a $q$-ary variable-length non-overlapping code is upper bounded by $C(n,q)$. Furthermore, we prove that the average length of the codewords in a $q$-ary variable-length non-overlapping codes is lower bounded by $\\lceil \\log_q \\tilde{C} \\rceil$, and is asymptotically no shorter than $n-2$ as $q$ approaches $\\infty$, where $\\tilde{C}$ denotes the cardinality of $q$-ary variable-length non-overlapping codes of length up to $n$.\n    ",
        "primary_category": "cs.IT",
        "categories": [
            "math.CO"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18899": {
        "title": "Aligning Language Models for Versatile Text-based Item Retrieval",
        "authors": [
            "Yuxuan Lei",
            "Jianxun Lian",
            "Jing Yao",
            "Mingqi Wu",
            "Defu Lian",
            "Xing Xie"
        ],
        "comments": "4 pages,1 figures, 4 tables",
        "subjects": "Information Retrieval (cs.IR)",
        "abstract": "This paper addresses the gap between general-purpose text embeddings and the specific demands of item retrieval tasks. We demonstrate the shortcomings of existing models in capturing the nuances necessary for zero-shot performance on item retrieval tasks. To overcome these limitations, we propose generate in-domain dataset from ten tasks tailored to unlocking models' representation ability for item retrieval. Our empirical studies demonstrate that fine-tuning embedding models on the dataset leads to remarkable improvements in a variety of retrieval tasks. We also illustrate the practical application of our refined model in a conversational setting, where it enhances the capabilities of LLM-based Recommender Agents like Chat-Rec. Our code is available at this https URL.\n    ",
        "primary_category": "cs.IR",
        "categories": [],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18905": {
        "title": "On the Convergence of Differentially-Private Fine-tuning: To Linearly Probe or to Fully Fine-tune?",
        "authors": [
            "Shuqi Ke",
            "Charlie Hou",
            "Giulia Fanti",
            "Sewoong Oh"
        ],
        "comments": " ",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Differentially private (DP) machine learning pipelines typically involve a two-phase process: non-private pre-training on a public dataset, followed by fine-tuning on private data using DP optimization techniques. In the DP setting, it has been observed that full fine-tuning may not always yield the best test accuracy, even for in-distribution data. This paper (1) analyzes the training dynamics of DP linear probing (LP) and full fine-tuning (FT), and (2) explores the phenomenon of sequential fine-tuning, starting with linear probing and transitioning to full fine-tuning (LP-FT), and its impact on test loss. We provide theoretical insights into the convergence of DP fine-tuning within an overparameterized neural network and establish a utility curve that determines the allocation of privacy budget between linear probing and full fine-tuning. The theoretical results are supported by empirical evaluations on various benchmarks and models. The findings reveal the complex nature of DP fine-tuning methods. These results contribute to a deeper understanding of DP machine learning and highlight the importance of considering the allocation of privacy budget in the fine-tuning process.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.AI",
            "cs.CR",
            "math.OC"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18908": {
        "title": "Facility Location Games with Scaling Effects",
        "authors": [
            "Yu He",
            "Alexander Lam",
            "Minming Li"
        ],
        "comments": " ",
        "subjects": "Computer Science and Game Theory (cs.GT)",
        "abstract": "We take the classic facility location problem and consider a variation, in which each agent's individual cost function is equal to their distance from the facility multiplied by a scaling factor which is determined by the facility placement. In addition to the general class of continuous scaling functions, we also provide results for piecewise linear scaling functions which can effectively approximate or model the scaling of many real world scenarios. We focus on the objectives of total and maximum cost, describing the computation of the optimal solution. We then move to the approximate mechanism design setting, observing that the agents' preferences may no longer be single-peaked. Consequently, we characterize the conditions on scaling functions which ensure that agents have single-peaked preferences. Under these conditions, we find results on the total and maximum cost approximation ratios achievable by strategyproof and anonymous mechanisms.\n    ",
        "primary_category": "cs.GT",
        "categories": [
            "cs.AI",
            "cs.MA",
            "econ.TH"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18909": {
        "title": "Updating Language Models with Unstructured Facts: Towards Practical Knowledge Editing",
        "authors": [
            "Xiaobao Wu",
            "Liangming Pan",
            "William Yang Wang",
            "Anh Tuan Luu"
        ],
        "comments": " ",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "Knowledge editing aims to inject knowledge updates into language models to keep them correct and up-to-date. However, its current evaluation strategies are notably impractical: they solely update with well-curated structured facts (triplets with subjects, relations, and objects), whereas real-world knowledge updates commonly emerge in unstructured texts like news articles. In this paper, we propose a new benchmark, Unstructured Knowledge Editing (UKE). It evaluates editing performance directly using unstructured texts as knowledge updates, termed unstructured facts. Hence UKE avoids the laborious construction of structured facts and enables efficient and responsive knowledge editing, becoming a more practical benchmark. We conduct extensive experiments on newly built datasets and demonstrate that UKE poses a significant challenge to state-of-the-art knowledge editing methods, resulting in their critical performance declines. We further show that this challenge persists even if we extract triplets as structured facts. Our analysis discloses key insights to motivate future research in UKE for more practical knowledge editing.\n    ",
        "primary_category": "cs.CL",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18910": {
        "title": "DIGIC: Domain Generalizable Imitation Learning by Causal Discovery",
        "authors": [
            "Yang Chen",
            "Yitao Liang",
            "Zhouchen Lin"
        ],
        "comments": " ",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Causality has been combined with machine learning to produce robust representations for domain generalization. Most existing methods of this type require massive data from multiple domains to identify causal features by cross-domain variations, which can be expensive or even infeasible and may lead to misidentification in some cases. In this work, we make a different attempt by leveraging the demonstration data distribution to discover the causal features for a domain generalizable policy. We design a novel framework, called DIGIC, to identify the causal features by finding the direct cause of the expert action from the demonstration data distribution via causal discovery. Our framework can achieve domain generalizable imitation learning with only single-domain data and serve as a complement for cross-domain variation-based methods under non-structural assumptions on the underlying causal models. Our empirical study in various control tasks shows that the proposed framework evidently improves the domain generalization performance and has comparable performance to the expert in the original domain simultaneously.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.AI",
            "stat.ME"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18913": {
        "title": "AdaMergeX: Cross-Lingual Transfer with Large Language Models via Adaptive Adapter Merging",
        "authors": [
            "Yiran Zhao",
            "Wenxuan Zhang",
            "Huiming Wang",
            "Kenji Kawaguchi",
            "Lidong Bing"
        ],
        "comments": " ",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "As an effective alternative to the direct fine-tuning on target tasks in specific languages, cross-lingual transfer addresses the challenges of limited training data by decoupling ''task ability'' and ''language ability'' by fine-tuning on the target task in the source language and another selected task in the target language, respectively. However, they fail to fully separate the task ability from the source language or the language ability from the chosen task. In this paper, we acknowledge the mutual reliance between task ability and language ability and direct our attention toward the gap between the target language and the source language on tasks. As the gap removes the impact of tasks, we assume that it remains consistent across tasks. Based on this assumption, we propose a new cross-lingual transfer method called $\\texttt{AdaMergeX}$ that utilizes adaptive adapter merging. By introducing a reference task, we can determine that the divergence of adapters fine-tuned on the reference task in both languages follows the same distribution as the divergence of adapters fine-tuned on the target task in both languages. Hence, we can obtain target adapters by combining the other three adapters. Furthermore, we propose a structure-adaptive adapter merging method. Our empirical results demonstrate that our approach yields new and effective cross-lingual transfer, outperforming existing methods across all settings.\n    ",
        "primary_category": "cs.CL",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18917": {
        "title": "Stop Relying on No-Choice and Do not Repeat the Moves: Optimal, Efficient and Practical Algorithms for Assortment Optimization",
        "authors": [
            "Aadirupa Saha",
            "Pierre Gaillard"
        ],
        "comments": " ",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "We address the problem of active online assortment optimization problem with preference feedback, which is a framework for modeling user choices and subsetwise utility maximization. The framework is useful in various real-world applications including ad placement, online retail, recommender systems, fine-tuning language models, amongst many. The problem, although has been studied in the past, lacks an intuitive and practical solution approach with simultaneously efficient algorithm and optimal regret guarantee. E.g., popularly used assortment selection algorithms often require the presence of a `strong reference' which is always included in the choice sets, further they are also designed to offer the same assortments repeatedly until the reference item gets selected -- all such requirements are quite unrealistic for practical applications. In this paper, we designed efficient algorithms for the problem of regret minimization in assortment selection with \\emph{Plackett Luce} (PL) based user choices. We designed a novel concentration guarantee for estimating the score parameters of the PL model using `\\emph{Pairwise Rank-Breaking}', which builds the foundation of our proposed algorithms. Moreover, our methods are practical, provably optimal, and devoid of the aforementioned limitations of the existing methods. Empirical evaluations corroborate our findings and outperform the existing baselines.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.IR"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18919": {
        "title": "Decompose-and-Compose: A Compositional Approach to Mitigating Spurious Correlation",
        "authors": [
            "Fahimeh Hosseini Noohdani",
            "Parsa Hosseini",
            "Aryan Yazdan Parast",
            "Hamidreza Yaghoubi Araghi",
            "Mahdieh Soleymani Baghshah"
        ],
        "comments": " ",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "While standard Empirical Risk Minimization (ERM) training is proven effective for image classification on in-distribution data, it fails to perform well on out-of-distribution samples. One of the main sources of distribution shift for image classification is the compositional nature of images. Specifically, in addition to the main object or component(s) determining the label, some other image components usually exist, which may lead to the shift of input distribution between train and test environments. More importantly, these components may have spurious correlations with the label. To address this issue, we propose Decompose-and-Compose (DaC), which improves robustness to correlation shift by a compositional approach based on combining elements of images. Based on our observations, models trained with ERM usually highly attend to either the causal components or the components having a high spurious correlation with the label (especially in datapoints on which models have a high confidence). In fact, according to the amount of spurious correlation and the easiness of classification based on the causal or non-causal components, the model usually attends to one of these more (on samples with high confidence). Following this, we first try to identify the causal components of images using class activation maps of models trained with ERM. Afterward, we intervene on images by combining them and retraining the model on the augmented data, including the counterfactual ones. Along with its high interpretability, this work proposes a group-balancing method by intervening on images without requiring group labels or information regarding the spurious features during training. The method has an overall better worst group accuracy compared to previous methods with the same amount of supervision on the group labels in correlation shift.\n    ",
        "primary_category": "cs.CV",
        "categories": [
            "cs.LG"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18922": {
        "title": "A Simple yet Effective Network based on Vision Transformer for Camouflaged Object and Salient Object Detection",
        "authors": [
            "Chao Hao",
            "Zitong Yu",
            "Xin Liu",
            "Jun Xu",
            "Huanjing Yue",
            "Jingyu Yang"
        ],
        "comments": "submitted to IEEE TIP",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Camouflaged object detection (COD) and salient object detection (SOD) are two distinct yet closely-related computer vision tasks widely studied during the past decades. Though sharing the same purpose of segmenting an image into binary foreground and background regions, their distinction lies in the fact that COD focuses on concealed objects hidden in the image, while SOD concentrates on the most prominent objects in the image. Previous works achieved good performance by stacking various hand-designed modules and multi-scale features. However, these carefully-designed complex networks often performed well on one task but not on another. In this work, we propose a simple yet effective network (SENet) based on vision Transformer (ViT), by employing a simple design of an asymmetric ViT-based encoder-decoder structure, we yield competitive results on both tasks, exhibiting greater versatility than meticulously crafted ones. Furthermore, to enhance the Transformer's ability to model local information, which is important for pixel-level binary segmentation tasks, we propose a local information capture module (LICM). We also propose a dynamic weighted loss (DW loss) based on Binary Cross-Entropy (BCE) and Intersection over Union (IoU) loss, which guides the network to pay more attention to those smaller and more difficult-to-find target objects according to their size. Moreover, we explore the issue of joint training of SOD and COD, and propose a preliminary solution to the conflict in joint training, further improving the performance of SOD. Extensive experiments on multiple benchmark datasets demonstrate the effectiveness of our method. The code is available at this https URL.\n    ",
        "primary_category": "cs.CV",
        "categories": [],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18923": {
        "title": "Inappropriate Pause Detection In Dysarthric Speech Using Large-Scale Speech Recognition",
        "authors": [
            "Jeehyun Lee",
            "Yerin Choi",
            "Tae-Jin Song",
            "Myoung-Wan Koo"
        ],
        "comments": "Accepted to ICASSP 2024",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "Dysarthria, a common issue among stroke patients, severely impacts speech intelligibility. Inappropriate pauses are crucial indicators in severity assessment and speech-language therapy. We propose to extend a large-scale speech recognition model for inappropriate pause detection in dysarthric speech. To this end, we propose task design, labeling strategy, and a speech recognition model with an inappropriate pause prediction layer. First, we treat pause detection as speech recognition, using an automatic speech recognition (ASR) model to convert speech into text with pause tags. According to the newly designed task, we label pause locations at the text level and their appropriateness. We collaborate with speech-language pathologists to establish labeling criteria, ensuring high-quality annotated data. Finally, we extend the ASR model with an inappropriate pause prediction layer for end-to-end inappropriate pause detection. Moreover, we propose a task-tailored metric for evaluating inappropriate pause detection independent of ASR performance. Our experiments show that the proposed method better detects inappropriate pauses in dysarthric speech than baselines. (Inappropriate Pause Error Rate: 14.47%)\n    ",
        "primary_category": "cs.CL",
        "categories": [
            "cs.SD",
            "eess.AS"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18925": {
        "title": "PCDepth: Pattern-based Complementary Learning for Monocular Depth Estimation by Best of Both Worlds",
        "authors": [
            "Haotian Liu",
            "Sanqing Qu",
            "Fan Lu",
            "Zongtao Bu",
            "Florian Roehrbein",
            "Alois Knoll",
            "Guang Chen"
        ],
        "comments": "Under Review",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Event cameras can record scene dynamics with high temporal resolution, providing rich scene details for monocular depth estimation (MDE) even at low-level illumination. Therefore, existing complementary learning approaches for MDE fuse intensity information from images and scene details from event data for better scene understanding. However, most methods directly fuse two modalities at pixel level, ignoring that the attractive complementarity mainly impacts high-level patterns that only occupy a few pixels. For example, event data is likely to complement contours of scene objects. In this paper, we discretize the scene into a set of high-level patterns to explore the complementarity and propose a Pattern-based Complementary learning architecture for monocular Depth estimation (PCDepth). Concretely, PCDepth comprises two primary components: a complementary visual representation learning module for discretizing the scene into high-level patterns and integrating complementary patterns across modalities and a refined depth estimator aimed at scene reconstruction and depth prediction while maintaining an efficiency-accuracy balance. Through pattern-based complementary learning, PCDepth fully exploits two modalities and achieves more accurate predictions than existing methods, especially in challenging nighttime scenarios. Extensive experiments on MVSEC and DSEC datasets verify the effectiveness and superiority of our PCDepth. Remarkably, compared with state-of-the-art, PCDepth achieves a 37.9% improvement in accuracy in MVSEC nighttime scenarios.\n    ",
        "primary_category": "cs.CV",
        "categories": [],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18927": {
        "title": "Edge Computing Enabled Real-Time Video Analysis via Adaptive Spatial-Temporal Semantic Filtering",
        "authors": [
            "Xiang Chen",
            "Wenjie Zhu",
            "Jiayuan Chen",
            "Tong Zhang",
            "Changyan Yi",
            "Jun Cai"
        ],
        "comments": " ",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "This paper proposes a novel edge computing enabled real-time video analysis system for intelligent visual devices. The proposed system consists of a tracking-assisted object detection module (TAODM) and a region of interesting module (ROIM). TAODM adaptively determines the offloading decision to process each video frame locally with a tracking algorithm or to offload it to the edge server inferred by an object detection model. ROIM determines each offloading frame's resolution and detection model configuration to ensure that the analysis results can return in time. TAODM and ROIM interact jointly to filter the repetitive spatial-temporal semantic information to maximize the processing rate while ensuring high video analysis accuracy. Unlike most existing works, this paper investigates the real-time video analysis systems where the intelligent visual device connects to the edge server through a wireless network with fluctuating network conditions. We decompose the real-time video analysis problem into the offloading decision and configurations selection sub-problems. To solve these two sub-problems, we introduce a double deep Q network (DDQN) based offloading approach and a contextual multi-armed bandit (CMAB) based adaptive configurations selection approach, respectively. A DDQN-CMAB reinforcement learning (DCRL) training framework is further developed to integrate these two approaches to improve the overall video analyzing performance. Extensive simulations are conducted to evaluate the performance of the proposed solution, and demonstrate its superiority over counterparts.\n    ",
        "primary_category": "cs.CV",
        "categories": [
            "cs.MM",
            "cs.NI"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18929": {
        "title": "Navigating Beyond Dropout: An Intriguing Solution Towards Generalizable Image Super Resolution",
        "authors": [
            "Hongjun Wang",
            "Jiyuan Chen",
            "Yinqiang Zheng",
            "Tieyong Zeng"
        ],
        "comments": " ",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Deep learning has led to a dramatic leap on Single Image Super-Resolution (SISR) performances in recent years. %Despite the substantial advancement% While most existing work assumes a simple and fixed degradation model (e.g., bicubic downsampling), the research of Blind SR seeks to improve model generalization ability with unknown degradation. Recently, Kong et al pioneer the investigation of a more suitable training strategy for Blind SR using Dropout. Although such method indeed brings substantial generalization improvements via mitigating overfitting, we argue that Dropout simultaneously introduces undesirable side-effect that compromises model's capacity to faithfully reconstruct fine details. We show both the theoretical and experimental analyses in our paper, and furthermore, we present another easy yet effective training strategy that enhances the generalization ability of the model by simply modulating its first and second-order features statistics. Experimental results have shown that our method could serve as a model-agnostic regularization and outperforms Dropout on seven benchmark datasets including both synthetic and real-world scenarios.\n    ",
        "primary_category": "cs.CV",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18930": {
        "title": "Variable-Rate Learned Image Compression with Multi-Objective Optimization and Quantization-Reconstruction Offsets",
        "authors": [
            "Fatih Kamisli",
            "Fabien Racape",
            "Hyomin Choi"
        ],
        "comments": "Accepted as a paper at DCC 2024",
        "subjects": "Image and Video Processing (eess.IV)",
        "abstract": "Achieving successful variable bitrate compression with computationally simple algorithms from a single end-to-end learned image or video compression model remains a challenge. Many approaches have been proposed, including conditional auto-encoders, channel-adaptive gains for the latent tensor or uniformly quantizing all elements of the latent tensor. This paper follows the traditional approach to vary a single quantization step size to perform uniform quantization of all latent tensor elements. However, three modifications are proposed to improve the variable rate compression performance. First, multi objective optimization is used for (post) training. Second, a quantization-reconstruction offset is introduced into the quantization operation. Third, variable rate quantization is used also for the hyper latent. All these modifications can be made on a pre-trained single-rate compression model by performing post training. The algorithms are implemented into three well-known image compression models and the achieved variable rate compression results indicate negligible or minimal compression performance loss compared to training multiple models. (Codes will be shared at this https URL)\n    ",
        "primary_category": "eess.IV",
        "categories": [
            "cs.CV"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18932": {
        "title": "Extending Multilingual Speech Synthesis to 100+ Languages without Transcribed Data",
        "authors": [
            "Takaaki Saeki",
            "Gary Wang",
            "Nobuyuki Morioka",
            "Isaac Elias",
            "Kyle Kastner",
            "Andrew Rosenberg",
            "Bhuvana Ramabhadran",
            "Heiga Zen",
            "Fran\u00e7oise Beaufays",
            "Hadar Shemtov"
        ],
        "comments": "To appear in ICASSP 2024",
        "subjects": "Audio and Speech Processing (eess.AS)",
        "abstract": "Collecting high-quality studio recordings of audio is challenging, which limits the language coverage of text-to-speech (TTS) systems. This paper proposes a framework for scaling a multilingual TTS model to 100+ languages using found data without supervision. The proposed framework combines speech-text encoder pretraining with unsupervised training using untranscribed speech and unspoken text data sources, thereby leveraging massively multilingual joint speech and text representation learning. Without any transcribed speech in a new language, this TTS model can generate intelligible speech in >30 unseen languages (CER difference of <10% to ground truth). With just 15 minutes of transcribed, found data, we can reduce the intelligibility difference to 1% or less from the ground-truth, and achieve naturalness scores that match the ground-truth in several languages.\n    ",
        "primary_category": "eess.AS",
        "categories": [
            "cs.SD"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18936": {
        "title": "Energy-Efficient UAV Swarm Assisted MEC with Dynamic Clustering and Scheduling",
        "authors": [
            "Jialiuyuan Li",
            "Jiayuan Chen",
            "Changyan Yi",
            "Tong Zhang",
            "Kun Zhu",
            "Jun Cai"
        ],
        "comments": " ",
        "subjects": "Networking and Internet Architecture (cs.NI)",
        "abstract": "In this paper, the energy-efficient unmanned aerial vehicle (UAV) swarm assisted mobile edge computing (MEC) with dynamic clustering and scheduling is studied. In the considered system model, UAVs are divided into multiple swarms, with each swarm consisting of a leader UAV and several follower UAVs to provide computing services to end-users. Unlike existing work, we allow UAVs to dynamically cluster into different swarms, i.e., each follower UAV can change its leader based on the time-varying spatial positions, updated application placement, etc. in a dynamic manner. Meanwhile, UAVs are required to dynamically schedule their energy replenishment, application placement, trajectory planning and task delegation. With the aim of maximizing the long-term energy efficiency of the UAV swarm assisted MEC system, a joint optimization problem of dynamic clustering and scheduling is formulated. Taking into account the underlying cooperation and competition among intelligent UAVs, we further reformulate this optimization problem as a combination of a series of strongly coupled multi-agent stochastic games, and then propose a novel reinforcement learning-based UAV swarm dynamic coordination (RLDC) algorithm for obtaining the equilibrium. Simulations are conducted to evaluate the performance of the RLDC algorithm and demonstrate its superiority over counterparts.\n    ",
        "primary_category": "cs.NI",
        "categories": [
            "eess.SP"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18937": {
        "title": "Equivalence of ADER and Lax-Wendroff in DG / FR framework for linear problems",
        "authors": [
            "Arpit Babbar",
            "Praveen Chandrashekar"
        ],
        "comments": " ",
        "subjects": "Numerical Analysis (math.NA)",
        "abstract": "ADER (Arbitrary high order by DERivatives) and Lax-Wendroff (LW) schemes are two high order single stage methods for solving time dependent partial differential equations. ADER is based on solving a locally implicit equation to obtain a space-time predictor solution while LW is based on an explicit Taylor's expansion in time. We cast the corrector step of ADER Discontinuous Galerkin (DG) scheme into an equivalent quadrature free Flux Reconstruction (FR) framework and then show that the obtained ADER-FR scheme is equivalent to the LWFR scheme with D2 dissipation numerical flux for linear problems. This also implies that the two schemes have the same Fourier stability limit for time step size. The equivalence is verified by numerical experiments.\n    ",
        "primary_category": "math.NA",
        "categories": [],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18944": {
        "title": "SemEval 2024 -- Task 10: Emotion Discovery and Reasoning its Flip in Conversation (EDiReF)",
        "authors": [
            "Shivani Kumar",
            "Md Shad Akhtar",
            "Erik Cambria",
            "Tanmoy Chakraborty"
        ],
        "comments": "11 pages, 3 figures, 7 tables",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "We present SemEval-2024 Task 10, a shared task centred on identifying emotions and finding the rationale behind their flips within monolingual English and Hindi-English code-mixed dialogues. This task comprises three distinct subtasks - emotion recognition in conversation for code-mixed dialogues, emotion flip reasoning for code-mixed dialogues, and emotion flip reasoning for English dialogues. Participating systems were tasked to automatically execute one or more of these subtasks. The datasets for these tasks comprise manually annotated conversations focusing on emotions and triggers for emotion shifts (The task data is available at this https URL). A total of 84 participants engaged in this task, with the most adept systems attaining F1-scores of 0.70, 0.79, and 0.76 for the respective subtasks. This paper summarises the results and findings from 24 teams alongside their system descriptions.\n    ",
        "primary_category": "cs.CL",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18945": {
        "title": "Syntactic Ghost: An Imperceptible General-purpose Backdoor Attacks on Pre-trained Language Models",
        "authors": [
            "Pengzhou Cheng",
            "Wei Du",
            "Zongru Wu",
            "Fengwei Zhang",
            "Libo Chen",
            "Gongshen Liu"
        ],
        "comments": "16 pages, 16 figures, 13 tables",
        "subjects": "Cryptography and Security (cs.CR)",
        "abstract": "Pre-trained language models (PLMs) have been found susceptible to backdoor attacks, which can transfer vulnerabilities to various downstream tasks. However, existing PLM backdoors are conducted with explicit triggers under the manually aligned, thus failing to satisfy expectation goals simultaneously in terms of effectiveness, stealthiness, and universality. In this paper, we propose a novel approach to achieve invisible and general backdoor implantation, called \\textbf{Syntactic Ghost} (synGhost for short). Specifically, the method hostilely manipulates poisoned samples with different predefined syntactic structures as stealth triggers and then implants the backdoor to pre-trained representation space without disturbing the primitive knowledge. The output representations of poisoned samples are distributed as uniformly as possible in the feature space via contrastive learning, forming a wide range of backdoors. Additionally, in light of the unique properties of syntactic triggers, we introduce an auxiliary module to drive the PLMs to learn this knowledge in priority, which can alleviate the interference between different syntactic structures. Experiments show that our method outperforms the previous methods and achieves the predefined objectives. Not only do severe threats to various natural language understanding (NLU) tasks on two tuning paradigms but also to multiple PLMs. Meanwhile, the synGhost is imperceptible against three countermeasures based on perplexity, fine-pruning, and the proposed maxEntropy.\n    ",
        "primary_category": "cs.CR",
        "categories": [
            "cs.AI",
            "cs.CL"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18949": {
        "title": "Improving Group Connectivity for Generalization of Federated Deep Learning",
        "authors": [
            "Zexi Li",
            "Jie Lin",
            "Zhiqi Li",
            "Didi Zhu",
            "Chao Wu"
        ],
        "comments": "Preprint",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Federated learning (FL) involves multiple heterogeneous clients collaboratively training a global model via iterative local updates and model fusion. The generalization of FL's global model has a large gap compared with centralized training, which is its bottleneck for broader applications. In this paper, we study and improve FL's generalization through a fundamental ``connectivity'' perspective, which means how the local models are connected in the parameter region and fused into a generalized global model. The term ``connectivity'' is derived from linear mode connectivity (LMC), studying the interpolated loss landscape of two different solutions (e.g., modes) of neural networks. Bridging the gap between LMC and FL, in this paper, we leverage fixed anchor models to empirically and theoretically study the transitivity property of connectivity from two models (LMC) to a group of models (model fusion in FL). Based on the findings, we propose FedGuCci and FedGuCci+, improving group connectivity for better generalization. It is shown that our methods can boost the generalization of FL under client heterogeneity across various tasks (4 CV datasets and 6 NLP datasets), models (both convolutional and transformer-based), and training paradigms (both from-scratch and pretrain-finetune).\n    ",
        "primary_category": "cs.LG",
        "categories": [],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18950": {
        "title": "PopALM: Popularity-Aligned Language Models for Social Media Trendy Response Prediction",
        "authors": [
            "Erxin Yu",
            "Jing Li",
            "Chunpu Xu"
        ],
        "comments": "Accepted by COLING 2024",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "Social media platforms are daily exhibiting millions of events. To preliminarily predict the mainstream public reaction to these events, we study trendy response prediction to automatically generate top-liked user replies to social media events. While previous works focus on generating responses without factoring in popularity, we propose Popularity-Aligned Language Models (PopALM) to distinguish responses liked by a larger audience through reinforcement learning. Recognizing the noisy labels from user \"likes\", we tailor-make curriculum learning in proximal policy optimization (PPO) to help models capture the essential samples for easy-to-hard training. In experiments, we build a large-scale Weibo dataset for trendy response prediction, and its results show that PopALM can help boost the performance of advanced language models.\n    ",
        "primary_category": "cs.CL",
        "categories": [],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18951": {
        "title": "Percept, Chat, and then Adapt: Multimodal Knowledge Transfer of Foundation Models for Open-World Video Recognition",
        "authors": [
            "Boyu Chen",
            "Siran Chen",
            "Kunchang Li",
            "Qinglin Xu",
            "Yu Qiao",
            "Yali Wang"
        ],
        "comments": "35 pages, 6 figures, 8 tables",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Open-world video recognition is challenging since traditional networks are not generalized well on complex environment variations. Alternatively, foundation models with rich knowledge have recently shown their generalization power. However, how to apply such knowledge has not been fully explored for open-world video recognition. To this end, we propose a generic knowledge transfer pipeline, which progressively exploits and integrates external multimodal knowledge from foundation models to boost open-world video recognition. We name it PCA, based on three stages of Percept, Chat, and Adapt. First, we perform Percept process to reduce the video domain gap and obtain external visual knowledge. Second, we generate rich linguistic semantics as external textual knowledge in Chat stage. Finally, we blend external multimodal knowledge in Adapt stage, by inserting multimodal knowledge adaptation modules into networks. We conduct extensive experiments on three challenging open-world video benchmarks, i.e., TinyVIRAT, ARID, and QV-Pipe. Our approach achieves state-of-the-art performance on all three datasets.\n    ",
        "primary_category": "cs.CV",
        "categories": [],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18954": {
        "title": "Getting Saturated with Induction",
        "authors": [
            "M\u00e1rton Hajdu",
            "Petra Hozzov\u00e1",
            "Laura Kov\u00e1cs",
            "Giles Reger",
            "Andrei Voronkov"
        ],
        "comments": "26 pages; this is an extended version of the published paper",
        "subjects": "Logic in Computer Science (cs.LO)",
        "abstract": "Induction in saturation-based first-order theorem proving is a new exciting direction in the automation of inductive reasoning. In this paper we survey our work on integrating induction directly into the saturation-based proof search framework of first-order theorem proving. We describe our induction inference rules proving properties with inductively defined datatypes and integers. We also present additional reasoning heuristics for strengthening inductive reasoning, as well as for using induction hypotheses and recursive function definitions for guiding induction. We present exhaustive experimental results demonstrating the practical impact of our approach as implemented within Vampire.\nThis is an extended version of a Principles of Systems Design 2022 paper with the same title and the same authors.\n    ",
        "primary_category": "cs.LO",
        "categories": [],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18958": {
        "title": "Boosting Semi-Supervised Object Detection in Remote Sensing Images With Active Teaching",
        "authors": [
            "Boxuan Zhang",
            "Zengmao Wang",
            "Bo Du"
        ],
        "comments": " ",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "The lack of object-level annotations poses a significant challenge for object detection in remote sensing images (RSIs). To address this issue, active learning (AL) and semi-supervised learning (SSL) techniques have been proposed to enhance the quality and quantity of annotations. AL focuses on selecting the most informative samples for annotation, while SSL leverages the knowledge from unlabeled samples. In this letter, we propose a novel AL method to boost semi-supervised object detection (SSOD) for remote sensing images with a teacher student network, called SSOD-AT. The proposed method incorporates an RoI comparison module (RoICM) to generate high-confidence pseudo-labels for regions of interest (RoIs). Meanwhile, the RoICM is utilized to identify the top-K uncertain images. To reduce redundancy in the top-K uncertain images for human labeling, a diversity criterion is introduced based on object-level prototypes of different categories using both labeled and pseudo-labeled images. Extensive experiments on DOTA and DIOR, two popular datasets, demonstrate that our proposed method outperforms state-of-the-art methods for object detection in RSIs. Compared with the best performance in the SOTA methods, the proposed method achieves 1 percent improvement in most cases in the whole AL.\n    ",
        "primary_category": "cs.CV",
        "categories": [],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18959": {
        "title": "MambaStock: Selective state space model for stock prediction",
        "authors": [
            "Zhuangwei Shi"
        ],
        "comments": "arXiv admin note: substantial text overlap with arXiv:2204.02623",
        "subjects": "Computational Engineering, Finance, and Science (cs.CE)",
        "abstract": "The stock market plays a pivotal role in economic development, yet its intricate volatility poses challenges for investors. Consequently, research and accurate predictions of stock price movements are crucial for mitigating risks. Traditional time series models fall short in capturing nonlinearity, leading to unsatisfactory stock predictions. This limitation has spurred the widespread adoption of neural networks for stock prediction, owing to their robust nonlinear generalization capabilities. Recently, Mamba, a structured state space sequence model with a selection mechanism and scan module (S6), has emerged as a powerful tool in sequence modeling tasks. Leveraging this framework, this paper proposes a novel Mamba-based model for stock price prediction, named MambaStock. The proposed MambaStock model effectively mines historical stock market data to predict future stock prices without handcrafted features or extensive preprocessing procedures. Empirical studies on several stocks indicate that the MambaStock model outperforms previous methods, delivering highly accurate predictions. This enhanced accuracy can assist investors and institutions in making informed decisions, aiming to maximize returns while minimizing risks. This work underscores the value of Mamba in time-series forecasting. Source code is available at this https URL.\n    ",
        "primary_category": "cs.CE",
        "categories": [
            "q-fin.ST"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18960": {
        "title": "Towards Out-of-Distribution Detection for breast cancer classification in Point-of-Care Ultrasound Imaging",
        "authors": [
            "Jennie Karlsson",
            "Marisa Wodrich",
            "Niels Christian Overgaard",
            "Freja Sahlin",
            "Kristina L\u00e5ng",
            "Anders Heyden",
            "Ida Arvidsson"
        ],
        "comments": " ",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Deep learning has shown to have great potential in medical applications. In critical domains as such, it is of high interest to have trustworthy algorithms which are able to tell when reliable assessments cannot be guaranteed. Detecting out-of-distribution (OOD) samples is a crucial step towards building a safe classifier. Following a previous study, showing that it is possible to classify breast cancer in point-of-care ultrasound images, this study investigates OOD detection using three different methods: softmax, energy score and deep ensembles. All methods are tested on three different OOD data sets. The results show that the energy score method outperforms the softmax method, performing well on two of the data sets. The ensemble method is the most robust, performing the best at detecting OOD samples for all three OOD data sets.\n    ",
        "primary_category": "cs.CV",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18962": {
        "title": "Program Synthesis in Saturation",
        "authors": [
            "Petra Hozzov\u00e1",
            "Laura Kov\u00e1cs",
            "Chase Norman",
            "Andrei Voronkov"
        ],
        "comments": "23 pages; this is an extended version of the published paper",
        "subjects": "Logic in Computer Science (cs.LO)",
        "abstract": "We present an automated reasoning framework for synthesizing recursion-free programs using saturation-based theorem proving. Given a functional specification encoded as a first-order logical formula, we use a first-order theorem prover to both establish validity of this formula and discover program fragments satisfying the specification. As a result, when deriving a proof of program correctness, we also synthesize a program that is correct with respect to the given specification. We describe properties of the calculus that a saturation-based prover capable of synthesis should employ, and extend the superposition calculus in a corresponding way. We implemented our work in the first-order prover Vampire, extending the successful applicability of first-order proving to program synthesis.\nThis is an extended version of an Automated Deduction -- CADE 29 paper with the same title and the same authors.\n    ",
        "primary_category": "cs.LO",
        "categories": [],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18968": {
        "title": "Ambisonics Networks -- The Effect Of Radial Functions Regularization",
        "authors": [
            "Bar Shaybet",
            "Anurag Kumar",
            "Vladimir Tourbabin",
            "Boaz Rafaely"
        ],
        "comments": "to be published in Icassp 2024",
        "subjects": "Audio and Speech Processing (eess.AS)",
        "abstract": "Ambisonics, a popular format of spatial audio, is the spherical harmonic (SH) representation of the plane wave density function of a sound field. Many algorithms operate in the SH domain and utilize the Ambisonics as their input signal. The process of encoding Ambisonics from a spherical microphone array involves dividing by the radial functions, which may amplify noise at low frequencies. This can be overcome by regularization, with the downside of introducing errors to the Ambisonics encoding. This paper aims to investigate the impact of different ways of regularization on Deep Neural Network (DNN) training and performance. Ideally, these networks should be robust to the way of regularization. Simulated data of a single speaker in a room and experimental data from the LOCATA challenge were used to evaluate this robustness on an example algorithm of speaker localization based on the direct-path dominance (DPD) test. Results show that performance may be sensitive to the way of regularization, and an informed approach is proposed and investigated, highlighting the importance of regularization information.\n    ",
        "primary_category": "eess.AS",
        "categories": [
            "cs.SD"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18969": {
        "title": "OHTA: One-shot Hand Avatar via Data-driven Implicit Priors",
        "authors": [
            "Xiaozheng Zheng",
            "Chao Wen",
            "Zhuo Su",
            "Zeran Xu",
            "Zhaohu Li",
            "Yang Zhao",
            "Zhou Xue"
        ],
        "comments": "Accepted to CVPR 2024. Project page: this https URL",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "In this paper, we delve into the creation of one-shot hand avatars, attaining high-fidelity and drivable hand representations swiftly from a single image. With the burgeoning domains of the digital human, the need for quick and personalized hand avatar creation has become increasingly critical. Existing techniques typically require extensive input data and may prove cumbersome or even impractical in certain scenarios. To enhance accessibility, we present a novel method OHTA (One-shot Hand avaTAr) that enables the creation of detailed hand avatars from merely one image. OHTA tackles the inherent difficulties of this data-limited problem by learning and utilizing data-driven hand priors. Specifically, we design a hand prior model initially employed for 1) learning various hand priors with available data and subsequently for 2) the inversion and fitting of the target identity with prior knowledge. OHTA demonstrates the capability to create high-fidelity hand avatars with consistent animatable quality, solely relying on a single image. Furthermore, we illustrate the versatility of OHTA through diverse applications, encompassing text-to-avatar conversion, hand editing, and identity latent space manipulation.\n    ",
        "primary_category": "cs.CV",
        "categories": [],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18970": {
        "title": "PrivatEyes: Appearance-based Gaze Estimation Using Federated Secure Multi-Party Computation",
        "authors": [
            "Mayar Elfares",
            "Pascal Reisert",
            "Zhiming Hu",
            "Wenwu Tang",
            "Ralf K\u00fcsters",
            "Andreas Bulling"
        ],
        "comments": " ",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Latest gaze estimation methods require large-scale training data but their collection and exchange pose significant privacy risks. We propose PrivatEyes - the first privacy-enhancing training approach for appearance-based gaze estimation based on federated learning (FL) and secure multi-party computation (MPC). PrivatEyes enables training gaze estimators on multiple local datasets across different users and server-based secure aggregation of the individual estimators' updates. PrivatEyes guarantees that individual gaze data remains private even if a majority of the aggregating servers is malicious. We also introduce a new data leakage attack DualView that shows that PrivatEyes limits the leakage of private training data more effectively than previous approaches. Evaluations on the MPIIGaze, MPIIFaceGaze, GazeCapture, and NVGaze datasets further show that the improved privacy does not lead to a lower gaze estimation accuracy or substantially higher computational costs - both of which are on par with its non-secure counterparts.\n    ",
        "primary_category": "cs.CV",
        "categories": [
            "cs.HC"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18973": {
        "title": "Privacy Management and Interface Design for a Smart House",
        "authors": [
            "Ana-Maria Comeaga",
            "Iuliana Marin"
        ],
        "comments": " ",
        "subjects": "Cryptography and Security (cs.CR)",
        "abstract": "In today's life, more and more people tend to opt for a smart house. In this way, the idea of including technology has become popular worldwide. Despite this concept's many benefits, managing security remains an essential problem due to the shared activities. The Internet of Things system behind a smart house is based on several sensors to measure temperature, humidity, air quality, and movement. Because of being supervised every day through sensors and controlling their house only with a simple click, many people can be afraid of this new approach in terms of their privacy, and this fact can constrain them from following their habits. The security aspects should be constantly analyzed to keep the data's confidentiality and make people feel safe in their own houses. In this context, the current paper puts light on an alternative design of a platform in which the safety of homeowners is the primary purpose, and they maintain complete control over the data generated by smart devices. The current research highlights the role of security and interface design in controlling a smart house. The study underscores the importance of providing an interface that can be used easily by any person to manage data and live activities in a modern residence in an era dominated by continuously developing technology.\n    ",
        "primary_category": "cs.CR",
        "categories": [
            "cs.SE"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18974": {
        "title": "Graph Generation via Spectral Diffusion",
        "authors": [
            "Giorgia Minello",
            "Alessandro Bicciato",
            "Luca Rossi",
            "Andrea Torsello",
            "Luca Cosmo"
        ],
        "comments": " ",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "In this paper, we present GRASP, a novel graph generative model based on 1) the spectral decomposition of the graph Laplacian matrix and 2) a diffusion process. Specifically, we propose to use a denoising model to sample eigenvectors and eigenvalues from which we can reconstruct the graph Laplacian and adjacency matrix. Our permutation invariant model can also handle node features by concatenating them to the eigenvectors of each node. Using the Laplacian spectrum allows us to naturally capture the structural characteristics of the graph and work directly in the node space while avoiding the quadratic complexity bottleneck that limits the applicability of other methods. This is achieved by truncating the spectrum, which as we show in our experiments results in a faster yet accurate generative process. An extensive set of experiments on both synthetic and real world graphs demonstrates the strengths of our model against state-of-the-art alternatives.\n    ",
        "primary_category": "cs.LG",
        "categories": [],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18980": {
        "title": "Helper Data Schemes for Coded Modulation and Shaping in Physical Unclonable Functions",
        "authors": [
            "Robert F.H. Fischer"
        ],
        "comments": " ",
        "subjects": "Information Theory (cs.IT)",
        "abstract": "In this paper, we consider the generation and utilization of helper data for physical unclonable functions (PUFs) that provide real-valued readout symbols. Compared to classical binary PUFs, more entropy can be extracted from each basic building block (PUF node), resulting in longer keys/fingerprints and/or a higher reliability. To this end, a coded modulation and signal shaping scheme that matches the (approximately) Gaussian distribution of the readout has to be employed. A new helper data scheme is proposed that works with any type of coded modulation/shaping scheme. Compared to the permutation scheme from the literature, less amount of helper data has to be generated and a higher reliability is achieved. Moreover, the recently proposed idea of a two-metric helper data scheme is generalized to coded modulation and a general S-metric scheme. It is shown how extra helper data can be generated to improve decodability. The proposed schemes are assessed by numerical simulations and by evaluation of measurement data. We compare multi-level codes using a new rate design strategy with bit-interleaved coded modulation and trellis shaping with a distribution matcher. By selecting a suitable design, the rate per PUF node that can be reliably extracted can be as high as 2~bit/node.\n    ",
        "primary_category": "cs.IT",
        "categories": [],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18982": {
        "title": "Splitting integrators for linear Vlasov equations with stochastic perturbations",
        "authors": [
            "Charles-Edouard Br\u00e9hier",
            "David Cohen"
        ],
        "comments": " ",
        "subjects": "Numerical Analysis (math.NA)",
        "abstract": "We consider a class of linear Vlasov partial differential equations driven by Wiener noise. Different types of stochastic perturbations are treated: additive noise, multiplicative It\u00f4 and Stratonovich noise, and transport noise. We propose to employ splitting integrators for the temporal discretization of these stochastic partial differential equations. These integrators are designed in order to preserve qualitative properties of the exact solutions depending on the stochastic perturbation, such as preservation of norms or positivity of the solutions. We provide numerical experiments in order to illustrate the properties of the proposed integrators and investigate mean-square rates of convergence.\n    ",
        "primary_category": "math.NA",
        "categories": [
            "math.PR"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18984": {
        "title": "Graph Burning: Bounds and Hardness",
        "authors": [
            "Dhanyamol Antony",
            "Anita Das",
            "Shirish Gosavi",
            "Dalu Jacob",
            "Shashanka Kulamarva"
        ],
        "comments": "22 pages, 6 figures",
        "subjects": "Combinatorics (math.CO)",
        "abstract": "The burning number of a graph $G$, denoted by $b(G)$, is the minimum number of steps required to burn all the vertices of a graph where in each step the existing fire spreads to all the adjacent vertices and one additional vertex can be burned as a new fire source. In this paper, we study the burning number problem both from an algorithmic and a structural point of view. The decision problem of computing the burning number of an input graph is known to be NP-Complete for trees with maximum degree at most three and interval graphs. Here, we prove that this problem is NP-Complete even when restricted to connected proper interval graphs and connected cubic graphs. The well-known burning number conjecture asserts that all the vertices of any graph of order $n$ can be burned in $\\lceil \\sqrt{n}~\\rceil$ steps. In line with this conjecture, upper and lower bounds of $b(G)$ are well-studied for various special graph classes. Here, we provide an improved upper bound for the burning number of connected $P_k$-free graphs and show that the bound is tight up to an additive constant $1$. Finally, we study two variants of the problem, namely edge burning (only edges are burned) and total burning (both vertices and edges are burned). In particular, we establish their relationship with the burning number problem and evaluate the complexity of these variants.\n    ",
        "primary_category": "math.CO",
        "categories": [
            "cs.DM"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18986": {
        "title": "Always be Pre-Training: Representation Learning for Network Intrusion Detection with GNNs",
        "authors": [
            "Zhengyao Gu",
            "Diego Troy Lopez",
            "Lilas Alrahis",
            "Ozgur Sinanoglu"
        ],
        "comments": "Will appear in the 2024 International Symposium on Quality Electronic Design (ISQED'24)",
        "subjects": "Cryptography and Security (cs.CR)",
        "abstract": "Graph neural network-based network intrusion detection systems have recently demonstrated state-of-the-art performance on benchmark datasets. Nevertheless, these methods suffer from a reliance on target encoding for data pre-processing, limiting widespread adoption due to the associated need for annotated labels--a cost-prohibitive requirement. In this work, we propose a solution involving in-context pre-training and the utilization of dense representations for categorical features to jointly overcome the label-dependency limitation. Our approach exhibits remarkable data efficiency, achieving over 98% of the performance of the supervised state-of-the-art with less than 4% labeled data on the NF-UQ-NIDS-V2 dataset.\n    ",
        "primary_category": "cs.CR",
        "categories": [],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18994": {
        "title": "Spyx: A Library for Just-In-Time Compiled Optimization of Spiking Neural Networks",
        "authors": [
            "Kade M. Heckel",
            "Thomas Nowotny"
        ],
        "comments": " ",
        "subjects": "Neural and Evolutionary Computing (cs.NE)",
        "abstract": "As the role of artificial intelligence becomes increasingly pivotal in modern society, the efficient training and deployment of deep neural networks have emerged as critical areas of focus. Recent advancements in attention-based large neural architectures have spurred the development of AI accelerators, facilitating the training of extensive, multi-billion parameter models. Despite their effectiveness, these powerful networks often incur high execution costs in production environments. Neuromorphic computing, inspired by biological neural processes, offers a promising alternative. By utilizing temporally-sparse computations, Spiking Neural Networks (SNNs) offer to enhance energy efficiency through a reduced and low-power hardware footprint. However, the training of SNNs can be challenging due to their recurrent nature which cannot as easily leverage the massive parallelism of modern AI accelerators. To facilitate the investigation of SNN architectures and dynamics researchers have sought to bridge Python-based deep learning frameworks such as PyTorch or TensorFlow with custom-implemented compute kernels. This paper introduces Spyx, a new and lightweight SNN simulation and optimization library designed in JAX. By pre-staging data in the expansive vRAM of contemporary accelerators and employing extensive JIT compilation, Spyx allows for SNN optimization to be executed as a unified, low-level program on NVIDIA GPUs or Google TPUs. This approach achieves optimal hardware utilization, surpassing the performance of many existing SNN training frameworks while maintaining considerable flexibility.\n    ",
        "primary_category": "cs.NE",
        "categories": [
            "cs.LG"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18995": {
        "title": "Negative-Binomial Randomized Gamma Markov Processes for Heterogeneous Overdispersed Count Time Series",
        "authors": [
            "Rui Huang",
            "Sikun Yang",
            "Heinz Koeppl"
        ],
        "comments": " ",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Modeling count-valued time series has been receiving increasing attention since count time series naturally arise in physical and social domains. Poisson gamma dynamical systems (PGDSs) are newly-developed methods, which can well capture the expressive latent transition structure and bursty dynamics behind count sequences. In particular, PGDSs demonstrate superior performance in terms of data imputation and prediction, compared with canonical linear dynamical system (LDS) based methods. Despite these advantages, PGDS cannot capture the heterogeneous overdispersed behaviours of the underlying dynamic processes. To mitigate this defect, we propose a negative-binomial-randomized gamma Markov process, which not only significantly improves the predictive performance of the proposed dynamical system, but also facilitates the fast convergence of the inference algorithm. Moreover, we develop methods to estimate both factor-structured and graph-structured transition dynamics, which enable us to infer more explainable latent structure, compared with PGDSs. Finally, we demonstrate the explainable latent structure learned by the proposed method, and show its superior performance in imputing missing data and forecasting future observations, compared with the related models.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.AI",
            "stat.ML"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18998": {
        "title": "COFT-AD: COntrastive Fine-Tuning for Few-Shot Anomaly Detection",
        "authors": [
            "Jingyi Liao",
            "Xun Xu",
            "Manh Cuong Nguyen",
            "Adam Goodge",
            "Chuan Sheng Foo"
        ],
        "comments": "IEEE Transactions on Image Processing",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Existing approaches towards anomaly detection~(AD) often rely on a substantial amount of anomaly-free data to train representation and density models. However, large anomaly-free datasets may not always be available before the inference stage; in which case an anomaly detection model must be trained with only a handful of normal samples, a.k.a. few-shot anomaly detection (FSAD). In this paper, we propose a novel methodology to address the challenge of FSAD which incorporates two important techniques. Firstly, we employ a model pre-trained on a large source dataset to initialize model weights. Secondly, to ameliorate the covariate shift between source and target domains, we adopt contrastive training to fine-tune on the few-shot target domain data. To learn suitable representations for the downstream AD task, we additionally incorporate cross-instance positive pairs to encourage a tight cluster of the normal samples, and negative pairs for better separation between normal and synthesized negative samples. We evaluate few-shot anomaly detection on on 3 controlled AD tasks and 4 real-world AD tasks to demonstrate the effectiveness of the proposed method.\n    ",
        "primary_category": "cs.CV",
        "categories": [],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19002": {
        "title": "GoalNet: Goal Areas Oriented Pedestrian Trajectory Prediction",
        "authors": [
            "Ching-Lin Lee",
            "Zhi-Xuan Wang",
            "Kuan-Ting Lai",
            "Amar Fadillah"
        ],
        "comments": " ",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Predicting the future trajectories of pedestrians on the road is an important task for autonomous driving. The pedestrian trajectory prediction is affected by scene paths, pedestrian's intentions and decision-making, which is a multi-modal problem. Most recent studies use past trajectories to predict a variety of potential future trajectory distributions, which do not account for the scene context and pedestrian targets. Instead of predicting the future trajectory directly, we propose to use scene context and observed trajectory to predict the goal points first, and then reuse the goal points to predict the future trajectories. By leveraging the information from scene context and observed trajectory, the uncertainty can be limited to a few target areas, which represent the \"goals\" of the pedestrians. In this paper, we propose GoalNet, a new trajectory prediction neural network based on the goal areas of a pedestrian. Our network can predict both pedestrian's trajectories and bounding boxes. The overall model is efficient and modular, and its outputs can be changed according to the usage scenario. Experimental results show that GoalNet significantly improves the previous state-of-the-art performance by 48.7% on the JAAD and 40.8% on the PIE dataset.\n    ",
        "primary_category": "cs.CV",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19004": {
        "title": "RSAM-Seg: A SAM-based Approach with Prior Knowledge Integration for Remote Sensing Image Semantic Segmentation",
        "authors": [
            "Jie Zhang",
            "Xubing Yang",
            "Rui Jiang",
            "Wei Shao",
            "Li Zhang"
        ],
        "comments": "12 pages, 11 figures",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "The development of high-resolution remote sensing satellites has provided great convenience for research work related to remote sensing. Segmentation and extraction of specific targets are essential tasks when facing the vast and complex remote sensing images. Recently, the introduction of Segment Anything Model (SAM) provides a universal pre-training model for image segmentation tasks. While the direct application of SAM to remote sensing image segmentation tasks does not yield satisfactory results, we propose RSAM-Seg, which stands for Remote Sensing SAM with Semantic Segmentation, as a tailored modification of SAM for the remote sensing field and eliminates the need for manual intervention to provide prompts. Adapter-Scale, a set of supplementary scaling modules, are proposed in the multi-head attention blocks of the encoder part of SAM. Furthermore, Adapter-Feature are inserted between the Vision Transformer (ViT) blocks. These modules aim to incorporate high-frequency image information and image embedding features to generate image-informed prompts. Experiments are conducted on four distinct remote sensing scenarios, encompassing cloud detection, field monitoring, building detection and road mapping tasks . The experimental results not only showcase the improvement over the original SAM and U-Net across cloud, buildings, fields and roads scenarios, but also highlight the capacity of RSAM-Seg to discern absent areas within the ground truth of certain datasets, affirming its potential as an auxiliary annotation method. In addition, the performance in few-shot scenarios is commendable, underscores its potential in dealing with limited datasets.\n    ",
        "primary_category": "cs.CV",
        "categories": [
            "eess.IV"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19007": {
        "title": "DOZE: A Dataset for Open-Vocabulary Zero-Shot Object Navigation in Dynamic Environments",
        "authors": [
            "Ji Ma",
            "Hongming Dai",
            "Yao Mu",
            "Pengying Wu",
            "Hao Wang",
            "Xiaowei Chi",
            "Yang Fei",
            "Shanghang Zhang",
            "Chang Liu"
        ],
        "comments": " ",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Zero-Shot Object Navigation (ZSON) requires agents to autonomously locate and approach unseen objects in unfamiliar environments and has emerged as a particularly challenging task within the domain of Embodied AI. Existing datasets for developing ZSON algorithms lack consideration of dynamic obstacles, object attribute diversity, and scene texts, thus exhibiting noticeable discrepancy from real-world situations. To address these issues, we propose a Dataset for Open-Vocabulary Zero-Shot Object Navigation in Dynamic Environments (DOZE) that comprises ten high-fidelity 3D scenes with over 18k tasks, aiming to mimic complex, dynamic real-world scenarios. Specifically, DOZE scenes feature multiple moving humanoid obstacles, a wide array of open-vocabulary objects, diverse distinct-attribute objects, and valuable textual hints. Besides, different from existing datasets that only provide collision checking between the agent and static obstacles, we enhance DOZE by integrating capabilities for detecting collisions between the agent and moving obstacles. This novel functionality enables evaluation of the agents' collision avoidance abilities in dynamic environments. We test four representative ZSON methods on DOZE, revealing substantial room for improvement in existing approaches concerning navigation efficiency, safety, and object recognition accuracy. Our dataset could be found at this https URL.\n    ",
        "primary_category": "cs.CV",
        "categories": [
            "cs.RO"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19009": {
        "title": "Generating, Reconstructing, and Representing Discrete and Continuous Data: Generalized Diffusion with Learnable Encoding-Decoding",
        "authors": [
            "Guangyi Liu",
            "Yu Wang",
            "Zeyu Feng",
            "Qiyu Wu",
            "Liping Tang",
            "Yuan Gao",
            "Zhen Li",
            "Shuguang Cui",
            "Julian McAuley",
            "Eric P. Xing",
            "Zichao Yang",
            "Zhiting Hu"
        ],
        "comments": " ",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "The vast applications of deep generative models are anchored in three core capabilities -- generating new instances, reconstructing inputs, and learning compact representations -- across various data types, such as discrete text/protein sequences and continuous images. Existing model families, like Variational Autoencoders (VAEs), Generative Adversarial Networks (GANs), autoregressive models, and diffusion models, generally excel in specific capabilities and data types but fall short in others. We introduce generalized diffusion with learnable encoder-decoder (DiLED), that seamlessly integrates the core capabilities for broad applicability and enhanced performance. DiLED generalizes the Gaussian noising-denoising in standard diffusion by introducing parameterized encoding-decoding. Crucially, DiLED is compatible with the well-established diffusion model objective and training recipes, allowing effective learning of the encoder-decoder parameters jointly with diffusion. By choosing appropriate encoder/decoder (e.g., large language models), DiLED naturally applies to different data types. Extensive experiments on text, proteins, and images demonstrate DiLED's flexibility to handle diverse data and tasks and its strong improvement over various existing models.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19011": {
        "title": "Ruledger: Ensuring Execution Integrity in Trigger-Action IoT Platforms",
        "authors": [
            "Jingwen Fan",
            "Yi He",
            "Bo Tang",
            "Qi Li",
            "Ravi Sandhu"
        ],
        "comments": " ",
        "subjects": "Cryptography and Security (cs.CR)",
        "abstract": "Smart home IoT systems utilize trigger-action platforms, e.g., IFTTT, to manage devices from various vendors. However, they may be abused by triggering malicious rule execution with forged IoT devices or events violating the execution integrity and the intentions of the users. To address this issue, we propose a ledger based IoT platform called Ruledger, which ensures the correct execution of rules by verifying the authenticity of the corresponding information. Ruledger utilizes smart contracts to enforce verifying the information associated with rule executions, e.g., the user and configuration information from users, device events, and triggers in the trigger-action platforms. In particular, we develop three algorithms to enable ledger-wallet based applications for Ruledger and guarantee that the records used for verification are stateful and correct. Thus, the execution integrity of rules is ensured even if devices and platforms in the smart home systems are compromised. We prototype Ruledger in a real IoT platform, i.e., IFTTT, and evaluate the performance with various settings. The experimental results demonstrate Ruledger incurs an average of 12.53% delay, which is acceptable for smart home systems.\n    ",
        "primary_category": "cs.CR",
        "categories": [],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19012": {
        "title": "Algorithmically Expressive, Always-Terminating Model for Reversible Computation",
        "authors": [
            "Matteo Palazzo",
            "Luca Roversi"
        ],
        "comments": "16 pages, 4 figures, 2 listings",
        "subjects": "Programming Languages (cs.PL)",
        "abstract": "Concerning classical computational models able to express all the Primitive Recursive Functions (PRF), there are interesting results regarding limits on their algorithmic expressiveness or, equivalently, efficiency, namely the ability to express algorithms with minimal computational cost. By introducing the reversible programming model Forest, at our knowledge, we provide a first study of analogous properties, adapted to the context of reversible computational models that can represent all the functions in PRF. Firstly, we show that Forest extends Matos' linear reversible computational model MSRL, the very extension being a guaranteed terminating iteration that can be halted by means of logical predicates. The consequence is that Forest is PRF complete, because MSRL is. Secondly, we show that Forest is strictly algorithmically more expressive than MSRL: it can encode a reversible algorithm for the minimum between two integers in optimal time, while MSRL cannot.\n    ",
        "primary_category": "cs.PL",
        "categories": [
            "cs.LO"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19014": {
        "title": "Enhancing Visual Document Understanding with Contrastive Learning in Large Visual-Language Models",
        "authors": [
            "Xin Li",
            "Yunfei Wu",
            "Xinghua Jiang",
            "Zhihao Guo",
            "Mingming Gong",
            "Haoyu Cao",
            "Yinsong Liu",
            "Deqiang Jiang",
            "Xing Sun"
        ],
        "comments": " ",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Recently, the advent of Large Visual-Language Models (LVLMs) has received increasing attention across various domains, particularly in the field of visual document understanding (VDU). Different from conventional vision-language tasks, VDU is specifically concerned with text-rich scenarios containing abundant document elements. Nevertheless, the importance of fine-grained features remains largely unexplored within the community of LVLMs, leading to suboptimal performance in text-rich scenarios. In this paper, we abbreviate it as the fine-grained feature collapse issue. With the aim of filling this gap, we propose a contrastive learning framework, termed Document Object COntrastive learning (DoCo), specifically tailored for the downstream tasks of VDU. DoCo leverages an auxiliary multimodal encoder to obtain the features of document objects and align them to the visual features generated by the vision encoder of LVLM, which enhances visual representation in text-rich scenarios. It can represent that the contrastive learning between the visual holistic representations and the multimodal fine-grained features of document objects can assist the vision encoder in acquiring more effective visual cues, thereby enhancing the comprehension of text-rich documents in LVLMs. We also demonstrate that the proposed DoCo serves as a plug-and-play pre-training method, which can be employed in the pre-training of various LVLMs without inducing any increase in computational complexity during the inference process. Extensive experimental results on multiple benchmarks of VDU reveal that LVLMs equipped with our proposed DoCo can achieve superior performance and mitigate the gap between VDU and generic vision-language tasks.\n    ",
        "primary_category": "cs.CV",
        "categories": [],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19015": {
        "title": "Fractional material derivative: pointwise representation and a finite volume numerical scheme",
        "authors": [
            "\u0141ukasz P\u0142ociniczak",
            "Marek A. Teuerle"
        ],
        "comments": " ",
        "subjects": "Numerical Analysis (math.NA)",
        "abstract": "The fractional material derivative appears as the fractional operator that governs the dynamics of the scaling limits of L\u00e9vy walks - a stochastic process that originates from the famous continuous-time random walks. It is usually defined as the Fourier-Laplace multiplier, therefore, it can be thought of as a pseudo-differential operator. In this paper, we show that there exists a local representation in time and space, pointwise, of the fractional material derivative. This allows us to define it on a space of locally integrable functions which is larger than the original one in which Fourier and Laplace transform exist as functions.\nWe consider several typical differential equations involving the fractional material derivative and provide conditions for their solutions to exist. In some cases, the analytical solution can be found. For the general initial value problem, we devise a finite volume method and prove its stability, convergence, and conservation of probability. Numerical illustrations verify our analytical findings. Moreover, our numerical experiments show superiority in the computation time of the proposed numerical scheme over a Monte Carlo method applied to the problem of probability density function's derivation.\n    ",
        "primary_category": "math.NA",
        "categories": [],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19016": {
        "title": "SPriFed-OMP: A Differentially Private Federated Learning Algorithm for Sparse Basis Recovery",
        "authors": [
            "Ajinkya Kiran Mulay",
            "Xiaojun Lin"
        ],
        "comments": "Paper under review",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Sparse basis recovery is a classical and important statistical learning problem when the number of model dimensions $p$ is much larger than the number of samples $n$. However, there has been little work that studies sparse basis recovery in the Federated Learning (FL) setting, where the client data's differential privacy (DP) must also be simultaneously protected. In particular, the performance guarantees of existing DP-FL algorithms (such as DP-SGD) will degrade significantly when $p \\gg n$, and thus, they will fail to learn the true underlying sparse model accurately. In this work, we develop a new differentially private sparse basis recovery algorithm for the FL setting, called SPriFed-OMP. SPriFed-OMP converts OMP (Orthogonal Matching Pursuit) to the FL setting. Further, it combines SMPC (secure multi-party computation) and DP to ensure that only a small amount of noise needs to be added in order to achieve differential privacy. As a result, SPriFed-OMP can efficiently recover the true sparse basis for a linear model with only $n = O(\\sqrt{p})$ samples. We further present an enhanced version of our approach, SPriFed-OMP-GRAD based on gradient privatization, that improves the performance of SPriFed-OMP. Our theoretical analysis and empirical results demonstrate that both SPriFed-OMP and SPriFed-OMP-GRAD terminate in a small number of steps, and they significantly outperform the previous state-of-the-art DP-FL solutions in terms of the accuracy-privacy trade-off.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.CR"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19020": {
        "title": "Unsupervised Learning of High-resolution Light Field Imaging via Beam Splitter-based Hybrid Lenses",
        "authors": [
            "Jianxin Lei",
            "Chengcai Xu",
            "Langqing Shi",
            "Junhui Hou",
            "Ping Zhou"
        ],
        "comments": " ",
        "subjects": "Image and Video Processing (eess.IV)",
        "abstract": "In this paper, we design a beam splitter-based hybrid light field imaging prototype to record 4D light field image and high-resolution 2D image simultaneously, and make a hybrid light field dataset. The 2D image could be considered as the high-resolution ground truth corresponding to the low-resolution central sub-aperture image of 4D light field image. Subsequently, we propose an unsupervised learning-based super-resolution framework with the hybrid light field dataset, which adaptively settles the light field spatial super-resolution problem with a complex degradation model. Specifically, we design two loss functions based on pre-trained models that enable the super-resolution network to learn the detailed features and light field parallax structure with only one ground truth. Extensive experiments demonstrate the same superiority of our approach with supervised learning-based state-of-the-art ones. To our knowledge, it is the first end-to-end unsupervised learning-based spatial super-resolution approach in light field imaging research, whose input is available from our beam splitter-based hybrid light field system. The hardware and software together may help promote the application of light field super-resolution to a great extent.\n    ",
        "primary_category": "eess.IV",
        "categories": [
            "cs.CV"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19025": {
        "title": "Combination of Weak Learners eXplanations to Improve Random Forest eXplicability Robustness",
        "authors": [
            "Riccardo Pala",
            "Esteban Garc\u00eda-Cuesta"
        ],
        "comments": "8 pages, 10 figures",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "The notion of robustness in XAI refers to the observed variations in the explanation of the prediction of a learned model with respect to changes in the input leading to that prediction. Intuitively, if the input being explained is modified slightly subtly enough so as to not change the prediction of the model too much, then we would expect that the explanation provided for that new input does not change much either. We argue that a combination through discriminative averaging of ensembles weak learners explanations can improve the robustness of explanations in ensemble methods.This approach has been implemented and tested with post-hoc SHAP method and Random Forest ensemble with successful results. The improvements obtained have been measured quantitatively and some insights into the explicability robustness in ensemble methods are presented.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19026": {
        "title": "Progressive Contrastive Learning with Multi-Prototype for Unsupervised Visible-Infrared Person Re-identification",
        "authors": [
            "Jiangming Shi",
            "Xiangbo Yin",
            "Yaoxing Wang",
            "Xiaofeng Liu",
            "Yuan Xie",
            "Yanyun Qu"
        ],
        "comments": " ",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Unsupervised visible-infrared person re-identification (USVI-ReID) aims to match specified people in infrared images to visible images without annotation, and vice versa. USVI-ReID is a challenging yet under-explored task. Most existing methods address the USVI-ReID problem using cluster-based contrastive learning, which simply employs the cluster center as a representation of a person. However, the cluster center primarily focuses on shared information, overlooking disparity. To address the problem, we propose a Progressive Contrastive Learning with Multi-Prototype (PCLMP) method for USVI-ReID. In brief, we first generate the hard prototype by selecting the sample with the maximum distance from the cluster center. This hard prototype is used in the contrastive loss to emphasize disparity. Additionally, instead of rigidly aligning query images to a specific prototype, we generate the dynamic prototype by randomly picking samples within a cluster. This dynamic prototype is used to retain the natural variety of features while reducing instability in the simultaneous learning of both common and disparate information. Finally, we introduce a progressive learning strategy to gradually shift the model's attention towards hard samples, avoiding cluster deterioration. Extensive experiments conducted on the publicly available SYSU-MM01 and RegDB datasets validate the effectiveness of the proposed method. PCLMP outperforms the existing state-of-the-art method with an average mAP improvement of 3.9%. The source codes will be released.\n    ",
        "primary_category": "cs.CV",
        "categories": [],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19027": {
        "title": "How to Train your Antivirus: RL-based Hardening through the Problem-Space",
        "authors": [
            "Jacopo Cortellazzi",
            "Ilias Tsingenopoulos",
            "Branislav Bo\u0161ansk\u00fd",
            "Simone Aonzo",
            "Davy Preuveneers",
            "Wouter Joosen",
            "Fabio Pierazzi",
            "Lorenzo Cavallaro"
        ],
        "comments": "20 pages,4 figures",
        "subjects": "Cryptography and Security (cs.CR)",
        "abstract": "ML-based malware detection on dynamic analysis reports is vulnerable to both evasion and spurious correlations. In this work, we investigate a specific ML architecture employed in the pipeline of a widely-known commercial antivirus company, with the goal to harden it against adversarial malware. Adversarial training, the sole defensive technique that can confer empirical robustness, is not applicable out of the box in this domain, for the principal reason that gradient-based perturbations rarely map back to feasible problem-space programs. We introduce a novel Reinforcement Learning approach for constructing adversarial examples, a constituent part of adversarially training a model against evasion. Our approach comes with multiple advantages. It performs modifications that are feasible in the problem-space, and only those; thus it circumvents the inverse mapping problem. It also makes possible to provide theoretical guarantees on the robustness of the model against a particular set of adversarial capabilities. Our empirical exploration validates our theoretical insights, where we can consistently reach 0\\% Attack Success Rate after a few adversarial retraining iterations.\n    ",
        "primary_category": "cs.CR",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19028": {
        "title": "Invariant Checking for SMT-based Systems with Quantifiers",
        "authors": [
            "Gianluca Redondi",
            "Alessandro Cimatti",
            "Alberto Griggio",
            "Kenneth McMillan"
        ],
        "comments": " ",
        "subjects": "Logic in Computer Science (cs.LO)",
        "abstract": "This paper addresses the problem of checking invariant properties for a large class of symbolic transition systems, defined by a combination of SMT theories and quantifiers. State variables can be functions from an uninterpreted sort (finite, but unbounded) to an interpreted sort, such as the the integers under the theory of linear arithmetic. This formalism is very expressive and can be used for modeling parameterized systems, array-manipulating programs, and more. We propose two algorithms for finding universal inductive invariants for such systems. The first algorithm combines an IC3-style loop with a form of implicit predicate abstraction to construct an invariant in an incremental manner. The second algorithm constructs an under-approximation of the original problem, and searches for a formula which is an inductive invariant for this case; then, the invariant is generalized to the original case, and checked with a portfolio of techniques. We have implemented the two algorithms and conducted an extensive experimental evaluation, considering various benchmarks and different tools from the literature. As far as we know, our method is the first capable of handling in a large class of systems in a uniform way. The experiment shows that both algorithms are competitive with the state of the art.\n    ",
        "primary_category": "cs.LO",
        "categories": [],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19033": {
        "title": "High-Speed Motion Planning for Aerial Swarms in Unknown and Cluttered Environments",
        "authors": [
            "Charbel Toumieh",
            "Dario Floreano"
        ],
        "comments": " ",
        "subjects": "Robotics (cs.RO)",
        "abstract": "Coordinated flight of multiple drones allows to achieve tasks faster such as search and rescue and infrastructure inspection. Thus, pushing the state-of-the-art of aerial swarms in navigation speed and robustness is of tremendous benefit. In particular, being able to account for unexplored/unknown environments when planning trajectories allows for safer flight. In this work, we propose the first high-speed, decentralized, and synchronous motion planning framework (HDSM) for an aerial swarm that explicitly takes into account the unknown/undiscovered parts of the environment. The proposed approach generates an optimized trajectory for each planning agent that avoids obstacles and other planning agents while moving and exploring the environment. The only global information that each agent has is the target location. The generated trajectory is high-speed, safe from unexplored spaces, and brings the agent closer to its goal. The proposed method outperforms four recent state-of-the-art methods in success rate (100% success in reaching the target location), flight speed (67% faster), and flight time (42% lower). Finally, the method is validated on a set of Crazyflie nano-drones as a proof of concept.\n    ",
        "primary_category": "cs.RO",
        "categories": [],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19037": {
        "title": "A Deep-Learning Technique to Locate Cryptographic Operations in Side-Channel Traces",
        "authors": [
            "Giuseppe Chiari",
            "Davide Galli",
            "Francesco Lattari",
            "Matteo Matteucci",
            "Davide Zoni"
        ],
        "comments": "Accepted for presentation by DATE'24",
        "subjects": "Cryptography and Security (cs.CR)",
        "abstract": "Side-channel attacks allow extracting secret information from the execution of cryptographic primitives by correlating the partially known computed data and the measured side-channel signal. However, to set up a successful side-channel attack, the attacker has to perform i) the challenging task of locating the time instant in which the target cryptographic primitive is executed inside a side-channel trace and then ii)the time-alignment of the measured data on that time instant. This paper presents a novel deep-learning technique to locate the time instant in which the target computed cryptographic operations are executed in the side-channel trace. In contrast to state-of-the-art solutions, the proposed methodology works even in the presence of trace deformations obtained through random delay insertion techniques. We validated our proposal through a successful attack against a variety of unprotected and protected cryptographic primitives that have been executed on an FPGA-implemented system-on-chip featuring a RISC-V CPU.\n    ",
        "primary_category": "cs.CR",
        "categories": [
            "cs.LG"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19038": {
        "title": "Understanding Fairness in Software Engineering: Insights from Stack Exchange",
        "authors": [
            "Emeralda Sesari",
            "Federica Sarro",
            "Ayushi Rastogi"
        ],
        "comments": " ",
        "subjects": "Software Engineering (cs.SE)",
        "abstract": "Software practitioners discuss problems at work with peers, in-person and online. These discussions can be technical (e.g., how to fix a bug?) and social (e.g., how to assign work fairly?). While there is a growing body of knowledge exploring fairness problems and solutions in the human and social factors of software engineering, most focus has been on specific problems. This study provides fairness discussions by software practitioners on Stack Exchange sites. We present an exploratory study presenting the fairness experience of software practitioners and fairness expectations in software teams. We also want to identify the fairness aspects software practitioners talk about the most. For example, do they care more about fairness in income or how they are treated in the workplace?\nOur investigation of fairness discussions on eight Stack Exchange sites resulted in a list of 136 posts (28 questions and 108 answers) manually curated from 4,178 candidate posts. The study reveals that the majority of fairness discussions (24 posts) revolve around the topic of income suggesting that many software practitioners are highly interested in matters related to their pay and how it is fairly distributed. Further, we noted that while not discussed as often, discussions on fairness in recruitment tend to receive the highest number of views and scores. Interestingly, the study shows that unfairness experiences extend beyond the protected attributes. In this study, only 25 out of 136 posts mention protected attributes, with gender mainly being discussed.\n    ",
        "primary_category": "cs.SE",
        "categories": [],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19041": {
        "title": "Atmospheric Turbulence Removal with Video Sequence Deep Visual Priors",
        "authors": [
            "P. Hill",
            "N. Anantrasirichai",
            "A. Achim",
            "D.R. Bull"
        ],
        "comments": " ",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Atmospheric turbulence poses a challenge for the interpretation and visual perception of visual imagery due to its distortion effects. Model-based approaches have been used to address this, but such methods often suffer from artefacts associated with moving content. Conversely, deep learning based methods are dependent on large and diverse datasets that may not effectively represent any specific content. In this paper, we address these problems with a self-supervised learning method that does not require ground truth. The proposed method is not dependent on any dataset outside of the single data sequence being processed but is also able to improve the quality of any input raw sequences or pre-processed sequences. Specifically, our method is based on an accelerated Deep Image Prior (DIP), but integrates temporal information using pixel shuffling and a temporal sliding window. This efficiently learns spatio-temporal priors leading to a system that effectively mitigates atmospheric turbulence distortions. The experiments show that our method improves visual quality results qualitatively and quantitatively.\n    ",
        "primary_category": "cs.CV",
        "categories": [
            "cs.AI",
            "eess.IV"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19043": {
        "title": "WDM: 3D Wavelet Diffusion Models for High-Resolution Medical Image Synthesis",
        "authors": [
            "Paul Friedrich",
            "Julia Wolleb",
            "Florentin Bieder",
            "Alicia Durrer",
            "Philippe C. Cattin"
        ],
        "comments": "Code: this https URL",
        "subjects": "Image and Video Processing (eess.IV)",
        "abstract": "Due to the three-dimensional nature of CT- or MR-scans, generative modeling of medical images is a particularly challenging task. Existing approaches mostly apply patch-wise, slice-wise, or cascaded generation techniques to fit the high-dimensional data into the limited GPU memory. However, these approaches may introduce artifacts and potentially restrict the model's applicability for certain downstream tasks. This work presents WDM, a wavelet-based medical image synthesis framework that applies a diffusion model on wavelet decomposed images. The presented approach is a simple yet effective way of scaling diffusion models to high resolutions and can be trained on a single 40 GB GPU. Experimental results on BraTS and LIDC-IDRI unconditional image generation at a resolution of $128 \\times 128 \\times 128$ show state-of-the-art image fidelity (FID) and sample diversity (MS-SSIM) scores compared to GANs, Diffusion Models, and Latent Diffusion Models. Our proposed method is the only one capable of generating high-quality images at a resolution of $256 \\times 256 \\times 256$.\n    ",
        "primary_category": "eess.IV",
        "categories": [
            "cs.CV"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19044": {
        "title": "DMSA -- Dense Multi Scan Adjustment for LiDAR Inertial Odometry and Global Optimization",
        "authors": [
            "David Skuddis",
            "Norbert Haala"
        ],
        "comments": "accepted for ICRA 2024",
        "subjects": "Robotics (cs.RO)",
        "abstract": "We propose a new method for fine registering multiple point clouds simultaneously. The approach is characterized by being dense, therefore point clouds are not reduced to pre-selected features in advance. Furthermore, the approach is robust against small overlaps and dynamic objects, since no direct correspondences are assumed between point clouds. Instead, all points are merged into a global point cloud, whose scattering is then iteratively reduced. This is achieved by dividing the global point cloud into uniform grid cells whose contents are subsequently modeled by normal distributions. We show that the proposed approach can be used in a sliding window continuous trajectory optimization combined with IMU measurements to obtain a highly accurate and robust LiDAR inertial odometry estimation. Furthermore, we show that the proposed approach is also suitable for large scale keyframe optimization to increase accuracy. We provide the source code and some experimental data on this https URL.\n    ",
        "primary_category": "cs.RO",
        "categories": [],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19047": {
        "title": "Theoretical Foundations of Deep Selective State-Space Models",
        "authors": [
            "Nicola Muca Cirone",
            "Antonio Orvieto",
            "Benjamin Walker",
            "Cristopher Salvi",
            "Terry Lyons"
        ],
        "comments": " ",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Structured state-space models (SSMs) such as S4, stemming from the seminal work of Gu et al., are gaining popularity as effective approaches for modeling sequential data. Deep SSMs demonstrate outstanding performance across a diverse set of domains, at a reduced training and inference cost compared to attention-based transformers. Recent developments show that if the linear recurrence powering SSMs allows for multiplicative interactions between inputs and hidden states (e.g. GateLoop, Mamba, GLA), then the resulting architecture can surpass in both in accuracy and efficiency attention-powered foundation models trained on text, at scales of billion parameters. In this paper, we give theoretical grounding to this recent finding using tools from Rough Path Theory: we show that when random linear recurrences are equipped with simple input-controlled transitions (selectivity mechanism), then the hidden state is provably a low-dimensional projection of a powerful mathematical object called the signature of the input -- capturing non-linear interactions between tokens at distinct timescales. Our theory not only motivates the success of modern selective state-space models such as Mamba but also provides a solid framework to understand the expressive power of future SSM variants.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "math.DS"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19052": {
        "title": "Exploring the Efficacy of Large Language Models in Summarizing Mental Health Counseling Sessions: A Benchmark Study",
        "authors": [
            "Prottay Kumar Adhikary",
            "Aseem Srivastava",
            "Shivani Kumar",
            "Salam Michael Singh",
            "Puneet Manuja",
            "Jini K Gopinath",
            "Vijay Krishnan",
            "Swati Kedia",
            "Koushik Sinha Deb",
            "Tanmoy Chakraborty"
        ],
        "comments": " ",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "Comprehensive summaries of sessions enable an effective continuity in mental health counseling, facilitating informed therapy planning. Yet, manual summarization presents a significant challenge, diverting experts' attention from the core counseling process. This study evaluates the effectiveness of state-of-the-art Large Language Models (LLMs) in selectively summarizing various components of therapy sessions through aspect-based summarization, aiming to benchmark their performance. We introduce MentalCLOUDS, a counseling-component guided summarization dataset consisting of 191 counseling sessions with summaries focused on three distinct counseling components (aka counseling aspects). Additionally, we assess the capabilities of 11 state-of-the-art LLMs in addressing the task of component-guided summarization in counseling. The generated summaries are evaluated quantitatively using standard summarization metrics and verified qualitatively by mental health professionals. Our findings demonstrate the superior performance of task-specific LLMs such as MentalLlama, Mistral, and MentalBART in terms of standard quantitative metrics such as Rouge-1, Rouge-2, Rouge-L, and BERTScore across all aspects of counseling components. Further, expert evaluation reveals that Mistral supersedes both MentalLlama and MentalBART based on six parameters -- affective attitude, burden, ethicality, coherence, opportunity costs, and perceived effectiveness. However, these models share the same weakness by demonstrating a potential for improvement in the opportunity costs and perceived effectiveness metrics.\n    ",
        "primary_category": "cs.CL",
        "categories": [
            "cs.HC"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19054": {
        "title": "RobWE: Robust Watermark Embedding for Personalized Federated Learning Model Ownership Protection",
        "authors": [
            "Yang Xu",
            "Yunlin Tan",
            "Cheng Zhang",
            "Kai Chi",
            "Peng Sun",
            "Wenyuan Yang",
            "Ju Ren",
            "Hongbo Jiang",
            "Yaoxue Zhang"
        ],
        "comments": " ",
        "subjects": "Cryptography and Security (cs.CR)",
        "abstract": "Embedding watermarks into models has been widely used to protect model ownership in federated learning (FL). However, existing methods are inadequate for protecting the ownership of personalized models acquired by clients in personalized FL (PFL). This is due to the aggregation of the global model in PFL, resulting in conflicts over clients' private watermarks. Moreover, malicious clients may tamper with embedded watermarks to facilitate model leakage and evade accountability. This paper presents a robust watermark embedding scheme, named RobWE, to protect the ownership of personalized models in PFL. We first decouple the watermark embedding of personalized models into two parts: head layer embedding and representation layer embedding. The head layer belongs to clients' private part without participating in model aggregation, while the representation layer is the shared part for aggregation. For representation layer embedding, we employ a watermark slice embedding operation, which avoids watermark embedding conflicts. Furthermore, we design a malicious watermark detection scheme enabling the server to verify the correctness of watermarks before aggregating local models. We conduct an exhaustive experimental evaluation of RobWE. The results demonstrate that RobWE significantly outperforms the state-of-the-art watermark embedding schemes in FL in terms of fidelity, reliability, and robustness.\n    ",
        "primary_category": "cs.CR",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19058": {
        "title": "On the Design of Human-Robot Collaboration Gestures",
        "authors": [
            "Anas Shrinah",
            "Masoud S. Bahraini",
            "Fahad Khan",
            "Seemal Asif",
            "Niels Lohse",
            "Kerstin Eder"
        ],
        "comments": " ",
        "subjects": "Robotics (cs.RO)",
        "abstract": "Effective communication between humans and collaborative robots is essential for seamless Human-Robot Collaboration (HRC). In noisy industrial settings, nonverbal communication, such as gestures, plays a key role in conveying commands and information to robots efficiently. While existing literature has thoroughly examined gesture recognition and robots' responses to these gestures, there is a notable gap in exploring the design of these gestures. The criteria for creating efficient HRC gestures are scattered across numerous studies. This paper surveys the design principles of HRC gestures, as contained in the literature, aiming to consolidate a set of criteria for HRC gesture design. It also examines the methods used for designing and evaluating HRC gestures to highlight research gaps and present directions for future research in this area.\n    ",
        "primary_category": "cs.RO",
        "categories": [
            "cs.HC"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19061": {
        "title": "Optimal ANN-SNN Conversion with Group Neurons",
        "authors": [
            "Liuzhenghao Lv",
            "Wei Fang",
            "Li Yuan",
            "Yonghong Tian"
        ],
        "comments": "Accepted by International Conference on Acoustics, Speech, and Signal Processing (ICASSP) 2024",
        "subjects": "Neural and Evolutionary Computing (cs.NE)",
        "abstract": "Spiking Neural Networks (SNNs) have emerged as a promising third generation of neural networks, offering unique characteristics such as binary outputs, high sparsity, and biological plausibility. However, the lack of effective learning algorithms remains a challenge for SNNs. For instance, while converting artificial neural networks (ANNs) to SNNs circumvents the need for direct training of SNNs, it encounters issues related to conversion errors and high inference time delays. In order to reduce or even eliminate conversion errors while decreasing inference time-steps, we have introduced a novel type of neuron called Group Neurons (GNs). One GN is composed of multiple Integrate-and-Fire (IF) neurons as members, and its neural dynamics are meticulously designed. Based on GNs, we have optimized the traditional ANN-SNN conversion framework. Specifically, we replace the IF neurons in the SNNs obtained by the traditional conversion framework with GNs. The resulting SNNs, which utilize GNs, are capable of achieving accuracy levels comparable to ANNs even within extremely short inference time-steps. The experiments on CIFAR10, CIFAR100, and ImageNet datasets demonstrate the superiority of the proposed methods in terms of both inference accuracy and latency. Code is available at this https URL.\n    ",
        "primary_category": "cs.NE",
        "categories": [],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19062": {
        "title": "Graph Convolutional Neural Networks for Automated Echocardiography View Recognition: A Holistic Approach",
        "authors": [
            "Sarina Thomas",
            "Cristiana Tiago",
            "B\u00f8rge Solli Andreassen",
            "Svein Arne Aase",
            "Jurica \u0160prem",
            "Erik Steen",
            "Anne Solberg",
            "Guy Ben-Yosef"
        ],
        "comments": "Presented at ASMUS - MICCAI conference 2023, Vancouver",
        "subjects": "Image and Video Processing (eess.IV)",
        "abstract": "To facilitate diagnosis on cardiac ultrasound (US), clinical practice has established several standard views of the heart, which serve as reference points for diagnostic measurements and define viewports from which images are acquired. Automatic view recognition involves grouping those images into classes of standard views. Although deep learning techniques have been successful in achieving this, they still struggle with fully verifying the suitability of an image for specific measurements due to factors like the correct location, pose, and potential occlusions of cardiac structures. Our approach goes beyond view classification and incorporates a 3D mesh reconstruction of the heart that enables several more downstream tasks, like segmentation and pose estimation. In this work, we explore learning 3D heart meshes via graph convolutions, using similar techniques to learn 3D meshes in natural images, such as human pose estimation. As the availability of fully annotated 3D images is limited, we generate synthetic US images from 3D meshes by training an adversarial denoising diffusion model. Experiments were conducted on synthetic and clinical cases for view recognition and structure detection. The approach yielded good performance on synthetic images and, despite being exclusively trained on synthetic data, it already showed potential when applied to clinical images. With this proof-of-concept, we aim to demonstrate the benefits of graphs to improve cardiac view recognition that can ultimately lead to better efficiency in cardiac diagnosis.\n    ",
        "primary_category": "eess.IV",
        "categories": [
            "cs.CV",
            "cs.LG"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19064": {
        "title": "The Influence of Color Stimuli on Adolescents' Emotion Playing Mobile Games",
        "authors": [
            "Leonie Kallabis",
            "Bruno Baruque-Zan\u00f3n",
            "Heinrich Klocke",
            "Ana Mar\u00eda Lara-Palma",
            "Boris Naujoks"
        ],
        "comments": "17 pages, 12 figures, 1 table",
        "subjects": "Human-Computer Interaction (cs.HC)",
        "abstract": "Video games elicit emotions which can be influenced by color stimuli as shown by previous studies. However, little research has been conducted on whether this applies to mobile games played by adolescents. Therefore, we examined the influence of color stimuli hue and saturation on mobile game play. Adolescents (n=21) played a mobile platformer game with varying hue and saturation per level for about 25 minutes. We gathered data on emotional states after each level using the Self-Assessment Manikin questionnaire, recorded time spent in each level, and collected participant self-reports on their video game experience. We performed statistical tests, such as ANOVA, which depict no significant influence of hue and/or saturation on the emotional state of our players. We conclude that it is possible that color alone is not an effective measure for eliciting emotion in mobile games, and further research is needed to consider measures such as time spent in the game and screen size, as these are unique to mobile games. There was a noticeable variance in emotional response between male and female players, with a significant interaction of hue and saturation among male players for valence ratings. This may be an indication that color preference influences perceived pleasantness.\n    ",
        "primary_category": "cs.HC",
        "categories": [],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19071": {
        "title": "FATE in MMLA: A Student-Centred Exploration of Fairness, Accountability, Transparency, and Ethics in Multimodal Learning Analytics",
        "authors": [
            "Yueqiao Jin",
            "Vanessa Echeverria",
            "Lixiang Yan",
            "Linxuan Zhao",
            "Riordan Alfredo",
            "Yi-Shan Tsai",
            "Dragan Ga\u0161evi\u0107",
            "Roberto Martinez-Maldonado"
        ],
        "comments": "16 pages, 1 figure",
        "subjects": "Computers and Society (cs.CY)",
        "abstract": "Multimodal Learning Analytics (MMLA) integrates novel sensing technologies and artificial intelligence algorithms, providing opportunities to enhance student reflection during complex, collaborative learning experiences. Although recent advancements in MMLA have shown its capability to generate insights into diverse learning behaviours across various learning settings, little research has been conducted to evaluate these systems in authentic learning contexts, particularly regarding students' perceived fairness, accountability, transparency, and ethics (FATE). Understanding these perceptions is essential to using MMLA effectively without introducing ethical complications or negatively affecting how students learn. This study aimed to address this gap by assessing the FATE of MMLA in an authentic, collaborative learning context. We conducted semi-structured interviews with 14 undergraduate students who used MMLA visualisations for post-activity reflection. The findings highlighted the significance of accurate and comprehensive data representation to ensure visualisation fairness, the need for different levels of data access to foster accountability, the imperative of measuring and cultivating transparency with students, and the necessity of transforming informed consent from dichotomous to continuous and measurable scales. While students value the benefits of MMLA, they also emphasise the importance of ethical considerations, highlighting a pressing need for the LA and MMLA community to investigate and address FATE issues actively.\n    ",
        "primary_category": "cs.CY",
        "categories": [
            "cs.HC"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19072": {
        "title": "TimeXer: Empowering Transformers for Time Series Forecasting with Exogenous Variables",
        "authors": [
            "Yuxuan Wang",
            "Haixu Wu",
            "Jiaxiang Dong",
            "Yong Liu",
            "Yunzhong Qiu",
            "Haoran Zhang",
            "Jianmin Wang",
            "Mingsheng Long"
        ],
        "comments": " ",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Recent studies have demonstrated remarkable performance in time series forecasting. However, due to the partially-observed nature of real-world applications, solely focusing on the target of interest, so-called endogenous variables, is usually insufficient to guarantee accurate forecasting. Notably, a system is often recorded into multiple variables, where the exogenous series can provide valuable external information for endogenous variables. Thus, unlike prior well-established multivariate or univariate forecasting that either treats all the variables equally or overlooks exogenous information, this paper focuses on a practical setting, which is time series forecasting with exogenous variables. We propose a novel framework, TimeXer, to utilize external information to enhance the forecasting of endogenous variables. With a deftly designed embedding layer, TimeXer empowers the canonical Transformer architecture with the ability to reconcile endogenous and exogenous information, where patch-wise self-attention and variate-wise cross-attention are employed. Moreover, a global endogenous variate token is adopted to effectively bridge the exogenous series into endogenous temporal patches. Experimentally, TimeXer significantly improves time series forecasting with exogenous variables and achieves consistent state-of-the-art performance in twelve real-world forecasting benchmarks.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19076": {
        "title": "Pointing out the Shortcomings of Relation Extraction Models with Semantically Motivated Adversarials",
        "authors": [
            "Gennaro Nolano",
            "Moritz Blum",
            "Basil Ell",
            "Philipp Cimiano"
        ],
        "comments": " ",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "In recent years, large language models have achieved state-of-the-art performance across various NLP tasks. However, investigations have shown that these models tend to rely on shortcut features, leading to inaccurate predictions and causing the models to be unreliable at generalization to out-of-distribution (OOD) samples. For instance, in the context of relation extraction (RE), we would expect a model to identify the same relation independently of the entities involved in it. For example, consider the sentence \"Leonardo da Vinci painted the Mona Lisa\" expressing the created(Leonardo_da_Vinci, Mona_Lisa) relation. If we substiute \"Leonardo da Vinci\" with \"Barack Obama\", then the sentence still expresses the created relation. A robust model is supposed to detect the same relation in both cases. In this work, we describe several semantically-motivated strategies to generate adversarial examples by replacing entity mentions and investigate how state-of-the-art RE models perform under pressure. Our analyses show that the performance of these models significantly deteriorates on the modified datasets (avg. of -48.5% in F1), which indicates that these models rely to a great extent on shortcuts, such as surface forms (or patterns therein) of entities, without making full use of the information present in the sentences.\n    ",
        "primary_category": "cs.CL",
        "categories": [],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19080": {
        "title": "MIMDRAM: An End-to-End Processing-Using-DRAM System for High-Throughput, Energy-Efficient and Programmer-Transparent Multiple-Instruction Multiple-Data Processing",
        "authors": [
            "Geraldo F. Oliveira",
            "Ataberk Olgun",
            "Abdullah Giray Ya\u011fl\u0131k\u00e7\u0131",
            "F. Nisa Bostanc\u0131",
            "Juan G\u00f3mez-Luna",
            "Saugata Ghose",
            "Onur Mutlu"
        ],
        "comments": "Extended version of HPCA 2024 paper. arXiv admin note: text overlap with arXiv:2109.05881 by other authors",
        "subjects": "Hardware Architecture (cs.AR)",
        "abstract": "Processing-using-DRAM (PUD) is a processing-in-memory (PIM) approach that uses a DRAM array's massive internal parallelism to execute very-wide data-parallel operations, in a single-instruction multiple-data (SIMD) fashion. However, DRAM rows' large and rigid granularity limit the effectiveness and applicability of PUD in three ways. First, since applications have varying degrees of SIMD parallelism, PUD execution often leads to underutilization, throughput loss, and energy waste. Second, most PUD architectures are limited to the execution of parallel map operations. Third, the need to feed the wide DRAM row with tens of thousands of data elements combined with the lack of adequate compiler support for PUD systems create a programmability barrier.\nOur goal is to design a flexible PUD system that overcomes the limitations caused by the large and rigid granularity of PUD. To this end, we propose MIMDRAM, a hardware/software co-designed PUD system that introduces new mechanisms to allocate and control only the necessary resources for a given PUD operation. The key idea of MIMDRAM is to leverage fine-grained DRAM (i.e., the ability to independently access smaller segments of a large DRAM row) for PUD computation. MIMDRAM exploits this key idea to enable a multiple-instruction multiple-data (MIMD) execution model in each DRAM subarray.\nWe evaluate MIMDRAM using twelve real-world applications and 495 multi-programmed application mixes. Our evaluation shows that MIMDRAM provides 34x the performance, 14.3x the energy efficiency, 1.7x the throughput, and 1.3x the fairness of a state-of-the-art PUD framework, along with 30.6x and 6.8x the energy efficiency of a high-end CPU and GPU, respectively. MIMDRAM adds small area cost to a DRAM chip (1.11%) and CPU die (0.6%).\n    ",
        "primary_category": "cs.AR",
        "categories": [
            "cs.DC"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19082": {
        "title": "VideoMAC: Video Masked Autoencoders Meet ConvNets",
        "authors": [
            "Gensheng Pei",
            "Tao Chen",
            "Xiruo Jiang",
            "Huafeng Liu",
            "Zeren Sun",
            "Yazhou Yao"
        ],
        "comments": "accepted by IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2024",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Recently, the advancement of self-supervised learning techniques, like masked autoencoders (MAE), has greatly influenced visual representation learning for images and videos. Nevertheless, it is worth noting that the predominant approaches in existing masked image / video modeling rely excessively on resource-intensive vision transformers (ViTs) as the feature encoder. In this paper, we propose a new approach termed as \\textbf{VideoMAC}, which combines video masked autoencoders with resource-friendly ConvNets. Specifically, VideoMAC employs symmetric masking on randomly sampled pairs of video frames. To prevent the issue of mask pattern dissipation, we utilize ConvNets which are implemented with sparse convolutional operators as encoders. Simultaneously, we present a simple yet effective masked video modeling (MVM) approach, a dual encoder architecture comprising an online encoder and an exponential moving average target encoder, aimed to facilitate inter-frame reconstruction consistency in videos. Additionally, we demonstrate that VideoMAC, empowering classical (ResNet) / modern (ConvNeXt) convolutional encoders to harness the benefits of MVM, outperforms ViT-based approaches on downstream tasks, including video object segmentation (+\\textbf{5.2\\%} / \\textbf{6.4\\%} $\\mathcal{J}\\&\\mathcal{F}$), body part propagation (+\\textbf{6.3\\%} / \\textbf{3.1\\%} mIoU), and human pose tracking (+\\textbf{10.2\\%} / \\textbf{11.1\\%} PCK@0.1).\n    ",
        "primary_category": "cs.CV",
        "categories": [],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19084": {
        "title": "High multiplicity of positive solutions in a superlinear problem of Moore-Nehari type",
        "authors": [
            "Pablo Cubillos",
            "Juli\u00e1n L\u00f3pez-G\u00f3mez",
            "Andrea Tellini"
        ],
        "comments": " ",
        "subjects": "Analysis of PDEs (math.AP)",
        "abstract": "In this paper we consider a superlinear one-dimensional elliptic boundary value problem that generalizes the one studied by Moore and Nehari in [43]. Specifically, we deal with piecewise-constant weight functions in front of the nonlinearity with an arbitrary number $\\kappa\\geq 1$ of vanishing regions. We study, from an analytic and numerical point of view, the number of positive solutions, depending on the value of a parameter $\\lambda$ and on $\\kappa$.\nOur main results are twofold. On the one hand, we study analytically the behavior of the solutions, as $\\lambda\\downarrow-\\infty$, in the regions where the weight vanishes. Our result leads us to conjecture the existence of $2^{\\kappa+1}-1$ solutions for sufficiently negative $\\lambda$. On the other hand, we support such a conjecture with the results of numerical simulations which also shed light on the structure of the global bifurcation diagrams in $\\lambda$ and the profiles of positive solutions.\nFinally, we give additional numerical results suggesting that the same high multiplicity result holds true for a much larger class of weights, also arbitrarily close to situations where there is uniqueness of positive solutions.\n    ",
        "primary_category": "math.AP",
        "categories": [
            "math.CA",
            "math.NA"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19085": {
        "title": "Controllable Preference Optimization: Toward Controllable Multi-Objective Alignment",
        "authors": [
            "Yiju Guo",
            "Ganqu Cui",
            "Lifan Yuan",
            "Ning Ding",
            "Jiexin Wang",
            "Huimin Chen",
            "Bowen Sun",
            "Ruobing Xie",
            "Jie Zhou",
            "Yankai Lin",
            "Zhiyuan Liu",
            "Maosong Sun"
        ],
        "comments": " ",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "Alignment in artificial intelligence pursues the consistency between model responses and human preferences as well as values. In practice, the multifaceted nature of human preferences inadvertently introduces what is known as the \"alignment tax\" -a compromise where enhancements in alignment within one objective (e.g.,harmlessness) can diminish performance in others (e.g.,helpfulness). However, existing alignment techniques are mostly unidirectional, leading to suboptimal trade-offs and poor flexibility over various objectives. To navigate this challenge, we argue the prominence of grounding LLMs with evident preferences. We introduce controllable preference optimization (CPO), which explicitly specifies preference scores for different objectives, thereby guiding the model to generate responses that meet the requirements. Our experimental analysis reveals that the aligned models can provide responses that match various preferences among the \"3H\" (helpfulness, honesty, harmlessness) desiderata. Furthermore, by introducing diverse data and alignment goals, we surpass baseline methods in aligning with single objectives, hence mitigating the impact of the alignment tax and achieving Pareto improvements in multi-objective alignment.\n    ",
        "primary_category": "cs.CL",
        "categories": [
            "cs.AI",
            "eess.SY"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19089": {
        "title": "Around Don's conjecture for binary completely reachable automata",
        "authors": [
            "Yinfeng Zhu"
        ],
        "comments": "10 pages, 2 figures",
        "subjects": "Formal Languages and Automata Theory (cs.FL)",
        "abstract": "A word $w$ is called a reaching word of a subset $S$ of states in a deterministic finite automaton (DFA) if $S$ is the image of $Q$ under the action of $w$. A DFA is called completely reachable if every non-empty subset of the state set has a reaching word. A conjecture states that in every $n$-state completely reachable DFA, for every $k$-element subset of states, there exists a reaching word of length at most $n(n-k)$. We present infinitely many completely reachable DFAs with two letters that violate this conjecture. A subfamily of completely reachable DFAs with two letters, is called standardized DFAs, introduced by Casas and Volkov (2023). We prove that every $k$-element subset of states in an $n$-state standardized DFA has a reaching word of length $\\le n(n-k) + n - 1$. Finally, we confirm the conjecture for standardized DFAs with additional properties, thus generalizing a result of Casas and Volkov (2023).\n    ",
        "primary_category": "cs.FL",
        "categories": [],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19090": {
        "title": "Best Arm Identification with Resource Constraints",
        "authors": [
            "Zitian Li",
            "Wang Chi Cheung"
        ],
        "comments": " ",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Motivated by the cost heterogeneity in experimentation across different alternatives, we study the Best Arm Identification with Resource Constraints (BAIwRC) problem. The agent aims to identify the best arm under resource constraints, where resources are consumed for each arm pull. We make two novel contributions. We design and analyze the Successive Halving with Resource Rationing algorithm (SH-RR). The SH-RR achieves a near-optimal non-asymptotic rate of convergence in terms of the probability of successively identifying an optimal arm. Interestingly, we identify a difference in convergence rates between the cases of deterministic and stochastic resource consumption.\n    ",
        "primary_category": "cs.LG",
        "categories": [],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19091": {
        "title": "Leveraging Representations from Intermediate Encoder-blocks for Synthetic Image Detection",
        "authors": [
            "Christos Koutlis",
            "Symeon Papadopoulos"
        ],
        "comments": " ",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "The recently developed and publicly available synthetic image generation methods and services make it possible to create extremely realistic imagery on demand, raising great risks for the integrity and safety of online information. State-of-the-art Synthetic Image Detection (SID) research has led to strong evidence on the advantages of feature extraction from foundation models. However, such extracted features mostly encapsulate high-level visual semantics instead of fine-grained details, which are more important for the SID task. On the contrary, shallow layers encode low-level visual information. In this work, we leverage the image representations extracted by intermediate Transformer blocks of CLIP's image-encoder via a lightweight network that maps them to a learnable forgery-aware vector space capable of generalizing exceptionally well. We also employ a trainable module to incorporate the importance of each Transformer block to the final prediction. Our method is compared against the state-of-the-art by evaluating it on 20 test datasets and exhibits an average +10.6% absolute performance improvement. Notably, the best performing models require just a single epoch for training (~8 minutes). Code available at this https URL.\n    ",
        "primary_category": "cs.CV",
        "categories": [],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19097": {
        "title": "TEncDM: Understanding the Properties of Diffusion Model in the Space of Language Model Encodings",
        "authors": [
            "Alexander Shabalin",
            "Viacheslav Meshchaninov",
            "Tingir Badmaev",
            "Dmitry Molchanov",
            "Grigory Bartosh",
            "Sergey Markov",
            "Dmitry Vetrov"
        ],
        "comments": "14 pages, 8 figures, submitted to ACL 2024",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "Drawing inspiration from the success of diffusion models in various domains, numerous research papers proposed methods for adapting them to text data. Despite these efforts, none of them has managed to achieve the quality of the large language models. In this paper, we conduct a comprehensive analysis of key components of the text diffusion models and introduce a novel approach named Text Encoding Diffusion Model (TEncDM). Instead of the commonly used token embedding space, we train our model in the space of the language model encodings. Additionally, we propose to use a Transformer-based decoder that utilizes contextual information for text reconstruction. We also analyse self-conditioning and find that it increases the magnitude of the model outputs, allowing the reduction of the number of denoising steps at the inference stage. Evaluation of TEncDM on two downstream text generation tasks, QQP and XSum, demonstrates its superiority over existing non-autoregressive models.\n    ",
        "primary_category": "cs.CL",
        "categories": [],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19101": {
        "title": "Effective Two-Stage Knowledge Transfer for Multi-Entity Cross-Domain Recommendation",
        "authors": [
            "Jianyu Guan",
            "Zongming Yin",
            "Tianyi Zhang",
            "Leihui Chen",
            "Yin Zhang",
            "Fei Huang",
            "Jufeng Chen",
            "Shuguang Han"
        ],
        "comments": " ",
        "subjects": "Information Retrieval (cs.IR)",
        "abstract": "In recent years, the recommendation content on e-commerce platforms has become increasingly rich -- a single user feed may contain multiple entities, such as selling products, short videos, and content posts. To deal with the multi-entity recommendation problem, an intuitive solution is to adopt the shared-network-based architecture for joint training. The idea is to transfer the extracted knowledge from one type of entity (source entity) to another (target entity). However, different from the conventional same-entity cross-domain recommendation, multi-entity knowledge transfer encounters several important issues: (1) data distributions of the source entity and target entity are naturally different, making the shared-network-based joint training susceptible to the negative transfer issue, (2) more importantly, the corresponding feature schema of each entity is not exactly aligned (e.g., price is an essential feature for selling product while missing for content posts), making the existing methods no longer appropriate. Recent researchers have also experimented with the pre-training and fine-tuning paradigm. Again, they only consider the scenarios with the same entity type and feature systems, which is inappropriate in our case. To this end, we design a pre-training & fine-tuning based Multi-entity Knowledge Transfer framework called MKT. MKT utilizes a multi-entity pre-training module to extract transferable knowledge across different entities. In particular, a feature alignment module is first applied to scale and align different feature schemas. Afterward, a couple of knowledge extractors are employed to extract the common and entity-specific knowledge. In the end, the extracted common knowledge is adopted for target entity model training. Through extensive offline and online experiments, we demonstrated the superiority of MKT over multiple State-Of-The-Art methods.\n    ",
        "primary_category": "cs.IR",
        "categories": [
            "cs.LG"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19102": {
        "title": "FlatNAS: optimizing Flatness in Neural Architecture Search for Out-of-Distribution Robustness",
        "authors": [
            "Matteo Gambella",
            "Fabrizio Pittorino",
            "Manuel Roveri"
        ],
        "comments": " ",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Neural Architecture Search (NAS) paves the way for the automatic definition of Neural Network (NN) architectures, attracting increasing research attention and offering solutions in various scenarios. This study introduces a novel NAS solution, called Flat Neural Architecture Search (FlatNAS), which explores the interplay between a novel figure of merit based on robustness to weight perturbations and single NN optimization with Sharpness-Aware Minimization (SAM). FlatNAS is the first work in the literature to systematically explore flat regions in the loss landscape of NNs in a NAS procedure, while jointly optimizing their performance on in-distribution data, their out-of-distribution (OOD) robustness, and constraining the number of parameters in their architecture. Differently from current studies primarily concentrating on OOD algorithms, FlatNAS successfully evaluates the impact of NN architectures on OOD robustness, a crucial aspect in real-world applications of machine and deep learning. FlatNAS achieves a good trade-off between performance, OOD generalization, and the number of parameters, by using only in-distribution data in the NAS exploration. The OOD robustness of the NAS-designed models is evaluated by focusing on robustness to input data corruptions, using popular benchmark datasets in the literature.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.AI",
            "cs.CV"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19103": {
        "title": "Whispers that Shake Foundations: Analyzing and Mitigating False Premise Hallucinations in Large Language Models",
        "authors": [
            "Hongbang Yuan",
            "Pengfei Cao",
            "Zhuoran Jin",
            "Yubo Chen",
            "Daojian Zeng",
            "Kang Liu",
            "Jun Zhao"
        ],
        "comments": "12 pages, 5 figures, 5 tables",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "Large Language Models (LLMs) have shown impressive capabilities but still suffer from the issue of hallucinations. A significant type of this issue is the false premise hallucination, which we define as the phenomenon when LLMs generate hallucinated text when confronted with false premise questions. In this paper, we perform a comprehensive analysis of the false premise hallucination and elucidate its internal working mechanism: a small subset of attention heads (which we designate as false premise heads) disturb the knowledge extraction process, leading to the occurrence of false premise hallucination. Based on our analysis, we propose \\textbf{FAITH} (\\textbf{F}alse premise \\textbf{A}ttention head constra\\textbf{I}ining for mi\\textbf{T}igating \\textbf{H}allucinations), a novel and effective method to mitigate false premise hallucinations. It constrains the false premise attention heads during the model inference process. Impressively, extensive experiments demonstrate that constraining only approximately $1\\%$ of the attention heads in the model yields a notable increase of nearly $20\\%$ of model performance.\n    ",
        "primary_category": "cs.CL",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19105": {
        "title": "CollaFuse: Navigating Limited Resources and Privacy in Collaborative Generative AI",
        "authors": [
            "Domenique Zipperling",
            "Simeon Allmendinger",
            "Lukas Struppek",
            "Niklas K\u00fchl"
        ],
        "comments": "Thirty-Second European Conference on Information Systems (ECIS 2024)",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "In the landscape of generative artificial intelligence, diffusion-based models present challenges for socio-technical systems in data requirements and privacy. Traditional approaches like federated learning distribute the learning process but strain individual clients, especially with constrained resources (e.g., edge devices). In response to these challenges, we introduce CollaFuse, a novel framework inspired by split learning. Tailored for efficient and collaborative use of denoising diffusion probabilistic models, CollaFuse enables shared server training and inference, alleviating client computational burdens. This is achieved by retaining data and computationally inexpensive GPU processes locally at each client while outsourcing the computationally expensive processes to the shared server. Demonstrated in a healthcare context, CollaFuse enhances privacy by highly reducing the need for sensitive information sharing. These capabilities hold the potential to impact various application areas, such as the design of edge computing solutions, healthcare research, or autonomous driving. In essence, our work advances distributed machine learning, shaping the future of collaborative GenAI networks.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19106": {
        "title": "A SOUND APPROACH: Using Large Language Models to generate audio descriptions for egocentric text-audio retrieval",
        "authors": [
            "Andreea-Maria Oncescu",
            "Jo\u00e3o F. Henriques",
            "Andrew Zisserman",
            "Samuel Albanie",
            "A. Sophia Koepke"
        ],
        "comments": "9 pages, 2 figures, 9 tables, Accepted at ICASSP 2024",
        "subjects": "Audio and Speech Processing (eess.AS)",
        "abstract": "Video databases from the internet are a valuable source of text-audio retrieval datasets. However, given that sound and vision streams represent different \"views\" of the data, treating visual descriptions as audio descriptions is far from optimal. Even if audio class labels are present, they commonly are not very detailed, making them unsuited for text-audio retrieval. To exploit relevant audio information from video-text datasets, we introduce a methodology for generating audio-centric descriptions using Large Language Models (LLMs). In this work, we consider the egocentric video setting and propose three new text-audio retrieval benchmarks based on the EpicMIR and EgoMCQ tasks, and on the EpicSounds dataset. Our approach for obtaining audio-centric descriptions gives significantly higher zero-shot performance than using the original visual-centric descriptions. Furthermore, we show that using the same prompts, we can successfully employ LLMs to improve the retrieval on EpicSounds, compared to using the original audio class labels of the dataset. Finally, we confirm that LLMs can be used to determine the difficulty of identifying the action associated with a sound.\n    ",
        "primary_category": "eess.AS",
        "categories": [
            "cs.IR",
            "cs.SD"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19107": {
        "title": "Rahmani Sort: A Novel Variant of Insertion Sort Algorithm with O(nlogn) Complexity",
        "authors": [
            "Mohammad Khalid Imam Rahmani"
        ],
        "comments": "None",
        "subjects": "Cryptography and Security (cs.CR)",
        "abstract": "Various decision support systems are available that implement Data Mining and Data Warehousing techniques for diving into the sea of data for getting useful patterns of knowledge (pearls). Classification, regression, clustering, and many other algorithms are used to enhance the precision and accuracy of the decision process. So, there is scope for increasing the response time of the decision process, especially in mission-critical operations. If data are ordered with suitable and efficient sorting operation, the response time of the decision process can be minimized. Insertion sort is much more suitable for such applications due to its simple and straight logic along with its dynamic nature suitable for list implementation. But it is slower than merge sort and quick sort. The main reasons this is slow: firstly, a sequential search is used to find the actual position of the next key element into the sorted left subarray and secondly, shifting of elements is required by one position towards the right for accommodating the newly inserted element. Therefore, I propose a new algorithm by using a novel technique of binary search mechanism for finding the sorted location of the next key item into the previously sorted left subarray much quicker than the conventional insertion sort algorithm. Performance measurement in terms of the actual running time of the new algorithm has been compared with those of other conventional sorting algorithms apart from the insertion sort. The results obtained on various sample data show that the new algorithm is better in performance than the conventional insertion sort and merge sort algorithms.\n    ",
        "primary_category": "cs.CR",
        "categories": [
            "cs.DS"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19108": {
        "title": "DeepEraser: Deep Iterative Context Mining for Generic Text Eraser",
        "authors": [
            "Hao Feng",
            "Wendi Wang",
            "Shaokai Liu",
            "Jiajun Deng",
            "Wengang Zhou",
            "Houqiang Li"
        ],
        "comments": " ",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "In this work, we present DeepEraser, an effective deep network for generic text removal. DeepEraser utilizes a recurrent architecture that erases the text in an image via iterative operations. Our idea comes from the process of erasing pencil script, where the text area designated for removal is subject to continuous monitoring and the text is attenuated progressively, ensuring a thorough and clean erasure. Technically, at each iteration, an innovative erasing module is deployed, which not only explicitly aggregates the previous erasing progress but also mines additional semantic context to erase the target text. Through iterative refinements, the text regions are progressively replaced with more appropriate content and finally converge to a relatively accurate status. Furthermore, a custom mask generation strategy is introduced to improve the capability of DeepEraser for adaptive text removal, as opposed to indiscriminately removing all the text in an image. Our DeepEraser is notably compact with only 1.4M parameters and trained in an end-to-end manner. To verify its effectiveness, extensive experiments are conducted on several prevalent benchmarks, including SCUT-Syn, SCUT-EnsText, and Oxford Synthetic text dataset. The quantitative and qualitative results demonstrate the effectiveness of our DeepEraser over the state-of-the-art methods, as well as its strong generalization ability in custom mask text removal. The codes and pre-trained models are available at this https URL\n",
        "primary_category": "cs.CV",
        "categories": [],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19109": {
        "title": "Confidence and Assurance of Percentiles",
        "authors": [
            "Sanjay M. Joshi"
        ],
        "comments": "5 pages, 4 Figures",
        "subjects": "Methodology (stat.ME)",
        "abstract": "Confidence interval of mean is often used when quoting statistics. The same rigor is often missing when quoting percentiles and tolerance or percentile intervals. This article derives the expression for confidence in percentiles of a sample population. Confidence intervals of median is compared to those of mean for a few sample distributions. The concept of assurance from reliability engineering is then extended to percentiles. The assurance level of sorted samples simply matches the confidence and percentile levels. Numerical method to compute assurance using Brent's optimization method is provided as an open-source python package.\n    ",
        "primary_category": "stat.ME",
        "categories": [
            "cs.IT"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19110": {
        "title": "Temporal-Aware Deep Reinforcement Learning for Energy Storage Bidding in Energy and Contingency Reserve Markets",
        "authors": [
            "Jinhao Li",
            "Changlong Wang",
            "Yanru Zhang",
            "Hao Wang"
        ],
        "comments": "15 pages",
        "subjects": "Systems and Control (eess.SY)",
        "abstract": "The battery energy storage system (BESS) has immense potential for enhancing grid reliability and security through its participation in the electricity market. BESS often seeks various revenue streams by taking part in multiple markets to unlock its full potential, but effective algorithms for joint-market participation under price uncertainties are insufficiently explored in the existing research. To bridge this gap, we develop a novel BESS joint bidding strategy that utilizes deep reinforcement learning (DRL) to bid in the spot and contingency frequency control ancillary services (FCAS) markets. Our approach leverages a transformer-based temporal feature extractor to effectively respond to price fluctuations in seven markets simultaneously and helps DRL learn the best BESS bidding strategy in joint-market participation. Additionally, unlike conventional \"black-box\" DRL model, our approach is more interpretable and provides valuable insights into the temporal bidding behavior of BESS in the dynamic electricity market. We validate our method using realistic market prices from the Australian National Electricity Market. The results show that our strategy outperforms benchmarks, including both optimization-based and other DRL-based strategies, by substantial margins. Our findings further suggest that effective temporal-aware bidding can significantly increase profits in the spot and contingency FCAS markets compared to individual market participation.\n    ",
        "primary_category": "eess.SY",
        "categories": [
            "cs.LG",
            "math.OC"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19111": {
        "title": "Deep Network for Image Compressed Sensing Coding Using Local Structural Sampling",
        "authors": [
            "Wenxue Cui",
            "Xingtao Wang",
            "Xiaopeng Fan",
            "Shaohui Liu",
            "Xinwei Gao",
            "Debin Zhao"
        ],
        "comments": "Accepted by ACM Transactions on Multimedia Computing Communications and Applications (TOMM)",
        "subjects": "Image and Video Processing (eess.IV)",
        "abstract": "Existing image compressed sensing (CS) coding frameworks usually solve an inverse problem based on measurement coding and optimization-based image reconstruction, which still exist the following two challenges: 1) The widely used random sampling matrix, such as the Gaussian Random Matrix (GRM), usually leads to low measurement coding efficiency. 2) The optimization-based reconstruction methods generally maintain a much higher computational complexity. In this paper, we propose a new CNN based image CS coding framework using local structural sampling (dubbed CSCNet) that includes three functional modules: local structural sampling, measurement coding and Laplacian pyramid reconstruction. In the proposed framework, instead of GRM, a new local structural sampling matrix is first developed, which is able to enhance the correlation between the measurements through a local perceptual sampling strategy. Besides, the designed local structural sampling matrix can be jointly optimized with the other functional modules during training process. After sampling, the measurements with high correlations are produced, which are then coded into final bitstreams by the third-party image codec. At last, a Laplacian pyramid reconstruction network is proposed to efficiently recover the target image from the measurement domain to the image domain. Extensive experimental results demonstrate that the proposed scheme outperforms the existing state-of-the-art CS coding methods, while maintaining fast computational speed.\n    ",
        "primary_category": "eess.IV",
        "categories": [
            "cs.CV"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19116": {
        "title": "How to Understand \"Support\"? An Implicit-enhanced Causal Inference Approach for Weakly-supervised Phrase Grounding",
        "authors": [
            "Jiamin Luo",
            "Jianing Zhao",
            "Jingjing Wang",
            "Guodong Zhou"
        ],
        "comments": " ",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "Weakly-supervised Phrase Grounding (WPG) is an emerging task of inferring the fine-grained phrase-region matching, while merely leveraging the coarse-grained sentence-image pairs for training. However, existing studies on WPG largely ignore the implicit phrase-region matching relations, which are crucial for evaluating the capability of models in understanding the deep multimodal semantics. To this end, this paper proposes an Implicit-Enhanced Causal Inference (IECI) approach to address the challenges of modeling the implicit relations and highlighting them beyond the explicit. Specifically, this approach leverages both the intervention and counterfactual techniques to tackle the above two challenges respectively. Furthermore, a high-quality implicit-enhanced dataset is annotated to evaluate IECI and detailed evaluations show the great advantages of IECI over the state-of-the-art baselines. Particularly, we observe an interesting finding that IECI outperforms the advanced multimodal LLMs by a large margin on this implicit-enhanced dataset, which may facilitate more research to evaluate the multimodal LLMs in this direction.\n    ",
        "primary_category": "cs.CL",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19118": {
        "title": "Continuous Sign Language Recognition Based on Motor attention mechanism and frame-level Self-distillation",
        "authors": [
            "Qidan Zhu",
            "Jing Li",
            "Fei Yuan",
            "Quan Gan"
        ],
        "comments": "10 pages, 7 figures",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Changes in facial expression, head movement, body movement and gesture movement are remarkable cues in sign language recognition, and most of the current continuous sign language recognition(CSLR) research methods mainly focus on static images in video sequences at the frame-level feature extraction stage, while ignoring the dynamic changes in the images. In this paper, we propose a novel motor attention mechanism to capture the distorted changes in local motion regions during sign language expression, and obtain a dynamic representation of image changes. And for the first time, we apply the self-distillation method to frame-level feature extraction for continuous sign language, which improves the feature expression without increasing the computational resources by self-distilling the features of adjacent stages and using the higher-order features as teachers to guide the lower-order features. The combination of the two constitutes our proposed holistic model of CSLR Based on motor attention mechanism and frame-level Self-Distillation (MAM-FSD), which improves the inference ability and robustness of the model. We conduct experiments on three publicly available datasets, and the experimental results show that our proposed method can effectively extract the sign language motion information in videos, improve the accuracy of CSLR and reach the state-of-the-art level.\n    ",
        "primary_category": "cs.CV",
        "categories": [],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19120": {
        "title": "A Naive Approach for Automatic Line-level Code Completion",
        "authors": [
            "Shamima Naznin",
            "Dr.Manishankar Mondal"
        ],
        "comments": "6 pages",
        "subjects": "Software Engineering (cs.SE)",
        "abstract": "Coding is an integral aspect of programming. A programmer can automatically complete a code fragment after writing a few tokens, and the process of automatic completion is known as code completion. Several research studies on code completion have previously been conducted for method body completion and method parameter completion. However, this fundamental study explores the automatic completion of any program statement that might not even be part of a method.\nThe goal is to provide suggestions to the programmer for completing code throughout the codebase by identifying and analyzing code similarities. The proposed methodology can be regarded as a fundamental framework for automated code completion. From the investigation of hundreds of revisions of four subject systems written in C and Java, it is observed that the proposed method can automatically complete around 22% of code statements with an average accuracy of 87% that a programmer writes during development, accelerating software development time. The empirical analysis further demonstrates that the approach can be used with programming language neutrality.\nThe study concludes by illustrating that taking 10 characters as prefixes before invoking completion provides maximum precision.\n    ",
        "primary_category": "cs.SE",
        "categories": [],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19125": {
        "title": "Highly efficient Gauss's law-preserving spectral algorithms for Maxwell's double-curl source and eigenvalue problems based on eigen-decomposition",
        "authors": [
            "Sen Lin",
            "Huiyuan Li",
            "Zhiguo Yang"
        ],
        "comments": " ",
        "subjects": "Numerical Analysis (math.NA)",
        "abstract": "In this paper, we present Gauss's law-preserving spectral methods and their efficient solution algorithms for curl-curl source and eigenvalue problems in two and three dimensions arising from Maxwell's equations. Arbitrary order $H(curl)$-conforming spectral basis functions in two and three dimensions are firstly proposed using compact combination of Legendre polynomials. A mixed formulation involving a Lagrange multiplier is then adopted to preserve the Gauss's law in the weak sense. To overcome the bottleneck of computational efficiency caused by the saddle-point nature of the mixed scheme, we present highly efficient solution algorithms based on reordering and decoupling of the resultant linear algebraic system and numerical eigen-decomposition of one dimensional mass matrix. The proposed solution algorithms are direct methods requiring only several matrix-matrix or matrix-tensor products of $N$-by-$N$ matrices, where $N$ is the highest polynomial order in each direction. Compared with other direct methods, the computational complexities are reduced from $O(N^6)$ and $O(N^9)$ to $O(N^3)$ and $O(N^4)$ with small and constant pre-factors for 2D and 3D cases, respectively, and can further be accelerated to $O(N^{2.807})$ and $O(N^{3.807})$, when boosted with the Strassen's matrix multiplication algorithm. Moreover, these algorithms strictly obey the Helmholtz-Hodge decomposition, thus totally eliminate the spurious eigen-modes of non-physical zero eigenvalues. Extensions of the proposed methods and algorithms to problems in complex geometries with variable coefficients and inhomogeneous boundary conditions are discussed to deal with more general situations. Ample numerical examples for solving Maxwell's source and eigenvalue problems are presented to demonstrate the accuracy and efficiency of the proposed methods.\n    ",
        "primary_category": "math.NA",
        "categories": [],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19128": {
        "title": "ARMCHAIR: integrated inverse reinforcement learning and model predictive control for human-robot collaboration",
        "authors": [
            "Angelo Caregnato-Neto",
            "Luciano Cavalcante Siebert",
            "Arkady Zgonnikov",
            "Marcos Ricardo Omena de Albuquerque Maximo",
            "Rubens Junqueira Magalh\u00e3es Afonso"
        ],
        "comments": " ",
        "subjects": "Robotics (cs.RO)",
        "abstract": "One of the key issues in human-robot collaboration is the development of computational models that allow robots to predict and adapt to human behavior. Much progress has been achieved in developing such models, as well as control techniques that address the autonomy problems of motion planning and decision-making in robotics. However, the integration of computational models of human behavior with such control techniques still poses a major challenge, resulting in a bottleneck for efficient collaborative human-robot teams. In this context, we present a novel architecture for human-robot collaboration: Adaptive Robot Motion for Collaboration with Humans using Adversarial Inverse Reinforcement learning (ARMCHAIR). Our solution leverages adversarial inverse reinforcement learning and model predictive control to compute optimal trajectories and decisions for a mobile multi-robot system that collaborates with a human in an exploration task. During the mission, ARMCHAIR operates without human intervention, autonomously identifying the necessity to support and acting accordingly. Our approach also explicitly addresses the network connectivity requirement of the human-robot team. Extensive simulation-based evaluations demonstrate that ARMCHAIR allows a group of robots to safely support a simulated human in an exploration scenario, preventing collisions and network disconnections, and improving the overall performance of the task.\n    ",
        "primary_category": "cs.RO",
        "categories": [
            "cs.HC",
            "cs.MA",
            "eess.SY"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19132": {
        "title": "Weighted least $\\ell_p$ approximation on compact Riemannian manifolds",
        "authors": [
            "Jiansong Li",
            "Yun Ling",
            "Jiaxin Geng",
            "Heping Wang"
        ],
        "comments": "23 pages",
        "subjects": "Numerical Analysis (math.NA)",
        "abstract": "Given a sequence of Marcinkiewicz-Zygmund inequalities in $L_2$ on a compact space, Gr\u00f6chenig in \\cite{G} discussed weighted least squares approximation and least squares quadrature. Inspired by this work, for all $1\\le p\\le\\infty$, we develop weighted least $\\ell_p$ approximation induced by a sequence of Marcinkiewicz-Zygmund inequalities in $L_p$ on a compact smooth Riemannian manifold $\\Bbb M$ with normalized Riemannian measure (typical examples are the torus and the sphere). In this paper we derive corresponding approximation theorems with the error measured in $L_q,\\,1\\le q\\le\\infty$, and least quadrature errors for both Sobolev spaces $H_p^r(\\Bbb M), \\, r>d/p$ generated by eigenfunctions associated with the Laplace-Beltrami operator and Besov spaces $B_{p,\\tau}^r(\\Bbb M),\\, 0<\\tau\\le \\infty, r>d/p $ defined by best polynomial approximation. Finally, we discuss the optimality of the obtained results by giving sharp estimates of sampling numbers and optimal quadrature errors for the aforementioned spaces.\n    ",
        "primary_category": "math.NA",
        "categories": [],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19133": {
        "title": "Evaluating Webcam-based Gaze Data as an Alternative for Human Rationale Annotations",
        "authors": [
            "Stephanie Brandl",
            "Oliver Eberle",
            "Tiago Ribeiro",
            "Anders S\u00f8gaard",
            "Nora Hollenstein"
        ],
        "comments": "Accepted to LREC-COLING 2024",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "Rationales in the form of manually annotated input spans usually serve as ground truth when evaluating explainability methods in NLP. They are, however, time-consuming and often biased by the annotation process. In this paper, we debate whether human gaze, in the form of webcam-based eye-tracking recordings, poses a valid alternative when evaluating importance scores. We evaluate the additional information provided by gaze data, such as total reading times, gaze entropy, and decoding accuracy with respect to human rationale annotations. We compare WebQAmGaze, a multilingual dataset for information-seeking QA, with attention and explainability-based importance scores for 4 different multilingual Transformer-based language models (mBERT, distil-mBERT, XLMR, and XLMR-L) and 3 languages (English, Spanish, and German). Our pipeline can easily be applied to other tasks and languages. Our findings suggest that gaze data offers valuable linguistic insights that could be leveraged to infer task difficulty and further show a comparable ranking of explainability methods to that of human rationales.\n    ",
        "primary_category": "cs.CL",
        "categories": [],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19135": {
        "title": "Think Fast, Think Slow, Think Critical: Designing an Automated Propaganda Detection Tool",
        "authors": [
            "Liudmila Zavolokina",
            "Kilian Sprenkamp",
            "Zoya Katashinskaya",
            "Daniel Gordon Jones",
            "Gerhard Schwabe"
        ],
        "comments": "The paper is accepted for publication in proceedings of the CHI Conference on Human Factors in Computing Systems (2024)",
        "subjects": "Human-Computer Interaction (cs.HC)",
        "abstract": "In today's digital age, characterized by rapid news consumption and increasing vulnerability to propaganda, fostering citizens' critical thinking is crucial for stable democracies. This paper introduces the design of ClarifAI, a novel automated propaganda detection tool designed to nudge readers towards more critical news consumption by activating the analytical mode of thinking, following Kahneman's dual-system theory of cognition. Using Large Language Models, ClarifAI detects propaganda in news articles and provides context-rich explanations, enhancing users' understanding and critical thinking. Our contribution is threefold: first, we propose the design of ClarifAI; second, in an online experiment, we demonstrate that this design effectively encourages news readers to engage in more critical reading; and third, we emphasize the value of explanations for fostering critical thinking. The study thus offers both a practical tool and useful design knowledge for mitigating propaganda in digital news.\n    ",
        "primary_category": "cs.HC",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19142": {
        "title": "ProtoP-OD: Explainable Object Detection with Prototypical Parts",
        "authors": [
            "Pavlos Rath-Manakidis",
            "Frederik Strothmann",
            "Tobias Glasmachers",
            "Laurenz Wiskott"
        ],
        "comments": "9 pages, 11 figures",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Interpretation and visualization of the behavior of detection transformers tends to highlight the locations in the image that the model attends to, but it provides limited insight into the \\emph{semantics} that the model is focusing on. This paper introduces an extension to detection transformers that constructs prototypical local features and uses them in object detection. These custom features, which we call prototypical parts, are designed to be mutually exclusive and align with the classifications of the model. The proposed extension consists of a bottleneck module, the prototype neck, that computes a discretized representation of prototype activations and a new loss term that matches prototypes to object classes. This setup leads to interpretable representations in the prototype neck, allowing visual inspection of the image content perceived by the model and a better understanding of the model's reliability. We show experimentally that our method incurs only a limited performance penalty, and we provide examples that demonstrate the quality of the explanations provided by our method, which we argue outweighs the performance penalty.\n    ",
        "primary_category": "cs.CV",
        "categories": [
            "cs.LG"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19144": {
        "title": "Weakly Supervised Monocular 3D Detection with a Single-View Image",
        "authors": [
            "Xueying Jiang",
            "Sheng Jin",
            "Lewei Lu",
            "Xiaoqin Zhang",
            "Shijian Lu"
        ],
        "comments": " ",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Monocular 3D detection (M3D) aims for precise 3D object localization from a single-view image which usually involves labor-intensive annotation of 3D detection boxes. Weakly supervised M3D has recently been studied to obviate the 3D annotation process by leveraging many existing 2D annotations, but it often requires extra training data such as LiDAR point clouds or multi-view images which greatly degrades its applicability and usability in various applications. We propose SKD-WM3D, a weakly supervised monocular 3D detection framework that exploits depth information to achieve M3D with a single-view image exclusively without any 3D annotations or other training data. One key design in SKD-WM3D is a self-knowledge distillation framework, which transforms image features into 3D-like representations by fusing depth information and effectively mitigates the inherent depth ambiguity in monocular scenarios with little computational overhead in inference. In addition, we design an uncertainty-aware distillation loss and a gradient-targeted transfer modulation strategy which facilitate knowledge acquisition and knowledge transfer, respectively. Extensive experiments show that SKD-WM3D surpasses the state-of-the-art clearly and is even on par with many fully supervised methods.\n    ",
        "primary_category": "cs.CV",
        "categories": [],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19145": {
        "title": "A SAM-guided Two-stream Lightweight Model for Anomaly Detection",
        "authors": [
            "Chenghao Li",
            "Lei Qi",
            "Xin Geng"
        ],
        "comments": " ",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "In industrial anomaly detection, model efficiency and mobile-friendliness become the primary concerns in real-world applications. Simultaneously, the impressive generalization capabilities of Segment Anything (SAM) have garnered broad academic attention, making it an ideal choice for localizing unseen anomalies and diverse real-world patterns. In this paper, considering these two critical factors, we propose a SAM-guided Two-stream Lightweight Model for unsupervised anomaly detection (STLM) that not only aligns with the two practical application requirements but also harnesses the robust generalization capabilities of SAM. We employ two lightweight image encoders, i.e., our two-stream lightweight module, guided by SAM's knowledge. To be specific, one stream is trained to generate discriminative and general feature representations in both normal and anomalous regions, while the other stream reconstructs the same images without anomalies, which effectively enhances the differentiation of two-stream representations when facing anomalous regions. Furthermore, we employ a shared mask decoder and a feature aggregation module to generate anomaly maps. Our experiments conducted on MVTec AD benchmark show that STLM, with about 16M parameters and achieving an inference time in 20ms, competes effectively with state-of-the-art methods in terms of performance, 98.26% on pixel-level AUC and 94.92% on PRO. We further experiment on more difficult datasets, e.g., VisA and DAGM, to demonstrate the effectiveness and generalizability of STLM.\n    ",
        "primary_category": "cs.CV",
        "categories": [],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19147": {
        "title": "Efficient quaternion CUR method for low-rank approximation to quaternion matrix",
        "authors": [
            "Peng-Ling Wu",
            "Kit Ian Kou",
            "Hongmin Cai",
            "Zhaoyuan Yu"
        ],
        "comments": " ",
        "subjects": "Numerical Analysis (math.NA)",
        "abstract": "The low-rank quaternion matrix approximation has been successfully applied in many applications involving signal processing and color image processing. However, the cost of quaternion models for generating low-rank quaternion matrix approximation is sometimes considerable due to the computation of the quaternion singular value decomposition (QSVD), which limits their application to real large-scale data. To address this deficiency, an efficient quaternion matrix CUR (QMCUR) method for low-rank approximation is suggested, which provides significant acceleration in color image processing. We first explore the QMCUR approximation method, which uses actual columns and rows of the given quaternion matrix, instead of the costly QSVD. Additionally, two different sampling strategies are used to sample the above-selected columns and rows. Then, the perturbation analysis is performed on the QMCUR approximation of noisy versions of low-rank quaternion matrices. Extensive experiments on both synthetic and real data further reveal the superiority of the proposed algorithm compared with other algorithms for getting low-rank approximation, in terms of both efficiency and accuracy.\n    ",
        "primary_category": "math.NA",
        "categories": [],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19155": {
        "title": "Beyond Language Models: Byte Models are Digital World Simulators",
        "authors": [
            "Shangda Wu",
            "Xu Tan",
            "Zili Wang",
            "Rui Wang",
            "Xiaobing Li",
            "Maosong Sun"
        ],
        "comments": "19 pages, 5 figures, 5 tables",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Traditional deep learning often overlooks bytes, the basic units of the digital world, where all forms of information and operations are encoded and manipulated in binary format. Inspired by the success of next token prediction in natural language processing, we introduce bGPT, a model with next byte prediction to simulate the digital world. bGPT matches specialized models in performance across various modalities, including text, audio, and images, and offers new possibilities for predicting, simulating, and diagnosing algorithm or hardware behaviour. It has almost flawlessly replicated the process of converting symbolic music data, achieving a low error rate of 0.0011 bits per byte in converting ABC notation to MIDI format. In addition, bGPT demonstrates exceptional capabilities in simulating CPU behaviour, with an accuracy exceeding 99.99% in executing various operations. Leveraging next byte prediction, models like bGPT can directly learn from vast binary data, effectively simulating the intricate patterns of the digital world.\n    ",
        "primary_category": "cs.LG",
        "categories": [],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19163": {
        "title": "FedStruct: Federated Decoupled Learning over Interconnected Graphs",
        "authors": [
            "Javad Aliakbari",
            "Johan \u00d6stman",
            "Alexandre Graell i Amat"
        ],
        "comments": "10 pages plus 13 pages of appendices",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "We address the challenge of federated learning on graph-structured data distributed across multiple clients. Specifically, we focus on the prevalent scenario of interconnected subgraphs, where inter-connections between different clients play a critical role. We present a novel framework for this scenario, named FedStruct, that harnesses deep structural dependencies. To uphold privacy, unlike existing methods, FedStruct eliminates the necessity of sharing or generating sensitive node features or embeddings among clients. Instead, it leverages explicit global graph structure information to capture inter-node dependencies. We validate the effectiveness of FedStruct through experimental results conducted on six datasets for semi-supervised node classification, showcasing performance close to the centralized approach across various scenarios, including different data partitioning methods, varying levels of label availability, and number of clients.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.IT"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19166": {
        "title": "Conversational Language Models for Human-in-the-Loop Multi-Robot Coordination",
        "authors": [
            "William Hunt",
            "Toby Godfrey",
            "Mohammad D. Soorati"
        ],
        "comments": " ",
        "subjects": "Robotics (cs.RO)",
        "abstract": "With the increasing prevalence and diversity of robots interacting in the real world, there is need for flexible, on-the-fly planning and cooperation. Large Language Models are starting to be explored in a multimodal setup for communication, coordination, and planning in robotics. Existing approaches generally use a single agent building a plan, or have multiple homogeneous agents coordinating for a simple task. We present a decentralised, dialogical approach in which a team of agents with different abilities plans solutions through peer-to-peer and human-robot discussion. We suggest that argument-style dialogues are an effective way to facilitate adaptive use of each agent's abilities within a cooperative team. Two robots discuss how to solve a cleaning problem set by a human, define roles, and agree on paths they each take. Each step can be interrupted by a human advisor and agents check their plans with the human. Agents then execute this plan in the real world, collecting rubbish from people in each room. Our implementation uses text at every step, maintaining transparency and effective human-multi-robot interaction.\n    ",
        "primary_category": "cs.RO",
        "categories": [],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19167": {
        "title": "Teaching Large Language Models an Unseen Language on the Fly",
        "authors": [
            "Chen Zhang",
            "Xiao Liu",
            "Jiuheng Lin",
            "Yansong Feng"
        ],
        "comments": " ",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "Existing large language models struggle to support numerous low-resource languages, particularly the extremely low-resource ones where there is minimal training data available for effective parameter updating. We thus investigate whether LLMs can learn a new language on the fly solely through prompting. To study this question, we collect a research suite for Zhuang, a language supported by no LLMs currently. We introduce \\textsc{DiPMT++}, a framework for adapting LLMs to unseen languages by in-context learning. Using a dictionary and only 5K parallel sentences, \\textsc{DiPMT++} significantly enhances the performance of GPT-4 from 0 to 16 BLEU for Chinese-to-Zhuang translation and achieves 32 BLEU for Zhuang-to-Chinese translation. Furthermore, we demonstrate the practical utility of this framework in aiding humans to translate completely unseen languages, which could contribute to the preservation of linguistic diversity.\n    ",
        "primary_category": "cs.CL",
        "categories": [],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19168": {
        "title": "Disturbance Decoupling Problem for $n$-link chain pendulum on a cart system",
        "authors": [
            "Sayar Das",
            "Deepak Patil"
        ],
        "comments": " ",
        "subjects": "Systems and Control (eess.SY)",
        "abstract": "A disturbance decoupling problem for a $n$-link chain pendulum on a cart is considered. A model of the cart developed in a coordinate-free framework and the linearized equations of this system are considered from [1]. It is shown that it is possible to design a suitable state feedback such that the angular position or velocity of the $n^{th}$-link can always be decoupled from the disturbance coming at the cart.\n    ",
        "primary_category": "eess.SY",
        "categories": [],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19171": {
        "title": "Towards Assessing Spread in Sets of Software Architecture Designs",
        "authors": [
            "Vittorio Cortellessa",
            "J. Andres Diaz-Pace",
            "Daniele Di Pompeo",
            "Michele Tucci"
        ],
        "comments": "17th European Conference on Software Architecture (ECSA 2023), 8 pages",
        "subjects": "Software Engineering (cs.SE)",
        "abstract": "Several approaches have recently used automated techniques to generate architecture design alternatives by means of optimization techniques. These approaches aim at improving an initial architecture with respect to quality aspects, such as performance, reliability, or maintainability. In this context, each optimization experiment usually produces a different set of architecture alternatives that is characterized by specific settings. As a consequence, the designer is left with the task of comparing such sets to identify the settings that lead to better solution sets for the problem. To assess the quality of solution sets, multi-objective optimization commonly relies on quality indicators. Among these, the quality indicator for the maximum spread estimates the diversity of the generated alternatives, providing a measure of how much of the solution space has been explored. However, the maximum spread indicator is computed only on the objective space and does not consider architectural information (e.g., components structure, design decisions) from the architectural space. In this paper, we propose a quality indicator for the spread that assesses the diversity of alternatives by taking into account architectural features. To compute the spread, we rely on a notion of distance between alternatives according to the way they were generated during the optimization. We demonstrate how our architectural quality indicator can be applied to a dataset from the literature.\n    ",
        "primary_category": "cs.SE",
        "categories": [
            "cs.PF"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19172": {
        "title": "Point Processes and spatial statistics in time-frequency analysis",
        "authors": [
            "Barbara Pascal",
            "R\u00e9mi Bardenet"
        ],
        "comments": "Submitted",
        "subjects": "Signal Processing (eess.SP)",
        "abstract": "A finite-energy signal is represented by a square-integrable, complex-valued function $t\\mapsto s(t)$ of a real variable $t$, interpreted as time. Similarly, a noisy signal is represented by a random process. Time-frequency analysis, a subfield of signal processing, amounts to describing the temporal evolution of the frequency content of a signal. Loosely speaking, if $s$ is the audio recording of a musical piece, time-frequency analysis somehow consists in writing the musical score of the piece. Mathematically, the operation is performed through a transform $\\mathcal{V}$, mapping $s \\in L^2(\\mathbb{R})$ onto a complex-valued function $\\mathcal{V}s \\in L^2(\\mathbb{R}^2)$ of time $t$ and angular frequency $\\omega$. The squared modulus $(t, \\omega) \\mapsto \\vert\\mathcal{V}s(t,\\omega)\\vert^2$ of the time-frequency representation is known as the spectrogram of $s$; in the musical score analogy, a peaked spectrogram at $(t_0,\\omega_0)$ corresponds to a musical note at angular frequency $\\omega_0$ localized at time $t_0$. More generally, the intuition is that upper level sets of the spectrogram contain relevant information about in the original signal. Hence, many signal processing algorithms revolve around identifying maxima of the spectrogram. In contrast, zeros of the spectrogram indicate perfect silence, that is, a time at which a particular frequency is absent. Assimilating $\\mathbb{R}^2$ to $\\mathbb{C}$ through $z = \\omega + \\mathrm{i}t$, this chapter focuses on time-frequency transforms $\\mathcal{V}$ that map signals to analytic functions. The zeros of the spectrogram of a noisy signal are then the zeros of a random analytic function, hence forming a Point Process in $\\mathbb{C}$. This chapter is devoted to the study of these Point Processes, to their links with zeros of Gaussian Analytic Functions, and to designing signal detection and denoising algorithms using spatial statistics.\n    ",
        "primary_category": "eess.SP",
        "categories": [
            "cs.SD",
            "eess.AS",
            "math.PR"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19173": {
        "title": "StarCoder 2 and The Stack v2: The Next Generation",
        "authors": [
            "Anton Lozhkov",
            "Raymond Li",
            "Loubna Ben Allal",
            "Federico Cassano",
            "Joel Lamy-Poirier",
            "Nouamane Tazi",
            "Ao Tang",
            "Dmytro Pykhtar",
            "Jiawei Liu",
            "Yuxiang Wei",
            "Tianyang Liu",
            "Max Tian",
            "Denis Kocetkov",
            "Arthur Zucker",
            "Younes Belkada",
            "Zijian Wang",
            "Qian Liu",
            "Dmitry Abulkhanov",
            "Indraneil Paul",
            "Zhuang Li",
            "Wen-Ding Li",
            "Megan Risdal",
            "Jia Li",
            "Jian Zhu",
            "Terry Yue Zhuo",
            "Evgenii Zheltonozhskii",
            "Nii Osae Osae Dade",
            "Wenhao Yu",
            "Lucas Krau\u00df",
            "Naman Jain",
            "Yixuan Su",
            "Xuanli He",
            "Manan Dey",
            "Edoardo Abati",
            "Yekun Chai",
            "Niklas Muennighoff",
            "Xiangru Tang",
            "Muhtasham Oblokulov",
            "Christopher Akiki",
            "Marc Marone",
            "Chenghao Mou",
            "Mayank Mishra",
            "Alex Gu",
            "Binyuan Hui",
            "Tri Dao",
            "Armel Zebaze",
            "Olivier Dehaene",
            "Nicolas Patry",
            "Canwen Xu",
            "Julian McAuley",
            "Han Hu",
            "Torsten Scholak",
            "Sebastien Paquet",
            "Jennifer Robinson",
            "Carolyn Jane Anderson",
            "Nicolas Chapados",
            "Mostofa Patwary",
            "Nima Tajbakhsh",
            "Yacine Jernite",
            "Carlos Mu\u00f1oz Ferrandis",
            "Lingming Zhang",
            "Sean Hughes",
            "Thomas Wolf",
            "Arjun Guha",
            "Leandro von Werra",
            "Harm de Vries"
        ],
        "comments": " ",
        "subjects": "Software Engineering (cs.SE)",
        "abstract": "The BigCode project, an open-scientific collaboration focused on the responsible development of Large Language Models for Code (Code LLMs), introduces StarCoder2. In partnership with Software Heritage (SWH), we build The Stack v2 on top of the digital commons of their source code archive. Alongside the SWH repositories spanning 619 programming languages, we carefully select other high-quality data sources, such as GitHub pull requests, Kaggle notebooks, and code documentation. This results in a training set that is 4x larger than the first StarCoder dataset. We train StarCoder2 models with 3B, 7B, and 15B parameters on 3.3 to 4.3 trillion tokens and thoroughly evaluate them on a comprehensive set of Code LLM benchmarks. We find that our small model, StarCoder2-3B, outperforms other Code LLMs of similar size on most benchmarks, and also outperforms StarCoderBase-15B. Our large model, StarCoder2- 15B, significantly outperforms other models of comparable size. In addition, it matches or outperforms CodeLlama-34B, a model more than twice its size. Although DeepSeekCoder- 33B is the best-performing model at code completion for high-resource languages, we find that StarCoder2-15B outperforms it on math and code reasoning benchmarks, as well as several low-resource languages. We make the model weights available under an OpenRAIL license and ensure full transparency regarding the training data by releasing the SoftWare Heritage persistent IDentifiers (SWHIDs) of the source code data.\n    ",
        "primary_category": "cs.SE",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19180": {
        "title": "ModZoo: A Large-Scale Study of Modded Android Apps and their Markets",
        "authors": [
            "Luis A. Saavedra",
            "Hridoy S. Dutta",
            "Alastair R. Beresford",
            "Alice Hutchings"
        ],
        "comments": " ",
        "subjects": "Other Computer Science (cs.OH)",
        "abstract": "We present the results of the first large-scale study into Android markets that offer modified or modded apps: apps whose features and functionality have been altered by a third-party. We analyse over 146k (thousand) apps obtained from 13 of the most popular modded app markets. Around 90% of apps we collect are altered in some way when compared to the official counterparts on Google Play. Modifications include games cheats, such as infinite coins or lives; mainstream apps with premium features provided for free; and apps with modified advertising identifiers or excluded ads. We find the original app developers lose significant potential revenue due to: the provision of paid for apps for free (around 5% of the apps across all markets); the free availability of premium features that require payment in the official app; and modified advertising identifiers. While some modded apps have all trackers and ads removed (3%), in general, the installation of these apps is significantly more risky for the user than the official version: modded apps are ten times more likely to be marked as malicious and often request additional permissions.\n    ",
        "primary_category": "cs.OH",
        "categories": [
            "cs.CR",
            "cs.SE"
        ],
        "submitted_date": "15 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19184": {
        "title": "Data Transfer Optimizations for Host-CPU and Accelerators in AXI4MLIR",
        "authors": [
            "Jude Haris",
            "Nicolas Bohm Agostini",
            "Antonino Tumeo",
            "David Kaeli",
            "Jos\u00e9 Cano"
        ],
        "comments": " ",
        "subjects": "Programming Languages (cs.PL)",
        "abstract": "As custom hardware accelerators become more prevalent, it becomes increasingly important to automatically generate efficient host-driver code that can fully leverage the capabilities of these accelerators. This approach saves time and reduces the likelihood of errors that can occur during manual implementation. AXI4MLIR extends the MLIR compiler framework to generate host-driver code for custom accelerators for linear algebra problems. By leveraging specific compiler optimizations, we can further increase accelerator utilization.\nIn this work we offer two key observations through a MatMul accelerator case study. First, the accelerator's compute core utilization is less than 10%, and second, the critical latency bottleneck is caused by copying data between the heap and memory-mapped DMA buffers. We identify a set of missing host code optimizations to improve the under-utilization and the latency bottleneck. Therefore, we propose three key host-code data-movement-related optimizations, extending AXI4MLIR. The optimizations provide DMA-based data allocation, coalescing of DMA transfers, and pipelining of the accelerator's load, compute, and store stages.\n    ",
        "primary_category": "cs.PL",
        "categories": [],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19186": {
        "title": "Disentangling representations of retinal images with generative models",
        "authors": [
            "Sarah M\u00fcller",
            "Lisa M. Koch",
            "Hendrik P. A. Lensch",
            "Philipp Berens"
        ],
        "comments": " ",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Retinal fundus images play a crucial role in the early detection of eye diseases and, using deep learning approaches, recent studies have even demonstrated their potential for detecting cardiovascular risk factors and neurological disorders. However, the impact of technical factors on these images can pose challenges for reliable AI applications in ophthalmology. For example, large fundus cohorts are often confounded by factors like camera type, image quality or illumination level, bearing the risk of learning shortcuts rather than the causal relationships behind the image generation process. Here, we introduce a novel population model for retinal fundus images that effectively disentangles patient attributes from camera effects, thus enabling controllable and highly realistic image generation. To achieve this, we propose a novel disentanglement loss based on distance correlation. Through qualitative and quantitative analyses, we demonstrate the effectiveness of this novel loss function in disentangling the learned subspaces. Our results show that our model provides a new perspective on the complex relationship between patient attributes and technical confounders in retinal fundus image generation.\n    ",
        "primary_category": "cs.CV",
        "categories": [
            "cs.LG"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19189": {
        "title": "Link Recommendation to Augment Influence Diffusion with Provable Guarantees",
        "authors": [
            "Xiaolong Chen",
            "Yifan Song",
            "Jing Tang"
        ],
        "comments": "TheWebConf'24; Corresponding author: Jing Tang",
        "subjects": "Social and Information Networks (cs.SI)",
        "abstract": "Link recommendation systems in online social networks (OSNs), such as Facebook's ``People You May Know'', Twitter's ``Who to Follow'', and Instagram's ``Suggested Accounts'', facilitate the formation of new connections among users. This paper addresses the challenge of link recommendation for the purpose of social influence maximization. In particular, given a graph $G$ and the seed set $S$, our objective is to select $k$ edges that connect seed nodes and ordinary nodes to optimize the influence dissemination of the seed set. This problem, referred to as influence maximization with augmentation (IMA), has been proven to be NP-hard.\nIn this paper, we propose an algorithm, namely \\textsf{AIS}, consisting of an efficient estimator for augmented influence estimation and an accelerated sampling approach. \\textsf{AIS} provides a $(1-1/\\mathrm{e}-\\varepsilon)$-approximate solution with a high probability of $1-\\delta$, and runs in $O(k^2 (m+n) \\log (n / \\delta) / \\varepsilon^2 + k \\left|E_{\\mathcal{C}}\\right|)$ time assuming that the influence of any singleton node is smaller than that of the seed set. To the best of our knowledge, this is the first algorithm that can be implemented on large graphs containing millions of nodes while preserving strong theoretical guarantees. We conduct extensive experiments to demonstrate the effectiveness and efficiency of our proposed algorithm.\n    ",
        "primary_category": "cs.SI",
        "categories": [],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19191": {
        "title": "An asymptotic-preserving method for the three-temperature radiative transfer model",
        "authors": [
            "Ruo Li",
            "Weiming Li",
            "Shengtong Liang",
            "Yuehan Shao",
            "Min Tang",
            "Yanli Wang"
        ],
        "comments": " ",
        "subjects": "Numerical Analysis (math.NA)",
        "abstract": "We present an asymptotic-preserving (AP) numerical method for solving the three-temperature radiative transfer model, which holds significant importance in inertial confinement fusion. A carefully designedsplitting method is developed that can provide a general framework of extending AP schemes for the gray radiative transport equation to the more complex three-temperature radiative transfer model. The proposed scheme captures two important limiting models: the three-temperature radiation diffusion equation (3TRDE) when opacity approaches infinity and the two-temperature limit when the ion-electron coupling coefficient goes to infinity. We have rigorously demonstrated the AP property and energy conservation characteristics of the proposed scheme and its efficiency has been validated through a series of benchmark tests in the numerical part.\n    ",
        "primary_category": "math.NA",
        "categories": [
            "math-ph"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19194": {
        "title": "High Expectations: An Observational Study of Programming and Cannabis Intoxication",
        "authors": [
            "Wenxin He",
            "Manasvi Parikh",
            "Westley Weimer",
            "Madeline Endres"
        ],
        "comments": "To appear in the proceedings of the International Conference of Software Engineering (ICSE), 2024",
        "subjects": "Software Engineering (cs.SE)",
        "abstract": "Anecdotal evidence of cannabis use by professional programmers abounds. Recent studies have found that some professionals regularly use cannabis while programming even for work-related tasks. However, accounts of the impacts of cannabis on programming vary widely and are often contradictory. For example, some programmers claim that it impairs their ability to generate correct solutions while others claim it enhances creativity and focus. There remains a need for an empirical understanding of the true impacts of cannabis on programming. This paper presents the first controlled observational study of the effects of cannabis on programming ability. Based on a within-subjects design with over 70 participants, we find that at ecologically valid dosages, cannabis significantly impairs programming performance. Programs implemented while high contain more bugs and take longer to write (p < 0.05), a small to medium effect (0.22 <= d <= 0.44). We also did not find any evidence that high programmers generate more divergent solutions. However, programmers can accurately assess differences in their programming performance (r = 0.59), even when under the influence of cannabis. We hope that this research will facilitate evidence-based policies and help developers make informed decisions regarding cannabis use while programming.\n    ",
        "primary_category": "cs.SE",
        "categories": [],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19195": {
        "title": "Negative Sampling in Knowledge Graph Representation Learning: A Review",
        "authors": [
            "Tiroshan Madushanka",
            "Ryutaro Ichise"
        ],
        "comments": " ",
        "subjects": "Artificial Intelligence (cs.AI)",
        "abstract": "Knowledge graph representation learning (KGRL) or knowledge graph embedding (KGE) plays a crucial role in AI applications for knowledge construction and information exploration. These models aim to encode entities and relations present in a knowledge graph into a lower-dimensional vector space. During the training process of KGE models, using positive and negative samples becomes essential for discrimination purposes. However, obtaining negative samples directly from existing knowledge graphs poses a challenge, emphasizing the need for effective generation techniques. The quality of these negative samples greatly impacts the accuracy of the learned embeddings, making their generation a critical aspect of KGRL. This comprehensive survey paper systematically reviews various negative sampling (NS) methods and their contributions to the success of KGRL. Their respective advantages and disadvantages are outlined by categorizing existing NS methods into five distinct categories. Moreover, this survey identifies open research questions that serve as potential directions for future investigations. By offering a generalization and alignment of fundamental NS concepts, this survey provides valuable insights for designing effective NS methods in the context of KGRL and serves as a motivating force for further advancements in the field.\n    ",
        "primary_category": "cs.AI",
        "categories": [],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19196": {
        "title": "Generative models struggle with kirigami metamaterials",
        "authors": [
            "Gerrit Felsch",
            "Viacheslav Slesarenko"
        ],
        "comments": " ",
        "subjects": "Computational Engineering, Finance, and Science (cs.CE)",
        "abstract": "Generative machine learning models have shown notable success in identifying architectures for metamaterials - materials whose behavior is determined primarily by their internal organization - that match specific target properties. By examining kirigami metamaterials, in which dependencies between cuts yield complex design restrictions, we demonstrate that this perceived success in the employment of generative models for metamaterials might be akin to survivorship bias. We assess the performance of the four most popular generative models - the Variational Autoencoder (VAE), the Generative Adversarial Network (GAN), the Wasserstein GAN (WGAN), and the Denoising Diffusion Probabilistic Model (DDPM) - in generating kirigami structures. Prohibiting cut intersections can prevent the identification of an appropriate similarity measure for kirigami metamaterials, significantly impacting the effectiveness of VAE and WGAN, which rely on the Euclidean distance - a metric shown to be unsuitable for considered geometries. This imposes significant limitations on employing modern generative models for the creation of diverse metamaterials.\n    ",
        "primary_category": "cs.CE",
        "categories": [
            "cond-mat.mtrl-sci",
            "cond-mat.soft"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19197": {
        "title": "Fine Structure-Aware Sampling: A New Sampling Training Scheme for Pixel-Aligned Implicit Models in Single-View Human Reconstruction",
        "authors": [
            "Kennard Yanting Chan",
            "Fayao Liu",
            "Guosheng Lin",
            "Chuan Sheng Foo",
            "Weisi Lin"
        ],
        "comments": "Accepted in Proceedings of the AAAI Conference on Artificial Intelligence, 2024 (AAAI 2024)",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Pixel-aligned implicit models, such as PIFu, PIFuHD, and ICON, are used for single-view clothed human reconstruction. These models need to be trained using a sampling training scheme. Existing sampling training schemes either fail to capture thin surfaces (e.g. ears, fingers) or cause noisy artefacts in reconstructed meshes. To address these problems, we introduce Fine Structured-Aware Sampling (FSS), a new sampling training scheme to train pixel-aligned implicit models for single-view human reconstruction. FSS resolves the aforementioned problems by proactively adapting to the thickness and complexity of surfaces. In addition, unlike existing sampling training schemes, FSS shows how normals of sample points can be capitalized in the training process to improve results. Lastly, to further improve the training process, FSS proposes a mesh thickness loss signal for pixel-aligned implicit models. It becomes computationally feasible to introduce this loss once a slight reworking of the pixel-aligned implicit function framework is carried out. Our results show that our methods significantly outperform SOTA methods qualitatively and quantitatively. Our code is publicly available at this https URL.\n    ",
        "primary_category": "cs.CV",
        "categories": [
            "cs.AI",
            "cs.LG"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19199": {
        "title": "Rewriting and Inductive Reasoning",
        "authors": [
            "M\u00e1rton Hajdu",
            "Laura Kov\u00e1cs",
            "Michael Rawson"
        ],
        "comments": " ",
        "subjects": "Logic in Computer Science (cs.LO)",
        "abstract": "Rewriting techniques based on reduction orderings generate \"just enough\" consequences to retain first-order completeness. This is ideal for superposition-based first-order theorem proving, but for at least one approach to inductive reasoning we show that we are missing crucial consequences. We therefore extend the superposition calculus with rewriting-based techniques to generate sufficient consequences for automating induction in saturation. When applying our work within the unit-equational fragment, our experiments with the theorem prover Vampire show significant improvements for inductive reasoning.\n    ",
        "primary_category": "cs.LO",
        "categories": [],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19200": {
        "title": "PRSA: Prompt Reverse Stealing Attacks against Large Language Models",
        "authors": [
            "Yong Yang",
            "Xuhong Zhang",
            "Yi Jiang",
            "Xi Chen",
            "Haoyu Wang",
            "Shouling Ji",
            "Zonghui Wang"
        ],
        "comments": " ",
        "subjects": "Cryptography and Security (cs.CR)",
        "abstract": "Prompt, recognized as crucial intellectual property, enables large language models (LLMs) to perform specific tasks without the need of fine-tuning, underscoring their escalating importance. With the rise of prompt-based services, such as prompt marketplaces and LLM applications, providers often display prompts' capabilities through input-output examples to attract users. However, this paradigm raises a pivotal security concern: does the exposure of input-output pairs pose the risk of potential prompt leakage, infringing on the intellectual property rights of the developers? To our knowledge, this problem still has not been comprehensively explored yet. To remedy this gap, in this paper, we perform the first in depth exploration and propose a novel attack framework for reverse-stealing prompts against commercial LLMs, namely PRSA. The main idea of PRSA is that by analyzing the critical features of the input-output pairs, we mimic and gradually infer (steal) the target prompts. In detail, PRSA mainly consists of two key phases: prompt mutation and prompt pruning. In the mutation phase, we propose a prompt attention algorithm based on differential feedback to capture these critical features for effectively inferring the target prompts. In the prompt pruning phase, we identify and mask the words dependent on specific inputs, enabling the prompts to accommodate diverse inputs for generalization. Through extensive evaluation, we verify that PRSA poses a severe threat in real world scenarios. We have reported these findings to prompt service providers and actively collaborate with them to take protective measures for prompt copyright.\n    ",
        "primary_category": "cs.CR",
        "categories": [
            "cs.CL"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19204": {
        "title": "PeLLE: Encoder-based language models for Brazilian Portuguese based on open data",
        "authors": [
            "Guilherme Lamartine de Mello",
            "Marcelo Finger",
            "and Felipe Serras",
            "Miguel de Mello Carpi",
            "Marcos Menon Jose",
            "Pedro Henrique Domingues",
            "Paulo Cavalim"
        ],
        "comments": "15 pages",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "In this paper we present PeLLE, a family of large language models based on the RoBERTa architecture, for Brazilian Portuguese, trained on curated, open data from the Carolina corpus. Aiming at reproducible results, we describe details of the pretraining of the models. We also evaluate PeLLE models against a set of existing multilingual and PT-BR refined pretrained Transformer-based LLM encoders, contrasting performance of large versus smaller-but-curated pretrained models in several downstream tasks. We conclude that several tasks perform better with larger models, but some tasks benefit from smaller-but-curated data in its pretraining.\n    ",
        "primary_category": "cs.CL",
        "categories": [],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19215": {
        "title": "Training Generative Image Super-Resolution Models by Wavelet-Domain Losses Enables Better Control of Artifacts",
        "authors": [
            "Cansu Korkmaz",
            "A. Murat Tekalp",
            "Zafer Dogan"
        ],
        "comments": "Accepted for IEEE CVPR 2024, total of 11 pages, 3 pages for references, 7 figures and 2 tables",
        "subjects": "Image and Video Processing (eess.IV)",
        "abstract": "Super-resolution (SR) is an ill-posed inverse problem, where the size of the set of feasible solutions that are consistent with a given low-resolution image is very large. Many algorithms have been proposed to find a \"good\" solution among the feasible solutions that strike a balance between fidelity and perceptual quality. Unfortunately, all known methods generate artifacts and hallucinations while trying to reconstruct high-frequency (HF) image details. A fundamental question is: Can a model learn to distinguish genuine image details from artifacts? Although some recent works focused on the differentiation of details and artifacts, this is a very challenging problem and a satisfactory solution is yet to be found. This paper shows that the characterization of genuine HF details versus artifacts can be better learned by training GAN-based SR models using wavelet-domain loss functions compared to RGB-domain or Fourier-space losses. Although wavelet-domain losses have been used in the literature before, they have not been used in the context of the SR task. More specifically, we train the discriminator only on the HF wavelet sub-bands instead of on RGB images and the generator is trained by a fidelity loss over wavelet subbands to make it sensitive to the scale and orientation of structures. Extensive experimental results demonstrate that our model achieves better perception-distortion trade-off according to multiple objective measures and visual evaluations.\n    ",
        "primary_category": "eess.IV",
        "categories": [
            "cs.CV"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19218": {
        "title": "Memory-Augmented Generative Adversarial Transformers",
        "authors": [
            "Stephan Raaijmakers",
            "Roos Bakker",
            "Anita Cremers",
            "Roy de Kleijn",
            "Tom Kouwenhoven",
            "Tessa Verhoef"
        ],
        "comments": " ",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "Conversational AI systems that rely on Large Language Models, like Transformers, have difficulty interweaving external data (like facts) with the language they generate. Vanilla Transformer architectures are not designed for answering factual questions with high accuracy. This paper investigates a possible route for addressing this problem. We propose to extend the standard Transformer architecture with an additional memory bank holding extra information (such as facts drawn from a knowledge base), and an extra attention layer for addressing this memory. We add this augmented memory to a Generative Adversarial Network-inspired Transformer architecture. This setup allows for implementing arbitrary felicity conditions on the generated language of the Transformer. We first demonstrate how this machinery can be deployed for handling factual questions in goal-oriented dialogues. Secondly, we demonstrate that our approach can be useful for applications like {\\it style adaptation} as well: the adaptation of utterances according to certain stylistic (external) constraints, like social properties of human interlocutors in dialogues.\n    ",
        "primary_category": "cs.CL",
        "categories": [],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19222": {
        "title": "Airport take-off and landing optimization through genetic algorithms",
        "authors": [
            "Fernando Guedan Pecker",
            "Cristian Ramirez Atencia"
        ],
        "comments": "Preprint submitted and accepted in Expert Systems",
        "subjects": "Neural and Evolutionary Computing (cs.NE)",
        "abstract": "This research addresses the crucial issue of pollution from aircraft operations, focusing on optimizing both gate allocation and runway scheduling simultaneously, a novel approach not previously explored. The study presents an innovative genetic algorithm-based method for minimizing pollution from fuel combustion during aircraft take-off and landing at airports. This algorithm uniquely integrates the optimization of both landing gates and take-off/landing runways, considering the correlation between engine operation time and pollutant levels. The approach employs advanced constraint handling techniques to manage the intricate time and resource limitations inherent in airport operations. Additionally, the study conducts a thorough sensitivity analysis of the model, with a particular emphasis on the mutation factor and the type of penalty function, to fine-tune the optimization process. This dual-focus optimization strategy represents a significant advancement in reducing environmental impact in the aviation sector, establishing a new standard for comprehensive and efficient airport operation management.\n    ",
        "primary_category": "cs.NE",
        "categories": [],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19223": {
        "title": "Edit and Alphabet-Ordering Sensitivity of Lex-parse",
        "authors": [
            "Yuto Nakashima",
            "Dominik K\u00f6ppl",
            "Mitsuru Funakoshi",
            "Shunsuke Inenaga",
            "Hideo Bannai"
        ],
        "comments": " ",
        "subjects": "Data Structures and Algorithms (cs.DS)",
        "abstract": "We investigate the compression sensitivity [Akagi et al., 2023] of lex-parse [Navarro et al., 2021] for two operations: (1) single character edit and (2) modification of the alphabet ordering, and give tight upper and lower bounds for both operations. For both lower bounds, we use the family of Fibonacci words. For the bounds on edit operations, our analysis makes heavy use of properties of the Lyndon factorization of Fibonacci words to characterize the structure of lex-parse.\n    ",
        "primary_category": "cs.DS",
        "categories": [],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19229": {
        "title": "CAPTURE-24: A large dataset of wrist-worn activity tracker data collected in the wild for human activity recognition",
        "authors": [
            "Shing Chan",
            "Hang Yuan",
            "Catherine Tong",
            "Aidan Acquah",
            "Abram Schonfeldt",
            "Jonathan Gershuny",
            "Aiden Doherty"
        ],
        "comments": " ",
        "subjects": "Human-Computer Interaction (cs.HC)",
        "abstract": "Existing activity tracker datasets for human activity recognition are typically obtained by having participants perform predefined activities in an enclosed environment under supervision. This results in small datasets with a limited number of activities and heterogeneity, lacking the mixed and nuanced movements normally found in free-living scenarios. As such, models trained on laboratory-style datasets may not generalise out of sample. To address this problem, we introduce a new dataset involving wrist-worn accelerometers, wearable cameras, and sleep diaries, enabling data collection for over 24 hours in a free-living setting. The result is CAPTURE-24, a large activity tracker dataset collected in the wild from 151 participants, amounting to 3883 hours of accelerometer data, of which 2562 hours are annotated. CAPTURE-24 is two to three orders of magnitude larger than existing publicly available datasets, which is critical to developing accurate human activity recognition models.\n    ",
        "primary_category": "cs.HC",
        "categories": [],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19232": {
        "title": "Trained Random Forests Completely Reveal your Dataset",
        "authors": [
            "Julien Ferry",
            "Ricardo Fukasawa",
            "Timoth\u00e9e Pascal",
            "Thibaut Vidal"
        ],
        "comments": " ",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "We introduce an optimization-based reconstruction attack capable of completely or near-completely reconstructing a dataset utilized for training a random forest. Notably, our approach relies solely on information readily available in commonly used libraries such as scikit-learn. To achieve this, we formulate the reconstruction problem as a combinatorial problem under a maximum likelihood objective. We demonstrate that this problem is NP-hard, though solvable at scale using constraint programming -- an approach rooted in constraint propagation and solution-domain reduction. Through an extensive computational investigation, we demonstrate that random forests trained without bootstrap aggregation but with feature randomization are susceptible to a complete reconstruction. This holds true even with a small number of trees. Even with bootstrap aggregation, the majority of the data can also be reconstructed. These findings underscore a critical vulnerability inherent in widely adopted ensemble methods, warranting attention and mitigation. Although the potential for such reconstruction attacks has been discussed in privacy research, our study provides clear empirical evidence of their practicability.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.CR"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19233": {
        "title": "Shared lightweight autonomous vehicles for urban food deliveries: A simulation study",
        "authors": [
            "Ainhoa Genua Cervi\u00f1o",
            "Naroa Coretti Sanchez",
            "Elaine Liu Wang",
            "Arnaud Grignard",
            "Kent Larson"
        ],
        "comments": "17 pages, 25 including abstract, 16 figures, journal paper",
        "subjects": "Computers and Society (cs.CY)",
        "abstract": "In recent years, the rapid growth of on-demand deliveries, especially in food deliveries, has spurred the exploration of innovative mobility solutions. In this context, lightweight autonomous vehicles have emerged as a potential alternative. However, their fleet-level behavior remains largely unexplored. To address this gap, we have developed an agent-based model and an environmental impact study assessing the fleet performance of lightweight autonomous food delivery vehicles. This model explores critical factors such as fleet sizing, service level, operational strategies, and environmental impacts. We have applied this model to a case study in Cambridge, MA, USA, where results indicate that there could be environmental benefits in replacing traditional car-based deliveries with shared lightweight autonomous vehicle fleets. Lastly, we introduce an interactive platform that offers a user-friendly means of comprehending the model's performance and potential trade-offs, which can help inform decision-makers in the evolving landscape of food delivery innovation.\n    ",
        "primary_category": "cs.CY",
        "categories": [],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19234": {
        "title": "Broadcast independence number of oriented circulant graphs",
        "authors": [
            "Abdelamin Laouar",
            "Isma Bouchemakh",
            "Eric Sopena"
        ],
        "comments": "arXiv admin note: text overlap with arXiv:2102.04094",
        "subjects": "Combinatorics (math.CO)",
        "abstract": "In 2001, D. Erwin \\cite{Erw01} introduced in his Ph.D. dissertation the notion of broadcast independence in unoriented graphs. Since then, some results but not many, are published on this notion, including research work on the broadcast independence number of unoriented circulant graphs \\cite{LBS23}. In this paper, we are focused in the same parameter but of the class of oriented circulant graphs. An independent broadcast on an oriented graph $\\overrightarrow{G}$ is a function $f: V\\longrightarrow \\{0,\\ldots,\\diam(\\overrightarrow{G})\\}$ such that $(i)$ $f(v)\\leq e(v)$ for every vertex $v\\in V(\\overrightarrow{G})$, where $\\diam(\\overrightarrow{G})$ denotes the diameter of $\\overrightarrow{G}$ and $e(v)$ the eccentricity of vertex $v$, and $(ii)$ $d_{\\overrightarrow{G}}(u,v) > f(u)$ for every distinct vertices $u$, $v$ with $f(u)$, $f(v)>0$, where $d_{\\overrightarrow{G}}(u,v)$ denotes the length of a shortest oriented path from $u$ to $v$. The broadcast independence number $\\beta_b(\\overrightarrow{G})$ of $\\overrightarrow{G}$ is then the maximum value of $\\sum_{v \\in V} f(v)$, taken over all independent broadcasts on $\\overrightarrow{G}$. The goal of this paper is to study the properties of independent broadcasts of oriented circulant graphs $\\overrightarrow{C}(n;1,a)$, for any integers $n$ and $a$ with $n>|a|\\geq 1$ and $a \\notin \\{1,n-1\\}$. Then, we give some bounds and some exact values for the number $\\beta_b(\\overrightarrow{C}(n;1,a))$.\n    ",
        "primary_category": "math.CO",
        "categories": [
            "cs.DM"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19237": {
        "title": "Context-based Interpretable Spatio-Temporal Graph Convolutional Network for Human Motion Forecasting",
        "authors": [
            "Edgar Medina",
            "Leyong Loh",
            "Namrata Gurung",
            "Kyung Hun Oh",
            "Niels Heller"
        ],
        "comments": "10 pages, 6 figures",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Human motion prediction is still an open problem extremely important for autonomous driving and safety applications. Due to the complex spatiotemporal relation of motion sequences, this remains a challenging problem not only for movement prediction but also to perform a preliminary interpretation of the joint connections. In this work, we present a Context-based Interpretable Spatio-Temporal Graph Convolutional Network (CIST-GCN), as an efficient 3D human pose forecasting model based on GCNs that encompasses specific layers, aiding model interpretability and providing information that might be useful when analyzing motion distribution and body behavior. Our architecture extracts meaningful information from pose sequences, aggregates displacements and accelerations into the input model, and finally predicts the output displacements. Extensive experiments on Human 3.6M, AMASS, 3DPW, and ExPI datasets demonstrate that CIST-GCN outperforms previous methods in human motion prediction and robustness. Since the idea of enhancing interpretability for motion prediction has its merits, we showcase experiments towards it and provide preliminary evaluations of such insights here. available code: this https URL\n",
        "primary_category": "cs.CV",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "21 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19242": {
        "title": "Derivative-enhanced Deep Operator Network",
        "authors": [
            "Yuan Qiu",
            "Nolan Bridges",
            "Peng Chen"
        ],
        "comments": " ",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Deep operator networks (DeepONets), a class of neural operators that learn mappings between function spaces, have recently been developed as surrogate models for parametric partial differential equations (PDEs). In this work we propose a derivative-enhanced deep operator network (DE-DeepONet), which leverages the derivative information to enhance the prediction accuracy, and provide a more accurate approximation of the derivatives, especially when the training data are limited. DE-DeepONet incorporates dimension reduction of input into DeepONet and includes two types of derivative labels in the loss function for training, that is, the directional derivatives of the output function with respect to the input function and the gradient of the output function with respect to the physical domain variables. We test DE-DeepONet on three different equations with increasing complexity to demonstrate its effectiveness compared to the vanilla DeepONet.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.CE",
            "math.NA"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19248": {
        "title": "Let LLMs Take on the Latest Challenges! A Chinese Dynamic Question Answering Benchmark",
        "authors": [
            "Zhikun Xu",
            "Yinghui Li",
            "Ruixue Ding",
            "Xinyu Wang",
            "Boli Chen",
            "Yong Jiang",
            "Hai-Tao Zheng",
            "Wenlian Lu",
            "Pengjun Xie",
            "Fei Huang"
        ],
        "comments": "Work in progress!",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "How to better evaluate the capabilities of Large Language Models (LLMs) is the focal point and hot topic in current LLMs research. Previous work has noted that due to the extremely high cost of iterative updates of LLMs, they are often unable to answer the latest dynamic questions well. To promote the improvement of Chinese LLMs' ability to answer dynamic questions, in this paper, we introduce CDQA, a Chinese Dynamic QA benchmark containing question-answer pairs related to the latest news on the Chinese Internet. We obtain high-quality data through a pipeline that combines humans and models, and carefully classify the samples according to the frequency of answer changes to facilitate a more fine-grained observation of LLMs' capabilities. We have also evaluated and analyzed mainstream and advanced Chinese LLMs on CDQA. Extensive experiments and valuable insights suggest that our proposed CDQA is challenging and worthy of more further study. We believe that the benchmark we provide will become one of the key data resources for improving LLMs' Chinese question-answering ability in the future.\n    ",
        "primary_category": "cs.CL",
        "categories": [],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19249": {
        "title": "Mirage: Cross-Embodiment Zero-Shot Policy Transfer with Cross-Painting",
        "authors": [
            "Lawrence Yunliang Chen",
            "Kush Hari",
            "Karthik Dharmarajan",
            "Chenfeng Xu",
            "Quan Vuong",
            "Ken Goldberg"
        ],
        "comments": "Project page: this https URL",
        "subjects": "Robotics (cs.RO)",
        "abstract": "The ability to reuse collected data and transfer trained policies between robots could alleviate the burden of additional data collection and training. While existing approaches such as pretraining plus finetuning and co-training show promise, they do not generalize to robots unseen in training. Focusing on common robot arms with similar workspaces and 2-jaw grippers, we investigate the feasibility of zero-shot transfer. Through simulation studies on 8 manipulation tasks, we find that state-based Cartesian control policies can successfully zero-shot transfer to a target robot after accounting for forward dynamics. To address robot visual disparities for vision-based policies, we introduce Mirage, which uses \"cross-painting\"--masking out the unseen target robot and inpainting the seen source robot--during execution in real time so that it appears to the policy as if the trained source robot were performing the task. Despite its simplicity, our extensive simulation and physical experiments provide strong evidence that Mirage can successfully zero-shot transfer between different robot arms and grippers with only minimal performance degradation on a variety of manipulation tasks such as picking, stacking, and assembly, significantly outperforming a generalist policy. Project website: this https URL\n",
        "primary_category": "cs.RO",
        "categories": [],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19250": {
        "title": "Feature boosting with efficient attention for scene parsing",
        "authors": [
            "Vivek Singh",
            "Shailza Sharma",
            "Fabio Cuzzolin"
        ],
        "comments": " ",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "The complexity of scene parsing grows with the number of object and scene classes, which is higher in unrestricted open scenes. The biggest challenge is to model the spatial relation between scene elements while succeeding in identifying objects at smaller scales. This paper presents a novel feature-boosting network that gathers spatial context from multiple levels of feature extraction and computes the attention weights for each level of representation to generate the final class labels. A novel `channel attention module' is designed to compute the attention weights, ensuring that features from the relevant extraction stages are boosted while the others are attenuated. The model also learns spatial context information at low resolution to preserve the abstract spatial relationships among scene elements and reduce computation cost. Spatial attention is subsequently concatenated into a final feature set before applying feature boosting. Low-resolution spatial attention features are trained using an auxiliary task that helps learning a coarse global scene structure. The proposed model outperforms all state-of-the-art models on both the ADE20K and the Cityscapes datasets.\n    ",
        "primary_category": "cs.CV",
        "categories": [],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19251": {
        "title": "A Cognitive-Based Trajectory Prediction Approach for Autonomous Driving",
        "authors": [
            "Haicheng Liao",
            "Yongkang Li",
            "Zhenning Li",
            "Chengyue Wang",
            "Zhiyong Cui",
            "Shengbo Eben Li",
            "Chengzhong Xu"
        ],
        "comments": " ",
        "subjects": "Artificial Intelligence (cs.AI)",
        "abstract": "In autonomous vehicle (AV) technology, the ability to accurately predict the movements of surrounding vehicles is paramount for ensuring safety and operational efficiency. Incorporating human decision-making insights enables AVs to more effectively anticipate the potential actions of other vehicles, significantly improving prediction accuracy and responsiveness in dynamic environments. This paper introduces the Human-Like Trajectory Prediction (HLTP) model, which adopts a teacher-student knowledge distillation framework inspired by human cognitive processes. The HLTP model incorporates a sophisticated teacher-student knowledge distillation framework. The \"teacher\" model, equipped with an adaptive visual sector, mimics the visual processing of the human brain, particularly the functions of the occipital and temporal lobes. The \"student\" model focuses on real-time interaction and decision-making, drawing parallels to prefrontal and parietal cortex functions. This approach allows for dynamic adaptation to changing driving scenarios, capturing essential perceptual cues for accurate prediction. Evaluated using the Macao Connected and Autonomous Driving (MoCAD) dataset, along with the NGSIM and HighD benchmarks, HLTP demonstrates superior performance compared to existing models, particularly in challenging environments with incomplete data. The project page is available at Github.\n    ",
        "primary_category": "cs.AI",
        "categories": [
            "cs.RO"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19254": {
        "title": "Machine learning for modular multiplication",
        "authors": [
            "Kristin Lauter",
            "Cathy Yuanchen Li",
            "Krystal Maughan",
            "Rachel Newton",
            "Megha Srivastava"
        ],
        "comments": "14 pages, 12 figures. Comments welcome!",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Motivated by cryptographic applications, we investigate two machine learning approaches to modular multiplication: namely circular regression and a sequence-to-sequence transformer model. The limited success of both methods demonstrated in our results gives evidence for the hardness of tasks involving modular multiplication upon which cryptosystems are based.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.CR"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19255": {
        "title": "GSM-Plus: A Comprehensive Benchmark for Evaluating the Robustness of LLMs as Mathematical Problem Solvers",
        "authors": [
            "Qintong Li",
            "Leyang Cui",
            "Xueliang Zhao",
            "Lingpeng Kong",
            "Wei Bi"
        ],
        "comments": " ",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "Large language models (LLMs) have achieved impressive performance across various mathematical reasoning benchmarks. However, there are increasing debates regarding whether these models truly understand and apply mathematical knowledge or merely rely on shortcuts for mathematical reasoning. One essential and frequently occurring evidence is that when the math questions are slightly changed, LLMs can behave incorrectly. This motivates us to evaluate the robustness of LLMs' math reasoning capability by testing a wide range of question variations. We introduce the adversarial grade school math (\\datasetname) dataset, an extension of GSM8K augmented with various mathematical perturbations. Our experiments on 25 LLMs and 4 prompting techniques show that while LLMs exhibit different levels of math reasoning abilities, their performances are far from robust. In particular, even for problems that have been solved in GSM8K, LLMs can make mistakes when new statements are added or the question targets are altered. We also explore whether more robust performance can be achieved by composing existing prompting methods, in which we try an iterative method that generates and verifies each intermediate thought based on its reasoning goal and calculation result. Code and data are available at \\url{this https URL}.\n    ",
        "primary_category": "cs.CL",
        "categories": [],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19257": {
        "title": "More algorithmic results for problems of spread of influence in edge-weighted graphs with and without incentives",
        "authors": [
            "Siavash Askari",
            "Manouchehr Zaker"
        ],
        "comments": " ",
        "subjects": "Discrete Mathematics (cs.DM)",
        "abstract": "Many phenomena in real world social networks are interpreted as spread of influence between activated and non-activated network elements. These phenomena are formulated by combinatorial graphs, where vertices represent the elements and edges represent social ties between elements. A main problem is to study important subsets of elements (target sets or dynamic monopolies) such that their activation spreads to the entire network. In edge-weighted networks the influence between two adjacent vertices depends on the weight of their edge. In models with incentives, the main problem is to minimize total amount of incentives (called optimal target vectors) which can be offered to vertices such that some vertices are activated and their activation spreads to the whole network. Algorithmic study of target sets and vectors is a hot research field. We prove an inapproximability result for optimal target sets in edge weighted networks even for complete graphs. Some other hardness and polynomial time results are presented for optimal target vectors and degenerate threshold assignments in edge-weighted networks.\n    ",
        "primary_category": "cs.DM",
        "categories": [
            "math.CO"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19258": {
        "title": "MaskFi: Unsupervised Learning of WiFi and Vision Representations for Multimodal Human Activity Recognition",
        "authors": [
            "Jianfei Yang",
            "Shijie Tang",
            "Yuecong Xu",
            "Yunjiao Zhou",
            "Lihua Xie"
        ],
        "comments": "9 pages",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Human activity recognition (HAR) has been playing an increasingly important role in various domains such as healthcare, security monitoring, and metaverse gaming. Though numerous HAR methods based on computer vision have been developed to show prominent performance, they still suffer from poor robustness in adverse visual conditions in particular low illumination, which motivates WiFi-based HAR to serve as a good complementary modality. Existing solutions using WiFi and vision modalities rely on massive labeled data that are very cumbersome to collect. In this paper, we propose a novel unsupervised multimodal HAR solution, MaskFi, that leverages only unlabeled video and WiFi activity data for model training. We propose a new algorithm, masked WiFi-vision modeling (MI2M), that enables the model to learn cross-modal and single-modal features by predicting the masked sections in representation learning. Benefiting from our unsupervised learning procedure, the network requires only a small amount of annotated data for finetuning and can adapt to the new environment with better performance. We conduct extensive experiments on two WiFi-vision datasets collected in-house, and our method achieves human activity recognition and human identification in terms of both robustness and accuracy.\n    ",
        "primary_category": "cs.CV",
        "categories": [],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19259": {
        "title": "Total Completion Time Scheduling Under Scenarios",
        "authors": [
            "Thomas Bosman",
            "Martijn van Ee",
            "Ekin Ergen",
            "Csanad Imreh",
            "Alberto Marchetti-Spaccamela",
            "Martin Skutella",
            "Leen Stougie"
        ],
        "comments": " ",
        "subjects": "Data Structures and Algorithms (cs.DS)",
        "abstract": "Scheduling jobs with given processing times on identical parallel machines so as to minimize their total completion time is one of the most basic scheduling problems. We study interesting generalizations of this classical problem involving scenarios. In our model, a scenario is defined as a subset of a predefined and fully specified set of jobs. The aim is to find an assignment of the whole set of jobs to identical parallel machines such that the schedule, obtained for the given scenarios by simply skipping the jobs not in the scenario, optimizes a function of the total completion times over all scenarios.\nWhile the underlying scheduling problem without scenarios can be solved efficiently by a simple greedy procedure (SPT rule), scenarios, in general, make the problem NP-hard. We paint an almost complete picture of the evolving complexity landscape, drawing the line between easy and hard. One of our main algorithmic contributions relies on a deep structural result on the maximum imbalance of an optimal schedule, based on a subtle connection to Hilbert bases of a related convex cone.\n    ",
        "primary_category": "cs.DS",
        "categories": [],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19262": {
        "title": "Masks, Signs, And Learning Rate Rewinding",
        "authors": [
            "Advait Gadhikar",
            "Rebekka Burkholz"
        ],
        "comments": "Accepted for publishing at ICLR 2024",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Learning Rate Rewinding (LRR) has been established as a strong variant of Iterative Magnitude Pruning (IMP) to find lottery tickets in deep overparameterized neural networks. While both iterative pruning schemes couple structure and parameter learning, understanding how LRR excels in both aspects can bring us closer to the design of more flexible deep learning algorithms that can optimize diverse sets of sparse architectures. To this end, we conduct experiments that disentangle the effect of mask learning and parameter optimization and how both benefit from overparameterization. The ability of LRR to flip parameter signs early and stay robust to sign perturbations seems to make it not only more effective in mask identification but also in optimizing diverse sets of masks, including random ones. In support of this hypothesis, we prove in a simplified single hidden neuron setting that LRR succeeds in more cases than IMP, as it can escape initially problematic sign configurations.\n    ",
        "primary_category": "cs.LG",
        "categories": [],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19263": {
        "title": "Spinal Osteophyte Detection via Robust Patch Extraction on minimally annotated X-rays",
        "authors": [
            "Soumya Snigdha Kundu",
            "Yuanhan Mo",
            "Nicharee Srikijkasemwat",
            "Bart\u0142omiej W. Papiez"
        ],
        "comments": "ISBI'24 Full Paper",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "The development and progression of arthritis is strongly associated with osteophytes, which are small and elusive bone growths. This paper presents one of the first efforts towards automated spinal osteophyte detection in spinal X-rays. A novel automated patch extraction process, called SegPatch, has been proposed based on deep learning-driven vertebrae segmentation and the enlargement of mask contours. A final patch classification accuracy of 84.5\\% is secured, surpassing a baseline tiling-based patch generation technique by 9.5%. This demonstrates that even with limited annotations, SegPatch can deliver superior performance for detection of tiny structures such as osteophytes. The proposed approach has potential to assist clinicians in expediting the process of manually identifying osteophytes in spinal X-ray.\n    ",
        "primary_category": "cs.CV",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19264": {
        "title": "T3DNet: Compressing Point Cloud Models for Lightweight 3D Recognition",
        "authors": [
            "Zhiyuan Yang",
            "Yunjiao Zhou",
            "Lihua Xie",
            "Jianfei Yang"
        ],
        "comments": "12 pages",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "3D point cloud has been widely used in many mobile application scenarios, including autonomous driving and 3D sensing on mobile devices. However, existing 3D point cloud models tend to be large and cumbersome, making them hard to deploy on edged devices due to their high memory requirements and non-real-time latency. There has been a lack of research on how to compress 3D point cloud models into lightweight models. In this paper, we propose a method called T3DNet (Tiny 3D Network with augmEntation and disTillation) to address this issue. We find that the tiny model after network augmentation is much easier for a teacher to distill. Instead of gradually reducing the parameters through techniques such as pruning or quantization, we pre-define a tiny model and improve its performance through auxiliary supervision from augmented networks and the original model. We evaluate our method on several public datasets, including ModelNet40, ShapeNet, and ScanObjectNN. Our method can achieve high compression rates without significant accuracy sacrifice, achieving state-of-the-art performances on three datasets against existing methods. Amazingly, our T3DNet is 58 times smaller and 54 times faster than the original model yet with only 1.4% accuracy descent on the ModelNet40 dataset.\n    ",
        "primary_category": "cs.CV",
        "categories": [],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19265": {
        "title": "Learning Logic Specifications for Policy Guidance in POMDPs: an Inductive Logic Programming Approach",
        "authors": [
            "Daniele Meli",
            "Alberto Castellini",
            "Alessandro Farinelli"
        ],
        "comments": " ",
        "subjects": "Artificial Intelligence (cs.AI)",
        "abstract": "Partially Observable Markov Decision Processes (POMDPs) are a powerful framework for planning under uncertainty. They allow to model state uncertainty as a belief probability distribution. Approximate solvers based on Monte Carlo sampling show great success to relax the computational demand and perform online planning. However, scaling to complex realistic domains with many actions and long planning horizons is still a major challenge, and a key point to achieve good performance is guiding the action-selection process with domain-dependent policy heuristics which are tailored for the specific application domain. We propose to learn high-quality heuristics from POMDP traces of executions generated by any solver. We convert the belief-action pairs to a logical semantics, and exploit data- and time-efficient Inductive Logic Programming (ILP) to generate interpretable belief-based policy specifications, which are then used as online heuristics. We evaluate thoroughly our methodology on two notoriously challenging POMDP problems, involving large action spaces and long planning horizons, namely, rocksample and pocman. Considering different state-of-the-art online POMDP solvers, including POMCP, DESPOT and AdaOPS, we show that learned heuristics expressed in Answer Set Programming (ASP) yield performance superior to neural networks and similar to optimal handcrafted task-specific heuristics within lower computational time. Moreover, they well generalize to more challenging scenarios not experienced in the training phase (e.g., increasing rocks and grid size in rocksample, incrementing the size of the map and the aggressivity of ghosts in pocman).\n    ",
        "primary_category": "cs.AI",
        "categories": [
            "cs.LG",
            "cs.LO"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19266": {
        "title": "Cauchy-completions and the rule of unique choice in relational doctrines",
        "authors": [
            "Francesco Dagnino",
            "Fabio Pasquali"
        ],
        "comments": " ",
        "subjects": "Category Theory (math.CT)",
        "abstract": "Lawvere's generalised the notion of complete metric space to the field of enriched categories: an enriched category is said to be Cauchy-complete if every left adjoint bimodule into it is represented by an enriched functor. Looking at this definition from a logical standpoint, regarding bimodules as an abstraction of relations and functors as an abstraction of functions, Cauchy-completeness resembles a formulation of the rule of unique choice. In this paper, we make this analogy precise, using the language of relational doctrines, a categorical tool that provides a functorial description of the calculus of relations, in the same way Lawvere's hyperdoctrines give a functorial description of predicate logic. Given a relational doctrine, we define Cauchy-complete objects as those objects of the domain category satisfying the rule of unique choice. Then, we present a universal construction that completes a relational doctrine with the rule of unique choice, that is, producing a new relational doctrine where all objects are Cauchy-complete. We also introduce relational doctrines with singleton objects and show that these have the minimal structure needed to build the reflector of the full subcategory of its domain on Cauchy-complete objects. The main result is that this reflector exists if and only if the relational doctrine has singleton objects and this happens if and only if its restriction to Cauchy-complete objects is equivalent to its completion with the rule of unique choice. We support our results with many examples, also falling outside the scope of standard doctrines, such as complete metric spaces, Banach spaces and compact Hausdorff spaces in the general context of monoidal topology, which are all shown to be Cauchy-complete objects for appropriate relational doctrines.\n    ",
        "primary_category": "math.CT",
        "categories": [
            "cs.LO",
            "math.LO"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19267": {
        "title": "Robust Guidance for Unsupervised Data Selection: Capturing Perplexing Named Entities for Domain-Specific Machine Translation",
        "authors": [
            "Seunghyun Ji",
            "Hagai Raja Sinulingga",
            "Darongsae Kwon"
        ],
        "comments": "Submitted to SIGUL 2024, a satellite workshop of LREC-COLING 2024",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "Employing extensive datasets enables the training of multilingual machine translation models; however, these models often fail to accurately translate sentences within specialized domains. Although obtaining and translating domain-specific data incurs high costs, it is inevitable for high-quality translations. Hence, finding the most 'effective' data with an unsupervised setting becomes a practical strategy for reducing labeling costs. Recent research indicates that this effective data could be found by selecting 'properly difficult data' based on its volume. This means the data should not be excessively challenging or overly simplistic, especially if the amount of data is limited. However, we found that establishing a criterion for unsupervised data selection remains challenging, as the 'proper difficulty' might vary based on the data domain being trained on. We introduce a novel unsupervised data selection method, 'Capturing Perplexing Named Entities', which adopts the maximum inference entropy in translated named entities as a selection measure. The motivation was that named entities in domain-specific data are considered the most complex portion of the data and should be predicted with high confidence. When verified with the 'Korean-English Parallel Corpus of Specialized Domains,' our method served as a robust guidance for unsupervised data selection, in contrast to existing methods.\n    ",
        "primary_category": "cs.CL",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19273": {
        "title": "PlanGPT: Enhancing Urban Planning with Tailored Language Model and Efficient Retrieval",
        "authors": [
            "He Zhu",
            "Wenjia Zhang",
            "Nuoxian Huang",
            "Boyang Li",
            "Luyao Niu",
            "Zipei Fan",
            "Tianle Lun",
            "Yicheng Tao",
            "Junyou Su",
            "Zhaoya Gong",
            "Chenyu Fang",
            "Xing Liu"
        ],
        "comments": " ",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "In the field of urban planning, general-purpose large language models often struggle to meet the specific needs of planners. Tasks like generating urban planning texts, retrieving related information, and evaluating planning documents pose unique challenges. To enhance the efficiency of urban professionals and overcome these obstacles, we introduce PlanGPT, the first specialized Large Language Model tailored for urban and spatial planning. Developed through collaborative efforts with institutions like the Chinese Academy of Urban Planning, PlanGPT leverages a customized local database retrieval framework, domain-specific fine-tuning of base models, and advanced tooling capabilities. Empirical tests demonstrate that PlanGPT has achieved advanced performance, delivering responses of superior quality precisely tailored to the intricacies of urban planning.\n    ",
        "primary_category": "cs.CL",
        "categories": [],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19275": {
        "title": "Adaptive Testing Environment Generation for Connected and Automated Vehicles with Dense Reinforcement Learning",
        "authors": [
            "Jingxuan Yang",
            "Ruoxuan Bai",
            "Haoyuan Ji",
            "Yi Zhang",
            "Jianming Hu",
            "Shuo Feng"
        ],
        "comments": " ",
        "subjects": "Systems and Control (eess.SY)",
        "abstract": "The assessment of safety performance plays a pivotal role in the development and deployment of connected and automated vehicles (CAVs). A common approach involves designing testing scenarios based on prior knowledge of CAVs (e.g., surrogate models), conducting tests in these scenarios, and subsequently evaluating CAVs' safety performances. However, substantial differences between CAVs and the prior knowledge can significantly diminish the evaluation efficiency. In response to this issue, existing studies predominantly concentrate on the adaptive design of testing scenarios during the CAV testing process. Yet, these methods have limitations in their applicability to high-dimensional scenarios. To overcome this challenge, we develop an adaptive testing environment that bolsters evaluation robustness by incorporating multiple surrogate models and optimizing the combination coefficients of these surrogate models to enhance evaluation efficiency. We formulate the optimization problem as a regression task utilizing quadratic programming. To efficiently obtain the regression target via reinforcement learning, we propose the dense reinforcement learning method and devise a new adaptive policy with high sample efficiency. Essentially, our approach centers on learning the values of critical scenes displaying substantial surrogate-to-real gaps. The effectiveness of our method is validated in high-dimensional overtaking scenarios, demonstrating that our approach achieves notable evaluation efficiency.\n    ",
        "primary_category": "eess.SY",
        "categories": [
            "cs.LG"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19279": {
        "title": "SIFT-Aided Rectified 2D-DIC for Displacement and Strain Measurements in Asphalt Concrete Testing",
        "authors": [
            "Zehui Zhu",
            "Imad L. Al-Qadi"
        ],
        "comments": "Journal of Transportation Engineering, Part B: Pavements",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Two-dimensional digital image correlation (2D-DIC) is a widely used optical technique to measure displacement and strain during asphalt concrete (AC) testing. An accurate 2-D DIC measurement can only be achieved when the camera's principal axis is perpendicular to the planar specimen surface. However, this requirement may not be met during testing due to device constraints. This paper proposes a simple and reliable method to correct errors induced by non-perpendicularity. The method is based on image feature matching and rectification. No additional equipment is needed. A theoretical error analysis was conducted to quantify the effect of a non-perpendicular camera alignment on measurement accuracy. The proposed method was validated numerically using synthetic images and experimentally in an AC fracture test. It achieved relatively high accuracy, even under considerable camera rotation angle and large deformation. As a pre-processing technique, the proposed method showed promising performance in assisting the recently developed CrackPropNet for automated crack propagation measurement under a non-perpendicular camera alignment.\n    ",
        "primary_category": "cs.CV",
        "categories": [],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19287": {
        "title": "StiefelGen: A Simple, Model Agnostic Approach for Time Series Data Augmentation over Riemannian Manifolds",
        "authors": [
            "Prasad Cheema",
            "Mahito Sugiyama"
        ],
        "comments": "61 pages, 41 figures",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Data augmentation is an area of research which has seen active development in many machine learning fields, such as in image-based learning models, reinforcement learning for self driving vehicles, and general noise injection for point cloud data. However, convincing methods for general time series data augmentation still leaves much to be desired, especially since the methods developed for these models do not readily cross-over. Three common approaches for time series data augmentation include: (i) Constructing a physics-based model and then imbuing uncertainty over the coefficient space (for example), (ii) Adding noise to the observed data set(s), and, (iii) Having access to ample amounts of time series data sets from which a robust generative neural network model can be trained. However, for many practical problems that work with time series data in the industry: (i) One usually does not have access to a robust physical model, (ii) The addition of noise can in of itself require large or difficult assumptions (for example, what probability distribution should be used? Or, how large should the noise variance be?), and, (iii) In practice, it can be difficult to source a large representative time series data base with which to train the neural network model for the underlying problem. In this paper, we propose a methodology which attempts to simultaneously tackle all three of these previous limitations to a large extent. The method relies upon the well-studied matrix differential geometry of the Stiefel manifold, as it proposes a simple way in which time series signals can placed on, and then smoothly perturbed over the manifold. We attempt to clarify how this method works by showcasing several potential use cases which in particular work to take advantage of the unique properties of this underlying manifold.\n    ",
        "primary_category": "cs.LG",
        "categories": [],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19294": {
        "title": "Degradation Modeling and Prognostic Analysis Under Unknown Failure Modes",
        "authors": [
            "Ying Fu",
            "Ye Kwon Huh",
            "Kaibo Liu"
        ],
        "comments": " ",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Operating units often experience various failure modes in complex systems, leading to distinct degradation paths. Relying on a prognostic model trained on a single failure mode may lead to poor generalization performance across multiple failure modes. Therefore, accurately identifying the failure mode is of critical importance. Current prognostic approaches either ignore failure modes during degradation or assume known failure mode labels, which can be challenging to acquire in practice. Moreover, the high dimensionality and complex relations of sensor signals make it challenging to identify the failure modes accurately. To address these issues, we propose a novel failure mode diagnosis method that leverages a dimension reduction technique called UMAP (Uniform Manifold Approximation and Projection) to project and visualize each unit's degradation trajectory into a lower dimension. Then, using these degradation trajectories, we develop a time series-based clustering method to identify the training units' failure modes. Finally, we introduce a monotonically constrained prognostic model to predict the failure mode labels and RUL of the test units simultaneously using the obtained failure modes of the training units. The proposed prognostic model provides failure mode-specific RUL predictions while preserving the monotonic property of the RUL predictions across consecutive time steps. We evaluate the proposed model using a case study with the aircraft gas turbine engine dataset.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19295": {
        "title": "Anomaly Detection in Offshore Wind Turbine Structures using Hierarchical Bayesian Modelling",
        "authors": [
            "S. M. Smith",
            "A. J. Hughes",
            "T. A. Dardeno",
            "L. A. Bull",
            "N. Dervilis",
            "K. Worden"
        ],
        "comments": "Submitted to International Workshop on Structural Health Monitoring 2023, Stanford University, California, USA",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Population-based structural health monitoring (PBSHM), aims to share information between members of a population. An offshore wind (OW) farm could be considered as a population of nominally-identical wind-turbine structures. However, benign variations exist among members, such as geometry, sea-bed conditions and temperature differences. These factors could influence structural properties and therefore the dynamic response, making it more difficult to detect structural problems via traditional SHM techniques. This paper explores the use of a hierarchical Bayesian model to infer expected soil stiffness distributions at both population and local levels, as a basis to perform anomaly detection, in the form of scour, for new and existing turbines. To do this, observations of natural frequency will be generated as though they are from a small population of wind turbines. Differences between individual observations will be introduced by postulating distributions over the soil stiffness and measurement noise, as well as reducing soil depth (to represent scour), in the case of anomaly detection.\n    ",
        "primary_category": "cs.LG",
        "categories": [],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19296": {
        "title": "An AI based Digital Score of Tumour-Immune Microenvironment Predicts Benefit to Maintenance Immunotherapy in Advanced Oesophagogastric Adenocarcinoma",
        "authors": [
            "Quoc Dang Vu",
            "Caroline Fong",
            "Anderley Gordon",
            "Tom Lund",
            "Tatiany L Silveira",
            "Daniel Rodrigues",
            "Katharina von Loga",
            "Shan E Ahmed Raza",
            "David Cunningham",
            "Nasir Rajpoot"
        ],
        "comments": " ",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Gastric and oesophageal (OG) cancers are the leading causes of cancer mortality worldwide. In OG cancers, recent studies have showed that PDL1 immune checkpoint inhibitors (ICI) in combination with chemotherapy improves patient survival. However, our understanding of the tumour immune microenvironment in OG cancers remains limited. In this study, we interrogate multiplex immunofluorescence (mIF) images taken from patients with advanced Oesophagogastric Adenocarcinoma (OGA) who received first-line fluoropyrimidine and platinum-based chemotherapy in the PLATFORM trial (NCT02678182) to predict the efficacy of the treatment and to explore the biological basis of patients responding to maintenance durvalumab (PDL1 inhibitor). Our proposed Artificial Intelligence (AI) based marker successfully identified responder from non-responder (p < 0.05) as well as those who could potentially benefit from ICI with statistical significance (p < 0.05) for both progression free and overall survival. Our findings suggest that T cells that express FOXP3 seem to heavily influence the patient treatment response and survival outcome. We also observed that higher levels of CD8+PD1+ cells are consistently linked to poor prognosis for both OS and PFS, regardless of ICI.\n    ",
        "primary_category": "cs.CV",
        "categories": [
            "cs.LG"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19299": {
        "title": "RL-GPT: Integrating Reinforcement Learning and Code-as-policy",
        "authors": [
            "Shaoteng Liu",
            "Haoqi Yuan",
            "Minda Hu",
            "Yanwei Li",
            "Yukang Chen",
            "Shu Liu",
            "Zongqing Lu",
            "Jiaya Jia"
        ],
        "comments": " ",
        "subjects": "Artificial Intelligence (cs.AI)",
        "abstract": "Large Language Models (LLMs) have demonstrated proficiency in utilizing various tools by coding, yet they face limitations in handling intricate logic and precise control. In embodied tasks, high-level planning is amenable to direct coding, while low-level actions often necessitate task-specific refinement, such as Reinforcement Learning (RL). To seamlessly integrate both modalities, we introduce a two-level hierarchical framework, RL-GPT, comprising a slow agent and a fast agent. The slow agent analyzes actions suitable for coding, while the fast agent executes coding tasks. This decomposition effectively focuses each agent on specific tasks, proving highly efficient within our pipeline. Our approach outperforms traditional RL methods and existing GPT agents, demonstrating superior efficiency. In the Minecraft game, it rapidly obtains diamonds within a single day on an RTX3090. Additionally, it achieves SOTA performance across all designated MineDojo tasks.\n    ",
        "primary_category": "cs.AI",
        "categories": [
            "cs.LG"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19302": {
        "title": "DiffAssemble: A Unified Graph-Diffusion Model for 2D and 3D Reassembly",
        "authors": [
            "Gianluca Scarpellini",
            "Stefano Fiorini",
            "Francesco Giuliari",
            "Pietro Morerio",
            "Alessio Del Bue"
        ],
        "comments": "Accepted at CVPR2024",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Reassembly tasks play a fundamental role in many fields and multiple approaches exist to solve specific reassembly problems. In this context, we posit that a general unified model can effectively address them all, irrespective of the input data type (images, 3D, etc.). We introduce DiffAssemble, a Graph Neural Network (GNN)-based architecture that learns to solve reassembly tasks using a diffusion model formulation. Our method treats the elements of a set, whether pieces of 2D patch or 3D object fragments, as nodes of a spatial graph. Training is performed by introducing noise into the position and rotation of the elements and iteratively denoising them to reconstruct the coherent initial pose. DiffAssemble achieves state-of-the-art (SOTA) results in most 2D and 3D reassembly tasks and is the first learning-based approach that solves 2D puzzles for both rotation and translation. Furthermore, we highlight its remarkable reduction in run-time, performing 11 times faster than the quickest optimization-based method for puzzle solving. Code available at this https URL\n",
        "primary_category": "cs.CV",
        "categories": [],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19303": {
        "title": "Learnability Gaps of Strategic Classification",
        "authors": [
            "Lee Cohen",
            "Yishay Mansour",
            "Shay Moran",
            "Han Shao"
        ],
        "comments": " ",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "In contrast with standard classification tasks, strategic classification involves agents strategically modifying their features in an effort to receive favorable predictions. For instance, given a classifier determining loan approval based on credit scores, applicants may open or close their credit cards to fool the classifier. The learning goal is to find a classifier robust against strategic manipulations. Various settings, based on what and when information is known, have been explored in strategic classification. In this work, we focus on addressing a fundamental question: the learnability gaps between strategic classification and standard learning.\nWe essentially show that any learnable class is also strategically learnable: we first consider a fully informative setting, where the manipulation structure (which is modeled by a manipulation graph $G^\\star$) is known and during training time the learner has access to both the pre-manipulation data and post-manipulation data. We provide nearly tight sample complexity and regret bounds, offering significant improvements over prior results. Then, we relax the fully informative setting by introducing two natural types of uncertainty. First, following Ahmadi et al. (2023), we consider the setting in which the learner only has access to the post-manipulation data. We improve the results of Ahmadi et al. (2023) and close the gap between mistake upper bound and lower bound raised by them. Our second relaxation of the fully informative setting introduces uncertainty to the manipulation structure. That is, we assume that the manipulation graph is unknown but belongs to a known class of graphs. We provide nearly tight bounds on the learning complexity in various unknown manipulation graph settings. Notably, our algorithm in this setting is of independent interest and can be applied to other problems such as multi-label learning.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.GT"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19305": {
        "title": "HyenaPixel: Global Image Context with Convolutions",
        "authors": [
            "Julian Spravil",
            "Sebastian Houben",
            "Sven Behnke"
        ],
        "comments": " ",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "In vision tasks, a larger effective receptive field (ERF) is associated with better performance. While attention natively supports global context, convolution requires multiple stacked layers and a hierarchical structure for large context. In this work, we extend Hyena, a convolution-based attention replacement, from causal sequences to the non-causal two-dimensional image space. We scale the Hyena convolution kernels beyond the feature map size up to 191$\\times$191 to maximize the ERF while maintaining sub-quadratic complexity in the number of pixels. We integrate our two-dimensional Hyena, HyenaPixel, and bidirectional Hyena into the MetaFormer framework. For image categorization, HyenaPixel and bidirectional Hyena achieve a competitive ImageNet-1k top-1 accuracy of 83.0% and 83.5%, respectively, while outperforming other large-kernel networks. Combining HyenaPixel with attention further increases accuracy to 83.6%. We attribute the success of attention to the lack of spatial bias in later stages and support this finding with bidirectional Hyena.\n    ",
        "primary_category": "cs.CV",
        "categories": [],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19308": {
        "title": "Loss-Free Machine Unlearning",
        "authors": [
            "Jack Foster",
            "Stefan Schoepf",
            "Alexandra Brintrup"
        ],
        "comments": "Accepted as a Tiny Paper at ICLR 2024",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "We present a machine unlearning approach that is both retraining- and label-free. Most existing machine unlearning approaches require a model to be fine-tuned to remove information while preserving performance. This is computationally expensive and necessitates the storage of the whole dataset for the lifetime of the model. Retraining-free approaches often utilise Fisher information, which is derived from the loss and requires labelled data which may not be available. Thus, we present an extension to the Selective Synaptic Dampening algorithm, substituting the diagonal of the Fisher information matrix for the gradient of the l2 norm of the model output to approximate sensitivity. We evaluate our method in a range of experiments using ResNet18 and Vision Transformer. Results show our label-free method is competitive with existing state-of-the-art approaches.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.CV"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19309": {
        "title": "Closed-loop training of static output feedback neural network controllers for large systems: A distillation case study",
        "authors": [
            "E. M. Turan",
            "J. J\u00e4schke"
        ],
        "comments": " ",
        "subjects": "Systems and Control (eess.SY)",
        "abstract": "The online implementation of model predictive control for constrained multivariate systems has two main disadvantages: it requires an estimate of the entire model state and an optimisation problem must be solved online. These issues have typically been treated separately. This work proposes an integrated approach for the offline training of an output feedback neural network controller in closed loop. Online this neural network controller computers the plant inputs cheaply using noisy measurements. In addition, the controller can be trained to only make use of certain predefined measurements. Further, a heuristic approach is proposed to perform the automatic selection of important measurements. The proposed method is demonstrated by extensive simulations using a non-linear distillation column model of 50 states.\n    ",
        "primary_category": "eess.SY",
        "categories": [
            "math.OC"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19318": {
        "title": "DISCERN: Designing Decision Support Interfaces to Investigate the Complexities of Workplace Social Decision-Making With Line Managers",
        "authors": [
            "Pranav Khadpe",
            "Lindy Le",
            "Kate Nowak",
            "Shamsi T. Iqbal",
            "Jina Suh"
        ],
        "comments": "CHI 2024",
        "subjects": "Human-Computer Interaction (cs.HC)",
        "abstract": "Line managers form the first level of management in organizations, and must make complex decisions, while maintaining relationships with those impacted by their decisions. Amidst growing interest in technology-supported decision-making at work, their needs remain understudied. Further, most existing design knowledge for supporting social decision-making comes from domains where decision-makers are more socially detached from those they decide for. We conducted iterative design research with line managers within a technology organization, investigating decision-making practices, and opportunities for technological support. Through formative research, development of a decision-representation tool -- DISCERN -- and user enactments, we identify their communication and analysis needs that lack adequate support. We found they preferred tools for externalizing reasoning rather than tools that replace interpersonal interactions, and they wanted tools to support a range of intuitive and calculative decision-making. We discuss how design of social decision-making supports, especially in the workplace, can more explicitly support highly interactional social decision-making.\n    ",
        "primary_category": "cs.HC",
        "categories": [],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19319": {
        "title": "Attacks Against Mobility Prediction in 5G Networks",
        "authors": [
            "Syafiq Al Atiiq",
            "Yachao Yuan",
            "Christian Gehrmann",
            "Jakob Sternby",
            "Luis Barriga"
        ],
        "comments": "This is the preprint version of a paper which appears in 22th IEEE International Conference on Trust, Security and Privacy in Computing and Communications (TrustCom 2023)",
        "subjects": "Cryptography and Security (cs.CR)",
        "abstract": "The $5^{th}$ generation of mobile networks introduces a new Network Function (NF) that was not present in previous generations, namely the Network Data Analytics Function (NWDAF). Its primary objective is to provide advanced analytics services to various entities within the network and also towards external application services in the 5G ecosystem. One of the key use cases of NWDAF is mobility trajectory prediction, which aims to accurately support efficient mobility management of User Equipment (UE) in the network by allocating ``just in time'' necessary network resources. In this paper, we show that there are potential mobility attacks that can compromise the accuracy of these predictions. In a semi-realistic scenario with 10,000 subscribers, we demonstrate that an adversary equipped with the ability to hijack cellular mobile devices and clone them can significantly reduce the prediction accuracy from 75\\% to 40\\% using just 100 adversarial UEs. While a defense mechanism largely depends on the attack and the mobility types in a particular area, we prove that a basic KMeans clustering is effective in distinguishing legitimate and adversarial UEs.\n    ",
        "primary_category": "cs.CR",
        "categories": [
            "cs.LG",
            "cs.NI"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19325": {
        "title": "Do End-to-End Neural Diarization Attractors Need to Encode Speaker Characteristic Information?",
        "authors": [
            "Lin Zhang",
            "Themos Stafylakis",
            "Federico Landini",
            "Mireia Diez",
            "Anna Silnova",
            "Luk\u00e1\u0161 Burget"
        ],
        "comments": "Submitted to Odyssey 2024",
        "subjects": "Sound (cs.SD)",
        "abstract": "In this paper, we apply the variational information bottleneck approach to end-to-end neural diarization with encoder-decoder attractors (EEND-EDA). This allows us to investigate what information is essential for the model. EEND-EDA utilizes vector representations of the speakers in a conversation - attractors. Our analysis shows that, attractors do not necessarily have to contain speaker characteristic information. On the other hand, giving the attractors more freedom allowing them to encode some extra (possibly speaker-specific) information leads to small but consistent diarization performance improvements. Despite architectural differences in EEND systems, the notion of attractors and frame embeddings is common to most of them and not specific to EEND-EDA. We believe that the main conclusions of this work can apply to other variants of EEND. Thus, we hope this paper will be a valuable contribution to guide the community to make more informed decisions when designing new systems.\n    ",
        "primary_category": "cs.SD",
        "categories": [
            "eess.AS"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19328": {
        "title": "Seeking Soulmate via Voice: Understanding Promises and Challenges of Online Synchronized Voice-Based Mobile Dating",
        "authors": [
            "Chenxinran Shen",
            "Yan Xu",
            "Ray LC",
            "Zhicong Lu"
        ],
        "comments": "14 pages, 2 figures. Accepted to ACM CHI 2024. In Proceedings of the CHI Conference on Human Factors in Computing Systems (CHI '24)",
        "subjects": "Human-Computer Interaction (cs.HC)",
        "abstract": "Online dating has become a popular way for individuals to connect with potential romantic partners. Many dating apps use personal profiles that include a headshot and self-description, allowing users to present themselves and search for compatible matches. However, this traditional model often has limitations. In this study, we explore a non-traditional voice-based dating app called \"Soul\". Unlike traditional platforms that rely heavily on profile information, Soul facilitates user interactions through voice-based communication. We conducted semi-structured interviews with 18 dedicated Soul users to investigate how they engage with the platform and perceive themselves and others in this unique dating environment. Our findings indicate that the role of voice as a moderator influences impression management and shapes perceptions between the sender and the receiver of the voice. Additionally, the synchronous voice-based and community-based dating model offers benefits to users in the Chinese cultural context. Our study contributes to understanding the affordances introduced by voice-based interactions in online dating in China.\n    ",
        "primary_category": "cs.HC",
        "categories": [
            "cs.CY",
            "cs.SI"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19333": {
        "title": "Compact Speech Translation Models via Discrete Speech Units Pretraining",
        "authors": [
            "Tsz Kin Lam",
            "Alexandra Birch",
            "Barry Haddow"
        ],
        "comments": " ",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "Using Self-Supervised Learning (SSL) as model initialization is now common to obtain strong results in Speech Translation (ST). However, they also impose a large memory footprint, hindering on-device deployment. In this paper, we leverage the SSL models by pretraining smaller models on their Discrete Speech Units (DSU). We pretrain encoder-decoder models on 1) Filterbank-to-DSU and 2) DSU-to-Translation data, and take the encoder from 1) and the decoder from 2) to initialise a new model, finetuning this on limited speech-translation data. The final model becomes compact by using the DSU pretraining to distil the knowledge of the SSL model. Our method has several benefits over using DSU as model inputs, such as shorter inference pipeline and robustness over (DSU) tokenization. In contrast to ASR pretraining, it does not require transcripts, making it applicable to low-resource settings. Evaluation on CoVoST-2 X-En shows that our method is >$0.5$ BLEU better than a ST model that directly finetune the SSL model, given only half the model size, and on a par with ASR pretraining.\n    ",
        "primary_category": "cs.CL",
        "categories": [
            "cs.SD",
            "eess.AS"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19334": {
        "title": "Here's a Free Lunch: Sanitizing Backdoored Models with Model Merge",
        "authors": [
            "Ansh Arora",
            "Xuanli He",
            "Maximilian Mozes",
            "Srinibas Swain",
            "Mark Dras",
            "Qiongkai Xu"
        ],
        "comments": "work in progress",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "The democratization of pre-trained language models through open-source initiatives has rapidly advanced innovation and expanded access to cutting-edge technologies. However, this openness also brings significant security risks, including backdoor attacks, where hidden malicious behaviors are triggered by specific inputs, compromising natural language processing (NLP) system integrity and reliability. This paper suggests that merging a backdoored model with other homogeneous models can remediate backdoor vulnerabilities even if such models are not entirely secure. In our experiments, we explore various models (BERT-Base, RoBERTa-Large, Llama2-7B, and Mistral-7B) and datasets (SST-2, OLID, AG News, and QNLI). Compared to multiple advanced defensive approaches, our method offers an effective and efficient inference-stage defense against backdoor attacks without additional resources or specific knowledge. Our approach consistently outperforms the other advanced baselines, leading to an average of 75% reduction in the attack success rate. Since model merging has been an established approach for improving model performance, the extra advantage it provides regarding defense can be seen as a cost-free bonus.\n    ",
        "primary_category": "cs.CL",
        "categories": [],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19339": {
        "title": "Stitching Gaps: Fusing Situated Perceptual Knowledge with Vision Transformers for High-Level Image Classification",
        "authors": [
            "Delfina Sol Martinez Pandiani",
            "Nicolas Lazzari",
            "Valentina Presutti"
        ],
        "comments": "Preprint",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "The increasing demand for automatic high-level image understanding, particularly in detecting abstract concepts (AC) within images, underscores the necessity for innovative and more interpretable approaches. These approaches need to harmonize traditional deep vision methods with the nuanced, context-dependent knowledge humans employ to interpret images at intricate semantic levels. In this work, we leverage situated perceptual knowledge of cultural images to enhance performance and interpretability in AC image classification. We automatically extract perceptual semantic units from images, which we then model and integrate into the ARTstract Knowledge Graph (AKG). This resource captures situated perceptual semantics gleaned from over 14,000 cultural images labeled with ACs. Additionally, we enhance the AKG with high-level linguistic frames. We compute KG embeddings and experiment with relative representations and hybrid approaches that fuse these embeddings with visual transformer embeddings. Finally, for interpretability, we conduct posthoc qualitative analyses by examining model similarities with training instances. Our results show that our hybrid KGE-ViT methods outperform existing techniques in AC image classification. The posthoc interpretability analyses reveal the visual transformer's proficiency in capturing pixel-level visual attributes, contrasting with our method's efficacy in representing more abstract and semantic scene elements. We demonstrate the synergy and complementarity between KGE embeddings' situated perceptual knowledge and deep visual model's sensory-perceptual understanding for AC image classification. This work suggests a strong potential of neuro-symbolic methods for knowledge integration and robust image representation for use in downstream intricate visual comprehension tasks. All the materials and code are available online.\n    ",
        "primary_category": "cs.CV",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19341": {
        "title": "RoadRunner - Learning Traversability Estimation for Autonomous Off-road Driving",
        "authors": [
            "Jonas Frey",
            "Shehryar Khattak",
            "Manthan Patel",
            "Deegan Atha",
            "Julian Nubert",
            "Curtis Padgett",
            "Marco Hutter",
            "Patrick Spieler"
        ],
        "comments": "under review for Field Robotics",
        "subjects": "Robotics (cs.RO)",
        "abstract": "Autonomous navigation at high speeds in off-road environments necessitates robots to comprehensively understand their surroundings using onboard sensing only. The extreme conditions posed by the off-road setting can cause degraded camera image quality due to poor lighting and motion blur, as well as limited sparse geometric information available from LiDAR sensing when driving at high speeds. In this work, we present RoadRunner, a novel framework capable of predicting terrain traversability and an elevation map directly from camera and LiDAR sensor inputs. RoadRunner enables reliable autonomous navigation, by fusing sensory information, handling of uncertainty, and generation of contextually informed predictions about the geometry and traversability of the terrain while operating at low latency. In contrast to existing methods relying on classifying handcrafted semantic classes and using heuristics to predict traversability costs, our method is trained end-to-end in a self-supervised fashion. The RoadRunner network architecture builds upon popular sensor fusion network architectures from the autonomous driving domain, which embed LiDAR and camera information into a common Bird's Eye View perspective. Training is enabled by utilizing an existing traversability estimation stack to generate training data in hindsight in a scalable manner from real-world off-road driving datasets. Furthermore, RoadRunner improves the system latency by a factor of roughly 4, from 500 ms to 140 ms, while improving the accuracy for traversability costs and elevation map predictions. We demonstrate the effectiveness of RoadRunner in enabling safe and reliable off-road navigation at high speeds in multiple real-world driving scenarios through unstructured desert environments.\n    ",
        "primary_category": "cs.RO",
        "categories": [
            "cs.CV"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19347": {
        "title": "#PoetsOfInstagram: Navigating The Practices And Challenges Of Novice Poets On Instagram",
        "authors": [
            "Ankolika De",
            "Zhicong Lu"
        ],
        "comments": "16 pages, 2 figures; Accepted to ACM CHI 2024. In Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems (CHI'24)",
        "subjects": "Human-Computer Interaction (cs.HC)",
        "abstract": "Commencing as a photo-sharing platform, Instagram has since become multifaceted, accommodating diverse art forms, with poetry emerging as a prominent one. However, the academic understanding of Instagram's poetry community is limited, yet its significance emerges from its distinctive utilization of a primarily visual social media platform guided by recommendation algorithms for disseminating poetry, further characterized by a predominantly novice creative population. We employ qualitative analysis to explore motivations, experiences, and algorithmic influence within Instagram's poetry community. We demonstrate that participants prioritize conforming to algorithmic constraints for visibility, yet maintain their community's values of integrity and originality, illustrating the tension between algorithmic growth and participant authenticity. We introduce the concept of Algorithmically Mediated Creative Labor, a phenomenon specific to non-monetizing creative users who are impacted by the prioritization of professional creators and continually adapt their creative endeavors to align with platform logic, thereby affecting their motivation and creative outputs.\n    ",
        "primary_category": "cs.HC",
        "categories": [
            "cs.CY",
            "cs.SI"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19348": {
        "title": "Deep Learning for Cross-Domain Data Fusion in Urban Computing: Taxonomy, Advances, and Outlook",
        "authors": [
            "Xingchen Zou",
            "Yibo Yan",
            "Xixuan Hao",
            "Yuehong Hu",
            "Haomin Wen",
            "Erdong Liu",
            "Junbo Zhang",
            "Yong Li",
            "Tianrui Li",
            "Yu Zheng",
            "Yuxuan Liang"
        ],
        "comments": " ",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "As cities continue to burgeon, Urban Computing emerges as a pivotal discipline for sustainable development by harnessing the power of cross-domain data fusion from diverse sources (e.g., geographical, traffic, social media, and environmental data) and modalities (e.g., spatio-temporal, visual, and textual modalities). Recently, we are witnessing a rising trend that utilizes various deep-learning methods to facilitate cross-domain data fusion in smart cities. To this end, we propose the first survey that systematically reviews the latest advancements in deep learning-based data fusion methods tailored for urban computing. Specifically, we first delve into data perspective to comprehend the role of each modality and data source. Secondly, we classify the methodology into four primary categories: feature-based, alignment-based, contrast-based, and generation-based fusion methods. Thirdly, we further categorize multi-modal urban applications into seven types: urban planning, transportation, economy, public safety, society, environment, and energy. Compared with previous surveys, we focus more on the synergy of deep learning methods with urban computing applications. Furthermore, we shed light on the interplay between Large Language Models (LLMs) and urban computing, postulating future research directions that could revolutionize the field. We firmly believe that the taxonomy, progress, and prospects delineated in our survey stand poised to significantly enrich the research community. The summary of the comprehensive and up-to-date paper list can be found at this https URL.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19351": {
        "title": "Oriented trees in $O(k \\sqrt{k})$-chromatic digraphs, a subquadratic bound for Burr's conjecture",
        "authors": [
            "St\u00e9phane Bessy",
            "Daniel Gon\u00e7alves",
            "Amadeus Reinald"
        ],
        "comments": "17 pages, 2 figures",
        "subjects": "Combinatorics (math.CO)",
        "abstract": "In 1980, Burr conjectured that every directed graph with chromatic number $2k-2$ contains any oriented tree of order $k$ as a subdigraph. Burr showed that chromatic number $(k-1)^2$ suffices, which was improved in 2013 to $\\frac{k^2}{2} - \\frac{k}{2} + 1$ by Addario-Berry et al. We give the first subquadratic bound for Burr's conjecture, by showing that every directed graph with chromatic number $8\\sqrt{\\frac{2}{15}} k \\sqrt{k} + O(k)$ contains any oriented tree of order $k$. Moreover, we provide improved bounds of $\\sqrt{\\frac{4}{3}} k \\sqrt{k}+O(k)$ for arborescences, and $(b-1)(k-3)+3$ for paths on $b$ blocks, with $b\\ge 2$.\n    ",
        "primary_category": "math.CO",
        "categories": [
            "cs.DM"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19355": {
        "title": "Unraveling Adversarial Examples against Speaker Identification -- Techniques for Attack Detection and Victim Model Classification",
        "authors": [
            "Sonal Joshi",
            "Thomas Thebaud",
            "Jes\u00fas Villalba",
            "Najim Dehak"
        ],
        "comments": " ",
        "subjects": "Sound (cs.SD)",
        "abstract": "Adversarial examples have proven to threaten speaker identification systems, and several countermeasures against them have been proposed. In this paper, we propose a method to detect the presence of adversarial examples, i.e., a binary classifier distinguishing between benign and adversarial examples. We build upon and extend previous work on attack type classification by exploring new architectures. Additionally, we introduce a method for identifying the victim model on which the adversarial attack is carried out. To achieve this, we generate a new dataset containing multiple attacks performed against various victim models. We achieve an AUC of 0.982 for attack detection, with no more than a 0.03 drop in performance for unknown attacks. Our attack classification accuracy (excluding benign) reaches 86.48% across eight attack types using our LightResNet34 architecture, while our victim model classification accuracy reaches 72.28% across four victim models.\n    ",
        "primary_category": "cs.SD",
        "categories": [
            "cs.CR",
            "cs.LG",
            "eess.AS"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19360": {
        "title": "Joint Chance Constrained Optimal Control via Linear Programming",
        "authors": [
            "Niklas Schmid",
            "Marta Fochesato",
            "Tobias Sutter",
            "John Lygeros"
        ],
        "comments": " ",
        "subjects": "Optimization and Control (math.OC)",
        "abstract": "We establish a linear programming formulation for the solution of joint chance constrained optimal control problems over finite time horizons. The joint chance constraint may represent an invariance, reachability or reach-avoid specification that the trajectory must satisfy with a predefined probability. Compared to the existing literature, the formulation is computationally tractable and the solution exact.\n    ",
        "primary_category": "math.OC",
        "categories": [
            "eess.SY"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19365": {
        "title": "On Efficient Computation of DiRe Committees",
        "authors": [
            "Kunal Relia"
        ],
        "comments": "single-column format. 33 pages. 26 Figures. 6 Tables. 4 Algorithms. 4 Theorems. 9 Lemmas/Lemmata. 2 Observations. 14 Definitions. 2 Examples. Reducing inequality is easier than expected. P=NP",
        "subjects": "Computational Complexity (cs.CC)",
        "abstract": "Consider a committee election consisting of (i) a set of candidates who are divided into arbitrary groups each of size \\emph{at most} two and a diversity constraint that stipulates the selection of \\emph{at least} one candidate from each group and (ii) a set of voters who are divided into arbitrary populations each approving \\emph{at most} two candidates and a representation constraint that stipulates the selection of \\emph{at least} one candidate from each population who has a non-null set of approved candidates.\nThe DiRe (Diverse + Representative) committee feasibility problem (a.k.a. the minimum vertex cover problem on unweighted undirected graphs) concerns the determination of the smallest size committee that satisfies the given constraints. Here, for this problem, we discover an unconditional deterministic polynomial-time algorithm that is an amalgamation of maximum matching, breadth-first search, maximal matching, and local minimization.\n    ",
        "primary_category": "cs.CC",
        "categories": [
            "cs.CY",
            "cs.GT"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19366": {
        "title": "SoK: Exploring the Potential of Large Language Models for Improving Digital Forensic Investigation Efficiency",
        "authors": [
            "Akila Wickramasekara",
            "Frank Breitinger",
            "Mark Scanlon"
        ],
        "comments": " ",
        "subjects": "Cryptography and Security (cs.CR)",
        "abstract": "The growing number of cases requiring digital forensic analysis raises concerns about law enforcement's ability to conduct investigations promptly. Consequently, this systemisation of knowledge paper delves into the potential and effectiveness of integrating Large Language Models (LLMs) into digital forensic investigation to address these challenges. A thorough literature review is undertaken, encompassing existing digital forensic models, tools, LLMs, deep learning techniques, and the utilisation of LLMs in investigations. The review identifies current challenges within existing digital forensic processes and explores both the obstacles and possibilities of incorporating LLMs. In conclusion, the study asserts that the adoption of LLMs in digital forensics, with appropriate constraints, holds the potential to enhance investigation efficiency, improve traceability, and alleviate technical and judicial barriers faced by law enforcement entities.\n    ",
        "primary_category": "cs.CR",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19369": {
        "title": "Structure Preserving Diffusion Models",
        "authors": [
            "Haoye Lu",
            "Spencer Szabados",
            "Yaoliang Yu"
        ],
        "comments": " ",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Diffusion models have become the leading distribution-learning method in recent years. Herein, we introduce structure-preserving diffusion processes, a family of diffusion processes for learning distributions that possess additional structure, such as group symmetries, by developing theoretical conditions under which the diffusion transition steps preserve said symmetry. While also enabling equivariant data sampling trajectories, we exemplify these results by developing a collection of different symmetry equivariant diffusion models capable of learning distributions that are inherently symmetric. Empirical studies, over both synthetic and real-world datasets, are used to validate the developed models adhere to the proposed theory and are capable of achieving improved performance over existing methods in terms of sample equality. We also show how the proposed models can be used to achieve theoretically guaranteed equivariant image noise reduction without prior knowledge of the image orientation.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.CV"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19371": {
        "title": "OpenMedLM: Prompt engineering can out-perform fine-tuning in medical question-answering with open-source large language models",
        "authors": [
            "Jenish Maharjan",
            "Anurag Garikipati",
            "Navan Preet Singh",
            "Leo Cyrus",
            "Mayank Sharma",
            "Madalina Ciobanu",
            "Gina Barnes",
            "Rahul Thapa",
            "Qingqing Mao",
            "Ritankar Das"
        ],
        "comments": " ",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "LLMs have become increasingly capable at accomplishing a range of specialized-tasks and can be utilized to expand equitable access to medical knowledge. Most medical LLMs have involved extensive fine-tuning, leveraging specialized medical data and significant, thus costly, amounts of computational power. Many of the top performing LLMs are proprietary and their access is limited to very few research groups. However, open-source (OS) models represent a key area of growth for medical LLMs due to significant improvements in performance and an inherent ability to provide the transparency and compliance required in healthcare. We present OpenMedLM, a prompting platform which delivers state-of-the-art (SOTA) performance for OS LLMs on medical benchmarks. We evaluated a range of OS foundation LLMs (7B-70B) on four medical benchmarks (MedQA, MedMCQA, PubMedQA, MMLU medical-subset). We employed a series of prompting strategies, including zero-shot, few-shot, chain-of-thought (random selection and kNN selection), and ensemble/self-consistency voting. We found that OpenMedLM delivers OS SOTA results on three common medical LLM benchmarks, surpassing the previous best performing OS models that leveraged computationally costly extensive fine-tuning. The model delivers a 72.6% accuracy on the MedQA benchmark, outperforming the previous SOTA by 2.4%, and achieves 81.7% accuracy on the MMLU medical-subset, establishing itself as the first OS LLM to surpass 80% accuracy on this benchmark. Our results highlight medical-specific emergent properties in OS LLMs which have not yet been documented to date elsewhere, and showcase the benefits of further leveraging prompt engineering to improve the performance of accessible LLMs for medical applications.\n    ",
        "primary_category": "cs.CL",
        "categories": [
            "cs.AI",
            "cs.IR"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19375": {
        "title": "Unveiling Internet Censorship: Analysing the Impact of Nation States' Content Control Efforts on Internet Architecture and Routing Patterns",
        "authors": [
            "Joshua Levett",
            "Vassilios Vassilakis",
            "Poonam Yadav"
        ],
        "comments": " ",
        "subjects": "Networking and Internet Architecture (cs.NI)",
        "abstract": "Heightened interest from nation states to perform content censorship make it evermore critical to identify the impact of censorship efforts on the Internet. We undertake a study of Internet architecture, capturing the state of Internet topology with greater completeness than existing state-of-the-art. We describe our methodology for this, including the tooling we create to collect and process data from a wide range of sources. We analyse this data to find key patterns in nation states with higher censorship, discovering a funnelling effect wherein higher Internet censorship effort is reflected in a constraining effect on a state's Internet routing architecture. However, there are a small number of nation states that do not follow this trend, for which we provide an analysis and explanation, demonstrating a relationship between geographical factors in addition to geopolitics. In summary, our work provides a deeper understanding of how these censorship measures impact the overall functioning and dynamics of the Internet.\n    ",
        "primary_category": "cs.NI",
        "categories": [],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19376": {
        "title": "OzMAC: An Energy-Efficient Sparsity-Exploiting Multiply-Accumulate-Unit Design for DL Inference",
        "authors": [
            "Harideep Nair",
            "Prabhu Vellaisamy",
            "Tsung-Han Lin",
            "Perry Wang",
            "Shawn Blanton",
            "John Paul Shen"
        ],
        "comments": " ",
        "subjects": "Hardware Architecture (cs.AR)",
        "abstract": "General Matrix Multiply (GEMM) hardware, employing large arrays of multiply-accumulate (MAC) units, perform bulk of the computation in deep learning (DL). Recent trends have established 8-bit integer (INT8) as the most widely used precision for DL inference. This paper proposes a novel MAC design capable of dynamically exploiting bit sparsity (i.e., number of `0' bits within a binary value) in input data to achieve significant improvements on area, power and energy. The proposed architecture, called OzMAC (Omit-zero-MAC), skips over zeros within a binary input value and performs simple shift-and-add-based compute in place of expensive multipliers. We implement OzMAC in SystemVerilog and present post-synthesis performance-power-area (PPA) results using commercial TSMC N5 (5nm) process node. Using eight pretrained INT8 deep neural networks (DNNs) as benchmarks, we demonstrate the existence of high bit sparsity in real DNN workloads and show that 8-bit OzMAC improves all three metrics of area, power, and energy significantly by 21%, 70%, and 28%, respectively. Similar improvements are achieved when scaling data precisions (4, 8, 16 bits) and clock frequencies (0.5 GHz, 1 GHz, 1.5 GHz). For the 8-bit OzMAC, scaling its frequency to normalize the throughput relative to conventional MAC, it still achieves 30% improvement on both power and energy.\n    ",
        "primary_category": "cs.AR",
        "categories": [],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19381": {
        "title": "Optimized Bayesian Framework for Inverse Heat Transfer Problems Using Reduced Order Methods",
        "authors": [
            "Kabir Bakhshaei",
            "Umberto Emil Morelli",
            "Giovanni Stabile",
            "Gianluigi Rozza"
        ],
        "comments": " ",
        "subjects": "Numerical Analysis (math.NA)",
        "abstract": "A stochastic inverse heat transfer problem is formulated to infer the transient heat flux, treated as an unknown Neumann boundary condition. Therefore, an Ensemble-based Simultaneous Input and State Filtering as a Data Assimilation technique is utilized for simultaneous temperature distribution prediction and heat flux estimation. This approach is incorporated with Radial Basis Functions not only to lessen the size of unknown inputs but also to mitigate the computational burden of this technique. The procedure applies to the specific case of a mold used in Continuous Casting machinery, and it is based on the sequential availability of temperature provided by thermocouples inside the mold. Our research represents a significant contribution to achieving probabilistic boundary condition estimation in real-time handling with noisy measurements and errors in the model. We additionally demonstrate the procedure's dependence on some hyperparameters that are not documented in the existing literature. Accurate real-time prediction of the heat flux is imperative for the smooth operation of Continuous Casting machinery at the boundary region where the Continuous Casting mold and the molten steel meet which is not also physically measurable. Thus, this paves the way for efficient real-time monitoring and control, which is critical for preventing caster shutdowns.\n    ",
        "primary_category": "math.NA",
        "categories": [],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19385": {
        "title": "Towards Safe and Reliable Autonomous Driving: Dynamic Occupancy Set Prediction",
        "authors": [
            "Wenbo Shao",
            "Jiahui Xu",
            "Wenhao Yu",
            "Jun Li",
            "Hong Wang"
        ],
        "comments": "9 pages, 5 figures",
        "subjects": "Robotics (cs.RO)",
        "abstract": "In the rapidly evolving field of autonomous driving, accurate trajectory prediction is pivotal for vehicular safety. However, trajectory predictions often deviate from actual paths, particularly in complex and challenging environments, leading to significant errors. To address this issue, our study introduces a novel method for Dynamic Occupancy Set (DOS) prediction, enhancing trajectory prediction capabilities. This method effectively combines advanced trajectory prediction networks with a DOS prediction module, overcoming the shortcomings of existing models. It provides a comprehensive and adaptable framework for predicting the potential occupancy sets of traffic participants. The main contributions of this research include: 1) A novel DOS prediction model tailored for complex scenarios, augmenting traditional trajectory prediction; 2) The development of unique DOS representations and evaluation metrics; 3) Extensive validation through experiments, demonstrating enhanced performance and adaptability. This research contributes to the advancement of safer and more efficient intelligent vehicle and transportation systems.\n    ",
        "primary_category": "cs.RO",
        "categories": [
            "cs.CV"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19387": {
        "title": "SeD: Semantic-Aware Discriminator for Image Super-Resolution",
        "authors": [
            "Bingchen Li",
            "Xin Li",
            "Hanxin Zhu",
            "Yeying Jin",
            "Ruoyu Feng",
            "Zhizheng Zhang",
            "Zhibo Chen"
        ],
        "comments": "CVPR2024",
        "subjects": "Image and Video Processing (eess.IV)",
        "abstract": "Generative Adversarial Networks (GANs) have been widely used to recover vivid textures in image super-resolution (SR) tasks. In particular, one discriminator is utilized to enable the SR network to learn the distribution of real-world high-quality images in an adversarial training manner. However, the distribution learning is overly coarse-grained, which is susceptible to virtual textures and causes counter-intuitive generation results. To mitigate this, we propose the simple and effective Semantic-aware Discriminator (denoted as SeD), which encourages the SR network to learn the fine-grained distributions by introducing the semantics of images as a condition. Concretely, we aim to excavate the semantics of images from a well-trained semantic extractor. Under different semantics, the discriminator is able to distinguish the real-fake images individually and adaptively, which guides the SR network to learn the more fine-grained semantic-aware textures. To obtain accurate and abundant semantics, we take full advantage of recently popular pretrained vision models (PVMs) with extensive datasets, and then incorporate its semantic features into the discriminator through a well-designed spatial cross-attention module. In this way, our proposed semantic-aware discriminator empowered the SR network to produce more photo-realistic and pleasing images. Extensive experiments on two typical tasks, i.e., SR and Real SR have demonstrated the effectiveness of our proposed methods.\n    ",
        "primary_category": "eess.IV",
        "categories": [
            "cs.CV"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19401": {
        "title": "Assessing Visually-Continuous Corruption Robustness of Neural Networks Relative to Human Performance",
        "authors": [
            "Huakun Shen",
            "Boyue Caroline Hu",
            "Krzysztof Czarnecki",
            "Lina Marsso",
            "Marsha Chechik"
        ],
        "comments": " ",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "While Neural Networks (NNs) have surpassed human accuracy in image classification on ImageNet, they often lack robustness against image corruption, i.e., corruption robustness. Yet such robustness is seemingly effortless for human perception. In this paper, we propose visually-continuous corruption robustness (VCR) -- an extension of corruption robustness to allow assessing it over the wide and continuous range of changes that correspond to the human perceptive quality (i.e., from the original image to the full distortion of all perceived visual information), along with two novel human-aware metrics for NN evaluation. To compare VCR of NNs with human perception, we conducted extensive experiments on 14 commonly used image corruptions with 7,718 human participants and state-of-the-art robust NN models with different training objectives (e.g., standard, adversarial, corruption robustness), different architectures (e.g., convolution NNs, vision transformers), and different amounts of training data augmentation. Our study showed that: 1) assessing robustness against continuous corruption can reveal insufficient robustness undetected by existing benchmarks; as a result, 2) the gap between NN and human robustness is larger than previously known; and finally, 3) some image corruptions have a similar impact on human perception, offering opportunities for more cost-effective robustness assessments. Our validation set with 14 image corruptions, human robustness data, and the evaluation code is provided as a toolbox and a benchmark.\n    ",
        "primary_category": "cs.CV",
        "categories": [],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19402": {
        "title": "A Scalable and Transferable Time Series Prediction Framework for Demand Forecasting",
        "authors": [
            "Young-Jin Park",
            "Donghyun Kim",
            "Fr\u00e9d\u00e9ric Odermatt",
            "Juho Lee",
            "Kyung-Min Kim"
        ],
        "comments": "Published as a full paper at ICDM 2022",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Time series forecasting is one of the most essential and ubiquitous tasks in many business problems, including demand forecasting and logistics optimization. Traditional time series forecasting methods, however, have resulted in small models with limited expressive power because they have difficulty in scaling their model size up while maintaining high accuracy. In this paper, we propose Forecasting orchestra (Forchestra), a simple but powerful framework capable of accurately predicting future demand for a diverse range of items. We empirically demonstrate that the model size is scalable to up to 0.8 billion parameters. The proposed method not only outperforms existing forecasting models with a significant margin, but it could generalize well to unseen data points when evaluated in a zero-shot fashion on downstream datasets. Last but not least, we present extensive qualitative and quantitative studies to analyze how the proposed model outperforms baseline models and differs from conventional approaches. The original paper was presented as a full paper at ICDM 2022 and is available at: this https URL.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19405": {
        "title": "Navigating Hallucinations for Reasoning of Unintentional Activities",
        "authors": [
            "Shresth Grover",
            "Vibhav Vineet",
            "Yogesh S Rawat"
        ],
        "comments": " ",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "In this work we present a novel task of understanding unintentional human activities in videos. We formalize this problem as a reasoning task under zero-shot scenario, where given a video of an unintentional activity we want to know why it transitioned from intentional to unintentional. We first evaluate the effectiveness of current state-of-the-art Large Multimodal Models on this reasoning task and observe that they suffer from hallucination. We further propose a novel prompting technique,termed as Dream of Thoughts (DoT), which allows the model to navigate through hallucinated thoughts to achieve better reasoning. To evaluate the performance on this task, we also introduce three different specialized metrics designed to quantify the models reasoning capability. We perform our experiments on two different datasets, OOPs and UCF-Crimes, and our findings show that DOT prompting technique is able to outperform standard prompting, while minimizing hallucinations.\n    ",
        "primary_category": "cs.CV",
        "categories": [],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19406": {
        "title": "On the Scaling Laws of Geographical Representation in Language Models",
        "authors": [
            "Nathan Godey",
            "\u00c9ric de la Clergerie",
            "Beno\u00eet Sagot"
        ],
        "comments": "Accepted at LREC-COLING 2024",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "Language models have long been shown to embed geographical information in their hidden representations. This line of work has recently been revisited by extending this result to Large Language Models (LLMs). In this paper, we propose to fill the gap between well-established and recent literature by observing how geographical knowledge evolves when scaling language models. We show that geographical knowledge is observable even for tiny models, and that it scales consistently as we increase the model size. Notably, we observe that larger language models cannot mitigate the geographical bias that is inherent to the training data.\n    ",
        "primary_category": "cs.CL",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19407": {
        "title": "MENTOR: Multi-level Self-supervised Learning for Multimodal Recommendation",
        "authors": [
            "Jinfeng Xu",
            "Zheyu Chen",
            "Shuo Yang",
            "Jinze Li",
            "Hewei Wang",
            "Edith C.-H. Ngai"
        ],
        "comments": " ",
        "subjects": "Information Retrieval (cs.IR)",
        "abstract": "With the increasing multimedia information, multimodal recommendation has received extensive attention. It utilizes multimodal information to alleviate the data sparsity problem in recommendation systems, thus improving recommendation accuracy. However, the reliance on labeled data severely limits the performance of multimodal recommendation models. Recently, self-supervised learning has been used in multimodal recommendations to mitigate the label sparsity problem. Nevertheless, the state-of-the-art methods cannot avoid the modality noise when aligning multimodal information due to the large differences in the distributions of different modalities. To this end, we propose a Multi-level sElf-supervised learNing for mulTimOdal Recommendation (MENTOR) method to address the label sparsity problem and the modality alignment problem. Specifically, MENTOR first enhances the specific features of each modality using the graph convolutional network (GCN) and fuses the visual and textual modalities. It then enhances the item representation via the item semantic graph for all modalities, including the fused modality. Then, it introduces two multilevel self-supervised tasks: the multilevel cross-modal alignment task and the general feature enhancement task. The multilevel cross-modal alignment task aligns each modality under the guidance of the ID embedding from multiple levels while maintaining the historical interaction information. The general feature enhancement task enhances the general feature from both the graph and feature perspectives to improve the robustness of our model. Extensive experiments on three publicly available datasets demonstrate the effectiveness of our method. Our code is publicly available at this https URL.\n    ",
        "primary_category": "cs.IR",
        "categories": [],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19410": {
        "title": "Genie: Smart ROS-based Caching for Connected Autonomous Robots",
        "authors": [
            "Zexin Li",
            "Soroush Bateni",
            "Cong Liu"
        ],
        "comments": "Submitted to IROS 2024",
        "subjects": "Robotics (cs.RO)",
        "abstract": "Despite the promising future of autonomous robots, several key issues currently remain that can lead to compromised performance and safety. One such issue is latency, where we find that even the latest embedded platforms from NVIDIA fail to execute intelligence tasks (e.g., object detection) of autonomous vehicles in a real-time fashion. One remedy to this problem is the promising paradigm of edge computing. Through collaboration with our industry partner, we identify key prohibitive limitations of the current edge mindset: (1) servers are not distributed enough and thus, are not close enough to vehicles, (2) current proposed edge solutions do not provide substantially better performance and extra information specific to autonomous vehicles to warrant their cost to the user, and (3) the state-of-the-art solutions are not compatible with popular frameworks used in autonomous systems, particularly the Robot Operating System (ROS).\nTo remedy these issues, we provide Genie, an encapsulation technique that can enable transparent caching in ROS in a non-intrusive way (i.e., without modifying the source code), can build the cache in a distributed manner (in contrast to traditional central caching methods), and can construct a collective three-dimensional object map to provide substantially better latency (even on low-power edge servers) and higher quality data to all vehicles in a certain locality. We fully implement our design on state-of-the-art industry-adopted embedded and edge platforms, using the prominent autonomous driving software Autoware, and find that Genie can enhance the latency of Autoware Vision Detector by 82% on average, enable object reusability 31% of the time on average and as much as 67% for the incoming requests, and boost the confidence in its object map considerably over time.\n    ",
        "primary_category": "cs.RO",
        "categories": [
            "eess.SY"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19411": {
        "title": "PaECTER: Patent-level Representation Learning using Citation-informed Transformers",
        "authors": [
            "Mainak Ghosh",
            "Sebastian Erhardt",
            "Michael E. Rose",
            "Erik Buunk",
            "Dietmar Harhoff"
        ],
        "comments": "7 pages, 3 figures",
        "subjects": "Information Retrieval (cs.IR)",
        "abstract": "PaECTER is a publicly available, open-source document-level encoder specific for patents. We fine-tune BERT for Patents with examiner-added citation information to generate numerical representations for patent documents. PaECTER performs better in similarity tasks than current state-of-the-art models used in the patent domain. More specifically, our model outperforms the next-best patent specific pre-trained language model (BERT for Patents) on our patent citation prediction test dataset on two different rank evaluation metrics. PaECTER predicts at least one most similar patent at a rank of 1.32 on average when compared against 25 irrelevant patents. Numerical representations generated by PaECTER from patent text can be used for downstream tasks such as classification, tracing knowledge flows, or semantic similarity search. Semantic similarity search is especially relevant in the context of prior art search for both inventors and patent examiners. PaECTER is available on Hugging Face.\n    ",
        "primary_category": "cs.IR",
        "categories": [
            "cs.CL",
            "cs.LG"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19420": {
        "title": "Understanding Iterative Combinatorial Auction Designs via Multi-Agent Reinforcement Learning",
        "authors": [
            "Greg d'Eon",
            "Neil Newman",
            "Kevin Leyton-Brown"
        ],
        "comments": "18 pages (body) + 10 pages (acknowledgements, references, appendices)",
        "subjects": "Computer Science and Game Theory (cs.GT)",
        "abstract": "Iterative combinatorial auctions are widely used in high stakes settings such as spectrum auctions. Such auctions can be hard to understand analytically, making it difficult for bidders to determine how to behave and for designers to optimize auction rules to ensure desirable outcomes such as high revenue or welfare. In this paper, we investigate whether multi-agent reinforcement learning (MARL) algorithms can be used to understand iterative combinatorial auctions, given that these algorithms have recently shown empirical success in several other domains. We find that MARL can indeed benefit auction analysis, but that deploying it effectively is nontrivial. We begin by describing modelling decisions that keep the resulting game tractable without sacrificing important features such as imperfect information or asymmetry between bidders. We also discuss how to navigate pitfalls of various MARL algorithms, how to overcome challenges in verifying convergence, and how to generate and interpret multiple equilibria. We illustrate the promise of our resulting approach by using it to evaluate a specific rule change to a clock auction, finding substantially different auction outcomes due to complex changes in bidders' behavior.\n    ",
        "primary_category": "cs.GT",
        "categories": [
            "cs.AI",
            "cs.MA"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19421": {
        "title": "Crafting Knowledge: Exploring the Creative Mechanisms of Chat-Based Search Engines",
        "authors": [
            "Lijia Ma",
            "Xingchen Xu",
            "Yong Tan"
        ],
        "comments": "38 pages, 2 figures, 7 tables",
        "subjects": "Information Retrieval (cs.IR)",
        "abstract": "In the domain of digital information dissemination, search engines act as pivotal conduits linking information seekers with providers. The advent of chat-based search engines utilizing Large Language Models (LLMs) and Retrieval Augmented Generation (RAG), exemplified by Bing Chat, marks an evolutionary leap in the search ecosystem. They demonstrate metacognitive abilities in interpreting web information and crafting responses with human-like understanding and creativity. Nonetheless, the intricate nature of LLMs renders their \"cognitive\" processes opaque, challenging even their designers' understanding. This research aims to dissect the mechanisms through which an LLM-powered chat-based search engine, specifically Bing Chat, selects information sources for its responses. To this end, an extensive dataset has been compiled through engagements with New Bing, documenting the websites it cites alongside those listed by the conventional search engine. Employing natural language processing (NLP) techniques, the research reveals that Bing Chat exhibits a preference for content that is not only readable and formally structured, but also demonstrates lower perplexity levels, indicating a unique inclination towards text that is predictable by the underlying LLM. Further enriching our analysis, we procure an additional dataset through interactions with the GPT-4 based knowledge retrieval API, unveiling a congruent text preference between the RAG API and Bing Chat. This consensus suggests that these text preferences intrinsically emerge from the underlying language models, rather than being explicitly crafted by Bing Chat's developers. Moreover, our investigation documents a greater similarity among websites cited by RAG technologies compared to those ranked highest by conventional search engines.\n    ",
        "primary_category": "cs.IR",
        "categories": [
            "cs.AI",
            "econ.GN"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19423": {
        "title": "Leveraging AI Predicted and Expert Revised Annotations in Interactive Segmentation: Continual Tuning or Full Training?",
        "authors": [
            "Tiezheng Zhang",
            "Xiaoxi Chen",
            "Chongyu Qu",
            "Alan Yuille",
            "Zongwei Zhou"
        ],
        "comments": "IEEE International Symposium on Biomedical Imaging (ISBI)",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Interactive segmentation, an integration of AI algorithms and human expertise, premises to improve the accuracy and efficiency of curating large-scale, detailed-annotated datasets in healthcare. Human experts revise the annotations predicted by AI, and in turn, AI improves its predictions by learning from these revised annotations. This interactive process continues to enhance the quality of annotations until no major revision is needed from experts. The key challenge is how to leverage AI predicted and expert revised annotations to iteratively improve the AI. Two problems arise: (1) The risk of catastrophic forgetting--the AI tends to forget the previously learned classes if it is only retrained using the expert revised classes. (2) Computational inefficiency when retraining the AI using both AI predicted and expert revised annotations; moreover, given the dominant AI predicted annotations in the dataset, the contribution of newly revised annotations--often account for a very small fraction--to the AI training remains marginal. This paper proposes Continual Tuning to address the problems from two perspectives: network design and data reuse. Firstly, we design a shared network for all classes followed by class-specific networks dedicated to individual classes. To mitigate forgetting, we freeze the shared network for previously learned classes and only update the class-specific network for revised classes. Secondly, we reuse a small fraction of data with previous annotations to avoid over-computing. The selection of such data relies on the importance estimate of each data. The importance score is computed by combining the uncertainty and consistency of AI predictions. Our experiments demonstrate that Continual Tuning achieves a speed 16x greater than repeatedly training AI from scratch without compromising the performance.\n    ",
        "primary_category": "cs.CV",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19427": {
        "title": "Griffin: Mixing Gated Linear Recurrences with Local Attention for Efficient Language Models",
        "authors": [
            "Soham De",
            "Samuel L. Smith",
            "Anushan Fernando",
            "Aleksandar Botev",
            "George Cristian-Muraru",
            "Albert Gu",
            "Ruba Haroun",
            "Leonard Berrada",
            "Yutian Chen",
            "Srivatsan Srinivasan",
            "Guillaume Desjardins",
            "Arnaud Doucet",
            "David Budden",
            "Yee Whye Teh",
            "Razvan Pascanu",
            "Nando De Freitas",
            "Caglar Gulcehre"
        ],
        "comments": "25 pages, 11 figures",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Recurrent neural networks (RNNs) have fast inference and scale efficiently on long sequences, but they are difficult to train and hard to scale. We propose Hawk, an RNN with gated linear recurrences, and Griffin, a hybrid model that mixes gated linear recurrences with local attention. Hawk exceeds the reported performance of Mamba on downstream tasks, while Griffin matches the performance of Llama-2 despite being trained on over 6 times fewer tokens. We also show that Griffin can extrapolate on sequences significantly longer than those seen during training. Our models match the hardware efficiency of Transformers during training, and during inference they have lower latency and significantly higher throughput. We scale Griffin up to 14B parameters, and explain how to shard our models for efficient distributed training.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.CL"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19431": {
        "title": "Compositional API Recommendation for Library-Oriented Code Generation",
        "authors": [
            "Zexiong Ma",
            "Shengnan An",
            "Bing Xie",
            "Zeqi Lin"
        ],
        "comments": " ",
        "subjects": "Software Engineering (cs.SE)",
        "abstract": "Large language models (LLMs) have achieved exceptional performance in code generation. However, the performance remains unsatisfactory in generating library-oriented code, especially for the libraries not present in the training data of LLMs. Previous work utilizes API recommendation technology to help LLMs use libraries: it retrieves APIs related to the user requirements, then leverages them as context to prompt LLMs. However, developmental requirements can be coarse-grained, requiring a combination of multiple fine-grained APIs. This granularity inconsistency makes API recommendation a challenging task. To address this, we propose CAPIR (Compositional API Recommendation), which adopts a \"divide-and-conquer\" strategy to recommend APIs for coarse-grained requirements. Specifically, CAPIR employs an LLM-based Decomposer to break down a coarse-grained task description into several detailed subtasks. Then, CAPIR applies an embedding-based Retriever to identify relevant APIs corresponding to each subtask. Moreover, CAPIR leverages an LLM-based Reranker to filter out redundant APIs and provides the final recommendation. To facilitate the evaluation of API recommendation methods on coarse-grained requirements, we present two challenging benchmarks, RAPID (Recommend APIs based on Documentation) and LOCG (Library-Oriented Code Generation). Experimental results on these benchmarks, demonstrate the effectiveness of CAPIR in comparison to existing baselines. Specifically, on RAPID's Torchdata-AR dataset, compared to the state-of-the-art API recommendation approach, CAPIR improves recall@5 from 18.7% to 43.2% and precision@5 from 15.5% to 37.1%. On LOCG's Torchdata-Code dataset, compared to code generation without API recommendation, CAPIR improves pass@100 from 16.0% to 28.0%.\n    ",
        "primary_category": "cs.SE",
        "categories": [
            "cs.AI",
            "cs.CL"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19432": {
        "title": "Pushing the Limits of Cross-Embodiment Learning for Manipulation and Navigation",
        "authors": [
            "Jonathan Yang",
            "Catherine Glossop",
            "Arjun Bhorkar",
            "Dhruv Shah",
            "Quan Vuong",
            "Chelsea Finn",
            "Dorsa Sadigh",
            "Sergey Levine"
        ],
        "comments": "16 pages, 9 figures",
        "subjects": "Robotics (cs.RO)",
        "abstract": "Recent years in robotics and imitation learning have shown remarkable progress in training large-scale foundation models by leveraging data across a multitude of embodiments. The success of such policies might lead us to wonder: just how diverse can the robots in the training set be while still facilitating positive transfer? In this work, we study this question in the context of heterogeneous embodiments, examining how even seemingly very different domains, such as robotic navigation and manipulation, can provide benefits when included in the training data for the same model. We train a single goal-conditioned policy that is capable of controlling robotic arms, quadcopters, quadrupeds, and mobile bases. We then investigate the extent to which transfer can occur across navigation and manipulation on these embodiments by framing them as a single goal-reaching task. We find that co-training with navigation data can enhance robustness and performance in goal-conditioned manipulation with a wrist-mounted camera. We then deploy our policy trained only from navigation-only and static manipulation-only data on a mobile manipulator, showing that it can control a novel embodiment in a zero-shot manner. These results provide evidence that large-scale robotic policies can benefit from data collected across various embodiments. Further information and robot videos can be found on our project website this http URL.\n    ",
        "primary_category": "cs.RO",
        "categories": [],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19434": {
        "title": "Digital Twin Aided Massive MIMO: CSI Compression and Feedback",
        "authors": [
            "Shuaifeng Jiang",
            "Ahmed Alkhateeb"
        ],
        "comments": "Accepted in ICC 2024. Dataset and code files will be available soon on the DeepMIMO website this https URL",
        "subjects": "Information Theory (cs.IT)",
        "abstract": "Deep learning (DL) approaches have demonstrated high performance in compressing and reconstructing the channel state information (CSI) and reducing the CSI feedback overhead in massive MIMO systems. One key challenge, however, with the DL approaches is the demand for extensive training data. Collecting this real-world CSI data incurs significant overhead that hinders the DL approaches from scaling to a large number of communication sites. To address this challenge, we propose a novel direction that utilizes site-specific \\textit{digital twins} to aid the training of DL models. The proposed digital twin approach generates site-specific synthetic CSI data from the EM 3D model and ray tracing, which can then be used to train the DL model without real-world data collection. To further improve the performance, we adopt online data selection to refine the DL model training with a small real-world CSI dataset. Results show that a DL model trained solely on the digital twin data can achieve high performance when tested in a real-world deployment. Further, leveraging domain adaptation techniques, the proposed approach requires orders of magnitude less real-world data to approach the same performance of the model trained completely on a real-world CSI dataset.\n    ",
        "primary_category": "cs.IT",
        "categories": [
            "eess.SP"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19437": {
        "title": "Differentially Private Worst-group Risk Minimization",
        "authors": [
            "Xinyu Zhou",
            "Raef Bassily"
        ],
        "comments": " ",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "We initiate a systematic study of worst-group risk minimization under $(\\epsilon, \\delta)$-differential privacy (DP). The goal is to privately find a model that approximately minimizes the maximal risk across $p$ sub-populations (groups) with different distributions, where each group distribution is accessed via a sample oracle. We first present a new algorithm that achieves excess worst-group population risk of $\\tilde{O}(\\frac{p\\sqrt{d}}{K\\epsilon} + \\sqrt{\\frac{p}{K}})$, where $K$ is the total number of samples drawn from all groups and $d$ is the problem dimension. Our rate is nearly optimal when each distribution is observed via a fixed-size dataset of size $K/p$. Our result is based on a new stability-based analysis for the generalization error. In particular, we show that $\\Delta$-uniform argument stability implies $\\tilde{O}(\\Delta + \\frac{1}{\\sqrt{n}})$ generalization error w.r.t. the worst-group risk, where $n$ is the number of samples drawn from each sample oracle. Next, we propose an algorithmic framework for worst-group population risk minimization using any DP online convex optimization algorithm as a subroutine. Hence, we give another excess risk bound of $\\tilde{O}\\left( \\sqrt{\\frac{d^{1/2}}{\\epsilon K}} +\\sqrt{\\frac{p}{K\\epsilon^2}} \\right)$. Assuming the typical setting of $\\epsilon=\\Theta(1)$, this bound is more favorable than our first bound in a certain range of $p$ as a function of $K$ and $d$. Finally, we study differentially private worst-group empirical risk minimization in the offline setting, where each group distribution is observed by a fixed-size dataset. We present a new algorithm with nearly optimal excess risk of $\\tilde{O}(\\frac{p\\sqrt{d}}{K\\epsilon})$.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.AI",
            "cs.CR"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19441": {
        "title": "3D Gaussian Model for Animation and Texturing",
        "authors": [
            "Xiangzhi Eric Wang",
            "Zackary P. T. Sin"
        ],
        "comments": " ",
        "subjects": "Graphics (cs.GR)",
        "abstract": "3D Gaussian Splatting has made a marked impact on neural rendering by achieving impressive fidelity and performance. Despite this achievement, however, it is not readily applicable to developing interactive applications. Real-time applications like XR apps and games require functions such as animation, UV-mapping, and model editing simultaneously manipulated through the usage of a 3D model. We propose a modeling that is analogous to typical 3D models, which we call 3D Gaussian Model (3DGM); it provides a manipulatable proxy for novel animation and texture transfer. By binding the 3D Gaussians in texture space and re-projecting them back to world space through implicit shell mapping, we show how our 3D modeling can serve as a valid rendering methodology for interactive applications. It is further noted that recently, 3D mesh reconstruction works have been able to produce high-quality mesh for rendering. Our work, on the other hand, only requires an approximated geometry for rendering an object in high fidelity. Applicationwise, we will show that our proxy-based 3DGM is capable of driving novel animation without animated training data and texture transferring via UV mapping of the 3D Gaussians. We believe the result indicates the potential of our work for enabling interactive applications for 3D Gaussian Splatting.\n    ",
        "primary_category": "cs.GR",
        "categories": [],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19442": {
        "title": "Training Dynamics of Multi-Head Softmax Attention for In-Context Learning: Emergence, Convergence, and Optimality",
        "authors": [
            "Siyu Chen",
            "Heejune Sheen",
            "Tianhao Wang",
            "Zhuoran Yang"
        ],
        "comments": "141 pages, 7 figures",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "We study the dynamics of gradient flow for training a multi-head softmax attention model for in-context learning of multi-task linear regression. We establish the global convergence of gradient flow under suitable choices of initialization. In addition, we prove that an interesting \"task allocation\" phenomenon emerges during the gradient flow dynamics, where each attention head focuses on solving a single task of the multi-task model. Specifically, we prove that the gradient flow dynamics can be split into three phases -- a warm-up phase where the loss decreases rather slowly and the attention heads gradually build up their inclination towards individual tasks, an emergence phase where each head selects a single task and the loss rapidly decreases, and a convergence phase where the attention parameters converge to a limit. Furthermore, we prove the optimality of gradient flow in the sense that the limiting model learned by gradient flow is on par with the best possible multi-head softmax attention model up to a constant factor. Our analysis also delineates a strict separation in terms of the prediction accuracy of ICL between single-head and multi-head attention models. The key technique for our convergence analysis is to map the gradient flow dynamics in the parameter space to a set of ordinary differential equations in the spectral domain, where the relative magnitudes of the semi-singular values of the attention weights determines task allocation. To our best knowledge, our work provides the first convergence result for the multi-head softmax attention model.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.AI",
            "math.OC",
            "math.ST",
            "stat.ML"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19443": {
        "title": "Probing the Information Encoded in Neural-based Acoustic Models of Automatic Speech Recognition Systems",
        "authors": [
            "Quentin Raymondaud",
            "Mickael Rouvier",
            "Richard Dufour"
        ],
        "comments": " ",
        "subjects": "Sound (cs.SD)",
        "abstract": "Deep learning architectures have made significant progress in terms of performance in many research areas. The automatic speech recognition (ASR) field has thus benefited from these scientific and technological advances, particularly for acoustic modeling, now integrating deep neural network architectures. However, these performance gains have translated into increased complexity regarding the information learned and conveyed through these black-box architectures. Following many researches in neural networks interpretability, we propose in this article a protocol that aims to determine which and where information is located in an ASR acoustic model (AM). To do so, we propose to evaluate AM performance on a determined set of tasks using intermediate representations (here, at different layer levels). Regarding the performance variation and targeted tasks, we can emit hypothesis about which information is enhanced or perturbed at different architecture steps. Experiments are performed on both speaker verification, acoustic environment classification, gender classification, tempo-distortion detection systems and speech sentiment/emotion identification. Analysis showed that neural-based AMs hold heterogeneous information that seems surprisingly uncorrelated with phoneme recognition, such as emotion, sentiment or speaker identity. The low-level hidden layers globally appears useful for the structuring of information while the upper ones would tend to delete useless information for phoneme recognition.\n    ",
        "primary_category": "cs.SD",
        "categories": [
            "cs.AI",
            "eess.AS"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19446": {
        "title": "ArCHer: Training Language Model Agents via Hierarchical Multi-Turn RL",
        "authors": [
            "Yifei Zhou",
            "Andrea Zanette",
            "Jiayi Pan",
            "Sergey Levine",
            "Aviral Kumar"
        ],
        "comments": " ",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "A broad use case of large language models (LLMs) is in goal-directed decision-making tasks (or \"agent\" tasks), where an LLM needs to not just generate completions for a given prompt, but rather make intelligent decisions over a multi-turn interaction to accomplish a task (e.g., when interacting with the web, using tools, or providing customer support). Reinforcement learning (RL) provides a general paradigm to address such agent tasks, but current RL methods for LLMs largely focus on optimizing single-turn rewards. By construction, most single-turn RL methods cannot endow LLMs with the ability to intelligently seek information over multiple turns, perform credit assignment, or reason about their past actions -- all of which are critical in agent tasks. This raises the question: how can we design effective and efficient multi-turn RL algorithms for LLMs? In this paper, we develop a framework for building multi-turn RL algorithms for fine-tuning LLMs, that preserves the flexibility of existing single-turn RL methods for LLMs (e.g., proximal policy optimization), while accommodating multiple turns, long horizons, and delayed rewards effectively. To do this, our framework adopts a hierarchical RL approach and runs two RL algorithms in parallel: a high-level off-policy value-based RL algorithm to aggregate reward over utterances, and a low-level RL algorithm that utilizes this high-level value function to train a token policy within each utterance or turn. Our hierarchical framework, Actor-Critic Framework with a Hierarchical Structure (ArCHer), can also give rise to other RL methods. Empirically, we find that ArCHer significantly improves efficiency and performance on agent tasks, attaining a sample efficiency of about 100x over existing methods, while also improving with larger model capacity (upto the 7 billion scale that we tested on).\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.AI",
            "cs.CL"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19449": {
        "title": "Heavy-Tailed Class Imbalance and Why Adam Outperforms Gradient Descent on Language Models",
        "authors": [
            "Frederik Kunstner",
            "Robin Yadav",
            "Alan Milligan",
            "Mark Schmidt",
            "Alberto Bietti"
        ],
        "comments": " ",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Adam has been shown to outperform gradient descent in optimizing large language transformers empirically, and by a larger margin than on other tasks, but it is unclear why this happens. We show that the heavy-tailed class imbalance found in language modeling tasks leads to difficulties in the optimization dynamics. When training with gradient descent, the loss associated with infrequent words decreases slower than the loss associated with frequent ones. As most samples come from relatively infrequent words, the average loss decreases slowly with gradient descent. On the other hand, Adam and sign-based methods do not suffer from this problem and improve predictions on all classes. To establish that this behavior is indeed caused by class imbalance, we show empirically that it persist through different architectures and data types, on language transformers, vision CNNs, and linear models. We further study this phenomenon on a linear classification with cross-entropy loss, showing that heavy-tailed class imbalance leads to ill-conditioning, and that the normalization used by Adam can counteract it.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.CL",
            "math.OC",
            "stat.ML"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19450": {
        "title": "Functional Benchmarks for Robust Evaluation of Reasoning Performance, and the Reasoning Gap",
        "authors": [
            "Saurabh Srivastava",
            "Annarose M B",
            "Anto P V",
            "Shashank Menon",
            "Ajay Sukumar",
            "Adwaith Samod T",
            "Alan Philipose",
            "Stevin Prince",
            "Sooraj Thomas"
        ],
        "comments": "37 pages, 10 figures",
        "subjects": "Artificial Intelligence (cs.AI)",
        "abstract": "We propose a framework for robust evaluation of reasoning capabilities of language models, using functional variants of benchmarks. Models that solve a reasoning test should exhibit no difference in performance over the static version of a problem compared to a snapshot of the functional variant. We have rewritten the relevant fragment of the MATH benchmark into its functional variant MATH(), with functionalization of other benchmarks to follow. When evaluating current state-of-the-art models over snapshots of MATH(), we find a reasoning gap -- the percentage difference between the static and functional accuracies. We find reasoning gaps from 58.35% to 80.31% among the state-of-the-art closed and open weights models that perform well on static benchmarks, with the caveat that the gaps are likely to be smaller with more sophisticated prompting strategies. Here we show that models which anecdotally have good reasoning performance over real-world tasks, have quantifiable lower gaps, motivating the open problem of building \"gap 0\" models. Code for evaluation and new evaluation datasets, three MATH() snapshots, are publicly available at this https URL.\n    ",
        "primary_category": "cs.AI",
        "categories": [
            "cs.CL"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19455": {
        "title": "Listening to the Noise: Blind Denoising with Gibbs Diffusion",
        "authors": [
            "David Heurtel-Depeiges",
            "Charles C. Margossian",
            "Ruben Ohana",
            "Bruno R\u00e9galdo-Saint Blancard"
        ],
        "comments": "12+8 pages, 7+3 figures, 1+1 tables, code: this https URL",
        "subjects": "Machine Learning (stat.ML)",
        "abstract": "In recent years, denoising problems have become intertwined with the development of deep generative models. In particular, diffusion models are trained like denoisers, and the distribution they model coincide with denoising priors in the Bayesian picture. However, denoising through diffusion-based posterior sampling requires the noise level and covariance to be known, preventing blind denoising. We overcome this limitation by introducing Gibbs Diffusion (GDiff), a general methodology addressing posterior sampling of both the signal and the noise parameters. Assuming arbitrary parametric Gaussian noise, we develop a Gibbs algorithm that alternates sampling steps from a conditional diffusion model trained to map the signal prior to the family of noise distributions, and a Monte Carlo sampler to infer the noise parameters. Our theoretical analysis highlights potential pitfalls, guides diagnostic usage, and quantifies errors in the Gibbs stationary distribution caused by the diffusion model. We showcase our method for 1) blind denoising of natural images involving colored noises with unknown amplitude and spectral index, and 2) a cosmology problem, namely the analysis of cosmic microwave background data, where Bayesian inference of \"noise\" parameters means constraining models of the evolution of the Universe.\n    ",
        "primary_category": "stat.ML",
        "categories": [
            "astro-ph.CO",
            "cs.CV",
            "cs.LG",
            "eess.SP"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19456": {
        "title": "Statistical Estimation in the Spiked Tensor Model via the Quantum Approximate Optimization Algorithm",
        "authors": [
            "Leo Zhou",
            "Joao Basso",
            "Song Mei"
        ],
        "comments": "51 pages, 4 figures, 1 table",
        "subjects": "Quantum Physics (quant-ph)",
        "abstract": "The quantum approximate optimization algorithm (QAOA) is a general-purpose algorithm for combinatorial optimization. In this paper, we analyze the performance of the QAOA on a statistical estimation problem, namely, the spiked tensor model, which exhibits a statistical-computational gap classically. We prove that the weak recovery threshold of $1$-step QAOA matches that of $1$-step tensor power iteration. Additional heuristic calculations suggest that the weak recovery threshold of $p$-step QAOA matches that of $p$-step tensor power iteration when $p$ is a fixed constant. This further implies that multi-step QAOA with tensor unfolding could achieve, but not surpass, the classical computation threshold $\\Theta(n^{(q-2)/4})$ for spiked $q$-tensors.\nMeanwhile, we characterize the asymptotic overlap distribution for $p$-step QAOA, finding an intriguing sine-Gaussian law verified through simulations. For some $p$ and $q$, the QAOA attains an overlap that is larger by a constant factor than the tensor power iteration overlap. Of independent interest, our proof techniques employ the Fourier transform to handle difficult combinatorial sums, a novel approach differing from prior QAOA analyses on spin-glass models without planted structure.\n    ",
        "primary_category": "quant-ph",
        "categories": [
            "cs.DS",
            "math.PR",
            "math.ST",
            "stat.ML"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19457": {
        "title": "$\\texttt{COSMIC}$: Mutual Information for Task-Agnostic Summarization Evaluation",
        "authors": [
            "Maxime Darrin",
            "Philippe Formont",
            "Jackie Chi Kit Cheung",
            "Pablo Piantanida"
        ],
        "comments": " ",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "Assessing the quality of summarizers poses significant challenges. In response, we propose a novel task-oriented evaluation approach that assesses summarizers based on their capacity to produce summaries that are useful for downstream tasks, while preserving task outcomes. We theoretically establish a direct relationship between the resulting error probability of these tasks and the mutual information between source texts and generated summaries. We introduce $\\texttt{COSMIC}$ as a practical implementation of this metric, demonstrating its strong correlation with human judgment-based metrics and its effectiveness in predicting downstream task performance. Comparative analyses against established metrics like $\\texttt{BERTScore}$ and $\\texttt{ROUGE}$ highlight the competitive performance of $\\texttt{COSMIC}$.\n    ",
        "primary_category": "cs.CL",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19460": {
        "title": "Benchmarking Uncertainty Disentanglement: Specialized Uncertainties for Specialized Tasks",
        "authors": [
            "B\u00e1lint Mucs\u00e1nyi",
            "Michael Kirchhof",
            "Seong Joon Oh"
        ],
        "comments": "43 pages",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Uncertainty quantification, once a singular task, has evolved into a spectrum of tasks, including abstained prediction, out-of-distribution detection, and aleatoric uncertainty quantification. The latest goal is disentanglement: the construction of multiple estimators that are each tailored to one and only one task. Hence, there is a plethora of recent advances with different intentions - that often entirely deviate from practical behavior. This paper conducts a comprehensive evaluation of numerous uncertainty estimators across diverse tasks on ImageNet. We find that, despite promising theoretical endeavors, disentanglement is not yet achieved in practice. Additionally, we reveal which uncertainty estimators excel at which specific tasks, providing insights for practitioners and guiding future research toward task-centric and disentangled uncertainty estimation methods. Our code is available at this https URL.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "stat.ML"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19462": {
        "title": "Accelerating materials discovery for polymer solar cells: Data-driven insights enabled by natural language processing",
        "authors": [
            "Pranav Shetty",
            "Aishat Adeboye",
            "Sonakshi Gupta",
            "Chao Zhang",
            "Rampi Ramprasad"
        ],
        "comments": " ",
        "subjects": "Materials Science (cond-mat.mtrl-sci)",
        "abstract": "We present a natural language processing pipeline that was used to extract polymer solar cell property data from the literature and simulate various active learning strategies. While data-driven methods have been well established to discover novel materials faster than Edisonian trial-and-error approaches, their benefits have not been quantified. Our approach demonstrates a potential reduction in discovery time by approximately 75 %, equivalent to a 15 year acceleration in material innovation. Our pipeline enables us to extract data from more than 3300 papers which is ~5 times larger than similar data sets reported by others. We also trained machine learning models to predict the power conversion efficiency and used our model to identify promising donor-acceptor combinations that are as yet unreported. We thus demonstrate a workflow that goes from published literature to extracted material property data which in turn is used to obtain data-driven insights. Our insights include active learning strategies that can simultaneously optimize the material system and train strong predictive models of material properties. This work provides a valuable framework for research in material science.\n    ",
        "primary_category": "cond-mat.mtrl-sci",
        "categories": [
            "cs.CL",
            "physics.app-ph"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19464": {
        "title": "Curiosity-driven Red-teaming for Large Language Models",
        "authors": [
            "Zhang-Wei Hong",
            "Idan Shenfeld",
            "Tsun-Hsuan Wang",
            "Yung-Sung Chuang",
            "Aldo Pareja",
            "James Glass",
            "Akash Srivastava",
            "Pulkit Agrawal"
        ],
        "comments": "Published at ICLR 2024",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Large language models (LLMs) hold great potential for many natural language applications but risk generating incorrect or toxic content. To probe when an LLM generates unwanted content, the current paradigm is to recruit a \\textit{red team} of human testers to design input prompts (i.e., test cases) that elicit undesirable responses from LLMs. However, relying solely on human testers is expensive and time-consuming. Recent works automate red teaming by training a separate red team LLM with reinforcement learning (RL) to generate test cases that maximize the chance of eliciting undesirable responses from the target LLM. However, current RL methods are only able to generate a small number of effective test cases resulting in a low coverage of the span of prompts that elicit undesirable responses from the target LLM. To overcome this limitation, we draw a connection between the problem of increasing the coverage of generated test cases and the well-studied approach of curiosity-driven exploration that optimizes for novelty. Our method of curiosity-driven red teaming (CRT) achieves greater coverage of test cases while mantaining or increasing their effectiveness compared to existing methods. Our method, CRT successfully provokes toxic responses from LLaMA2 model that has been heavily fine-tuned using human preferences to avoid toxic outputs. Code is available at \\url{this https URL}\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.AI",
            "cs.CL"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19465": {
        "title": "Towards Tracing Trustworthiness Dynamics: Revisiting Pre-training Period of Large Language Models",
        "authors": [
            "Chen Qian",
            "Jie Zhang",
            "Wei Yao",
            "Dongrui Liu",
            "Zhenfei Yin",
            "Yu Qiao",
            "Yong Liu",
            "Jing Shao"
        ],
        "comments": " ",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "Ensuring the trustworthiness of large language models (LLMs) is crucial. Most studies concentrate on fully pre-trained LLMs to better understand and improve LLMs' trustworthiness. In this paper, to reveal the untapped potential of pre-training, we pioneer the exploration of LLMs' trustworthiness during this period, focusing on five key dimensions: reliability, privacy, toxicity, fairness, and robustness. To begin with, we apply linear probing to LLMs. The high probing accuracy suggests that \\textit{LLMs in early pre-training can already distinguish concepts in each trustworthiness dimension}. Therefore, to further uncover the hidden possibilities of pre-training, we extract steering vectors from a LLM's pre-training checkpoints to enhance the LLM's trustworthiness. Finally, inspired by~\\citet{choi2023understanding} that mutual information estimation is bounded by linear probing accuracy, we also probe LLMs with mutual information to investigate the dynamics of trustworthiness during pre-training. We are the first to observe a similar two-phase phenomenon: fitting and compression~\\citep{shwartz2017opening}. This research provides an initial exploration of trustworthiness modeling during LLM pre-training, seeking to unveil new insights and spur further developments in the field. We will make our code publicly accessible at \\url{this https URL}.\n    ",
        "primary_category": "cs.CL",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19469": {
        "title": "Humanoid Locomotion as Next Token Prediction",
        "authors": [
            "Ilija Radosavovic",
            "Bike Zhang",
            "Baifeng Shi",
            "Jathushan Rajasegaran",
            "Sarthak Kamat",
            "Trevor Darrell",
            "Koushil Sreenath",
            "Jitendra Malik"
        ],
        "comments": " ",
        "subjects": "Robotics (cs.RO)",
        "abstract": "We cast real-world humanoid control as a next token prediction problem, akin to predicting the next word in language. Our model is a causal transformer trained via autoregressive prediction of sensorimotor trajectories. To account for the multi-modal nature of the data, we perform prediction in a modality-aligned way, and for each input token predict the next token from the same modality. This general formulation enables us to leverage data with missing modalities, like video trajectories without actions. We train our model on a collection of simulated trajectories coming from prior neural network policies, model-based controllers, motion capture data, and YouTube videos of humans. We show that our model enables a full-sized humanoid to walk in San Francisco zero-shot. Our model can transfer to the real world even when trained on only 27 hours of walking data, and can generalize to commands not seen during training like walking backward. These findings suggest a promising path toward learning challenging real-world control tasks by generative modeling of sensorimotor trajectories.\n    ",
        "primary_category": "cs.RO",
        "categories": [
            "cs.CV",
            "cs.LG"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19472": {
        "title": "Lifelong Benchmarks: Efficient Model Evaluation in an Era of Rapid Progress",
        "authors": [
            "Ameya Prabhu",
            "Vishaal Udandarao",
            "Philip Torr",
            "Matthias Bethge",
            "Adel Bibi",
            "Samuel Albanie"
        ],
        "comments": " ",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Standardized benchmarks drive progress in machine learning. However, with repeated testing, the risk of overfitting grows as algorithms over-exploit benchmark idiosyncrasies. In our work, we seek to mitigate this challenge by compiling ever-expanding large-scale benchmarks called Lifelong Benchmarks. As exemplars of our approach, we create Lifelong-CIFAR10 and Lifelong-ImageNet, containing (for now) 1.69M and 1.98M test samples, respectively. While reducing overfitting, lifelong benchmarks introduce a key challenge: the high cost of evaluating a growing number of models across an ever-expanding sample set. To address this challenge, we also introduce an efficient evaluation framework: Sort \\& Search (S&S), which reuses previously evaluated models by leveraging dynamic programming algorithms to selectively rank and sub-select test samples, enabling cost-effective lifelong benchmarking. Extensive empirical evaluations across 31,000 models demonstrate that S&S achieves highly-efficient approximate accuracy measurement, reducing compute cost from 180 GPU days to 5 GPU hours (1000x reduction) on a single A100 GPU, with low approximation error. As such, lifelong benchmarks offer a robust, practical solution to the \"benchmark exhaustion\" problem.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.CV"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19475": {
        "title": "The Counterfeit Conundrum: Can Code Language Models Grasp the Nuances of Their Incorrect Generations?",
        "authors": [
            "Alex Gu",
            "Wen-Ding Li",
            "Naman Jain",
            "Theo X. Olausson",
            "Celine Lee",
            "Koushik Sen",
            "Armando Solar-Lezama"
        ],
        "comments": "54 pages, 25 figures",
        "subjects": "Software Engineering (cs.SE)",
        "abstract": "While language models are increasingly more proficient at code generation, they still frequently generate incorrect programs. Many of these programs are obviously wrong, but others are more subtle and pass weaker correctness checks such as being able to compile. In this work, we focus on these counterfeit samples: programs sampled from a language model that 1) have a high enough log-probability to be generated at a moderate temperature and 2) pass weak correctness checks. Overall, we discover that most models have a very shallow understanding of counterfeits through three clear failure modes. First, models mistakenly classify them as correct. Second, models are worse at reasoning about the execution behaviour of counterfeits and often predict their execution results as if they were correct. Third, when asking models to fix counterfeits, the likelihood of a model successfully repairing a counterfeit is often even lower than that of sampling a correct program from scratch. Counterfeits also have very unexpected properties: first, counterfeit programs for problems that are easier for a model to solve are not necessarily easier to detect and only slightly easier to execute and repair. Second, counterfeits from a given model are just as confusing to the model itself as they are to other models. Finally, both strong and weak models are able to generate counterfeit samples that equally challenge all models. In light of our findings, we recommend that care and caution be taken when relying on models to understand their own samples, especially when no external feedback is incorporated.\n    ",
        "primary_category": "cs.SE",
        "categories": [
            "cs.AI",
            "cs.LG"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19477": {
        "title": "Learning a Generalized Physical Face Model From Data",
        "authors": [
            "Lingchen Yang",
            "Gaspard Zoss",
            "Prashanth Chandran",
            "Markus Gross",
            "Barbara Solenthaler",
            "Eftychios Sifakis",
            "Derek Bradley"
        ],
        "comments": " ",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Physically-based simulation is a powerful approach for 3D facial animation as the resulting deformations are governed by physical constraints, allowing to easily resolve self-collisions, respond to external forces and perform realistic anatomy edits. Today's methods are data-driven, where the actuations for finite elements are inferred from captured skin geometry. Unfortunately, these approaches have not been widely adopted due to the complexity of initializing the material space and learning the deformation model for each character separately, which often requires a skilled artist followed by lengthy network training. In this work, we aim to make physics-based facial animation more accessible by proposing a generalized physical face model that we learn from a large 3D face dataset in a simulation-free manner. Once trained, our model can be quickly fit to any unseen identity and produce a ready-to-animate physical face model automatically. Fitting is as easy as providing a single 3D face scan, or even a single face image. After fitting, we offer intuitive animation controls, as well as the ability to retarget animations across characters. All the while, the resulting animations allow for physical effects like collision avoidance, gravity, paralysis, bone reshaping and more.\n    ",
        "primary_category": "cs.CV",
        "categories": [
            "cs.GR"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19479": {
        "title": "Panda-70M: Captioning 70M Videos with Multiple Cross-Modality Teachers",
        "authors": [
            "Tsai-Shien Chen",
            "Aliaksandr Siarohin",
            "Willi Menapace",
            "Ekaterina Deyneka",
            "Hsiang-wei Chao",
            "Byung Eun Jeon",
            "Yuwei Fang",
            "Hsin-Ying Lee",
            "Jian Ren",
            "Ming-Hsuan Yang",
            "Sergey Tulyakov"
        ],
        "comments": "CVPR 2024. Project Page: this https URL",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "The quality of the data and annotation upper-bounds the quality of a downstream model. While there exist large text corpora and image-text pairs, high-quality video-text data is much harder to collect. First of all, manual labeling is more time-consuming, as it requires an annotator to watch an entire video. Second, videos have a temporal dimension, consisting of several scenes stacked together, and showing multiple actions. Accordingly, to establish a video dataset with high-quality captions, we propose an automatic approach leveraging multimodal inputs, such as textual video description, subtitles, and individual video frames. Specifically, we curate 3.8M high-resolution videos from the publicly available HD-VILA-100M dataset. We then split them into semantically consistent video clips, and apply multiple cross-modality teacher models to obtain captions for each video. Next, we finetune a retrieval model on a small subset where the best caption of each video is manually selected and then employ the model in the whole dataset to select the best caption as the annotation. In this way, we get 70M videos paired with high-quality text captions. We dub the dataset as Panda-70M. We show the value of the proposed dataset on three downstream tasks: video captioning, video and text retrieval, and text-driven video generation. The models trained on the proposed data score substantially better on the majority of metrics across all the tasks.\n    ",
        "primary_category": "cs.CV",
        "categories": [],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2403.00008": {
        "title": "Mathematical models of drug delivery via a contact lens during wear",
        "authors": [
            "Daniel M. Anderson",
            "Rayanne A. Luke"
        ],
        "comments": "44 pages, 20 figures, 4 tables",
        "subjects": "Biological Physics (physics.bio-ph)",
        "abstract": "In this work we develop and investigate mathematical and computational models that describe drug delivery from a contact lens during wear. Our models are designed to predict the dynamics of drug release from the contact lens and subsequent transport into the adjacent pre-lens tear film and post-lens tear film as well as into the ocular tissue (e.g. cornea), into the eyelid, and out of these regions. These processes are modeled by one dimensional diffusion out of the lens coupled to compartment-type models for drug concentrations in the various accompanying regions. In addition to numerical solutions that are compared with experimental data on drug release in an in vitro eye model, we also identify a large diffusion limit model for which analytical solutions can be written down for all quantities of interest, such as cumulative release of the drug from the contact lens. We use our models to make assessments about possible mechanisms and drug transport pathways through the pre-lens and post-lens tear films and provide interpretation of experimental observations. We discuss successes and limitations of our models as well as their potential to guide further research to help understand the dynamics of ophthalmic drug delivery via drug-eluting contact lenses.\n    ",
        "primary_category": "physics.bio-ph",
        "categories": [
            "math.NA"
        ],
        "submitted_date": "7 Feb 2024",
        "last_revised_date": " "
    },
    "2403.00009": {
        "title": "Randomized Control in Performance Analysis and Empirical Asset Pricing",
        "authors": [
            "Cyril Bachelard",
            "Apostolos Chalkis",
            "Vissarion Fisikopoulos",
            "Elias Tsigaridas"
        ],
        "comments": "57 pages, 7 figures, 2 tables",
        "subjects": "Portfolio Management (q-fin.PM)",
        "abstract": "The present article explores the application of randomized control techniques in empirical asset pricing and performance evaluation. It introduces geometric random walks, a class of Markov chain Monte Carlo methods, to construct flexible control groups in the form of random portfolios adhering to investor constraints. The sampling-based methods enable an exploration of the relationship between academically studied factor premia and performance in a practical setting. In an empirical application, the study assesses the potential to capture premias associated with size, value, quality, and momentum within a strongly constrained setup, exemplified by the investor guidelines of the MSCI Diversified Multifactor index. Additionally, the article highlights issues with the more traditional use case of random portfolios for drawing inferences in performance evaluation, showcasing challenges related to the intricacies of high-dimensional geometry.\n    ",
        "primary_category": "q-fin.PM",
        "categories": [
            "cs.CG",
            "q-fin.CP"
        ],
        "submitted_date": "14 Feb 2024",
        "last_revised_date": " "
    },
    "2403.00011": {
        "title": "Introducing User Feedback-based Counterfactual Explanations (UFCE)",
        "authors": [
            "Muhammad Suffian",
            "Jose M. Alonso-Moral",
            "Alessandro Bogliolo"
        ],
        "comments": "preprint of paper submitted to IJCIS Springer",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Machine learning models are widely used in real-world applications. However, their complexity makes it often challenging to interpret the rationale behind their decisions. Counterfactual explanations (CEs) have emerged as a viable solution for generating comprehensible explanations in eXplainable Artificial Intelligence (XAI). CE provides actionable information to users on how to achieve the desired outcome with minimal modifications to the input. However, current CE algorithms usually operate within the entire feature space when optimizing changes to turn over an undesired outcome, overlooking the identification of key contributors to the outcome and disregarding the practicality of the suggested changes. In this study, we introduce a novel methodology, that is named as user feedback-based counterfactual explanation (UFCE), which addresses these limitations and aims to bolster confidence in the provided explanations. UFCE allows for the inclusion of user constraints to determine the smallest modifications in the subset of actionable features while considering feature dependence, and evaluates the practicality of suggested changes using benchmark evaluation metrics. We conducted three experiments with five datasets, demonstrating that UFCE outperforms two well-known CE methods in terms of \\textit{proximity}, \\textit{sparsity}, and \\textit{feasibility}. Reported results indicate that user constraints influence the generation of feasible CEs.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.AI",
            "cs.HC"
        ],
        "submitted_date": "26 Feb 2024",
        "last_revised_date": " "
    },
    "2403.00013": {
        "title": "Prioritizing Informative Features and Examples for Deep Learning from Noisy Data",
        "authors": [
            "Dongmin Park"
        ],
        "comments": "PhD thesis",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "In this dissertation, we propose a systemic framework that prioritizes informative features and examples to enhance each stage of the development process. Specifically, we prioritize informative features and examples and improve the performance of feature learning, data labeling, and data selection. We first propose an approach to extract only informative features that are inherent to solving a target task by using auxiliary out-of-distribution data. We deactivate the noise features in the target distribution by using that in the out-of-distribution data. Next, we introduce an approach that prioritizes informative examples from unlabeled noisy data in order to reduce the labeling cost of active learning. In order to solve the purity-information dilemma, where an attempt to select informative examples induces the selection of many noisy examples, we propose a meta-model that finds the best balance between purity and informativeness. Lastly, we suggest an approach that prioritizes informative examples from labeled noisy data to preserve the performance of data selection. For labeled image noise data, we propose a data selection method that considers the confidence of neighboring samples to maintain the performance of the state-of-the-art Re-labeling models. For labeled text noise data, we present an instruction selection method that takes diversity into account for ranking the quality of instructions with prompting, thereby enhancing the performance of aligned large language models.\nOverall, our unified framework induces the deep learning development process robust to noisy data, thereby effectively mitigating noisy features and examples in real-world applications.\n    ",
        "primary_category": "cs.LG",
        "categories": [],
        "submitted_date": "27 Feb 2024",
        "last_revised_date": " "
    },
    "2403.00014": {
        "title": "GIN-SD: Source Detection in Graphs with Incomplete Nodes via Positional Encoding and Attentive Fusion",
        "authors": [
            "Le Cheng",
            "Peican Zhu",
            "Keke Tang",
            "Chao Gao",
            "Zhen Wang"
        ],
        "comments": "The paper is accepted by AAAI24",
        "subjects": "Social and Information Networks (cs.SI)",
        "abstract": "Source detection in graphs has demonstrated robust efficacy in the domain of rumor source identification. Although recent solutions have enhanced performance by leveraging deep neural networks, they often require complete user data. In this paper, we address a more challenging task, rumor source detection with incomplete user data, and propose a novel framework, i.e., Source Detection in Graphs with Incomplete Nodes via Positional Encoding and Attentive Fusion (GIN-SD), to tackle this challenge. Specifically, our approach utilizes a positional embedding module to distinguish nodes that are incomplete and employs a self-attention mechanism to focus on nodes with greater information transmission capacity. To mitigate the prediction bias caused by the significant disparity between the numbers of source and non-source nodes, we also introduce a class-balancing mechanism. Extensive experiments validate the effectiveness of GIN-SD and its superiority to state-of-the-art methods.\n    ",
        "primary_category": "cs.SI",
        "categories": [
            "cs.AI",
            "cs.LG"
        ],
        "submitted_date": "27 Feb 2024",
        "last_revised_date": " "
    },
    "2403.00016": {
        "title": "Deep Sensitivity Analysis for Objective-Oriented Combinatorial Optimization",
        "authors": [
            "Ganga Gireesan",
            "Nisha Pillai",
            "Michael J Rothrock",
            "Bindu Nanduri",
            "Zhiqian Chen",
            "Mahalingam Ramkumar"
        ],
        "comments": "The 2023 International Conference on Computational Science & Computational Intelligence (CSCI'23)",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Pathogen control is a critical aspect of modern poultry farming, providing important benefits for both public health and productivity. Effective poultry management measures to reduce pathogen levels in poultry flocks promote food safety by lowering risks of food-borne illnesses. They also support animal health and welfare by preventing infectious diseases that can rapidly spread and impact flock growth, egg production, and overall health. This study frames the search for optimal management practices that minimize the presence of multiple pathogens as a combinatorial optimization problem. Specifically, we model the various possible combinations of management settings as a solution space that can be efficiently explored to identify configurations that optimally reduce pathogen levels. This design incorporates a neural network feedback-based method that combines feature explanations with global sensitivity analysis to ensure combinatorial optimization in multiobjective settings. Our preliminary experiments have promising results when applied to two real-world agricultural datasets. While further validation is still needed, these early experimental findings demonstrate the potential of the model to derive targeted feature interactions that adaptively optimize pathogen control under varying real-world constraints.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "28 Feb 2024",
        "last_revised_date": " "
    },
    "2403.00017": {
        "title": "Towards Interpreting Multi-Objective Feature Associations",
        "authors": [
            "Nisha Pillai",
            "Ganga Gireesan",
            "Michael J. Rothrock Jr.",
            "Bindu Nanduri",
            "Zhiqian Chen",
            "Mahalingam Ramkumar"
        ],
        "comments": "The 18th Annual IEEE International Systems Conference 2024 (IEEE SYSCON 2024)",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Understanding how multiple features are associated and contribute to a specific objective is as important as understanding how each feature contributes to a particular outcome. Interpretability of a single feature in a prediction may be handled in multiple ways; however, in a multi-objective prediction, it is difficult to obtain interpretability of a combination of feature values. To address this issue, we propose an objective specific feature interaction design using multi-labels to find the optimal combination of features in agricultural settings. One of the novel aspects of this design is the identification of a method that integrates feature explanations with global sensitivity analysis in order to ensure combinatorial optimization in multi-objective settings. We have demonstrated in our preliminary experiments that an approximate combination of feature values can be found to achieve the desired outcome using two agricultural datasets: one with pre-harvest poultry farm practices for multi-drug resistance presence, and one with post-harvest poultry farm practices for food-borne pathogens. In our combinatorial optimization approach, all three pathogens are taken into consideration simultaneously to account for the interaction between conditions that favor different types of pathogen growth. These results indicate that explanation-based approaches are capable of identifying combinations of features that reduce pathogen presence in fewer iterations than a baseline.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "28 Feb 2024",
        "last_revised_date": " "
    },
    "2403.00018": {
        "title": "Crypto Technology -- Impact on Global Economy",
        "authors": [
            "Arunkumar Velayudhan Pillai"
        ],
        "comments": " ",
        "subjects": "Cryptography and Security (cs.CR)",
        "abstract": "The last decade has been marked by the evolution of cryptocurrencies, which have captured the interest of the public through the offered opportunities and the feeling of freedom, resulting from decentralization and lack of authority to oversee how cryptocurrency transactions are conducted. The innovation in crypto space is often compared to the impact internet had on human life. There is a new term called Web 3.0 for denoting all new computing innovations arising due to the blockchain technologies. Blockchain has emerged as one of the most important inventions of the last decade with crypto currencies or financial use case as one of the domains which progressed most in the last 10 years. It is very important to research about Web 3 technologies, how it is connected to crypto economy and what to expect in this field for the next several decades.\n    ",
        "primary_category": "cs.CR",
        "categories": [
            "cs.CY"
        ],
        "submitted_date": "28 Feb 2024",
        "last_revised_date": " "
    },
    "2403.00019": {
        "title": "Transformer-based Parameter Estimation in Statistics",
        "authors": [
            "Xiaoxin Yin",
            "David S. Yin"
        ],
        "comments": " ",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Parameter estimation is one of the most important tasks in statistics, and is key to helping people understand the distribution behind a sample of observations. Traditionally parameter estimation is done either by closed-form solutions (e.g., maximum likelihood estimation for Gaussian distribution), or by iterative numerical methods such as Newton-Raphson method when closed-form solution does not exist (e.g., for Beta distribution).\nIn this paper we propose a transformer-based approach to parameter estimation. Compared with existing solutions, our approach does not require a closed-form solution or any mathematical derivations. It does not even require knowing the probability density function, which is needed by numerical methods. After the transformer model is trained, only a single inference is needed to estimate the parameters of the underlying distribution based on a sample of observations. In the empirical study we compared our approach with maximum likelihood estimation on commonly used distributions such as normal distribution, exponential distribution and beta distribution. It is shown that our approach achieves similar or better accuracy as measured by mean-square-errors.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "stat.ML"
        ],
        "submitted_date": "28 Feb 2024",
        "last_revised_date": " "
    },
    "2403.00023": {
        "title": "Auditable Homomorphic-based Decentralized Collaborative AI with Attribute-based Differential Privacy",
        "authors": [
            "Lo-Yao Yeh",
            "Sheng-Po Tseng",
            "Chia-Hsun Lu",
            "Chih-Ya Shen"
        ],
        "comments": "12 pages, 9 figures",
        "subjects": "Cryptography and Security (cs.CR)",
        "abstract": "In recent years, the notion of federated learning (FL) has led to the new paradigm of distributed artificial intelligence (AI) with privacy preservation. However, most current FL systems suffer from data privacy issues due to the requirement of a trusted third party. Although some previous works introduce differential privacy to protect the data, however, it may also significantly deteriorate the model performance. To address these issues, we propose a novel decentralized collaborative AI framework, named Auditable Homomorphic-based Decentralised Collaborative AI (AerisAI), to improve security with homomorphic encryption and fine-grained differential privacy. Our proposed AerisAI directly aggregates the encrypted parameters with a blockchain-based smart contract to get rid of the need of a trusted third party. We also propose a brand-new concept for eliminating the negative impacts of differential privacy for model performance. Moreover, the proposed AerisAI also provides the broadcast-aware group key management based on ciphertext-policy attribute-based encryption (CPABE) to achieve fine-grained access control based on different service-level agreements. We provide a formal theoretical analysis of the proposed AerisAI as well as the functionality comparison with the other baselines. We also conduct extensive experiments on real datasets to evaluate the proposed approach. The experimental results indicate that our proposed AerisAI significantly outperforms the other state-of-the-art baselines.\n    ",
        "primary_category": "cs.CR",
        "categories": [
            "cs.AI",
            "cs.LG"
        ],
        "submitted_date": "28 Feb 2024",
        "last_revised_date": " "
    },
    "2403.00025": {
        "title": "On the Challenges and Opportunities in Generative AI",
        "authors": [
            "Laura Manduchi",
            "Kushagra Pandey",
            "Robert Bamler",
            "Ryan Cotterell",
            "Sina D\u00e4ubener",
            "Sophie Fellenz",
            "Asja Fischer",
            "Thomas G\u00e4rtner",
            "Matthias Kirchler",
            "Marius Kloft",
            "Yingzhen Li",
            "Christoph Lippert",
            "Gerard de Melo",
            "Eric Nalisnick",
            "Bj\u00f6rn Ommer",
            "Rajesh Ranganath",
            "Maja Rudolph",
            "Karen Ullrich",
            "Guy Van den Broeck",
            "Julia E Vogt",
            "Yixin Wang",
            "Florian Wenzel",
            "Frank Wood",
            "Stephan Mandt",
            "Vincent Fortuin"
        ],
        "comments": " ",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "The field of deep generative modeling has grown rapidly and consistently over the years. With the availability of massive amounts of training data coupled with advances in scalable unsupervised learning paradigms, recent large-scale generative models show tremendous promise in synthesizing high-resolution images and text, as well as structured data such as videos and molecules. However, we argue that current large-scale generative AI models do not sufficiently address several fundamental issues that hinder their widespread adoption across domains. In this work, we aim to identify key unresolved challenges in modern generative AI paradigms that should be tackled to further enhance their capabilities, versatility, and reliability. By identifying these challenges, we aim to provide researchers with valuable insights for exploring fruitful research directions, thereby fostering the development of more robust and accessible generative AI solutions.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "28 Feb 2024",
        "last_revised_date": " "
    },
    "2403.00026": {
        "title": "Learning to Deliver: a Foundation Model for the Montreal Capacitated Vehicle Routing Problem",
        "authors": [
            "Samuel J. K. Chin",
            "Matthias Winkenbach",
            "Akash Srivastava"
        ],
        "comments": " ",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "In this paper, we present the Foundation Model for the Montreal Capacitated Vehicle Routing Problem (FM-MCVRP), a novel Deep Learning (DL) model that approximates high-quality solutions to a variant of the Capacitated Vehicle Routing Problem (CVRP) that characterizes many real-world applications. The so-called Montreal Capacitated Vehicle Routing Problem (MCVRP), first formally described by Bengio et al. (2021), is defined on a fixed and finite graph, which is analogous to a city. Each MCVRP instance is essentially the sub-graph connecting a randomly sampled subset of the nodes in the fixed graph, which represent a set of potential addresses in a real-world delivery problem on a given day. Our work exploits this problem structure to frame the MCVRP as an analogous Natural Language Processing (NLP) task. Specifically, we leverage a Transformer architecture embedded in a Large Language Model (LLM) framework to train our model in a supervised manner on computationally inexpensive, sub-optimal MCVRP solutions obtained algorithmically. Through comprehensive computational experiments, we show that FM-MCVRP produces better MCVRP solutions than the training data and generalizes to larger sized problem instances not seen during training. Even when compared to near-optimal solutions from state-of-the-art heuristics, FM-MCVRP yields competitive results despite being trained on inferior data. For instance, for 400-customer problems, FM-MCVRP solutions on average fall within 2% of the benchmark. Our results further demonstrate that unlike prior works in the literature, FM-MCVRP is a unified model, which performs consistently and reliably on a range of problem instance sizes and parameter values such as the vehicle capacity.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.AI",
            "math.OC"
        ],
        "submitted_date": "28 Feb 2024",
        "last_revised_date": " "
    },
    "2403.00027": {
        "title": "A Quick Framework for Evaluating Worst Robustness of Complex Networks",
        "authors": [
            "Wenjun Jiang",
            "Peiyan Li",
            "Tianlong Fan",
            "Ting Li",
            "Chuan-fu Zhang",
            "Tao Zhang",
            "Zong-fu Luo"
        ],
        "comments": "30 pages, 8figures, 4tables,journal",
        "subjects": "Social and Information Networks (cs.SI)",
        "abstract": "Robustness is pivotal for comprehending, designing, optimizing, and rehabilitating networks, with simulation attacks being the prevailing evaluation method. Simulation attacks are often time-consuming or even impractical, however, a more crucial yet persistently overlooked drawback is that any attack strategy merely provides a potential paradigm of disintegration. The key concern is: in the worst-case scenario or facing the most severe attacks, what is the limit of robustness, referred to as ``Worst Robustness'', for a given system? Understanding a system's worst robustness is imperative for grasping its reliability limits, accurately evaluating protective capabilities, and determining associated design and security maintenance costs. To address these challenges, we introduce the concept of Most Destruction Attack (MDA) based on the idea of knowledge stacking. MDA is employed to assess the worst robustness of networks, followed by the application of an adapted CNN algorithm for rapid worst robustness prediction. We establish the logical validity of MDA and highlight the exceptional performance of the adapted CNN algorithm in predicting the worst robustness across diverse network topologies, encompassing both model and empirical networks.\n    ",
        "primary_category": "cs.SI",
        "categories": [
            "cs.LG",
            "cs.NI"
        ],
        "submitted_date": "28 Feb 2024",
        "last_revised_date": " "
    },
    "2403.00032": {
        "title": "Time to Cite: Modeling Citation Networks using the Dynamic Impact Single-Event Embedding Model",
        "authors": [
            "Nikolaos Nakis",
            "Abdulkadir Celikkanat",
            "Louis Boucherie",
            "Sune Lehmann",
            "Morten M\u00f8rup"
        ],
        "comments": "Accepted for AISTATS 2024",
        "subjects": "Social and Information Networks (cs.SI)",
        "abstract": "Understanding the structure and dynamics of scientific research, i.e., the science of science (SciSci), has become an important area of research in order to address imminent questions including how scholars interact to advance science, how disciplines are related and evolve, and how research impact can be quantified and predicted. Central to the study of SciSci has been the analysis of citation networks. Here, two prominent modeling methodologies have been employed: one is to assess the citation impact dynamics of papers using parametric distributions, and the other is to embed the citation networks in a latent space optimal for characterizing the static relations between papers in terms of their citations. Interestingly, citation networks are a prominent example of single-event dynamic networks, i.e., networks for which each dyad only has a single event (i.e., the point in time of citation). We presently propose a novel likelihood function for the characterization of such single-event networks. Using this likelihood, we propose the Dynamic Impact Single-Event Embedding model (DISEE). The \\textsc{\\modelabbrev} model characterizes the scientific interactions in terms of a latent distance model in which random effects account for citation heterogeneity while the time-varying impact is characterized using existing parametric representations for assessment of dynamic impact. We highlight the proposed approach on several real citation networks finding that the DISEE well reconciles static latent distance network embedding approaches with classical dynamic impact assessments.\n    ",
        "primary_category": "cs.SI",
        "categories": [
            "cs.AI",
            "cs.DL"
        ],
        "submitted_date": "28 Feb 2024",
        "last_revised_date": " "
    },
    "2403.00036": {
        "title": "Influencing Bandits: Arm Selection for Preference Shaping",
        "authors": [
            "Viraj Nadkarni",
            "D. Manjunath",
            "Sharayu Moharir"
        ],
        "comments": "14 pages, 8 figures, 24 references, proofs in appendix",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "We consider a non stationary multi-armed bandit in which the population preferences are positively and negatively reinforced by the observed rewards. The objective of the algorithm is to shape the population preferences to maximize the fraction of the population favouring a predetermined arm. For the case of binary opinions, two types of opinion dynamics are considered -- decreasing elasticity (modeled as a Polya urn with increasing number of balls) and constant elasticity (using the voter model). For the first case, we describe an Explore-then-commit policy and a Thompson sampling policy and analyse the regret for each of these policies. We then show that these algorithms and their analyses carry over to the constant elasticity case. We also describe a Thompson sampling based algorithm for the case when more than two types of opinions are present. Finally, we discuss the case where presence of multiple recommendation systems gives rise to a trade-off between their popularity and opinion shaping objectives.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.AI",
            "cs.IR",
            "eess.SY"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2403.00037": {
        "title": "Evolving to the Future: Unseen Event Adaptive Fake News Detection on Social Media",
        "authors": [
            "Jiajun Zhang",
            "Zhixun Li",
            "Qiang Liu",
            "Shu Wu",
            "Liang Wang"
        ],
        "comments": " ",
        "subjects": "Social and Information Networks (cs.SI)",
        "abstract": "With the rapid development of social media, the wide dissemination of fake news on social media is increasingly threatening both individuals and society. In the dynamic landscape of social media, fake news detection aims to develop a model trained on news reporting past events. The objective is to predict and identify fake news about future events, which often relate to subjects entirely different from those in the past. However, existing fake detection methods exhibit a lack of robustness and cannot generalize to unseen events. To address this, we introduce Future ADaptive Event-based Fake news Detection (FADE) framework. Specifically, we train a target predictor through an adaptive augmentation strategy and graph contrastive learning to make more robust overall predictions. Simultaneously, we independently train an event-only predictor to obtain biased predictions. Then we further mitigate event bias by obtaining the final prediction by subtracting the output of the event-only predictor from the output of the target predictor. Encouraging results from experiments designed to emulate real-world social media conditions validate the effectiveness of our method in comparison to existing state-of-the-art approaches.\n    ",
        "primary_category": "cs.SI",
        "categories": [
            "cs.AI",
            "cs.CL"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2403.00039": {
        "title": "FhGenie: A Custom, Confidentiality-preserving Chat AI for Corporate and Scientific Use",
        "authors": [
            "Ingo Weber",
            "Hendrik Linka",
            "Daniel Mertens",
            "Tamara Muryshkin",
            "Heinrich Opgenoorth",
            "Stefan Langer"
        ],
        "comments": " ",
        "subjects": "Software Engineering (cs.SE)",
        "abstract": "Since OpenAI's release of ChatGPT, generative AI has received significant attention across various domains. These AI-based chat systems have the potential to enhance the productivity of knowledge workers in diverse tasks. However, the use of free public services poses a risk of data leakage, as service providers may exploit user input for additional training and optimization without clear boundaries. Even subscription-based alternatives sometimes lack transparency in handling user data. To address these concerns and enable Fraunhofer staff to leverage this technology while ensuring confidentiality, we have designed and developed a customized chat AI called FhGenie (genie being a reference to a helpful spirit). Within few days of its release, thousands of Fraunhofer employees started using this service. As pioneers in implementing such a system, many other organizations have followed suit. Our solution builds upon commercial large language models (LLMs), which we have carefully integrated into our system to meet our specific requirements and compliance constraints, including confidentiality and GDPR. In this paper, we share detailed insights into the architectural considerations, design, implementation, and subsequent updates of FhGenie. Additionally, we discuss challenges, observations, and the core lessons learned from its productive usage.\n    ",
        "primary_category": "cs.SE",
        "categories": [
            "cs.AI",
            "cs.HC"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2403.00043": {
        "title": "RiNALMo: General-Purpose RNA Language Models Can Generalize Well on Structure Prediction Tasks",
        "authors": [
            "Rafael Josip Peni\u0107",
            "Tin Vla\u0161i\u0107",
            "Roland G. Huber",
            "Yue Wan",
            "Mile \u0160iki\u0107"
        ],
        "comments": "18 pages, 7 figures",
        "subjects": "Biomolecules (q-bio.BM)",
        "abstract": "Ribonucleic acid (RNA) plays a variety of crucial roles in fundamental biological processes. Recently, RNA has become an interesting drug target, emphasizing the need to improve our understanding of its structures and functions. Over the years, sequencing technologies have produced an enormous amount of unlabeled RNA data, which hides important knowledge and potential. Motivated by the successes of protein language models, we introduce RiboNucleic Acid Language Model (RiNALMo) to help unveil the hidden code of RNA. RiNALMo is the largest RNA language model to date with $650$ million parameters pre-trained on $36$ million non-coding RNA sequences from several available databases. RiNALMo is able to extract hidden knowledge and capture the underlying structure information implicitly embedded within the RNA sequences. RiNALMo achieves state-of-the-art results on several downstream tasks. Notably, we show that its generalization capabilities can overcome the inability of other deep learning methods for secondary structure prediction to generalize on unseen RNA families. The code has been made publicly available on this https URL.\n    ",
        "primary_category": "q-bio.BM",
        "categories": [
            "cs.LG"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2403.00044": {
        "title": "Scaling up Dynamic Edge Partition Models via Stochastic Gradient MCMC",
        "authors": [
            "Sikun Yang",
            "Heinz Koeppl"
        ],
        "comments": " ",
        "subjects": "Social and Information Networks (cs.SI)",
        "abstract": "The edge partition model (EPM) is a generative model for extracting an overlapping community structure from static graph-structured data. In the EPM, the gamma process (GaP) prior is adopted to infer the appropriate number of latent communities, and each vertex is endowed with a gamma distributed positive memberships vector. Despite having many attractive properties, inference in the EPM is typically performed using Markov chain Monte Carlo (MCMC) methods that prevent it from being applied to massive network data. In this paper, we generalize the EPM to account for dynamic enviroment by representing each vertex with a positive memberships vector constructed using Dirichlet prior specification, and capturing the time-evolving behaviour of vertices via a Dirichlet Markov chain construction. A simple-to-implement Gibbs sampler is proposed to perform posterior computation using Negative- Binomial augmentation technique. For large network data, we propose a stochastic gradient Markov chain Monte Carlo (SG-MCMC) algorithm for scalable inference in the proposed model. The experimental results show that the novel methods achieve competitive performance in terms of link prediction, while being much faster.\n    ",
        "primary_category": "cs.SI",
        "categories": [
            "cs.AI",
            "cs.LG"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2403.00045": {
        "title": "An All-Optical General-Purpose CPU and Optical Computer Architecture",
        "authors": [
            "Michael Kissner",
            "Leonardo Del Bino",
            "Felix P\u00e4sler",
            "Peter Caruana",
            "George Ghalanos"
        ],
        "comments": "14 pages, 10 figures",
        "subjects": "Emerging Technologies (cs.ET)",
        "abstract": "Energy efficiency of electronic digital processors is primarily limited by the energy consumption of electronic communication and interconnects. The industry is almost unanimously pushing towards replacing both long-haul, as well as local chip interconnects, using optics to drastically increase efficiency. In this paper, we explore what comes after the successful migration to optical interconnects, as with this inefficiency solved, the main source of energy consumption will be electronic digital computing, memory and electro-optical conversion. Our approach attempts to address all these issues by introducing efficient all-optical digital computing and memory, which in turn eliminates the need for electro-optical conversions. Here, we demonstrate for the first time a scheme to enable general purpose digital data processing in an integrated form and present our photonic integrated circuit (PIC) implementation. For this demonstration we implemented a URISC architecture capable of running any classical piece of software all-optically and present a comprehensive architectural framework for all-optical computing to go beyond.\n    ",
        "primary_category": "cs.ET",
        "categories": [
            "physics.optics"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2403.00049": {
        "title": "TEXterity -- Tactile Extrinsic deXterity: Simultaneous Tactile Estimation and Control for Extrinsic Dexterity",
        "authors": [
            "Sangwoon Kim",
            "Antonia Bronars",
            "Parag Patre",
            "Alberto Rodriguez"
        ],
        "comments": "project website: this https URL. arXiv admin note: substantial text overlap with arXiv:2401.10230",
        "subjects": "Robotics (cs.RO)",
        "abstract": "We introduce a novel approach that combines tactile estimation and control for in-hand object manipulation. By integrating measurements from robot kinematics and an image-based tactile sensor, our framework estimates and tracks object pose while simultaneously generating motion plans in a receding horizon fashion to control the pose of a grasped object. This approach consists of a discrete pose estimator that tracks the most likely sequence of object poses in a coarsely discretized grid, and a continuous pose estimator-controller to refine the pose estimate and accurately manipulate the pose of the grasped object. Our method is tested on diverse objects and configurations, achieving desired manipulation objectives and outperforming single-shot methods in estimation accuracy. The proposed approach holds potential for tasks requiring precise manipulation and limited intrinsic in-hand dexterity under visual occlusion, laying the foundation for closed-loop behavior in applications such as regrasping, insertion, and tool use. Please see this https URL for videos of real-world demonstrations.\n    ",
        "primary_category": "cs.RO",
        "categories": [],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2403.00067": {
        "title": "Query-OPT: Optimizing Inference of Large Language Models via Multi-Query Instructions in Meeting Summarization",
        "authors": [
            "Md Tahmid Rahman Laskar",
            "Elena Khasanova",
            "Xue-Yong Fu",
            "Cheng Chen",
            "Shashi Bhushan TN"
        ],
        "comments": " ",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "This work focuses on the task of query-based meeting summarization in which the summary of a context (meeting transcript) is generated in response to a specific query. When using Large Language Models (LLMs) for this task, a new call to the LLM inference endpoint/API is required for each new query even if the context stays the same. However, repeated calls to the LLM inference endpoints would significantly increase the costs of using them in production, making LLMs impractical for many real-world use cases. To address this problem, in this paper, we investigate whether combining the queries for the same input context in a single prompt to minimize repeated calls can be successfully used in meeting summarization. In this regard, we conduct extensive experiments by comparing the performance of various popular LLMs: GPT-4, PaLM-2, LLaMA-2, Mistral, and FLAN-T5 in single-query and multi-query settings. We observe that while most LLMs tend to respond to the multi-query instructions, almost all of them (except GPT-4), even after fine-tuning, could not properly generate the response in the required output format. We conclude that while multi-query prompting could be useful to optimize the inference costs by reducing calls to the inference endpoints/APIs for the task of meeting summarization, this capability to reliably generate the response in the expected format is only limited to certain LLMs.\n    ",
        "primary_category": "cs.CL",
        "categories": [],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2403.00068": {
        "title": "Artwork Explanation in Large-scale Vision Language Models",
        "authors": [
            "Kazuki Hayashi",
            "Yusuke Sakai",
            "Hidetaka Kamigaito",
            "Katsuhiko Hayashi",
            "Taro Watanabe"
        ],
        "comments": " ",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Large-scale vision-language models (LVLMs) output text from images and instructions, demonstrating advanced capabilities in text generation and comprehension. However, it has not been clarified to what extent LVLMs understand the knowledge necessary for explaining images, the complex relationships between various pieces of knowledge, and how they integrate these understandings into their explanations. To address this issue, we propose a new task: the artwork explanation generation task, along with its evaluation dataset and metric for quantitatively assessing the understanding and utilization of knowledge about artworks. This task is apt for image description based on the premise that LVLMs are expected to have pre-existing knowledge of artworks, which are often subjects of wide recognition and documented information. It consists of two parts: generating explanations from both images and titles of artworks, and generating explanations using only images, thus evaluating the LVLMs' language-based and vision-based knowledge. Alongside, we release a training dataset for LVLMs to learn explanations that incorporate knowledge about artworks. Our findings indicate that LVLMs not only struggle with integrating language and visual information but also exhibit a more pronounced limitation in acquiring knowledge from images alone. The datasets (ExpArt=Explain Artworks) are available at this https URL.\n    ",
        "primary_category": "cs.CV",
        "categories": [],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2403.00071": {
        "title": "Resonance RoPE: Improving Context Length Generalization of Large Language Models",
        "authors": [
            "Suyuchen Wang",
            "Ivan Kobyzev",
            "Peng Lu",
            "Mehdi Rezagholizadeh",
            "Bang Liu"
        ],
        "comments": " ",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "This paper addresses the challenge of train-short-test-long (TSTL) scenarios in Large Language Models (LLMs) equipped with Rotary Position Embedding (RoPE), where models pre-trained on shorter sequences face difficulty with out-of-distribution (OOD) token positions in longer sequences. We introduce Resonance RoPE, a novel approach designed to narrow the generalization gap in TSTL scenarios by refining the interpolation of RoPE features for OOD positions, significantly improving the model performance without additional online computational costs. Furthermore, we present PosGen, a new synthetic benchmark specifically designed for fine-grained behavior analysis in TSTL scenarios, aiming to isolate the constantly increasing difficulty of token generation on long contexts from the challenges of recognizing new token positions. Our experiments on synthetic tasks show that after applying Resonance RoPE, Transformers recognize OOD position better and more robustly. Our extensive LLM experiments also show superior performance after applying Resonance RoPE to the current state-of-the-art RoPE scaling method, YaRN, on both upstream language modeling tasks and a variety of downstream long-text applications.\n    ",
        "primary_category": "cs.CL",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2403.00075": {
        "title": "The Invariant Rauch-Tung-Striebel Smoother",
        "authors": [
            "Niels van der Laan",
            "Mitchell Cohen",
            "Jonathan Arsenault",
            "James Richard Forbes"
        ],
        "comments": "8 pages, 3 figures, published in Robotics and Automation Letters",
        "subjects": "Robotics (cs.RO)",
        "abstract": "This paper presents an invariant Rauch-Tung- Striebel (IRTS) smoother applicable to systems with states that are an element of a matrix Lie group. In particular, the extended Rauch-Tung-Striebel (RTS) smoother is adapted to work within a matrix Lie group framework. The main advantage of the invariant RTS (IRTS) smoother is that the linearization of the process and measurement models is independent of the state estimate resulting in state-estimate-independent Jacobians when certain technical requirements are met. A sample problem is considered that involves estimation of the three dimensional pose of a rigid body on SE(3), along with sensor biases. The multiplicative RTS (MRTS) smoother is also reviewed and is used as a direct comparison to the proposed IRTS smoother using experimental data. Both smoothing methods are also compared to invariant and multiplicative versions of the Gauss-Newton approach to solving the batch state estimation problem.\n    ",
        "primary_category": "cs.RO",
        "categories": [],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2403.00076": {
        "title": "Navigation and Control of Unconventional VTOL UAVs in Forward-Flight with Explicit Wind Velocity Estimation",
        "authors": [
            "Mitchell Cohen",
            "James Richard Forbes"
        ],
        "comments": "8 pages, 7 figures, published in Robotics and Automation Letters",
        "subjects": "Robotics (cs.RO)",
        "abstract": "This paper presents a solution for the state estimation and control problems for a class of unconventional vertical takeoff and landing (VTOL) UAVs operating in forward-flight conditions. A tightly-coupled state estimation approach is used to estimate the aircraft navigation states, sensor biases, and the wind velocity. State estimation is done within a matrix Lie group framework using the Invariant Extended Kalman Filter (IEKF), which offers several advantages compared to standard multiplicative EKFs traditionally used in aerospace and robotics problems. An SO(3)- based attitude controller is employed, leading to a single attitude control law without a separate sideslip control loop. A control allocator is used to determine how to use multiple, possibly redundant, actuators to produce the desired control moments. The wind velocity estimates are used in the attitude controller and the control allocator to improve performance. A numerical example is considered using a sample VTOL tailsitter-type UAV with four control surfaces. Monte-Carlo simulations demonstrate robustness of the proposed control and estimation scheme to various initial conditions, noise levels, and flight trajectories.\n    ",
        "primary_category": "cs.RO",
        "categories": [],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2403.00081": {
        "title": "The Constitutions of Web3",
        "authors": [
            "Joshua Z. Tan",
            "Max Langenkamp",
            "Anna Weichselbraun",
            "Ann Brody",
            "Lucia Korpas"
        ],
        "comments": " ",
        "subjects": "Computers and Society (cs.CY)",
        "abstract": "The governance of online communities has been a critical issue since the first USENET groups, and a number of serious constitutions -- declarations of goals, values, and rights -- have emerged since the mid-1990s. More recently, decentralized autonomous organizations (DAOs) have begun to publish their own constitutions, manifestos, and other governance documents. There are two unique aspects to these documents: they (1) often govern significantly more resources than previously-observed online communities, and (2) are used in conjunction with smart contracts that can secure certain community rights and processes through code. In this article, we analyze 25 DAO constitutions, observe a number of common patterns, and provide a template and a set of recommendations to support the crafting and dissemination of future DAO constitutions. We conclude with a report on how our template and recommendations were then used within the actual constitutional drafting process of a major blockchain.\n    ",
        "primary_category": "cs.CY",
        "categories": [],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2403.00087": {
        "title": "Towards the verification of a generic interlocking logic: Dafny meets parameterized model checking",
        "authors": [
            "Alessandro Cimatti",
            "Alberto Griggio",
            "Gianluca Redondi"
        ],
        "comments": " ",
        "subjects": "Logic in Computer Science (cs.LO)",
        "abstract": "Interlocking logics are at the core of critical systems controlling the traffic within stations. In this paper, we consider a generic interlocking logic, which can be instantiated to control a wide class of stations. We tackle the problem of parameterized verification, i.e. prove that the logic satisfies the required properties for all the relevant stations. We present a simplified case study, where the interlocking logic is directly encoded in Dafny. Then, we show how to automate the proof of an important safety requirement, by integrating simple, template-based invariants and more complex invariants obtained from a model checker for parameterized systems. Based on these positive preliminary results, we outline how we intend to integrate the approach by extending the IDE for the design of the interlocking logic.\n    ",
        "primary_category": "cs.LO",
        "categories": [],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2403.00088": {
        "title": "Modern Code Reviews -- Survey of Literature and Practice",
        "authors": [
            "Deepika Badampudi",
            "Michael Unterkalmsteiner",
            "Ricardo Britto"
        ],
        "comments": " ",
        "subjects": "Software Engineering (cs.SE)",
        "abstract": "Background: Modern Code Review (MCR) is a lightweight alternative to traditional code inspections. While secondary studies on MCR exist, it is unknown whether the research community has targeted themes that practitioners consider important. Objectives: The objectives are to provide an overview of MCR research, analyze the practitioners' opinions on the importance of MCR research, investigate the alignment between research and practice, and propose future MCR research avenues. Method: We conducted a systematic mapping study to survey state of the art until and including 2021, employed the Q-Methodology to analyze the practitioners' perception of the relevance of MCR research, and analyzed the primary studies' research impact. Results: We analyzed 244 primary studies, resulting in five themes. As a result of the 1,300 survey data points, we found that the respondents are positive about research investigating the impact of MCR on product quality and MCR process properties. In contrast, they are negative about human factor- and support systems-related research. Conclusion: These results indicate a misalignment between the state of the art and the themes deemed important by most survey respondents. Researchers should focus on solutions that can improve the state of MCR practice. We provide an MCR research agenda that can potentially increase the impact of MCR research.\n    ",
        "primary_category": "cs.SE",
        "categories": [],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2403.00092": {
        "title": "PROC2PDDL: Open-Domain Planning Representations from Texts",
        "authors": [
            "Tianyi Zhang",
            "Li Zhang",
            "Zhaoyi Hou",
            "Ziyu Wang",
            "Yuling Gu",
            "Peter Clark",
            "Chris Callison-Burch",
            "Niket Tandon"
        ],
        "comments": " ",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "Planning in a text-based environment continues to be a major challenge for AI systems. Recent approaches have used language models to predict a planning domain definition (e.g., PDDL) but have only been evaluated in closed-domain simulated environments. To address this, we present Proc2PDDL , the first dataset containing open-domain procedural texts paired with expert-annotated PDDL representations. Using this dataset, we evaluate state-of-the-art models on defining the preconditions and effects of actions. We show that Proc2PDDL is highly challenging, with GPT-3.5's success rate close to 0% and GPT-4's around 35%. Our analysis shows both syntactic and semantic errors, indicating LMs' deficiency in both generating domain-specific prgorams and reasoning about events. We hope this analysis and dataset helps future progress towards integrating the best of LMs and formal planning.\n    ",
        "primary_category": "cs.CL",
        "categories": [],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2403.00095": {
        "title": "Solving Jigsaw Puzzles using Iterative Random Sampling: Parallels with Development of Skill Mastery",
        "authors": [
            "Neil Zhao",
            "Diana Zheng"
        ],
        "comments": "26 pages, 15 figures, 1 table",
        "subjects": "Computers and Society (cs.CY)",
        "abstract": "Skill mastery is a priority for success in all fields. We present a parallel between the development of skill mastery and the process of solving jigsaw puzzles. We show that iterative random sampling solves jigsaw puzzles in two phases: a lag phase that is characterized by little change and occupies the majority of the time, and a growth phase that marks rapid and imminent puzzle completion. Changes in the proportions of the number of single pieces and larger pieces can be overlaid on the timeline and progression of skill mastery. An emphasis is placed on the development of connections between pieces, which serves as an indicator of increasing puzzle completion and increasing skill mastery. Our manuscript provides a straightforward visual of skill mastery in the context of a common recreational activity.\n    ",
        "primary_category": "cs.CY",
        "categories": [
            "physics.soc-ph"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2403.00096": {
        "title": "Future of Pandemic Prevention and Response CCC Workshop Report",
        "authors": [
            "David Danks",
            "Rada Mihalcea",
            "Katie Siek",
            "Mona Singh",
            "Brian Dixon",
            "Haley Griffin"
        ],
        "comments": " ",
        "subjects": "Computers and Society (cs.CY)",
        "abstract": "This report summarizes the discussions and conclusions of a 2-day multidisciplinary workshop that brought together researchers and practitioners in healthcare, computer science, and social sciences to explore what lessons were learned and what actions, primarily in research, could be taken. One consistent observation was that there is significant merit in thinking not only about pandemic situations, but also about peacetime advances, as many healthcare networks and communities are now in a perpetual state of crisis. Attendees discussed how the COVID-19 pandemic amplified gaps in our health and computing systems, and how current and future computing technologies could fill these gaps and improve the trajectory of the next pandemic.\nThree major computing themes emerged from the workshop: models, data, and infrastructure. Computational models are extremely important during pandemics, from anticipating supply needs of hospitals, to determining the care capacity of hospital and social service providers, to projecting the spread of the disease. Accurate, reliable models can save lives, and inform community leaders on policy decisions. Health system users require accurate, reliable data to achieve success when applying models. This requires data and measurement standardization across health care organizations, modernizing the data infrastructure, and methods for ensuring data remains private while shared for model development, validation, and application. Finally, many health care systems lack the data, compute, and communication infrastructures required to build models on their data, use those models in ordinary operations, or even to reliably access their data. Robust and timely computing research has the potential to better support healthcare works to save lives in times of crisis (e.g., pandemics) and today during relative peacetime.\n    ",
        "primary_category": "cs.CY",
        "categories": [],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2403.00098": {
        "title": "On the Counting Complexity of the Skolem Problem",
        "authors": [
            "Gorav Jindal",
            "Jo\u00ebl Ouaknine"
        ],
        "comments": " ",
        "subjects": "Computational Complexity (cs.CC)",
        "abstract": "The Skolem Problem asks, given an integer linear recurrence sequence (LRS), to determine whether the sequence contains a zero term or not. Its decidability is a longstanding open problem in theoretical computer science and automata theory. Currently, decidability is only known for LRS of order at most 4. On the other hand, the sole known complexity result is NP-hardness, due to Blondel and Portier.\nA fundamental result in this area is the celebrated Skolem-Mahler-Lech theorem, which asserts that the zero set of any LRS is the union of a finite set and finitely many arithmetic progressions. This paper focuses on a computational perspective of the Skolem-Mahler-Lech theorem: we show that the problem of counting the zeros of a given LRS is #P-hard, and in fact #P-complete for the instances generated in our reduction.\n    ",
        "primary_category": "cs.CC",
        "categories": [
            "cs.LO"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2403.00099": {
        "title": "An approach for performance requirements verification and test environments generation",
        "authors": [
            "Waleed Abdeen",
            "Xingru Chen",
            "Michael Unterkalmsteiner"
        ],
        "comments": " ",
        "subjects": "Software Engineering (cs.SE)",
        "abstract": "Model-based testing (MBT) is a method that supports the design and execution of test cases by models that specify the intended behaviors of a system under test. While systematic literature reviews on MBT in general exist, the state of the art on modeling and testing performance requirements has seen much less attention. Therefore, we conducted a systematic mapping study on model-based performance testing. Then, we studied natural language software requirements specifications in order to understand which and how performance requirements are typically specified. Since none of the identified MBT techniques supported a major benefit of modeling, namely identifying faults in requirements specifications, we developed the Performance Requirements verificatiOn and Test EnvironmentS generaTion approach (PRO-TEST). Finally, we evaluated PRO-TEST on 149 requirements specifications. We found and analyzed 57 primary studies from the systematic mapping study and extracted 50 performance requirements models. However, those models don't achieve the goals of MBT, which are validating requirements, ensuring their testability, and generating the minimum required test cases. We analyzed 77 Software Requirements Specification (SRS) documents, extracted 149 performance requirements from those SRS, and illustrate that with PRO-TEST we can model performance requirements, find issues in those requirements and detect missing ones. We detected three not-quantifiable requirements, 43 not-quantified requirements, and 180 underspecified parameters in the 149 modeled performance requirements. Furthermore, we generated 96 test environments from those models. By modeling performance requirements with PRO-TEST, we can identify issues in the requirements related to their ambiguity, measurability, and completeness. Additionally, it allows to generate parameters for test environments.\n    ",
        "primary_category": "cs.SE",
        "categories": [],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2403.00103": {
        "title": "On Robustness and Generalization of ML-Based Congestion Predictors to Valid and Imperceptible Perturbations",
        "authors": [
            "Chester Holtz",
            "Yucheng Wang",
            "Chung-Kuan Cheng",
            "Bill Lin"
        ],
        "comments": "7 pages, 7 figures",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "There is substantial interest in the use of machine learning (ML)-based techniques throughout the electronic computer-aided design (CAD) flow, particularly methods based on deep learning. However, while deep learning methods have achieved state-of-the-art performance in several applications, recent work has demonstrated that neural networks are generally vulnerable to small, carefully chosen perturbations of their input (e.g. a single pixel change in an image). In this work, we investigate robustness in the context of ML-based EDA tools -- particularly for congestion prediction. As far as we are aware, we are the first to explore this concept in the context of ML-based EDA.\nWe first describe a novel notion of imperceptibility designed specifically for VLSI layout problems defined on netlists and cell placements. Our definition of imperceptibility is characterized by a guarantee that a perturbation to a layout will not alter its global routing. We then demonstrate that state-of-the-art CNN and GNN-based congestion models exhibit brittleness to imperceptible perturbations. Namely, we show that when a small number of cells (e.g. 1%-5% of cells) have their positions shifted such that a measure of global congestion is guaranteed to remain unaffected (e.g. 1% of the design adversarially shifted by 0.001% of the layout space results in a predicted decrease in congestion of up to 90%, while no change in congestion is implied by the perturbation). In other words, the quality of a predictor can be made arbitrarily poor (i.e. can be made to predict that a design is \"congestion-free\") for an arbitrary input layout. Next, we describe a simple technique to train predictors that improves robustness to these perturbations. Our work indicates that CAD engineers should be cautious when integrating neural network-based mechanisms in EDA flows to ensure robust and high-quality results.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.AR"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2403.00105": {
        "title": "Longitudinal Counterfactuals: Constraints and Opportunities",
        "authors": [
            "Alexander Asemota",
            "Giles Hooker"
        ],
        "comments": " ",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Counterfactual explanations are a common approach to providing recourse to data subjects. However, current methodology can produce counterfactuals that cannot be achieved by the subject, making the use of counterfactuals for recourse difficult to justify in practice. Though there is agreement that plausibility is an important quality when using counterfactuals for algorithmic recourse, ground truth plausibility continues to be difficult to quantify. In this paper, we propose using longitudinal data to assess and improve plausibility in counterfactuals. In particular, we develop a metric that compares longitudinal differences to counterfactual differences, allowing us to evaluate how similar a counterfactual is to prior observed changes. Furthermore, we use this metric to generate plausible counterfactuals. Finally, we discuss some of the inherent difficulties of using counterfactuals for recourse.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.CY"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2403.00106": {
        "title": "Umwelt: Accessible Structured Editing of Multimodal Data Representations",
        "authors": [
            "Jonathan Zong",
            "Isabella Pedraza Pineros",
            "Mengzhu Katie Chen",
            "Daniel Hajas",
            "Arvind Satyanarayan"
        ],
        "comments": "ACM CHI 2024",
        "subjects": "Human-Computer Interaction (cs.HC)",
        "abstract": "We present Umwelt, an authoring environment for interactive multimodal data representations. In contrast to prior approaches, which center the visual modality, Umwelt treats visualization, sonification, and textual description as coequal representations: they are all derived from a shared abstract data model, such that no modality is prioritized over the others. To simplify specification, Umwelt evaluates a set of heuristics to generate default multimodal representations that express a dataset's functional relationships. To support smoothly moving between representations, Umwelt maintains a shared query predicated that is reified across all modalities -- for instance, navigating the textual description also highlights the visualization and filters the sonification. In a study with 5 blind / low-vision expert users, we found that Umwelt's multimodal representations afforded complementary overview and detailed perspectives on a dataset, allowing participants to fluidly shift between task- and representation-oriented ways of thinking.\n    ",
        "primary_category": "cs.HC",
        "categories": [],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2403.00107": {
        "title": "Talent hat, cross-border mobility, and career development in China",
        "authors": [
            "Yurui Huang",
            "Xuesen Cheng",
            "Chaolin Tian",
            "Xunyi Jiang",
            "Langtian Ma",
            "Yifang Ma"
        ],
        "comments": " ",
        "subjects": "Digital Libraries (cs.DL)",
        "abstract": "This study aims to investigate the influence of cross-border recruitment program in China, which confers scientists with a 'talent hat' including a startup package comprising significant bonuses, pay, and funding, on their future performance and career development. By curating a unique dataset from China's 10-year talent recruitment program, we employed multiple matching designs to quantify the effects of the cross-border recruitment with 'talent hat' on early career STEM scholars. Our findings indicate that the cross-border talents perform better than their comparable contenders who move without talent hats and those who do not move, given equivalent scientific performance before relocation. Moreover, we observed that scholars in experimental fields derive greater benefits from the talent program than those in non-experimental fields. Finally, we investigated how the changes in scientific environment of scientists affect their future performance. We found that talents who reassembled their collaboration network with new collaborators in new institutions after job replacement experienced significant improvements in their academic performance. However, shifting research directions entails risks, which results in a subsequent decrease of future productivity and citation impact following the relocation. This study has significant implications for young scientists, research institutions, and governments concerning cultivating cross-border talents.\n    ",
        "primary_category": "cs.DL",
        "categories": [],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2403.00108": {
        "title": "LoRA-as-an-Attack! Piercing LLM Safety Under The Share-and-Play Scenario",
        "authors": [
            "Hongyi Liu",
            "Zirui Liu",
            "Ruixiang Tang",
            "Jiayi Yuan",
            "Shaochen Zhong",
            "Yu-Neng Chuang",
            "Li Li",
            "Rui Chen",
            "Xia Hu"
        ],
        "comments": " ",
        "subjects": "Cryptography and Security (cs.CR)",
        "abstract": "Fine-tuning LLMs is crucial to enhancing their task-specific performance and ensuring model behaviors are aligned with human preferences. Among various fine-tuning methods, LoRA is popular for its efficiency and ease to use, allowing end-users to easily post and adopt lightweight LoRA modules on open-source platforms to tailor their model for different customization. However, such a handy share-and-play setting opens up new attack surfaces, that the attacker can render LoRA as an attacker, such as backdoor injection, and widely distribute the adversarial LoRA to the community easily. This can result in detrimental outcomes. Despite the huge potential risks of sharing LoRA modules, this aspect however has not been fully explored. To fill the gap, in this study we thoroughly investigate the attack opportunities enabled in the growing share-and-play scenario. Specifically, we study how to inject backdoor into the LoRA module and dive deeper into LoRA's infection mechanisms. We found that training-free mechanism is possible in LoRA backdoor injection. We also discover the impact of backdoor attacks with the presence of multiple LoRA adaptions concurrently as well as LoRA based backdoor transferability. Our aim is to raise awareness of the potential risks under the emerging share-and-play scenario, so as to proactively prevent potential consequences caused by LoRA-as-an-Attack. Warning: the paper contains potential offensive content generated by models.\n    ",
        "primary_category": "cs.CR",
        "categories": [
            "cs.AI",
            "cs.CL"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2403.00115": {
        "title": "PosSLP and Sum of Squares",
        "authors": [
            "Markus Bl\u00e4ser",
            "Julian D\u00f6rfler",
            "Gorav Jindal"
        ],
        "comments": " ",
        "subjects": "Computational Complexity (cs.CC)",
        "abstract": "The problem PosSLP is the problem of determining whether a given straight-line program (SLP) computes a positive integer. PosSLP was introduced by Allender et al. to study the complexity of numerical analysis (Allender et al., 2009). PosSLP can also be reformulated as the problem of deciding whether the integer computed by a given SLP can be expressed as the sum of squares of four integers, based on the well-known result by Lagrange in 1770, which demonstrated that every natural number can be represented as the sum of four non-negative integer squares.\nIn this paper, we explore several natural extensions of this problem by investigating whether the positive integer computed by a given SLP can be written as the sum of squares of two or three integers. We delve into the complexity of these variations and demonstrate relations between the complexity of the original PosSLP problem and the complexity of these related problems. Additionally, we introduce a new intriguing problem called Div2SLP and illustrate how Div2SLP is connected to DegSLP and the problem of whether an SLP computes an integer expressible as the sum of three squares.\nBy comprehending the connections between these problems, our results offer a deeper understanding of decision problems associated with SLPs and open avenues for further exciting research\n    ",
        "primary_category": "cs.CC",
        "categories": [
            "cs.DM"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2403.00116": {
        "title": "Federated Linear Contextual Bandits with Heterogeneous Clients",
        "authors": [
            "Ethan Blaser",
            "Chuanhao Li",
            "Hongning Wang"
        ],
        "comments": " ",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "The demand for collaborative and private bandit learning across multiple agents is surging due to the growing quantity of data generated from distributed systems. Federated bandit learning has emerged as a promising framework for private, efficient, and decentralized online learning. However, almost all previous works rely on strong assumptions of client homogeneity, i.e., all participating clients shall share the same bandit model; otherwise, they all would suffer linear regret. This greatly restricts the application of federated bandit learning in practice. In this work, we introduce a new approach for federated bandits for heterogeneous clients, which clusters clients for collaborative bandit learning under the federated learning setting. Our proposed algorithm achieves non-trivial sub-linear regret and communication cost for all clients, subject to the communication protocol under federated learning that at anytime only one model can be shared by the server.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2403.00122": {
        "title": "Quantum Readiness in Healthcare and Public Health: Building a Quantum Literate Workforce",
        "authors": [
            "Jonathan B VanGeest",
            "Kieran J Fogarty",
            "William G Hervey",
            "Robert A Hanson",
            "Suresh Nair",
            "Timothy A Akers"
        ],
        "comments": "13 pages, 1 table",
        "subjects": "Physics and Society (physics.soc-ph)",
        "abstract": "Quantum technologies, including quantum computing, cryptography, and sensing, among others, are set to revolutionize sectors ranging from materials science to drug discovery. Despite their significant potential, the implications for public health have been largely overlooked, highlighting a critical gap in recognition and preparation. This oversight necessitates immediate action, as public health remains largely unaware of quantum technologies as a tool for advancement. The application of quantum principles to epidemiology and health informatics, termed quantum health epidemiology and quantum health informatics, has the potential to radically transform disease surveillance, prediction, modeling, and analysis of health data. However, there is a notable lack of quantum expertise within the public health workforce and educational pipelines. This gap underscores the urgent need for the development of quantum literacy among public health practitioners, leaders, and students to leverage emerging opportunities while addressing risks and ethical considerations. Innovative teaching methods, such as interactive simulations, games, visual models, and other tailored platforms, offer viable solutions for bridging knowledge gaps without the need for advanced physics or mathematics. However, the opportunity to adapt is fleeting as the quantum era in healthcare looms near. It is imperative that public health urgently focuses on updating its educational approaches, workforce strategies, data governance, and organizational culture to proactively meet the challenges of quantum disruption thereby becoming quantum ready.\n    ",
        "primary_category": "physics.soc-ph",
        "categories": [
            "cs.CY",
            "cs.ET",
            "quant-ph"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2403.00125": {
        "title": "Penalty-free discontinuous Galerkin method",
        "authors": [
            "Jan Ja\u015bkowiec",
            "N. Sukumar"
        ],
        "comments": " ",
        "subjects": "Numerical Analysis (math.NA)",
        "abstract": "In this paper, we present a new high-order discontinuous Galerkin (DG) method, in which neither a penalty parameter nor a stabilization parameter is needed. We refer to this method as penalty-free DG (\\PFDG). In this method, the trial and test functions belong to the broken Sobolev space, in which the functions are in general discontinuous on the mesh skeleton and do not meet the Dirichlet boundary conditions. However, a subset can be distinguished in this space, where the functions are continuous and satisfy the Dirichlet boundary conditions, and this subset is called admissible. The trial solution is chosen to lie in an \\emph{augmented} admissible subset, in which a small violation of the continuity condition is permitted. This subset is constructed by applying special augmented constraints to the linear combination of finite element basis functions. In this approach, all the advantages of the DG method are retained without the necessity of using stability parameters or numerical fluxes. Several benchmark problems in two dimensions (Poisson equation, linear elasticity, hyperelasticity, and biharmonic equation) on polygonal (triangles, quadrilateral and weakly convex polygons) meshes as well as a three-dimensional Poisson problem on hexahedral meshes are considered. Numerical results are presented that affirm the sound accuracy and optimal convergence of the method in the $L^2$ norm and the energy seminorm.\n    ",
        "primary_category": "math.NA",
        "categories": [],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2403.00126": {
        "title": "FAC$^2$E: Better Understanding Large Language Model Capabilities by Dissociating Language and Cognition",
        "authors": [
            "Xiaoqiang Wang",
            "Bang Liu",
            "Lingfei Wu"
        ],
        "comments": "Work in Progress",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "Large language models (LLMs) are primarily evaluated by overall performance on various text understanding and generation tasks. However, such a paradigm fails to comprehensively differentiate the fine-grained language and cognitive skills, rendering the lack of sufficient interpretation to LLMs' capabilities. In this paper, we present FAC$^2$E, a framework for Fine-grAined and Cognition-grounded LLMs' Capability Evaluation. Specifically, we formulate LLMs' evaluation in a multi-dimensional and explainable manner by dissociating the language-related capabilities and the cognition-related ones. Besides, through extracting the intermediate reasoning from LLMs, we further break down the process of applying a specific capability into three sub-steps: recalling relevant knowledge, utilizing knowledge, and solving problems. Finally, FAC$^2$E evaluates each sub-step of each fine-grained capability, providing a two-faceted diagnosis for LLMs. Utilizing FAC$^2$E, we identify a common shortfall in knowledge utilization among models and propose a straightforward, knowledge-enhanced method to mitigate this issue. Our results not only showcase promising performance enhancements but also highlight a direction for future LLM advancements.\n    ",
        "primary_category": "cs.CL",
        "categories": [],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2403.00128": {
        "title": "From Flies to Robots: Inverted Landing in Small Quadcopters with Dynamic Perching",
        "authors": [
            "Bryan Habas",
            "Bo Cheng"
        ],
        "comments": "17 pages, 19 Figures, Journal paper currently under review",
        "subjects": "Robotics (cs.RO)",
        "abstract": "Inverted landing is a routine behavior among a number of animal fliers. However, mastering this feat poses a considerable challenge for robotic fliers, especially to perform dynamic perching with rapid body rotations (or flips) and landing against gravity. Inverted landing in flies have suggested that optical flow senses are closely linked to the precise triggering and control of body flips that lead to a variety of successful landing behaviors. Building upon this knowledge, we aimed to replicate the flies' landing behaviors in small quadcopters by developing a control policy general to arbitrary ceiling-approach conditions. First, we employed reinforcement learning in simulation to optimize discrete sensory-motor pairs across a broad spectrum of ceiling-approach velocities and directions. Next, we converted the sensory-motor pairs to a two-stage control policy in a continuous augmented-optical flow space. The control policy consists of a first-stage Flip-Trigger Policy, which employs a one-class support vector machine, and a second-stage Flip-Action Policy, implemented as a feed-forward neural network. To transfer the inverted-landing policy to physical systems, we utilized domain randomization and system identification techniques for a zero-shot sim-to-real transfer. As a result, we successfully achieved a range of robust inverted-landing behaviors in small quadcopters, emulating those observed in flies.\n    ",
        "primary_category": "cs.RO",
        "categories": [
            "cs.LG",
            "eess.SY"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2403.00129": {
        "title": "Average-Case Local Computation Algorithms",
        "authors": [
            "Amartya Shankha Biswas",
            "Ruidi Cao",
            "Edward Pyne",
            "Ronitt Rubinfeld"
        ],
        "comments": "27 pages",
        "subjects": "Data Structures and Algorithms (cs.DS)",
        "abstract": "We initiate the study of Local Computation Algorithms on average case inputs. In the Local Computation Algorithm (LCA) model, we are given probe access to a huge graph, and asked to answer membership queries about some combinatorial structure on the graph, answering each query with sublinear work.\nFor instance, an LCA for the $k$-spanner problem gives access to a sparse subgraph $H\\subseteq G$ that preserves distances up to a factor of $k$. We build simple LCAs for this problem assuming the input graph is drawn from the well-studied Erdos-Reyni and Preferential Attachment graph models. In both cases, our spanners achieve size and stretch tradeoffs that are impossible to achieve for general graphs, while having dramatically lower query complexity than worst-case LCAs.\nOur second result investigates the intersection of LCAs with Local Access Generators (LAGs). Local Access Generators provide efficient query access to a random object, for instance an Erdos Reyni random graph. We explore the natural problem of generating a random graph together with a combinatorial structure on it. We show that this combination can be easier to solve than focusing on each problem by itself, by building a fast, simple algorithm that provides access to an Erdos Reyni random graph together with a maximal independent set.\n    ",
        "primary_category": "cs.DS",
        "categories": [],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2403.00131": {
        "title": "UniTS: Building a Unified Time Series Model",
        "authors": [
            "Shanghua Gao",
            "Teddy Koker",
            "Owen Queen",
            "Thomas Hartvigsen",
            "Theodoros Tsiligkaridis",
            "Marinka Zitnik"
        ],
        "comments": " ",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Foundation models, especially LLMs, are profoundly transforming deep learning. Instead of training many task-specific models, we can adapt a single pretrained model to many tasks via fewshot prompting or fine-tuning. However, current foundation models apply to sequence data but not to time series, which present unique challenges due to the inherent diverse and multidomain time series datasets, diverging task specifications across forecasting, classification and other types of tasks, and the apparent need for task-specialized models. We developed UNITS, a unified time series model that supports a universal task specification, accommodating classification, forecasting, imputation, and anomaly detection tasks. This is achieved through a novel unified network backbone, which incorporates sequence and variable attention along with a dynamic linear operator and is trained as a unified model. Across 38 multi-domain datasets, UNITS demonstrates superior performance compared to task-specific models and repurposed natural language-based LLMs. UNITS exhibits remarkable zero-shot, few-shot, and prompt learning capabilities when evaluated on new data domains and tasks. The source code and datasets are available at this https URL.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2403.00132": {
        "title": "Quantum Hardware Roofline: Evaluating the Impact of Gate Expressivity on Quantum Processor Design",
        "authors": [
            "Justin Kalloor",
            "Mathias Weiden",
            "Ed Younis",
            "John Kubiatowicz",
            "Bert De Jong",
            "Costin Iancu"
        ],
        "comments": " ",
        "subjects": "Quantum Physics (quant-ph)",
        "abstract": "The design space of current quantum computers is expansive with no obvious winning solution. This leaves practitioners with a clear question: \"What is the optimal system configuration to run an algorithm?\". This paper explores hardware design trade-offs across NISQ systems to guide algorithm and hardware design choices. The evaluation is driven by algorithmic workloads and algorithm fidelity models which capture architectural features such as gate expressivity, fidelity, and crosstalk. We also argue that the criteria for gate design and selection should be extended from maximizing average fidelity to a more comprehensive approach that takes into account the gate expressivity with respect to algorithmic structures. We consider native entangling gates (CNOT, ECR, CZ, ZZ, XX, Sycamore, $\\sqrt{\\text{iSWAP}}$), proposed gates (B Gate, $\\sqrt[4]{\\text{CNOT}}$, $\\sqrt[8]{\\text{CNOT}}$), as well as parameterized gates (FSim, XY). Our methodology is driven by a custom synthesis driven circuit compilation workflow, which is able to produce minimal circuit representations for a given system configuration. By providing a method to evaluate the suitability of algorithms for hardware platforms, this work emphasizes the importance of hardware-software co-design for quantum computing.\n    ",
        "primary_category": "quant-ph",
        "categories": [
            "cs.AR",
            "cs.PF"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2403.00133": {
        "title": "ForTune: Running Offline Scenarios to Estimate Impact on Business Metrics",
        "authors": [
            "Georges Dupret",
            "Konstantin Sozinov",
            "Carmen Barcena Gonzalez",
            "Ziggy Zacks",
            "Amber Yuan",
            "Benjamin Carterette",
            "Manuel Mai",
            "Shubham Bansal",
            "Gwo Liang",
            "Lien",
            "Andrey Gatash",
            "Roberto Sanchis Ojeda",
            "Mounia Lalmas"
        ],
        "comments": " ",
        "subjects": "Computational Engineering, Finance, and Science (cs.CE)",
        "abstract": "Making ideal decisions as a product leader in a web-facing company is extremely difficult. In addition to navigating the ambiguity of customer satisfaction and achieving business goals, one must also pave a path forward for ones' products and services to remain relevant, desirable, and profitable. Data and experimentation to test product hypotheses are key to informing product decisions. Online controlled experiments by A/B testing may provide the best data to support such decisions with high confidence, but can be time-consuming and expensive, especially when one wants to understand impact to key business metrics such as retention or long-term value. Offline experimentation allows one to rapidly iterate and test, but often cannot provide the same level of confidence, and cannot easily shine a light on impact on business metrics. We introduce a novel, lightweight, and flexible approach to investigating hypotheses, called scenario analysis, that aims to support product leaders' decisions using data about users and estimates of business metrics. Its strengths are that it can provide guidance on trade-offs that are incurred by growing or shifting consumption, estimate trends in long-term outcomes like retention and other important business metrics, and can generate hypotheses about relationships between metrics at scale.\n    ",
        "primary_category": "cs.CE",
        "categories": [
            "stat.AP"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2403.00134": {
        "title": "Active Sensing for Reciprocal MIMO Channels",
        "authors": [
            "Tao Jiang",
            "Wei Yu"
        ],
        "comments": " ",
        "subjects": "Information Theory (cs.IT)",
        "abstract": "This paper addresses the design of transmit precoder and receive combiner matrices to support $N_{\\rm s}$ independent data streams over a time-division duplex (TDD) point-to-point massive multiple-input multiple-output (MIMO) channel with either a fully digital or a hybrid structure. The optimal precoder and combiner design amounts to finding the top-$N_{\\rm s}$ singular vectors of the channel matrix, but the explicit estimation of the entire high-dimensional channel would require significant pilot overhead. Alternatively, prior works seek to find the precoding and combining matrices directly by exploiting channel reciprocity and by using the power iteration method, but its performance degrades in the low SNR regime. To tackle this challenging problem, this paper proposes a learning-based active sensing framework, where the transmitter and the receiver send pilots alternately using sensing beamformers that are actively designed as functions of previously received pilots. This is accomplished by using recurrent neural networks to summarize information from the historical observations into hidden state vectors, then using fully connected neural networks to learn the appropriate sensing beamformers in the next pilot stage and finally the transmit precoding and receive combiner matrices for data communications. Simulations demonstrate that the learning-based method outperforms existing approaches significantly and maintains superior performance even in low SNR regimes both in fully digital and hybrid MIMO scenarios.\n    ",
        "primary_category": "cs.IT",
        "categories": [
            "eess.SP"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2403.00136": {
        "title": "Developing a Taxonomy of Elements Adversarial to Autonomous Vehicles",
        "authors": [
            "Mohammadali Saffary",
            "Nishan Inampudi",
            "Joshua E. Siegel"
        ],
        "comments": "18 pages total, 4 pages of references, initial page left blank for IEEE submission statement. Includes 4 figures and 2 tables. Written using IEEEtran document class",
        "subjects": "Robotics (cs.RO)",
        "abstract": "As highly automated vehicles reach higher deployment rates, they find themselves in increasingly dangerous situations. Knowing that the consequence of a crash is significant for the health of occupants, bystanders, and properties, as well as to the viability of autonomy and adjacent businesses, we must search for more efficacious ways to comprehensively and reliably train autonomous vehicles to better navigate the complex scenarios with which they struggle. We therefore introduce a taxonomy of potentially adversarial elements that may contribute to poor performance or system failures as a means of identifying and elucidating lesser-seen risks. This taxonomy may be used to characterize failures of automation, as well as to support simulation and real-world training efforts by providing a more comprehensive classification system for events resulting in disengagement, collision, or other negative consequences. This taxonomy is created from and tested against real collision events to ensure comprehensive coverage with minimal class overlap and few omissions. It is intended to be used both for the identification of harm-contributing adversarial events and in the generation thereof (to create extreme edge- and corner-case scenarios) in training procedures.\n    ",
        "primary_category": "cs.RO",
        "categories": [],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2403.00137": {
        "title": "User Characteristics in Explainable AI: The Rabbit Hole of Personalization?",
        "authors": [
            "Robert Nimmo",
            "Marios Constantinides",
            "Ke Zhou",
            "Daniele Quercia",
            "Simone Stumpf"
        ],
        "comments": "20 pages, 4 tables, 2 figures",
        "subjects": "Human-Computer Interaction (cs.HC)",
        "abstract": "As Artificial Intelligence (AI) becomes ubiquitous, the need for Explainable AI (XAI) has become critical for transparency and trust among users. A significant challenge in XAI is catering to diverse users, such as data scientists, domain experts, and end-users. Recent research has started to investigate how users' characteristics impact interactions with and user experience of explanations, with a view to personalizing XAI. However, are we heading down a rabbit hole by focusing on unimportant details? Our research aimed to investigate how user characteristics are related to using, understanding, and trusting an AI system that provides explanations. Our empirical study with 149 participants who interacted with an XAI system that flagged inappropriate comments showed that very few user characteristics mattered; only age and the personality trait openness influenced actual understanding. Our work provides evidence to reorient user-focused XAI research and question the pursuit of personalized XAI based on fine-grained user characteristics.\n    ",
        "primary_category": "cs.HC",
        "categories": [],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2403.00141": {
        "title": "EROS: Entity-Driven Controlled Policy Document Summarization",
        "authors": [
            "Joykirat Singh",
            "Sehban Fazili",
            "Rohan Jain",
            "Md Shad Akhtar"
        ],
        "comments": "Accepted in LREC-COLING 2024",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "Privacy policy documents have a crucial role in educating individuals about the collection, usage, and protection of users' personal data by organizations. However, they are notorious for their lengthy, complex, and convoluted language especially involving privacy-related entities. Hence, they pose a significant challenge to users who attempt to comprehend organization's data usage policy. In this paper, we propose to enhance the interpretability and readability of policy documents by using controlled abstractive summarization -- we enforce the generated summaries to include critical privacy-related entities (e.g., data and medium) and organization's rationale (e.g.,target and reason) in collecting those entities. To achieve this, we develop PD-Sum, a policy-document summarization dataset with marked privacy-related entity labels. Our proposed model, EROS, identifies critical entities through a span-based entity extraction model and employs them to control the information content of the summaries using proximal policy optimization (PPO). Comparison shows encouraging improvement over various baselines. Furthermore, we furnish qualitative and human evaluations to establish the efficacy of EROS.\n    ",
        "primary_category": "cs.CL",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2403.00143": {
        "title": "Ensemble-Based Unsupervised Discontinuous Constituency Parsing by Tree Averaging",
        "authors": [
            "Behzad Shayegh",
            "Yuqiao Wen",
            "Lili Mou"
        ],
        "comments": " ",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "We address unsupervised discontinuous constituency parsing, where we observe a high variance in the performance of the only previous model. We propose to build an ensemble of different runs of the existing discontinuous parser by averaging the predicted trees, to stabilize and boost performance. To begin with, we provide comprehensive computational complexity analysis (in terms of P and NP-complete) for tree averaging under different setups of binarity and continuity. We then develop an efficient exact algorithm to tackle the task, which runs in a reasonable time for all samples in our experiments. Results on three datasets show our method outperforms all baselines in all metrics; we also provide in-depth analyses of our approach.\n    ",
        "primary_category": "cs.CL",
        "categories": [
            "cs.AI",
            "cs.LG"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2403.00144": {
        "title": "EBBS: An Ensemble with Bi-Level Beam Search for Zero-Shot Machine Translation",
        "authors": [
            "Yuqiao Wen",
            "Behzad Shayegh",
            "Chenyang Huang",
            "Yanshuai Cao",
            "Lili Mou"
        ],
        "comments": " ",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "The ability of zero-shot translation emerges when we train a multilingual model with certain translation directions; the model can then directly translate in unseen directions. Alternatively, zero-shot translation can be accomplished by pivoting through a third language (e.g., English). In our work, we observe that both direct and pivot translations are noisy and achieve less satisfactory performance. We propose EBBS, an ensemble method with a novel bi-level beam search algorithm, where each ensemble component explores its own prediction step by step at the lower level but they are synchronized by a \"soft voting\" mechanism at the upper level. Results on two popular multilingual translation datasets show that EBBS consistently outperforms direct and pivot translations as well as existing ensemble techniques. Further, we can distill the ensemble's knowledge back to the multilingual model to improve inference efficiency; profoundly, our EBBS-based distillation does not sacrifice, or even improves, the translation quality.\n    ",
        "primary_category": "cs.CL",
        "categories": [
            "cs.AI",
            "cs.LG"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2403.00145": {
        "title": "Guidelines for Integrating Value Sensitive Design in Responsible AI Toolkits",
        "authors": [
            "Malak Sadek",
            "Marios Constantinides",
            "Daniele Quercia",
            "C\u00e9line Mougenot"
        ],
        "comments": "26 pages, 8 figures, 3 tables",
        "subjects": "Human-Computer Interaction (cs.HC)",
        "abstract": "Value Sensitive Design (VSD) is a framework for integrating human values throughout the technology design process. In parallel, Responsible AI (RAI) advocates for the development of systems aligning with ethical values, such as fairness and transparency. In this study, we posit that a VSD approach is not only compatible, but also advantageous to the development of RAI toolkits. To empirically assess this hypothesis, we conducted four workshops involving 17 early-career AI researchers. Our aim was to establish links between VSD and RAI values while examining how existing toolkits incorporate VSD principles in their design. Our findings show that collaborative and educational design features within these toolkits, including illustrative examples and open-ended cues, facilitate an understanding of human and ethical values, and empower researchers to incorporate values into AI systems. Drawing on these insights, we formulated six design guidelines for integrating VSD values into the development of RAI toolkits.\n    ",
        "primary_category": "cs.HC",
        "categories": [],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2403.00147": {
        "title": "Analysis of Kernel Mirror Prox for Measure Optimization",
        "authors": [
            "Pavel Dvurechensky",
            "Jia-Jie Zhu"
        ],
        "comments": "Accepted to AISTATS 2024",
        "subjects": "Optimization and Control (math.OC)",
        "abstract": "By choosing a suitable function space as the dual to the non-negative measure cone, we study in a unified framework a class of functional saddle-point optimization problems, which we term the Mixed Functional Nash Equilibrium (MFNE), that underlies several existing machine learning algorithms, such as implicit generative models, distributionally robust optimization (DRO), and Wasserstein barycenters. We model the saddle-point optimization dynamics as an interacting Fisher-Rao-RKHS gradient flow when the function space is chosen as a reproducing kernel Hilbert space (RKHS). As a discrete time counterpart, we propose a primal-dual kernel mirror prox (KMP) algorithm, which uses a dual step in the RKHS, and a primal entropic mirror prox step. We then provide a unified convergence analysis of KMP in an infinite-dimensional setting for this class of MFNE problems, which establishes a convergence rate of $O(1/N)$ in the deterministic case and $O(1/\\sqrt{N})$ in the stochastic case, where $N$ is the iteration counter. As a case study, we apply our analysis to DRO, providing algorithmic guarantees for DRO robustness and convergence.\n    ",
        "primary_category": "math.OC",
        "categories": [
            "cs.LG"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2403.00148": {
        "title": "Implications of Regulations on the Use of AI and Generative AI for Human-Centered Responsible Artificial Intelligence",
        "authors": [
            "Marios Constantinides",
            "Mohammad Tahaei",
            "Daniele Quercia",
            "Simone Stumpf",
            "Michael Madaio",
            "Sean Kennedy",
            "Lauren Wilcox",
            "Jessica Vitak",
            "Henriette Cramer",
            "Edyta Bogucka",
            "Ricardo Baeza-Yates",
            "Ewa Luger",
            "Jess Holbrook",
            "Michael Muller",
            "Ilana Golbin Blumenfeld",
            "Giada Pistilli"
        ],
        "comments": "6 pages",
        "subjects": "Human-Computer Interaction (cs.HC)",
        "abstract": "With the upcoming AI regulations (e.g., EU AI Act) and rapid advancements in generative AI, new challenges emerge in the area of Human-Centered Responsible Artificial Intelligence (HCR-AI). As AI becomes more ubiquitous, questions around decision-making authority, human oversight, accountability, sustainability, and the ethical and legal responsibilities of AI and their creators become paramount. Addressing these questions requires a collaborative approach. By involving stakeholders from various disciplines in the 2\\textsuperscript{nd} edition of the HCR-AI Special Interest Group (SIG) at CHI 2024, we aim to discuss the implications of regulations in HCI research, develop new theories, evaluation frameworks, and methods to navigate the complex nature of AI ethics, steering AI development in a direction that is beneficial and sustainable for all of humanity.\n    ",
        "primary_category": "cs.HC",
        "categories": [],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2403.00153": {
        "title": "Practical and Rich User Digitization",
        "authors": [
            "Karan Ahuja"
        ],
        "comments": "PhD thesis",
        "subjects": "Human-Computer Interaction (cs.HC)",
        "abstract": "A long-standing vision in computer science has been to evolve computing devices into proactive assistants that enhance our productivity, health and wellness, and many other facets of our lives. User digitization is crucial in achieving this vision as it allows computers to intimately understand their users, capturing activity, pose, routine, and behavior. Today's consumer devices - like smartphones and smartwatches provide a glimpse of this potential, offering coarse digital representations of users with metrics such as step count, heart rate, and a handful of human activities like running and biking. Even these very low-dimensional representations are already bringing value to millions of people's lives, but there is significant potential for improvement. On the other end, professional, high-fidelity comprehensive user digitization systems exist. For example, motion capture suits and multi-camera rigs that digitize our full body and appearance, and scanning machines such as MRI capture our detailed anatomy. However, these carry significant user practicality burdens, such as financial, privacy, ergonomic, aesthetic, and instrumentation considerations, that preclude consumer use. In general, the higher the fidelity of capture, the lower the user's practicality. Most conventional approaches strike a balance between user practicality and digitization fidelity.\nMy research aims to break this trend, developing sensing systems that increase user digitization fidelity to create new and powerful computing experiences while retaining or even improving user practicality and accessibility, allowing such technologies to have a societal impact. Armed with such knowledge, our future devices could offer longitudinal health tracking, more productive work environments, full body avatars in extended reality, and embodied telepresence experiences, to name just a few domains.\n    ",
        "primary_category": "cs.HC",
        "categories": [
            "cs.CV"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2403.00155": {
        "title": "Towards Explaining Deep Neural Network Compression Through a Probabilistic Latent Space",
        "authors": [
            "Mahsa Mozafari-Nia",
            "Salimeh Yasaei Sekeh"
        ],
        "comments": " ",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Despite the impressive performance of deep neural networks (DNNs), their computational complexity and storage space consumption have led to the concept of network compression. While DNN compression techniques such as pruning and low-rank decomposition have been extensively studied, there has been insufficient attention paid to their theoretical explanation. In this paper, we propose a novel theoretical framework that leverages a probabilistic latent space of DNN weights and explains the optimal network sparsity by using the information-theoretic divergence measures. We introduce new analogous projected patterns (AP2) and analogous-in-probability projected patterns (AP3) notions for DNNs and prove that there exists a relationship between AP3/AP2 property of layers in the network and its performance. Further, we provide a theoretical analysis that explains the training process of the compressed network. The theoretical results are empirically validated through experiments conducted on standard pre-trained benchmarks, including AlexNet, ResNet50, and VGG16, using CIFAR10 and CIFAR100 datasets. Through our experiments, we highlight the relationship of AP3 and AP2 properties with fine-tuning pruned DNNs and sparsity levels.\n    ",
        "primary_category": "cs.LG",
        "categories": [],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2403.00157": {
        "title": "Privacy-Preserving Distributed Optimization and Learning",
        "authors": [
            "Ziqin Chen",
            "Yongqiang Wang"
        ],
        "comments": "Accepted as a chapter in the Encyclopedia of Systems and Control Engineering published by Elsevier",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Distributed optimization and learning has recently garnered great attention due to its wide applications in sensor networks, smart grids, machine learning, and so forth. Despite rapid development, existing distributed optimization and learning algorithms require each agent to exchange messages with its neighbors, which may expose sensitive information and raise significant privacy concerns. In this survey paper, we overview privacy-preserving distributed optimization and learning methods. We first discuss cryptography, differential privacy, and other techniques that can be used for privacy preservation and indicate their pros and cons for privacy protection in distributed optimization and learning. We believe that among these approaches, differential privacy is most promising due to its low computational and communication complexities, which are extremely appealing for modern learning based applications with high dimensions of optimization variables. We then introduce several differential-privacy algorithms that can simultaneously ensure privacy and optimization accuracy. Moreover, we provide example applications in several machine learning problems to confirm the real-world effectiveness of these algorithms. Finally, we highlight some challenges in this research domain and discuss future directions.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.CR",
            "cs.GT"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2403.00165": {
        "title": "TELEClass: Taxonomy Enrichment and LLM-Enhanced Hierarchical Text Classification with Minimal Supervision",
        "authors": [
            "Yunyi Zhang",
            "Ruozhen Yang",
            "Xueqiang Xu",
            "Jinfeng Xiao",
            "Jiaming Shen",
            "Jiawei Han"
        ],
        "comments": " ",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "Hierarchical text classification aims to categorize each document into a set of classes in a label taxonomy. Most earlier works focus on fully or semi-supervised methods that require a large amount of human annotated data which is costly and time-consuming to acquire. To alleviate human efforts, in this paper, we work on hierarchical text classification with the minimal amount of supervision: using the sole class name of each node as the only supervision. Recently, large language models (LLM) show competitive performance on various tasks through zero-shot prompting, but this method performs poorly in the hierarchical setting, because it is ineffective to include the large and structured label space in a prompt. On the other hand, previous weakly-supervised hierarchical text classification methods only utilize the raw taxonomy skeleton and ignore the rich information hidden in the text corpus that can serve as additional class-indicative features. To tackle the above challenges, we propose TELEClass, Taxonomy Enrichment and LLM-Enhanced weakly-supervised hierarchical text classification, which (1) automatically enriches the label taxonomy with class-indicative topical terms mined from the corpus to facilitate classifier training and (2) utilizes LLMs for both data annotation and creation tailored for the hierarchical label space. Experiments show that TELEClass can outperform previous weakly-supervised hierarchical text classification methods and LLM-based zero-shot prompting methods on two public datasets.\n    ",
        "primary_category": "cs.CL",
        "categories": [
            "cs.LG"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2403.00169": {
        "title": "Quantitative Assurance and Synthesis of Controllers from Activity Diagrams",
        "authors": [
            "Kangfeng Ye",
            "Fang Yan",
            "Simos Gerasimou"
        ],
        "comments": "43 pages, 29 figures, 5 tables, submitted to Journal of Systems and Software (JSS)",
        "subjects": "Logic in Computer Science (cs.LO)",
        "abstract": "Probabilistic model checking is a widely used formal verification technique to automatically verify qualitative and quantitative properties for probabilistic models. However, capturing such systems, writing corresponding properties, and verifying them require domain knowledge. This makes it not accessible for researchers and engineers who may not have the required knowledge. Previous studies have extended UML activity diagrams (ADs), developed transformations, and implemented accompanying tools for automation. The research, however, is incomprehensive and not fully open, which makes it hard to be evaluated, extended, adapted, and accessed. In this paper, we propose a comprehensive verification framework for ADs, including a new profile for probability, time, and quality annotations, a semantics interpretation of ADs in three Markov models, and a set of transformation rules from activity diagrams to the PRISM language, supported by PRISM and Storm. Most importantly, we developed algorithms for transformation and implemented them in a tool, called QASCAD, using model-based techniques, for fully automated verification. We evaluated one case study where multiple robots are used for delivery in a hospital and further evaluated six other examples from the literature. With all these together, this work makes noteworthy contributions to the verification of ADs by improving evaluation, extensibility, adaptability, and accessibility.\n    ",
        "primary_category": "cs.LO",
        "categories": [
            "cs.FL",
            "cs.SE"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2403.00172": {
        "title": "Go Beyond Black-box Policies: Rethinking the Design of Learning Agent for Interpretable and Verifiable HVAC Control",
        "authors": [
            "Zhiyu An",
            "Xianzhong Ding",
            "Wan Du"
        ],
        "comments": "Accepted for the 61st Design Automation Conference (DAC)",
        "subjects": "Systems and Control (eess.SY)",
        "abstract": "Recent research has shown the potential of Model-based Reinforcement Learning (MBRL) to enhance energy efficiency of Heating, Ventilation, and Air Conditioning (HVAC) systems. However, existing methods rely on black-box thermal dynamics models and stochastic optimizers, lacking reliability guarantees and posing risks to occupant health. In this work, we overcome the reliability bottleneck by redesigning HVAC controllers using decision trees extracted from existing thermal dynamics models and historical data. Our decision tree-based policies are deterministic, verifiable, interpretable, and more energy-efficient than current MBRL methods. First, we introduce a novel verification criterion for RL agents in HVAC control based on domain knowledge. Second, we develop a policy extraction procedure that produces a verifiable decision tree policy. We found that the high dimensionality of the thermal dynamics model input hinders the efficiency of policy extraction. To tackle the dimensionality challenge, we leverage importance sampling conditioned on historical data distributions, significantly improving policy extraction efficiency. Lastly, we present an offline verification algorithm that guarantees the reliability of a control policy. Extensive experiments show that our method saves 68.4% more energy and increases human comfort gain by 14.8% compared to the state-of-the-art method, in addition to an 1127x reduction in computation overhead. Our code and data are available at this https URL\n",
        "primary_category": "eess.SY",
        "categories": [
            "cs.AI",
            "cs.LG"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2403.00176": {
        "title": "SoD$^2$: Statically Optimizing Dynamic Deep Neural Network",
        "authors": [
            "Wei Niu",
            "Gagan Agrawal",
            "Bin Ren"
        ],
        "comments": " ",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Though many compilation and runtime systems have been developed for DNNs in recent years, the focus has largely been on static DNNs. Dynamic DNNs, where tensor shapes and sizes and even the set of operators used are dependent upon the input and/or execution, are becoming common. This paper presents SoD$^2$, a comprehensive framework for optimizing Dynamic DNNs. The basis of our approach is a classification of common operators that form DNNs, and the use of this classification towards a Rank and Dimension Propagation (RDP) method. This framework statically determines the shapes of operators as known constants, symbolic constants, or operations on these. Next, using RDP we enable a series of optimizations, like fused code generation, execution (order) planning, and even runtime memory allocation plan generation. By evaluating the framework on 10 emerging Dynamic DNNs and comparing it against several existing systems, we demonstrate both reductions in execution latency and memory requirements, with RDP-enabled key optimizations responsible for much of the gains. Our evaluation results show that SoD$^2$ runs up to $3.9\\times$ faster than these systems while saving up to $88\\%$ peak memory consumption.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.AI",
            "cs.PL"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2403.00177": {
        "title": "Non-Invasive Medical Digital Twins using Physics-Informed Self-Supervised Learning",
        "authors": [
            "Keying Kuang",
            "Frances Dean",
            "Jack B. Jedlicki",
            "David Ouyang",
            "Anthony Philippakis",
            "David Sontag",
            "Ahmed M. Alaa"
        ],
        "comments": " ",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "A digital twin is a virtual replica of a real-world physical phenomena that uses mathematical modeling to characterize and simulate its defining features. By constructing digital twins for disease processes, we can perform in-silico simulations that mimic patients' health conditions and counterfactual outcomes under hypothetical interventions in a virtual setting. This eliminates the need for invasive procedures or uncertain treatment decisions. In this paper, we propose a method to identify digital twin model parameters using only noninvasive patient health data. We approach the digital twin modeling as a composite inverse problem, and observe that its structure resembles pretraining and finetuning in self-supervised learning (SSL). Leveraging this, we introduce a physics-informed SSL algorithm that initially pretrains a neural network on the pretext task of solving the physical model equations. Subsequently, the model is trained to reconstruct low-dimensional health measurements from noninvasive modalities while being constrained by the physical equations learned in pretraining. We apply our method to identify digital twins of cardiac hemodynamics using noninvasive echocardiogram videos, and demonstrate its utility in unsupervised disease detection and in-silico clinical trials.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "q-bio.QM"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2403.00178": {
        "title": "Causal Graph ODE: Continuous Treatment Effect Modeling in Multi-agent Dynamical Systems",
        "authors": [
            "Zijie Huang",
            "Jeehyun Hwang",
            "Junkai Zhang",
            "Jinwoo Baik",
            "Weitong Zhang",
            "Dominik Wodarz",
            "Yizhou Sun",
            "Quanquan Gu",
            "Wei Wang"
        ],
        "comments": " ",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Real-world multi-agent systems are often dynamic and continuous, where the agents co-evolve and undergo changes in their trajectories and interactions over time. For example, the COVID-19 transmission in the U.S. can be viewed as a multi-agent system, where states act as agents and daily population movements between them are interactions. Estimating the counterfactual outcomes in such systems enables accurate future predictions and effective decision-making, such as formulating COVID-19 policies. However, existing methods fail to model the continuous dynamic effects of treatments on the outcome, especially when multiple treatments (e.g., \"stay-at-home\" and \"get-vaccine\" policies) are applied simultaneously. To tackle this challenge, we propose Causal Graph Ordinary Differential Equations (CAG-ODE), a novel model that captures the continuous interaction among agents using a Graph Neural Network (GNN) as the ODE function. The key innovation of our model is to learn time-dependent representations of treatments and incorporate them into the ODE function, enabling precise predictions of potential outcomes. To mitigate confounding bias, we further propose two domain adversarial learning-based objectives, which enable our model to learn balanced continuous representations that are not affected by treatments or interference. Experiments on two datasets (i.e., COVID-19 and tumor growth) demonstrate the superior performance of our proposed model.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2403.00179": {
        "title": "Counterspeakers' Perspectives: Unveiling Barriers and AI Needs in the Fight against Online Hate",
        "authors": [
            "Jimin Mun",
            "Cathy Buerger",
            "Jenny T. Liang",
            "Joshua Garland",
            "Maarten Sap"
        ],
        "comments": "To appear in CHI 2024. 22 pages, 3 figures, 7 tables",
        "subjects": "Human-Computer Interaction (cs.HC)",
        "abstract": "Counterspeech, i.e., direct responses against hate speech, has become an important tool to address the increasing amount of hate online while avoiding censorship. Although AI has been proposed to help scale up counterspeech efforts, this raises questions of how exactly AI could assist in this process, since counterspeech is a deeply empathetic and agentic process for those involved. In this work, we aim to answer this question, by conducting in-depth interviews with 10 extensively experienced counterspeakers and a large scale public survey with 342 everyday social media users. In participant responses, we identified four main types of barriers and AI needs related to resources, training, impact, and personal harms. However, our results also revealed overarching concerns of authenticity, agency, and functionality in using AI tools for counterspeech. To conclude, we discuss considerations for designing AI assistants that lower counterspeaking barriers without jeopardizing its meaning and purpose.\n    ",
        "primary_category": "cs.HC",
        "categories": [],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2403.00180": {
        "title": "\"Flex Tape Can't Fix That\": Bias and Misinformation in Edited Language Models",
        "authors": [
            "Karina Halevy",
            "Anna Sotnikova",
            "Badr AlKhamissi",
            "Syrielle Montariol",
            "Antoine Bosselut"
        ],
        "comments": "8 pages, 3 figures",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "Model editing has emerged as a cost-effective strategy to update knowledge stored in language models. However, model editing can have unintended consequences after edits are applied: information unrelated to the edits can also be changed, and other general behaviors of the model can be wrongly altered. In this work, we investigate how model editing methods unexpectedly amplify model biases post-edit. We introduce a novel benchmark dataset, Seesaw-CF, for measuring bias-related harms of model editing and conduct the first in-depth investigation of how different weight-editing methods impact model bias. Specifically, we focus on biases with respect to demographic attributes such as race, geographic origin, and gender, as well as qualitative flaws in long-form texts generated by edited language models. We find that edited models exhibit, to various degrees, more biased behavior as they become less confident in attributes for Asian, African, and South American subjects. Furthermore, edited models amplify sexism and xenophobia in text generations while remaining seemingly coherent and logical. Finally, editing facts about place of birth, country of citizenship, or gender have particularly negative effects on the model's knowledge about unrelated features like field of work.\n    ",
        "primary_category": "cs.CL",
        "categories": [],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2403.00182": {
        "title": "SAT, Gadgets, Max2XOR, and Quantum Annealers",
        "authors": [
            "Carlos Ans\u00f3tegui",
            "Jordi Levy"
        ],
        "comments": "arXiv admin note: text overlap with arXiv:2204.01774",
        "subjects": "Quantum Physics (quant-ph)",
        "abstract": "Quantum Annealers are basically quantum computers that with high probability can optimize certain quadratic functions on Boolean variables in constant time. These functions are basically the Hamiltonian of Ising models that reach the ground energy state, with a high probability, after an annealing process. They have been proposed as a way to solve SAT.\nThese Hamiltonians can be seen as Max2XOR problems, i.e. as the problem of finding an assignment that maximizes the number of XOR clauses of at most 2 variables that are satisfied. In this paper, we present several gadgets to reduce SAT to Max2XOR. We show how they can be used to translate SAT instances to initial configurations of a quantum annealer.\n    ",
        "primary_category": "quant-ph",
        "categories": [
            "cs.CC",
            "cs.LO"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2403.00184": {
        "title": "Entry-Specific Bounds for Low-Rank Matrix Completion under Highly Non-Uniform Sampling",
        "authors": [
            "Xumei Xi",
            "Christina Lee Yu",
            "Yudong Chen"
        ],
        "comments": " ",
        "subjects": "Machine Learning (stat.ML)",
        "abstract": "Low-rank matrix completion concerns the problem of estimating unobserved entries in a matrix using a sparse set of observed entries. We consider the non-uniform setting where the observed entries are sampled with highly varying probabilities, potentially with different asymptotic scalings. We show that under structured sampling probabilities, it is often better and sometimes optimal to run estimation algorithms on a smaller submatrix rather than the entire matrix. In particular, we prove error upper bounds customized to each entry, which match the minimax lower bounds under certain conditions. Our bounds characterize the hardness of estimating each entry as a function of the localized sampling probabilities. We provide numerical experiments that confirm our theoretical findings.\n    ",
        "primary_category": "stat.ML",
        "categories": [
            "cs.LG"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2403.00187": {
        "title": "Learning to walk in confined spaces using 3D representation",
        "authors": [
            "Takahiro Miki",
            "Joonho Lee",
            "Lorenz Wellhausen",
            "Marco Hutter"
        ],
        "comments": "Accepted to ICRA 2024",
        "subjects": "Robotics (cs.RO)",
        "abstract": "Legged robots have the potential to traverse complex terrain and access confined spaces beyond the reach of traditional platforms thanks to their ability to carefully select footholds and flexibly adapt their body posture while walking. However, robust deployment in real-world applications is still an open challenge. In this paper, we present a method for legged locomotion control using reinforcement learning and 3D volumetric representations to enable robust and versatile locomotion in confined and unstructured environments. By employing a two-layer hierarchical policy structure, we exploit the capabilities of a highly robust low-level policy to follow 6D commands and a high-level policy to enable three-dimensional spatial awareness for navigating under overhanging obstacles. Our study includes the development of a procedural terrain generator to create diverse training environments. We present a series of experimental evaluations in both simulation and real-world settings, demonstrating the effectiveness of our approach in controlling a quadruped robot in confined, rough terrain. By achieving this, our work extends the applicability of legged robots to a broader range of scenarios.\n    ",
        "primary_category": "cs.RO",
        "categories": [],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2403.00188": {
        "title": "Impact of Decentralized Learning on Player Utilities in Stackelberg Games",
        "authors": [
            "Kate Donahue",
            "Nicole Immorlica",
            "Meena Jagadeesan",
            "Brendan Lucier",
            "Aleksandrs Slivkins"
        ],
        "comments": " ",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "When deployed in the world, a learning agent such as a recommender system or a chatbot often repeatedly interacts with another learning agent (such as a user) over time. In many such two-agent systems, each agent learns separately and the rewards of the two agents are not perfectly aligned. To better understand such cases, we examine the learning dynamics of the two-agent system and the implications for each agent's objective. We model these systems as Stackelberg games with decentralized learning and show that standard regret benchmarks (such as Stackelberg equilibrium payoffs) result in worst-case linear regret for at least one player. To better capture these systems, we construct a relaxed regret benchmark that is tolerant to small learning errors by agents. We show that standard learning algorithms fail to provide sublinear regret, and we develop algorithms to achieve near-optimal $O(T^{2/3})$ regret for both players with respect to these benchmarks. We further design relaxed environments under which faster learning ($O(\\sqrt{T})$) is possible. Altogether, our results take a step towards assessing how two-agent interactions in sequential and decentralized learning environments affect the utility of both agents.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.GT"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2403.00189": {
        "title": "The Road to Next-Generation Multiple Access: A 50-Year Tutorial Review",
        "authors": [
            "Yuanwei Liu",
            "Chongjun Ouyang",
            "Zhiguo Ding",
            "Robert Schober"
        ],
        "comments": "43 pages, 38 figures; Submitted to Proceedings of the IEEE",
        "subjects": "Information Theory (cs.IT)",
        "abstract": "The evolution of wireless communications has been significantly influenced by remarkable advancements in multiple access (MA) technologies over the past five decades, shaping the landscape of modern connectivity. Within this context, a comprehensive tutorial review is presented, focusing on representative MA techniques developed over the past 50 years. The following areas are explored: i) The foundational principles and information-theoretic capacity limits of power-domain non-orthogonal multiple access (NOMA) are characterized, along with its extension to multiple-input multiple-output (MIMO)-NOMA. ii) Several MA transmission schemes exploiting the spatial domain are investigated, encompassing both conventional space-division multiple access (SDMA)/MIMO-NOMA systems and near-field MA systems utilizing spherical-wave propagation models. iii) The application of NOMA to integrated sensing and communications (ISAC) systems is studied. This includes an introduction to typical NOMA-based downlink/uplink ISAC frameworks, followed by an evaluation of their performance limits using a mutual information (MI)-based analytical framework. iv) Major issues and research opportunities associated with the integration of MA with other emerging technologies are identified to facilitate MA in next-generation networks, i.e., next-generation multiple access (NGMA). Throughout the paper, promising directions are highlighted to inspire future research endeavors in the realm of MA and NGMA.\n    ",
        "primary_category": "cs.IT",
        "categories": [
            "eess.SP"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2403.00190": {
        "title": "Identification of important nodes in the information propagation network based on the artificial intelligence method",
        "authors": [
            "Bin Yuan",
            "Tianbo Song",
            "Jerry Yao"
        ],
        "comments": " ",
        "subjects": "Social and Information Networks (cs.SI)",
        "abstract": "This study presents an integrated approach for identifying key nodes in information propagation networks using advanced artificial intelligence methods. We introduce a novel technique that combines the Decision-making Trial and Evaluation Laboratory (DEMATEL) method with the Global Structure Model (GSM), creating a synergistic model that effectively captures both local and global influences within a network. This method is applied across various complex networks, such as social, transportation, and communication systems, utilizing the Global Network Influence Dataset (GNID). Our analysis highlights the structural dynamics and resilience of these networks, revealing insights into node connectivity and community formation. The findings demonstrate the effectiveness of our AI-based approach in offering a comprehensive understanding of network behavior, contributing significantly to strategic network analysis and optimization.\n    ",
        "primary_category": "cs.SI",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2403.00192": {
        "title": "Block-MDS QC-LDPC Codes for Information Reconciliation in Key Distribution",
        "authors": [
            "Lev Tauz",
            "Debarnab Mitra",
            "Jayanth Shreekumar",
            "Murat Can Sarihan",
            "Chee Wei Wong",
            "Lara Dolecek"
        ],
        "comments": "7 pages, 1 figure, submitted to the International Symposium on Information Theory (ISIT) 2024",
        "subjects": "Information Theory (cs.IT)",
        "abstract": "Quantum key distribution (QKD) is a popular protocol that provides information theoretically secure keys to multiple parties. Two important post-processing steps of QKD are 1) the information reconciliation (IR) step, where parties reconcile mismatches in generated keys through classical communication, and 2) the privacy amplification (PA) step, where parties distill their common key into a new secure key that the adversary has little to no information about. In general, these two steps have been abstracted as two distinct problems. In this work, we consider a new technique of performing the IR and PA steps jointly through sampling that relaxes the requirement on the IR step, allowing for more success in key creation. We provide a novel LDPC code construction known as Block-MDS QC-LDPC codes that can utilize the relaxed requirement by creating LDPC codes with pre-defined sub-matrices of full-rank. We demonstrate through simulations that our technique of sampling can provide notable gains in successfully creating secret keys.\n    ",
        "primary_category": "cs.IT",
        "categories": [],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2403.00193": {
        "title": "Structural Resilience and Connectivity of the IPv6 Internet: An AS-level Topology Examination",
        "authors": [
            "Bin Yuan",
            "Tianbo Song"
        ],
        "comments": " ",
        "subjects": "Networking and Internet Architecture (cs.NI)",
        "abstract": "The study utilizes a comprehensive dataset informed by IPv6 routing information to provide statistics, degree distribution, joint degree distribution, and clustering analysis of the IPv6 Internet's structure and resilience.The dataset includes 17,232 unique ASes and 10,000 unique IPv6 prefixes. Analysis reveals an interconnected network with an average path length of approximately 3 hops, suggesting a robust and efficient network with potential redundancy and resilience, despite some isolated components. The paper outlines the degree distribution, indicating many peripheral nodes in a sparse network, and a clustering analysis showing a tendency for ASes to form clusters, which is indicative of redundancy and robustness against failures. The connectivity analysis, including path redundancy and reachability, supports the network's resilience.The findings are crucial for network design and strategic planning, particularly as IPv6 adoption increases. The paper emphasizes the importance of continuous monitoring and improvement of network connectivity in the evolving Internet landscape, highlighting the IPv6 Internet's resilience and structured connectivity.\n    ",
        "primary_category": "cs.NI",
        "categories": [
            "cs.CR"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2403.00194": {
        "title": "Ask Your Distribution Shift if Pre-Training is Right for You",
        "authors": [
            "Benjamin Cohen-Wang",
            "Joshua Vendrow",
            "Aleksander Madry"
        ],
        "comments": " ",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Pre-training is a widely used approach to develop models that are robust to distribution shifts. However, in practice, its effectiveness varies: fine-tuning a pre-trained model improves robustness significantly in some cases but not at all in others (compared to training from scratch). In this work, we seek to characterize the failure modes that pre-training can and cannot address. In particular, we focus on two possible failure modes of models under distribution shift: poor extrapolation (e.g., they cannot generalize to a different domain) and biases in the training data (e.g., they rely on spurious features). Our study suggests that, as a rule of thumb, pre-training can help mitigate poor extrapolation but not dataset biases. After providing theoretical motivation and empirical evidence for this finding, we explore two of its implications for developing robust models: (1) pre-training and interventions designed to prevent exploiting biases have complementary robustness benefits, and (2) fine-tuning on a (very) small, non-diverse but de-biased dataset can result in significantly more robust models than fine-tuning on a large and diverse but biased dataset. Code is available at this https URL.\n    ",
        "primary_category": "cs.LG",
        "categories": [],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2403.00196": {
        "title": "Learning to Find Missing Video Frames with Synthetic Data Augmentation: A General Framework and Application in Generating Thermal Images Using RGB Cameras",
        "authors": [
            "Mathias Viborg Andersen",
            "Ross Greer",
            "Andreas M\u00f8gelmose",
            "Mohan Trivedi"
        ],
        "comments": " ",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Advanced Driver Assistance Systems (ADAS) in intelligent vehicles rely on accurate driver perception within the vehicle cabin, often leveraging a combination of sensing modalities. However, these modalities operate at varying rates, posing challenges for real-time, comprehensive driver state monitoring. This paper addresses the issue of missing data due to sensor frame rate mismatches, introducing a generative model approach to create synthetic yet realistic thermal imagery. We propose using conditional generative adversarial networks (cGANs), specifically comparing the pix2pix and CycleGAN architectures. Experimental results demonstrate that pix2pix outperforms CycleGAN, and utilizing multi-view input styles, especially stacked views, enhances the accuracy of thermal image generation. Moreover, the study evaluates the model's generalizability across different subjects, revealing the importance of individualized training for optimal performance. The findings suggest the potential of generative models in addressing missing frames, advancing driver state monitoring for intelligent vehicles, and underscoring the need for continued research in model generalization and customization.\n    ",
        "primary_category": "cs.CV",
        "categories": [
            "cs.AI",
            "cs.LG"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2403.00198": {
        "title": "AXOLOTL: Fairness through Assisted Self-Debiasing of Large Language Model Outputs",
        "authors": [
            "Sana Ebrahimi",
            "Kaiwen Chen",
            "Abolfazl Asudeh",
            "Gautam Das",
            "Nick Koudas"
        ],
        "comments": " ",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "Pre-trained Large Language Models (LLMs) have significantly advanced natural language processing capabilities but are susceptible to biases present in their training data, leading to unfair outcomes in various applications. While numerous strategies have been proposed to mitigate bias, they often require extensive computational resources and may compromise model performance. In this work, we introduce AXOLOTL, a novel post-processing framework, which operates agnostically across tasks and models, leveraging public APIs to interact with LLMs without direct access to internal parameters. Through a three-step process resembling zero-shot learning, AXOLOTL identifies biases, proposes resolutions, and guides the model to self-debias its outputs. This approach minimizes computational costs and preserves model performance, making AXOLOTL a promising tool for debiasing LLM outputs with broad applicability and ease of use.\n    ",
        "primary_category": "cs.CL",
        "categories": [
            "cs.AI",
            "cs.CY",
            "cs.LG"
        ],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00206": {
        "title": "MaskLRF: Self-supervised Pretraining via Masked Autoencoding of Local Reference Frames for Rotation-invariant 3D Point Set Analysis",
        "authors": [
            "Takahiko Furuya"
        ],
        "comments": " ",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Following the successes in the fields of vision and language, self-supervised pretraining via masked autoencoding of 3D point set data, or Masked Point Modeling (MPM), has achieved state-of-the-art accuracy in various downstream tasks. However, current MPM methods lack a property essential for 3D point set analysis, namely, invariance against rotation of 3D objects/scenes. Existing MPM methods are thus not necessarily suitable for real-world applications where 3D point sets may have inconsistent orientations. This paper develops, for the first time, a rotation-invariant self-supervised pretraining framework for practical 3D point set analysis. The proposed algorithm, called MaskLRF, learns rotation-invariant and highly generalizable latent features via masked autoencoding of 3D points within Local Reference Frames (LRFs), which are not affected by rotation of 3D point sets. MaskLRF enhances the quality of latent features by integrating feature refinement using relative pose encoding and feature reconstruction using low-level but rich 3D geometry. The efficacy of MaskLRF is validated via extensive experiments on diverse downstream tasks including classification, segmentation, registration, and domain adaptation. I confirm that MaskLRF achieves new state-of-the-art accuracies in analyzing 3D point sets having inconsistent orientations. Code will be available at: this https URL\n",
        "primary_category": "cs.CV",
        "categories": [],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00207": {
        "title": "Yodel: A Layer 3.5 Name-Based Multicast Network Architecture For The Future Internet",
        "authors": [
            "Morteza Moghaddassian",
            "Alberto Leon-Garcia"
        ],
        "comments": "Contains animated figures",
        "subjects": "Networking and Internet Architecture (cs.NI)",
        "abstract": "Multicasting refers to the ability of transmitting data to multiple recipients without data sources needing to provide more than one copy of the data to the network. The network takes responsibility to route and deliver a copy of each data to every intended recipient. Multicasting has the potential to improve the network efficiency and performance (e.g., throughput and latency) through transferring fewer bits in communicating the same data to multiple recipients compared with unicast transmissions, reduce the amount of networking resources needed for communication, lower the network energy footprint, and alleviate the occurrence of congestion in the network. Over the past few decades, providing multicast services has been a real challenge for ISPs, especially to support home users and multi-domain network applications, leading to the emergence of complex application-level solutions. These solutions like Content Delivery and Peer-to-Peer networks take advantage of complex caching, routing, transport, and topology management systems which put heavy strains on the underlying Internet infrastructures to offer multicasting services. In reality, the main motivation behind the design of these systems is rather sharing content than offering efficient multicast services. In this paper, we propound Yodel, a name-based multicast network architecture that can provide multi-domain multicast services for current and future Internet applications. Compared to the wider array of other name-based network architectures with clean-slate infrastructure requirements, Yodel is designed to provide multicast services over the current Internet infrastructure. Hence, Yodel puts forward several design goals that distinguish it from other name-based network architectures with inherent multicast capabilities. This paper is prepared to discuss the Yodel architecture, its design goals, and architectural functions.\n    ",
        "primary_category": "cs.NI",
        "categories": [],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00212": {
        "title": "Transcription and translation of videos using fine-tuned XLSR Wav2Vec2 on custom dataset and mBART",
        "authors": [
            "Aniket Tathe",
            "Anand Kamble",
            "Suyash Kumbharkar",
            "Atharva Bhandare",
            "Anirban C. Mitra"
        ],
        "comments": " ",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "This research addresses the challenge of training an ASR model for personalized voices with minimal data. Utilizing just 14 minutes of custom audio from a YouTube video, we employ Retrieval-Based Voice Conversion (RVC) to create a custom Common Voice 16.0 corpus. Subsequently, a Cross-lingual Self-supervised Representations (XLSR) Wav2Vec2 model is fine-tuned on this dataset. The developed web-based GUI efficiently transcribes and translates input Hindi videos. By integrating XLSR Wav2Vec2 and mBART, the system aligns the translated text with the video timeline, delivering an accessible solution for multilingual video content transcription and translation for personalized voice.\n    ",
        "primary_category": "cs.CL",
        "categories": [
            "cs.CV",
            "cs.LG",
            "cs.SD",
            "eess.AS"
        ],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00219": {
        "title": "Multi-modal Attribute Prompting for Vision-Language Models",
        "authors": [
            "Xin Liu",
            "Jiamin Wu",
            "Tianzhu Zhang"
        ],
        "comments": " ",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Large pre-trained Vision-Language Models (VLMs), like CLIP, exhibit strong generalization ability to downstream tasks but struggle in few-shot scenarios. Existing prompting techniques primarily focus on global text and image representations, yet overlooking multi-modal attribute characteristics. This limitation hinders the model's ability to perceive fine-grained visual details and restricts its generalization ability to a broader range of unseen classes. To address this issue, we propose a Multi-modal Attribute Prompting method (MAP) by jointly exploring textual attribute prompting, visual attribute prompting, and attribute-level alignment. The proposed MAP enjoys several merits. First, we introduce learnable visual attribute prompts enhanced by textual attribute semantics to adaptively capture visual attributes for images from unknown categories, boosting fine-grained visual perception capabilities for CLIP. Second, the proposed attribute-level alignment complements the global alignment to enhance the robustness of cross-modal alignment for open-vocabulary objects. To our knowledge, this is the first work to establish cross-modal attribute-level alignment for CLIP-based few-shot adaptation. Extensive experimental results on 11 datasets demonstrate that our method performs favorably against state-of-the-art approaches.\n    ",
        "primary_category": "cs.CV",
        "categories": [],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00221": {
        "title": "Mode Consensus Algorithms With Finite Convergence Time",
        "authors": [
            "Chao Huang",
            "Hyungbo Shim",
            "Siliang Yu",
            "Brian D. O. Anderson"
        ],
        "comments": " ",
        "subjects": "Systems and Control (eess.SY)",
        "abstract": "This paper studies the distributed mode consensus problem in a multi-agent system, in which the agents each possess a certain attribute and they aim to agree upon the mode (the most frequent attribute owned by the agents) via distributed computation. Three algorithms are proposed. The first one directly calculates the frequency of all attributes at every agent, with protocols based on blended dynamics, and then returns the most frequent attribute as the mode. Assuming knowledge at each agent of a lower bound of the mode frequency as a priori information, the second algorithm is able to reduce the number of frequencies to be computed at every agent if the lower bound is large. The third algorithm further eliminates the need for this information by introducing an adaptive updating mechanism. The algorithms find the mode in finite time, and estimates of convergence time are provided. The proposed first and second algorithms enjoy the plug-and-play property with a dwell time.\n    ",
        "primary_category": "eess.SY",
        "categories": [],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00222": {
        "title": "Efficient Reinforcement Learning for Global Decision Making in the Presence of Local Agents at Scale",
        "authors": [
            "Emile Anand",
            "Guannan Qu"
        ],
        "comments": "30 pages, 6 figures",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "We study reinforcement learning for global decision-making in the presence of many local agents, where the global decision-maker makes decisions affecting all local agents, and the objective is to learn a policy that maximizes the rewards of both the global and the local agents. Such problems find many applications, e.g. demand response, EV charging, queueing, etc. In this setting, scalability has been a long-standing challenge due to the size of the state/action space which can be exponential in the number of agents. This work proposes the SUB-SAMPLE-Q algorithm where the global agent subsamples $k\\leq n$ local agents to compute an optimal policy in time that is only exponential in $k$, providing an exponential speedup from standard methods that are exponential in $n$. We show that the learned policy converges to the optimal policy in the order of $\\tilde{O}(1/\\sqrt{k}+\\epsilon_{k,m})$ as the number of sub-sampled agents $k$ increases, where $\\epsilon_{k,m}$ is the Bellman noise. We also conduct numerical simulations in a demand-response setting and a queueing setting.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.MA"
        ],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00228": {
        "title": "DISORF: A Distributed Online NeRF Training and Rendering Framework for Mobile Robots",
        "authors": [
            "Chunlin Li",
            "Ruofan Liang",
            "Hanrui Fan",
            "Zhengen Zhang",
            "Sankeerth Durvasula",
            "Nandita Vijaykumar"
        ],
        "comments": " ",
        "subjects": "Robotics (cs.RO)",
        "abstract": "We present a framework, DISORF, to enable online 3D reconstruction and visualization of scenes captured by resource-constrained mobile robots and edge devices. To address the limited compute capabilities of edge devices and potentially limited network availability, we design a framework that efficiently distributes computation between the edge device and remote server. We leverage on-device SLAM systems to generate posed keyframes and transmit them to remote servers that can perform high quality 3D reconstruction and visualization at runtime by leveraging NeRF models. We identify a key challenge with online NeRF training where naive image sampling strategies can lead to significant degradation in rendering quality. We propose a novel shifted exponential frame sampling method that addresses this challenge for online NeRF training. We demonstrate the effectiveness of our framework in enabling high-quality real-time reconstruction and visualization of unknown scenes as they are captured and streamed from cameras in mobile robots and edge devices.\n    ",
        "primary_category": "cs.RO",
        "categories": [
            "cs.CV"
        ],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00229": {
        "title": "Diffraction and Scattering Aware Radio Map and Environment Reconstruction using Geometry Model-Assisted Deep Learning",
        "authors": [
            "Wangqian Chen",
            "Junting Chen"
        ],
        "comments": "13 pages",
        "subjects": "Signal Processing (eess.SP)",
        "abstract": "Machine learning (ML) facilitates rapid channel modeling for 5G and beyond wireless communication systems. Many existing ML techniques utilize a city map to construct the radio map; however, an updated city map may not always be available. This paper proposes to employ the received signal strength (RSS) data to jointly construct the radio map and the virtual environment by exploiting the geometry structure of the environment. In contrast to many existing ML approaches that lack of an environment model, we develop a virtual obstacle model and characterize the geometry relation between the propagation paths and the virtual obstacles. A multi-screen knife-edge model is adopted to extract the key diffraction features, and these features are fed into a neural network (NN) for diffraction representation. To describe the scattering, as oppose to most existing methods that directly input an entire city map, our model focuses on the geometry structure from the local area surrounding the TX-RX pair and the spatial invariance of such local geometry structure is exploited. Numerical experiments demonstrate that, in addition to reconstructing a 3D virtual environment, the proposed model outperforms the state-of-the-art methods in radio map construction with 10%-18% accuracy improvements. It can also reduce 20% data and 50% training epochs when transferred to a new environment.\n    ",
        "primary_category": "eess.SP",
        "categories": [
            "cs.LG"
        ],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00231": {
        "title": "Multimodal ArXiv: A Dataset for Improving Scientific Comprehension of Large Vision-Language Models",
        "authors": [
            "Lei Li",
            "Yuqi Wang",
            "Runxin Xu",
            "Peiyi Wang",
            "Xiachong Feng",
            "Lingpeng Kong",
            "Qi Liu"
        ],
        "comments": "Project page: this https URL Fix typos",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Large vision-language models (LVLMs), exemplified by GPT-4V, excel across diverse tasks involving concrete images from natural scenes. However, their ability to interpret abstract figures, such as geometry shapes and scientific plots, remains limited due to a scarcity of training datasets in scientific domains. To fill this gap, we introduce Multimodal ArXiv, consisting of ArXivCap and ArXivQA, for enhancing LVLMs scientific comprehension. ArXivCap is a figure-caption dataset comprising 6.4M images and 3.9M captions sourced from 572K ArXiv papers spanning various scientific domains. Drawing from ArXivCap, we introduce ArXivQA, a question-answering dataset generated by prompting GPT-4V based on scientific figures. ArXivQA greatly enhances LVLMs' mathematical reasoning capabilities, achieving a 10.4% absolute accuracy gain on a multimodal mathematical reasoning benchmark. Furthermore, employing ArXivCap, we devise four vision-to-text tasks for benchmarking LVLMs. Evaluation results with state-of-the-art LVLMs underscore their struggle with the nuanced semantics of academic figures, with domain-specific training yielding substantial performance gains. Our error analysis uncovers misinterpretations of visual context, recognition errors, and the production of overly simplified captions by current LVLMs, shedding light on future improvements.\n    ",
        "primary_category": "cs.CV",
        "categories": [
            "cs.CL"
        ],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00232": {
        "title": "FTTN: Feature-Targeted Testing for Numerical Properties of NVIDIA & AMD Matrix Accelerators",
        "authors": [
            "Xinyi Li",
            "Ang Li",
            "Bo Fang",
            "Katarzyna Swirydowicz",
            "Ignacio Laguna",
            "Ganesh Gopalakrishnan"
        ],
        "comments": " ",
        "subjects": "Hardware Architecture (cs.AR)",
        "abstract": "NVIDIA Tensor Cores and AMD Matrix Cores (together called Matrix Accelerators) are of growing interest in high-performance computing and machine learning owing to their high performance. Unfortunately, their numerical behaviors are not publicly documented, including the number of extra precision bits maintained, the accumulation order of addition, and predictable subnormal number handling during computations. This makes it impossible to reliably port codes across these differing accelerators. This paper contributes a collection of {\\em Feature Targeted Tests for Numerical Properties} that that help determine these features across five floating-point formats, four rounding modes and additional that highlight the rounding behaviors and preservation of extra precision bits. To show the practical relevance of FTTN, we design a simple matrix-multiplication test designed with insights gathered from our feature-tests. We executed this very simple test on five platforms, producing different answers: V100, A100, and MI250X produced 0, MI100 produced 255.875, and Hopper H100 produced 191.875. Our matrix multiplication tests employ patterns found in iterative refinement-based algorithms, highlighting the need to check for significant result variability when porting code across GPUs.\n    ",
        "primary_category": "cs.AR",
        "categories": [],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00233": {
        "title": "Causal Bandits with General Causal Models and Interventions",
        "authors": [
            "Zirui Yan",
            "Dennis Wei",
            "Dmitriy Katz-Rogozhnikov",
            "Prasanna Sattigeri",
            "Ali Tajer"
        ],
        "comments": "37 pages, 13 figures, conference",
        "subjects": "Machine Learning (stat.ML)",
        "abstract": "This paper considers causal bandits (CBs) for the sequential design of interventions in a causal system. The objective is to optimize a reward function via minimizing a measure of cumulative regret with respect to the best sequence of interventions in hindsight. The paper advances the results on CBs in three directions. First, the structural causal models (SCMs) are assumed to be unknown and drawn arbitrarily from a general class $\\mathcal{F}$ of Lipschitz-continuous functions. Existing results are often focused on (generalized) linear SCMs. Second, the interventions are assumed to be generalized soft with any desired level of granularity, resulting in an infinite number of possible interventions. The existing literature, in contrast, generally adopts atomic and hard interventions. Third, we provide general upper and lower bounds on regret. The upper bounds subsume (and improve) known bounds for special cases. The lower bounds are generally hitherto unknown. These bounds are characterized as functions of the (i) graph parameters, (ii) eluder dimension of the space of SCMs, denoted by $\\operatorname{dim}(\\mathcal{F})$, and (iii) the covering number of the function space, denoted by ${\\rm cn}(\\mathcal{F})$. Specifically, the cumulative achievable regret over horizon $T$ is $\\mathcal{O}(K d^{L-1}\\sqrt{T\\operatorname{dim}(\\mathcal{F}) \\log({\\rm cn}(\\mathcal{F}))})$, where $K$ is related to the Lipschitz constants, $d$ is the graph's maximum in-degree, and $L$ is the length of the longest causal path. The upper bound is further refined for special classes of SCMs (neural network, polynomial, and linear), and their corresponding lower bounds are provided.\n    ",
        "primary_category": "stat.ML",
        "categories": [
            "cs.LG"
        ],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00236": {
        "title": "Benchmarking zero-shot stance detection with FlanT5-XXL: Insights from training data, prompting, and decoding strategies into its near-SoTA performance",
        "authors": [
            "Rachith Aiyappa",
            "Shruthi Senthilmani",
            "Jisun An",
            "Haewoon Kwak",
            "Yong-Yeol Ahn"
        ],
        "comments": " ",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "We investigate the performance of LLM-based zero-shot stance detection on tweets. Using FlanT5-XXL, an instruction-tuned open-source LLM, with the SemEval 2016 Tasks 6A, 6B, and P-Stance datasets, we study the performance and its variations under different prompts and decoding strategies, as well as the potential biases of the model. We show that the zero-shot approach can match or outperform state-of-the-art benchmarks, including fine-tuned models. We provide various insights into its performance including the sensitivity to instructions and prompts, the decoding strategies, the perplexity of the prompts, and to negations and oppositions present in prompts. Finally, we ensure that the LLM has not been trained on test datasets, and identify a positivity bias which may partially explain the performance differences across decoding strategie\n    ",
        "primary_category": "cs.CL",
        "categories": [
            "cs.AI",
            "cs.LG"
        ],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00239": {
        "title": "OPAF: Optimized Secure Two-Party Computation Protocols for Nonlinear Activation Functions in Recurrent Neural Network",
        "authors": [
            "Qian Feng",
            "Zhihua Xia",
            "Zhifeng Xu",
            "Jiasi Weng",
            "Jian Weng"
        ],
        "comments": " ",
        "subjects": "Cryptography and Security (cs.CR)",
        "abstract": "Deep neural network (DNN) typically involves convolutions, pooling, and activation function. Due to the growing concern about privacy, privacy-preserving DNN becomes a hot research topic. Generally, the convolution and pooling operations can be supported by additive homomorphic and secure comparison, but the secure implementation of activation functions is not so straightforward for the requirements of accuracy and efficiency, especially for the non-linear ones such as exponential, sigmoid, and tanh functions. This paper pays a special attention to the implementation of such non-linear functions in semi-honest model with two-party settings, for which SIRNN is the current state-of-the-art. Different from previous works, we proposed improved implementations for these functions by using their intrinsic features as well as worthy tiny tricks. At first, we propose a novel and efficient protocol for exponential function by using a divide-and-conquer strategy with most of the computations executed locally. Exponential protocol is widely used in machine learning tasks such as Poisson regression, and is also a key component of sigmoid and tanh functions. Next, we take advantage of the symmetry of sigmoid and Tanh, and fine-tune the inputs to reduce the 2PC building blocks, which helps to save overhead and improve performance. As a result, we implement these functions with fewer fundamental building blocks. The comprehensive evaluations show that our protocols achieve state-of-the-art precision while reducing run-time by approximately 57%, 44%, and 42% for exponential (with only negative inputs), sigmoid, and Tanh functions, respectively.\n    ",
        "primary_category": "cs.CR",
        "categories": [],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00245": {
        "title": "YOLO-MED : Multi-Task Interaction Network for Biomedical Images",
        "authors": [
            "Suizhi Huang",
            "Shalayiding Sirejiding",
            "Yuxiang Lu",
            "Yue Ding",
            "Leheng Liu",
            "Hui Zhou",
            "Hongtao Lu"
        ],
        "comments": "Accepted by ICASSP 2024",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Object detection and semantic segmentation are pivotal components in biomedical image analysis. Current single-task networks exhibit promising outcomes in both detection and segmentation tasks. Multi-task networks have gained prominence due to their capability to simultaneously tackle segmentation and detection tasks, while also accelerating the segmentation inference. Nevertheless, recent multi-task networks confront distinct limitations such as the difficulty in striking a balance between accuracy and inference speed. Additionally, they often overlook the integration of cross-scale features, which is especially important for biomedical image analysis. In this study, we propose an efficient end-to-end multi-task network capable of concurrently performing object detection and semantic segmentation called YOLO-Med. Our model employs a backbone and a neck for multi-scale feature extraction, complemented by the inclusion of two task-specific decoders. A cross-scale task-interaction module is employed in order to facilitate information fusion between various tasks. Our model exhibits promising results in balancing accuracy and speed when evaluated on the Kvasir-seg dataset and a private biomedical image dataset.\n    ",
        "primary_category": "cs.CV",
        "categories": [],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00246": {
        "title": "Analysis of Phylogeny Tracking Algorithms for Serial and Multiprocess Applications",
        "authors": [
            "Matthew Andres Moreno",
            "Santiago Rodriguez Papa",
            "Emily Dolson"
        ],
        "comments": " ",
        "subjects": "Data Structures and Algorithms (cs.DS)",
        "abstract": "Since the advent of modern bioinformatics, the challenging, multifaceted problem of reconstructing phylogenetic history from biological sequences has hatched perennial statistical and algorithmic innovation. Studies of the phylogenetic dynamics of digital, agent-based evolutionary models motivate a peculiar converse question: how to best engineer tracking to facilitate fast, accurate, and memory-efficient lineage reconstructions? Here, we formally describe procedures for phylogenetic analysis in both serial and distributed computing scenarios. With respect to the former, we demonstrate reference-counting-based pruning of extinct lineages. For the latter, we introduce a trie-based phylogenetic reconstruction approach for \"hereditary stratigraphy\" genome annotations. This process allows phylogenetic relationships between genomes to be inferred by comparing their similarities, akin to reconstruction of natural history from biological DNA sequences. Phylogenetic analysis capabilities significantly advance distributed agent-based simulations as a tool for evolutionary research, and also benefit application-oriented evolutionary computing. Such tracing could extend also to other digital artifacts that proliferate through replication, like digital media and computer viruses.\n    ",
        "primary_category": "cs.DS",
        "categories": [
            "q-bio.PE"
        ],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00249": {
        "title": "Semantics-enhanced Cross-modal Masked Image Modeling for Vision-Language Pre-training",
        "authors": [
            "Haowei Liu",
            "Yaya Shi",
            "Haiyang Xu",
            "Chunfeng Yuan",
            "Qinghao Ye",
            "Chenliang Li",
            "Ming Yan",
            "Ji Zhang",
            "Fei Huang",
            "Bing Li",
            "Weiming Hu"
        ],
        "comments": "Accepted to LREC-COLING 2024",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "In vision-language pre-training (VLP), masked image modeling (MIM) has recently been introduced for fine-grained cross-modal alignment. However, in most existing methods, the reconstruction targets for MIM lack high-level semantics, and text is not sufficiently involved in masked modeling. These two drawbacks limit the effect of MIM in facilitating cross-modal semantic alignment. In this work, we propose a semantics-enhanced cross-modal MIM framework (SemMIM) for vision-language representation learning. Specifically, to provide more semantically meaningful supervision for MIM, we propose a local semantics enhancing approach, which harvest high-level semantics from global image features via self-supervised agreement learning and transfer them to local patch encodings by sharing the encoding space. Moreover, to achieve deep involvement of text during the entire MIM process, we propose a text-guided masking strategy and devise an efficient way of injecting textual information in both masked modeling and reconstruction target acquisition. Experimental results validate that our method improves the effectiveness of the MIM task in facilitating cross-modal semantic alignment. Compared to previous VLP models with similar model size and data scale, our SemMIM model achieves state-of-the-art or competitive performance on multiple downstream vision-language tasks.\n    ",
        "primary_category": "cs.CV",
        "categories": [],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00250": {
        "title": "Rethinking Classifier Re-Training in Long-Tailed Recognition: A Simple Logits Retargeting Approach",
        "authors": [
            "Han Lu",
            "Siyu Sun",
            "Yichen Xie",
            "Liqing Zhang",
            "Xiaokang Yang",
            "Junchi Yan"
        ],
        "comments": " ",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "In the long-tailed recognition field, the Decoupled Training paradigm has demonstrated remarkable capabilities among various methods. This paradigm decouples the training process into separate representation learning and classifier re-training. Previous works have attempted to improve both stages simultaneously, making it difficult to isolate the effect of classifier re-training. Furthermore, recent empirical studies have demonstrated that simple regularization can yield strong feature representations, emphasizing the need to reassess existing classifier re-training methods. In this study, we revisit classifier re-training methods based on a unified feature representation and re-evaluate their performances. We propose a new metric called Logits Magnitude as a superior measure of model performance, replacing the commonly used Weight Norm. However, since it is hard to directly optimize the new metric during training, we introduce a suitable approximate invariant called Regularized Standard Deviation. Based on the two newly proposed metrics, we prove that reducing the absolute value of Logits Magnitude when it is nearly balanced can effectively decrease errors and disturbances during training, leading to better model performance. Motivated by these findings, we develop a simple logits retargeting approach (LORT) without the requirement of prior knowledge of the number of samples per class. LORT divides the original one-hot label into small true label probabilities and large negative label probabilities distributed across each class. Our method achieves state-of-the-art performance on various imbalanced datasets, including CIFAR100-LT, ImageNet-LT, and iNaturalist2018.\n    ",
        "primary_category": "cs.CV",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00251": {
        "title": "Are your comments outdated? Towards automatically detecting code-comment consistency",
        "authors": [
            "Yuan Huang",
            "Yinan Chen",
            "Xiangping Chen",
            "Xiaocong Zhou"
        ],
        "comments": " ",
        "subjects": "Software Engineering (cs.SE)",
        "abstract": "In software development and maintenance, code comments can help developers understand source code, and improve communication among developers. However, developers sometimes neglect to update the corresponding comment when changing the code, resulting in outdated comments (i.e., inconsistent codes and comments). Outdated comments are dangerous and harmful and may mislead subsequent developers. More seriously, the outdated comments may lead to a fatal flaw sometime in the future. To automatically identify the outdated comments in source code, we proposed a learning-based method, called CoCC, to detect the consistency between code and comment. To efficiently identify outdated comments, we extract multiple features from both codes and comments before and after they change. Besides, we also consider the relation between code and comment in our model. Experiment results show that CoCC can effectively detect outdated comments with precision over 90%. In addition, we have identified the 15 most important factors that cause outdated comments, and verified the applicability of CoCC in different programming languages. We also used CoCC to find outdated comments in the latest commits of open source projects, which further proves the effectiveness of the proposed method.\n    ",
        "primary_category": "cs.SE",
        "categories": [],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00252": {
        "title": "EUROPA: A Legal Multilingual Keyphrase Generation Dataset",
        "authors": [
            "Olivier Sala\u00fcn",
            "Fr\u00e9d\u00e9ric Piedboeuf",
            "Guillaume Le Berre",
            "David Alfonso Hermelo",
            "Philippe Langlais"
        ],
        "comments": "8 pages",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "Keyphrase generation has primarily been explored within the context of academic research articles, with a particular focus on scientific domains and the English language. In this work, we present EUROPA, a dataset for multilingual keyphrase generation in the legal domain. It is derived from legal judgments from the Court of Justice of the European Union (EU), and contains instances in all 24 EU official languages. We run multilingual models on our corpus and analyze the results, showing room for improvement on a domain-specific multilingual corpus such as the one we present.\n    ",
        "primary_category": "cs.CL",
        "categories": [
            "cs.AI",
            "cs.LG"
        ],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00254": {
        "title": "Cloud-based Federated Learning Framework for MRI Segmentation",
        "authors": [
            "Rukesh Prajapati",
            "Amr S. El-Wakeel"
        ],
        "comments": " ",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "In contemporary rural healthcare settings, the principal challenge in diagnosing brain images is the scarcity of available data, given that most of the existing deep learning models demand extensive training data to optimize their performance, necessitating centralized processing methods that potentially compromise data privacy. This paper proposes a novel framework tailored for brain tissue segmentation in rural healthcare facilities. The framework employs a deep reinforcement learning (DRL) environment in tandem with a refinement model (RM) deployed locally at rural healthcare sites. The proposed DRL model has a reduced parameter count and practicality for implementation across distributed rural sites. To uphold data privacy and enhance model generalization without transgressing privacy constraints, we employ federated learning (FL) for cooperative model training. We demonstrate the efficacy of our approach by training the network with a limited data set and observing a substantial performance enhancement, mitigating inaccuracies and irregularities in segmentation across diverse sites. Remarkably, the DRL model attains an accuracy of up to 80%, surpassing the capabilities of conventional convolutional neural networks when confronted with data insufficiency. Incorporating our RM results in an additional accuracy improvement of at least 10%, while FL contributes to a further accuracy enhancement of up to 5%. Collectively, the framework achieves an average 92% accuracy rate within rural healthcare settings characterized by data constraints.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.AI",
            "cs.CV"
        ],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00255": {
        "title": "Leveraging Team Correlation for Approximating Equilibrium in Two-Team Zero-Sum Games",
        "authors": [
            "Naming Liu",
            "Mingzhi Wang",
            "Youzhi Zhang",
            "Yaodong Yang",
            "Bo An",
            "Ying Wen"
        ],
        "comments": " ",
        "subjects": "Computer Science and Game Theory (cs.GT)",
        "abstract": "Two-team zero-sum games are one of the most important paradigms in game theory. In this paper, we focus on finding an unexploitable equilibrium in large team games. An unexploitable equilibrium is a worst-case policy, where members in the opponent team cannot increase their team reward by taking any policy, e.g., cooperatively changing to other joint policies. As an optimal unexploitable equilibrium in two-team zero-sum games, correlated-team maxmin equilibrium remains unexploitable even in the worst case where players in the opponent team can achieve arbitrary cooperation through a joint team policy. However, finding such an equilibrium in large games is challenging due to the impracticality of evaluating the exponentially large number of joint policies. To solve this problem, we first introduce a general solution concept called restricted correlated-team maxmin equilibrium, which solves the problem of being impossible to evaluate all joint policy by a sample factor while avoiding an exploitation problem under the incomplete joint policy evaluation. We then develop an efficient sequential correlation mechanism, and based on which we propose an algorithm for approximating the unexploitable equilibrium in large games. We show that our approach achieves lower exploitability than the state-of-the-art baseline when encountering opponent teams with different exploitation ability in large team games including Google Research Football.\n    ",
        "primary_category": "cs.GT",
        "categories": [
            "cs.MA"
        ],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00257": {
        "title": "Robust deep labeling of radiological emphysema subtypes using squeeze and excitation convolutional neural networks: The MESA Lung and SPIROMICS Studies",
        "authors": [
            "Artur Wysoczanski",
            "Nabil Ettehadi",
            "Soroush Arabshahi",
            "Yifei Sun",
            "Karen Hinkley Stukovsky",
            "Karol E. Watson",
            "MeiLan K. Han",
            "Erin D Michos",
            "Alejandro P. Comellas",
            "Eric A. Hoffman",
            "Andrew F. Laine",
            "R. Graham Barr",
            "Elsa D. Angelini"
        ],
        "comments": " ",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Pulmonary emphysema, the progressive, irreversible loss of lung tissue, is conventionally categorized into three subtypes identifiable on pathology and on lung computed tomography (CT) images. Recent work has led to the unsupervised learning of ten spatially-informed lung texture patterns (sLTPs) on lung CT, representing distinct patterns of emphysematous lung parenchyma based on both textural appearance and spatial location within the lung, and which aggregate into 6 robust and reproducible CT Emphysema Subtypes (CTES). Existing methods for sLTP segmentation, however, are slow and highly sensitive to changes in CT acquisition protocol. In this work, we present a robust 3-D squeeze-and-excitation CNN for supervised classification of sLTPs and CTES on lung CT. Our results demonstrate that this model achieves accurate and reproducible sLTP segmentation on lung CTscans, across two independent cohorts and independently of scanner manufacturer and model.\n    ",
        "primary_category": "cs.CV",
        "categories": [
            "cs.LG"
        ],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00258": {
        "title": "\"Lossless\" Compression of Deep Neural Networks: A High-dimensional Neural Tangent Kernel Approach",
        "authors": [
            "Lingyu Gu",
            "Yongqi Du",
            "Yuan Zhang",
            "Di Xie",
            "Shiliang Pu",
            "Robert C. Qiu",
            "Zhenyu Liao"
        ],
        "comments": "32 pages, 4 figures, and 2 tables. Fixing typos in Theorems 1 and 2 from NeurIPS 2022 proceeding (this https URL)",
        "subjects": "Machine Learning (stat.ML)",
        "abstract": "Modern deep neural networks (DNNs) are extremely powerful; however, this comes at the price of increased depth and having more parameters per layer, making their training and inference more computationally challenging. In an attempt to address this key limitation, efforts have been devoted to the compression (e.g., sparsification and/or quantization) of these large-scale machine learning models, so that they can be deployed on low-power IoT devices. In this paper, building upon recent advances in neural tangent kernel (NTK) and random matrix theory (RMT), we provide a novel compression approach to wide and fully-connected \\emph{deep} neural nets. Specifically, we demonstrate that in the high-dimensional regime where the number of data points $n$ and their dimension $p$ are both large, and under a Gaussian mixture model for the data, there exists \\emph{asymptotic spectral equivalence} between the NTK matrices for a large family of DNN models. This theoretical result enables \"lossless\" compression of a given DNN to be performed, in the sense that the compressed network yields asymptotically the same NTK as the original (dense and unquantized) network, with its weights and activations taking values \\emph{only} in $\\{ 0, \\pm 1 \\}$ up to a scaling. Experiments on both synthetic and real-world data are conducted to support the advantages of the proposed compression scheme, with code available at \\url{this https URL}.\n    ",
        "primary_category": "stat.ML",
        "categories": [
            "cs.LG"
        ],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00259": {
        "title": "Deciphering diffuse scattering with machine learning and the equivariant foundation model: The case of molten FeO",
        "authors": [
            "Ganesh Sivaraman",
            "Chris J. Benmore"
        ],
        "comments": "9 pages, 5 figures",
        "subjects": "Materials Science (cond-mat.mtrl-sci)",
        "abstract": "Bridging the gap between diffuse x-ray or neutron scattering measurements and predicted structures derived from atom-atom pair potentials in disordered materials, has been a longstanding challenge in condensed matter physics. This perspective gives a brief overview of the traditional approaches employed over the past several decades. Namely, the use of approximate interatomic pair potentials that relate 3-dimensional structural models to the measured structure factor and its associated pair distribution function. The use of machine learned interatomic potentials has grown in the past few years, and has been particularly successful in the cases of ionic and oxide systems. Recent advances in large scale sampling, along with a direct integration of scattering measurements into the model development, has provided improved agreement between experiments and large-scale models calculated with quantum mechanical accuracy. However, details of local polyhedral bonding and connectivity in meta-stable disordered systems still require improvement. Here we leverage MACE-MP-0; a newly introduced equivariant foundation model and validate the results against high-quality experimental scattering data for the case of molten iron(II) oxide (FeO). These preliminary results suggest that the emerging foundation model has the potential to surpass the traditional limitations of classical interatomic potentials.\n    ",
        "primary_category": "cond-mat.mtrl-sci",
        "categories": [
            "cs.LG"
        ],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00260": {
        "title": "Extracting Polymer Nanocomposite Samples from Full-Length Documents",
        "authors": [
            "Ghazal Khalighinejad",
            "Defne Circi",
            "L.C. Brinson",
            "Bhuwan Dhingra"
        ],
        "comments": " ",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "This paper investigates the use of large language models (LLMs) for extracting sample lists of polymer nanocomposites (PNCs) from full-length materials science research papers. The challenge lies in the complex nature of PNC samples, which have numerous attributes scattered throughout the text. The complexity of annotating detailed information on PNCs limits the availability of data, making conventional document-level relation extraction techniques impractical due to the challenge in creating comprehensive named entity span annotations. To address this, we introduce a new benchmark and an evaluation technique for this task and explore different prompting strategies in a zero-shot manner. We also incorporate self-consistency to improve the performance. Our findings show that even advanced LLMs struggle to extract all of the samples from an article. Finally, we analyze the errors encountered in this process, categorizing them into three main challenges, and discuss potential strategies for future research to overcome them.\n    ",
        "primary_category": "cs.CL",
        "categories": [],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00261": {
        "title": "Spatial Cascaded Clustering and Weighted Memory for Unsupervised Person Re-identification",
        "authors": [
            "Jiahao Hong",
            "Jialong Zuo",
            "Chuchu Han",
            "Ruochen Zheng",
            "Ming Tian",
            "Changxin Gao",
            "Nong Sang"
        ],
        "comments": " ",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Recent unsupervised person re-identification (re-ID) methods achieve high performance by leveraging fine-grained local context. These methods are referred to as part-based methods. However, most part-based methods obtain local contexts through horizontal division, which suffer from misalignment due to various human poses. Additionally, the misalignment of semantic information in part features restricts the use of metric learning, thus affecting the effectiveness of part-based methods. The two issues mentioned above result in the under-utilization of part features in part-based methods. We introduce the Spatial Cascaded Clustering and Weighted Memory (SCWM) method to address these challenges. SCWM aims to parse and align more accurate local contexts for different human body parts while allowing the memory module to balance hard example mining and noise suppression. Specifically, we first analyze the foreground omissions and spatial confusions issues in the previous method. Then, we propose foreground and space corrections to enhance the completeness and reasonableness of the human parsing results. Next, we introduce a weighted memory and utilize two weighting strategies. These strategies address hard sample mining for global features and enhance noise resistance for part features, which enables better utilization of both global and part features. Extensive experiments on Market-1501 and MSMT17 validate the proposed method's effectiveness over many state-of-the-art methods.\n    ",
        "primary_category": "cs.CV",
        "categories": [],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00265": {
        "title": "Designing for Harm Reduction: Communication Repair for Multicultural Users' Voice Interactions",
        "authors": [
            "Kimi Wenzel",
            "Geoff Kaufman"
        ],
        "comments": "2024 CHI Conference on Human Factors in Computing Systems (CHI '24)",
        "subjects": "Human-Computer Interaction (cs.HC)",
        "abstract": "Voice assistants' inability to serve people-of-color and non-native English speakers has largely been documented as a quality-of-service harm. However, little work has investigated what downstream harms propagate from this poor service. How does poor usability materially manifest and affect users' lives? And what interaction designs might help users recover from these effects? We identify 6 downstream harms that propagate from quality-of-service harms in voice assistants. Through interviews and design activities with 16 multicultural participants, we unveil these 6 harms, outline how multicultural users uniquely personify their voice assistant, and suggest how these harms and personifications may affect their interactions. Lastly, we employ techniques from psychology on communication repair to contribute suggestions for harm-reducing repair that may be implemented in voice technologies. Our communication repair strategies include: identity affirmations (intermittent frequency), cultural sensitivity, and blame redirection. This work shows potential for a harm-repair framework to positively influence voice interactions.\n    ",
        "primary_category": "cs.HC",
        "categories": [
            "cs.CY"
        ],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00266": {
        "title": "Algorithms for Efficient, Compact Online Data Stream Curation",
        "authors": [
            "Matthew Andres Moreno",
            "Santiago Rodriguez Papa",
            "Emily Dolson"
        ],
        "comments": " ",
        "subjects": "Data Structures and Algorithms (cs.DS)",
        "abstract": "Data stream algorithms tackle operations on high-volume sequences of read-once data items. Data stream scenarios include inherently real-time systems like sensor networks and financial markets. They also arise in purely-computational scenarios like ordered traversal of big data or long-running iterative simulations. In this work, we develop methods to maintain running archives of stream data that are temporally representative, a task we call \"stream curation.\" Our approach contributes to rich existing literature on data stream binning, which we extend by providing stateless (i.e., non-iterative) curation schemes that enable key optimizations to trim archive storage overhead and streamline processing of incoming observations. We also broaden support to cover new trade-offs between curated archive size and temporal coverage. We present a suite of five stream curation algorithms that span $\\mathcal{O}(n)$, $\\mathcal{O}(\\log n)$, and $\\mathcal{O}(1)$ orders of growth for retained data items. Within each order of growth, algorithms are provided to maintain even coverage across history or bias coverage toward more recent time points. More broadly, memory-efficient stream curation can boost the data stream mining capabilities of low-grade hardware in roles such as sensor nodes and data logging devices.\n    ",
        "primary_category": "cs.DS",
        "categories": [],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00268": {
        "title": "Improving Acne Image Grading with Label Distribution Smoothing",
        "authors": [
            "Kirill Prokhorov",
            "Alexandr A. Kalinin"
        ],
        "comments": "Accepted to IEEE ISBI 2024",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Acne, a prevalent skin condition, necessitates precise severity assessment for effective treatment. Acne severity grading typically involves lesion counting and global assessment. However, manual grading suffers from variability and inefficiency, highlighting the need for automated tools. Recently, label distribution learning (LDL) was proposed as an effective framework for acne image grading, but its effectiveness is hindered by severity scales that assign varying numbers of lesions to different severity grades. Addressing these limitations, we proposed to incorporate severity scale information into lesion counting by combining LDL with label smoothing, and to decouple if from global assessment. A novel weighting scheme in our approach adjusts the degree of label smoothing based on the severity grading scale. This method helped to effectively manage label uncertainty without compromising class distinctiveness. Applied to the benchmark ACNE04 dataset, our model demonstrated improved performance in automated acne grading, showcasing its potential in enhancing acne diagnostics. The source code is publicly available at this http URL.\n    ",
        "primary_category": "cs.CV",
        "categories": [],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00270": {
        "title": "Event-Driven Learning for Spiking Neural Networks",
        "authors": [
            "Wenjie Wei",
            "Malu Zhang",
            "Jilin Zhang",
            "Ammar Belatreche",
            "Jibin Wu",
            "Zijing Xu",
            "Xuerui Qiu",
            "Hong Chen",
            "Yang Yang",
            "Haizhou Li"
        ],
        "comments": " ",
        "subjects": "Neural and Evolutionary Computing (cs.NE)",
        "abstract": "Brain-inspired spiking neural networks (SNNs) have gained prominence in the field of neuromorphic computing owing to their low energy consumption during feedforward inference on neuromorphic hardware. However, it remains an open challenge how to effectively benefit from the sparse event-driven property of SNNs to minimize backpropagation learning costs. In this paper, we conduct a comprehensive examination of the existing event-driven learning algorithms, reveal their limitations, and propose novel solutions to overcome them. Specifically, we introduce two novel event-driven learning methods: the spike-timing-dependent event-driven (STD-ED) and membrane-potential-dependent event-driven (MPD-ED) algorithms. These proposed algorithms leverage precise neuronal spike timing and membrane potential, respectively, for effective learning. The two methods are extensively evaluated on static and neuromorphic datasets to confirm their superior performance. They outperform existing event-driven counterparts by up to 2.51% for STD-ED and 6.79% for MPD-ED on the CIFAR-100 dataset. In addition, we theoretically and experimentally validate the energy efficiency of our methods on neuromorphic hardware. On-chip learning experiments achieved a remarkable 30-fold reduction in energy consumption over time-step-based surrogate gradient methods. The demonstrated efficiency and efficacy of the proposed event-driven learning methods emphasize their potential to significantly advance the fields of neuromorphic computing, offering promising avenues for energy-efficiency applications.\n    ",
        "primary_category": "cs.NE",
        "categories": [
            "cs.CV"
        ],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00272": {
        "title": "Dual Pose-invariant Embeddings: Learning Category and Object-specific Discriminative Representations for Recognition and Retrieval",
        "authors": [
            "Rohan Sarkar",
            "Avinash Kak"
        ],
        "comments": "Accepted by IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR 2024)",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "In the context of pose-invariant object recognition and retrieval, we demonstrate that it is possible to achieve significant improvements in performance if both the category-based and the object-identity-based embeddings are learned simultaneously during training. In hindsight, that sounds intuitive because learning about the categories is more fundamental than learning about the individual objects that correspond to those categories. However, to the best of what we know, no prior work in pose-invariant learning has demonstrated this effect. This paper presents an attention-based dual-encoder architecture with specially designed loss functions that optimize the inter- and intra-class distances simultaneously in two different embedding spaces, one for the category embeddings and the other for the object-level embeddings. The loss functions we have proposed are pose-invariant ranking losses that are designed to minimize the intra-class distances and maximize the inter-class distances in the dual representation spaces. We demonstrate the power of our approach with three challenging multi-view datasets, ModelNet-40, ObjectPI, and FG3D. With our dual approach, for single-view object recognition, we outperform the previous best by 20.0% on ModelNet40, 2.0% on ObjectPI, and 46.5% on FG3D. On the other hand, for single-view object retrieval, we outperform the previous best by 33.7% on ModelNet40, 18.8% on ObjectPI, and 56.9% on FG3D.\n    ",
        "primary_category": "cs.CV",
        "categories": [
            "cs.IR",
            "cs.LG"
        ],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00273": {
        "title": "ARED: Argentina Real Estate Dataset",
        "authors": [
            "Iv\u00e1n Belenky"
        ],
        "comments": "3 pages, 6 figures",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "The Argentinian real estate market presents a unique case study characterized by its unstable and rapidly shifting macroeconomic circumstances over the past decades. Despite the existence of a few datasets for price prediction, there is a lack of mixed modality datasets specifically focused on Argentina. In this paper, the first edition of ARED is introduced. A comprehensive real estate price prediction dataset series, designed for the Argentinian market. This edition contains information solely for Jan-Feb 2024. It was found that despite the short time range captured by this zeroth edition (44 days), time dependent phenomena has been occurring mostly on a market level (market as a whole). Nevertheless future editions of this dataset, will most likely contain historical data. Each listing in ARED comprises descriptive features, and variable-length sets of images.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.DL",
            "q-fin.ST"
        ],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00276": {
        "title": "Graph Construction with Flexible Nodes for Traffic Demand Prediction",
        "authors": [
            "Jinyan Hou",
            "Shan Liu",
            "Ya Zhang",
            "Haotong Qin"
        ],
        "comments": " ",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Graph neural networks (GNNs) have been widely applied in traffic demand prediction, and transportation modes can be divided into station-based mode and free-floating traffic mode. Existing research in traffic graph construction primarily relies on map matching to construct graphs based on the road network. However, the complexity and inhomogeneity of data distribution in free-floating traffic demand forecasting make road network matching inflexible. To tackle these challenges, this paper introduces a novel graph construction method tailored to free-floating traffic mode. We propose a novel density-based clustering algorithm (HDPC-L) to determine the flexible positioning of nodes in the graph, overcoming the computational bottlenecks of traditional clustering algorithms and enabling effective handling of large-scale datasets. Furthermore, we extract valuable information from ridership data to initialize the edge weights of GNNs. Comprehensive experiments on two real-world datasets, the Shenzhen bike-sharing dataset and the Haikou ride-hailing dataset, show that the method significantly improves the performance of the model. On average, our models show an improvement in accuracy of around 25\\% and 19.5\\% on the two datasets. Additionally, it significantly enhances computational efficiency, reducing training time by approximately 12% and 32.5% on the two datasets. We make our code available at this https URL.\n    ",
        "primary_category": "cs.LG",
        "categories": [],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00277": {
        "title": "Gender Bias in Large Language Models across Multiple Languages",
        "authors": [
            "Jinman Zhao",
            "Yitian Ding",
            "Chen Jia",
            "Yining Wang",
            "Zifan Qian"
        ],
        "comments": "20 pages, 27 tables, 7 figures, submitted to ACL2024",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "With the growing deployment of large language models (LLMs) across various applications, assessing the influence of gender biases embedded in LLMs becomes crucial. The topic of gender bias within the realm of natural language processing (NLP) has gained considerable focus, particularly in the context of English. Nonetheless, the investigation of gender bias in languages other than English is still relatively under-explored and insufficiently analyzed. In this work, We examine gender bias in LLMs-generated outputs for different languages. We use three measurements: 1) gender bias in selecting descriptive words given the gender-related context. 2) gender bias in selecting gender-related pronouns (she/he) given the descriptive words. 3) gender bias in the topics of LLM-generated dialogues. We investigate the outputs of the GPT series of LLMs in various languages using our three measurement methods. Our findings revealed significant gender biases across all the languages we examined.\n    ",
        "primary_category": "cs.CL",
        "categories": [],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00278": {
        "title": "Shifted Interpolation for Differential Privacy",
        "authors": [
            "Jinho Bok",
            "Weijie Su",
            "Jason M. Altschuler"
        ],
        "comments": "42 pages",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Noisy gradient descent and its variants are the predominant algorithms for differentially private machine learning. It is a fundamental question to quantify their privacy leakage, yet tight characterizations remain open even in the foundational setting of convex losses. This paper improves over previous analyses by establishing (and refining) the \"privacy amplification by iteration\" phenomenon in the unifying framework of $f$-differential privacy--which tightly captures all aspects of the privacy loss and immediately implies tighter privacy accounting in other notions of differential privacy, e.g., $(\\varepsilon,\\delta)$-DP and Renyi DP. Our key technical insight is the construction of shifted interpolated processes that unravel the popular shifted-divergences argument, enabling generalizations beyond divergence-based relaxations of DP. Notably, this leads to the first exact privacy analysis in the foundational setting of strongly convex optimization. Our techniques extend to many settings: convex/strongly convex, constrained/unconstrained, full/cyclic/stochastic batches, and all combinations thereof. As an immediate corollary, we recover the $f$-DP characterization of the exponential mechanism for strongly convex optimization in Gopi et al. (2022), and moreover extend this result to more general settings.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.CR",
            "math.OC",
            "math.ST",
            "stat.ML"
        ],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00280": {
        "title": "SoK: Security of Programmable Logic Controllers",
        "authors": [
            "Efr\u00e9n L\u00f3pez-Morales",
            "Ulysse Planta",
            "Carlos Rubio-Medrano",
            "Ali Abbasi",
            "Alvaro A. Cardenas"
        ],
        "comments": "25 pages, 13 figures, Extended version February 2024, A shortened version is to be published in the 33rd USENIX Security Symposium, for more information, see this https URL",
        "subjects": "Cryptography and Security (cs.CR)",
        "abstract": "Billions of people rely on essential utility and manufacturing infrastructures such as water treatment plants, energy management, and food production. Our dependence on reliable infrastructures makes them valuable targets for cyberattacks. One of the prime targets for adversaries attacking physical infrastructures are Programmable Logic Controllers (PLCs) because they connect the cyber and physical worlds. In this study, we conduct the first comprehensive systematization of knowledge that explores the security of PLCs: We present an in-depth analysis of PLC attacks and defenses and discover trends in the security of PLCs from the last 17 years of research. We introduce a novel threat taxonomy for PLCs and Industrial Control Systems (ICS). Finally, we identify and point out research gaps that, if left ignored, could lead to new catastrophic attacks against critical infrastructures.\n    ",
        "primary_category": "cs.CR",
        "categories": [],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00282": {
        "title": "Scale-Invariant Gradient Aggregation for Constrained Multi-Objective Reinforcement Learning",
        "authors": [
            "Dohyeong Kim",
            "Mineui Hong",
            "Jeongho Park",
            "Songhwai Oh"
        ],
        "comments": "22 pages",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Multi-objective reinforcement learning (MORL) aims to find a set of Pareto optimal policies to cover various preferences. However, to apply MORL in real-world applications, it is important to find policies that are not only Pareto optimal but also satisfy pre-defined constraints for safety. To this end, we propose a constrained MORL (CMORL) algorithm called Constrained Multi-Objective Gradient Aggregator (CoMOGA). Recognizing the difficulty of handling multiple objectives and constraints concurrently, CoMOGA relaxes the original CMORL problem into a constrained optimization problem by transforming the objectives into additional constraints. This novel transformation process ensures that the converted constraints are invariant to the objective scales while having the same effect as the original objectives. We show that the proposed method converges to a local Pareto optimal policy while satisfying the predefined constraints. Empirical evaluations across various tasks show that the proposed method outperforms other baselines by consistently meeting constraints and demonstrating invariance to the objective scales.\n    ",
        "primary_category": "cs.LG",
        "categories": [],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00289": {
        "title": "Optimization of Array Encoding for Ultrasound Imaging",
        "authors": [
            "Jacob Spainhour",
            "Korben Smart",
            "Stephen Becker",
            "Nick Bottenus"
        ],
        "comments": " ",
        "subjects": "Medical Physics (physics.med-ph)",
        "abstract": "Objective: The transmit encoding model for synthetic aperture imaging is a robust and flexible framework for understanding the effect of acoustic transmission on ultrasound image reconstruction. Our objective is to use machine learning (ML) to construct scanning sequences, parameterized by time delays and apodization weights, that produce high quality B-mode images. Approach: We use an ML model in PyTorch and simulated RF data from Field II to probe the space of possible encoding sequences for those that minimize a loss function that describes image quality. This approach is made computationally feasible by a novel formulation of the derivative for delay-and-sum beamforming. We demonstrate these results experimentally on wire targets and a tissue-mimicking phantom. Main Results: When trained according to a given set of imaging parameters (imaging domain, hardware restrictions), our ML imaging model produces optimized encoding sequences that improve a number of standard quality metrics including resolution, field of view, and contrast, over conventional sequences. Significance: This work demonstrates that the set of encoding schemes that are commonly used represent only a narrow subset of those available. Additionally, it demonstrates the value for ML tasks in synthetic transmit aperture imaging to consider the beamformer within the model, instead of as purely post-processing.\n    ",
        "primary_category": "physics.med-ph",
        "categories": [
            "cs.LG",
            "math.OC"
        ],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00290": {
        "title": "Semantic Text Transmission via Prediction with Small Language Models: Cost-Similarity Trade-off",
        "authors": [
            "Bhavani A Madhabhavi",
            "Gangadhar Karevvanavar",
            "Rajshekhar V Bhat",
            "Nikolaos Pappas"
        ],
        "comments": " ",
        "subjects": "Information Theory (cs.IT)",
        "abstract": "We consider the communication of natural language text from a source to a destination over noiseless and character-erasure channels. We exploit language's inherent correlations and predictability to constrain transmission costs by allowing the destination to predict or complete words with potential dissimilarity with the source text. Concretely, our objective is to obtain achievable $(\\bar{c}, \\bar{s})$ pairs, where $\\bar{c}$ is the average transmission cost at the source and $\\bar{s}$ is the average semantic similarity measured via cosine similarity between vector embedding of words at the source and those predicted/completed at the destination. We obtain $(\\bar{c}, \\bar{s})$ pairs for neural language and first-order Markov chain-based small language models (SLM) for prediction, using both a threshold policy that transmits a word if its cosine similarity with that predicted/completed at the destination is below a threshold, and a periodic policy, which transmits words after a specific interval and predicts/completes the words in between, at the destination. We adopt an SLM for word completion. We demonstrate that, when communication occurs over a noiseless channel, the threshold policy achieves a higher $\\bar{s}$ for a given $\\bar{c}$ than the periodic policy and that the $\\bar{s}$ achieved with the neural SLM is greater than or equal to that of the Markov chain-based algorithm for the same $\\bar{c}$. The improved performance comes with a higher complexity in terms of time and computing requirements. However, when communication occurs over a character-erasure channel, all prediction algorithms and scheduling policies perform poorly. Furthermore, if character-level Huffman coding is used, the required $\\bar{c}$ to achieve a given $\\bar{s}$ is reduced, but the above observations still apply.\n    ",
        "primary_category": "cs.IT",
        "categories": [
            "cs.AI",
            "cs.LG"
        ],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00292": {
        "title": "DPP-Based Adversarial Prompt Searching for Lanugage Models",
        "authors": [
            "Xu Zhang",
            "Xiaojun Wan"
        ],
        "comments": " ",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "Language models risk generating mindless and offensive content, which hinders their safe deployment. Therefore, it is crucial to discover and modify potential toxic outputs of pre-trained language models before deployment. In this work, we elicit toxic content by automatically searching for a prompt that directs pre-trained language models towards the generation of a specific target output. The problem is challenging due to the discrete nature of textual data and the considerable computational resources required for a single forward pass of the language model. To combat these challenges, we introduce Auto-regressive Selective Replacement Ascent (ASRA), a discrete optimization algorithm that selects prompts based on both quality and similarity with determinantal point process (DPP). Experimental results on six different pre-trained language models demonstrate the efficacy of ASRA for eliciting toxic content. Furthermore, our analysis reveals a strong correlation between the success rate of ASRA attacks and the perplexity of target outputs, while indicating limited association with the quantity of model parameters.\n    ",
        "primary_category": "cs.CL",
        "categories": [],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00293": {
        "title": "Efficient Adapter Tuning of Pre-trained Speech Models for Automatic Speaker Verification",
        "authors": [
            "Mufan Sang",
            "John H.L. Hansen"
        ],
        "comments": "Accepted to ICASSP 2024",
        "subjects": "Audio and Speech Processing (eess.AS)",
        "abstract": "With excellent generalization ability, self-supervised speech models have shown impressive performance on various downstream speech tasks in the pre-training and fine-tuning paradigm. However, as the growing size of pre-trained models, fine-tuning becomes practically unfeasible due to heavy computation and storage overhead, as well as the risk of overfitting. Adapters are lightweight modules inserted into pre-trained models to facilitate parameter-efficient adaptation. In this paper, we propose an effective adapter framework designed for adapting self-supervised speech models to the speaker verification task. With a parallel adapter design, our proposed framework inserts two types of adapters into the pre-trained model, allowing the adaptation of latent features within intermediate Transformer layers and output embeddings from all Transformer layers. We conduct comprehensive experiments to validate the efficiency and effectiveness of the proposed framework. Experimental results on the VoxCeleb1 dataset demonstrate that the proposed adapters surpass fine-tuning and other parameter-efficient transfer learning methods, achieving superior performance while updating only 5% of the parameters.\n    ",
        "primary_category": "eess.AS",
        "categories": [
            "cs.LG",
            "cs.SD"
        ],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00294": {
        "title": "A Gradually Reinforced Sample-Average-Approximation Differentiable Homotopy Method for a System of Stochastic Equations",
        "authors": [
            "Peixuan Li",
            "Chuangyin Dang",
            "Yang Zhan"
        ],
        "comments": " ",
        "subjects": "Numerical Analysis (math.NA)",
        "abstract": "This paper intends to apply the sample-average-approximation (SAA) scheme to solve a system of stochastic equations (SSE), which has many applications in a variety of fields. The SAA is an effective paradigm to address risks and uncertainty in stochastic models from the perspective of Monte Carlo principle. Nonetheless, a numerical conflict arises from the sample size of SAA when one has to make a tradeoff between the accuracy of solutions and the computational cost. To alleviate this issue, we incorporate a gradually reinforced SAA scheme into a differentiable homotopy method and develop a gradually reinforced sample-average-approximation (GRSAA) differentiable homotopy method in this paper. By introducing a series of continuously differentiable functions of the homotopy parameter $t$ ranging between zero and one, we establish a differentiable homotopy system, which is able to gradually increase the sample size of SAA as $t$ descends from one to zero. The set of solutions to the homotopy system contains an everywhere smooth path, which starts from an arbitrary point and ends at a solution to the SAA with any desired accuracy. The GRSAA differentiable homotopy method serves as a bridge to link the gradually reinforced SAA scheme and a differentiable homotopy method and retains the nice property of global convergence the homotopy method possesses while greatly reducing the computational cost for attaining a desired solution to the original SSE. Several numerical experiments further confirm the effectiveness and efficiency of the proposed method.\n    ",
        "primary_category": "math.NA",
        "categories": [],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00299": {
        "title": "Universal Auto-encoder Framework for MIMO CSI Feedback",
        "authors": [
            "Jinhyun So",
            "Hyukjoon Kwon"
        ],
        "comments": "7 pages, 11 figures",
        "subjects": "Information Theory (cs.IT)",
        "abstract": "Existing auto-encoder (AE)-based channel state information (CSI) frameworks have focused on a specific configuration of user equipment (UE) and base station (BS), and thus the input and output sizes of the AE are fixed. However, in the real-world scenario, the input and output sizes may vary depending on the number of antennas of the BS and UE and the allocated resource block in the frequency dimension. A naive approach to support the different input and output sizes is to use multiple AE models, which is impractical for the UE due to the limited HW resources. In this paper, we propose a universal AE framework that can support different input sizes and multiple compression ratios. The proposed AE framework significantly reduces the HW complexity while providing comparable performance in terms of compression ratio-distortion trade-off compared to the naive and state-of-the-art approaches.\n    ",
        "primary_category": "cs.IT",
        "categories": [
            "cs.AI",
            "cs.LG",
            "eess.SP"
        ],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00300": {
        "title": "Hybrid Base Complex: Extract and Visualize Structure of Hex-dominant Meshes",
        "authors": [
            "Lei Si",
            "Haowei Cao",
            "Guoning Chen"
        ],
        "comments": "accepted by IEEE Transactions on Visualization and Computer Graphics",
        "subjects": "Graphics (cs.GR)",
        "abstract": "Hex-dominant mesh generation has received significant attention in recent research due to its superior robustness compared to pure hex-mesh generation techniques. In this work, we introduce the first structure for analyzing hex-dominant meshes. This structure builds on the base complex of pure hex-meshes but incorporates the non-hex elements for a more comprehensive and complete representation. We provide its definition and describe its construction steps. Based on this structure, we present an extraction and categorization of sheets using advanced graph matching techniques to handle the non-hex elements. This enables us to develop an enhanced visual analysis of the structure for any hex-dominant meshes.We apply this structure-based visual analysis to compare hex-dominant meshes generated by different methods to study their advantages and disadvantages. This complements the standard quality metric based on the non-hex element percentage for hex-dominant meshes. Moreover, we propose a strategy to extract a cleaned (optimized) valence-based singularity graph wireframe to analyze the structure for both mesh and sheets. Our results demonstrate that the proposed hybrid base complex provides a coarse representation for mesh element, and the proposed valence singularity graph wireframe provides a better internal visualization of hex-dominant meshes.\n    ",
        "primary_category": "cs.GR",
        "categories": [],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00306": {
        "title": "qPMS Sigma -- An Efficient and Exact Parallel Algorithm for the Planted $(l, d)$ Motif Search Problem",
        "authors": [
            "Saurav Dhar",
            "Amlan Saha",
            "Dhiman Goswami",
            "Md. Abul Kashem Mia"
        ],
        "comments": " ",
        "subjects": "Data Structures and Algorithms (cs.DS)",
        "abstract": "Motif finding is an important step for the detection of rare events occurring in a set of DNA or protein sequences. Extraction of information about these rare events can lead to new biological discoveries. Motifs are some important patterns that have numerous applications including the identification of transcription factors and their binding sites, composite regulatory patterns, similarity between families of proteins, etc. Although several flavors of motif searching algorithms have been studied in the literature, we study the version known as $ (l, d) $-motif search or Planted Motif Search (PMS). In PMS, given two integers $ l $, $ d $ and $ n $ input sequences we try to find all the patterns of length $ l $ that appear in each of the $ n $ input sequences with at most $ d $ mismatches. We also discuss the quorum version of PMS in our work that finds motifs that are not planted in all the input sequences but at least in $ q $ of the sequences. Our algorithm is mainly based on the algorithms qPMSPrune, qPMS7, TraverStringRef and PMS8. We introduce some techniques to compress the input strings and make faster comparison between strings with bitwise operations. Our algorithm performs a little better than the existing exact algorithms to solve the qPMS problem in DNA sequence. We have also proposed an idea for parallel implementation of our algorithm.\n    ",
        "primary_category": "cs.DS",
        "categories": [],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00307": {
        "title": "Embedded Multi-label Feature Selection via Orthogonal Regression",
        "authors": [
            "Xueyuan Xu",
            "Fulin Wei",
            "Tianyuan Jia",
            "Li Zhuo",
            "Feiping Nie",
            "Xia Wu"
        ],
        "comments": " ",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "In the last decade, embedded multi-label feature selection methods, incorporating the search for feature subsets into model optimization, have attracted considerable attention in accurately evaluating the importance of features in multi-label classification tasks. Nevertheless, the state-of-the-art embedded multi-label feature selection algorithms based on least square regression usually cannot preserve sufficient discriminative information in multi-label data. To tackle the aforementioned challenge, a novel embedded multi-label feature selection method, termed global redundancy and relevance optimization in orthogonal regression (GRROOR), is proposed to facilitate the multi-label feature selection. The method employs orthogonal regression with feature weighting to retain sufficient statistical and structural information related to local label correlations of the multi-label data in the feature learning process. Additionally, both global feature redundancy and global label relevancy information have been considered in the orthogonal regression model, which could contribute to the search for discriminative and non-redundant feature subsets in the multi-label data. The cost function of GRROOR is an unbalanced orthogonal Procrustes problem on the Stiefel manifold. A simple yet effective scheme is utilized to obtain an optimal solution. Extensive experimental results on ten multi-label data sets demonstrate the effectiveness of GRROOR.\n    ",
        "primary_category": "cs.CV",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00315": {
        "title": "Axe the X in XAI: A Plea for Understandable AI",
        "authors": [
            "Andr\u00e9s P\u00e1ez"
        ],
        "comments": " ",
        "subjects": "Artificial Intelligence (cs.AI)",
        "abstract": "In a recent paper, Erasmus et al. (2021) defend the idea that the ambiguity of the term \"explanation\" in explainable AI (XAI) can be solved by adopting any of four different extant accounts of explanation in the philosophy of science: the Deductive Nomological, Inductive Statistical, Causal Mechanical, and New Mechanist models. In this chapter, I show that the authors' claim that these accounts can be applied to deep neural networks as they would to any natural phenomenon is mistaken. I also provide a more general argument as to why the notion of explainability as it is currently used in the XAI literature bears little resemblance to the traditional concept of scientific explanation. It would be more fruitful to use the label \"understandable AI\" to avoid the confusion that surrounds the goal and purposes of XAI. In the second half of the chapter, I argue for a pragmatic conception of understanding that is better suited to play the central role attributed to explanation in XAI. Following Kuorikoski & Ylikoski (2015), the conditions of satisfaction for understanding an ML system are fleshed out in terms of an agent's success in using the system, in drawing correct inferences from it.\n    ",
        "primary_category": "cs.AI",
        "categories": [
            "cs.LG"
        ],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00318": {
        "title": "Deep Reinforcement Learning for Solving Management Problems: Towards A Large Management Mode",
        "authors": [
            "Jinyang Jiang",
            "Xiaotian Liu",
            "Tao Ren",
            "Qinghao Wang",
            "Yi Zheng",
            "Yufu Du",
            "Yijie Peng",
            "Cheng Zhang"
        ],
        "comments": " ",
        "subjects": "Artificial Intelligence (cs.AI)",
        "abstract": "We introduce a deep reinforcement learning (DRL) approach for solving management problems including inventory management, dynamic pricing, and recommendation. This DRL approach has the potential to lead to a large management model based on certain transformer neural network structures, resulting in an artificial general intelligence paradigm for various management tasks. Traditional methods have limitations for solving complex real-world problems, and we demonstrate how DRL can surpass existing heuristic approaches for solving management tasks. We aim to solve the problems in a unified framework, considering the interconnections between different tasks. Central to our methodology is the development of a foundational decision model coordinating decisions across the different domains through generative decision-making. Our experimental results affirm the effectiveness of our DRL-based framework in complex and dynamic business environments. This work opens new pathways for the application of DRL in management problems, highlighting its potential to revolutionize traditional business management.\n    ",
        "primary_category": "cs.AI",
        "categories": [
            "cs.LG"
        ],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00321": {
        "title": "DEEP-IoT: Downlink-Enhanced Efficient-Power Internet of Things",
        "authors": [
            "Yulin Shao"
        ],
        "comments": " ",
        "subjects": "Information Theory (cs.IT)",
        "abstract": "At the heart of the Internet of Things (IoT) -- a domain witnessing explosive growth -- the imperative for energy efficiency and the extension of device lifespans has never been more pressing. This paper presents DEEP-IoT, a revolutionary communication paradigm poised to redefine how IoT devices communicate. Through a pioneering \"listen more, transmit less\" strategy, DEEP-IoT challenges and transforms the traditional transmitter (IoT devices)-centric communication model to one where the receiver (the access point) play a pivotal role, thereby cutting down energy use and boosting device longevity. We not only conceptualize DEEP-IoT but also actualize it by integrating deep learning-enhanced feedback channel codes within a narrow-band system. Simulation results show a significant enhancement in the operational lifespan of IoT cells -- surpassing traditional systems using Turbo and Polar codes by up to 52.71%. This leap signifies a paradigm shift in IoT communications, setting the stage for a future where IoT devices boast unprecedented efficiency and durability.\n    ",
        "primary_category": "cs.IT",
        "categories": [
            "cs.LG",
            "eess.SP",
            "eess.SY"
        ],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00322": {
        "title": "Model-Based Planning and Control for Terrestrial-Aerial Bimodal Vehicles with Passive Wheels",
        "authors": [
            "Ruibin Zhang",
            "Junxiao Lin",
            "Yuze Wu",
            "Yuman Gao",
            "Chi Wang",
            "Chao Xu",
            "Yanjun Cao",
            "Fei Gao"
        ],
        "comments": "Accepted at IROS 2023",
        "subjects": "Robotics (cs.RO)",
        "abstract": "Terrestrial and aerial bimodal vehicles have gained widespread attention due to their cross-domain maneuverability. Nevertheless, their bimodal dynamics significantly increase the complexity of motion planning and control, thus hindering robust and efficient autonomous navigation in unknown environments. To resolve this issue, we develop a model-based planning and control framework for terrestrial aerial bi-modal vehicles. This work begins by deriving a unified dynamic model and the corresponding differential flatness. Leveraging differential flatness, an optimization-based trajectory planner is proposed, which takes into account both solution quality and computational efficiency. Moreover, we design a tracking controller using nonlinear model predictive control based on the proposed unified dynamic model to achieve accurate trajectory tracking and smooth mode transition. We validate our framework through extensive benchmark comparisons and experiments, demonstrating its effectiveness in terms of planning quality and control performance.\n    ",
        "primary_category": "cs.RO",
        "categories": [],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00323": {
        "title": "Softened Symbol Grounding for Neuro-symbolic Systems",
        "authors": [
            "Zenan Li",
            "Yuan Yao",
            "Taolue Chen",
            "Jingwei Xu",
            "Chun Cao",
            "Xiaoxing Ma",
            "Jian L\u00fc"
        ],
        "comments": "Published as a conference paper at ICLR 2023. Code is available at this https URL",
        "subjects": "Artificial Intelligence (cs.AI)",
        "abstract": "Neuro-symbolic learning generally consists of two separated worlds, i.e., neural network training and symbolic constraint solving, whose success hinges on symbol grounding, a fundamental problem in AI. This paper presents a novel, softened symbol grounding process, bridging the gap between the two worlds, and resulting in an effective and efficient neuro-symbolic learning framework. Technically, the framework features (1) modeling of symbol solution states as a Boltzmann distribution, which avoids expensive state searching and facilitates mutually beneficial interactions between network training and symbolic reasoning;(2) a new MCMC technique leveraging projection and SMT solvers, which efficiently samples from disconnected symbol solution spaces; (3) an annealing mechanism that can escape from %being trapped into sub-optimal symbol groundings. Experiments with three representative neuro symbolic learning tasks demonstrate that, owining to its superior symbol grounding capability, our framework successfully solves problems well beyond the frontier of the existing proposals.\n    ",
        "primary_category": "cs.AI",
        "categories": [
            "cs.LG"
        ],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00325": {
        "title": "Small, Versatile and Mighty: A Range-View Perception Framework",
        "authors": [
            "Qiang Meng",
            "Xiao Wang",
            "JiaBao Wang",
            "Liujiang Yan",
            "Ke Wang"
        ],
        "comments": " ",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Despite its compactness and information integrity, the range view representation of LiDAR data rarely occurs as the first choice for 3D perception tasks. In this work, we further push the envelop of the range-view representation with a novel multi-task framework, achieving unprecedented 3D detection performances. Our proposed Small, Versatile, and Mighty (SVM) network utilizes a pure convolutional architecture to fully unleash the efficiency and multi-tasking potentials of the range view representation. To boost detection performances, we first propose a range-view specific Perspective Centric Label Assignment (PCLA) strategy, and a novel View Adaptive Regression (VAR) module to further refine hard-to-predict box properties. In addition, our framework seamlessly integrates semantic segmentation and panoptic segmentation tasks for the LiDAR point cloud, without extra modules. Among range-view-based methods, our model achieves new state-of-the-art detection performances on the Waymo Open Dataset. Especially, over 10 mAP improvement over convolutional counterparts can be obtained on the vehicle class. Our presented results for other tasks further reveal the multi-task capabilities of the proposed small but mighty framework.\n    ",
        "primary_category": "cs.CV",
        "categories": [],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00327": {
        "title": "Task Indicating Transformer for Task-conditional Dense Predictions",
        "authors": [
            "Yuxiang Lu",
            "Shalayiding Sirejiding",
            "Bayram Bayramli",
            "Suizhi Huang",
            "Yue Ding",
            "Hongtao Lu"
        ],
        "comments": "Accepted by ICASSP 2024",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "The task-conditional model is a distinctive stream for efficient multi-task learning. Existing works encounter a critical limitation in learning task-agnostic and task-specific representations, primarily due to shortcomings in global context modeling arising from CNN-based architectures, as well as a deficiency in multi-scale feature interaction within the decoder. In this paper, we introduce a novel task-conditional framework called Task Indicating Transformer (TIT) to tackle this challenge. Our approach designs a Mix Task Adapter module within the transformer block, which incorporates a Task Indicating Matrix through matrix decomposition, thereby enhancing long-range dependency modeling and parameter-efficient feature adaptation by capturing intra- and inter-task features. Moreover, we propose a Task Gate Decoder module that harnesses a Task Indicating Vector and gating mechanism to facilitate adaptive multi-scale feature refinement guided by task embeddings. Experiments on two public multi-task dense prediction benchmarks, NYUD-v2 and PASCAL-Context, demonstrate that our approach surpasses state-of-the-art task-conditional methods.\n    ",
        "primary_category": "cs.CV",
        "categories": [],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00329": {
        "title": "Learning with Logical Constraints but without Shortcut Satisfaction",
        "authors": [
            "Zenan Li",
            "Zehua Liu",
            "Yuan Yao",
            "Jingwei Xu",
            "Taolue Chen",
            "Xiaoxing Ma",
            "Jian L\u00fc"
        ],
        "comments": "Published as a conference paper at ICLR 2023, and code is available at this https URL",
        "subjects": "Artificial Intelligence (cs.AI)",
        "abstract": "Recent studies in neuro-symbolic learning have explored the integration of logical knowledge into deep learning via encoding logical constraints as an additional loss function. However, existing approaches tend to vacuously satisfy logical constraints through shortcuts, failing to fully exploit the knowledge. In this paper, we present a new framework for learning with logical constraints. Specifically, we address the shortcut satisfaction issue by introducing dual variables for logical connectives, encoding how the constraint is satisfied. We further propose a variational framework where the encoded logical constraint is expressed as a distributional loss that is compatible with the model's original training loss. The theoretical analysis shows that the proposed approach bears salient properties, and the experimental evaluations demonstrate its superior performance in both model generalizability and constraint satisfaction.\n    ",
        "primary_category": "cs.AI",
        "categories": [
            "cs.LG"
        ],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00334": {
        "title": "NOVA: A visual interface for assessing polarizing media coverage",
        "authors": [
            "Keshav Dasu",
            "Sam Yu-Te Lee",
            "Ying-Cheng Chen",
            "Kwan-Liu Ma"
        ],
        "comments": " ",
        "subjects": "Human-Computer Interaction (cs.HC)",
        "abstract": "Within the United States, the majority of the populace receives their news online. U.S mainstream media outlets both generate and influence the news consumed by U.S citizens. Many of these citizens have their personal beliefs about these outlets and question the fairness of their reporting. We offer an interactive visualization system for the public to assess their perception of the mainstream media's coverage of a topic against the data. Our system combines belief elicitation techniques and narrative structure designs, emphasizing transparency and user-friendliness to facilitate users' self-assessment on personal beliefs. We gathered $\\sim${25k} articles from the span of 2020-2022 from six mainstream media outlets as a testbed. To evaluate our system, we present usage scenarios alongside a user study with a qualitative analysis of user exploration strategies for personal belief assessment. We report our observations from this study and discuss future work and challenges of developing tools for the public to assess media outlet coverage and belief updating on provocative topics.\n    ",
        "primary_category": "cs.HC",
        "categories": [],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00336": {
        "title": "Never-Ending Embodied Robot Learning",
        "authors": [
            "Wenqi Liang",
            "Gan Sun",
            "Qian He",
            "Yu Ren",
            "Jiahua Dong",
            "Yang Cong"
        ],
        "comments": "14 pages, 5 figures, 8 tables",
        "subjects": "Robotics (cs.RO)",
        "abstract": "Relying on large language models (LLMs), embodied robots could perform complex multimodal robot manipulation tasks from visual observations with powerful generalization ability. However, most visual behavior-cloning agents suffer from manipulation performance degradation and skill knowledge forgetting when adapting into a series of challenging unseen tasks. We here investigate the above challenge with NBCagent in embodied robots, a pioneering language-conditioned Never-ending Behavior-Cloning agent, which can continually learn observation knowledge of novel robot manipulation skills from skill-specific and skill-shared attributes. Specifically, we establish a skill-specific evolving planner to perform knowledge decoupling, which can continually embed novel skill-specific knowledge in our NBCagent agent from latent and low-rank space. Meanwhile, we propose a skill-shared semantics rendering module and a skill-shared representation distillation module to effectively transfer anti-forgetting skill-shared knowledge, further tackling catastrophic forgetting on old skills from semantics and representation aspects. Finally, we design a continual embodied robot manipulation benchmark, and several expensive experiments demonstrate the significant performance of our method. Visual results, code, and dataset are provided at: this https URL.\n    ",
        "primary_category": "cs.RO",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00337": {
        "title": "Nonlinear Sheaf Diffusion in Graph Neural Networks",
        "authors": [
            "Olga Zaghen"
        ],
        "comments": "Thesis for Master's degree in Artificial Intelligence Systems (University of Trento), 65 pages",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "This work focuses on exploring the potential benefits of introducing a nonlinear Laplacian in Sheaf Neural Networks for graph-related tasks. The primary aim is to understand the impact of such nonlinearity on diffusion dynamics, signal propagation, and performance of neural network architectures in discrete-time settings. The study primarily emphasizes experimental analysis, using real-world and synthetic datasets to validate the practical effectiveness of different versions of the model. This approach shifts the focus from an initial theoretical exploration to demonstrating the practical utility of the proposed model.\n    ",
        "primary_category": "cs.LG",
        "categories": [],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00338": {
        "title": "Semi-Instruct: Bridging Natural-Instruct and Self-Instruct for Code Large Language Models",
        "authors": [
            "Xianzhen Luo",
            "Qingfu Zhu",
            "Zhiming Zhang",
            "Xu Wang",
            "Qing Yang",
            "Dongliang Xu",
            "Wanxiang Che"
        ],
        "comments": " ",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "Instruction tuning plays a pivotal role in Code Large Language Models (Code LLMs) for the task of program synthesis. Presently, two dominant paradigms for collecting tuning data are natural-instruct (human-written) and self-instruct (automatically generated). Natural-instruct includes diverse and correct codes but lacks instruction-code pairs, and exists improper code formats like nested single-line codes. In contrast, self-instruct automatically generates proper paired data. However, it suffers from low diversity due to generating duplicates and cannot ensure the correctness of codes. To bridge the both paradigms, we propose \\textbf{Semi-Instruct}. It first converts diverse but improper codes from natural-instruct into proper instruction-code pairs through a method similar to self-instruct. To verify the correctness of generated codes, we design a novel way to construct test cases by generating cases' inputs and executing correct codes from natural-instruct to get outputs. Finally, diverse and correct instruction-code pairs are retained for instruction tuning. Experiments show that semi-instruct is significantly better than natural-instruct and self-instruct. Furthermore, the performance steadily improves as data scale increases.\n    ",
        "primary_category": "cs.CL",
        "categories": [],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00349": {
        "title": "Impact of Inter-Operator Interference via Reconfigurable Intelligent Surfaces",
        "authors": [
            "Nikolaos I. Miridakis",
            "Theodoros A. Tsiftsis",
            "Panagiotis A. Karkazis",
            "Helen C. Leligou",
            "Petar Popovski"
        ],
        "comments": " ",
        "subjects": "Information Theory (cs.IT)",
        "abstract": "A wireless communication system is studied that operates in the presence of multiple reconfigurable intelligent surfaces (RISs). In particular, a multi-operator environment is considered where each operator utilizes an RIS to enhance its communication quality. Although out-of-band interference does not exist (since each operator uses isolated spectrum resources), RISs controlled by different operators do affect the system performance of one another due to the inherently rapid phase shift adjustments that occur on an independent basis. The system performance of such a communication scenario is analytically studied for the practical case where discrete-only phase shifts occur at RIS. The proposed framework is quite general since it is valid under arbitrary channel fading conditions as well as the presence (or not) of the transceiver's direct link. Finally, the derived analytical results are verified via numerical and simulation trial as well as some novel and useful engineering outcomes are manifested.\n    ",
        "primary_category": "cs.IT",
        "categories": [
            "eess.SP"
        ],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00352": {
        "title": "Revisiting Disentanglement in Downstream Tasks: A Study on Its Necessity for Abstract Visual Reasoning",
        "authors": [
            "Ruiqian Nai",
            "Zixin Wen",
            "Ji Li",
            "Yuanzhi Li",
            "Yang Gao"
        ],
        "comments": "Accepted to AAAI-2024",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "In representation learning, a disentangled representation is highly desirable as it encodes generative factors of data in a separable and compact pattern. Researchers have advocated leveraging disentangled representations to complete downstream tasks with encouraging empirical evidence. This paper further investigates the necessity of disentangled representation in downstream applications. Specifically, we show that dimension-wise disentangled representations are unnecessary on a fundamental downstream task, abstract visual reasoning. We provide extensive empirical evidence against the necessity of disentanglement, covering multiple datasets, representation learning methods, and downstream network architectures. Furthermore, our findings suggest that the informativeness of representations is a better indicator of downstream performance than disentanglement. Finally, the positive correlation between informativeness and disentanglement explains the claimed usefulness of disentangled representations in previous works. The source code is available at this https URL.\n    ",
        "primary_category": "cs.CV",
        "categories": [
            "cs.LG"
        ],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00353": {
        "title": "MS-Net: A Multi-Path Sparse Model for Motion Prediction in Multi-Scenes",
        "authors": [
            "Xiaqiang Tang",
            "Weigao Sun",
            "Siyuan Hu",
            "Yiyang Sun",
            "Yafeng Guo"
        ],
        "comments": "Accepted by IEEE Robotics and Automation Letters (RAL)",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "The multi-modality and stochastic characteristics of human behavior make motion prediction a highly challenging task, which is critical for autonomous driving. While deep learning approaches have demonstrated their great potential in this area, it still remains unsolved to establish a connection between multiple driving scenes (e.g., merging, roundabout, intersection) and the design of deep learning models. Current learning-based methods typically use one unified model to predict trajectories in different scenarios, which may result in sub-optimal results for one individual scene. To address this issue, we propose Multi-Scenes Network (aka. MS-Net), which is a multi-path sparse model trained by an evolutionary process. MS-Net selectively activates a subset of its parameters during the inference stage to produce prediction results for each scene. In the training stage, the motion prediction task under differentiated scenes is abstracted as a multi-task learning problem, an evolutionary algorithm is designed to encourage the network search of the optimal parameters for each scene while sharing common knowledge between different scenes. Our experiment results show that with substantially reduced parameters, MS-Net outperforms existing state-of-the-art methods on well-established pedestrian motion prediction datasets, e.g., ETH and UCY, and ranks the 2nd place on the INTERACTION challenge.\n    ",
        "primary_category": "cs.CV",
        "categories": [
            "cs.AI",
            "cs.RO"
        ],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00354": {
        "title": "Self-Consistent Reasoning-based Aspect-Sentiment Quad Prediction with Extract-Then-Assign Strategy",
        "authors": [
            "Jieyong Kim",
            "Ryang Heo",
            "Yongsik Seo",
            "SeongKu Kang",
            "Jinyoung Yeo",
            "Dongha Lee"
        ],
        "comments": " ",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "In the task of aspect sentiment quad prediction (ASQP), generative methods for predicting sentiment quads have shown promising results. However, they still suffer from imprecise predictions and limited interpretability, caused by data scarcity and inadequate modeling of the quadruplet composition process. In this paper, we propose Self-Consistent Reasoning-based Aspect-sentiment quadruple Prediction (SCRAP), optimizing its model to generate reasonings and the corresponding sentiment quadruplets in sequence. SCRAP adopts the Extract-Then-Assign reasoning strategy, which closely mimics human cognition. In the end, SCRAP significantly improves the model's ability to handle complex reasoning tasks and correctly predict quadruplets through consistency voting, resulting in enhanced interpretability and accuracy in ASQP.\n    ",
        "primary_category": "cs.CL",
        "categories": [],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00363": {
        "title": "SFQ counter-based precomputation for large-scale cryogenic VQE machines",
        "authors": [
            "Yosuke Ueno",
            "Satoshi Imamura",
            "Yuna Tomida",
            "Teruo Tanimoto",
            "Masamitsu Tanaka",
            "Yutaka Tabuchi",
            "Koji Inoue",
            "Hiroshi Nakamura"
        ],
        "comments": "7 pages, 5 figures, 3 tables. Accepted by DAC'24 WIP poster session",
        "subjects": "Quantum Physics (quant-ph)",
        "abstract": "The variational quantum eigensolver (VQE) is a promising candidate that brings practical benefits from quantum computing. However, the required bandwidth in/out of a cryostat is a limiting factor to scale cryogenic quantum computers. We propose a tailored counter-based module with single flux quantum circuits in 4-K stage which precomputes a part of VQE calculation and reduces the amount of inter-temperature communication. The evaluation shows that our system reduces the required bandwidth by 97%, and with this drastic reduction, total power consumption is reduced by 93% in the case where 277 VQE programs are executed in parallel on a 10000-qubit machine.\n    ",
        "primary_category": "quant-ph",
        "categories": [
            "cs.AR"
        ],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00365": {
        "title": "Can a Funny Chatbot Make a Difference? Infusing Humor into Conversational Agent for Behavioral Intervention",
        "authors": [
            "Xin Sun",
            "Isabelle Teljeur",
            "Zhuying Li",
            "Jos A. Bosch"
        ],
        "comments": " ",
        "subjects": "Human-Computer Interaction (cs.HC)",
        "abstract": "Regular physical activity is crucial for reducing the risk of non-communicable disease (NCD). With NCDs on the rise globally, there is an urgent need for effective health interventions, with chatbots emerging as a viable and cost-effective option because of limited healthcare accessibility. Although health professionals often utilize behavior change techniques (BCTs) to boost physical activity levels and enhance client engagement and motivation by affiliative humor, the efficacy of humor in chatbot-delivered interventions is not well-understood. This study conducted a randomized controlled trial to examine the impact of the generative humorous communication style in a 10-day chatbot-delivered intervention for physical activity. It further investigated if user engagement and motivation act as mediators between the communication style and changes in physical activity levels. 66 participants engaged with the chatbots across three groups (humorous, non-humorous, and no-intervention) and responded to daily ecological momentary assessment questionnaires assessing engagement, motivation, and physical activity levels. Multilevel time series analyses revealed that an affiliative humorous communication style positively impacted physical activity levels over time, with user engagement acting as a mediator in this relationship, whereas motivation did not. These findings clarify the role of humorous communication style in chatbot-delivered physical activity interventions, offering valuable insights for future development of intelligent conversational agents incorporating humor.\n    ",
        "primary_category": "cs.HC",
        "categories": [],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00366": {
        "title": "Exploring the dynamic interplay of cognitive load and emotional arousal by using multimodal measurements: Correlation of pupil diameter and emotional arousal in emotionally engaging tasks",
        "authors": [
            "C. Kosel",
            "S. Michel",
            "T. Seidel",
            "M. Foerster"
        ],
        "comments": "The first two authors contributed equally to the manuscript",
        "subjects": "Computers and Society (cs.CY)",
        "abstract": "Multimodal data analysis and validation based on streams from state-of-the-art sensor technology such as eye-tracking or emotion recognition using the Facial Action Coding System (FACTs) with deep learning allows educational researchers to study multifaceted learning and problem-solving processes and to improve educational experiences. This study aims to investigate the correlation between two continuous sensor streams, pupil diameter as an indicator of cognitive workload and FACTs with deep learning as an indicator of emotional arousal (RQ 1a), specifically for epochs of high, medium, and low arousal (RQ 1b). Furthermore, the time lag between emotional arousal and pupil diameter data will be analyzed (RQ 2). 28 participants worked on three cognitively demanding and emotionally engaging everyday moral dilemmas while eye-tracking and emotion recognition data were collected. The data were pre-processed in Phyton (synchronization, blink control, downsampling) and analyzed using correlation analysis and Granger causality tests. The results show negative and statistically significant correlations between the data streams for emotional arousal and pupil diameter. However, the correlation is negative and significant only for epochs of high arousal, while positive but non-significant relationships were found for epochs of medium or low arousal. The average time lag for the relationship between arousal and pupil diameter was 2.8 ms. In contrast to previous findings without a multimodal approach suggesting a positive correlation between the constructs, the results contribute to the state of research by highlighting the importance of multimodal data validation and research on convergent vagility. Future research should consider emotional regulation strategies and emotional valence.\n    ",
        "primary_category": "cs.CY",
        "categories": [
            "cs.CV"
        ],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00368": {
        "title": "Recommending Target Actions Outside Sessions in the Data-poor Insurance Domain",
        "authors": [
            "Simone Borg Bruun",
            "Christina Lioma",
            "Maria Maistro"
        ],
        "comments": "arXiv admin note: substantial text overlap with arXiv:2211.15360",
        "subjects": "Information Retrieval (cs.IR)",
        "abstract": "Providing personalized recommendations for insurance products is particularly challenging due to the intrinsic and distinctive features of the insurance domain. First, unlike more traditional domains like retail, movie etc., a large amount of user feedback is not available and the item catalog is smaller. Second, due to the higher complexity of products, the majority of users still prefer to complete their purchases over the phone instead of online. We present different recommender models to address such data scarcity in the insurance domain. We use recurrent neural networks with 3 different types of loss functions and architectures (cross-entropy, censored Weibull, attention). Our models cope with data scarcity by learning from multiple sessions and different types of user actions. Moreover, differently from previous session-based models, our models learn to predict a target action that does not happen within the session. Our models outperform state-of-the-art baselines on a real-world insurance dataset, with ca. 44K users, 16 items, 54K purchases and 117K sessions. Moreover, combining our models with demographic data boosts the performance. Analysis shows that considering multiple sessions and several types of actions are both beneficial for the models, and that our models are not unfair with respect to age, gender and income.\n    ",
        "primary_category": "cs.IR",
        "categories": [],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00370": {
        "title": "Post-decoder Biasing for End-to-End Speech Recognition of Multi-turn Medical Interview",
        "authors": [
            "Heyang Liu",
            "Yu Wang",
            "Yanfeng Wang"
        ],
        "comments": " ",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "End-to-end (E2E) approach is gradually replacing hybrid models for automatic speech recognition (ASR) tasks. However, the optimization of E2E models lacks an intuitive method for handling decoding shifts, especially in scenarios with a large number of domain-specific rare words that hold specific important meanings. Furthermore, the absence of knowledge-intensive speech datasets in academia has been a significant limiting factor, and the commonly used speech corpora exhibit significant disparities with realistic conversation. To address these challenges, we present Medical Interview (MED-IT), a multi-turn consultation speech dataset that contains a substantial number of knowledge-intensive named entities. We also explore methods to enhance the recognition performance of rare words for E2E models. We propose a novel approach, post-decoder biasing, which constructs a transform probability matrix based on the distribution of training transcriptions. This guides the model to prioritize recognizing words in the biasing list. In our experiments, for subsets of rare words appearing in the training speech between 10 and 20 times, and between 1 and 5 times, the proposed method achieves a relative improvement of 9.3% and 5.1%, respectively.\n    ",
        "primary_category": "cs.CL",
        "categories": [
            "cs.SD",
            "eess.AS"
        ],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00376": {
        "title": "Invariant Test-Time Adaptation for Vision-Language Model Generalization",
        "authors": [
            "Huan Ma",
            "Yan Zhu",
            "Changqing Zhang",
            "Peilin Zhao",
            "Baoyuan Wu",
            "Long-Kai Huang",
            "Qinghua Hu",
            "Bingzhe Wu"
        ],
        "comments": " ",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Vision-language foundation models have exhibited remarkable success across a multitude of downstream tasks due to their scalability on extensive image-text paired datasets. However, these models display significant limitations when applied to long-tail tasks, such as fine-grained image classification, as a result of \"decision shortcuts\" that hinders their generalization capabilities. In this work, we find that the CLIP model possesses a rich set of features, encompassing both \\textit{desired invariant causal features} and \\textit{undesired decision shortcuts}. Moreover, the underperformance of CLIP on downstream tasks originates from its inability to effectively utilize pre-trained features in accordance with specific task requirements. To address this challenge, this paper introduces a test-time prompt tuning paradigm that optimizes a learnable prompt, thereby compelling the model to exploit genuine causal invariant features while disregarding decision shortcuts during the inference phase. The proposed method effectively alleviates excessive dependence on potentially misleading, task-irrelevant contextual information, while concurrently emphasizing critical, task-related visual cues. We conduct comparative analysis of the proposed method against various approaches which validates its effectiveness.\n    ",
        "primary_category": "cs.CV",
        "categories": [
            "cs.AI",
            "cs.LG"
        ],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00379": {
        "title": "The Impact of Frequency Bands on Acoustic Anomaly Detection of Machines using Deep Learning Based Model",
        "authors": [
            "Tin Nguyen",
            "Lam Pham",
            "Phat Lam",
            "Dat Ngo",
            "Hieu Tang",
            "Alexander Schindler"
        ],
        "comments": " ",
        "subjects": "Audio and Speech Processing (eess.AS)",
        "abstract": "In this paper, we propose a deep learning based model for Acoustic Anomaly Detection of Machines, the task for detecting abnormal machines by analysing the machine sound. By conducting extensive experiments, we indicate that multiple techniques of pseudo audios, audio segment, data augmentation, Mahalanobis distance, and narrow frequency bands, which mainly focus on feature engineering, are effective to enhance the system performance. Among the evaluating techniques, the narrow frequency bands presents a significant impact. Indeed, our proposed model, which focuses on the narrow frequency bands, outperforms the DCASE baseline on the benchmark dataset of DCASE 2022 Task 2 Development set. The important role of the narrow frequency bands indicated in this paper inspires the research community on the task of Acoustic Anomaly Detection of Machines to further investigate and propose novel network architectures focusing on the frequency bands.\n    ",
        "primary_category": "eess.AS",
        "categories": [
            "cs.SD"
        ],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00381": {
        "title": "Structured Deep Neural Networks-Based Backstepping Trajectory Tracking Control for Lagrangian Systems",
        "authors": [
            "Jiajun Qian",
            "Liang Xu",
            "Xiaoqiang Ren",
            "Xiaofan Wang"
        ],
        "comments": " ",
        "subjects": "Robotics (cs.RO)",
        "abstract": "Deep neural networks (DNN) are increasingly being used to learn controllers due to their excellent approximation capabilities. However, their black-box nature poses significant challenges to closed-loop stability guarantees and performance analysis. In this paper, we introduce a structured DNN-based controller for the trajectory tracking control of Lagrangian systems using backing techniques. By properly designing neural network structures, the proposed controller can ensure closed-loop stability for any compatible neural network parameters. In addition, improved control performance can be achieved by further optimizing neural network parameters. Besides, we provide explicit upper bounds on tracking errors in terms of controller parameters, which allows us to achieve the desired tracking performance by properly selecting the controller parameters. Furthermore, when system models are unknown, we propose an improved Lagrangian neural network (LNN) structure to learn the system dynamics and design the controller. We show that in the presence of model approximation errors and external disturbances, the closed-loop stability and tracking control performance can still be guaranteed. The effectiveness of the proposed approach is demonstrated through simulations.\n    ",
        "primary_category": "cs.RO",
        "categories": [
            "cs.LG",
            "eess.SY"
        ],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00387": {
        "title": "For time-invariant delay systems, global asymptotic stability does not imply uniform global attractivity",
        "authors": [
            "Antoine Chaillet",
            "Fabian Wirth",
            "Andrii Mironchenko",
            "Lucas Brivadis"
        ],
        "comments": " ",
        "subjects": "Systems and Control (eess.SY)",
        "abstract": "Adapting a counterexample recently proposed by J.L. Mancilla-Aguilar and H. Haimovich, we show here that, for time-delay systems, global asymptotic stability does not ensure that solutions converge uniformly to zero over bounded sets of initial states. Hence, the convergence might be arbitrarily slow even if initial states are confined to a bounded set.\n    ",
        "primary_category": "eess.SY",
        "categories": [],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00390": {
        "title": "Deterministic Weighted Automata under Partial Observability",
        "authors": [
            "Jakub Michaliszyn",
            "Jan Otop"
        ],
        "comments": " ",
        "subjects": "Computational Complexity (cs.CC)",
        "abstract": "Weighted automata is a basic tool for specification in quantitative verification, which allows to express quantitative features of analysed systems such as resource consumption. Quantitative specification can be assisted by automata learning as there are classic results on Angluin-style learning of weighted automata. The existing work assumes perfect information about the values returned by the target weighted automaton. In assisted synthesis of a quantitative specification, knowledge of the exact values is a strong assumption and may be infeasible. In our work, we address this issue by introducing a new framework of partially-observable deterministic weighted automata, in which weighted automata return intervals containing the computed values of words instead of the exact values. We study the basic properties of this framework with the particular focus on the challenges of\n    ",
        "primary_category": "cs.CC",
        "categories": [],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00393": {
        "title": "Private Benchmarking to Prevent Contamination and Improve Comparative Evaluation of LLMs",
        "authors": [
            "Nishanth Chandran",
            "Sunayana Sitaram",
            "Divya Gupta",
            "Rahul Sharma",
            "Kashish Mittal",
            "Manohar Swaminathan"
        ],
        "comments": " ",
        "subjects": "Cryptography and Security (cs.CR)",
        "abstract": "Benchmarking is the de-facto standard for evaluating LLMs, due to its speed, replicability and low cost. However, recent work has pointed out that the majority of the open source benchmarks available today have been contaminated or leaked into LLMs, meaning that LLMs have access to test data during pretraining and/or fine-tuning. This raises serious concerns about the validity of benchmarking studies conducted so far and the future of evaluation using benchmarks. To solve this problem, we propose Private Benchmarking, a solution where test datasets are kept private and models are evaluated without revealing the test data to the model. We describe various scenarios (depending on the trust placed on model owners or dataset owners), and present solutions to avoid data contamination using private benchmarking. For scenarios where the model weights need to be kept private, we describe solutions from confidential computing and cryptography that can aid in private benchmarking. Finally, we present solutions the problem of benchmark dataset auditing, to ensure that private benchmarks are of sufficiently high quality.\n    ",
        "primary_category": "cs.CR",
        "categories": [
            "cs.CL"
        ],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00396": {
        "title": "GLFNET: Global-Local (frequency) Filter Networks for efficient medical image segmentation",
        "authors": [
            "Athanasios Tragakis",
            "Qianying Liu",
            "Chaitanya Kaul",
            "Swalpa Kumar Roy",
            "Hang Dai",
            "Fani Deligianni",
            "Roderick Murray-Smith",
            "Daniele Faccio"
        ],
        "comments": " ",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "We propose a novel transformer-style architecture called Global-Local Filter Network (GLFNet) for medical image segmentation and demonstrate its state-of-the-art performance. We replace the self-attention mechanism with a combination of global-local filter blocks to optimize model efficiency. The global filters extract features from the whole feature map whereas the local filters are being adaptively created as 4x4 patches of the same feature map and add restricted scale information. In particular, the feature extraction takes place in the frequency domain rather than the commonly used spatial (image) domain to facilitate faster computations. The fusion of information from both spatial and frequency spaces creates an efficient model with regards to complexity, required data and performance. We test GLFNet on three benchmark datasets achieving state-of-the-art performance on all of them while being almost twice as efficient in terms of GFLOP operations.\n    ",
        "primary_category": "cs.CV",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00397": {
        "title": "The Price of Fairness in Bipartite Matching",
        "authors": [
            "R\u00e9mi Castera",
            "Felipe Garrido-Lucero",
            "Mathieu Molina",
            "Simon Mauras",
            "Patrick Loiseau",
            "Vianney Perchet"
        ],
        "comments": " ",
        "subjects": "Computer Science and Game Theory (cs.GT)",
        "abstract": "We investigate notions of group fairness in bipartite matching markets involving agents and jobs, where agents are grouped based on sensitive attributes. Employing a geometric approach, we characterize how many agents can be matched in each group, showing that the set of feasible matchings forms a (discrete) polymatroid. We show how we can define weakly-fair matchings geometrically, for which poly-matroid properties imply that they are maximal. Next, we focus on strong fairness notions (inspired by group-fairness metrics in machine learning), where each group gets their exact same fraction of their entitlement, and we explore the Price of Fairness (PoF), i.e., the loss in optimality when imposing such fairness constraints. Importantly, we advocate for the notion of opportunity fairness, where a group entitlement is the maximum number of agents that can be matched without the presence of other competing groups. We show that the opportunity PoF is bounded independently of the number of agents and jobs, but may be linear in the number of groups. Finally, we provide improved bounds with additional structural properties, or with stochastic graphs.\n    ",
        "primary_category": "cs.GT",
        "categories": [],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00398": {
        "title": "Learning Quadrupedal Locomotion with Impaired Joints Using Random Joint Masking",
        "authors": [
            "Mincheol Kim",
            "Ukcheol Shin",
            "Jung-Yup Kim"
        ],
        "comments": "Appear to ICRA 2024, Project page: this https URL",
        "subjects": "Robotics (cs.RO)",
        "abstract": "Quadrupedal robots have played a crucial role in various environments, from structured environments to complex harsh terrains, thanks to their agile locomotion ability. However, these robots can easily lose their locomotion functionality if damaged by external accidents or internal malfunctions. In this paper, we propose a novel deep reinforcement learning framework to enable a quadrupedal robot to walk with impaired joints. The proposed framework consists of three components: 1) a random joint masking strategy for simulating impaired joint scenarios, 2) a joint state estimator to predict an implicit status of current joint condition based on past observation history, and 3) progressive curriculum learning to allow a single network to conduct both normal gait and various joint-impaired gaits. We verify that our framework enables the Unitree's Go1 robot to walk under various impaired joint conditions in real-world indoor and outdoor environments.\n    ",
        "primary_category": "cs.RO",
        "categories": [],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00401": {
        "title": "Enhancing Biomechanical Simulations Based on A Posteriori Error Estimates: The Potential of Dual Weighted Residual-Driven Adaptive Mesh Refinement",
        "authors": [
            "Huu Phuoc Bui",
            "Michel Duprez",
            "Pierre-Yves Rohan",
            "Arnaud Lejeune",
            "Stephane P.A. Bordas",
            "Marek Bucki",
            "Franz Chouly"
        ],
        "comments": " ",
        "subjects": "Numerical Analysis (math.NA)",
        "abstract": "The Finite Element Method (FEM) is a well-established procedure for computing approximate solutions to deterministic engineering problems described by partial differential equations. FEM produces discrete approximations of the solution with a discretisation error that can be an be quantified with \\emph{a posteriori} error estimates. The practical relevance of error estimates for biomechanics problems, especially for soft tissue where the response is governed by large strains, is rarely addressed. In this contribution, we propose an implementation of \\emph{a posteriori} error estimates targeting a user-defined quantity of interest, using the Dual Weighted Residual (DWR) technique tailored to biomechanics. The proposed method considers a general setting that encompasses three-dimensional geometries and model non-linearities, which appear in hyperelastic soft tissues. We take advantage of the automatic differentiation capabilities embedded in modern finite element software, which allows the error estimates to be computed generically for a large class of models and constitutive laws. First we validate our methodology using experimental measurements from silicone samples, and then illustrate its applicability for patient-specific computations of pressure ulcers on a human heel.\n    ",
        "primary_category": "math.NA",
        "categories": [],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00402": {
        "title": "Spatio-temporal reconstruction of substance dynamics using compressed sensing in multi-spectral magnetic resonance spectroscopic imaging",
        "authors": [
            "Utako Yamamoto",
            "Hirohiko Imai",
            "Kei Sano",
            "Masayuki Ohzeki",
            "Tetsuya Matsuda",
            "Toshiyuki Tanaka"
        ],
        "comments": " ",
        "subjects": "Signal Processing (eess.SP)",
        "abstract": "The objective of our study is to observe dynamics of multiple substances in vivo with high temporal resolution from multi-spectral magnetic resonance spectroscopic imaging (MRSI) data. The multi-spectral MRSI can effectively separate spectral peaks of multiple substances and is useful to measure spatial distributions of substances. However it is difficult to measure time-varying substance distributions directly by ordinary full sampling because the measurement requires a significantly long time. In this study, we propose a novel method to reconstruct the spatio-temporal distributions of substances from randomly undersampled multi-spectral MRSI data on the basis of compressed sensing (CS) and the partially separable function model with base spectra of substances. In our method, we have employed spatio-temporal sparsity and temporal smoothness of the substance distributions as prior knowledge to perform CS. The effectiveness of our method has been evaluated using phantom data sets of glass tubes filled with glucose or lactate solution in increasing amounts over time and animal data sets of a tumor-bearing mouse to observe the metabolic dynamics involved in the Warburg effect in vivo. The reconstructed results are consistent with the expected behaviors, showing that our method can reconstruct the spatio-temporal distribution of substances with a temporal resolution of four seconds which is extremely short time scale compared with that of full sampling. Since this method utilizes only prior knowledge naturally assumed for the spatio-temporal distributions of substances and is independent of the number of the spectral and spatial dimensions or the acquisition sequence of MRSI, it is expected to contribute to revealing the underlying substance dynamics in MRSI data already acquired or to be acquired in the future.\n    ",
        "primary_category": "eess.SP",
        "categories": [
            "cs.CV"
        ],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00403": {
        "title": "Fractal interpolation in the context of prediction accuracy optimization",
        "authors": [
            "Alexandra Baicoianu",
            "Cristina Gabriela Gavril\u0103",
            "Cristina Maria Pacurar",
            "Victor Dan Pacurar"
        ],
        "comments": " ",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "This paper focuses on the hypothesis of optimizing time series predictions using fractal interpolation techniques. In general, the accuracy of machine learning model predictions is closely related to the quality and quantitative aspects of the data used, following the principle of \\textit{garbage-in, garbage-out}. In order to quantitatively and qualitatively augment datasets, one of the most prevalent concerns of data scientists is to generate synthetic data, which should follow as closely as possible the actual pattern of the original data.\nThis study proposes three different data augmentation strategies based on fractal interpolation, namely the \\textit{Closest Hurst Strategy}, \\textit{Closest Values Strategy} and \\textit{Formula Strategy}. To validate the strategies, we used four public datasets from the literature, as well as a private dataset obtained from meteorological records in the city of Brasov, Romania. The prediction results obtained with the LSTM model using the presented interpolation strategies showed a significant accuracy improvement compared to the raw datasets, thus providing a possible answer to practical problems in the field of remote sensing and sensor sensitivity. Moreover, our methodologies answer some optimization-related open questions for the fractal interpolation step using \\textit{Optuna} framework.\n    ",
        "primary_category": "cs.LG",
        "categories": [],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00404": {
        "title": "Secure Routing for Mobile Ad hoc Networks",
        "authors": [
            "Panagiotis Papadimitratos",
            "Zygmunt J. Haas"
        ],
        "comments": "arXiv admin note: text overlap with arXiv:1208.3486, arXiv:1303.7300 by other authors",
        "subjects": "Cryptography and Security (cs.CR)",
        "abstract": "The emergence of the Mobile Ad Hoc Networking (MANET) technology advocates self-organized wireless interconnection of communication devices that would either extend or operate in concert with the wired networking infrastructure or, possibly, evolve to autonomous networks. In either case, the proliferation of MANET-based applications depends on a multitude of factors, with trustworthiness being one of the primary challenges to be met. Despite the existence of well-known security mechanisms, additional vulnerabilities and features pertinent to this new networking paradigm might render such traditional solutions inapplicable. In particular, the absence of a central authorization facility in an open and distributed communication environment is a major challenge, especially due to the need for cooperative network operation. In particular, in MANET, any node may compromise the routing protocol functionality by disrupting the route discovery process. In this paper, we present a route discovery protocol that mitigates the detrimental effects of such malicious behavior, as to provide correct connectivity information. Our protocol guarantees that fabricated, compromised, or replayed route replies would either be rejected or never reach back the querying node. Furthermore, the protocol responsiveness is safeguarded under different types of attacks that exploit the routing protocol itself. The sole requirement of the proposed scheme is the existence of a security association between the node initiating the query and the sought destination. Specifically, no assumption is made regarding the intermediate nodes, which may exhibit arbitrary and malicious behavior. The scheme is robust in the presence of a number of non-colluding nodes, and provides accurate routing information in a timely manner.\n    ",
        "primary_category": "cs.CR",
        "categories": [],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00405": {
        "title": "SoK: Cross-Chain Bridging Architectural Design Flaws and Mitigations",
        "authors": [
            "Jakob Svennevik Notland",
            "Jinguye Li",
            "Mariusz Nowostawski",
            "Peter Halland Haro"
        ],
        "comments": " ",
        "subjects": "Cryptography and Security (cs.CR)",
        "abstract": "Cross-chain bridges are solutions that enable interoperability between heterogeneous blockchains. In contrast to the underlying blockchains, the bridges often provide inferior security guarantees and have been targets of hacks causing damage in the range of 1.5 to 2 billion USD in 2022. The current state of bridge architectures is that they are ambiguous, and there is next to no notion of how different architectures and their components are related to different vulnerabilities. Throughout this study, we have analysed 60 different bridges and 34 bridge exploits in the last three years (2021-2023). Our analyses identified 13 architectural components of the bridges. We linked the components to eight types of vulnerabilities, also called design flaws. We identified prevention measures and proposed 11 impact reduction measures based on the existing and possible countermeasures to address the imminent exploits of the design flaws. The results are meant to be used as guidelines for designing and implementing secure cross-chain bridge architectures, preventing design flaws, and mitigating the negative impacts of exploits.\n    ",
        "primary_category": "cs.CR",
        "categories": [],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00406": {
        "title": "Adaptive Restructuring of Merkle and Verkle Trees for Enhanced Blockchain Scalability",
        "authors": [
            "Oleksandr Kuznetsov",
            "Dzianis Kanonik",
            "Alex Rusnak",
            "Anton Yezhov",
            "Oleksandr Domin"
        ],
        "comments": " ",
        "subjects": "Cryptography and Security (cs.CR)",
        "abstract": "The scalability of blockchain technology remains a pivotal challenge, impeding its widespread adoption across various sectors. This study introduces an innovative approach to address this challenge by proposing the adaptive restructuring of Merkle and Verkle trees, fundamental components of blockchain architecture responsible for ensuring data integrity and facilitating efficient verification processes. Unlike traditional static tree structures, our adaptive model dynamically adjusts the configuration of these trees based on usage patterns, significantly reducing the average path length required for verification and, consequently, the computational overhead associated with these processes. Through a comprehensive conceptual framework, we delineate the methodology for adaptive restructuring, encompassing both binary and non-binary tree configurations. This framework is validated through a series of detailed examples, demonstrating the practical feasibility and the efficiency gains achievable with our approach. Moreover, we present a comparative analysis with existing scalability solutions, highlighting the unique advantages of adaptive restructuring in terms of simplicity, security, and efficiency enhancement without introducing additional complexities or dependencies. This study's implications extend beyond theoretical advancements, offering a scalable, secure, and efficient method for blockchain data verification that could facilitate broader adoption of blockchain technology in finance, supply chain management, and beyond. As the blockchain ecosystem continues to evolve, the principles and methodologies outlined herein are poised to contribute significantly to its growth and maturity.\n    ",
        "primary_category": "cs.CR",
        "categories": [],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00412": {
        "title": "Improved Bounds for Point Selections and Halving Hyperplanes in Higher Dimensions",
        "authors": [
            "Natan Rubin"
        ],
        "comments": "A preliminary version has appeared in the Proceedings of the 2024 Annual ACM-SIAM Symposium on Discrete Algorithms (SODA)",
        "subjects": "Combinatorics (math.CO)",
        "abstract": "Let $(P,E)$ be a $(d+1)$-uniform geometric hypergraph, where $P$ is an $n$-point set in general position in $\\mathbb{R}^d$ and $E\\subseteq {P\\choose d+1}$ is a collection of $\\epsilon{n\\choose d+1}$ $d$-dimensional simplices with vertices in $P$, for $0<\\epsilon\\leq 1$. We show that there is a point $x\\in {\\mathbb R}^d$ that pierces $\\displaystyle \\Omega\\left(\\epsilon^{(d^4+d)(d+1)+\\delta}{n\\choose d+1}\\right)$ simplices in $E$, for any fixed $\\delta>0$. This is a dramatic improvement in all dimensions $d\\geq 3$, over the previous lower bounds of the general form $\\displaystyle \\epsilon^{(cd)^{d+1}}n^{d+1}$, which date back to the seminal 1991 work of Alon, B\u00e1r\u00e1ny, F\u00fcredi and Kleitman.\nAs a result, any $n$-point set in general position in $\\mathbb{R}^d$ admits only $\\displaystyle O\\left(n^{d-\\frac{1}{d(d-1)^4+d(d-1)}+\\delta}\\right)$ halving hyperplanes, for any $\\delta>0$, which is a significant improvement over the previously best known bound $\\displaystyle O\\left(n^{d-\\frac{1}{(2d)^{d}}}\\right)$ in all dimensions $d\\geq 5$.\nAn essential ingredient of our proof is the following semi-algebraic Tur\u00e1n-type result of independent interest: Let $(V_1,\\ldots,V_k,E)$ be a hypergraph of bounded semi-algebraic description complexity in ${\\mathbb R}^d$ that satisfies $|E|\\geq \\varepsilon |V_1|\\cdot\\ldots \\cdot |V_k|$ for some $\\varepsilon>0$. Then there exist subsets $W_i\\subseteq V_i$ that satisfy $W_1\\times W_2\\times\\ldots\\times W_k\\subseteq E$, and $|W_1|\\cdot\\ldots\\cdots|W_k|=\\Omega\\left(\\varepsilon^{d(k-1)+1}|V_1|\\cdot |V_2|\\cdot\\ldots\\cdot|V_k|\\right)$.\n    ",
        "primary_category": "math.CO",
        "categories": [
            "cs.CG"
        ],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00416": {
        "title": "Data-efficient Event Camera Pre-training via Disentangled Masked Modeling",
        "authors": [
            "Zhenpeng Huang",
            "Chao Li",
            "Hao Chen",
            "Yongjian Deng",
            "Yifeng Geng",
            "Limin Wang"
        ],
        "comments": " ",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "In this paper, we present a new data-efficient voxel-based self-supervised learning method for event cameras. Our pre-training overcomes the limitations of previous methods, which either sacrifice temporal information by converting event sequences into 2D images for utilizing pre-trained image models or directly employ paired image data for knowledge distillation to enhance the learning of event streams. In order to make our pre-training data-efficient, we first design a semantic-uniform masking method to address the learning imbalance caused by the varying reconstruction difficulties of different regions in non-uniform data when using random masking. In addition, we ease the traditional hybrid masked modeling process by explicitly decomposing it into two branches, namely local spatio-temporal reconstruction and global semantic reconstruction to encourage the encoder to capture local correlations and global semantics, respectively. This decomposition allows our selfsupervised learning method to converge faster with minimal pre-training data. Compared to previous approaches, our self-supervised learning method does not rely on paired RGB images, yet enables simultaneous exploration of spatial and temporal cues in multiple scales. It exhibits excellent generalization performance and demonstrates significant improvements across various tasks with fewer parameters and lower computational costs.\n    ",
        "primary_category": "cs.CV",
        "categories": [],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00417": {
        "title": "Rethinking Tokenization: Crafting Better Tokenizers for Large Language Models",
        "authors": [
            "Jinbiao Yang"
        ],
        "comments": " ",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "Tokenization significantly influences language models(LMs)' performance. This paper traces the evolution of tokenizers from word-level to subword-level, analyzing how they balance tokens and types to enhance model adaptability while controlling complexity. Despite subword tokenizers like Byte Pair Encoding (BPE) overcoming many word tokenizer limitations, they encounter difficulties in handling non-Latin languages and depend heavily on extensive training data and computational resources to grasp the nuances of multiword expressions (MWEs). This article argues that tokenizers, more than mere technical tools, should drawing inspiration from the cognitive science about human language processing. This study then introduces the \"Principle of Least Effort\" from cognitive science, that humans naturally seek to reduce cognitive effort, and discusses the benefits of this principle for tokenizer development. Based on this principle, the paper proposes that the Less-is-Better (LiB) model could be a new approach for LLM tokenizer. The LiB model can autonomously learn an integrated vocabulary consisting of subwords, words, and MWEs, which effectively reduces both the numbers of tokens and types. Comparative evaluations show that the LiB tokenizer outperforms existing word and BPE tokenizers, presenting an innovative method for tokenizer development, and hinting at the possibility of future cognitive science-based tokenizers being more efficient.\n    ",
        "primary_category": "cs.CL",
        "categories": [],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00418": {
        "title": "LLMs for Targeted Sentiment in News Headlines: Exploring Different Levels of Prompt Prescriptiveness",
        "authors": [
            "Jana Juro\u0161",
            "Laura Majer",
            "Jan \u0160najder"
        ],
        "comments": " ",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "News headlines often evoke sentiment by intentionally portraying entities in particular ways, making targeted sentiment analysis (TSA) of headlines a worthwhile but difficult task. Fine-tuned encoder models show satisfactory TSA performance, but their background knowledge is limited, and they require a labeled dataset. LLMs offer a potentially universal solution for TSA due to their broad linguistic and world knowledge along with in-context learning abilities, yet their performance is heavily influenced by prompt design. Drawing parallels with annotation paradigms for subjective tasks, we explore the influence of prompt design on the performance of LLMs for TSA of news headlines. We evaluate the predictive accuracy of state-of-the-art LLMs using prompts with different levels of prescriptiveness, ranging from plain zero-shot to elaborate few-shot prompts matching annotation guidelines. Recognizing the subjective nature of TSA, we evaluate the ability of LLMs to quantify predictive uncertainty via calibration error and correlation to human inter-annotator agreement. We find that, except for few-shot prompting, calibration and F1-score improve with increased prescriptiveness, but the optimal level depends on the model.\n    ",
        "primary_category": "cs.CL",
        "categories": [],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00420": {
        "title": "Robust Deep Reinforcement Learning Through Adversarial Attacks and Training : A Survey",
        "authors": [
            "Lucas Schott",
            "Josephine Delas",
            "Hatem Hajri",
            "Elies Gherbi",
            "Reda Yaich",
            "Nora Boulahia-Cuppens",
            "Frederic Cuppens",
            "Sylvain Lamprier"
        ],
        "comments": "57 pages, 16 figues, 2 tables",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Deep Reinforcement Learning (DRL) is an approach for training autonomous agents across various complex environments. Despite its significant performance in well known environments, it remains susceptible to minor conditions variations, raising concerns about its reliability in real-world applications. To improve usability, DRL must demonstrate trustworthiness and robustness. A way to improve robustness of DRL to unknown changes in the conditions is through Adversarial Training, by training the agent against well suited adversarial attacks on the dynamics of the environment. Addressing this critical issue, our work presents an in-depth analysis of contemporary adversarial attack methodologies, systematically categorizing them and comparing their objectives and operational mechanisms. This classification offers a detailed insight into how adversarial attacks effectively act for evaluating the resilience of DRL agents, thereby paving the way for enhancing their robustness.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00423": {
        "title": "Validation of ML-UQ calibration statistics using simulated reference values: a sensitivity analysis",
        "authors": [
            "Pascal Pernot"
        ],
        "comments": " ",
        "subjects": "Machine Learning (stat.ML)",
        "abstract": "Some popular Machine Learning Uncertainty Quantification (ML-UQ) calibration statistics do not have predefined reference values and are mostly used in comparative studies. In consequence, calibration is almost never validated and the diagnostic is left to the appreciation of the reader. Simulated reference values, based on synthetic calibrated datasets derived from actual uncertainties, have been proposed to palliate this problem. As the generative probability distribution for the simulation of synthetic errors is often not constrained, the sensitivity of simulated reference values to the choice of generative distribution might be problematic, shedding a doubt on the calibration diagnostic. This study explores various facets of this problem, and shows that some statistics are excessively sensitive to the choice of generative distribution to be used for validation when the generative distribution is unknown. This is the case, for instance, of the correlation coefficient between absolute errors and uncertainties (CC) and of the expected normalized calibration error (ENCE). A robust validation workflow to deal with simulated reference values is proposed.\n    ",
        "primary_category": "stat.ML",
        "categories": [
            "cs.LG",
            "physics.chem-ph"
        ],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00424": {
        "title": "Data-Based Control of Continuous-Time Linear Systems with Performance Specifications",
        "authors": [
            "Victor G. Lopez",
            "Matthias A. M\u00fcller"
        ],
        "comments": "16 pages, 1 figure",
        "subjects": "Systems and Control (eess.SY)",
        "abstract": "The design of direct data-based controllers has become a fundamental part of control theory research in the last few years. In this paper, we consider three classes of data-based state feedback control problems for linear systems. These control problems are such that, besides stabilization, some additional performance requirements must be satisfied. First, we formulate and solve a trajectory-reference control problem, on which desired closed-loop trajectories are known and a controller that allows the system to closely follow those trajectories is computed. Then, in the area of data-based optimal control, we solve two different problems: the inverse problem of optimal control, and the solution of the LQR problem for continuous-time systems. Finally, we consider the case in which the precise position of the desired poles of the closed-loop system is known, and introduce a data-based variant of a robust pole-placement procedure. Although we focus on continuous-time systems, all of the presented methods can also be easily formulated for the discrete-time case. The applicability of the proposed methods is tested using numerical simulations.\n    ",
        "primary_category": "eess.SY",
        "categories": [],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00425": {
        "title": "HALC: Object Hallucination Reduction via Adaptive Focal-Contrast Decoding",
        "authors": [
            "Zhaorun Chen",
            "Zhuokai Zhao",
            "Hongyin Luo",
            "Huaxiu Yao",
            "Bo Li",
            "Jiawei Zhou"
        ],
        "comments": "Code is released at this https URL",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "While large vision-language models (LVLMs) have demonstrated impressive capabilities in interpreting multi-modal contexts, they invariably suffer from object hallucinations (OH). We introduce HALC, a novel decoding algorithm designed to mitigate OH in LVLMs. HALC leverages distinct fine-grained optimal visual information in vision-language tasks and operates on both local and global contexts simultaneously. Specifically, HALC integrates a robust auto-focal grounding mechanism (locally) to correct hallucinated tokens on the fly, and a specialized beam search algorithm (globally) to significantly reduce OH while preserving text generation quality. Additionally, HALC can be integrated into any LVLMs as a plug-and-play module without extra training. Extensive experimental studies demonstrate the effectiveness of HALC in reducing OH, outperforming state-of-the-arts across four benchmarks.\n    ",
        "primary_category": "cs.CV",
        "categories": [
            "cs.AI",
            "cs.LG"
        ],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00426": {
        "title": "Deep Learning Computed Tomography based on the Defrise and Clack Algorithm",
        "authors": [
            "Chengze Ye",
            "Linda-Sophie Schneider",
            "Yipeng Sun",
            "Andreas Maier"
        ],
        "comments": " ",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "This study presents a novel approach for reconstructing cone beam computed tomography (CBCT) for specific orbits using known operator learning. Unlike traditional methods, this technique employs a filtered backprojection type (FBP-type) algorithm, which integrates a unique, adaptive filtering process. This process involves a series of operations, including weightings, differentiations, the 2D Radon transform, and backprojection. The filter is designed for a specific orbit geometry and is obtained using a data-driven approach based on deep learning. The approach efficiently learns and optimizes the orbit-related component of the filter. The method has demonstrated its ability through experimentation by successfully learning parameters from circular orbit projection data. Subsequently, the optimized parameters are used to reconstruct images, resulting in outcomes that closely resemble the analytical solution. This demonstrates the potential of the method to learn appropriate parameters from any specific orbit projection data and achieve reconstruction. The algorithm has demonstrated improvement, particularly in enhancing reconstruction speed and reducing memory usage for handling specific orbit reconstruction.\n    ",
        "primary_category": "cs.CV",
        "categories": [],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00430": {
        "title": "Introducing locality in some generalized AG codes",
        "authors": [
            "Bastien Pacifico"
        ],
        "comments": "18 pages",
        "subjects": "Information Theory (cs.IT)",
        "abstract": "In 1999, Xing, Niederreiter and Lam introduced a generalization of AG codes using the evaluation at non-rational places of a function field. In this paper, we show that one can obtain a locality parameter $r$ in such codes by using only non-rational places of degrees at most $r$. This is, up to the author's knowledge, a new way to construct locally recoverable codes (LRCs). We give an example of such a code reaching the Singleton-like bound for LRCs, and show the parameters obtained for some longer codes over $\\mathbb F_3$. We then investigate similarities with certain concatenated codes. Contrary to previous methods, our construction allows one to obtain directly codes whose dimension is not a multiple of the locality. Finally, we give an asymptotic study using the Garcia-Stichtenoth tower of function fields, for both our construction and a construction of concatenated codes. We give explicit infinite families of LRCs with locality 2 over any finite field of cardinality greater than 3 following our new approach.\n    ",
        "primary_category": "cs.IT",
        "categories": [
            "math.AG"
        ],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00431": {
        "title": "Robotic Process Automation as a Driver for Sustainable Innovation and Entrepreneurship",
        "authors": [
            "Petr Prucha"
        ],
        "comments": "XB-CON International Conference 2023, Zelezna Ruda, Czechia",
        "subjects": "Computers and Society (cs.CY)",
        "abstract": "Technological innovation plays a crucial role in driving economic growth and development. In this study, we investigate the extent to which technological innovation contributes to a more sustainable future and fosters entrepreneurship. To examine this, we focus on robotic process automation (RPA) highly relevant technology. We conducted a comprehensive analysis by examining the usage of RPA and its impact on environmental, social, and governance (ESG) factors. Our research involved gathering data from the 300 largest companies in terms of market capitalization. We assessed whether these companies used RPA and obtained their corresponding ESG ratings. To investigate the relationship between RPA and ESG, we employed a contingency table analysis, which involved categorizing the data based on ESG ratings. We further used Pearson's Chi-square Test of Independence to assess the impact of RPA on ESG. Our findings revealed a statistically significant association between RPA and ESG ratings, indicating their interconnection. The calculated value for Pearson's Chi-square Test of Independence was 6.54, with a corresponding p-value of 0.0381. This indicates that at a significance level of five percent, the RPA and ESG variables depend on each other. These results suggest that RPA, representative of modern technologies, likely influences the achievement of a sustainable future and the promotion of entrepreneurship. In conclusion, our study provides empirical evidence supporting the notion that technological innovations such as RPA have the potential to positively shape sustainability efforts and entrepreneurial endeavours.\n    ",
        "primary_category": "cs.CY",
        "categories": [],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00433": {
        "title": "Jiagu: Optimizing Serverless Computing Resource Utilization with Harmonized Efficiency and Practicability",
        "authors": [
            "Qingyuan Liu",
            "Yanning Yang",
            "Dong Du",
            "Yubin Xia",
            "Ping Zhang",
            "Jia Feng",
            "James Larus",
            "Haibo Chen"
        ],
        "comments": "17 pages, 17 figures",
        "subjects": "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "abstract": "Current serverless platforms struggle to optimize resource utilization due to their dynamic and fine-grained nature. Conventional techniques like overcommitment and autoscaling fall short, often sacrificing utilization for practicability or incurring performance trade-offs. Overcommitment requires predicting performance to prevent QoS violation, introducing trade-off between prediction accuracy and overheads. Autoscaling requires scaling instances in response to load fluctuations quickly to reduce resource wastage, but more frequent scaling also leads to more cold start overheads. This paper introduces Jiagu, which harmonizes efficiency with practicability through two novel techniques. First, pre-decision scheduling achieves accurate prediction while eliminating overheads by decoupling prediction and scheduling. Second, dual-staged scaling achieves frequent adjustment of instances with minimum overhead. We have implemented a prototype and evaluated it using real-world applications and traces from the public cloud platform. Our evaluation shows a 54.8% improvement in deployment density over commercial clouds (with Kubernetes) while maintaining QoS, and 81.0%--93.7% lower scheduling costs and a 57.4%--69.3% reduction in cold start latency compared to existing QoS-aware schedulers in research work.\n    ",
        "primary_category": "cs.DC",
        "categories": [],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00434": {
        "title": "Probabilistic Semantic Communication over Wireless Networks with Rate Splitting",
        "authors": [
            "Zhouxiang Zhao",
            "Zhaohui Yang",
            "Ye Hu",
            "Qianqian Yang",
            "Wei Xu",
            "Zhaoyang Zhang"
        ],
        "comments": " ",
        "subjects": "Information Theory (cs.IT)",
        "abstract": "In this paper, the problem of joint transmission and computation resource allocation for probabilistic semantic communication (PSC) system with rate splitting multiple access (RSMA) is investigated. In the considered model, the base station (BS) needs to transmit a large amount of data to multiple users with RSMA. Due to limited communication resources, the BS is required to utilize semantic communication techniques to compress the large-sized data. The semantic communication is enabled by shared probability graphs between the BS and the users. The probability graph can be used to further compress the transmission data at the BS, while the received compressed semantic information can be recovered through using the same shared probability graph at each user side. The semantic information compression progress consumes additional computation power at the BS, which inevitably decreases the transmission power due to limited total power budget. Considering both the effect of semantic compression ratio and computation power, the semantic rate expression for RSMA is first obtained. Then, based on the obtained rate expression, an optimization problem is formulated with the aim of maximizing the sum of semantic rates of all users under total power, semantic compression ratio, and rate allocation constraints. To tackle this problem, an iterative algorithm is proposed, where the rate allocation and transmit beamforming design subproblem is solved using a successive convex approximation method, and the semantic compression ratio subproblem is addressed using a greedy algorithm. Numerical results validate the effectiveness of the proposed scheme.\n    ",
        "primary_category": "cs.IT",
        "categories": [
            "eess.SP"
        ],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00435": {
        "title": "Hierarchical Indexing for Retrieval-Augmented Opinion Summarization",
        "authors": [
            "Tom Hosking",
            "Hao Tang",
            "Mirella Lapata"
        ],
        "comments": "Preprint",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "We propose a method for unsupervised abstractive opinion summarization, that combines the attributability and scalability of extractive approaches with the coherence and fluency of Large Language Models (LLMs). Our method, HIRO, learns an index structure that maps sentences to a path through a semantically organized discrete hierarchy. At inference time, we populate the index and use it to identify and retrieve clusters of sentences containing popular opinions from input reviews. Then, we use a pretrained LLM to generate a readable summary that is grounded in these extracted evidential clusters. The modularity of our approach allows us to evaluate its efficacy at each stage. We show that HIRO learns an encoding space that is more semantically structured than prior work, and generates summaries that are more representative of the opinions in the input reviews. Human evaluation confirms that HIRO generates more coherent, detailed and accurate summaries that are significantly preferred by annotators compared to prior work.\n    ",
        "primary_category": "cs.CL",
        "categories": [],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00436": {
        "title": "Abductive Ego-View Accident Video Understanding for Safe Driving Perception",
        "authors": [
            "Jianwu Fang",
            "Lei-lei Li",
            "Junfei Zhou",
            "Junbin Xiao",
            "Hongkai Yu",
            "Chen Lv",
            "Jianru Xue",
            "Tat-Seng Chua"
        ],
        "comments": "Accepted by CVPR2024. This is not the camera-ready version. The Project page: this http URL",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "We present MM-AU, a novel dataset for Multi-Modal Accident video Understanding. MM-AU contains 11,727 in-the-wild ego-view accident videos, each with temporally aligned text descriptions. We annotate over 2.23 million object boxes and 58,650 pairs of video-based accident reasons, covering 58 accident categories. MM-AU supports various accident understanding tasks, particularly multimodal video diffusion to understand accident cause-effect chains for safe driving. With MM-AU, we present an Abductive accident Video understanding framework for Safe Driving perception (AdVersa-SD). AdVersa-SD performs video diffusion via an Object-Centric Video Diffusion (OAVD) method which is driven by an abductive CLIP model. This model involves a contrastive interaction loss to learn the pair co-occurrence of normal, near-accident, accident frames with the corresponding text descriptions, such as accident reasons, prevention advice, and accident categories. OAVD enforces the causal region learning while fixing the content of the original frame background in video generation, to find the dominant cause-effect chain for certain accidents. Extensive experiments verify the abductive ability of AdVersa-SD and the superiority of OAVD against the state-of-the-art diffusion models. Additionally, we provide careful benchmark evaluations for object detection and accident reason answering since AdVersa-SD relies on precise object and accident reason information.\n    ",
        "primary_category": "cs.CV",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00437": {
        "title": "LoMOE: Localized Multi-Object Editing via Multi-Diffusion",
        "authors": [
            "Goirik Chakrabarty",
            "Aditya Chandrasekar",
            "Ramya Hebbalaguppe",
            "Prathosh AP"
        ],
        "comments": "18 pages",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Recent developments in the field of diffusion models have demonstrated an exceptional capacity to generate high-quality prompt-conditioned image edits. Nevertheless, previous approaches have primarily relied on textual prompts for image editing, which tend to be less effective when making precise edits to specific objects or fine-grained regions within a scene containing single/multiple objects. We introduce a novel framework for zero-shot localized multi-object editing through a multi-diffusion process to overcome this challenge. This framework empowers users to perform various operations on objects within an image, such as adding, replacing, or editing $\\textbf{many}$ objects in a complex scene $\\textbf{in one pass}$. Our approach leverages foreground masks and corresponding simple text prompts that exert localized influences on the target regions resulting in high-fidelity image editing. A combination of cross-attention and background preservation losses within the latent space ensures that the characteristics of the object being edited are preserved while simultaneously achieving a high-quality, seamless reconstruction of the background with fewer artifacts compared to the current methods. We also curate and release a dataset dedicated to multi-object editing, named $\\texttt{LoMOE}$-Bench. Our experiments against existing state-of-the-art methods demonstrate the improved effectiveness of our approach in terms of both image editing quality and inference speed.\n    ",
        "primary_category": "cs.CV",
        "categories": [
            "cs.AI",
            "cs.GR",
            "cs.LG"
        ],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00438": {
        "title": "Your Model Is Not Predicting Depression Well And That Is Why: A Case Study of PRIMATE Dataset",
        "authors": [
            "Kirill Milintsevich",
            "Kairit Sirts",
            "Ga\u00ebl Dias"
        ],
        "comments": " ",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "This paper addresses the quality of annotations in mental health datasets used for NLP-based depression level estimation from social media texts. While previous research relies on social media-based datasets annotated with binary categories, i.e. depressed or non-depressed, recent datasets such as D2S and PRIMATE aim for nuanced annotations using PHQ-9 symptoms. However, most of these datasets rely on crowd workers without the domain knowledge for annotation. Focusing on the PRIMATE dataset, our study reveals concerns regarding annotation validity, particularly for the lack of interest or pleasure symptom. Through reannotation by a mental health professional, we introduce finer labels and textual spans as evidence, identifying a notable number of false positives. Our refined annotations, to be released under a Data Use Agreement, offer a higher-quality test set for anhedonia detection. This study underscores the necessity of addressing annotation quality issues in mental health datasets, advocating for improved methodologies to enhance NLP model reliability in mental health assessments.\n    ",
        "primary_category": "cs.CL",
        "categories": [],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00439": {
        "title": "Authors' Values and Attitudes Towards AI-bridged Scalable Personalization of Creative Language Arts",
        "authors": [
            "Taewook Kim",
            "Hyomin Han",
            "Eytan Adar",
            "Matthew Kay",
            "John Joon Young Chung"
        ],
        "comments": "16 pages, 6 figures, 2 tables. Accepted to ACM CHI 2024",
        "subjects": "Human-Computer Interaction (cs.HC)",
        "abstract": "Generative AI has the potential to create a new form of interactive media: AI-bridged creative language arts (CLA), which bridge the author and audience by personalizing the author's vision to the audience's context and taste at scale. However, it is unclear what the authors' values and attitudes would be regarding AI-bridged CLA. To identify these values and attitudes, we conducted an interview study with 18 authors across eight genres (e.g., poetry, comics) by presenting speculative but realistic AI-bridged CLA scenarios. We identified three benefits derived from the dynamics between author, artifact, and audience: those that 1) authors get from the process, 2) audiences get from the artifact, and 3) authors get from the audience. We found how AI-bridged CLA would either promote or reduce these benefits, along with authors' concerns. We hope our investigation hints at how AI can provide intriguing experiences to CLA audiences while promoting authors' values.\n    ",
        "primary_category": "cs.HC",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00446": {
        "title": "Safe Hybrid-Action Reinforcement Learning-Based Decision and Control for Discretionary Lane Change",
        "authors": [
            "Ruichen Xu",
            "Xiao Liu",
            "Jinming Xu",
            "Yuan Lin"
        ],
        "comments": " ",
        "subjects": "Robotics (cs.RO)",
        "abstract": "Autonomous lane-change, a key feature of advanced driver-assistance systems, can enhance traffic efficiency and reduce the incidence of accidents. However, safe driving of autonomous vehicles remains challenging in complex environments. How to perform safe and appropriate lane change is a popular topic of research in the field of autonomous driving. Currently, few papers consider the safety of reinforcement learning in autonomous lane-change scenarios. We introduce safe hybrid-action reinforcement learning into discretionary lane change for the first time and propose Parameterized Soft Actor-Critic with PID Lagrangian (PASAC-PIDLag) algorithm. Furthermore, we conduct a comparative analysis of the Parameterized Soft Actor-Critic (PASAC), which is an unsafe version of PASAC-PIDLag. Both algorithms are employed to train the lane-change strategy of autonomous vehicles to output discrete lane-change decision and longitudinal vehicle acceleration. Our simulation results indicate that at a traffic density of 15 vehicles per kilometer (15 veh/km), the PASAC-PIDLag algorithm exhibits superior safety with a collision rate of 0%, outperforming the PASAC algorithm, which has a collision rate of 1%. The outcomes of the generalization assessments reveal that at low traffic density levels, both the PASAC-PIDLag and PASAC algorithms are proficient in attaining a 0% collision rate. Under conditions of high traffic flow density, the PASAC-PIDLag algorithm surpasses PASAC in terms of both safety and optimality.\n    ",
        "primary_category": "cs.RO",
        "categories": [
            "cs.LG"
        ],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00448": {
        "title": "When Large Language Models Confront Repository-Level Automatic Program Repair: How Well They Done?",
        "authors": [
            "Yuxiao Chen",
            "Jingzheng Wu",
            "Xiang Ling",
            "Changjiang Li",
            "Zhiqing Rui",
            "Tianyue Luo",
            "Yanjun Wu"
        ],
        "comments": "Accepted by ICSE 2024 Industry Challenge Track",
        "subjects": "Software Engineering (cs.SE)",
        "abstract": "In recent years, large language models (LLMs) have demonstrated substantial potential in addressing automatic program repair (APR) tasks. However, the current evaluation of these models for APR tasks focuses solely on the limited context of the single function or file where the bug is located, overlooking the valuable information in the repository-level context. This paper investigates the performance of popular LLMs in handling repository-level repair tasks. We introduce RepoBugs, a new benchmark comprising 124 typical repository-level bugs from open-source repositories. Preliminary experiments using GPT3.5 based on the function where the error is located, reveal that the repair rate on RepoBugs is only 22.58%, significantly diverging from the performance of GPT3.5 on function-level bugs in related studies. This underscores the importance of providing repository-level context when addressing bugs at this level. However, the repository-level context offered by the preliminary method often proves redundant and imprecise and easily exceeds the prompt length limit of LLMs. To solve the problem, we propose a simple and universal repository-level context extraction method (RLCE) designed to provide more precise context for repository-level code repair tasks. Evaluations of three mainstream LLMs show that RLCE significantly enhances the ability to repair repository-level bugs. The improvement reaches a maximum of 160% compared to the preliminary method. Additionally, we conduct a comprehensive analysis of the effectiveness and limitations of RLCE, along with the capacity of LLMs to address repository-level bugs, offering valuable insights for future research.\n    ",
        "primary_category": "cs.SE",
        "categories": [],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00450": {
        "title": "Parallel Hyperparameter Optimization Of Spiking Neural Network",
        "authors": [
            "Thomas Firmin",
            "Pierre Boulet",
            "El-Ghazali Talbi"
        ],
        "comments": " ",
        "subjects": "Neural and Evolutionary Computing (cs.NE)",
        "abstract": "Spiking Neural Networks (SNN). SNNs are based on a more biologically inspired approach than usual artificial neural networks. Such models are characterized by complex dynamics between neurons and spikes. These are very sensitive to the hyperparameters, making their optimization challenging. To tackle hyperparameter optimization of SNNs, we initially extended the signal loss issue of SNNs to what we call silent networks. These networks fail to emit enough spikes at their outputs due to mistuned hyperparameters or architecture. Generally, search spaces are heavily restrained, sometimes even discretized, to prevent the sampling of such networks. By defining an early stopping criterion detecting silent networks and by designing specific constraints, we were able to instantiate larger and more flexible search spaces. We applied a constrained Bayesian optimization technique, which was asynchronously parallelized, as the evaluation time of a SNN is highly stochastic. Large-scale experiments were carried-out on a multi-GPU Petascale architecture. By leveraging silent networks, results show an acceleration of the search, while maintaining good performances of both the optimization algorithm and the best solution obtained. We were able to apply our methodology to two popular training algorithms, known as spike timing dependent plasticity and surrogate gradient. Early detection allowed us to prevent worthless and costly computation, directing the search toward promising hyperparameter combinations. Our methodology could be applied to multi-objective problems, where the spiking activity is often minimized to reduce the energy consumption. In this scenario, it becomes essential to find the delicate frontier between low-spiking and silent networks. Finally, our approach may have implications for neural architecture search, particularly in defining suitable spiking architectures.\n    ",
        "primary_category": "cs.NE",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00452": {
        "title": "An Ordinal Diffusion Model for Generating Medical Images with Different Severity Levels",
        "authors": [
            "Shumpei Takezaki",
            "Seiichi Uchida"
        ],
        "comments": "Accepted at ISBI2024",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Diffusion models have recently been used for medical image generation because of their high image quality. In this study, we focus on generating medical images with ordinal classes, which have ordinal relationships, such as severity levels. We propose an Ordinal Diffusion Model (ODM) that controls the ordinal relationships of the estimated noise images among the classes. Our model was evaluated experimentally by generating retinal and endoscopic images of multiple severity classes. ODM achieved higher performance than conventional generative models by generating realistic images, especially in high-severity classes with fewer training samples.\n    ",
        "primary_category": "cs.CV",
        "categories": [],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00454": {
        "title": "Shorts vs. Regular Videos on YouTube: A Comparative Analysis of User Engagement and Content Creation Trends",
        "authors": [
            "Caroline Violot",
            "Tu\u011frulcan Elmas",
            "Igor Bilogrevic",
            "Mathias Humbert"
        ],
        "comments": "11 pages, 9 figures, to be published in the proceedings of ACM Web Science Conference 2024 (WEBSCI24)",
        "subjects": "Social and Information Networks (cs.SI)",
        "abstract": "YouTube introduced the Shorts video format in 2021, allowing users to upload short videos that are prominently displayed on its website and app. Despite having such a large visual footprint, there are no studies to date that have looked at the impact Shorts introduction had on the production and consumption of content on YouTube. This paper presents the first comparative analysis of YouTube Shorts versus regular videos with respect to user engagement (i.e., views, likes, and comments), content creation frequency and video categories. We collected a dataset containing information about 70k channels that posted at least one Short, and we analyzed the metadata of all the videos (9.9M Shorts and 6.9M regular videos) they uploaded between January 2021 and December 2022, spanning a two-year period including the introduction of Shorts. Our longitudinal analysis shows that content creators consistently increased the frequency of Shorts production over this period, especially for newly-created channels, which surpassed that of regular videos. We also observe that Shorts target mostly entertainment categories, while regular videos cover a wide variety of categories. In general, Shorts attract more views and likes per view than regular videos, but attract less comments per view. However, Shorts do not outperform regular videos in the education and political categories as much as they do in other categories. Our study contributes to understanding social media dynamics, to quantifying the spread of short-form content, and to motivating future research on its impact on society.\n    ",
        "primary_category": "cs.SI",
        "categories": [],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00455": {
        "title": "A Survey on Self-healing Software System",
        "authors": [
            "Zahra Yazdanparast"
        ],
        "comments": " ",
        "subjects": "Software Engineering (cs.SE)",
        "abstract": "With the increasing complexity of software systems, it becomes very difficult to install, configure, adjust, and maintain them. As systems become more interconnected and diverse, system architects are less able to predict and design the interaction between components, deferring the handling of these issues to runtime. One of the important problems that occur during execution is system failures, which increase the need for self-healing systems. The main purpose of self-healing is to have an automatic system that can heal itself without human intervention. This system has predefined actions and procedures that are suitable for recovering the system from different failure modes. In this study, different self-healing methods are categorized and a summary of them is presented.\n    ",
        "primary_category": "cs.SE",
        "categories": [],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00459": {
        "title": "Deformable One-shot Face Stylization via DINO Semantic Guidance",
        "authors": [
            "Yang Zhou",
            "Zichong Chen",
            "Hui Huang"
        ],
        "comments": "Accepted to CVPR 2024. Project page: this https URL",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "This paper addresses the complex issue of one-shot face stylization, focusing on the simultaneous consideration of appearance and structure, where previous methods have fallen short. We explore deformation-aware face stylization that diverges from traditional single-image style reference, opting for a real-style image pair instead. The cornerstone of our method is the utilization of a self-supervised vision transformer, specifically DINO-ViT, to establish a robust and consistent facial structure representation across both real and style domains. Our stylization process begins by adapting the StyleGAN generator to be deformation-aware through the integration of spatial transformers (STN). We then introduce two innovative constraints for generator fine-tuning under the guidance of DINO semantics: i) a directional deformation loss that regulates directional vectors in DINO space, and ii) a relative structural consistency constraint based on DINO token self-similarities, ensuring diverse generation. Additionally, style-mixing is employed to align the color generation with the reference, minimizing inconsistent correspondences. This framework delivers enhanced deformability for general one-shot face stylization, achieving notable efficiency with a fine-tuning duration of approximately 10 minutes. Extensive qualitative and quantitative comparisons demonstrate our superiority over state-of-the-art one-shot face stylization methods. Code is available at this https URL\n",
        "primary_category": "cs.CV",
        "categories": [],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00464": {
        "title": "Attacking Delay-based PUFs with Minimal Adversary Model",
        "authors": [
            "Hongming Fei",
            "Owen Millwood",
            "Prosanta Gope",
            "Jack Miskelly",
            "Biplab Sikdar"
        ],
        "comments": "13 pages, 6 figures, journal",
        "subjects": "Cryptography and Security (cs.CR)",
        "abstract": "Physically Unclonable Functions (PUFs) provide a streamlined solution for lightweight device authentication. Delay-based Arbiter PUFs, with their ease of implementation and vast challenge space, have received significant attention; however, they are not immune to modelling attacks that exploit correlations between their inputs and outputs. Research is therefore polarized between developing modelling-resistant PUFs and devising machine learning attacks against them. This dichotomy often results in exaggerated concerns and overconfidence in PUF security, primarily because there lacks a universal tool to gauge a PUF's security. In many scenarios, attacks require additional information, such as PUF type or configuration parameters. Alarmingly, new PUFs are often branded `secure' if they lack a specific attack model upon introduction. To impartially assess the security of delay-based PUFs, we present a generic framework featuring a Mixture-of-PUF-Experts (MoPE) structure for mounting attacks on various PUFs with minimal adversarial knowledge, which provides a way to compare their performance fairly and impartially. We demonstrate the capability of our model to attack different PUF types, including the first successful attack on Heterogeneous Feed-Forward PUFs using only a reasonable amount of challenges and responses. We propose an extension version of our model, a Multi-gate Mixture-of-PUF-Experts (MMoPE) structure, facilitating multi-task learning across diverse PUFs to recognise commonalities across PUF designs. This allows a streamlining of training periods for attacking multiple PUFs simultaneously. We conclude by showcasing the potent performance of MoPE and MMoPE across a spectrum of PUF types, employing simulated, real-world unbiased, and biased data sets for analysis.\n    ",
        "primary_category": "cs.CR",
        "categories": [
            "cs.AR"
        ],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00467": {
        "title": "When ControlNet Meets Inexplicit Masks: A Case Study of ControlNet on its Contour-following Ability",
        "authors": [
            "Wenjie Xuan",
            "Yufei Xu",
            "Shanshan Zhao",
            "Chaoyue Wang",
            "Juhua Liu",
            "Bo Du",
            "Dacheng Tao"
        ],
        "comments": " ",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "ControlNet excels at creating content that closely matches precise contours in user-provided masks. However, when these masks contain noise, as a frequent occurrence with non-expert users, the output would include unwanted artifacts. This paper first highlights the crucial role of controlling the impact of these inexplicit masks with diverse deterioration levels through in-depth analysis. Subsequently, to enhance controllability with inexplicit masks, an advanced Shape-aware ControlNet consisting of a deterioration estimator and a shape-prior modulation block is devised. The deterioration estimator assesses the deterioration factor of the provided masks. Then this factor is utilized in the modulation block to adaptively modulate the model's contour-following ability, which helps it dismiss the noise part in the inexplicit masks. Extensive experiments prove its effectiveness in encouraging ControlNet to interpret inaccurate spatial conditions robustly rather than blindly following the given contours. We showcase application scenarios like modifying shape priors and composable shape-controllable generation. Codes are soon available.\n    ",
        "primary_category": "cs.CV",
        "categories": [],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00470": {
        "title": "Autonomous Robotic Arm Manipulation for Planetary Missions using Causal Machine Learning",
        "authors": [
            "C. McDonnell",
            "M. Arana-Catania",
            "S. Upadhyay"
        ],
        "comments": "8 pages, ASTRA 2023: 17th Symposium on Advanced Space Technologies in Robotics and Automation, 18-20 October 2023, Leiden, The Netherlands",
        "subjects": "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
        "abstract": "Autonomous robotic arm manipulators have the potential to make planetary exploration and in-situ resource utilization missions more time efficient and productive, as the manipulator can handle the objects itself and perform goal-specific actions. We train a manipulator to autonomously study objects of which it has no prior knowledge, such as planetary rocks. This is achieved using causal machine learning in a simulated planetary environment. Here, the manipulator interacts with objects, and classifies them based on differing causal factors. These are parameters, such as mass or friction coefficient, that causally determine the outcomes of its interactions. Through reinforcement learning, the manipulator learns to interact in ways that reveal the underlying causal factors. We show that this method works even without any prior knowledge of the objects, or any previously-collected training data. We carry out the training in planetary exploration conditions, with realistic manipulator models.\n    ",
        "primary_category": "astro-ph.IM",
        "categories": [
            "astro-ph.EP",
            "cs.LG",
            "cs.RO"
        ],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00473": {
        "title": "Computer-Controlled 3D Freeform Surface Weaving",
        "authors": [
            "Xiangjia Chen",
            "Lip M. Lai",
            "Zishun Liu",
            "Chengkai Dai",
            "Isaac C.W. Leung",
            "Charlie C.L. Wang",
            "Yeung Yam"
        ],
        "comments": " ",
        "subjects": "Graphics (cs.GR)",
        "abstract": "In this paper, we present a new computer-controlled weaving technology that enables the fabrication of woven structures in the shape of given 3D surfaces by using threads in non-traditional materials with high bending-stiffness, allowing for multiple applications with the resultant woven fabrics. A new weaving machine and a new manufacturing process are developed to realize the function of 3D surface weaving by the principle of short-row shaping. A computational solution is investigated to convert input 3D freeform surfaces into the corresponding weaving operations (indicated as W-code) to guide the operation of this system. A variety of examples using cotton threads, conductive threads and optical fibres are fabricated by our prototype system to demonstrate its functionality.\n    ",
        "primary_category": "cs.GR",
        "categories": [
            "cs.RO",
            "eess.SY"
        ],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00482": {
        "title": "Implicit high-order gas-kinetic schemes for compressible flows on three-dimensional unstructured meshes II: unsteady flows",
        "authors": [
            "Yaqing Yang",
            "Liang Pan",
            "Kun Xu"
        ],
        "comments": "arXiv admin note: text overlap with arXiv:2304.09485",
        "subjects": "Numerical Analysis (math.NA)",
        "abstract": "For the simulations of unsteady flow, the global time step becomes really small with a large variation of local cell size. In this paper, an implicit high-order gas-kinetic scheme (HGKS) is developed to remove the restrictions on the time step for unsteady simulations. In order to improve the efficiency and keep the high-order accuracy, a two-stage third-order implicit time-accurate discretization is proposed. In each stage, an artificial steady solution is obtained for the implicit system with the pseudo-time iteration. In the iteration, the classical implicit methods are adopted to solve the nonlinear system, including the lower-upper symmetric Gauss-Seidel (LUSGS) and generalized minimum residual (GMRES) methods. To achieve the spatial accuracy, the HGKSs with both non-compact and compact reconstructions are constructed. For the non-compact scheme, the weighted essentially non-oscillatory (WENO) reconstruction is used. For the compact one, the Hermite WENO (HWENO) reconstruction is adopted due to the updates of both cell-averaged flow variables and their derivatives. The expected third-order temporal accuracy is achieved with the two-stage temporal discretization. For the smooth flow, only a single artificial iteration is needed. For uniform meshes, the efficiency of the current implicit method improves significantly in comparison with the explicit one. For the flow with discontinuities, compared with the well-known Crank-Nicholson method, the spurious oscillations in the current schemes are well suppressed. The increase of the artificial iteration steps introduces extra reconstructions associating with a reduction of the computational efficiency. Overall, the current implicit method leads to an improvement in efficiency over the explicit one in the cases with a large variation of mesh size.\n    ",
        "primary_category": "math.NA",
        "categories": [
            "physics.flu-dyn"
        ],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00483": {
        "title": "RealCustom: Narrowing Real Text Word for Real-Time Open-Domain Text-to-Image Customization",
        "authors": [
            "Mengqi Huang",
            "Zhendong Mao",
            "Mingcong Liu",
            "Qian He",
            "Yongdong Zhang"
        ],
        "comments": "Accepted by CVPR2024",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Text-to-image customization, which aims to synthesize text-driven images for the given subjects, has recently revolutionized content creation. Existing works follow the pseudo-word paradigm, i.e., represent the given subjects as pseudo-words and then compose them with the given text. However, the inherent entangled influence scope of pseudo-words with the given text results in a dual-optimum paradox, i.e., the similarity of the given subjects and the controllability of the given text could not be optimal simultaneously. We present RealCustom that, for the first time, disentangles similarity from controllability by precisely limiting subject influence to relevant parts only, achieved by gradually narrowing real text word from its general connotation to the specific subject and using its cross-attention to distinguish relevance. Specifically, RealCustom introduces a novel \"train-inference\" decoupled framework: (1) during training, RealCustom learns general alignment between visual conditions to original textual conditions by a novel adaptive scoring module to adaptively modulate influence quantity; (2) during inference, a novel adaptive mask guidance strategy is proposed to iteratively update the influence scope and influence quantity of the given subjects to gradually narrow the generation of the real text word. Comprehensive experiments demonstrate the superior real-time customization ability of RealCustom in the open domain, achieving both unprecedented similarity of the given subjects and controllability of the given text for the first time. The project page is this https URL.\n    ",
        "primary_category": "cs.CV",
        "categories": [],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00485": {
        "title": "A Survey of Geometric Graph Neural Networks: Data Structures, Models and Applications",
        "authors": [
            "Jiaqi Han",
            "Jiacheng Cen",
            "Liming Wu",
            "Zongzhao Li",
            "Xiangzhe Kong",
            "Rui Jiao",
            "Ziyang Yu",
            "Tingyang Xu",
            "Fandi Wu",
            "Zihe Wang",
            "Hongteng Xu",
            "Zhewei Wei",
            "Yang Liu",
            "Yu Rong",
            "Wenbing Huang"
        ],
        "comments": " ",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Geometric graph is a special kind of graph with geometric features, which is vital to model many scientific problems. Unlike generic graphs, geometric graphs often exhibit physical symmetries of translations, rotations, and reflections, making them ineffectively processed by current Graph Neural Networks (GNNs). To tackle this issue, researchers proposed a variety of Geometric Graph Neural Networks equipped with invariant/equivariant properties to better characterize the geometry and topology of geometric graphs. Given the current progress in this field, it is imperative to conduct a comprehensive survey of data structures, models, and applications related to geometric GNNs. In this paper, based on the necessary but concise mathematical preliminaries, we provide a unified view of existing models from the geometric message passing perspective. Additionally, we summarize the applications as well as the related datasets to facilitate later research for methodology development and experimental evaluation. We also discuss the challenges and future potential directions of Geometric GNNs at the end of this survey.\n    ",
        "primary_category": "cs.LG",
        "categories": [],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00486": {
        "title": "Selective-Stereo: Adaptive Frequency Information Selection for Stereo Matching",
        "authors": [
            "Xianqi Wang",
            "Gangwei Xu",
            "Hao Jia",
            "Xin Yang"
        ],
        "comments": "Accepted to CVPR 2024",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Stereo matching methods based on iterative optimization, like RAFT-Stereo and IGEV-Stereo, have evolved into a cornerstone in the field of stereo matching. However, these methods struggle to simultaneously capture high-frequency information in edges and low-frequency information in smooth regions due to the fixed receptive field. As a result, they tend to lose details, blur edges, and produce false matches in textureless areas. In this paper, we propose Selective Recurrent Unit (SRU), a novel iterative update operator for stereo matching. The SRU module can adaptively fuse hidden disparity information at multiple frequencies for edge and smooth regions. To perform adaptive fusion, we introduce a new Contextual Spatial Attention (CSA) module to generate attention maps as fusion weights. The SRU empowers the network to aggregate hidden disparity information across multiple frequencies, mitigating the risk of vital hidden disparity information loss during iterative processes. To verify SRU's universality, we apply it to representative iterative stereo matching methods, collectively referred to as Selective-Stereo. Our Selective-Stereo ranks $1^{st}$ on KITTI 2012, KITTI 2015, ETH3D, and Middlebury leaderboards among all published methods. Code is available at this https URL.\n    ",
        "primary_category": "cs.CV",
        "categories": [],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00491": {
        "title": "Analyzing Divergence for Nondeterministic Probabilistic Models",
        "authors": [
            "Hao Wu",
            "Yuxi Fu",
            "Huan Long",
            "Xian Xu",
            "Wenbo Zhang"
        ],
        "comments": " ",
        "subjects": "Logic in Computer Science (cs.LO)",
        "abstract": "Branching and weak probabilistic bisimilarities are two well-known notions capturing behavioral equivalence between nondeterministic probabilistic systems. For probabilistic systems, divergence is of major concern. Recently several divergence-sensitive refinements of branching and weak probabilistic bisimilarities have been proposed in the literature. Both the definitions of these equivalences and the techniques to investigate them differ significantly. This paper presents a comprehensive comparative study on divergence-sensitive behavioral equivalence relations that refine the branching and weak probabilistic bisimilarities. Additionally, these equivalence relations are shown to have efficient checking algorithms. The techniques of this paper might be of independent interest in a more general setting.\n    ",
        "primary_category": "cs.LO",
        "categories": [],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00497": {
        "title": "Graph Homomorphism, Monotone Classes and Bounded Pathwidth",
        "authors": [
            "Tala Eagling-Vose",
            "Barnaby Martin",
            "Daniel Paulusma",
            "Mark Siggers",
            "Siani Smith"
        ],
        "comments": " ",
        "subjects": "Computational Complexity (cs.CC)",
        "abstract": "A recent paper describes a framework for studying the computational complexity of graph problems on monotone classes, that is those omitting a set of graphs as a subgraph. If the problems lie in the framework, and many do, then the computational complexity can be described for all monotone classes defined by a finite set of omitted subgraphs. It is known that certain homomorphism problems, e.g. $C_5$-Colouring, do not sit in the framework. By contrast, we show that the more general problem of Graph Homomorphism does sit in the framework.\nThe original framework had examples where hard versus easy were NP-complete versus P, or at least quadratic versus almost linear. We give the first example of a problem in the framework such that hardness is in the polynomial hierarchy above NP. Considering a variant of the colouring game as studied by Bodlaender, we show that with the restriction of bounded alternation, the list version of this problem is contained in the framework. The hard cases are $\\Pi_{2k}^\\mathrm{P}$-complete and the easy cases are in P.\nThe cases in P comprise those classes for which the pathwidth is bounded. Bodlaender explains that Sequential $3$-Colouring Construction Game is in P on classes with bounded vertex separation number, which coincides with bounded pathwidth on unordered graphs. However, these graphs are ordered with a playing order for the two players, which corresponds to a prefix pattern in a quantified formula. We prove that Sequential $3$-Colouring Construction Game is Pspace-complete on some class of bounded pathwidth, using a celebrated result of Atserias and Oliva.\nWe consider several locally constrained variants of the homomorphism problem. Like $C_5$-Colouring, none of these is in the framework. However, when we consider the bounded-degree restrictions, we prove that each of these problems is in our framework.\n    ",
        "primary_category": "cs.CC",
        "categories": [
            "cs.LO"
        ],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00499": {
        "title": "Do Zombies Understand? A Choose-Your-Own-Adventure Exploration of Machine Cognition",
        "authors": [
            "Ariel Goldstein",
            "Gabriel Stanovsky"
        ],
        "comments": " ",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "Recent advances in LLMs have sparked a debate on whether they understand text. In this position paper, we argue that opponents in this debate hold different definitions for understanding, and particularly differ in their view on the role of consciousness. To substantiate this claim, we propose a thought experiment involving an open-source chatbot $Z$ which excels on every possible benchmark, seemingly without subjective experience. We ask whether $Z$ is capable of understanding, and show that different schools of thought within seminal AI research seem to answer this question differently, uncovering their terminological disagreement. Moving forward, we propose two distinct working definitions for understanding which explicitly acknowledge the question of consciousness, and draw connections with a rich literature in philosophy, psychology and neuroscience.\n    ",
        "primary_category": "cs.CL",
        "categories": [],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00504": {
        "title": "Learning and Leveraging World Models in Visual Representation Learning",
        "authors": [
            "Quentin Garrido",
            "Mahmoud Assran",
            "Nicolas Ballas",
            "Adrien Bardes",
            "Laurent Najman",
            "Yann LeCun"
        ],
        "comments": "23 pages, 16 figures",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Joint-Embedding Predictive Architecture (JEPA) has emerged as a promising self-supervised approach that learns by leveraging a world model. While previously limited to predicting missing parts of an input, we explore how to generalize the JEPA prediction task to a broader set of corruptions. We introduce Image World Models, an approach that goes beyond masked image modeling and learns to predict the effect of global photometric transformations in latent space. We study the recipe of learning performant IWMs and show that it relies on three key aspects: conditioning, prediction difficulty, and capacity. Additionally, we show that the predictive world model learned by IWM can be adapted through finetuning to solve diverse tasks; a fine-tuned IWM world model matches or surpasses the performance of previous self-supervised methods. Finally, we show that learning with an IWM allows one to control the abstraction level of the learned representations, learning invariant representations such as contrastive methods, or equivariant representations such as masked image modelling.\n    ",
        "primary_category": "cs.CV",
        "categories": [
            "cs.AI",
            "cs.LG"
        ],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00506": {
        "title": "PoTeC: A German Naturalistic Eye-tracking-while-reading Corpus",
        "authors": [
            "Deborah N. Jakobi",
            "Thomas Kern",
            "David R. Reich",
            "Patrick Haller",
            "Lena A. J\u00e4ger"
        ],
        "comments": " ",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "The Potsdam Textbook Corpus (PoTeC) is a naturalistic eye-tracking-while-reading corpus containing data from 75 participants reading 12 scientific texts. PoTeC is the first naturalistic eye-tracking-while-reading corpus that contains eye-movements from domain-experts as well as novices in a within-participant manipulation: It is based on a 2x2x2 fully-crossed factorial design which includes the participants' level of study and the participants' discipline of study as between-subject factors and the text domain as a within-subject factor. The participants' reading comprehension was assessed by a series of text comprehension questions and their domain knowledge was tested by text-independent background questions for each of the texts. The materials are annotated for a variety of linguistic features at different levels. We envision PoTeC to be used for a wide range of studies including but not limited to analyses of expert and non-expert reading strategies. The corpus and all the accompanying data at all stages of the preprocessing pipeline and all code used to preprocess the data are made available via GitHub: this https URL.\n    ",
        "primary_category": "cs.CL",
        "categories": [],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00507": {
        "title": "Molecular unfolding formulation with enhanced quantum annealing approach",
        "authors": [
            "Arit Kumar Bishwas",
            "Arish Pitchai",
            "Anuraj Som"
        ],
        "comments": "11 pages, 8 figures",
        "subjects": "Quantum Physics (quant-ph)",
        "abstract": "Molecular docking is a crucial phase in drug discovery, involving the precise determination of the optimal spatial arrangement between two molecules when they bind. The such analysis, the 3D structure of molecules is a fundamental consideration, involving the manipulation of molecular representations based on their degrees of freedom, including rigid roto-translation and fragment rotations along rotatable bonds, to determine the preferred spatial arrangement when molecules bind to each other. In this paper, quantum annealing based solution to solve Molecular unfolding (MU) problem, a specific phase within molecular docking, is explored and compared with a state-of-the-art classical algorithm named \"GeoDock\". Molecular unfolding focuses on expanding a molecule to an unfolded state to simplify manipulation within the target cavity and optimize its configuration, typically by maximizing molecular area or internal atom distances. Molecular unfolding problem aims to find the torsional configuration that increases the inter-atomic distance within a molecule, which also increases the molecular area. Quantum annealing approach first encodes the problem into a Higher-order Unconstrained Binary Optimization (HUBO) equation which is pruned to an arbitrary percentage to improve the time efficiency and to be able to solve the equation using any quantum annealer. The resultant HUBO is then converted to a Quadratic Unconstrained Binary Optimization equation (QUBO), which is easily embedded on a D-wave annealing Quantum processor.\n    ",
        "primary_category": "quant-ph",
        "categories": [
            "cs.ET"
        ],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00509": {
        "title": "Surveying the Dead Minds: Historical-Psychological Text Analysis with Contextualized Construct Representation (CCR) for Classical Chinese",
        "authors": [
            "Yuqi Chen",
            "Sixuan Li",
            "Ying Li",
            "Mohammad Atari"
        ],
        "comments": " ",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "In this work, we develop a pipeline for historical-psychological text analysis in classical Chinese. Humans have produced texts in various languages for thousands of years; however, most of the computational literature is focused on contemporary languages and corpora. The emerging field of historical psychology relies on computational techniques to extract aspects of psychology from historical corpora using new methods developed in natural language processing (NLP). The present pipeline, called Contextualized Construct Representations (CCR), combines expert knowledge in psychometrics (i.e., psychological surveys) with text representations generated via transformer-based language models to measure psychological constructs such as traditionalism, norm strength, and collectivism in classical Chinese corpora. Considering the scarcity of available data, we propose an indirect supervised contrastive learning approach and build the first Chinese historical psychology corpus (C-HI-PSY) to fine-tune pre-trained models. We evaluate the pipeline to demonstrate its superior performance compared with other approaches. The CCR method outperforms word-embedding-based approaches across all of our tasks and exceeds prompting with GPT-4 in most tasks. Finally, we benchmark the pipeline against objective, external data to further verify its validity.\n    ",
        "primary_category": "cs.CL",
        "categories": [
            "cs.AI",
            "cs.CY"
        ],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00510": {
        "title": "ROME: Memorization Insights from Text, Probability and Hidden State in Large Language Models",
        "authors": [
            "Bo Li",
            "Qinghua Zhao",
            "Lijie Wen"
        ],
        "comments": "Submitted to ACL, 2024",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "Probing the memorization of large language models holds significant importance. Previous works have established metrics for quantifying memorization, explored various influencing factors, such as data duplication, model size, and prompt length, and evaluated memorization by comparing model outputs with training corpora. However, the training corpora are of enormous scale and its pre-processing is time-consuming. To explore memorization without accessing training data, we propose a novel approach, named ROME, wherein memorization is explored by comparing disparities across memorized and non-memorized. Specifically, models firstly categorize the selected samples into memorized and non-memorized groups, and then comparing the demonstrations in the two groups from the insights of text, probability, and hidden state. Experimental findings show the disparities in factors including word length, part-of-speech, word frequency, mean and variance, just to name a few.\n    ",
        "primary_category": "cs.CL",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00514": {
        "title": "Overestimation, Overfitting, and Plasticity in Actor-Critic: the Bitter Lesson of Reinforcement Learning",
        "authors": [
            "Michal Nauman",
            "Micha\u0142 Bortkiewicz",
            "Mateusz Ostaszewski",
            "Piotr Mi\u0142o\u015b",
            "Tomasz Trzci\u0144ski",
            "Marek Cygan"
        ],
        "comments": " ",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Recent advancements in off-policy Reinforcement Learning (RL) have significantly improved sample efficiency, primarily due to the incorporation of various forms of regularization that enable more gradient update steps than traditional agents. However, many of these techniques have been tested in limited settings, often on tasks from single simulation benchmarks and against well-known algorithms rather than a range of regularization approaches. This limits our understanding of the specific mechanisms driving RL improvements. To address this, we implemented over 60 different off-policy agents, each integrating established regularization techniques from recent state-of-the-art algorithms. We tested these agents across 14 diverse tasks from 2 simulation benchmarks. Our findings reveal that while the effectiveness of a specific regularization setup varies with the task, certain combinations consistently demonstrate robust and superior performance. Notably, a simple Soft Actor-Critic agent, appropriately regularized, reliably solves dog tasks, which were previously solved mainly through model-based approaches.\n    ",
        "primary_category": "cs.LG",
        "categories": [],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00515": {
        "title": "Are Unikernels Ready for Serverless on the Edge?",
        "authors": [
            "Felix Moebius",
            "Tobias Pfandzelter",
            "David Bermbach"
        ],
        "comments": " ",
        "subjects": "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "abstract": "Function-as-a-Service (FaaS) is a promising edge computing execution model but requires secure sandboxing mechanisms to isolate workloads from multiple tenants on constrained infrastructure. Although Docker containers are lightweight and popular in open-source FaaS platforms, they are generally considered insufficient for executing untrusted code and providing sandbox isolation. Commercial cloud FaaS platforms thus rely on Linux microVMs or hardened container runtimes, which are secure but come with a higher resource footprint.\nUnikernels combine application code and limited operating system primitives into a single purpose appliance, reducing the footprint of an application and its sandbox while providing full Linux compatibility. In this paper, we study the suitability of unikernels as an edge FaaS execution environment using the Nanos and OSv unikernel tool chains. We compare performance along several metrics such as cold start overhead and idle footprint against sandboxes such as Firecracker Linux microVMs, Docker containers, and secure gVisor containers. We find that unikernels exhibit desirable cold start performance, yet lag behind Linux microVMs in stability. Nevertheless, we show that unikernels are a promising candidate for further research on Linux-compatible FaaS isolation.\n    ",
        "primary_category": "cs.DC",
        "categories": [],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00517": {
        "title": "Optimization of the Energy-Comfort Trade-Off of HVAC Systems in Electric City Buses Based on a Steady-State Model",
        "authors": [
            "Fabio Widmer",
            "Stijn van Dooren",
            "Christopher H. Onder"
        ],
        "comments": "Preprint submitted to Control Engineering Practice",
        "subjects": "Systems and Control (eess.SY)",
        "abstract": "The electrification of public transport vehicles offers the potential to relieve city centers of pollutant and noise emissions. Furthermore, electric buses have lower life-cycle greenhouse gas (GHG) emissions than diesel buses, particularly when operated with sustainably produced electricity. However, the heating, ventilation, and air-conditioning (HVAC) system can consume a significant amount of energy, thus limiting the achievable driving range. In this paper, we address the HVAC system in an electric city bus by analyzing the trade-off between the energy consumption and the thermal comfort of the passengers. We do this by developing a dynamic thermal model for the bus cabin, which we simplify by considering it to be in steady state. We introduce a method that is able to quickly optimize the steady-state HVAC system inputs for a large number of samples representative of a year-round operation. A comparison between the results from the steady-state optimization approach and a dynamic simulation reveal small deviations in both the HVAC system power demand and achieved thermal comfort. Thus, the approximation of the system performance with a steady-state model is justified. We present two case studies to demonstrate the practical relevance of the approach. First, we show how the method can be used to compare different system designs based on a year-round performance evaluation. Second, we show how the method can be used to generate accurate setpoints for online controllers. In conclusion, this study shows that a steady-state analysis of the HVAC systems of an electric city bus is a valuable approach to evaluate and optimize its performance.\n    ",
        "primary_category": "eess.SY",
        "categories": [],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00520": {
        "title": "IAI MovieBot 2.0: An Enhanced Research Platform with Trainable Neural Components and Transparent User Modeling",
        "authors": [
            "Nolwenn Bernard",
            "Ivica Kostric",
            "Krisztian Balog"
        ],
        "comments": "Proceedings of the 17th ACM International Conference on Web Search and Data Mining (WSDM '24), March 4--8, 2024, Merida, Mexico",
        "subjects": "Information Retrieval (cs.IR)",
        "abstract": "While interest in conversational recommender systems has been on the rise, operational systems suitable for serving as research platforms for comprehensive studies are currently lacking. This paper introduces an enhanced version of the IAI MovieBot conversational movie recommender system, aiming to evolve it into a robust and adaptable platform for conducting user-facing experiments. The key highlights of this enhancement include the addition of trainable neural components for natural language understanding and dialogue policy, transparent and explainable modeling of user preferences, along with improvements in the user interface and research infrastructure.\n    ",
        "primary_category": "cs.IR",
        "categories": [],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00522": {
        "title": "VisionLLaMA: A Unified LLaMA Interface for Vision Tasks",
        "authors": [
            "Xiangxiang Chu",
            "Jianlin Su",
            "Bo Zhang",
            "Chunhua Shen"
        ],
        "comments": " ",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Large language models are built on top of a transformer-based architecture to process textual inputs. For example, the LLaMA stands out among many open-source implementations. Can the same transformer be used to process 2D images? In this paper, we answer this question by unveiling a LLaMA-like vision transformer in plain and pyramid forms, termed VisionLLaMA, which is tailored for this purpose. VisionLLaMA is a unified and generic modelling framework for solving most vision tasks. We extensively evaluate its effectiveness using typical pre-training paradigms in a good portion of downstream tasks of image perception and especially image generation. In many cases, VisionLLaMA have exhibited substantial gains over the previous state-of-the-art vision transformers. We believe that VisionLLaMA can serve as a strong new baseline model for vision generation and understanding. Our code will be released at this https URL.\n    ",
        "primary_category": "cs.CV",
        "categories": [],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00523": {
        "title": "Assessing the Efficacy of Heuristic-Based Address Clustering for Bitcoin",
        "authors": [
            "Hugo Schnoering",
            "Pierre Porthaux",
            "Michalis Vazirgiannis"
        ],
        "comments": "20 pages",
        "subjects": "General Finance (q-fin.GN)",
        "abstract": "Exploring transactions within the Bitcoin blockchain entails examining the transfer of bitcoins among several hundred million entities. However, it is often impractical and resource-consuming to study such a vast number of entities. Consequently, entity clustering serves as an initial step in most analytical studies. This process often employs heuristics grounded in the practices and behaviors of these entities. In this research, we delve into the examination of two widely used heuristics, alongside the introduction of four novel ones. Our contribution includes the introduction of the \\textit{clustering ratio}, a metric designed to quantify the reduction in the number of entities achieved by a given heuristic. The assessment of this reduction ratio plays an important role in justifying the selection of a specific heuristic for analytical purposes. Given the dynamic nature of the Bitcoin system, characterized by a continuous increase in the number of entities on the blockchain, and the evolving behaviors of these entities, we extend our study to explore the temporal evolution of the clustering ratio for each heuristic. This temporal analysis enhances our understanding of the effectiveness of these heuristics over time.\n    ",
        "primary_category": "q-fin.GN",
        "categories": [
            "cs.CR",
            "cs.SI"
        ],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00526": {
        "title": "Data Quality Assessment: Challenges and Opportunities",
        "authors": [
            "Sedir Mohammed",
            "Hazar Harmouch",
            "Felix Naumann",
            "Divesh Srivastava"
        ],
        "comments": " ",
        "subjects": "Databases (cs.DB)",
        "abstract": "Data-oriented applications, their users, and even the law require data of high quality. Research has broken down the rather vague notion of data quality into various dimensions, such as accuracy, consistency, and reputation, to name but a few. To achieve the goal of high data quality, many tools and techniques exist to clean and otherwise improve data. Yet, systematic research on actually assessing data quality in all of its dimensions is largely absent, and with it the ability to gauge the success of any data cleaning effort. It is our vision to establish a systematic and comprehensive framework for the (numeric) assessment of data quality for a given dataset and its intended use. Such a framework must cover the various facets that influence data quality, as well as the many types of data quality dimensions. In particular, we identify five facets that serve as a foundation of data quality assessment. For each facet, we outline the challenges and opportunities that arise when trying to actually assign quality scores to data and create a data quality profile for it, along with a wide range of technologies needed for this purpose.\n    ",
        "primary_category": "cs.DB",
        "categories": [],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00527": {
        "title": "\"There is a Job Prepared for Me Here\": Understanding How Short Video and Live-streaming Platforms Empower Ageing Job Seekers in China",
        "authors": [
            "PiaoHong Wang",
            "Siying Hu",
            "Bo Wen",
            "Zhicong Lu"
        ],
        "comments": "14 pages, 3 figures; Accepted to ACM CHI 2024. In Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems (CHI'24)",
        "subjects": "Human-Computer Interaction (cs.HC)",
        "abstract": "In recent years, the global unemployment rate has remained persistently high. Compounding this issue, the ageing population in China often encounters additional challenges in finding employment due to prevalent age discrimination in daily life. However, with the advent of social media, there has been a rise in the popularity of short videos and live-streams for recruiting ageing workers. To better understand the motivations of ageing job seekers to engage with these video-based recruitment methods and to explore the extent to which such platforms can empower them, we conducted an interview-based study with ageing job seekers who have had exposure to these short recruitment videos and live-streaming channels. Our findings reveal that these platforms can provide a job-seeking choice that is particularly friendly to ageing job seekers, effectively improving their disadvantaged situation.\n    ",
        "primary_category": "cs.HC",
        "categories": [
            "cs.CY",
            "cs.SI"
        ],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00528": {
        "title": "Large Language Models for Simultaneous Named Entity Extraction and Spelling Correction",
        "authors": [
            "Edward Whittaker",
            "Ikuo Kitagishi"
        ],
        "comments": "9 pages, 1 figure",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "Language Models (LMs) such as BERT, have been shown to perform well on the task of identifying Named Entities (NE) in text. A BERT LM is typically used as a classifier to classify individual tokens in the input text, or to classify spans of tokens, as belonging to one of a set of possible NE categories.\nIn this paper, we hypothesise that decoder-only Large Language Models (LLMs) can also be used generatively to extract both the NE, as well as potentially recover the correct surface form of the NE, where any spelling errors that were present in the input text get automatically corrected.\nWe fine-tune two BERT LMs as baselines, as well as eight open-source LLMs, on the task of producing NEs from text that was obtained by applying Optical Character Recognition (OCR) to images of Japanese shop receipts; in this work, we do not attempt to find or evaluate the location of NEs in the text.\nWe show that the best fine-tuned LLM performs as well as, or slightly better than, the best fine-tuned BERT LM, although the differences are not significant. However, the best LLM is also shown to correct OCR errors in some cases, as initially hypothesised.\n    ",
        "primary_category": "cs.CL",
        "categories": [
            "cs.CV"
        ],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00529": {
        "title": "VoxGenesis: Unsupervised Discovery of Latent Speaker Manifold for Speech Synthesis",
        "authors": [
            "Weiwei Lin",
            "Chenhang He",
            "Man-Wai Mak",
            "Jiachen Lian",
            "Kong Aik Lee"
        ],
        "comments": "preprint",
        "subjects": "Sound (cs.SD)",
        "abstract": "Achieving nuanced and accurate emulation of human voice has been a longstanding goal in artificial intelligence. Although significant progress has been made in recent years, the mainstream of speech synthesis models still relies on supervised speaker modeling and explicit reference utterances. However, there are many aspects of human voice, such as emotion, intonation, and speaking style, for which it is hard to obtain accurate labels. In this paper, we propose VoxGenesis, a novel unsupervised speech synthesis framework that can discover a latent speaker manifold and meaningful voice editing directions without supervision. VoxGenesis is conceptually simple. Instead of mapping speech features to waveforms deterministically, VoxGenesis transforms a Gaussian distribution into speech distributions conditioned and aligned by semantic tokens. This forces the model to learn a speaker distribution disentangled from the semantic content. During the inference, sampling from the Gaussian distribution enables the creation of novel speakers with distinct characteristics. More importantly, the exploration of latent space uncovers human-interpretable directions associated with specific speaker characteristics such as gender attributes, pitch, tone, and emotion, allowing for voice editing by manipulating the latent codes along these identified directions. We conduct extensive experiments to evaluate the proposed VoxGenesis using both subjective and objective metrics, finding that it produces significantly more diverse and realistic speakers with distinct characteristics than the previous approaches. We also show that latent space manipulation produces consistent and human-identifiable effects that are not detrimental to the speech quality, which was not possible with previous approaches. Audio samples of VoxGenesis can be found at: \\url{this https URL}.\n    ",
        "primary_category": "cs.SD",
        "categories": [
            "cs.LG",
            "eess.AS"
        ],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00536": {
        "title": "Approximating the Geometric Knapsack Problem in Near-Linear Time and Dynamically",
        "authors": [
            "Moritz Buchem",
            "Paul Deuker",
            "Andreas Wiese"
        ],
        "comments": " ",
        "subjects": "Data Structures and Algorithms (cs.DS)",
        "abstract": "An important goal in algorithm design is determining the best running time for solving a problem (approximately). For some problems, we know the optimal running time, assuming certain conditional lower bounds. In this work, we study the $d$-dimensional geometric knapsack problem where we are far from this level of understanding. We are given a set of weighted d-dimensional geometric items like squares, rectangles, or hypercubes and a knapsack which is a square or a (hyper-)cube. We want to select a subset of items that fit non-overlappingly inside the knapsack, maximizing the total profit of the packed items. We make a significant step towards determining the best running time for solving these problems approximately by presenting approximation algorithms with near-linear running times for any constant dimension d and any constant parameter $\\epsilon$.\nFor (hyper)-cubes, we present a $(1+\\epsilon)$-approximation algorithm whose running time drastically improves upon the known $(1+\\epsilon)$-approximation algorithm which has a running time where the exponent of n depends exponentially on $1/\\epsilon$ and $d$. Moreover, we present a $(2+\\epsilon)$-approximation algorithm for rectangles in the setting without rotations and a $(17/9+\\epsilon)$-approximation algorithm if we allow rotations by 90 degrees. The best known polynomial time algorithms for these settings have approximation ratios of $17/9+\\epsilon$ and $1.5+\\epsilon$, respectively, and running times in which the exponent of n depends exponentially on $1/\\epsilon$. We also give dynamic algorithms with polylogarithmic query and update times and the same approximation guarantees as the algorithms above. Key to our results is a new family of structured packings which we call easily guessable packings. They are flexible enough to guarantee profitable solutions and structured enough so that we can compute these solutions quickly.\n    ",
        "primary_category": "cs.DS",
        "categories": [],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00539": {
        "title": "DyPyBench: A Benchmark of Executable Python Software",
        "authors": [
            "Islem Bouzenia",
            "Bajaj Piyush Krishan",
            "Michael Pradel"
        ],
        "comments": " ",
        "subjects": "Software Engineering (cs.SE)",
        "abstract": "Python has emerged as one of the most popular programming languages, extensively utilized in domains such as machine learning, data analysis, and web applications. Python's dynamic nature and extensive usage make it an attractive candidate for dynamic program analysis. However, unlike for other popular languages, there currently is no comprehensive benchmark suite of executable Python projects, which hinders the development of dynamic analyses. This work addresses this gap by presenting DyPyBench, the first benchmark of Python projects that is large scale, diverse, ready to run (i.e., with fully configured and prepared test suites), and ready to analyze (by integrating with the DynaPyt dynamic analysis framework). The benchmark encompasses 50 popular opensource projects from various application domains, with a total of 681k lines of Python code, and 30k test cases. DyPyBench enables various applications in testing and dynamic analysis, of which we explore three in this work: (i) Gathering dynamic call graphs and empirically comparing them to statically computed call graphs, which exposes and quantifies limitations of existing call graph construction techniques for Python. (ii) Using DyPyBench to build a training data set for LExecutor, a neural model that learns to predict values that otherwise would be missing at runtime. (iii) Using dynamically gathered execution traces to mine API usage specifications, which establishes a baseline for future work on specification mining for Python. We envision DyPyBench to provide a basis for other dynamic analyses and for studying the runtime behavior of Python code.\n    ",
        "primary_category": "cs.SE",
        "categories": [],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00542": {
        "title": "Machine Learning Training Optimization using the Barycentric Correction Procedure",
        "authors": [
            "Sofia Ramos-Pulido",
            "Neil Hernandez-Gress",
            "Hector G. Ceballos-Cancino"
        ],
        "comments": " ",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Machine learning (ML) algorithms are predictively competitive algorithms with many human-impact applications. However, the issue of long execution time remains unsolved in the literature for high-dimensional spaces. This study proposes combining ML algorithms with an efficient methodology known as the barycentric correction procedure (BCP) to address this issue. This study uses synthetic data and an educational dataset from a private university to show the benefits of the proposed method. It was found that this combination provides significant benefits related to time in synthetic and real data without losing accuracy when the number of instances and dimensions increases. Additionally, for high-dimensional spaces, it was proved that BCP and linear support vector classification (LinearSVC), after an estimated feature map for the gaussian radial basis function (RBF) kernel, were unfeasible in terms of computational time and accuracy.\n    ",
        "primary_category": "cs.LG",
        "categories": [],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00543": {
        "title": "SURE: SUrvey REcipes for building reliable and robust deep networks",
        "authors": [
            "Yuting Li",
            "Yingyi Chen",
            "Xuanlong Yu",
            "Dexiong Chen",
            "Xi Shen"
        ],
        "comments": "Accepted to CVPR2024",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "In this paper, we revisit techniques for uncertainty estimation within deep neural networks and consolidate a suite of techniques to enhance their reliability. Our investigation reveals that an integrated application of diverse techniques--spanning model regularization, classifier and optimization--substantially improves the accuracy of uncertainty predictions in image classification tasks. The synergistic effect of these techniques culminates in our novel SURE approach. We rigorously evaluate SURE against the benchmark of failure prediction, a critical testbed for uncertainty estimation efficacy. Our results showcase a consistently better performance than models that individually deploy each technique, across various datasets and model architectures. When applied to real-world challenges, such as data corruption, label noise, and long-tailed class distribution, SURE exhibits remarkable robustness, delivering results that are superior or on par with current state-of-the-art specialized methods. Particularly on Animal-10N and Food-101N for learning with noisy labels, SURE achieves state-of-the-art performance without any task-specific adjustments. This work not only sets a new benchmark for robust uncertainty estimation but also paves the way for its application in diverse, real-world scenarios where reliability is paramount. Our code is available at \\url{this https URL}.\n    ",
        "primary_category": "cs.CV",
        "categories": [],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00546": {
        "title": "Comparative Study of Simulators for Vehicular Networks",
        "authors": [
            "Rida Saghir",
            "Thenuka Karunathilake",
            "Anna F\u00f6rster"
        ],
        "comments": " ",
        "subjects": "Networking and Internet Architecture (cs.NI)",
        "abstract": "Vehicular Adhoc networks (VANETs) are composed of vehicles connected with wireless links to exchange data. VANETs have become the backbone of the Intelligent Transportation Systems (ITS) in smart cities and enable many essential services like roadside safety, traffic management, platooning, etc with vehicle-to-vehicle (V2V) and vehicle-to-infrastructure (V2I) communications. In any form of research testing and evaluation plays a crucial role. However, in VANETs, real-world experiments require high investment, and heavy resources and can cause many practical difficulties. Therefore, simulations have become critical and the primary way of evaluating VANETs' applications. Furthermore, the upfront challenge is the realistic capture of the networking mechanism of VANETs, which varies from situation to situation. Several factors may contribute to the successful achievement of a random realistic networking behavior. However, the biggest dependency is a powerful tool for the implementation, which could probably take into account all the configuration parameters, loss factors, mobility schemes, and other key features of a VANET, yet give out practical performance metrics with a good trade-off between investment of resources and the results. Hence, the aim of this research is to evaluate some simulators in the scope of VANETs with respect to resource utilization, packet delivery, and computational time.\n    ",
        "primary_category": "cs.NI",
        "categories": [],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00550": {
        "title": "Imitation Learning Datasets: A Toolkit For Creating Datasets, Training Agents and Benchmarking",
        "authors": [
            "Nathan Gavenski",
            "Michael Luck",
            "Odinaldo Rodrigues"
        ],
        "comments": "his paper has been accepted in the demonstration track for the 23rd International Conference on Autonomous Agents and Multi-Agent Systems",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Imitation learning field requires expert data to train agents in a task. Most often, this learning approach suffers from the absence of available data, which results in techniques being tested on its dataset. Creating datasets is a cumbersome process requiring researchers to train expert agents from scratch, record their interactions and test each benchmark method with newly created data. Moreover, creating new datasets for each new technique results in a lack of consistency in the evaluation process since each dataset can drastically vary in state and action distribution. In response, this work aims to address these issues by creating Imitation Learning Datasets, a toolkit that allows for: (i) curated expert policies with multithreaded support for faster dataset creation; (ii) readily available datasets and techniques with precise measurements; and (iii) sharing implementations of common imitation learning techniques. Demonstration link: this https URL\n",
        "primary_category": "cs.LG",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00553": {
        "title": "Standardizing the Measurement of Text Diversity: A Tool and a Comparative Analysis of Scores",
        "authors": [
            "Chantal Shaib",
            "Joe Barrow",
            "Jiuding Sun",
            "Alexa F. Siu",
            "Byron C. Wallace",
            "Ani Nenkova"
        ],
        "comments": "Preprint",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "The diversity across outputs generated by large language models shapes the perception of their quality and utility. Prompt leaks, templated answer structure, and canned responses across different interactions are readily noticed by people, but there is no standard score to measure this aspect of model behavior. In this work we empirically investigate diversity scores on English texts. We find that computationally efficient compression algorithms capture information similar to what is measured by slow to compute $n$-gram overlap homogeneity scores. Further, a combination of measures -- compression ratios, self-repetition of long $n$-grams and Self-BLEU and BERTScore -- are sufficient to report, as they have low mutual correlation with each other. The applicability of scores extends beyond analysis of generative models; for example, we highlight applications on instruction-tuning datasets and human-produced texts. We release a diversity score package to facilitate research and invite consistency across reports.\n    ",
        "primary_category": "cs.CL",
        "categories": [],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00554": {
        "title": "Distributed MPC for autonomous ships on inland waterways with collaborative collision avoidance",
        "authors": [
            "Hoang Anh Tran",
            "Tor Arne Johansen",
            "Rudy R. Negenborn"
        ],
        "comments": " ",
        "subjects": "Systems and Control (eess.SY)",
        "abstract": "This paper presents a distributed solution for the problem of collaborative collision avoidance for autonomous inland waterway ships. A two-layer collision avoidance framework that considers inland waterway traffic regulations is proposed to increase navigational safety for autonomous ships. Our approach allows for modifying traffic rules without changing the collision avoidance algorithm, and is based on a novel formulation of model predictive control (MPC) for collision avoidance of ships. This MPC formulation is designed for inland waterway traffic and can handle complex scenarios. The alternating direction method of multipliers is used as a scheme for exchanging and negotiating intentions among ships. Simulation results show that the proposed algorithm can comply with traffic rules. Furthermore, the proposed algorithm can safely deviate from traffic rules when necessary to increase efficiency in complex scenarios.\n    ",
        "primary_category": "eess.SY",
        "categories": [],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00558": {
        "title": "Rational Linkages: From Poses to 3D-printed Prototypes",
        "authors": [
            "Daniel Huczala",
            "Johannes Siegele",
            "Daren A. Thimm",
            "Martin Pfurner",
            "Hans-Peter Schr\u00f6cker"
        ],
        "comments": " ",
        "subjects": "Robotics (cs.RO)",
        "abstract": "In this paper, a set of tools is introduced that simplifies the synthesis and rapid-prototyping of single-loop rational kinematic chains. It allows the user to perform rational motion interpolation of up to four given poses and yields the design parameters of a linkage that can execute this motion. The package also provides a visualization of the output and performs a self-collision analysis with the possibility to adapt the design parameters. The results can be imported into CAD-systems for fast 3D printing.\n    ",
        "primary_category": "cs.RO",
        "categories": [],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00561": {
        "title": "Multi-Task Learning Using Uncertainty to Weigh Losses for Heterogeneous Face Attribute Estimation",
        "authors": [
            "Huaqing Yuan",
            "Yi He",
            "Peng Du",
            "Lu Song"
        ],
        "comments": " ",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Face images contain a wide variety of attribute information. In this paper, we propose a generalized framework for joint estimation of ordinal and nominal attributes based on information sharing. We tackle the correlation problem between heterogeneous attributes using hard parameter sharing of shallow features, and trade-off multiple loss functions by considering homoskedastic uncertainty for each attribute estimation task. This leads to optimal estimation of multiple attributes of the face and reduces the training cost of multitask learning. Experimental results on benchmarks with multiple face attributes show that the proposed approach has superior performance compared to state of the art. Finally, we discuss the bias issues arising from the proposed approach in face attribute estimation and validate its feasibility on edge systems.\n    ",
        "primary_category": "cs.CV",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00563": {
        "title": "Indirectly Parameterized Concrete Autoencoders",
        "authors": [
            "Alfred Nilsson",
            "Klas Wijk",
            "Sai bharath chandra Gutha",
            "Erik Englesson",
            "Alexandra Hotti",
            "Carlo Saccardi",
            "Oskar Kviman",
            "Jens Lagergren",
            "Ricardo Vinuesa",
            "Hossein Azizpour"
        ],
        "comments": " ",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Feature selection is a crucial task in settings where data is high-dimensional or acquiring the full set of features is costly. Recent developments in neural network-based embedded feature selection show promising results across a wide range of applications. Concrete Autoencoders (CAEs), considered state-of-the-art in embedded feature selection, may struggle to achieve stable joint optimization, hurting their training time and generalization. In this work, we identify that this instability is correlated with the CAE learning duplicate selections. To remedy this, we propose a simple and effective improvement: Indirectly Parameterized CAEs (IP-CAEs). IP-CAEs learn an embedding and a mapping from it to the Gumbel-Softmax distributions' parameters. Despite being simple to implement, IP-CAE exhibits significant and consistent improvements over CAE in both generalization and training time across several datasets for reconstruction and classification. Unlike CAE, IP-CAE effectively leverages non-linear relationships and does not require retraining the jointly optimized decoder. Furthermore, our approach is, in principle, generalizable to Gumbel-Softmax distributions beyond feature selection.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "stat.ML"
        ],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00564": {
        "title": "EfficientZero V2: Mastering Discrete and Continuous Control with Limited Data",
        "authors": [
            "Shengjie Wang",
            "Shaohuai Liu",
            "Weirui Ye",
            "Jiacheng You",
            "Yang Gao"
        ],
        "comments": "21 pages,10 figures",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Sample efficiency remains a crucial challenge in applying Reinforcement Learning (RL) to real-world tasks. While recent algorithms have made significant strides in improving sample efficiency, none have achieved consistently superior performance across diverse domains. In this paper, we introduce EfficientZero V2, a general framework designed for sample-efficient RL algorithms. We have expanded the performance of EfficientZero to multiple domains, encompassing both continuous and discrete actions, as well as visual and low-dimensional inputs. With a series of improvements we propose, EfficientZero V2 outperforms the current state-of-the-art (SOTA) by a significant margin in diverse tasks under the limited data setting. EfficientZero V2 exhibits a notable advancement over the prevailing general algorithm, DreamerV3, achieving superior outcomes in 50 of 66 evaluated tasks across diverse benchmarks, such as Atari 100k, Proprio Control, and Vision Control.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.AI",
            "cs.RO"
        ],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00565": {
        "title": "Predicting UAV Type: An Exploration of Sampling and Data Augmentation for Time Series Classification",
        "authors": [
            "Tarik Crnovrsanin",
            "Calvin Yu",
            "Dane Hankamer",
            "Cody Dunne"
        ],
        "comments": "12 pages, 3 figures, 4 tables, submitted to IEEE Transactions on Cybernetics",
        "subjects": "Robotics (cs.RO)",
        "abstract": "Unmanned aerial vehicles are becoming common and have many productive uses. However, their increased prevalence raises safety concerns -- how can we protect restricted airspace? Knowing the type of unmanned aerial vehicle can go a long way in determining any potential risks it carries. For instance, fixed-wing craft can carry more weight over longer distances, thus potentially posing a more significant threat. This paper presents a machine learning model for classifying unmanned aerial vehicles as quadrotor, hexarotor, or fixed-wing. Our approach effectively applies a Long-Short Term Memory (LSTM) neural network for the purpose of time series classification. We performed experiments to test the effects of changing the timestamp sampling method and addressing the imbalance in the class distribution. Through these experiments, we identified the top-performing sampling and class imbalance fixing methods. Averaging the macro f-scores across 10 folds of data, we found that the majority quadrotor class was predicted well (98.16%), and, despite an extreme class imbalance, the model could also predicted a majority of fixed-wing flights correctly (73.15%). Hexarotor instances were often misclassified as quadrotors due to the similarity of multirotors in general (42.15%). However, results remained relatively stable across certain methods, which prompted us to analyze and report on their tradeoffs. The supplemental material for this paper, including the code and data for running all the experiments and generating the results tables, is available at this https URL.\n    ",
        "primary_category": "cs.RO",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00566": {
        "title": "Lincoln's Annotated Spatio-Temporal Strawberry Dataset (LAST-Straw)",
        "authors": [
            "Katherine Margaret Frances James",
            "Karoline Heiwolt",
            "Daniel James Sargent",
            "Grzegorz Cielniak"
        ],
        "comments": " ",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Automated phenotyping of plants for breeding and plant studies promises to provide quantitative metrics on plant traits at a previously unattainable observation frequency. Developers of tools for performing high-throughput phenotyping are, however, constrained by the availability of relevant datasets on which to perform validation. To this end, we present a spatio-temporal dataset of 3D point clouds of strawberry plants for two varieties, totalling 84 individual point clouds. We focus on the end use of such tools - the extraction of biologically relevant phenotypes - and demonstrate a phenotyping pipeline on the dataset. This comprises of the steps, including; segmentation, skeletonisation and tracking, and we detail how each stage facilitates the extraction of different phenotypes or provision of data insights. We particularly note that assessment is focused on the validation of phenotypes, extracted from the representations acquired at each step of the pipeline, rather than singularly focusing on assessing the representation itself. Therefore, where possible, we provide \\textit{in silico} ground truth baselines for the phenotypes extracted at each step and introduce methodology for the quantitative assessment of skeletonisation and the length trait extracted thereof. This dataset contributes to the corpus of freely available agricultural/horticultural spatio-temporal data for the development of next-generation phenotyping tools, increasing the number of plant varieties available for research in this field and providing a basis for genuine comparison of new phenotyping methodology.\n    ",
        "primary_category": "cs.CV",
        "categories": [],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00570": {
        "title": "Rethinking cluster-conditioned diffusion models",
        "authors": [
            "Nikolas Adaloglou",
            "Tim Kaiser",
            "Felix Michels",
            "Markus Kollmann"
        ],
        "comments": " ",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "We present a comprehensive experimental study on image-level conditioning for diffusion models using cluster assignments. We elucidate how individual components regarding image clustering impact image synthesis across three datasets. By combining recent advancements from image clustering and diffusion models, we show that, given the optimal cluster granularity with respect to image synthesis (visual groups), cluster-conditioning can achieve state-of-the-art FID (i.e. 1.67, 2.17 on CIFAR10 and CIFAR100 respectively), while attaining a strong training sample efficiency. Finally, we propose a novel method to derive an upper cluster bound that reduces the search space of the visual groups using solely feature-based clustering. Unlike existing approaches, we find no significant connection between clustering and cluster-conditional image generation. The code and cluster assignments will be released.\n    ",
        "primary_category": "cs.CV",
        "categories": [
            "cs.AI",
            "cs.LG"
        ],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00571": {
        "title": "Computational homogenization for aerogel-like polydisperse open-porous materials using neural network--based surrogate models on the microscale",
        "authors": [
            "Axel Klawonn",
            "Martin Lanser",
            "Lucas Mager",
            "Ameya Rege"
        ],
        "comments": " ",
        "subjects": "Numerical Analysis (math.NA)",
        "abstract": "The morphology of nanostructured materials exhibiting a polydisperse porous space, such as aerogels, is very open porous and fine grained. Therefore, a simulation of the deformation of a large aerogel structure resolving the nanostructure would be extremely expensive. Thus, multi-scale or homogenization approaches have to be considered. Here, a computational scale bridging approach based on the FE$^2$ method is suggested, where the macroscopic scale is discretized using finite elements while the microstructure of the open-porous material is resolved as a network of Euler-Bernoulli beams. Here, the beam frame based RVEs (representative volume elements) have pores whose size distribution follows the measured values for a specific material. This is a well-known approach to model aerogel structures. For the computational homogenization, an approach to average the first Piola-Kirchhoff stresses in a beam frame by neglecting rotational moments is suggested. To further overcome the computationally most expensive part in the homogenization method, that is, solving the RVEs and averaging their stress fields, a surrogate model is introduced based on neural networks. The networks input is the localized deformation gradient on the macroscopic scale and its output is the averaged stress for the specific material. It is trained on data generated by the beam frame based approach. The effiency and robustness of both homogenization approaches is shown numerically, the approximation properties of the surrogate model is verified for different macroscopic problems and discretizations. Different (Quasi-)Newton solvers are considered on the macroscopic scale and compared with respect to their convergence properties.\n    ",
        "primary_category": "math.NA",
        "categories": [],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00573": {
        "title": "IDTrust: Deep Identity Document Quality Detection with Bandpass Filtering",
        "authors": [
            "Musab Al-Ghadi",
            "Joris Voerman",
            "Souhail Bakkali",
            "Micka\u00ebl Coustaty",
            "Nicolas Sidere",
            "Xavier St-Georges"
        ],
        "comments": "Submit to ICIP 2024",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "The increasing use of digital technologies and mobile-based registration procedures highlights the vital role of personal identity documents (IDs) in verifying users and safeguarding sensitive information. However, the rise in counterfeit ID production poses a significant challenge, necessitating the development of reliable and efficient automated verification methods. This paper introduces IDTrust, a deep-learning framework for assessing the quality of IDs. IDTrust is a system that enhances the quality of identification documents by using a deep learning-based approach. This method eliminates the need for relying on original document patterns for quality checks and pre-processing steps for alignment. As a result, it offers significant improvements in terms of dataset applicability. By utilizing a bandpass filtering-based method, the system aims to effectively detect and differentiate ID quality. Comprehensive experiments on the MIDV-2020 and L3i-ID datasets identify optimal parameters, significantly improving discrimination performance and effectively distinguishing between original and scanned ID documents.\n    ",
        "primary_category": "cs.CV",
        "categories": [],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00574": {
        "title": "Beyond Single-Model Views for Deep Learning: Optimization versus Generalizability of Stochastic Optimization Algorithms",
        "authors": [
            "Toki Tahmid Inan",
            "Mingrui Liu",
            "Amarda Shehu"
        ],
        "comments": " ",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Despite an extensive body of literature on deep learning optimization, our current understanding of what makes an optimization algorithm effective is fragmented. In particular, we do not understand well whether enhanced optimization translates to improved generalizability. Current research overlooks the inherent stochastic nature of stochastic gradient descent (SGD) and its variants, resulting in a lack of comprehensive benchmarking and insight into their statistical performance. This paper aims to address this gap by adopting a novel approach. Rather than solely evaluating the endpoint of individual optimization trajectories, we draw from an ensemble of trajectories to estimate the stationary distribution of stochastic optimizers. Our investigation encompasses a wide array of techniques, including SGD and its variants, flat-minima optimizers, and new algorithms we propose under the Basin Hopping framework. Through our evaluation, which encompasses synthetic functions with known minima and real-world problems in computer vision and natural language processing, we emphasize fair benchmarking under a statistical framework, comparing stationary distributions and establishing statistical significance. Our study uncovers several key findings regarding the relationship between training loss and hold-out accuracy, as well as the comparable performance of SGD, noise-enabled variants, and novel optimizers utilizing the BH framework. Notably, these algorithms demonstrate performance on par with flat-minima optimizers like SAM, albeit with half the gradient evaluations. We anticipate that our work will catalyze further exploration in deep learning optimization, encouraging a shift away from single-model approaches towards methodologies that acknowledge and leverage the stochastic nature of optimizers.\n    ",
        "primary_category": "cs.LG",
        "categories": [],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00578": {
        "title": "SINDy vs Hard Nonlinearities and Hidden Dynamics: a Benchmarking Study",
        "authors": [
            "Aurelio Raffa Ugolini",
            "Valentina Breschi",
            "Andrea Manzoni",
            "Mara Tanelli"
        ],
        "comments": "Submitted to IFAC SYSID 2024",
        "subjects": "Systems and Control (eess.SY)",
        "abstract": "In this work we analyze the effectiveness of the Sparse Identification of Nonlinear Dynamics (SINDy) technique on three benchmark datasets for nonlinear identification, to provide a better understanding of its suitability when tackling real dynamical systems. While SINDy can be an appealing strategy for pursuing physics-based learning, our analysis highlights difficulties in dealing with unobserved states and non-smooth dynamics. Due to the ubiquity of these features in real systems in general, and control applications in particular, we complement our analysis with hands-on approaches to tackle these issues in order to exploit SINDy also in these challenging contexts.\n    ",
        "primary_category": "eess.SY",
        "categories": [
            "cs.LG"
        ],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00582": {
        "title": "To Trust or Distrust Trust Measures: Validating Questionnaires for Trust in AI",
        "authors": [
            "Nicolas Scharowski",
            "Sebastian A. C. Perrig",
            "Lena Fanya Aeschbach",
            "Nick von Felten",
            "Klaus Opwis",
            "Philipp Wintersberger",
            "Florian Br\u00fchlmann"
        ],
        "comments": " ",
        "subjects": "Human-Computer Interaction (cs.HC)",
        "abstract": "Despite the importance of trust in human-AI interactions, researchers must adopt questionnaires from other disciplines that lack validation in the AI context. Motivated by the need for reliable and valid measures, we investigated the psychometric quality of two trust questionnaires, the Trust between People and Automation scale (TPA) by Jian et al. (2000) and the Trust Scale for the AI Context (TAI) by Hoffman et al. (2023). In a pre-registered online experiment (N = 1485), participants observed interactions with trustworthy and untrustworthy AI (autonomous vehicle and chatbot). Results support the psychometric quality of the TAI while revealing opportunities to improve the TPA, which we outline in our recommendations for using the two questionnaires. Furthermore, our findings provide additional empirical evidence of trust and distrust as two distinct constructs that may coexist independently. Building on our findings, we highlight the opportunities and added value of measuring both trust and distrust in human-AI research and advocate for further work on both constructs.\n    ",
        "primary_category": "cs.HC",
        "categories": [],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00584": {
        "title": "Generalized User Representations for Transfer Learning",
        "authors": [
            "Ghazal Fazelnia",
            "Sanket Gupta",
            "Claire Keum",
            "Mark Koh",
            "Ian Anderson",
            "Mounia Lalmas"
        ],
        "comments": " ",
        "subjects": "Information Retrieval (cs.IR)",
        "abstract": "We present a novel framework for user representation in large-scale recommender systems, aiming at effectively representing diverse user taste in a generalized manner. Our approach employs a two-stage methodology combining representation learning and transfer learning. The representation learning model uses an autoencoder that compresses various user features into a representation space. In the second stage, downstream task-specific models leverage user representations via transfer learning instead of curating user features individually. We further augment this methodology on the representation's input features to increase flexibility and enable reaction to user events, including new user experiences, in Near-Real Time. Additionally, we propose a novel solution to manage deployment of this framework in production models, allowing downstream models to work independently. We validate the performance of our framework through rigorous offline and online experiments within a large-scale system, showcasing its remarkable efficacy across multiple evaluation tasks. Finally, we show how the proposed framework can significantly reduce infrastructure costs compared to alternative approaches.\n    ",
        "primary_category": "cs.IR",
        "categories": [
            "cs.LG"
        ],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00585": {
        "title": "Decentralized Uncoded Storage Elastic Computing with Heterogeneous Computation Speeds",
        "authors": [
            "Wenbo Huang",
            "Xudong You",
            "Kai Wan",
            "Robert Caiming Qiu",
            "Mingyue Ji"
        ],
        "comments": "10 pages, 8 figures, submitted to ISIT2024",
        "subjects": "Information Theory (cs.IT)",
        "abstract": "Elasticity plays an important role in modern cloud computing systems. Elastic computing allows virtual machines (i.e., computing nodes) to be preempted when high-priority jobs arise, and also allows new virtual machines to participate in the computation. In 2018, Yang et al. introduced Coded Storage Elastic Computing (CSEC) to address the elasticity using coding technology, with lower storage and computation load requirements. However, CSEC is limited to certain types of computations (e.g., linear) due to the coded data storage based on linear coding. Then Centralized Uncoded Storage Elastic Computing (CUSEC) with heterogeneous computation speeds was proposed, which directly copies parts of data into the virtual machines. In all existing works in elastic computing, the storage assignment is centralized, meaning that the number and identity of all virtual machines possible used in the whole computation process are known during the storage assignment. In this paper, we consider Decentralized Uncoded Storage Elastic Computing (DUSEC) with heterogeneous computation speeds, where any available virtual machine can join the computation which is not predicted and thus coordination among different virtual machines' storage assignments is not allowed. Under a decentralized storage assignment originally proposed in coded caching by Maddah-Ali and Niesen, we propose a computing scheme with closed-form optimal computation time. We also run experiments over MNIST dataset with Softmax regression model through the Tencent cloud platform, and the experiment results demonstrate that the proposed DUSEC system approaches the state-of-art best storage assignment in the CUSEC system in computation time.\n    ",
        "primary_category": "cs.IT",
        "categories": [],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00586": {
        "title": "Open Assistant Toolkit -- version 2",
        "authors": [
            "Sophie Fischer",
            "Federico Rossetto",
            "Carlos Gemmell",
            "Andrew Ramsay",
            "Iain Mackie",
            "Philip Zubel",
            "Niklas Tecklenburg",
            "Jeffrey Dalton"
        ],
        "comments": " ",
        "subjects": "Information Retrieval (cs.IR)",
        "abstract": "We present the second version of the Open Assistant Toolkit (OAT-v2), an open-source task-oriented conversational system for composing generative neural models. OAT-v2 is a scalable and flexible assistant platform supporting multiple domains and modalities of user interaction. It splits processing a user utterance into modular system components, including submodules such as action code generation, multimodal content retrieval, and knowledge-augmented response generation. Developed over multiple years of the Alexa TaskBot challenge, OAT-v2 is a proven system that enables scalable and robust experimentation in experimental and real-world deployment. OAT-v2 provides open models and software for research and commercial applications to enable the future of multimodal virtual assistants across diverse applications and types of rich interaction.\n    ",
        "primary_category": "cs.IR",
        "categories": [],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00587": {
        "title": "Improving Explicit Spatial Relationships in Text-to-Image Generation through an Automatically Derived Dataset",
        "authors": [
            "Ander Salaberria",
            "Gorka Azkune",
            "Oier Lopez de Lacalle",
            "Aitor Soroa",
            "Eneko Agirre",
            "Frank Keller"
        ],
        "comments": "12 pages and 5 figures",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Existing work has observed that current text-to-image systems do not accurately reflect explicit spatial relations between objects such as 'left of' or 'below'. We hypothesize that this is because explicit spatial relations rarely appear in the image captions used to train these models. We propose an automatic method that, given existing images, generates synthetic captions that contain 14 explicit spatial relations. We introduce the Spatial Relation for Generation (SR4G) dataset, which contains 9.9 millions image-caption pairs for training, and more than 60 thousand captions for evaluation. In order to test generalization we also provide an 'unseen' split, where the set of objects in the train and test captions are disjoint. SR4G is the first dataset that can be used to spatially fine-tune text-to-image systems. We show that fine-tuning two different Stable Diffusion models (denoted as SD$_{SR4G}$) yields up to 9 points improvements in the VISOR metric. The improvement holds in the 'unseen' split, showing that SD$_{SR4G}$ is able to generalize to unseen objects. SD$_{SR4G}$ improves the state-of-the-art with fewer parameters, and avoids complex architectures. Our analysis shows that improvement is consistent for all relations. The dataset and the code will be publicly available.\n    ",
        "primary_category": "cs.CV",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00590": {
        "title": "Hercules: Heterogeneous Requirements Congestion Control Protocol",
        "authors": [
            "Neta Rozen-Schiff",
            "Itzcak Pechtalt",
            "Amit Navon",
            "Leon Bruckman"
        ],
        "comments": " ",
        "subjects": "Networking and Internet Architecture (cs.NI)",
        "abstract": "Today's networks are struggling to scale and satisfy the high number and high variety of co-existing network requirements. While existing congestion control (CC) protocols are designed to handle strict classification of network flows into one or few priorities, a more granular and dynamic congestion control is needed.\nIn this paper we present Hercules, a novel CC protocol based on an online learning approach, which supports unbounded and continues requirements space. We implemented Hercules as a QUIC module and we show, through analytical analysis and real-world experiments, that it provides between $50\\%-250\\%$ higher QoS for co-existing diverse network flows and outperforms state-of-the-art CC protocols, even under high network congestion.\n    ",
        "primary_category": "cs.NI",
        "categories": [],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00591": {
        "title": "Learning Causal Features for Incremental Object Detection",
        "authors": [
            "Zhenwei He",
            "Lei Zhang"
        ],
        "comments": " ",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Object detection limits its recognizable categories during the training phase, in which it can not cover all objects of interest for users. To satisfy the practical necessity, the incremental learning ability of the detector becomes a critical factor for real-world applications. Unfortunately, neural networks unavoidably meet catastrophic forgetting problem when it is implemented on a new task. To this end, many incremental object detection models preserve the knowledge of previous tasks by replaying samples or distillation from previous models. However, they ignore an important factor that the performance of the model mostly depends on its feature. These models try to rouse the memory of the neural network with previous samples but not to prevent forgetting. To this end, in this paper, we propose an incremental causal object detection (ICOD) model by learning causal features, which can adapt to more tasks. Traditional object detection models, unavoidably depend on the data-bias or data-specific features to get the detection results, which can not adapt to the new task. When the model meets the requirements of incremental learning, the data-bias information is not beneficial to the new task, and the incremental learning may eliminate these features and lead to forgetting. To this end, our ICOD is introduced to learn the causal features, rather than the data-bias features when training the detector. Thus, when the model is implemented to a new task, the causal features of the old task can aid the incremental learning process to alleviate the catastrophic forgetting problem. We conduct our model on several experiments, which shows a causal feature without data-bias can make the model adapt to new tasks better. \\keywords{Object detection, incremental learning, causal feature.\n    ",
        "primary_category": "cs.CV",
        "categories": [],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00592": {
        "title": "Rethinking Few-shot 3D Point Cloud Semantic Segmentation",
        "authors": [
            "Zhaochong An",
            "Guolei Sun",
            "Yun Liu",
            "Fayao Liu",
            "Zongwei Wu",
            "Dan Wang",
            "Luc Van Gool",
            "Serge Belongie"
        ],
        "comments": "Accepted to CVPR 2024",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "This paper revisits few-shot 3D point cloud semantic segmentation (FS-PCS), with a focus on two significant issues in the state-of-the-art: foreground leakage and sparse point distribution. The former arises from non-uniform point sampling, allowing models to distinguish the density disparities between foreground and background for easier segmentation. The latter results from sampling only 2,048 points, limiting semantic information and deviating from the real-world practice. To address these issues, we introduce a standardized FS-PCS setting, upon which a new benchmark is built. Moreover, we propose a novel FS-PCS model. While previous methods are based on feature optimization by mainly refining support features to enhance prototypes, our method is based on correlation optimization, referred to as Correlation Optimization Segmentation (COSeg). Specifically, we compute Class-specific Multi-prototypical Correlation (CMC) for each query point, representing its correlations to category prototypes. Then, we propose the Hyper Correlation Augmentation (HCA) module to enhance CMC. Furthermore, tackling the inherent property of few-shot training to incur base susceptibility for models, we propose to learn non-parametric prototypes for the base classes during training. The learned base prototypes are used to calibrate correlations for the background class through a Base Prototypes Calibration (BPC) module. Experiments on popular datasets demonstrate the superiority of COSeg over existing methods. The code is available at: this https URL\n",
        "primary_category": "cs.CV",
        "categories": [],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00598": {
        "title": "Popularity and Perfectness in One-sided Matching Markets with Capacities",
        "authors": [
            "Gergely Cs\u00e1ji"
        ],
        "comments": " ",
        "subjects": "Computer Science and Game Theory (cs.GT)",
        "abstract": "We consider many-to-one matching problems, where one side corresponds to applicants who have preferences and the other side to houses who do not have preferences. We consider two different types of this market: one, where the applicants have capacities, and one where the houses do. First, we answer an open question by Manlove and Sng (2006) (partly solved Paluch (2014) for preferences with ties), that is, we show that deciding if a popular matching exists in the house allocation problem, where agents have capacities is NP-hard for previously studied versions of popularity. Then, we consider the other version, where the houses have capacities. We study how to optimally increase the capacities of the houses to obtain a matching satisfying multiple optimality criteria, like popularity, Pareto-optimality and perfectness. We consider two common optimality criteria, one aiming to minimize the sum of capacity increases of all houses and the other aiming to minimize the maximum capacity increase of any school. We obtain a complete picture in terms of computational complexity and some algorithms.\n    ",
        "primary_category": "cs.GT",
        "categories": [
            "cs.DM"
        ],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00606": {
        "title": "Flattening Singular Values of Factorized Convolution for Medical Images",
        "authors": [
            "Zexin Feng",
            "Na Zeng",
            "Jiansheng Fang",
            "Xingyue Wang",
            "Xiaoxi Lu",
            "Heng Meng",
            "Jiang Liu"
        ],
        "comments": " ",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Convolutional neural networks (CNNs) have long been the paradigm of choice for robust medical image processing (MIP). Therefore, it is crucial to effectively and efficiently deploy CNNs on devices with different computing capabilities to support computer-aided diagnosis. Many methods employ factorized convolutional layers to alleviate the burden of limited computational resources at the expense of expressiveness. To this end, given weak medical image-driven CNN model optimization, a Singular value equalization generalizer-induced Factorized Convolution (SFConv) is proposed to improve the expressive power of factorized convolutions in MIP models. We first decompose the weight matrix of convolutional filters into two low-rank matrices to achieve model reduction. Then minimize the KL divergence between the two low-rank weight matrices and the uniform distribution, thereby reducing the number of singular value directions with significant variance. Extensive experiments on fundus and OCTA datasets demonstrate that our SFConv yields competitive expressiveness over vanilla convolutions while reducing complexity.\n    ",
        "primary_category": "cs.CV",
        "categories": [],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00607": {
        "title": "Dynamic Operational Planning in Warfare: A Stochastic Game Approach to Military Campaigns",
        "authors": [
            "Joseph E. McCarthy",
            "Mathieu Dahan",
            "Chelsea C. White III"
        ],
        "comments": " ",
        "subjects": "Computer Science and Game Theory (cs.GT)",
        "abstract": "We study a two-player discounted zero-sum stochastic game model for dynamic operational planning in military campaigns. At each stage, the players manage multiple commanders who order military actions on objectives that have an open line of control. When a battle over the control of an objective occurs, its stochastic outcome depends on the actions and the enabling support provided by the control of other objectives. Each player aims to maximize the cumulative number of objectives they control, weighted by their criticality. To solve this large-scale stochastic game, we derive properties of its Markov perfect equilibria by leveraging the logistics and military operational command and control structure. We show the consequential isotonicity of the optimal value function with respect to the partially ordered state space, which in turn leads to a significant reduction of the state and action spaces. We also accelerate Shapley's value iteration algorithm by eliminating dominated actions and investigating pure equilibria of the matrix game solved at each iteration. We demonstrate the computational value of our equilibrium results on a case study that reflects representative operational-level military campaigns with geopolitical implications. Our analysis reveals a complex interplay between the game's parameters and dynamics in equilibrium, resulting in new military insights for campaign analysts.\n    ",
        "primary_category": "cs.GT",
        "categories": [],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00612": {
        "title": "Advancing dermatological diagnosis: Development of a hyperspectral dermatoscope for enhanced skin imaging",
        "authors": [
            "Martin J. Hetz",
            "Carina Nogueira Garcia",
            "Sarah Haggenm\u00fcller",
            "Titus J. Brinker"
        ],
        "comments": "12 pages, 11 Figures",
        "subjects": "Image and Video Processing (eess.IV)",
        "abstract": "Clinical dermatology necessitates precision and innovation for efficient diagnosis and treatment of various skin conditions. This paper introduces the development of a cutting-edge hyperspectral dermatoscope (the Hyperscope) tailored for human skin analysis. We detail the requirements to such a device and the design considerations, from optical configurations to sensor selection, necessary to capture a wide spectral range with high fidelity. Preliminary results from 15 individuals and 160 recorded skin images demonstrate the potential of the Hyperscope in identifying and characterizing various skin conditions, offering a promising avenue for non-invasive skin evaluation and a platform for future research in dermatology-related hyperspectral imaging.\n    ",
        "primary_category": "eess.IV",
        "categories": [
            "cs.CV"
        ],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00621": {
        "title": "AdaBoost-Based Efficient Channel Estimation and Data Detection in One-Bit Massive MIMO",
        "authors": [
            "Majdoddin Esfandiari",
            "Sergiy A. Vorobyov",
            "Robert W. Heath Jr"
        ],
        "comments": " ",
        "subjects": "Information Theory (cs.IT)",
        "abstract": "The use of one-bit analog-to-digital converter (ADC) has been considered as a viable alternative to high resolution counterparts in realizing and commercializing massive multiple-input multiple-output (MIMO) systems. However, the issue of discarding the amplitude information by one-bit quantizers has to be compensated. Thus, carefully tailored methods need to be developed for one-bit channel estimation and data detection as the conventional ones cannot be used. To address these issues, the problems of one-bit channel estimation and data detection for MIMO orthogonal frequency division multiplexing (OFDM) system that operates over uncorrelated frequency selective channels are investigated here. We first develop channel estimators that exploit Gaussian discriminant analysis (GDA) classifier and approximated versions of it as the so-called weak classifiers in an adaptive boosting (AdaBoost) approach. Particularly, the combination of the approximated GDA classifiers with AdaBoost offers the benefit of scalability with the linear order of computations, which is critical in massive MIMO-OFDM systems. We then take advantage of the same idea for proposing the data detectors. Numerical results validate the efficiency of the proposed channel estimators and data detectors compared to other methods. They show comparable/better performance to that of the state-of-the-art methods, but require dramatically lower computational complexities and run times.\n    ",
        "primary_category": "cs.IT",
        "categories": [
            "eess.SP"
        ],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00622": {
        "title": "Shortened Polar Codes under Automorphism Ensemble Decoding",
        "authors": [
            "Charles Pillet",
            "Ilshat Sagitov",
            "Valerio Bioglio",
            "Pascal Giard"
        ],
        "comments": "5 pages, 4 figures, accepted in IEEE Communications Letters",
        "subjects": "Information Theory (cs.IT)",
        "abstract": "In this paper, we propose a low-latency decoding solution of shortened polar codes based on their automorphism groups. The automorphism group of shortened polar codes, designed according to two existing shortening patterns, are shown to be limited but non-empty, making the Automorphism Ensemble (AE) decoding of shortened polar codes possible. Extensive simulation results for shortened polar codes under AE are provided and are compared to the SC-List (SCL) algorithm. The block-error rate of shortened polar codes under AE matches or beats SCL while lowering the decoding latency.\n    ",
        "primary_category": "cs.IT",
        "categories": [],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00623": {
        "title": "Analysis of the particle relaxation method for generating uniform particle distributions in smoothed particle hydrodynamics",
        "authors": [
            "Yu Fan",
            "Xiaoliang Li",
            "Shuoguo Zhang",
            "Xiangyu Hu",
            "Nikolaus A. Adams"
        ],
        "comments": " ",
        "subjects": "Numerical Analysis (math.NA)",
        "abstract": "We establish a theoretical framework of the particle relaxation method for uniform particle generation of Smoothed Particle Hydrodynamics. We achieve this by reformulating the particle relaxation as an optimization problem. The objective function is an integral difference between discrete particle-based and smoothed-analytical volume fractions. The analysis demonstrates that the particle relaxation method in the domain interior is essentially equivalent to employing a gradient descent approach to solve this optimization problem, and we can extend such an equivalence to the bounded domain by introducing a proper boundary term. Additionally, each periodic particle distribution has a spatially uniform particle volume, denoted as characteristic volume. The relaxed particle distribution has the largest characteristic volume, and the kernel cut-off radius determines this volume. This insight enables us to control the relaxed particle distribution by selecting the target kernel cut-off radius for a given kernel function.\n    ",
        "primary_category": "math.NA",
        "categories": [
            "physics.comp-ph"
        ],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00625": {
        "title": "Bias Mitigation in Fine-tuning Pre-trained Models for Enhanced Fairness and Efficiency",
        "authors": [
            "Yixuan Zhang",
            "Feng Zhou"
        ],
        "comments": " ",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Fine-tuning pre-trained models is a widely employed technique in numerous real-world applications. However, fine-tuning these models on new tasks can lead to unfair outcomes. This is due to the absence of generalization guarantees for fairness properties, regardless of whether the original pre-trained model was developed with fairness considerations. To tackle this issue, we introduce an efficient and robust fine-tuning framework specifically designed to mitigate biases in new tasks. Our empirical analysis shows that the parameters in the pre-trained model that affect predictions for different demographic groups are different, so based on this observation, we employ a transfer learning strategy that neutralizes the importance of these influential weights, determined using Fisher information across demographic groups. Additionally, we integrate this weight importance neutralization strategy with a matrix factorization technique, which provides a low-rank approximation of the weight matrix using fewer parameters, reducing the computational demands. Experiments on multiple pre-trained models and new tasks demonstrate the effectiveness of our method.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.CY"
        ],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00628": {
        "title": "Region-Adaptive Transform with Segmentation Prior for Image Compression",
        "authors": [
            "Yuxi Liu",
            "Wenhan Yang",
            "Huihui Bai",
            "Yunchao Wei",
            "Yao Zhao"
        ],
        "comments": " ",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Learned Image Compression (LIC) has shown remarkable progress in recent years. Existing works commonly employ CNN-based or self-attention-based modules as transform methods for compression. However, there is no prior research on neural transform that focuses on specific regions. In response, we introduce the class-agnostic segmentation masks (i.e. semantic masks without category labels) for extracting region-adaptive contextual information. Our proposed module, Region-Adaptive Transform, applies adaptive convolutions on different regions guided by the masks. Additionally, we introduce a plug-and-play module named Scale Affine Layer to incorporate rich contexts from various regions. While there have been prior image compression efforts that involve segmentation masks as additional intermediate inputs, our approach differs significantly from them. Our advantages lie in that, to avoid extra bitrate overhead, we treat these masks as privilege information, which is accessible during the model training stage but not required during the inference phase. To the best of our knowledge, we are the first to employ class-agnostic masks as privilege information and achieve superior performance in pixel-fidelity metrics, such as Peak Signal to Noise Ratio (PSNR). The experimental results demonstrate our improvement compared to previously well-performing methods, with about 8.2% bitrate saving compared to VTM-17.0. The code will be released at this https URL.\n    ",
        "primary_category": "cs.CV",
        "categories": [
            "eess.IV"
        ],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00631": {
        "title": "Transforming Design Spaces Using Pareto-Laplace Filters",
        "authors": [
            "Hazhir Aliahmadi",
            "Ruben Perez",
            "Greg van Anders"
        ],
        "comments": "28+19 pages, 3 figures",
        "subjects": "Computational Engineering, Finance, and Science (cs.CE)",
        "abstract": "Optimization is a critical tool for addressing a broad range of human and technical problems. However, the paradox of advanced optimization techniques is that they have maximum utility for problems in which the relationship between the structure of the problem and the ultimate solution is the most obscure. The existence of solution with limited insight contrasts with techniques that have been developed for a broad range of engineering problems where integral transform techniques yield solutions and insight in tandem. Here, we present a ``Pareto-Laplace'' integral transform framework that can be applied to problems typically studied via optimization. We show that the framework admits related geometric, statistical, and physical representations that provide new forms of insight into relationships between objectives and outcomes. We argue that some known approaches are special cases of this framework, and point to a broad range of problems for further application.\n    ",
        "primary_category": "cs.CE",
        "categories": [
            "cond-mat.stat-mech",
            "math.OC"
        ],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00633": {
        "title": "Informed and Assessable Observability Design Decisions in Cloud-native Microservice Applications",
        "authors": [
            "Maria C. Borges",
            "Joshua Bauer",
            "Sebastian Werner",
            "Michael Gebauer",
            "Stefan Tai"
        ],
        "comments": " ",
        "subjects": "Software Engineering (cs.SE)",
        "abstract": "Observability is important to ensure the reliability of microservice applications. These applications are often prone to failures, since they have many independent services deployed on heterogeneous environments. When employed \"correctly\", observability can help developers identify and troubleshoot faults quickly. However, instrumenting and configuring the observability of a microservice application is not trivial but tool-dependent and tied to costs. Architects need to understand observability-related trade-offs in order to weigh between different observability design alternatives. Still, these architectural design decisions are not supported by systematic methods and typically just rely on \"professional intuition\". In this paper, we argue for a systematic method to arrive at informed and continuously assessable observability design decisions. Specifically, we focus on fault observability of cloud-native microservice applications, and turn this into a testable and quantifiable property. Towards our goal, we first model the scale and scope of observability design decisions across the cloud-native stack. Then, we propose observability metrics which can be determined for any microservice application through so-called observability experiments. We present a proof-of-concept implementation of our experiment tool OXN. OXN is able to inject arbitrary faults into an application, similar to Chaos Engineering, but also possesses the unique capability to modify the observability configuration, allowing for the assessment of design decisions that were previously left unexplored. We demonstrate our approach using a popular open source microservice application and show the trade-offs involved in different observability design decisions.\n    ",
        "primary_category": "cs.SE",
        "categories": [],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00636": {
        "title": "Graph Theory and GNNs to Unravel the Topographical Organization of Brain Lesions in Variants of Alzheimer's Disease Progression",
        "authors": [
            "Leopold Hebert-Stevens",
            "Gabriel Jimenez",
            "Benoit Delatour",
            "Lev Stimmer",
            "Daniel Racoceanu"
        ],
        "comments": " ",
        "subjects": "Image and Video Processing (eess.IV)",
        "abstract": "This study utilizes graph theory and deep learning to assess variations in Alzheimer's disease (AD) neuropathologies, focusing on classic (cAD) and rapid (rpAD) progression forms. It analyses the distribution of amyloid plaques and tau tangles in postmortem brain tissues. Histopathological images are converted into tau-pathology-based graphs, and derived metrics are used for statistical analysis and in machine learning classifiers. These classifiers incorporate SHAP value explainability to differentiate between cAD and rpAD. Graph neural networks (GNNs) demonstrate greater efficiency than traditional CNN methods in analyzing this data, preserving spatial pathology context. Additionally, GNNs provide significant insights through explainable AI techniques. The analysis shows denser networks in rpAD and a distinctive impact on brain cortical layers: rpAD predominantly affects middle layers, whereas cAD influences both superficial and deep layers of the same cortical regions. These results suggest a unique neuropathological network organization for each AD variant.\n    ",
        "primary_category": "eess.IV",
        "categories": [
            "cs.CV"
        ],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00637": {
        "title": "On the complexity of strong approximation of stochastic differential equations with a non-Lipschitz drift coefficient",
        "authors": [
            "T. M\u00fcller-Gronbach",
            "L. Yaroslavtseva"
        ],
        "comments": " ",
        "subjects": "Probability (math.PR)",
        "abstract": "We survey recent developments in the field of complexity of pathwise approximation in $p$-th mean of the solution of a stochastic differential equation at the final time based on finitely many evaluations of the driving Brownian motion. First, we briefly review the case of equations with globally Lipschitz continuous coefficients, for which an error rate of at least $1/2$ in terms of the number of evaluations of the driving Brownian motion is always guaranteed by using the equidistant Euler-Maruyama scheme. Then we illustrate that giving up the global Lipschitz continuity of the coefficients may lead to a non-polynomial decay of the error for the Euler-Maruyama scheme or even to an arbitrary slow decay of the smallest possible error that can be achieved on the basis of finitely many evaluations of the driving Brownian motion. Finally, we turn to recent positive results for equations with a drift coefficient that is not globally Lipschitz continuous. Here we focus on scalar equations with a Lipschitz continuous diffusion coefficient and a drift coefficient that satisfies piecewise smoothness assumptions or has fractional Sobolev regularity and we present corresponding complexity results.\n    ",
        "primary_category": "math.PR",
        "categories": [
            "math.NA"
        ],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00641": {
        "title": "Robust Online Epistemic Replanning of Multi-Robot Missions",
        "authors": [
            "Lauren Bramblett",
            "Branko Miloradovic",
            "Patrick Sherman",
            "Alessandro V. Papadopoulos",
            "Nicola Bezzo"
        ],
        "comments": " ",
        "subjects": "Robotics (cs.RO)",
        "abstract": "As Multi-Robot Systems (MRS) become more affordable and computing capabilities grow, they provide significant advantages for complex applications such as environmental monitoring, underwater inspections, or space exploration. However, accounting for potential communication loss or the unavailability of communication infrastructures in these application domains remains an open problem. Much of the applicable MRS research assumes that the system can sustain communication through proximity regulations and formation control or by devising a framework for separating and adhering to a predetermined plan for extended periods of disconnection. The latter technique enables an MRS to be more efficient, but breakdowns and environmental uncertainties can have a domino effect throughout the system, particularly when the mission goal is intricate or time-sensitive. To deal with this problem, our proposed framework has two main phases: i) a centralized planner to allocate mission tasks by rewarding intermittent rendezvous between robots to mitigate the effects of the unforeseen events during mission execution, and ii) a decentralized replanning scheme leveraging epistemic planning to formalize belief propagation and a Monte Carlo tree search for policy optimization given distributed rational belief updates. The proposed framework outperforms a baseline heuristic and is validated using simulations and experiments with aerial vehicles.\n    ",
        "primary_category": "cs.RO",
        "categories": [],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00643": {
        "title": "Undercomplete Decomposition of Symmetric Tensors in Linear Time, and Smoothed Analysis of the Condition Number",
        "authors": [
            "Pascal Koiran",
            "Subhayan Saha"
        ],
        "comments": "55 pages",
        "subjects": "Data Structures and Algorithms (cs.DS)",
        "abstract": "We study symmetric tensor decompositions, i.e., decompositions of the form $T = \\sum_{i=1}^r u_i^{\\otimes 3}$ where $T$ is a symmetric tensor of order 3 and $u_i \\in \\mathbb{C}^n$.In order to obtain efficient decomposition algorithms, it is necessary to require additional properties from $u_i$. In this paper we assume that the $u_i$ are linearly independent. This implies $r \\leq n$,that is, the decomposition of T is undercomplete.\nWe give a randomized algorithm for the following problem in the exact arithmetic model of computation: Let $T$ be an order-3 symmetric tensor that has an undercomplete decomposition.Then given some $T'$ close to $T$, an accuracy parameter $\\varepsilon$, and an upper bound B on the condition number of the tensor, output vectors $u'_i$ such that $||u_i - u'_i|| \\leq \\varepsilon$ (up to permutation and multiplication by cube roots of unity) with high probability. The main novel features of our algorithm are:\n1) We provide the first algorithm for this problem that runs in linear time in the size of the input tensor. More specifically, it requires $O(n^3)$ arithmetic operations for all accuracy parameters $\\varepsilon =$ 1/poly(n) and B = poly(n).\n2) Our algorithm is robust, that is, it can handle inverse-quasi-polynomial noise (in $n$,B,$\\frac{1}{\\varepsilon}$) in the input tensor.\n3) We present a smoothed analysis of the condition number of the tensor decomposition problem. This guarantees that the condition number is low with high probability and further shows that our algorithm runs in linear time, except for some rare badly conditioned inputs.\nOur main algorithm is a reduction to the complete case ($r=n$) treated in our previous work [Koiran,Saha,CIAC 2023]. For efficiency reasons we cannot use this algorithm as a blackbox. Instead, we show that it can be run on an implicitly represented tensor obtained from the input tensor by a change of basis.\n    ",
        "primary_category": "cs.DS",
        "categories": [
            "cs.CC",
            "math.NA"
        ],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00645": {
        "title": "Event-Triggered Robust Cooperative Output Regulation for a Class of Linear Multi-Agent Systems with an Unknown Exosystem",
        "authors": [
            "Yangyang Qian",
            "Lu Liu"
        ],
        "comments": "13 pages, 8 figures",
        "subjects": "Systems and Control (eess.SY)",
        "abstract": "This paper investigates the robust cooperative output regulation problem for a class of heterogeneous uncertain linear multi-agent systems with an unknown exosystem via event-triggered control (ETC). By utilizing the internal model approach and the adaptive control technique, a distributed adaptive internal model is constructed for each agent. Then, based on this internal model, a fully distributed ETC strategy composed of a distributed event-triggered adaptive output feedback control law and a distributed dynamic event-triggering mechanism is proposed, in which each agent updates its control input at its own triggering time instants. It is shown that under the proposed ETC strategy, the robust cooperative output regulation problem can be solved without requiring either the global information associated with the communication topology or the bounds of the uncertain or unknown parameters in each agent and the exosystem. A numerical example is provided to illustrate the effectiveness of the proposed control strategy.\n    ",
        "primary_category": "eess.SY",
        "categories": [],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00646": {
        "title": "Stability-Certified Learning of Control Systems with Quadratic Nonlinearities",
        "authors": [
            "Igor Pontes Duff",
            "Pawan Goyal",
            "Peter Benner"
        ],
        "comments": "12 pages, 4 figures",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "This work primarily focuses on an operator inference methodology aimed at constructing low-dimensional dynamical models based on a priori hypotheses about their structure, often informed by established physics or expert insights. Stability is a fundamental attribute of dynamical systems, yet it is not always assured in models derived through inference. Our main objective is to develop a method that facilitates the inference of quadratic control dynamical systems with inherent stability guarantees. To this aim, we investigate the stability characteristics of control systems with energy-preserving nonlinearities, thereby identifying conditions under which such systems are bounded-input bounded-state stable. These insights are subsequently applied to the learning process, yielding inferred models that are inherently stable by design. The efficacy of our proposed framework is demonstrated through a couple of numerical examples.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "math.DS",
            "math.OC"
        ],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00662": {
        "title": "Modeling the Quality of Dialogical Explanations",
        "authors": [
            "Milad Alshomary",
            "Felix Lange",
            "Meisam Booshehri",
            "Meghdut Sengupta",
            "Philipp Cimiano",
            "Henning Wachsmuth"
        ],
        "comments": "9 pages, 3 figures, LREC-COLING 24",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "Explanations are pervasive in our lives. Mostly, they occur in dialogical form where an {\\em explainer} discusses a concept or phenomenon of interest with an {\\em explainee}. Leaving the explainee with a clear understanding is not straightforward due to the knowledge gap between the two participants. Previous research looked at the interaction of explanation moves, dialogue acts, and topics in successful dialogues with expert explainers. However, daily-life explanations often fail, raising the question of what makes a dialogue successful. In this work, we study explanation dialogues in terms of the interactions between the explainer and explainee and how they correlate with the quality of explanations in terms of a successful understanding on the explainee's side. In particular, we first construct a corpus of 399 dialogues from the Reddit forum {\\em Explain Like I am Five} and annotate it for interaction flows and explanation quality. We then analyze the interaction flows, comparing them to those appearing in expert dialogues. Finally, we encode the interaction flows using two language models that can handle long inputs, and we provide empirical evidence for the effectiveness boost gained through the encoding in predicting the success of explanation dialogues.\n    ",
        "primary_category": "cs.CL",
        "categories": [],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00663": {
        "title": "COLON: The largest COlonoscopy LONg sequence public database",
        "authors": [
            "Lina Ruiz",
            "Franklin Sierra-Jerez",
            "Jair Ruiz",
            "Fabio Martinez"
        ],
        "comments": "7 pages, 3 figures, 3 tables",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Colorectal cancer is the third most aggressive cancer worldwide. Polyps, as the main biomarker of the disease, are detected, localized, and characterized through colonoscopy procedures. Nonetheless, during the examination, up to 25% of polyps are missed, because of challenging conditions (camera movements, lighting changes), and the close similarity of polyps and intestinal folds. Besides, there is a remarked subjectivity and expert dependency to observe and detect abnormal regions along the intestinal tract. Currently, publicly available polyp datasets have allowed significant advances in computational strategies dedicated to characterizing non-parametric polyp shapes. These computational strategies have achieved remarkable scores of up to 90% in segmentation tasks. Nonetheless, these strategies operate on cropped and expert-selected frames that always observe polyps. In consequence, these computational approximations are far from clinical scenarios and real applications, where colonoscopies are redundant on intestinal background with high textural variability. In fact, the polyps typically represent less than 1% of total observations in a complete colonoscopy record. This work introduces COLON: the largest COlonoscopy LONg sequence dataset with around of 30 thousand polyp labeled frames and 400 thousand background frames. The dataset was collected from a total of 30 complete colonoscopies with polyps at different stages, variations in preparation procedures, and some cases the observation of surgical instrumentation. Additionally, 10 full intestinal background video control colonoscopies were integrated in order to achieve a robust polyp-background frame differentiation. The COLON dataset is open to the scientific community to bring new scenarios to propose computational tools dedicated to polyp detection and segmentation over long sequences, being closer to real colonoscopy scenarios.\n    ",
        "primary_category": "cs.CV",
        "categories": [],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00668": {
        "title": "Exploring Upper-6GHz and mmWave in Real-World 5G Networks: A Direct on-Field Comparison",
        "authors": [
            "Marcello Morini",
            "Eugenio Moro",
            "Ilario Filippini",
            "Antonio Capone",
            "Danilo De Donno"
        ],
        "comments": " ",
        "subjects": "Networking and Internet Architecture (cs.NI)",
        "abstract": "The spectrum crunch challenge poses a vital threat to the progress of cellular networks and recently prompted the inclusion of millimeter wave (mmWave) and Upper 6GHz (U6G) in the 3GPP standards. These two bands promise to unlock a large portion of untapped spectrum, but the harsh propagation due to the increased carrier frequency might negatively impact the performance of urban Radio Access Network (RAN) deployments. Within the span of a year, two co-located 5G networks operating in these frequency bands were deployed at Politecnico di Milano, Milan, Italy, entirely dedicated to the dense urban performance assessment of the two systems. This paper presents an in-depth analysis of the measurement campaigns conducted on them, with the U6G campaign representing the first of its kind. A benchmark is provided by ray-tracing simulations. The results suggest that networks operating in these frequency bands provide good indoor and outdoor coverage and throughput in urban scenarios, even when deployed in the macro base station setup common to lower frequencies. In addition, a comparative performance analysis of these two key technologies is provided, offering insights on their relative strengths, weaknesses and improvement margins and informing on which bands is better suited for urban macro coverage.\n    ",
        "primary_category": "cs.NI",
        "categories": [
            "eess.SP"
        ],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00675": {
        "title": "Reusing Historical Trajectories in Natural Policy Gradient via Importance Sampling: Convergence and Convergence Rate",
        "authors": [
            "Yifan Lin",
            "Yuhao Wang",
            "Enlu Zhou"
        ],
        "comments": " ",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Reinforcement learning provides a mathematical framework for learning-based control, whose success largely depends on the amount of data it can utilize. The efficient utilization of historical trajectories obtained from previous policies is essential for expediting policy optimization. Empirical evidence has shown that policy gradient methods based on importance sampling work well. However, existing literature often neglect the interdependence between trajectories from different iterations, and the good empirical performance lacks a rigorous theoretical justification. In this paper, we study a variant of the natural policy gradient method with reusing historical trajectories via importance sampling. We show that the bias of the proposed estimator of the gradient is asymptotically negligible, the resultant algorithm is convergent, and reusing past trajectories helps improve the convergence rate. We further apply the proposed estimator to popular policy optimization algorithms such as trust region policy optimization. Our theoretical results are verified on classical benchmarks.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "math.OC"
        ],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00680": {
        "title": "Scalable Learning of Item Response Theory Models",
        "authors": [
            "Susanne Frick",
            "Amer Krivo\u0161ija",
            "Alexander Munteanu"
        ],
        "comments": "AISTATS 2024",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Item Response Theory (IRT) models aim to assess latent abilities of $n$ examinees along with latent difficulty characteristics of $m$ test items from categorical data that indicates the quality of their corresponding answers. Classical psychometric assessments are based on a relatively small number of examinees and items, say a class of $200$ students solving an exam comprising $10$ problems. More recent global large scale assessments such as PISA, or internet studies, may lead to significantly increased numbers of participants. Additionally, in the context of Machine Learning where algorithms take the role of examinees and data analysis problems take the role of items, both $n$ and $m$ may become very large, challenging the efficiency and scalability of computations. To learn the latent variables in IRT models from large data, we leverage the similarity of these models to logistic regression, which can be approximated accurately using small weighted subsets called coresets. We develop coresets for their use in alternating IRT training algorithms, facilitating scalable learning from large data.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.DS",
            "stat.ML"
        ],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00686": {
        "title": "A Bit of a Problem: Measurement Disparities in Dataset Sizes Across Languages",
        "authors": [
            "Catherine Arnett",
            "Tyler A. Chang",
            "Benjamin K. Bergen"
        ],
        "comments": " ",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "How should text dataset sizes be compared across languages? Even for content-matched (parallel) corpora, UTF-8 encoded text can require a dramatically different number of bytes for different languages. In our work, we define the byte premium between two languages as the ratio of bytes used to encode content-matched text in those languages. We compute byte premiums for 1155 languages, and we use linear regressions to estimate byte premiums for other languages. We release a tool to obtain byte premiums for any two languages, enabling comparisons of dataset sizes across languages for more equitable multilingual model development and data practices.\n    ",
        "primary_category": "cs.CL",
        "categories": [],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00689": {
        "title": "Hydra: Computer Vision for Data Quality Monitoring",
        "authors": [
            "Thomas Britton",
            "Torri Jeske",
            "David Lawrence",
            "Kishansingh Rajput"
        ],
        "comments": " ",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Hydra is a system which utilizes computer vision to perform near real time data quality management, initially developed for Hall-D in 2019. Since then, it has been deployed across all experimental halls at Jefferson Lab, with the CLAS12 collaboration in Hall-B being the first outside of GlueX to fully utilize Hydra. The system comprises back end processes that manage the models, their inferences, and the data flow. The front-end components, accessible via web pages, allow detector experts and shift crews to view and interact with the system. This talk will give an overview of the Hydra system as well as highlight significant developments in Hydra's feature set, acute challenges with operating Hydra in all halls, and lessons learned along the way.\n    ",
        "primary_category": "cs.CV",
        "categories": [
            "nucl-ex",
            "physics.ins-det"
        ],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00690": {
        "title": "Playing NetHack with LLMs: Potential & Limitations as Zero-Shot Agents",
        "authors": [
            "Dominik Jeurissen",
            "Diego Perez-Liebana",
            "Jeremy Gow",
            "Duygu Cakmak",
            "James Kwan"
        ],
        "comments": " ",
        "subjects": "Artificial Intelligence (cs.AI)",
        "abstract": "Large Language Models (LLMs) have shown great success as high-level planners for zero-shot game-playing agents. However, these agents are primarily evaluated on Minecraft, where long-term planning is relatively straightforward. In contrast, agents tested in dynamic robot environments face limitations due to simplistic environments with only a few objects and interactions. To fill this gap in the literature, we present NetPlay, the first LLM-powered zero-shot agent for the challenging roguelike NetHack. NetHack is a particularly challenging environment due to its diverse set of items and monsters, complex interactions, and many ways to die.\nNetPlay uses an architecture designed for dynamic robot environments, modified for NetHack. Like previous approaches, it prompts the LLM to choose from predefined skills and tracks past interactions to enhance decision-making. Given NetHack's unpredictable nature, NetPlay detects important game events to interrupt running skills, enabling it to react to unforeseen circumstances. While NetPlay demonstrates considerable flexibility and proficiency in interacting with NetHack's mechanics, it struggles with ambiguous task descriptions and a lack of explicit feedback. Our findings demonstrate that NetPlay performs best with detailed context information, indicating the necessity for dynamic methods in supplying context information for complex games such as NetHack.\n    ",
        "primary_category": "cs.AI",
        "categories": [],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00691": {
        "title": "Tri-Modal Motion Retrieval by Learning a Joint Embedding Space",
        "authors": [
            "Kangning Yin",
            "Shihao Zou",
            "Yuxuan Ge",
            "Zheng Tian"
        ],
        "comments": " ",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Information retrieval is an ever-evolving and crucial research domain. The substantial demand for high-quality human motion data especially in online acquirement has led to a surge in human motion research works. Prior works have mainly concentrated on dual-modality learning, such as text and motion tasks, but three-modality learning has been rarely explored. Intuitively, an extra introduced modality can enrich a model's application scenario, and more importantly, an adequate choice of the extra modality can also act as an intermediary and enhance the alignment between the other two disparate modalities. In this work, we introduce LAVIMO (LAnguage-VIdeo-MOtion alignment), a novel framework for three-modality learning integrating human-centric videos as an additional modality, thereby effectively bridging the gap between text and motion. Moreover, our approach leverages a specially designed attention mechanism to foster enhanced alignment and synergistic effects among text, video, and motion modalities. Empirically, our results on the HumanML3D and KIT-ML datasets show that LAVIMO achieves state-of-the-art performance in various motion-related cross-modal retrieval tasks, including text-to-motion, motion-to-text, video-to-motion and motion-to-video.\n    ",
        "primary_category": "cs.CV",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00692": {
        "title": "Toward Autonomous Cooperation in Heterogeneous Nanosatellite Constellations Using Dynamic Graph Neural Networks",
        "authors": [
            "Guillem Casadesus-Vila",
            "Joan-Adria Ruiz-de-Azua",
            "Eduard Alarcon"
        ],
        "comments": "8 pages, 5 figures, conference",
        "subjects": "Signal Processing (eess.SP)",
        "abstract": "The upcoming landscape of Earth Observation missions will defined by networked heterogeneous nanosatellite constellations required to meet strict mission requirements, such as revisit times and spatial resolution. However, scheduling satellite communications in these satellite networks through efficiently creating a global satellite Contact Plan (CP) is a complex task, with current solutions requiring ground-based coordination or being limited by onboard computational resources. The paper proposes a novel approach to overcome these challenges by modeling the constellations and CP as dynamic networks and employing graph-based techniques. The proposed method utilizes a state-of-the-art dynamic graph neural network to evaluate the performance of a given CP and update it using a heuristic algorithm based on simulated annealing. The trained neural network can predict the network delay with a mean absolute error of 3.6 minutes. Simulation results show that the proposed method can successfully design a contact plan for large satellite networks, improving the delay by 29.1%, similar to a traditional approach, while performing the objective evaluations 20x faster.\n    ",
        "primary_category": "eess.SP",
        "categories": [
            "cs.AI",
            "cs.NI"
        ],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00694": {
        "title": "Defining Expertise: Applications to Treatment Effect Estimation",
        "authors": [
            "Alihan H\u00fcy\u00fck",
            "Qiyao Wei",
            "Alicia Curth",
            "Mihaela van der Schaar"
        ],
        "comments": "The 12th International Conference on Learning Representations (ICLR 2024)",
        "subjects": "Machine Learning (stat.ML)",
        "abstract": "Decision-makers are often experts of their domain and take actions based on their domain knowledge. Doctors, for instance, may prescribe treatments by predicting the likely outcome of each available treatment. Actions of an expert thus naturally encode part of their domain knowledge, and can help make inferences within the same domain: Knowing doctors try to prescribe the best treatment for their patients, we can tell treatments prescribed more frequently are likely to be more effective. Yet in machine learning, the fact that most decision-makers are experts is often overlooked, and \"expertise\" is seldom leveraged as an inductive bias. This is especially true for the literature on treatment effect estimation, where often the only assumption made about actions is that of overlap. In this paper, we argue that expertise - particularly the type of expertise the decision-makers of a domain are likely to have - can be informative in designing and selecting methods for treatment effect estimation. We formally define two types of expertise, predictive and prognostic, and demonstrate empirically that: (i) the prominent type of expertise in a domain significantly influences the performance of different methods in treatment effect estimation, and (ii) it is possible to predict the type of expertise present in a dataset, which can provide a quantitative basis for model selection.\n    ",
        "primary_category": "stat.ML",
        "categories": [
            "cs.AI",
            "cs.LG",
            "stat.ME"
        ],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00696": {
        "title": "Self-Consistent Decoding for More Factual Open Responses",
        "authors": [
            "Christopher Malon",
            "Xiaodan Zhu"
        ],
        "comments": " ",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "Self-consistency has emerged as a powerful method for improving the accuracy of short answers generated by large language models. As previously defined, it only concerns the accuracy of a final answer parsed from generated text. In this work, we extend the idea to open response generation, by integrating voting into the decoding method. Each output sentence is selected from among multiple samples, conditioning on the previous selections, based on a simple token overlap score. We compare this \"Sample & Select\" method to greedy decoding, beam search, nucleus sampling, and the recently introduced hallucination avoiding decoders of DoLA, P-CRR, and S-CRR. We show that Sample & Select improves factuality by a 30% relative margin against these decoders in NLI-based evaluation on the subsets of CNN/DM and XSum used in the FRANK benchmark, while maintaining comparable ROUGE-1 F1 scores against reference summaries. We collect human verifications of the generated summaries, confirming the factual superiority of our method.\n    ",
        "primary_category": "cs.CL",
        "categories": [],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00698": {
        "title": "Path Tracking using Echoes in an Unknown Environment: the Issue of Symmetries and How to Break Them",
        "authors": [
            "Mireille Boutin",
            "Gregor Kemper"
        ],
        "comments": " ",
        "subjects": "Metric Geometry (math.MG)",
        "abstract": "This paper deals with the problem of reconstructing the path of a vehicle in an unknown environment consisting of planar structures using sound. Many systems in the literature do this by using a loudspeaker and microphones mounted on a vehicle. Symmetries in the environment lead to solution ambiguities for such systems. We propose to resolve this issue by placing the loudspeaker at a fixed location in the environment rather than on the vehicle. The question of whether this will remove ambiguities regardless of the environment geometry leads to a question about breaking symmetries that can be phrased in purely mathematical terms. We solve this question in the affirmative if the geometry is in dimension three or bigger, and give counterexamples in dimension two. Excluding the rare situations where the counterexamples arise, we also give an affirmative answer in dimension two. Our results lead to a simple path reconstruction algorithm for a vehicle carrying four microphones navigating within an environment in which a loudspeaker at a fixed position emits short bursts of sounds. This algorithm could be combined with other methods from the literature to construct a path tracking system for vehicles navigating within a potentially symmetric environment.\n    ",
        "primary_category": "math.MG",
        "categories": [
            "cs.RO"
        ],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00704": {
        "title": "Representing Guardedness in Call-by-Value and Guarded Parametrized Monads",
        "authors": [
            "Sergey Goncharov"
        ],
        "comments": "Extended version of this https URL",
        "subjects": "Logic in Computer Science (cs.LO)",
        "abstract": "Like the notion of computation via (strong) monads serves to classify various flavours of impurity, including exceptions, non-determinism, probability, local and global store, the notion of guardedness classifies well-behavedness of cycles in various settings. In its most general form, the guardedness discipline applies to general symmetric monoidal categories and further specializes to Cartesian and co-Cartesian categories, where it governs guarded recursion and guarded iteration respectively. Here, even more specifically, we deal with the semantics of call-by-value guarded iteration. It was shown by Levy, Power and Thielecke that call-by-value languages can be generally interpreted in Freyd categories, but in order to represent effectful function spaces, such a category must canonically arise from a strong monad. We generalize this fact by showing that representing guarded effectful function spaces calls for certain parametrized monads (in the sense of Uustalu). This provides a description of guardedness as an intrinsic categorical property of programs, complementing the existing description of guardedness as a predicate on a category.\n    ",
        "primary_category": "cs.LO",
        "categories": [],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00712": {
        "title": "Rethinking Inductive Biases for Surface Normal Estimation",
        "authors": [
            "Gwangbin Bae",
            "Andrew J. Davison"
        ],
        "comments": "CVPR 2024 (camera-ready version will be uploaded in March 2024)",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Despite the growing demand for accurate surface normal estimation models, existing methods use general-purpose dense prediction models, adopting the same inductive biases as other tasks. In this paper, we discuss the inductive biases needed for surface normal estimation and propose to (1) utilize the per-pixel ray direction and (2) encode the relationship between neighboring surface normals by learning their relative rotation. The proposed method can generate crisp - yet, piecewise smooth - predictions for challenging in-the-wild images of arbitrary resolution and aspect ratio. Compared to a recent ViT-based state-of-the-art model, our method shows a stronger generalization ability, despite being trained on an orders of magnitude smaller dataset. The code is available at this https URL.\n    ",
        "primary_category": "cs.CV",
        "categories": [],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00717": {
        "title": "MAIDR: Making Statistical Visualizations Accessible with Multimodal Data Representation",
        "authors": [
            "JooYoung Seo",
            "Yilin Xia",
            "Bongshin Lee",
            "Sean McCurry",
            "Yu Jun Yam"
        ],
        "comments": "Accepted to CHI 2024. Source code is available at this https URL",
        "subjects": "Human-Computer Interaction (cs.HC)",
        "abstract": "This paper investigates new data exploration experiences that enable blind users to interact with statistical data visualizations$-$bar plots, heat maps, box plots, and scatter plots$-$leveraging multimodal data representations. In addition to sonification and textual descriptions that are commonly employed by existing accessible visualizations, our MAIDR (multimodal access and interactive data representation) system incorporates two additional modalities (braille and review) that offer complementary benefits. It also provides blind users with the autonomy and control to interactively access and understand data visualizations. In a user study involving 11 blind participants, we found the MAIDR system facilitated the accurate interpretation of statistical visualizations. Participants exhibited a range of strategies in combining multiple modalities, influenced by their past interactions and experiences with data visualizations. This work accentuates the overlooked potential of combining refreshable tactile representation with other modalities and elevates the discussion on the importance of user autonomy when designing accessible data visualizations.\n    ",
        "primary_category": "cs.HC",
        "categories": [
            "cs.GR"
        ],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00720": {
        "title": "Subhomogeneous Deep Equilibrium Models",
        "authors": [
            "Pietro Sittoni",
            "Francesco Tudisco"
        ],
        "comments": " ",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Implicit-depth neural networks have grown as powerful alternatives to traditional networks in various applications in recent years. However, these models often lack guarantees of existence and uniqueness, raising stability, performance, and reproducibility issues. In this paper, we present a new analysis of the existence and uniqueness of fixed points for implicit-depth neural networks based on the concept of subhomogeneous operators and the nonlinear Perron-Frobenius theory. Compared to previous similar analyses, our theory allows for weaker assumptions on the parameter matrices, thus yielding a more flexible framework for well-defined implicit networks. We illustrate the performance of the resulting subhomogeneous networks on feed-forward, convolutional, and graph neural network examples.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "math.NA",
            "math.OC"
        ],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00724": {
        "title": "Few-Shot Relation Extraction with Hybrid Visual Evidence",
        "authors": [
            "Jiaying Gong",
            "Hoda Eldardiry"
        ],
        "comments": "16 pages, 5 figures",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "The goal of few-shot relation extraction is to predict relations between name entities in a sentence when only a few labeled instances are available for training. Existing few-shot relation extraction methods focus on uni-modal information such as text only. This reduces performance when there are no clear contexts between the name entities described in text. We propose a multi-modal few-shot relation extraction model (MFS-HVE) that leverages both textual and visual semantic information to learn a multi-modal representation jointly. The MFS-HVE includes semantic feature extractors and multi-modal fusion components. The MFS-HVE semantic feature extractors are developed to extract both textual and visual features. The visual features include global image features and local object features within the image. The MFS-HVE multi-modal fusion unit integrates information from various modalities using image-guided attention, object-guided attention, and hybrid feature attention to fully capture the semantic interaction between visual regions of images and relevant texts. Extensive experiments conducted on two public datasets demonstrate that semantic visual information significantly improves the performance of few-shot relation prediction.\n    ",
        "primary_category": "cs.CL",
        "categories": [
            "cs.CV"
        ],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00725": {
        "title": "Cost-Effective Activity Control of Asymptomatic Carriers in Layered Temporal Social Networks",
        "authors": [
            "Masoumeh Moradian",
            "Aresh Dadlani",
            "Rasul Kairgeldin",
            "Ahmad Khonsari"
        ],
        "comments": " ",
        "subjects": "Social and Information Networks (cs.SI)",
        "abstract": "The robustness of human social networks against epidemic propagation relies on the propensity for physical contact adaptation. During the early phase of infection, asymptomatic carriers exhibit the same activity level as susceptible individuals, which presents challenges for incorporating control measures in epidemic projection models. This paper focuses on modeling and cost-efficient activity control of susceptible and carrier individuals in the context of the susceptible-carrier-infected-removed (SCIR) epidemic model over a two-layer contact network. In this model, individuals switch from a static contact layer to create new links in a temporal layer based on state-dependent activation rates. We derive conditions for the infection to die out or persist in a homogeneous network. Considering the significant costs associated with reducing the activity of susceptible and carrier individuals, we formulate an optimization problem to minimize the disease decay rate while constrained by a limited budget. We propose the use of successive geometric programming (SGP) approximation for this optimization task. Through simulation experiments on Poisson random graphs, we assess the impact of different parameters on disease prevalence. The results demonstrate that our SGP framework achieves a cost reduction of nearly 33% compared to conventional methods based on degree and closeness centrality.\n    ",
        "primary_category": "cs.SI",
        "categories": [
            "cs.MA"
        ],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00729": {
        "title": "Can Transformers Capture Spatial Relations between Objects?",
        "authors": [
            "Chuan Wen",
            "Dinesh Jayaraman",
            "Yang Gao"
        ],
        "comments": "21 pages, 8 figures, ICLR 2024",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Spatial relationships between objects represent key scene information for humans to understand and interact with the world. To study the capability of current computer vision systems to recognize physically grounded spatial relations, we start by proposing precise relation definitions that permit consistently annotating a benchmark dataset. Despite the apparent simplicity of this task relative to others in the recognition literature, we observe that existing approaches perform poorly on this benchmark. We propose new approaches exploiting the long-range attention capabilities of transformers for this task, and evaluating key design principles. We identify a simple \"RelatiViT\" architecture and demonstrate that it outperforms all current approaches. To our knowledge, this is the first method to convincingly outperform naive baselines on spatial relation prediction in in-the-wild settings. The code and datasets are available in \\url{this https URL}.\n    ",
        "primary_category": "cs.CV",
        "categories": [
            "cs.RO"
        ],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00736": {
        "title": "The Probability to Hit Every Bin with a Linear Number of Balls",
        "authors": [
            "Stefan Walzer"
        ],
        "comments": " ",
        "subjects": "Probability (math.PR)",
        "abstract": "Assume that $2n$ balls are thrown independently and uniformly at random into $n$ bins. We consider the unlikely event $E$ that every bin receives at least one ball, showing that $\\Pr[E] = \\Theta(b^n)$ where $b \\approx 0.836$. Note that, due to correlations, $b$ is not simply the probability that any single bin receives at least one ball. More generally, we consider the event that throwing $\\alpha n$ balls into $n$ bins results in at least $d$ balls in each bin.\n    ",
        "primary_category": "math.PR",
        "categories": [
            "cs.DS"
        ],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00737": {
        "title": "Happy Ending: An Empty Hexagon in Every Set of 30 Points",
        "authors": [
            "Marijn J.H. Heule",
            "Manfred Scheucher"
        ],
        "comments": " ",
        "subjects": "Computational Geometry (cs.CG)",
        "abstract": "Satisfiability solving has been used to tackle a range of long-standing open math problems in recent years. We add another success by solving a geometry problem that originated a century ago. In the 1930s, Esther Klein's exploration of unavoidable shapes in planar point sets in general position showed that every set of five points includes four points in convex position. For a long time, it was open if an empty hexagon, i.e., six points in convex position without a point inside, can be avoided. In 2006, Gerken and Nicol\u00e1s independently proved that the answer is no. We establish the exact bound: Every 30-point set in the plane in general position contains an empty hexagon. Our key contributions include an effective, compact encoding and a search-space partitioning strategy enabling linear-time speedups even when using thousands of cores.\n    ",
        "primary_category": "cs.CG",
        "categories": [
            "cs.LO",
            "math.CO"
        ],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00742": {
        "title": "Dialect prejudice predicts AI decisions about people's character, employability, and criminality",
        "authors": [
            "Valentin Hofmann",
            "Pratyusha Ria Kalluri",
            "Dan Jurafsky",
            "Sharese King"
        ],
        "comments": " ",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "Hundreds of millions of people now interact with language models, with uses ranging from serving as a writing aid to informing hiring decisions. Yet these language models are known to perpetuate systematic racial prejudices, making their judgments biased in problematic ways about groups like African Americans. While prior research has focused on overt racism in language models, social scientists have argued that racism with a more subtle character has developed over time. It is unknown whether this covert racism manifests in language models. Here, we demonstrate that language models embody covert racism in the form of dialect prejudice: we extend research showing that Americans hold raciolinguistic stereotypes about speakers of African American English and find that language models have the same prejudice, exhibiting covert stereotypes that are more negative than any human stereotypes about African Americans ever experimentally recorded, although closest to the ones from before the civil rights movement. By contrast, the language models' overt stereotypes about African Americans are much more positive. We demonstrate that dialect prejudice has the potential for harmful consequences by asking language models to make hypothetical decisions about people, based only on how they speak. Language models are more likely to suggest that speakers of African American English be assigned less prestigious jobs, be convicted of crimes, and be sentenced to death. Finally, we show that existing methods for alleviating racial bias in language models such as human feedback training do not mitigate the dialect prejudice, but can exacerbate the discrepancy between covert and overt stereotypes, by teaching language models to superficially conceal the racism that they maintain on a deeper level. Our findings have far-reaching implications for the fair and safe employment of language technology.\n    ",
        "primary_category": "cs.CL",
        "categories": [
            "cs.AI",
            "cs.CY"
        ],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00743": {
        "title": "Neural Acceleration of Incomplete Cholesky Preconditioners",
        "authors": [
            "Joshua Dennis Booth",
            "Hongyang Sun",
            "Trevor Garnett"
        ],
        "comments": " ",
        "subjects": "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "abstract": "The solution of a sparse system of linear equations is ubiquitous in scientific applications. Iterative methods, such as the Preconditioned Conjugate Gradient method (PCG), are normally chosen over direct methods due to memory and computational complexity constraints. However, the efficiency of these methods depends on the preconditioner utilized. The development of the preconditioner normally requires some insight into the sparse linear system and the desired trade-off of generating the preconditioner and the reduction in the number of iterations. Incomplete factorization methods tend to be black box methods to generate these preconditioners but may fail for a number of reasons. These reasons include numerical issues that require searching for adequate scaling, shifting, and fill-in while utilizing a difficult to parallelize algorithm. With a move towards heterogeneous computing, many sparse applications find GPUs that are optimized for dense tensor applications like training neural networks being underutilized. In this work, we demonstrate that a simple artificial neural network trained either at compile time or in parallel to the running application on a GPU can provide an incomplete sparse Cholesky factorization that can be used as a preconditioner. This generated preconditioner is as good or better in terms of reduction of iterations than the one found using multiple preconditioning techniques such as scaling and shifting. Moreover, the generated method also works and never fails to produce a preconditioner that does not reduce the iteration count.\n    ",
        "primary_category": "cs.DC",
        "categories": [
            "math.NA"
        ],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00745": {
        "title": "AtP*: An efficient and scalable method for localizing LLM behaviour to components",
        "authors": [
            "J\u00e1nos Kram\u00e1r",
            "Tom Lieberum",
            "Rohin Shah",
            "Neel Nanda"
        ],
        "comments": " ",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Activation Patching is a method of directly computing causal attributions of behavior to model components. However, applying it exhaustively requires a sweep with cost scaling linearly in the number of model components, which can be prohibitively expensive for SoTA Large Language Models (LLMs). We investigate Attribution Patching (AtP), a fast gradient-based approximation to Activation Patching and find two classes of failure modes of AtP which lead to significant false negatives. We propose a variant of AtP called AtP*, with two changes to address these failure modes while retaining scalability. We present the first systematic study of AtP and alternative methods for faster activation patching and show that AtP significantly outperforms all other investigated methods, with AtP* providing further significant improvement. Finally, we provide a method to bound the probability of remaining false negatives of AtP* estimates.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.CL"
        ],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00746": {
        "title": "A time-stepping deep gradient flow method for option pricing in (rough) diffusion models",
        "authors": [
            "Antonis Papapantoleon",
            "Jasper Rou"
        ],
        "comments": "18 pages, 10 figures",
        "subjects": "Computational Finance (q-fin.CP)",
        "abstract": "We develop a novel deep learning approach for pricing European options in diffusion models, that can efficiently handle high-dimensional problems resulting from Markovian approximations of rough volatility models. The option pricing partial differential equation is reformulated as an energy minimization problem, which is approximated in a time-stepping fashion by deep artificial neural networks. The proposed scheme respects the asymptotic behavior of option prices for large levels of moneyness, and adheres to a priori known bounds for option prices. The accuracy and efficiency of the proposed method is assessed in a series of numerical examples, with particular focus in the lifted Heston model.\n    ",
        "primary_category": "q-fin.CP",
        "categories": [
            "cs.LG",
            "math.PR",
            "q-fin.MF"
        ],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00750": {
        "title": "Edge open packing: complexity, algorithmic aspects, and bounds",
        "authors": [
            "Bo\u0161tjan Bre\u0161ar",
            "Babak Samadi"
        ],
        "comments": "12 pages, 1 figure",
        "subjects": "Combinatorics (math.CO)",
        "abstract": "Given a graph $G$, two edges $e_{1},e_{2}\\in E(G)$ are said to have a common edge $e$ if $e$ joins an endvertex of $e_{1}$ to an endvertex of $e_{2}$. A subset $B\\subseteq E(G)$ is an edge open packing set in $G$ if no two edges of $B$ have a common edge in $G$, and the maximum cardinality of such a set in $G$ is called the edge open packing number, $\\rho_{e}^{o}(G)$, of $G$. In this paper, we prove that the decision version of the edge open packing number is NP-complete even when restricted to graphs with universal vertices, Eulerian bipartite graphs, and planar graphs with maximum degree $4$, respectively. In contrast, we present a linear-time algorithm that computes the edge open packing number of a tree. We also resolve two problems posed in the seminal paper [Edge open packing sets in graphs, RAIRO-Oper.\\ Res.\\ 56 (2022) 3765--3776]. Notably, we characterize the graphs $G$ that attain the upper bound $\\rho_e^o(G)\\le |E(G)|/\\delta(G)$, and provide lower and upper bounds for the edge-deleted subgraph of a graph and establish the corresponding realization result.\n    ",
        "primary_category": "math.CO",
        "categories": [
            "cs.DM"
        ],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00752": {
        "title": "An Experimental Study of Low-Latency Video Streaming over 5G",
        "authors": [
            "Imran Khan",
            "Tuyen X. Tran",
            "Matti Hiltunen",
            "Theodore Karagioules",
            "Dimitrios Koutsonikolas"
        ],
        "comments": "6 Pages",
        "subjects": "Multimedia (cs.MM)",
        "abstract": "Low-latency video streaming over 5G has become rapidly popular over the last few years due to its increased usage in hosting virtual events, online education, webinars, and all-hands meetings. Our work aims to address the absence of studies that reveal the real-world behavior of low-latency video streaming. To that end, we provide an experimental methodology and measurements, collected in a US metropolitan area over a commercial 5G network, that correlates application-level QoE and lower-layer metrics on the devices, such as RSRP, RSRQ, handover records, etc., under both static and mobility scenarios. We find that RAN-side information, which is readily available on every cellular device, has the potential to enhance throughput estimation modules of video streaming clients, ultimately making low-latency streaming more resilient against network perturbations and handover events.\n    ",
        "primary_category": "cs.MM",
        "categories": [
            "cs.PF"
        ],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00765": {
        "title": "An Architecture for Unattended Containerized (Deep) Reinforcement Learning with Webots",
        "authors": [
            "Tobias Haubold",
            "Petra Linke"
        ],
        "comments": "Latex with llncs.cls, 17 pages, 5 figures",
        "subjects": "Robotics (cs.RO)",
        "abstract": "As data science applications gain adoption across industries, the tooling landscape matures to facilitate the life cycle of such applications and provide solutions to the challenges involved to boost the productivity of the people involved. Reinforcement learning with agents in a 3D world could still face challenges: the knowledge required to use a simulation software as well as the utilization of a standalone simulation software in unattended training pipelines.\nIn this paper we review tools and approaches to train reinforcement learning agents for robots in 3D worlds with respect to the robot Robotino and argue that the separation of the simulation environment for creators of virtual worlds and the model development environment for data scientists is not a well covered topic. Often both are the same and data scientists require knowledge of the simulation software to work directly with their APIs. Moreover, sometimes creators of virtual worlds and data scientists even work on the same files. We want to contribute to that topic by describing an approach where data scientists don't require knowledge about the simulation software. Our approach uses the standalone simulation software Webots, the Robot Operating System to communicate with simulated robots as well as the simulation software itself and container technology to separate the simulation from the model development environment. We put emphasize on the APIs the data scientists work with and the use of a standalone simulation software in unattended training pipelines. We show the parts that are specific to the Robotino and the robot task to learn.\n    ",
        "primary_category": "cs.RO",
        "categories": [
            "cs.AI",
            "cs.LG"
        ],
        "submitted_date": "6 Feb 2024",
        "last_revised_date": " "
    },
    "2403.00766": {
        "title": "Towards Fair and Firm Real-Time Scheduling in DNN Multi-Tenant Multi-Accelerator Systems via Reinforcement Learning",
        "authors": [
            "Enrico Russo",
            "Francesco Giulio Blanco",
            "Maurizio Palesi",
            "Giuseppe Ascia",
            "Davide Patti",
            "Vincenzo Catania"
        ],
        "comments": " ",
        "subjects": "Hardware Architecture (cs.AR)",
        "abstract": "This paper addresses the critical challenge of managing Quality of Service (QoS) in cloud services, focusing on the nuances of individual tenant expectations and varying Service Level Indicators (SLIs). It introduces a novel approach utilizing Deep Reinforcement Learning for tenant-specific QoS management in multi-tenant, multi-accelerator cloud environments. The chosen SLI, deadline hit rate, allows clients to tailor QoS for each service request. A novel online scheduling algorithm for Deep Neural Networks in multi-accelerator systems is proposed, with a focus on guaranteeing tenant-wise, model-specific QoS levels while considering real-time constraints.\n    ",
        "primary_category": "cs.AR",
        "categories": [
            "cs.DC",
            "cs.LG"
        ],
        "submitted_date": "9 Feb 2024",
        "last_revised_date": " "
    },
    "2403.00769": {
        "title": "Text mining in education",
        "authors": [
            "R. Ferreira-Mello",
            "M. Andre",
            "A. Pinheiro",
            "E. Costa",
            "C. Romero"
        ],
        "comments": " ",
        "subjects": "Information Retrieval (cs.IR)",
        "abstract": "The explosive growth of online education environments is generating a massive volume of data, specially in text format from forums, chats, social networks, assessments, essays, among others. It produces exciting challenges on how to mine text data in order to find useful knowledge for educational stakeholders. Despite the increasing number of educational applications of text mining published recently, we have not found any paper surveying them. In this line, this work presents a systematic overview of the current status of the Educational Text Mining field. Our final goal is to answer three main research questions: Which are the text mining techniques most used in educational environments? Which are the most used educational resources? And which are the main applications or educational goals? Finally, we outline the conclusions and the more interesting future trends.\n    ",
        "primary_category": "cs.IR",
        "categories": [
            "cs.CY",
            "cs.LG"
        ],
        "submitted_date": "11 Feb 2024",
        "last_revised_date": " "
    },
    "2403.00770": {
        "title": "Blockchain Metrics and Indicators in Cryptocurrency Trading",
        "authors": [
            "Juan C. King",
            "Roberto Dale",
            "Jos\u00e9 M. Amig\u00f3"
        ],
        "comments": "26 pages; 14 figures",
        "subjects": "Statistical Finance (q-fin.ST)",
        "abstract": "The objective of this paper is the construction of new indicators that can be useful to operate in the cryptocurrency market. These indicators are based on public data obtained from the blockchain network, specifically from the nodes that make up Bitcoin mining. Therefore, our analysis is unique to that network. The results obtained with numerical simulations of algorithmic trading and prediction via statistical models and Machine Learning demonstrate the importance of variables such as the hash rate, the difficulty of mining or the cost per transaction when it comes to trade Bitcoin assets or predict the direction of price. Variables obtained from the blockchain network will be called here blockchain metrics. The corresponding indicators (inspired by the \"Hash Ribbon\") perform well in locating buy signals. From our results, we conclude that such blockchain indicators allow obtaining information with a statistical advantage in the highly volatile cryptocurrency market.\n    ",
        "primary_category": "q-fin.ST",
        "categories": [
            "cs.CR"
        ],
        "submitted_date": "11 Feb 2024",
        "last_revised_date": " "
    },
    "2403.00771": {
        "title": "XProspeCT: CT Volume Generation from Paired X-Rays",
        "authors": [
            "Benjamin Paulson",
            "Joshua Goldshteyn",
            "Sydney Balboni",
            "John Cisler",
            "Andrew Crisler",
            "Natalia Bukowski",
            "Julia Kalish",
            "Theodore Colwell"
        ],
        "comments": "Originally submitted as part of the MICS 2023 Undergraduate Paper Competition",
        "subjects": "Image and Video Processing (eess.IV)",
        "abstract": "Computed tomography (CT) is a beneficial imaging tool for diagnostic purposes. CT scans provide detailed information concerning the internal anatomic structures of a patient, but present higher radiation dose and costs compared to X-ray imaging. In this paper, we build on previous research to convert orthogonal X-ray images into simulated CT volumes by exploring larger datasets and various model structures. Significant model variations include UNet architectures, custom connections, activation functions, loss functions, optimizers, and a novel back projection approach.\n    ",
        "primary_category": "eess.IV",
        "categories": [
            "cs.CV",
            "cs.LG",
            "physics.med-ph"
        ],
        "submitted_date": "11 Feb 2024",
        "last_revised_date": " "
    },
    "2403.00772": {
        "title": "Do Weibo platform experts perform better at predicting stock market?",
        "authors": [
            "Ziyuan Ma",
            "Conor Ryan",
            "Jim Buckley",
            "Muslim Chochlov"
        ],
        "comments": " ",
        "subjects": "Statistical Finance (q-fin.ST)",
        "abstract": "Sentiment analysis can be used for stock market prediction. However, existing research has not studied the impact of a user's financial background on sentiment-based forecasting of the stock market using artificial neural networks. In this work, a novel combination of neural networks is used for the assessment of sentiment-based stock market prediction, based on the financial background of the population that generated the sentiment. The state-of-the-art language processing model Bidirectional Encoder Representations from Transformers (BERT) is used to classify the sentiment and a Long-Short Term Memory (LSTM) model is used for time-series based stock market prediction. For evaluation, the Weibo social networking platform is used as a sentiment data collection source. Weibo users (and their comments respectively) are divided into Authorized Financial Advisor (AFA) and Unauthorized Financial Advisor (UFA) groups according to their background information, as collected by Weibo. The Hong Kong Hang Seng index is used to extract historical stock market change data. The results indicate that stock market prediction learned from the AFA group users is 39.67% more precise than that learned from the UFA group users and shows the highest accuracy (87%) when compared to existing approaches.\n    ",
        "primary_category": "q-fin.ST",
        "categories": [
            "cs.AI",
            "cs.LG",
            "cs.SI"
        ],
        "submitted_date": "12 Feb 2024",
        "last_revised_date": " "
    },
    "2403.00773": {
        "title": "Misconduct in Post-Selections and Deep Learning",
        "authors": [
            "Juyang Weng"
        ],
        "comments": "9 pages, 2 figures, published in peer-viewed conference proceedings, Proc. 2023 the 8th International Conf. on Control, Robotics and Cybernetics (CRC 2023), pp. 1-9, IEEE Press, ISBN: 979-8-3503-3057-1, Changsha, China, Dec. 22-24, 2023",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "This is a theoretical paper on \"Deep Learning\" misconduct in particular and Post-Selection in general. As far as the author knows, the first peer-reviewed papers on Deep Learning misconduct are [32], [37], [36]. Regardless of learning modes, e.g., supervised, reinforcement, adversarial, and evolutional, almost all machine learning methods (except for a few methods that train a sole system) are rooted in the same misconduct -- cheating and hiding -- (1) cheating in the absence of a test and (2) hiding bad-looking data. It was reasoned in [32], [37], [36] that authors must report at least the average error of all trained networks, good and bad, on the validation set (called general cross-validation in this paper). Better, report also five percentage positions of ranked errors. From the new analysis here, we can see that the hidden culprit is Post-Selection. This is also true for Post-Selection on hand-tuned or searched hyperparameters, because they are random, depending on random observation data. Does cross-validation on data splits rescue Post-Selections from the Misconducts (1) and (2)? The new result here says: No. Specifically, this paper reveals that using cross-validation for data splits is insufficient to exonerate Post-Selections in machine learning. In general, Post-Selections of statistical learners based on their errors on the validation set are statistically invalid.\n    ",
        "primary_category": "cs.LG",
        "categories": [],
        "submitted_date": "13 Feb 2024",
        "last_revised_date": " "
    },
    "2403.00775": {
        "title": "Detecting Anomalous Events in Object-centric Business Processes via Graph Neural Networks",
        "authors": [
            "Alessandro Niro",
            "Michael Werner"
        ],
        "comments": "12 pages, 2 figures, to appear in the ICPM 2023 Workshops Proceedings",
        "subjects": "Statistical Finance (q-fin.ST)",
        "abstract": "Detecting anomalies is important for identifying inefficiencies, errors, or fraud in business processes. Traditional process mining approaches focus on analyzing 'flattened', sequential, event logs based on a single case notion. However, many real-world process executions exhibit a graph-like structure, where events can be associated with multiple cases. Flattening event logs requires selecting a single case identifier which creates a gap with the real event data and artificially introduces anomalies in the event logs. Object-centric process mining avoids these limitations by allowing events to be related to different cases. This study proposes a novel framework for anomaly detection in business processes that exploits graph neural networks and the enhanced information offered by object-centric process mining. We first reconstruct and represent the process dependencies of the object-centric event logs as attributed graphs and then employ a graph convolutional autoencoder architecture to detect anomalous events. Our results show that our approach provides promising performance in detecting anomalies at the activity type and attributes level, although it struggles to detect anomalies in the temporal order of events.\n    ",
        "primary_category": "q-fin.ST",
        "categories": [
            "cs.DB",
            "cs.LG"
        ],
        "submitted_date": "14 Feb 2024",
        "last_revised_date": " "
    },
    "2403.00777": {
        "title": "Combating Financial Crimes with Unsupervised Learning Techniques: Clustering and Dimensionality Reduction for Anti-Money Laundering",
        "authors": [
            "Ahmed N. Bakry",
            "Almohammady S. Alsharkawy",
            "Mohamed S. Farag",
            "Kamal R. Raslan"
        ],
        "comments": " ",
        "subjects": "Statistical Finance (q-fin.ST)",
        "abstract": "Anti-Money Laundering (AML) is a crucial task in ensuring the integrity of financial systems. One keychallenge in AML is identifying high-risk groups based on their behavior. Unsupervised learning, particularly clustering, is a promising solution for this task. However, the use of hundreds of features todescribe behavior results in a highdimensional dataset that negatively impacts clustering this http URL this paper, we investigate the effectiveness of combining clustering method agglomerative hierarchicalclustering with four dimensionality reduction techniques -Independent Component Analysis (ICA), andKernel Principal Component Analysis (KPCA), Singular Value Decomposition (SVD), Locality Preserving Projections (LPP)- to overcome the issue of high-dimensionality in AML data and improve clusteringresults. This study aims to provide insights into the most effective way of reducing the dimensionality ofAML data and enhance the accuracy of clustering-based AML systems. The experimental results demonstrate that KPCA outperforms other dimension reduction techniques when combined with agglomerativehierarchical clustering. This superiority is observed in the majority of situations, as confirmed by threedistinct validation indices.\n    ",
        "primary_category": "q-fin.ST",
        "categories": [
            "cs.LG"
        ],
        "submitted_date": "14 Feb 2024",
        "last_revised_date": " "
    },
    "2403.00780": {
        "title": "Empirical and Experimental Insights into Data Mining Techniques for Crime Prediction: A Comprehensive Survey",
        "authors": [
            "Kamal Taha"
        ],
        "comments": " ",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "This survey paper presents a comprehensive analysis of crime prediction methodologies, exploring the various techniques and technologies utilized in this area. The paper covers the statistical methods, machine learning algorithms, and deep learning techniques employed to analyze crime data, while also examining their effectiveness and limitations. We propose a methodological taxonomy that classifies crime prediction algorithms into specific techniques. This taxonomy is structured into four tiers, including methodology category, methodology sub-category, methodology techniques, and methodology sub-techniques. Empirical and experimental evaluations are provided to rank the different techniques. The empirical evaluation assesses the crime prediction techniques based on four criteria, while the experimental evaluation ranks the algorithms that employ the same sub-technique, the different sub-techniques that employ the same technique, the different techniques that employ the same methodology sub-category, the different methodology sub-categories within the same category, and the different methodology categories. The combination of methodological taxonomy, empirical evaluations, and experimental comparisons allows for a nuanced and comprehensive understanding of crime prediction algorithms, aiding researchers in making informed decisions. Finally, the paper provides a glimpse into the future of crime prediction techniques, highlighting potential advancements and opportunities for further research in this field\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "17 Feb 2024",
        "last_revised_date": " "
    },
    "2403.00782": {
        "title": "Ploutos: Towards interpretable stock movement prediction with financial large language model",
        "authors": [
            "Hanshuang Tong",
            "Jun Li",
            "Ning Wu",
            "Ming Gong",
            "Dongmei Zhang",
            "Qi Zhang"
        ],
        "comments": "8 pages, 4 figures",
        "subjects": "Statistical Finance (q-fin.ST)",
        "abstract": "Recent advancements in large language models (LLMs) have opened new pathways for many domains. However, the full potential of LLMs in financial investments remains largely untapped. There are two main challenges for typical deep learning-based methods for quantitative finance. First, they struggle to fuse textual and numerical information flexibly for stock movement prediction. Second, traditional methods lack clarity and interpretability, which impedes their application in scenarios where the justification for predictions is essential. To solve the above challenges, we propose Ploutos, a novel financial LLM framework that consists of PloutosGen and PloutosGPT. The PloutosGen contains multiple primary experts that can analyze different modal data, such as text and numbers, and provide quantitative strategies from different perspectives. Then PloutosGPT combines their insights and predictions and generates interpretable rationales. To generate accurate and faithful rationales, the training strategy of PloutosGPT leverage rearview-mirror prompting mechanism to guide GPT-4 to generate rationales, and a dynamic token weighting mechanism to finetune LLM by increasing key tokens weight. Extensive experiments show our framework outperforms the state-of-the-art methods on both prediction accuracy and interpretability.\n    ",
        "primary_category": "q-fin.ST",
        "categories": [
            "cs.AI",
            "cs.CL"
        ],
        "submitted_date": "18 Feb 2024",
        "last_revised_date": " "
    },
    "2403.00783": {
        "title": "On the Roles of LLMs in Planning: Embedding LLMs into Planning Graphs",
        "authors": [
            "Hankz Hankui Zhuo",
            "Xin Chen",
            "Rong Pan"
        ],
        "comments": " ",
        "subjects": "Artificial Intelligence (cs.AI)",
        "abstract": "Plan synthesis aims to generate a course of actions or policies to transit given initial states to goal states, provided domain models that could be designed by experts or learnt from training data or interactions with the world. Intrigued by the claims of emergent planning capabilities in large language models (LLMs), works have been proposed to investigate the planning effectiveness of LLMs, without considering any utilization of off-the-shelf planning techniques in LLMs. In this paper, we aim to further study the insight of the planning capability of LLMs by investigating the roles of LLMs in off-the-shelf planning frameworks. To do this, we investigate the effectiveness of embedding LLMs into one of the well-known planning frameworks, graph-based planning, proposing a novel LLMs-based planning framework with LLMs embedded in two levels of planning graphs, i.e., mutual constraints generation level and constraints solving level. We empirically exhibit the effectiveness of our proposed framework in various planning domains.\n    ",
        "primary_category": "cs.AI",
        "categories": [],
        "submitted_date": "18 Feb 2024",
        "last_revised_date": " "
    },
    "2403.00784": {
        "title": "Utilizing BERT for Information Retrieval: Survey, Applications, Resources, and Challenges",
        "authors": [
            "Jiajia Wang",
            "Jimmy X. Huang",
            "Xinhui Tu",
            "Junmei Wang",
            "Angela J. Huang",
            "Md Tahmid Rahman Laskar",
            "Amran Bhuiyan"
        ],
        "comments": " ",
        "subjects": "Information Retrieval (cs.IR)",
        "abstract": "Recent years have witnessed a substantial increase in the use of deep learning to solve various natural language processing (NLP) problems. Early deep learning models were constrained by their sequential or unidirectional nature, such that they struggled to capture the contextual relationships across text inputs. The introduction of bidirectional encoder representations from transformers (BERT) leads to a robust encoder for the transformer model that can understand the broader context and deliver state-of-the-art performance across various NLP tasks. This has inspired researchers and practitioners to apply BERT to practical problems, such as information retrieval (IR). A survey that focuses on a comprehensive analysis of prevalent approaches that apply pretrained transformer encoders like BERT to IR can thus be useful for academia and the industry. In light of this, we revisit a variety of BERT-based methods in this survey, cover a wide range of techniques of IR, and group them into six high-level categories: (i) handling long documents, (ii) integrating semantic information, (iii) balancing effectiveness and efficiency, (iv) predicting the weights of terms, (v) query expansion, and (vi) document expansion. We also provide links to resources, including datasets and toolkits, for BERT-based IR systems. A key highlight of our survey is the comparison between BERT's encoder-based models and the latest generative Large Language Models (LLMs), such as ChatGPT, which rely on decoders. Despite the popularity of LLMs, we find that for specific tasks, finely tuned BERT encoders still outperform, and at a lower deployment cost. Finally, we summarize the comprehensive outcomes of the survey and suggest directions for future research in the area.\n    ",
        "primary_category": "cs.IR",
        "categories": [
            "cs.AI",
            "cs.CL"
        ],
        "submitted_date": "18 Feb 2024",
        "last_revised_date": " "
    },
    "2403.00785": {
        "title": "Applying News and Media Sentiment Analysis for Generating Forex Trading Signals",
        "authors": [
            "Oluwafemi F Olaiyapo"
        ],
        "comments": " ",
        "subjects": "Statistical Finance (q-fin.ST)",
        "abstract": "The objective of this research is to examine how sentiment analysis can be employed to generate trading signals for the Foreign Exchange (Forex) market. The author assessed sentiment in social media posts and news articles pertaining to the United States Dollar (USD) using a combination of methods: lexicon-based analysis and the Naive Bayes machine learning algorithm. The findings indicate that sentiment analysis proves valuable in forecasting market movements and devising trading signals. Notably, its effectiveness is consistent across different market conditions. The author concludes that by analyzing sentiment expressed in news and social media, traders can glean insights into prevailing market sentiments towards the USD and other pertinent countries, thereby aiding trading decision-making. This study underscores the importance of weaving sentiment analysis into trading strategies as a pivotal tool for predicting market dynamics.\n    ",
        "primary_category": "q-fin.ST",
        "categories": [
            "cs.LG"
        ],
        "submitted_date": "19 Feb 2024",
        "last_revised_date": " "
    },
    "2403.00786": {
        "title": "Leveraging Contrastive Learning for Few-shot Geolocation of Social Posts",
        "authors": [
            "Menglin Li",
            "Kwan Hui Lim"
        ],
        "comments": "This paper contains 7-page main content and 2-page references and was submitted to IJCAI2024 for review",
        "subjects": "Information Retrieval (cs.IR)",
        "abstract": "Social geolocation is an important problem of predicting the originating locations of social media posts. However, this task is challenging due to the need for a substantial volume of training data, alongside well-annotated labels. These issues are further exacerbated by new or less popular locations with insufficient labels, further leading to an imbalanced dataset. In this paper, we propose \\textbf{ContrastGeo}, a \\textbf{Contrast}ive learning enhanced framework for few-shot social \\textbf{Geo}location. Specifically, a Tweet-Location Contrastive learning objective is introduced to align representations of tweets and locations within tweet-location pairs. To capture the correlations between tweets and locations, a Tweet-Location Matching objective is further adopted into the framework and refined via an online hard negative mining approach. We also develop three fusion strategies with various fusion encoders to better generate joint representations of tweets and locations. Comprehensive experiments on three social media datasets highlight ContrastGeo's superior performance over several state-of-the-art baselines in few-shot social geolocation.\n    ",
        "primary_category": "cs.IR",
        "categories": [
            "cs.SI"
        ],
        "submitted_date": "19 Feb 2024",
        "last_revised_date": " "
    },
    "2403.00787": {
        "title": "Reusable MLOps: Reusable Deployment, Reusable Infrastructure and Hot-Swappable Machine Learning models and services",
        "authors": [
            "D Panchal",
            "P Verma",
            "I Baran",
            "D Musgrove",
            "D Lu"
        ],
        "comments": " ",
        "subjects": "Software Engineering (cs.SE)",
        "abstract": "Although Machine Learning model building has become increasingly accessible due to a plethora of tools, libraries and algorithms being available freely, easy operationalization of these models is still a problem. It requires considerable expertise in data engineering, software development, cloud and DevOps. It also requires planning, agreement, and vision of how the model is going to be used by the business applications once it is in production, how it is going to be continuously trained on fresh incoming data, and how and when a newer model would replace an existing model. This leads to developers and data scientists working in silos and making suboptimal decisions. It also leads to wasted time and effort. We introduce the Acumos AI platform we developed and we demonstrate some unique novel capabilities that the Acumos model runner possesses, that can help solve the above problems. We introduce a new sustainable concept in the field of AI/ML operations - called Reusable MLOps - where we reuse the existing deployment and infrastructure to serve new models by hot-swapping them without tearing down the infrastructure or the microservice, thus achieving reusable deployment and operations for AI/ML models while still having continuously trained models in production.\n    ",
        "primary_category": "cs.SE",
        "categories": [
            "cs.CY"
        ],
        "submitted_date": "19 Feb 2024",
        "last_revised_date": " "
    },
    "2403.00788": {
        "title": "PRECISE Framework: GPT-based Text For Improved Readability, Reliability, and Understandability of Radiology Reports For Patient-Centered Care",
        "authors": [
            "Satvik Tripathi",
            "Liam Mutter",
            "Meghana Muppuri",
            "Suhani Dheer",
            "Emiliano Garza-Frias",
            "Komal Awan",
            "Aakash Jha",
            "Michael Dezube",
            "Azadeh Tabari",
            "Christopher P. Bridge",
            "Dania Daye"
        ],
        "comments": " ",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "This study introduces and evaluates the PRECISE framework, utilizing OpenAI's GPT-4 to enhance patient engagement by providing clearer and more accessible chest X-ray reports at a sixth-grade reading level. The framework was tested on 500 reports, demonstrating significant improvements in readability, reliability, and understandability. Statistical analyses confirmed the effectiveness of the PRECISE approach, highlighting its potential to foster patient-centric care delivery in healthcare decision-making.\n    ",
        "primary_category": "cs.CL",
        "categories": [
            "cs.AI",
            "cs.HC",
            "cs.LG"
        ],
        "submitted_date": "20 Feb 2024",
        "last_revised_date": " "
    },
    "2403.00790": {
        "title": "Structuring Concept Space with the Musical Circle of Fifths by Utilizing Music Grammar Based Activations",
        "authors": [
            "Tofara Moyo"
        ],
        "comments": "3 pages",
        "subjects": "Sound (cs.SD)",
        "abstract": "In this paper, we explore the intriguing similarities between the structure of a discrete neural network, such as a spiking network, and the composition of a piano piece. While both involve nodes or notes that are activated sequentially or in parallel, the latter benefits from the rich body of music theory to guide meaningful combinations. We propose a novel approach that leverages musical grammar to regulate activations in a spiking neural network, allowing for the representation of symbols as attractors. By applying rules for chord progressions from music theory, we demonstrate how certain activations naturally follow others, akin to the concept of attraction. Furthermore, we introduce the concept of modulating keys to navigate different basins of attraction within the network. Ultimately, we show that the map of concepts in our model is structured by the musical circle of fifths, highlighting the potential for leveraging music theory principles in deep learning algorithms.\n    ",
        "primary_category": "cs.SD",
        "categories": [
            "cs.AI",
            "eess.AS"
        ],
        "submitted_date": "22 Feb 2024",
        "last_revised_date": " "
    },
    "2403.00791": {
        "title": "$\\textit{L+M-24}$: Building a Dataset for Language + Molecules @ ACL 2024",
        "authors": [
            "Carl Edwards",
            "Qingyun Wang",
            "Lawrence Zhao",
            "Heng Ji"
        ],
        "comments": "The dataset, finetuned baselines, and evaluation code are released publicly at this https URL through this https URL",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "Language-molecule models have emerged as an exciting direction for molecular discovery and understanding. However, training these models is challenging due to the scarcity of molecule-language pair datasets. At this point, datasets have been released which are 1) small and scraped from existing databases, 2) large but noisy and constructed by performing entity linking on the scientific literature, and 3) built by converting property prediction datasets to natural language using templates. In this document, we detail the $\\textit{L+M-24}$ dataset, which has been created for the Language + Molecules Workshop shared task at ACL 2024. In particular, $\\textit{L+M-24}$ is designed to focus on three key benefits of natural language in molecule design: compositionality, functionality, and abstraction.\n    ",
        "primary_category": "cs.CL",
        "categories": [
            "cs.AI",
            "q-bio.BM",
            "q-bio.QM"
        ],
        "submitted_date": "22 Feb 2024",
        "last_revised_date": " "
    },
    "2403.00792": {
        "title": "Theory and Computation of Substructure Characteristic Modes",
        "authors": [
            "Mats Gustafsson",
            "Lukas Jelinek",
            "Miloslav Capek",
            "Johan Lundgren",
            "Kurt Schab"
        ],
        "comments": "9 pages, 8 figures",
        "subjects": "Computational Engineering, Finance, and Science (cs.CE)",
        "abstract": "The problem of substructure characteristic modes is reformulated using a scattering matrix-based formulation, generalizing subregion characteristic mode decomposition to arbitrary computational tools. It is shown that the scattering formulation is identical to the classical formulation based on the background Green's function for lossless systems. The scattering formulation, however, opens a variety of new subregion scenarios unavailable within previous formulations, including cases with lumped or wave ports or subregions in circuits. Thanks to its scattering nature, the formulation is solver-agnostic with the possibility to utilize an arbitrary full-wave method.\n    ",
        "primary_category": "cs.CE",
        "categories": [],
        "submitted_date": "22 Feb 2024",
        "last_revised_date": " "
    },
    "2403.00793": {
        "title": "Ad Recommendation in a Collapsed and Entangled World",
        "authors": [
            "Junwei Pan",
            "Wei Xue",
            "Ximei Wang",
            "Haibin Yu",
            "Xun Liu",
            "Shijie Quan",
            "Xueming Qiu",
            "Dapeng Liu",
            "Lei Xiao",
            "Jie Jiang"
        ],
        "comments": " ",
        "subjects": "Information Retrieval (cs.IR)",
        "abstract": "In this paper, we present an industry ad recommendation system, paying attention to the challenges and practices of learning appropriate representations. Our study begins by showcasing our approaches to preserving priors when encoding features of diverse types into embedding representations. Specifically, we address sequence features, numeric features, pre-trained embedding features, as well as sparse ID features. Moreover, we delve into two pivotal challenges associated with feature representation: the dimensional collapse of embeddings and the interest entanglement across various tasks or scenarios. Subsequently, we propose several practical approaches to effectively tackle these two challenges. We then explore several training techniques to facilitate model optimization, reduce bias, and enhance exploration. Furthermore, we introduce three analysis tools that enable us to comprehensively study feature correlation, dimensional collapse, and interest entanglement. This work builds upon the continuous efforts of Tencent's ads recommendation team in the last decade. It not only summarizes general design principles but also presents a series of off-the-shelf solutions and analysis tools. The reported performance is based on our online advertising platform, which handles hundreds of billions of requests daily, serving millions of ads to billions of users.\n    ",
        "primary_category": "cs.IR",
        "categories": [
            "cs.LG"
        ],
        "submitted_date": "22 Feb 2024",
        "last_revised_date": " "
    },
    "2403.00794": {
        "title": "Getting Serious about Humor: Crafting Humor Datasets with Unfunny Large Language Models",
        "authors": [
            "Zachary Horvitz",
            "Jingru Chen",
            "Rahul Aditya",
            "Harshvardhan Srivastava",
            "Robert West",
            "Zhou Yu",
            "Kathleen McKeown"
        ],
        "comments": " ",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "Humor is a fundamental facet of human cognition and interaction. Yet, despite recent advances in natural language processing, humor detection remains a challenging task that is complicated by the scarcity of datasets that pair humorous texts with similar non-humorous counterparts. In our work, we investigate whether large language models (LLMs), can generate synthetic data for humor detection via editing texts. We benchmark LLMs on an existing human dataset and show that current LLMs display an impressive ability to `unfun' jokes, as judged by humans and as measured on the downstream task of humor detection. We extend our approach to a code-mixed English-Hindi humor dataset, where we find that GPT-4's synthetic data is highly rated by bilingual annotators and provides challenging adversarial examples for humor classifiers.\n    ",
        "primary_category": "cs.CL",
        "categories": [
            "cs.AI",
            "cs.LG"
        ],
        "submitted_date": "23 Feb 2024",
        "last_revised_date": " "
    },
    "2403.00796": {
        "title": "Enhancing Mean-Reverting Time Series Prediction with Gaussian Processes: Functional and Augmented Data Structures in Financial Forecasting",
        "authors": [
            "Narayan Tondapu"
        ],
        "comments": " ",
        "subjects": "Statistical Finance (q-fin.ST)",
        "abstract": "In this paper, we explore the application of Gaussian Processes (GPs) for predicting mean-reverting time series with an underlying structure, using relatively unexplored functional and augmented data structures. While many conventional forecasting methods concentrate on the short-term dynamics of time series data, GPs offer the potential to forecast not just the average prediction but the entire probability distribution over a future trajectory. This is particularly beneficial in financial contexts, where accurate predictions alone may not suffice if incorrect volatility assessments lead to capital losses. Moreover, in trade selection, GPs allow for the forecasting of multiple Sharpe ratios adjusted for transaction costs, aiding in decision-making. The functional data representation utilized in this study enables longer-term predictions by leveraging information from previous years, even as the forecast moves away from the current year's training data. Additionally, the augmented representation enriches the training set by incorporating multiple targets for future points in time, facilitating long-term predictions. Our implementation closely aligns with the methodology outlined in, which assessed effectiveness on commodity futures. However, our testing methodology differs. Instead of real data, we employ simulated data with similar characteristics. We construct a testing environment to evaluate both data representations and models under conditions of increasing noise, fat tails, and inappropriate kernels-conditions commonly encountered in practice. By simulating data, we can compare our forecast distribution over time against a full simulation of the actual distribution of our test set, thereby reducing the inherent uncertainty in testing time series models on real data. We enable feature prediction through augmentation and employ sub-sampling to ensure the feasibility of GPs.\n    ",
        "primary_category": "q-fin.ST",
        "categories": [
            "cs.AI",
            "cs.LG",
            "stat.ML"
        ],
        "submitted_date": "23 Feb 2024",
        "last_revised_date": " "
    },
    "2403.00798": {
        "title": "Helen: Optimizing CTR Prediction Models with Frequency-wise Hessian Eigenvalue Regularization",
        "authors": [
            "Zirui Zhu",
            "Yong Liu",
            "Zangwei Zheng",
            "Huifeng Guo",
            "Yang You"
        ],
        "comments": "Proceedings of the ACM Web Conference 2024 (WWW '24)",
        "subjects": "Information Retrieval (cs.IR)",
        "abstract": "Click-Through Rate (CTR) prediction holds paramount significance in online advertising and recommendation scenarios. Despite the proliferation of recent CTR prediction models, the improvements in performance have remained limited, as evidenced by open-source benchmark assessments. Current researchers tend to focus on developing new models for various datasets and settings, often neglecting a crucial question: What is the key challenge that truly makes CTR prediction so demanding?\nIn this paper, we approach the problem of CTR prediction from an optimization perspective. We explore the typical data characteristics and optimization statistics of CTR prediction, revealing a strong positive correlation between the top hessian eigenvalue and feature frequency. This correlation implies that frequently occurring features tend to converge towards sharp local minima, ultimately leading to suboptimal performance. Motivated by the recent advancements in sharpness-aware minimization (SAM), which considers the geometric aspects of the loss landscape during optimization, we present a dedicated optimizer crafted for CTR prediction, named Helen. Helen incorporates frequency-wise Hessian eigenvalue regularization, achieved through adaptive perturbations based on normalized feature frequencies.\nEmpirical results under the open-source benchmark framework underscore Helen's effectiveness. It successfully constrains the top eigenvalue of the Hessian matrix and demonstrates a clear advantage over widely used optimization algorithms when applied to seven popular models across three public benchmark datasets on BARS. Our code locates at this http URL.\n    ",
        "primary_category": "cs.IR",
        "categories": [
            "cs.LG"
        ],
        "submitted_date": "23 Feb 2024",
        "last_revised_date": " "
    },
    "2403.00799": {
        "title": "An Empirical Study of Data Ability Boundary in LLMs' Math Reasoning",
        "authors": [
            "Zui Chen",
            "Yezeng Chen",
            "Jiaqi Han",
            "Zhijie Huang",
            "Ji Qi",
            "Yi Zhou"
        ],
        "comments": "33 pages, 5 figures",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "Large language models (LLMs) are displaying emergent abilities for math reasoning tasks,and there is a growing attention on enhancing the ability of open-source LLMs through supervised fine-tuning (SFT).In this paper, we aim to explore a general data strategy for supervised data to help optimize and expand math reasoning ability.Firstly, we determine the ability boundary of reasoning paths augmentation by identifying these paths' minimal optimal set.Secondly, we validate that different abilities of the model can be cumulatively enhanced by Mix of Minimal Optimal Sets of corresponding types of data, while our models MMOS achieve SOTA performance on series base models under much lower construction costs.Besides, we point out GSM-HARD is not really hard and today's LLMs no longer lack numerical robustness.Also, we provide an Auto Problem Generator for robustness testing and educational applications.Our code and data are publicly available at this https URL.\n    ",
        "primary_category": "cs.CL",
        "categories": [
            "cs.AI",
            "cs.LG"
        ],
        "submitted_date": "23 Feb 2024",
        "last_revised_date": " "
    },
    "2403.00800": {
        "title": "Brain-Inspired Two-Stage Approach: Enhancing Mathematical Reasoning by Imitating Human Thought Processes",
        "authors": [
            "Yezeng Chen",
            "Zui Chen",
            "Yi Zhou"
        ],
        "comments": "12 pages, 5 figures",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "Although large language models demonstrate emergent abilities in solving math word problems, there is a challenging task in complex multi-step mathematical reasoning tasks. To improve model performance on mathematical reasoning tasks, previous work has conducted supervised fine-tuning on open-source models by improving the quality and quantity of data. In this paper, we propose a novel approach, named Brain, to imitate human thought processes to enhance mathematical reasoning abilities, using the Frontal Lobe Model to generate plans, and then employing the Parietal Lobe Model to generate code and execute to obtain answers. First, we achieve SOTA performance in comparison with Code LLaMA 7B based models through this method. Secondly, we find that plans can be explicitly extracted from natural language, code, or formal language. Our code and data are publicly available at this https URL.\n    ",
        "primary_category": "cs.CL",
        "categories": [
            "cs.AI",
            "cs.LG"
        ],
        "submitted_date": "23 Feb 2024",
        "last_revised_date": " "
    },
    "2403.00802": {
        "title": "Towards a Theoretical Understanding of Two-Stage Recommender Systems",
        "authors": [
            "Amit Kumar Jaiswal"
        ],
        "comments": "18 pages (including references and appendix), 1 figure, 2 tables",
        "subjects": "Information Retrieval (cs.IR)",
        "abstract": "Production-grade recommender systems rely heavily on a large-scale corpus used by online media services, including Netflix, Pinterest, and Amazon. These systems enrich recommendations by learning users' and items' embeddings projected in a low-dimensional space with two-stage models (two deep neural networks), which facilitate their embedding constructs to predict users' feedback associated with items. Despite its popularity for recommendations, its theoretical behaviors remain comprehensively unexplored. We study the asymptotic behaviors of the two-stage recommender that entail a strong convergence to the optimal recommender system. We establish certain theoretical properties and statistical assurance of the two-stage recommender. In addition to asymptotic behaviors, we demonstrate that the two-stage recommender system attains faster convergence by relying on the intrinsic dimensions of the input features. Finally, we show numerically that the two-stage recommender enables encapsulating the impacts of items' and users' attributes on ratings, resulting in better performance compared to existing methods conducted using synthetic and real-world data experiments.\n    ",
        "primary_category": "cs.IR",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "23 Feb 2024",
        "last_revised_date": " "
    },
    "2403.00803": {
        "title": "LiMAML: Personalization of Deep Recommender Models via Meta Learning",
        "authors": [
            "Ruofan Wang",
            "Prakruthi Prabhakar",
            "Gaurav Srivastava",
            "Tianqi Wang",
            "Zeinab S. Jalali",
            "Varun Bharill",
            "Yunbo Ouyang",
            "Aastha Nigam",
            "Divya Venugopalan",
            "Aman Gupta",
            "Fedor Borisyuk",
            "Sathiya Keerthi",
            "Ajith Muralidharan"
        ],
        "comments": " ",
        "subjects": "Information Retrieval (cs.IR)",
        "abstract": "In the realm of recommender systems, the ubiquitous adoption of deep neural networks has emerged as a dominant paradigm for modeling diverse business objectives. As user bases continue to expand, the necessity of personalization and frequent model updates have assumed paramount significance to ensure the delivery of relevant and refreshed experiences to a diverse array of members. In this work, we introduce an innovative meta-learning solution tailored to the personalization of models for individual members and other entities, coupled with the frequent updates based on the latest user interaction signals. Specifically, we leverage the Model-Agnostic Meta Learning (MAML) algorithm to adapt per-task sub-networks using recent user interaction data. Given the near infeasibility of productionizing original MAML-based models in online recommendation systems, we propose an efficient strategy to operationalize meta-learned sub-networks in production, which involves transforming them into fixed-sized vectors, termed meta embeddings, thereby enabling the seamless deployment of models with hundreds of billions of parameters for online serving. Through extensive experimentation on production data drawn from various applications at LinkedIn, we demonstrate that the proposed solution consistently outperforms the baseline models of those applications, including strong baselines such as using wide-and-deep ID based personalization approach. Our approach has enabled the deployment of a range of highly personalized AI models across diverse LinkedIn applications, leading to substantial improvements in business metrics as well as refreshed experience for our members.\n    ",
        "primary_category": "cs.IR",
        "categories": [
            "cs.AI",
            "cs.LG"
        ],
        "submitted_date": "23 Feb 2024",
        "last_revised_date": " "
    },
    "2403.00804": {
        "title": "Uncovering Customer Issues through Topological Natural Language Analysis",
        "authors": [
            "Shu-Ting Pi",
            "Sidarth Srinivasan",
            "Yuying Zhu",
            "Michael Yang",
            "Qun Liu"
        ],
        "comments": "Accepted in KDD 2023 Workshop on Decision Intelligence and Analytics for Online Marketplaces",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "E-commerce companies deal with a high volume of customer service requests daily. While a simple annotation system is often used to summarize the topics of customer contacts, thoroughly exploring each specific issue can be challenging. This presents a critical concern, especially during an emerging outbreak where companies must quickly identify and address specific issues. To tackle this challenge, we propose a novel machine learning algorithm that leverages natural language techniques and topological data analysis to monitor emerging and trending customer issues. Our approach involves an end-to-end deep learning framework that simultaneously tags the primary question sentence of each customer's transcript and generates sentence embedding vectors. We then whiten the embedding vectors and use them to construct an undirected graph. From there, we define trending and emerging issues based on the topological properties of each transcript. We have validated our results through various methods and found that they are highly consistent with news sources.\n    ",
        "primary_category": "cs.CL",
        "categories": [
            "cs.AI",
            "cs.LG"
        ],
        "submitted_date": "24 Feb 2024",
        "last_revised_date": " "
    },
    "2403.00805": {
        "title": "A New Dynamic Distributed Planning Approach: Application to DPDP Problems",
        "authors": [
            "Zakaria Tolba"
        ],
        "comments": "Master's thesis, in French language",
        "subjects": "Artificial Intelligence (cs.AI)",
        "abstract": "In this work, we proposed a new dynamic distributed planning approach that is able to take into account the changes that the agent introduces on his set of actions to be planned in order to take into account the changes that occur in his environment. Our approach fits into the context of distributed planning for distributed plans where each agent can produce its own plans. According to our approach the generation of the plans is based on the satisfaction of the constraints by the use of the genetic algorithms. Our approach is to generate, a new plan by each agent, whenever there is a change in its set of actions to plan. This in order to take into account the new actions introduced in its new plan. In this new plan, the agent takes, each time, as a new action set to plan all the old un-executed actions of the old plan and the new actions engendered by the changes and as a new initial state; the state in which the set of actions of the agent undergoes a change. In our work, we used a concrete case to illustrate and demonstrate the utility of our approach.\n    ",
        "primary_category": "cs.AI",
        "categories": [
            "cs.MA"
        ],
        "submitted_date": "24 Feb 2024",
        "last_revised_date": " "
    },
    "2403.00806": {
        "title": "Enhanced User Interaction in Operating Systems through Machine Learning Language Models",
        "authors": [
            "Chenwei Zhang",
            "Wenran Lu",
            "Chunhe Ni",
            "Hongbo Wang",
            "Jiang Wu"
        ],
        "comments": " ",
        "subjects": "Information Retrieval (cs.IR)",
        "abstract": "With the large language model showing human-like logical reasoning and understanding ability, whether agents based on the large language model can simulate the interaction behavior of real users, so as to build a reliable virtual recommendation A/B test scene to help the application of recommendation research is an urgent, important and economic value problem. The combination of interaction design and machine learning can provide a more efficient and personalized user experience for products and services. This personalized service can meet the specific needs of users and improve user satisfaction and loyalty. Second, the interactive system can understand the user's views and needs for the product by providing a good user interface and interactive experience, and then use machine learning algorithms to improve and optimize the product. This iterative optimization process can continuously improve the quality and performance of the product to meet the changing needs of users. At the same time, designers need to consider how these algorithms and tools can be combined with interactive systems to provide a good user experience. This paper explores the potential applications of large language models, machine learning and interaction design for user interaction in recommendation systems and operating systems. By integrating these technologies, more intelligent and personalized services can be provided to meet user needs and promote continuous improvement and optimization of products. This is of great value for both recommendation research and user experience applications.\n    ",
        "primary_category": "cs.IR",
        "categories": [
            "cs.CE",
            "cs.CL",
            "cs.CV"
        ],
        "submitted_date": "24 Feb 2024",
        "last_revised_date": " "
    },
    "2403.00807": {
        "title": "Enhancing Cloud-Based Large Language Model Processing with Elasticsearch and Transformer Models",
        "authors": [
            "Chunhe Ni",
            "Jiang Wu",
            "Hongbo Wang",
            "Wenran Lu",
            "Chenwei Zhang"
        ],
        "comments": " ",
        "subjects": "Information Retrieval (cs.IR)",
        "abstract": "Large Language Models (LLMs) are a class of generative AI models built using the Transformer network, capable of leveraging vast datasets to identify, summarize, translate, predict, and generate language. LLMs promise to revolutionize society, yet training these foundational models poses immense challenges. Semantic vector search within large language models is a potent technique that can significantly enhance search result accuracy and relevance. Unlike traditional keyword-based search methods, semantic search utilizes the meaning and context of words to grasp the intent behind queries and deliver more precise outcomes. Elasticsearch emerges as one of the most popular tools for implementing semantic search an exceptionally scalable and robust search engine designed for indexing and searching extensive datasets. In this article, we delve into the fundamentals of semantic search and explore how to harness Elasticsearch and Transformer models to bolster large language model processing paradigms. We gain a comprehensive understanding of semantic search principles and acquire practical skills for implementing semantic search in real-world model application scenarios.\n    ",
        "primary_category": "cs.IR",
        "categories": [
            "cs.CL",
            "cs.DC",
            "cs.DL"
        ],
        "submitted_date": "24 Feb 2024",
        "last_revised_date": " "
    },
    "2403.00808": {
        "title": "IPED: An Implicit Perspective for Relational Triple Extraction based on Diffusion Model",
        "authors": [
            "Jianli Zhao",
            "Changhao Xu",
            "Bin Jiang"
        ],
        "comments": "12 pages, 4 figures, committed to NAACL 2024",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "Relational triple extraction is a fundamental task in the field of information extraction, and a promising framework based on table filling has recently gained attention as a potential baseline for entity relation extraction. However, inherent shortcomings such as redundant information and incomplete triple recognition remain problematic. To address these challenges, we propose an Implicit Perspective for relational triple Extraction based on Diffusion model (IPED), an innovative approach for extracting relational triples. Our classifier-free solution adopts an implicit strategy using block coverage to complete the tables, avoiding the limitations of explicit tagging methods. Additionally, we introduce a generative model structure, the block-denoising diffusion model, to collaborate with our implicit perspective and effectively circumvent redundant information disruptions. Experimental results on two popular datasets demonstrate that IPED achieves state-of-the-art performance while gaining superior inference speed and low computational complexity. To support future research, we have made our source code publicly available online.\n    ",
        "primary_category": "cs.CL",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "24 Feb 2024",
        "last_revised_date": " "
    },
    "2403.00809": {
        "title": "Abdelhak at SemEval-2024 Task 9 : Decoding Brainteasers, The Efficacy of Dedicated Models Versus ChatGPT",
        "authors": [
            "Abdelhak Kelious",
            "Mounir Okirim"
        ],
        "comments": " ",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "This study introduces a dedicated model aimed at solving the BRAINTEASER task 9 , a novel challenge designed to assess models lateral thinking capabilities through sentence and word puzzles. Our model demonstrates remarkable efficacy, securing Rank 1 in sentence puzzle solving during the test phase with an overall score of 0.98. Additionally, we explore the comparative performance of ChatGPT, specifically analyzing how variations in temperature settings affect its ability to engage in lateral thinking and problem-solving. Our findings indicate a notable performance disparity between the dedicated model and ChatGPT, underscoring the potential of specialized approaches in enhancing creative reasoning in AI.\n    ",
        "primary_category": "cs.CL",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "24 Feb 2024",
        "last_revised_date": " "
    },
    "2403.00810": {
        "title": "Bootstrapping Cognitive Agents with a Large Language Model",
        "authors": [
            "Feiyu Zhu",
            "Reid Simmons"
        ],
        "comments": " ",
        "subjects": "Artificial Intelligence (cs.AI)",
        "abstract": "Large language models contain noisy general knowledge of the world, yet are hard to train or fine-tune. On the other hand cognitive architectures have excellent interpretability and are flexible to update but require a lot of manual work to instantiate. In this work, we combine the best of both worlds: bootstrapping a cognitive-based model with the noisy knowledge encoded in large language models. Through an embodied agent doing kitchen tasks, we show that our proposed framework yields better efficiency compared to an agent based entirely on large language models. Our experiments indicate that large language models are a good source of information for cognitive architectures, and the cognitive architecture in turn can verify and update the knowledge of large language models to a specific domain.\n    ",
        "primary_category": "cs.AI",
        "categories": [
            "cs.CL"
        ],
        "submitted_date": "25 Feb 2024",
        "last_revised_date": " "
    },
    "2403.00811": {
        "title": "Cognitive Bias in High-Stakes Decision-Making with LLMs",
        "authors": [
            "Jessica Echterhoff",
            "Yao Liu",
            "Abeer Alessa",
            "Julian McAuley",
            "Zexue He"
        ],
        "comments": " ",
        "subjects": "Artificial Intelligence (cs.AI)",
        "abstract": "Large language models (LLMs) offer significant potential as tools to support an expanding range of decision-making tasks. However, given their training on human (created) data, LLMs can inherit both societal biases against protected groups, as well as be subject to cognitive bias. Such human-like bias can impede fair and explainable decisions made with LLM assistance. Our work introduces BiasBuster, a framework designed to uncover, evaluate, and mitigate cognitive bias in LLMs, particularly in high-stakes decision-making tasks. Inspired by prior research in psychology and cognitive sciences, we develop a dataset containing 16,800 prompts to evaluate different cognitive biases (e.g., prompt-induced, sequential, inherent). We test various bias mitigation strategies, amidst proposing a novel method using LLMs to debias their own prompts. Our analysis provides a comprehensive picture on the presence and effects of cognitive bias across different commercial and open-source models. We demonstrate that our self-help debiasing effectively mitigate cognitive bias without having to manually craft examples for each bias type.\n    ",
        "primary_category": "cs.AI",
        "categories": [
            "cs.CL"
        ],
        "submitted_date": "25 Feb 2024",
        "last_revised_date": " "
    },
    "2403.00812": {
        "title": "LoRA Meets Dropout under a Unified Framework",
        "authors": [
            "Sheng Wang",
            "Liheng Chen",
            "Jiyue Jiang",
            "Boyang Xue",
            "Lingpeng Kong",
            "Chuan Wu"
        ],
        "comments": " ",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "With the remarkable capabilities, large language models (LLMs) have emerged as essential elements in numerous NLP applications, while parameter-efficient finetuning, especially LoRA, has gained popularity as a lightweight approach for model customization. Meanwhile, various dropout methods, initially designed for full finetuning with all the parameters updated, alleviates overfitting associated with excessive parameter redundancy. Hence, a possible contradiction arises from negligible trainable parameters of LoRA and the effectiveness of previous dropout methods, which has been largely overlooked. To fill this gap, we first confirm that parameter-efficient LoRA is also overfitting-prone. We then revisit transformer-specific dropout methods, and establish their equivalence and distinctions mathematically and empirically. Building upon this comparative analysis, we introduce a unified framework for a comprehensive investigation, which instantiates these methods based on dropping position, structural pattern and compensation measure. Through this framework, we reveal the new preferences and performance comparisons of them when involved with limited trainable parameters. This framework also allows us to amalgamate the most favorable aspects into a novel dropout method named HiddenKey. Extensive experiments verify the remarkable superiority and sufficiency of HiddenKey across multiple models and tasks, which highlights it as the preferred approach for high-performance and parameter-efficient finetuning of LLMs.\n    ",
        "primary_category": "cs.CL",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "25 Feb 2024",
        "last_revised_date": " "
    },
    "2403.00814": {
        "title": "Gender Biased Legal Case Retrieval System on Users' Decision Process",
        "authors": [
            "Ruizhe Zhang",
            "Qingyao Ai",
            "Yiqun Liu",
            "Yueyue Wu",
            "Beining Wang"
        ],
        "comments": "10pages, in Chinese language. Accepted by CCIR 2023",
        "subjects": "Information Retrieval (cs.IR)",
        "abstract": "In the last decade, legal case search has become an important part of a legal practitioner's work. During legal case search, search engines retrieval a number of relevant cases from huge amounts of data and serve them to users. However, it is uncertain whether these cases are gender-biased and whether such bias has impact on user perceptions. We designed a new user experiment framework to simulate the judges' reading of relevant cases. 72 participants with backgrounds in legal affairs invited to conduct the experiment. Participants were asked to simulate the role of the judge in conducting a legal case search on 3 assigned cases and determine the sentences of the defendants in these cases. Gender of the defendants in both the task and relevant cases was edited to statistically measure the effect of gender bias in the legal case search results on participants' perceptions. The results showed that gender bias in the legal case search results did not have a significant effect on judges' perceptions.\n    ",
        "primary_category": "cs.IR",
        "categories": [
            "cs.CY",
            "cs.HC"
        ],
        "submitted_date": "25 Feb 2024",
        "last_revised_date": " "
    },
    "2403.00815": {
        "title": "RAM-EHR: Retrieval Augmentation Meets Clinical Predictions on Electronic Health Records",
        "authors": [
            "Ran Xu",
            "Wenqi Shi",
            "Yue Yu",
            "Yuchen Zhuang",
            "Bowen Jin",
            "May D. Wang",
            "Joyce C. Ho",
            "Carl Yang"
        ],
        "comments": " ",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "We present RAM-EHR, a Retrieval AugMentation pipeline to improve clinical predictions on Electronic Health Records (EHRs). RAM-EHR first collects multiple knowledge sources, converts them into text format, and uses dense retrieval to obtain information related to medical concepts. This strategy addresses the difficulties associated with complex names for the concepts. RAM-EHR then augments the local EHR predictive model co-trained with consistency regularization to capture complementary information from patient visits and summarized knowledge. Experiments on two EHR datasets show the efficacy of RAM-EHR over previous knowledge-enhanced baselines (3.4% gain in AUROC and 7.2% gain in AUPR), emphasizing the effectiveness of the summarized knowledge from RAM-EHR for clinical prediction tasks. The code will be published at \\url{this https URL}.\n    ",
        "primary_category": "cs.CL",
        "categories": [
            "cs.AI",
            "cs.IR",
            "q-bio.OT"
        ],
        "submitted_date": "25 Feb 2024",
        "last_revised_date": " "
    },
    "2403.00816": {
        "title": "CFRet-DVQA: Coarse-to-Fine Retrieval and Efficient Tuning for Document Visual Question Answering",
        "authors": [
            "Jinxu Zhang",
            "Yongqi Yu",
            "Yu Zhang"
        ],
        "comments": " ",
        "subjects": "Information Retrieval (cs.IR)",
        "abstract": "Document Visual Question Answering (DVQA) is a task that involves responding to queries based on the content of images. Existing work is limited to locating information within a single page and does not facilitate cross-page question-and-answer interaction. Furthermore, the token length limitation imposed on inputs to the model may lead to truncation of segments pertinent to the answer. In this study, we introduce a simple but effective methodology called CFRet-DVQA, which focuses on retrieval and efficient tuning to address this critical issue effectively. For that, we initially retrieve multiple segments from the document that correlate with the question at hand. Subsequently, we leverage the advanced reasoning abilities of the large language model (LLM), further augmenting its performance through instruction tuning. This approach enables the generation of answers that align with the style of the document labels. The experiments demonstrate that our methodology achieved state-of-the-art or competitive results with both single-page and multi-page documents in various fields.\n    ",
        "primary_category": "cs.IR",
        "categories": [
            "cs.AI",
            "cs.CV"
        ],
        "submitted_date": "26 Feb 2024",
        "last_revised_date": " "
    },
    "2403.00817": {
        "title": "Doubly Calibrated Estimator for Recommendation on Data Missing Not At Random",
        "authors": [
            "Wonbin Kweon",
            "Hwanjo Yu"
        ],
        "comments": "WWW 2024",
        "subjects": "Information Retrieval (cs.IR)",
        "abstract": "Recommender systems often suffer from selection bias as users tend to rate their preferred items. The datasets collected under such conditions exhibit entries missing not at random and thus are not randomized-controlled trials representing the target population. To address this challenge, a doubly robust estimator and its enhanced variants have been proposed as they ensure unbiasedness when accurate imputed errors or predicted propensities are provided. However, we argue that existing estimators rely on miscalibrated imputed errors and propensity scores as they depend on rudimentary models for estimation. We provide theoretical insights into how miscalibrated imputation and propensity models may limit the effectiveness of doubly robust estimators and validate our theorems using real-world datasets. On this basis, we propose a Doubly Calibrated Estimator that involves the calibration of both the imputation and propensity models. To achieve this, we introduce calibration experts that consider different logit distributions across users. Moreover, we devise a tri-level joint learning framework, allowing the simultaneous optimization of calibration experts alongside prediction and imputation models. Through extensive experiments on real-world datasets, we demonstrate the superiority of the Doubly Calibrated Estimator in the context of debiased recommendation tasks.\n    ",
        "primary_category": "cs.IR",
        "categories": [
            "cs.LG"
        ],
        "submitted_date": "26 Feb 2024",
        "last_revised_date": " "
    },
    "2403.00820": {
        "title": "Retrieval Augmented Generation Systems: Automatic Dataset Creation, Evaluation and Boolean Agent Setup",
        "authors": [
            "Tristan Kenneweg",
            "Philip Kenneweg",
            "Barbara Hammer"
        ],
        "comments": "Was handed in to IJCNN prior to preprint publication here. Was neither accepted nor rejected at date of publication here",
        "subjects": "Information Retrieval (cs.IR)",
        "abstract": "Retrieval Augmented Generation (RAG) systems have seen huge popularity in augmenting Large-Language Model (LLM) outputs with domain specific and time sensitive data. Very recently a shift is happening from simple RAG setups that query a vector database for additional information with every user input to more sophisticated forms of RAG. However, different concrete approaches compete on mostly anecdotal evidence at the moment. In this paper we present a rigorous dataset creation and evaluation workflow to quantitatively compare different RAG strategies. We use a dataset created this way for the development and evaluation of a boolean agent RAG setup: A system in which a LLM can decide whether to query a vector database or not, thus saving tokens on questions that can be answered with internal knowledge. We publish our code and generated dataset online.\n    ",
        "primary_category": "cs.IR",
        "categories": [
            "cs.CL"
        ],
        "submitted_date": "26 Feb 2024",
        "last_revised_date": " "
    },
    "2403.00821": {
        "title": "Social Media as a Sensor: Analyzing Twitter Data for Breast Cancer Medication Effects Using Natural Language Processing",
        "authors": [
            "Seibi Kobara",
            "Alireza Rafiei",
            "Masoud Nateghi",
            "Selen Bozkurt",
            "Rishikesan Kamaleswaran",
            "Abeed Sarker"
        ],
        "comments": " ",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "Breast cancer is a significant public health concern and is the leading cause of cancer-related deaths among women. Despite advances in breast cancer treatments, medication non-adherence remains a major problem. As electronic health records do not typically capture patient-reported outcomes that may reveal information about medication-related experiences, social media presents an attractive resource for enhancing our understanding of the patients' treatment experiences. In this paper, we developed natural language processing (NLP) based methodologies to study information posted by an automatically curated breast cancer cohort from social media. We employed a transformer-based classifier to identify breast cancer patients/survivors on X (Twitter) based on their self-reported information, and we collected longitudinal data from their profiles. We then designed a multi-layer rule-based model to develop a breast cancer therapy-associated side effect lexicon and detect patterns of medication usage and associated side effects among breast cancer patients. 1,454,637 posts were available from 583,962 unique users, of which 62,042 were detected as breast cancer members using our transformer-based model. 198 cohort members mentioned breast cancer medications with tamoxifen as the most common. Our side effect lexicon identified well-known side effects of hormone and chemotherapy. Furthermore, it discovered a subject feeling towards cancer and medications, which may suggest a pre-clinical phase of side effects or emotional distress. This analysis highlighted not only the utility of NLP techniques in unstructured social media data to identify self-reported breast cancer posts, medication usage patterns, and treatment side effects but also the richness of social data on such clinical questions.\n    ",
        "primary_category": "cs.CL",
        "categories": [
            "cs.LG",
            "cs.SI"
        ],
        "submitted_date": "26 Feb 2024",
        "last_revised_date": " "
    },
    "2403.00822": {
        "title": "InteraRec: Interactive Recommendations Using Multimodal Large Language Models",
        "authors": [
            "Saketh Reddy Karra",
            "Theja Tulabandhula"
        ],
        "comments": " ",
        "subjects": "Information Retrieval (cs.IR)",
        "abstract": "Weblogs, comprised of records detailing user activities on any website, offer valuable insights into user preferences, behavior, and interests. Numerous recommendation algorithms, employing strategies such as collaborative filtering, content-based filtering, and hybrid methods, leverage the data mined through these weblogs to provide personalized recommendations to users. Despite the abundance of information available in these weblogs, identifying and extracting pertinent information and key features necessitates extensive engineering endeavors. The intricate nature of the data also poses a challenge for interpretation, especially for non-experts. In this study, we introduce a sophisticated and interactive recommendation framework denoted as InteraRec, which diverges from conventional approaches that exclusively depend on weblogs for recommendation generation. This framework captures high-frequency screenshots of web pages as users navigate through a website. Leveraging state-of-the-art multimodal large language models (MLLMs), it extracts valuable insights into user preferences from these screenshots by generating a user behavioral summary based on predefined keywords. Subsequently, this summary is utilized as input to an LLM-integrated optimization setup to generate tailored recommendations. Through our experiments, we demonstrate the effectiveness of InteraRec in providing users with valuable and personalized offerings.\n    ",
        "primary_category": "cs.IR",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "26 Feb 2024",
        "last_revised_date": " "
    },
    "2403.00823": {
        "title": "Adapting to Teammates in a Cooperative Language Game",
        "authors": [
            "Christopher Archibald",
            "Spencer Brosnahan"
        ],
        "comments": " ",
        "subjects": "Artificial Intelligence (cs.AI)",
        "abstract": "The game of Codenames has recently emerged as a domain of interest for intelligent agent design. The game is unique due to the way that language and coordination between teammates play important roles. Previous approaches to designing agents for this game have utilized a single internal language model to determine action choices. This often leads to good performance with some teammates and inferior performance with other teammates, as the agent cannot adapt to any specific teammate. In this paper we present the first adaptive agent for playing Codenames. We adopt an ensemble approach with the goal of determining, during the course of interacting with a specific teammate, which of our internal expert agents, each potentially with its own language model, is the best match. One difficulty faced in this approach is the lack of a single numerical metric that accurately captures the performance of a Codenames team. Prior Codenames research has utilized a handful of different metrics to evaluate agent teams. We propose a novel single metric to evaluate the performance of a Codenames team, whether playing a single team (solitaire) game, or a competitive game against another team. We then present and analyze an ensemble agent which selects an internal expert on each turn in order to maximize this proposed metric. Experimental analysis shows that this ensemble approach adapts to individual teammates and often performs nearly as well as the best internal expert with a teammate. Crucially, this success does not depend on any previous knowledge about the teammates, the ensemble agents, or their compatibility. This research represents an important step to making language-based agents for cooperative language settings like Codenames more adaptable to individual teammates.\n    ",
        "primary_category": "cs.AI",
        "categories": [
            "cs.CL"
        ],
        "submitted_date": "26 Feb 2024",
        "last_revised_date": " "
    },
    "2403.00825": {
        "title": "Comparing effectiveness of regularization methods on text classification: Simple and complex model in data shortage situation",
        "authors": [
            "Jongga Lee",
            "Jaeseung Yim",
            "Seohee Park",
            "Changwon Lim"
        ],
        "comments": "13 pages, 2 figures",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "Text classification is the task of assigning a document to a predefined class. However, it is expensive to acquire enough labeled documents or to label them. In this paper, we study the regularization methods' effects on various classification models when only a few labeled data are available. We compare a simple word embedding-based model, which is simple but effective, with complex models (CNN and BiLSTM). In supervised learning, adversarial training can further regularize the model. When an unlabeled dataset is available, we can regularize the model using semi-supervised learning methods such as the Pi model and virtual adversarial training. We evaluate the regularization effects on four text classification datasets (AG news, DBpedia, Yahoo! Answers, Yelp Polarity), using only 0.1% to 0.5% of the original labeled training documents. The simple model performs relatively well in fully supervised learning, but with the help of adversarial training and semi-supervised learning, both simple and complex models can be regularized, showing better results for complex models. Although the simple model is robust to overfitting, a complex model with well-designed prior beliefs can be also robust to overfitting.\n    ",
        "primary_category": "cs.CL",
        "categories": [],
        "submitted_date": "27 Feb 2024",
        "last_revised_date": " "
    },
    "2403.00826": {
        "title": "LLMGuard: Guarding Against Unsafe LLM Behavior",
        "authors": [
            "Shubh Goyal",
            "Medha Hira",
            "Shubham Mishra",
            "Sukriti Goyal",
            "Arnav Goel",
            "Niharika Dadu",
            "Kirushikesh DB",
            "Sameep Mehta",
            "Nishtha Madaan"
        ],
        "comments": "accepted in demonstration track of AAAI-24",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "Although the rise of Large Language Models (LLMs) in enterprise settings brings new opportunities and capabilities, it also brings challenges, such as the risk of generating inappropriate, biased, or misleading content that violates regulations and can have legal concerns. To alleviate this, we present \"LLMGuard\", a tool that monitors user interactions with an LLM application and flags content against specific behaviours or conversation topics. To do this robustly, LLMGuard employs an ensemble of detectors.\n    ",
        "primary_category": "cs.CL",
        "categories": [
            "cs.CR",
            "cs.LG"
        ],
        "submitted_date": "27 Feb 2024",
        "last_revised_date": " "
    },
    "2403.00827": {
        "title": "Self-Refinement of Language Models from External Proxy Metrics Feedback",
        "authors": [
            "Keshav Ramji",
            "Young-Suk Lee",
            "Ram\u00f3n Fernandez Astudillo",
            "Md Arafat Sultan",
            "Tahira Naseem",
            "Asim Munawar",
            "Radu Florian",
            "Salim Roukos"
        ],
        "comments": " ",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "It is often desirable for Large Language Models (LLMs) to capture multiple objectives when providing a response. In document-grounded response generation, for example, agent responses are expected to be relevant to a user's query while also being grounded in a given document. In this paper, we introduce Proxy Metric-based Self-Refinement (ProMiSe), which enables an LLM to refine its own initial response along key dimensions of quality guided by external metrics feedback, yielding an overall better final response. ProMiSe leverages feedback on response quality through principle-specific proxy metrics, and iteratively refines its response one principle at a time. We apply ProMiSe to open source language models Flan-T5-XXL and Llama-2-13B-Chat, to evaluate its performance on document-grounded question answering datasets, MultiDoc2Dial and QuAC, demonstrating that self-refinement improves response quality. We further show that fine-tuning Llama-2-13B-Chat on the synthetic dialogue data generated by ProMiSe yields significant performance improvements over the zero-shot baseline as well as a supervised fine-tuned model on human annotated data.\n    ",
        "primary_category": "cs.CL",
        "categories": [
            "cs.AI",
            "cs.LG"
        ],
        "submitted_date": "27 Feb 2024",
        "last_revised_date": " "
    },
    "2403.00828": {
        "title": "Deep Learning Detection Method for Large Language Models-Generated Scientific Content",
        "authors": [
            "Bushra Alhijawi",
            "Rawan Jarrar",
            "Aseel AbuAlRub",
            "Arwa Bader"
        ],
        "comments": " ",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "Large Language Models (LLMs), such as GPT-3 and BERT, reshape how textual content is written and communicated. These models have the potential to generate scientific content that is indistinguishable from that written by humans. Hence, LLMs carry severe consequences for the scientific community, which relies on the integrity and reliability of publications. This research paper presents a novel ChatGPT-generated scientific text detection method, AI-Catcher. AI-Catcher integrates two deep learning models, multilayer perceptron (MLP) and convolutional neural networks (CNN). The MLP learns the feature representations of the linguistic and statistical features. The CNN extracts high-level representations of the sequential patterns from the textual content. AI-Catcher is a multimodal model that fuses hidden patterns derived from MLP and CNN. In addition, a new ChatGPT-Generated scientific text dataset is collected to enhance AI-generated text detection tools, AIGTxt. AIGTxt contains 3000 records collected from published academic articles across ten domains and divided into three classes: Human-written, ChatGPT-generated, and Mixed text. Several experiments are conducted to evaluate the performance of AI-Catcher. The comparative results demonstrate the capability of AI-Catcher to distinguish between human-written and ChatGPT-generated scientific text more accurately than alternative methods. On average, AI-Catcher improved accuracy by 37.4%.\n    ",
        "primary_category": "cs.CL",
        "categories": [
            "cs.AI",
            "cs.LG"
        ],
        "submitted_date": "27 Feb 2024",
        "last_revised_date": " "
    },
    "2403.00829": {
        "title": "TroubleLLM: Align to Red Team Expert",
        "authors": [
            "Zhuoer Xu",
            "Jianping Zhang",
            "Shiwen Cui",
            "Changhua Meng",
            "Weiqiang Wang"
        ],
        "comments": " ",
        "subjects": "Artificial Intelligence (cs.AI)",
        "abstract": "Large Language Models (LLMs) become the start-of-the-art solutions for a variety of natural language tasks and are integrated into real-world applications. However, LLMs can be potentially harmful in manifesting undesirable safety issues like social biases and toxic content. It is imperative to assess its safety issues before deployment. However, the quality and diversity of test prompts generated by existing methods are still far from satisfactory. Not only are these methods labor-intensive and require large budget costs, but the controllability of test prompt generation is lacking for the specific testing domain of LLM applications. With the idea of LLM for LLM testing, we propose the first LLM, called TroubleLLM, to generate controllable test prompts on LLM safety issues. Extensive experiments and human evaluation illustrate the superiority of TroubleLLM on generation quality and generation controllability.\n    ",
        "primary_category": "cs.AI",
        "categories": [
            "cs.CL"
        ],
        "submitted_date": "28 Feb 2024",
        "last_revised_date": " "
    },
    "2403.00830": {
        "title": "MedAide: Leveraging Large Language Models for On-Premise Medical Assistance on Edge Devices",
        "authors": [
            "Abdul Basit",
            "Khizar Hussain",
            "Muhammad Abdullah Hanif",
            "Muhammad Shafique"
        ],
        "comments": "7 pages, 11 figures, ACM conference paper, 33 references",
        "subjects": "Artificial Intelligence (cs.AI)",
        "abstract": "Large language models (LLMs) are revolutionizing various domains with their remarkable natural language processing (NLP) abilities. However, deploying LLMs in resource-constrained edge computing and embedded systems presents significant challenges. Another challenge lies in delivering medical assistance in remote areas with limited healthcare facilities and infrastructure. To address this, we introduce MedAide, an on-premise healthcare chatbot. It leverages tiny-LLMs integrated with LangChain, providing efficient edge-based preliminary medical diagnostics and support. MedAide employs model optimizations for minimal memory footprint and latency on embedded edge devices without server infrastructure. The training process is optimized using low-rank adaptation (LoRA). Additionally, the model is trained on diverse medical datasets, employing reinforcement learning from human feedback (RLHF) to enhance its domain-specific capabilities. The system is implemented on various consumer GPUs and Nvidia Jetson development board. MedAide achieves 77\\% accuracy in medical consultations and scores 56 in USMLE benchmark, enabling an energy-efficient healthcare assistance platform that alleviates privacy concerns due to edge-based deployment, thereby empowering the community.\n    ",
        "primary_category": "cs.AI",
        "categories": [
            "cs.CL"
        ],
        "submitted_date": "28 Feb 2024",
        "last_revised_date": " "
    },
    "2403.00832": {
        "title": "Explainable Session-based Recommendation via Path Reasoning",
        "authors": [
            "Yang Cao",
            "Shuo Shang",
            "Jun Wang",
            "Wei Zhang"
        ],
        "comments": " ",
        "subjects": "Information Retrieval (cs.IR)",
        "abstract": "This paper explores providing explainability for session-based recommendation (SR) by path reasoning. Current SR models emphasize accuracy but lack explainability, while traditional path reasoning prioritizes knowledge graph exploration, ignoring sequential patterns present in the session history. Therefore, we propose a generalized hierarchical reinforcement learning framework for SR, which improves the explainability of existing SR models via Path Reasoning, namely PR4SR. Considering the different importance of items to the session, we design the session-level agent to select the items in the session as the starting point for path reasoning and the path-level agent to perform path reasoning. In particular, we design a multi-target reward mechanism to adapt to the skip behaviors of sequential patterns in SR, and introduce path midpoint reward to enhance the exploration efficiency in knowledge graphs. To improve the completeness of the knowledge graph and to diversify the paths of explanation, we incorporate extracted feature information from images into the knowledge graph. We instantiate PR4SR in five state-of-the-art SR models (i.e., GRU4REC, NARM, GCSAN, SR-GNN, SASRec) and compare it with other explainable SR frameworks, to demonstrate the effectiveness of PR4SR for recommendation and explanation tasks through extensive experiments with these approaches on four datasets.\n    ",
        "primary_category": "cs.IR",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "28 Feb 2024",
        "last_revised_date": " "
    },
    "2403.00833": {
        "title": "Position Paper: Agent AI Towards a Holistic Intelligence",
        "authors": [
            "Qiuyuan Huang",
            "Naoki Wake",
            "Bidipta Sarkar",
            "Zane Durante",
            "Ran Gong",
            "Rohan Taori",
            "Yusuke Noda",
            "Demetri Terzopoulos",
            "Noboru Kuno",
            "Ade Famoti",
            "Ashley Llorens",
            "John Langford",
            "Hoi Vo",
            "Li Fei-Fei",
            "Katsu Ikeuchi",
            "Jianfeng Gao"
        ],
        "comments": "22 pages, 4 figures. arXiv admin note: substantial text overlap with arXiv:2401.03568",
        "subjects": "Artificial Intelligence (cs.AI)",
        "abstract": "Recent advancements in large foundation models have remarkably enhanced our understanding of sensory information in open-world environments. In leveraging the power of foundation models, it is crucial for AI research to pivot away from excessive reductionism and toward an emphasis on systems that function as cohesive wholes. Specifically, we emphasize developing Agent AI -- an embodied system that integrates large foundation models into agent actions. The emerging field of Agent AI spans a wide range of existing embodied and agent-based multimodal interactions, including robotics, gaming, and healthcare systems, etc. In this paper, we propose a novel large action model to achieve embodied intelligent behavior, the Agent Foundation Model. On top of this idea, we discuss how agent AI exhibits remarkable capabilities across a variety of domains and tasks, challenging our understanding of learning and cognition. Furthermore, we discuss the potential of Agent AI from an interdisciplinary perspective, underscoring AI cognition and consciousness within scientific discourse. We believe that those discussions serve as a basis for future research directions and encourage broader societal engagement.\n    ",
        "primary_category": "cs.AI",
        "categories": [],
        "submitted_date": "28 Feb 2024",
        "last_revised_date": " "
    },
    "2403.00834": {
        "title": "Virtual Reality for Understanding Artificial-Intelligence-driven Scientific Discovery with an Application in Quantum Optics",
        "authors": [
            "Philipp Schmidt",
            "S\u00f6ren Arlt",
            "Carlos Ruiz-Gonzalez",
            "Xuemei Gu",
            "Carla Rodr\u00edguez",
            "Mario Krenn"
        ],
        "comments": "12 pages, 6 figures, comments welcome",
        "subjects": "Human-Computer Interaction (cs.HC)",
        "abstract": "Generative Artificial Intelligence (AI) models can propose solutions to scientific problems beyond human capability. To truly make conceptual contributions, researchers need to be capable of understanding the AI-generated structures and extracting the underlying concepts and ideas. When algorithms provide little explanatory reasoning alongside the output, scientists have to reverse-engineer the fundamental insights behind proposals based solely on examples. This task can be challenging as the output is often highly complex and thus not immediately accessible to humans. In this work we show how transferring part of the analysis process into an immersive Virtual Reality (VR) environment can assist researchers in developing an understanding of AI-generated solutions. We demonstrate the usefulness of VR in finding interpretable configurations of abstract graphs, representing Quantum Optics experiments. Thereby, we can manually discover new generalizations of AI-discoveries as well as new understanding in experimental quantum optics. Furthermore, it allows us to customize the search space in an informed way - as a human-in-the-loop - to achieve significantly faster subsequent discovery iterations. As concrete examples, with this technology, we discover a new resource-efficient 3-dimensional entanglement swapping scheme, as well as a 3-dimensional 4-particle Greenberger-Horne-Zeilinger-state analyzer. Our results show the potential of VR for increasing a human researcher's ability to derive knowledge from graph-based generative AI that, which is a common abstract data representation used in diverse fields of science.\n    ",
        "primary_category": "cs.HC",
        "categories": [
            "cs.AI",
            "cs.GR",
            "quant-ph"
        ],
        "submitted_date": "20 Feb 2024",
        "last_revised_date": " "
    },
    "2403.00838": {
        "title": "Sharp-interface limits for brittle fracture via the inverse-deformation formulation",
        "authors": [
            "Timothy J. Healey",
            "Roberto Paroni",
            "Phoebus Rosakis"
        ],
        "comments": "12 pages, 8 figures",
        "subjects": "Analysis of PDEs (math.AP)",
        "abstract": "We derive sharp-interface models for one-dimensional brittle fracture via the inverse-deformation approach. Methods of Gamma-convergence are employed to obtain the singular limits of previously proposed models. The latter feature a local, non-convex stored energy of inverse strain, augmented by small interfacial energy, formulated in terms of the inverse-strain gradient. They predict spontaneous fracture with exact crack-opening discontinuities, without the use of damage (phase) fields or pre-existing cracks; crack faces are endowed with a thin layer of surface energy. The models obtained herewith inherit the same properties, except that surface energy is now concentrated at the crack faces. Accordingly, we construct energy-minimizing configurations. For a composite bar with a breakable layer, our results predict a pattern of equally spaced cracks whose number is given as an increasing function of applied load.\n    ",
        "primary_category": "math.AP",
        "categories": [
            "math.NA"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2403.00839": {
        "title": "ToolNet: Connecting Large Language Models with Massive Tools via Tool Graph",
        "authors": [
            "Xukun Liu",
            "Zhiyuan Peng",
            "Xiaoyuan Yi",
            "Xing Xie",
            "Lirong Xiang",
            "Yuchen Liu",
            "Dongkuan Xu"
        ],
        "comments": " ",
        "subjects": "Artificial Intelligence (cs.AI)",
        "abstract": "While achieving remarkable progress in a broad range of tasks, large language models (LLMs) remain significantly limited in properly using massive external tools. Existing in-context learning approaches simply format tools into a list of plain text descriptions and input them to LLMs, from which, LLMs generate a sequence of tool calls to solve problems step by step. Such a paradigm ignores the intrinsic dependency between tools and offloads all reasoning loads to LLMs, making them restricted to a limited number of specifically designed tools. It thus remains challenging for LLMs to operate on a library of massive tools, casting a great limitation when confronted with real-world scenarios. This paper proposes ToolNet, a plug-and-play framework that scales up the number of tools to thousands with a moderate increase in token consumption. ToolNet organizes tools into a directed graph. Each node represents a tool, and weighted edges denote tool transition. Starting from an initial tool node, an LLM navigates in the graph by iteratively choosing the next one from its successors until the task is resolved. Extensive experiments show that ToolNet can achieve impressive results in challenging multi-hop tool learning datasets and is resilient to tool failures.\n    ",
        "primary_category": "cs.AI",
        "categories": [
            "cs.CL"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2403.00840": {
        "title": "EyeGPT: Ophthalmic Assistant with Large Language Models",
        "authors": [
            "Xiaolan Chen",
            "Ziwei Zhao",
            "Weiyi Zhang",
            "Pusheng Xu",
            "Le Gao",
            "Mingpu Xu",
            "Yue Wu",
            "Yinwen Li",
            "Danli Shi",
            "Mingguang He"
        ],
        "comments": "47 pages, 4 figures, 1 table, 2 supplementary figures and 9 supplementary tables",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "Artificial intelligence (AI) has gained significant attention in healthcare consultation due to its potential to improve clinical workflow and enhance medical communication. However, owing to the complex nature of medical information, large language models (LLM) trained with general world knowledge might not possess the capability to tackle medical-related tasks at an expert level. Here, we introduce EyeGPT, a specialized LLM designed specifically for ophthalmology, using three optimization strategies including role-playing, finetuning, and retrieval-augmented generation. In particular, we proposed a comprehensive evaluation framework that encompasses a diverse dataset, covering various subspecialties of ophthalmology, different users, and diverse inquiry intents. Moreover, we considered multiple evaluation metrics, including accuracy, understandability, trustworthiness, empathy, and the proportion of hallucinations. By assessing the performance of different EyeGPT variants, we identify the most effective one, which exhibits comparable levels of understandability, trustworthiness, and empathy to human ophthalmologists (all Ps>0.05). Overall, ur study provides valuable insights for future research, facilitating comprehensive comparisons and evaluations of different strategies for developing specialized LLMs in ophthalmology. The potential benefits include enhancing the patient experience in eye care and optimizing ophthalmologists' services.\n    ",
        "primary_category": "cs.CL",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2403.00841": {
        "title": "Offline Fictitious Self-Play for Competitive Games",
        "authors": [
            "Jingxiao Chen",
            "Weiji Xie",
            "Weinan Zhang",
            "Yong yu",
            "Ying Wen"
        ],
        "comments": " ",
        "subjects": "Multiagent Systems (cs.MA)",
        "abstract": "Offline Reinforcement Learning (RL) has received significant interest due to its ability to improve policies in previously collected datasets without online interactions. Despite its success in the single-agent setting, offline multi-agent RL remains a challenge, especially in competitive games. Firstly, unaware of the game structure, it is impossible to interact with the opponents and conduct a major learning paradigm, self-play, for competitive games. Secondly, real-world datasets cannot cover all the state and action space in the game, resulting in barriers to identifying Nash equilibrium (NE). To address these issues, this paper introduces Off-FSP, the first practical model-free offline RL algorithm for competitive games. We start by simulating interactions with various opponents by adjusting the weights of the fixed dataset with importance sampling. This technique allows us to learn best responses to different opponents and employ the Offline Self-Play learning framework. In this framework, we further implement Fictitious Self-Play (FSP) to approximate NE. In partially covered real-world datasets, our methods show the potential to approach NE by incorporating any single-agent offline RL method. Experimental results in Leduc Hold'em Poker show that our method significantly improves performances compared with state-of-the-art baselines.\n    ",
        "primary_category": "cs.MA",
        "categories": [
            "cs.AI",
            "cs.GT",
            "cs.LG"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2403.00844": {
        "title": "Lower-Left Partial AUC: An Effective and Efficient Optimization Metric for Recommendation",
        "authors": [
            "Wentao Shi",
            "Chenxu Wang",
            "Fuli Feng",
            "Yang Zhang",
            "Wenjie Wang",
            "Junkang Wu",
            "Xiangnan He"
        ],
        "comments": "WWW 2024; 15 pages",
        "subjects": "Information Retrieval (cs.IR)",
        "abstract": "Optimization metrics are crucial for building recommendation systems at scale. However, an effective and efficient metric for practical use remains elusive. While Top-K ranking metrics are the gold standard for optimization, they suffer from significant computational overhead. Alternatively, the more efficient accuracy and AUC metrics often fall short of capturing the true targets of recommendation tasks, leading to suboptimal performance. To overcome this dilemma, we propose a new optimization metric, Lower-Left Partial AUC (LLPAUC), which is computationally efficient like AUC but strongly correlates with Top-K ranking metrics. Compared to AUC, LLPAUC considers only the partial area under the ROC curve in the Lower-Left corner to push the optimization focus on Top-K. We provide theoretical validation of the correlation between LLPAUC and Top-K ranking metrics and demonstrate its robustness to noisy user feedback. We further design an efficient point-wise recommendation loss to maximize LLPAUC and evaluate it on three datasets, validating its effectiveness and robustness.\n    ",
        "primary_category": "cs.IR",
        "categories": [
            "cs.LG"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2403.00845": {
        "title": "Improved Online Learning Algorithms for CTR Prediction in Ad Auctions",
        "authors": [
            "Zhe Feng",
            "Christopher Liaw",
            "Zixin Zhou"
        ],
        "comments": "Appeared in ICML 2023",
        "subjects": "Information Retrieval (cs.IR)",
        "abstract": "In this work, we investigate the online learning problem of revenue maximization in ad auctions, where the seller needs to learn the click-through rates (CTRs) of each ad candidate and charge the price of the winner through a pay-per-click manner. We focus on two models of the advertisers' strategic behaviors. First, we assume that the advertiser is completely myopic; i.e.~in each round, they aim to maximize their utility only for the current round. In this setting, we develop an online mechanism based on upper-confidence bounds that achieves a tight $O(\\sqrt{T})$ regret in the worst-case and negative regret when the values are static across all the auctions and there is a gap between the highest expected value (i.e.~value multiplied by their CTR) and second highest expected value ad. Next, we assume that the advertiser is non-myopic and cares about their long term utility. This setting is much more complex since an advertiser is incentivized to influence the mechanism by bidding strategically in earlier rounds. In this setting, we provide an algorithm to achieve negative regret for the static valuation setting (with a positive gap), which is in sharp contrast with the prior work that shows $O(T^{2/3})$ regret when the valuation is generated by adversary.\n    ",
        "primary_category": "cs.IR",
        "categories": [
            "cs.GT",
            "cs.LG"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2403.00849": {
        "title": "NeuraLUT: Hiding Neural Network Density in Boolean Synthesizable Functions",
        "authors": [
            "Marta Andronic",
            "George A. Constantinides"
        ],
        "comments": " ",
        "subjects": "Hardware Architecture (cs.AR)",
        "abstract": "Field-Programmable Gate Array (FPGA) accelerators have proven successful in handling latency- and resource-critical deep neural network (DNN) inference tasks. Among the most computationally intensive operations in a neural network (NN) is the dot product between the feature and weight vectors. Thus, some previous FPGA acceleration works have proposed mapping neurons with quantized inputs and outputs directly to lookup tables (LUTs) for hardware implementation. In these works, the boundaries of the neurons coincide with the boundaries of the LUTs. We propose relaxing these boundaries and mapping entire sub-networks to a single LUT. As the sub-networks are absorbed within the LUT, the NN topology and precision within a partition do not affect the size of the lookup tables generated. Therefore, we utilize fully connected layers with floating-point precision inside each partition, which benefit from being universal function approximators, with rigid sparsity and quantization enforced only between partitions, where the NN topology becomes exposed to the circuit topology. Although cheap to implement, this approach can lead to very deep NNs, and so to tackle challenges like vanishing gradients, we also introduce skip connections inside the partitions. The resulting methodology can be seen as training DNNs with a specific sparsity pattern that allows them to be mapped to much shallower circuit-level networks, thereby significantly improving latency. We validate our proposed method on a known latency-critical task, jet substructure tagging, and on the classical computer vision task, the digit classification using MNIST. Our approach allows for greater function expressivity within the LUTs compared to existing work, leading to lower latency NNs for the same accuracy.\n    ",
        "primary_category": "cs.AR",
        "categories": [
            "cs.LG",
            "stat.ML"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2403.00853": {
        "title": "Distributed Momentum Methods Under Biased Gradient Estimations",
        "authors": [
            "Ali Beikmohammadi",
            "Sarit Khirirat",
            "Sindri Magn\u00fasson"
        ],
        "comments": " ",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Distributed stochastic gradient methods are gaining prominence in solving large-scale machine learning problems that involve data distributed across multiple nodes. However, obtaining unbiased stochastic gradients, which have been the focus of most theoretical research, is challenging in many distributed machine learning applications. The gradient estimations easily become biased, for example, when gradients are compressed or clipped, when data is shuffled, and in meta-learning and reinforcement learning. In this work, we establish non-asymptotic convergence bounds on distributed momentum methods under biased gradient estimation on both general non-convex and $\\mu$-PL non-convex problems. Our analysis covers general distributed optimization problems, and we work out the implications for special cases where gradient estimates are biased, i.e., in meta-learning and when the gradients are compressed or clipped. Our numerical experiments on training deep neural networks with Top-$K$ sparsification and clipping verify faster convergence performance of momentum methods than traditional biased gradient descent.\n    ",
        "primary_category": "cs.LG",
        "categories": [],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2403.00854": {
        "title": "Speaker-Independent Dysarthria Severity Classification using Self-Supervised Transformers and Multi-Task Learning",
        "authors": [
            "Lauren Stumpf",
            "Balasundaram Kadirvelu",
            "Sigourney Waibel",
            "A. Aldo Faisal"
        ],
        "comments": "17 pages, 2 tables, 4 main figures, 2 supplemental figures, prepared for journal submission",
        "subjects": "Neurons and Cognition (q-bio.NC)",
        "abstract": "Dysarthria, a condition resulting from impaired control of the speech muscles due to neurological disorders, significantly impacts the communication and quality of life of patients. The condition's complexity, human scoring and varied presentations make its assessment and management challenging. This study presents a transformer-based framework for automatically assessing dysarthria severity from raw speech data. It can offer an objective, repeatable, accessible, standardised and cost-effective and compared to traditional methods requiring human expert assessors. We develop a transformer framework, called Speaker-Agnostic Latent Regularisation (SALR), incorporating a multi-task learning objective and contrastive learning for speaker-independent multi-class dysarthria severity classification. The multi-task framework is designed to reduce reliance on speaker-specific characteristics and address the intrinsic intra-class variability of dysarthric speech. We evaluated on the Universal Access Speech dataset using leave-one-speaker-out cross-validation, our model demonstrated superior performance over traditional machine learning approaches, with an accuracy of $70.48\\%$ and an F1 score of $59.23\\%$. Our SALR model also exceeded the previous benchmark for AI-based classification, which used support vector machines, by $16.58\\%$. We open the black box of our model by visualising the latent space where we can observe how the model substantially reduces speaker-specific cues and amplifies task-specific ones, thereby showing its robustness. In conclusion, SALR establishes a new benchmark in speaker-independent multi-class dysarthria severity classification using generative AI. The potential implications of our findings for broader clinical applications in automated dysarthria severity assessments.\n    ",
        "primary_category": "q-bio.NC",
        "categories": [
            "cs.AI",
            "cs.CL",
            "cs.LG",
            "cs.SD",
            "eess.AS"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2403.00859": {
        "title": "Team Formation amidst Conflicts",
        "authors": [
            "Iasonas Nikolaou",
            "Evimaria Terzi"
        ],
        "comments": " ",
        "subjects": "Artificial Intelligence (cs.AI)",
        "abstract": "In this work, we formulate the problem of team formation amidst conflicts. The goal is to assign individuals to tasks, with given capacities, taking into account individuals' task preferences and the conflicts between them. Using dependent rounding schemes as our main toolbox, we provide efficient approximation algorithms. Our framework is extremely versatile and can model many different real-world scenarios as they arise in educational settings and human-resource management. We test and deploy our algorithms on real-world datasets and we show that our algorithms find assignments that are better than those found by natural baselines. In the educational setting we also show how our assignments are far better than those done manually by human experts. In the human resource management application we show how our assignments increase the diversity of teams. Finally, using a synthetic dataset we demonstrate that our algorithms scale very well in practice.\n    ",
        "primary_category": "cs.AI",
        "categories": [
            "cs.GT",
            "cs.SI"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2403.00860": {
        "title": "Parallel Algorithms for Exact Enumeration of Deep Neural Network Activation Regions",
        "authors": [
            "Sabrina Drammis",
            "Bowen Zheng",
            "Karthik Srinivasan",
            "Robert C. Berwick",
            "Nancy A. Lynch",
            "Robert Ajemian"
        ],
        "comments": " ",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "A feedforward neural network using rectified linear units constructs a mapping from inputs to outputs by partitioning its input space into a set of convex regions where points within a region share a single affine transformation. In order to understand how neural networks work, when and why they fail, and how they compare to biological intelligence, we need to understand the organization and formation of these regions. Step one is to design and implement algorithms for exact region enumeration in networks beyond toy examples.\nIn this work, we present parallel algorithms for exact enumeration in deep (and shallow) neural networks. Our work has three main contributions: (1) we present a novel algorithm framework and parallel algorithms for region enumeration; (2) we implement one of our algorithms on a variety of network architectures and experimentally show how the number of regions dictates runtime; and (3) we show, using our algorithm's output, how the dimension of a region's affine transformation impacts further partitioning of the region by deeper layers.\nTo our knowledge, we run our implemented algorithm on networks larger than all of the networks used in the existing region enumeration literature. Further, we experimentally demonstrate the importance of parallelism for region enumeration of any reasonably sized network.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.AI",
            "cs.NE"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2403.00861": {
        "title": "Pivoting Retail Supply Chain with Deep Generative Techniques: Taxonomy, Survey and Insights",
        "authors": [
            "Yuan Wang",
            "Lokesh Kumar Sambasivan",
            "Mingang Fu",
            "Prakhar Mehrotra"
        ],
        "comments": " ",
        "subjects": "Artificial Intelligence (cs.AI)",
        "abstract": "Generative AI applications, such as ChatGPT or DALL-E, have shown the world their impressive capabilities in generating human-like text or image. Diving deeper, the science stakeholder for those AI applications are Deep Generative Models, a.k.a DGMs, which are designed to learn the underlying distribution of the data and generate new data points that are statistically similar to the original dataset. One critical question is raised: how can we leverage DGMs into morden retail supply chain realm? To address this question, this paper expects to provide a comprehensive review of DGMs and discuss their existing and potential usecases in retail supply chain, by (1) providing a taxonomy and overview of state-of-the-art DGMs and their variants, (2) reviewing existing DGM applications in retail supply chain from a end-to-end view of point, and (3) discussing insights and potential directions on how DGMs can be further utilized on solving retail supply chain problems.\n    ",
        "primary_category": "cs.AI",
        "categories": [
            "cs.LG"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2403.00863": {
        "title": "LLM-Ensemble: Optimal Large Language Model Ensemble Method for E-commerce Product Attribute Value Extraction",
        "authors": [
            "Chenhao Fang",
            "Xiaohan Li",
            "Zezhong Fan",
            "Jianpeng Xu",
            "Kaushiki Nag",
            "Evren Korpeoglu",
            "Sushant Kumar",
            "Kannan Achan"
        ],
        "comments": " ",
        "subjects": "Information Retrieval (cs.IR)",
        "abstract": "Product attribute value extraction is a pivotal component in Natural Language Processing (NLP) and the contemporary e-commerce industry. The provision of precise product attribute values is fundamental in ensuring high-quality recommendations and enhancing customer satisfaction. The recently emerging Large Language Models (LLMs) have demonstrated state-of-the-art performance in numerous attribute extraction tasks, without the need for domain-specific training data. Nevertheless, varying strengths and weaknesses are exhibited by different LLMs due to the diversity in data, architectures, and hyperparameters. This variation makes them complementary to each other, with no single LLM dominating all others. Considering the diverse strengths and weaknesses of LLMs, it becomes necessary to develop an ensemble method that leverages their complementary potentials. In this paper, we propose a novel algorithm called LLM-ensemble to ensemble different LLMs' outputs for attribute value extraction. We iteratively learn the weights for different LLMs to aggregate the labels with weights to predict the final attribute value. Not only can our proposed method be proven theoretically optimal, but it also ensures efficient computation, fast convergence, and safe deployment. We have also conducted extensive experiments with various state-of-the-art LLMs, including Llama2-13B, Llama2-70B, PaLM-2, GPT-3.5, and GPT-4, on Walmart's internal data. Our offline metrics demonstrate that the LLM-ensemble method outperforms all the state-of-the-art single LLMs on Walmart's internal dataset. This method has been launched in several production models, leading to improved Gross Merchandise Volume (GMV), Click-Through Rate (CTR), Conversion Rate (CVR), and Add-to-Cart Rate (ATC).\n    ",
        "primary_category": "cs.IR",
        "categories": [
            "cs.AI",
            "cs.CL"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2403.00864": {
        "title": "Analysis of Logistic Map for Pseudorandom Number Generation in Game Development",
        "authors": [
            "Chenxiao Zhou"
        ],
        "comments": " ",
        "subjects": "Cryptography and Security (cs.CR)",
        "abstract": "Many popular video games use pseudorandom number generators to create randomly distributed locations for game objects as highly unpredictable as possible. Some scenarios like game competition also need reproducible randomness, namely the random results can be reproducible if given the same seed input. Existing random generation methods have limited choices for seed input. To address this limitation, this study analyzes a chaotic map called the Logistic Map for game development. After analyzing the properties of this chaotic map, I developed a pseudorandom sequence generation algorithm and a generation algorithm of random locations of game objects. Experiments on the game of Snake demonstrate that the Logistic Map is viable for game development. The reproducible randomness is also realized with the proposed algorithm.\n    ",
        "primary_category": "cs.CR",
        "categories": [],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00865": {
        "title": "Fast and Efficient Local Search for Genetic Programming Based Loss Function Learning",
        "authors": [
            "Christian Raymond",
            "Qi Chen",
            "Bing Xue",
            "Mengjie Zhang"
        ],
        "comments": "arXiv admin note: substantial text overlap with arXiv:2209.08907",
        "subjects": "Neural and Evolutionary Computing (cs.NE)",
        "abstract": "In this paper, we develop upon the topic of loss function learning, an emergent meta-learning paradigm that aims to learn loss functions that significantly improve the performance of the models trained under them. Specifically, we propose a new meta-learning framework for task and model-agnostic loss function learning via a hybrid search approach. The framework first uses genetic programming to find a set of symbolic loss functions. Second, the set of learned loss functions is subsequently parameterized and optimized via unrolled differentiation. The versatility and performance of the proposed framework are empirically validated on a diverse set of supervised learning tasks. Results show that the learned loss functions bring improved convergence, sample efficiency, and inference performance on tabulated, computer vision, and natural language processing problems, using a variety of task-specific neural network architectures.\n    ",
        "primary_category": "cs.NE",
        "categories": [
            "cs.AI",
            "cs.CV",
            "cs.LG"
        ],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00869": {
        "title": "Enhancing Multivariate Time Series Forecasting with Mutual Information-driven Cross-Variable and Temporal Modeling",
        "authors": [
            "Shiyi Qi",
            "Liangjian Wen",
            "Yiduo Li",
            "Yuanhang Yang",
            "Zhe Li",
            "Zhongwen Rao",
            "Lujia Pan",
            "Zenglin Xu"
        ],
        "comments": " ",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Recent advancements have underscored the impact of deep learning techniques on multivariate time series forecasting (MTSF). Generally, these techniques are bifurcated into two categories: Channel-independence and Channel-mixing approaches. Although Channel-independence methods typically yield better results, Channel-mixing could theoretically offer improvements by leveraging inter-variable correlations. Nonetheless, we argue that the integration of uncorrelated information in channel-mixing methods could curtail the potential enhancement in MTSF model performance. To substantiate this claim, we introduce the Cross-variable Decorrelation Aware feature Modeling (CDAM) for Channel-mixing approaches, aiming to refine Channel-mixing by minimizing redundant information between channels while enhancing relevant mutual information. Furthermore, we introduce the Temporal correlation Aware Modeling (TAM) to exploit temporal correlations, a step beyond conventional single-step forecasting methods. This strategy maximizes the mutual information between adjacent sub-sequences of both the forecasted and target series. Combining CDAM and TAM, our novel framework significantly surpasses existing models, including those previously considered state-of-the-art, in comprehensive tests.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "stat.ML"
        ],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00871": {
        "title": "Teach LLMs to Phish: Stealing Private Information from Language Models",
        "authors": [
            "Ashwinee Panda",
            "Christopher A. Choquette-Choo",
            "Zhengming Zhang",
            "Yaoqing Yang",
            "Prateek Mittal"
        ],
        "comments": "ICLR 2024",
        "subjects": "Cryptography and Security (cs.CR)",
        "abstract": "When large language models are trained on private data, it can be a significant privacy risk for them to memorize and regurgitate sensitive information. In this work, we propose a new practical data extraction attack that we call \"neural phishing\". This attack enables an adversary to target and extract sensitive or personally identifiable information (PII), e.g., credit card numbers, from a model trained on user data with upwards of 10% attack success rates, at times, as high as 50%. Our attack assumes only that an adversary can insert as few as 10s of benign-appearing sentences into the training dataset using only vague priors on the structure of the user data.\n    ",
        "primary_category": "cs.CR",
        "categories": [
            "cs.AI",
            "cs.CL",
            "cs.LG"
        ],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00872": {
        "title": "DFIN-SQL: Integrating Focused Schema with DIN-SQL for Superior Accuracy in Large-Scale Databases",
        "authors": [
            "Shai Volvovsky",
            "Marco Marcassa",
            "Mustafa Panbiharwala"
        ],
        "comments": " ",
        "subjects": "Databases (cs.DB)",
        "abstract": "The task of converting natural language queries into SQL queries is intricate, necessitating a blend of precise techniques for an accurate translation. The DIN-SQL (Decomposed-In-Context SQL) methodology represents a significant development in this domain. This paper introduces DFIN (Decomposed Focused-In-Context), an innovative extension of DIN-SQL that enhances Text-to-SQL conversion by addressing schema linking errors, which are a major source of inaccuracies. DFIN uniquely alternates between prompting techniques and Retrieval-Augmented Generation (RAG), adapting to the size and complexity of the database schema. A preprocessing phase embeds database definitions and leverages annotated files, akin to those in the BIRD dataset, facilitating the runtime retrieval of pertinent schema information. This strategy significantly reduces the token count for schema linking prompts, enabling the use of a standard GPT-4 model over its larger context variant, thus handling large-scale databases more effectively and economically. Our evaluation on the BIRD dataset, a challenging real-world benchmark, demonstrates that DFIN not only scales efficiently but also improves accuracy, achieving a score of 51.69. This improvement surpasses DIN-SQL method (the current third-place), which is the highest-ranked model employing in-context learning rather than fine-tuning, previously scoring 50.72. The advancement of DFIN underscores the evolving capabilities of in-context learning methodologies combined with advanced language models, offering a promising avenue for future research in complex Text-to-SQL conversion tasks.\n    ",
        "primary_category": "cs.DB",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00873": {
        "title": "Blockchain-empowered Federated Learning: Benefits, Challenges, and Solutions",
        "authors": [
            "Zeju Cai",
            "Jianguo Chen",
            "Yuting Fan",
            "Zibin Zheng",
            "Keqin Li"
        ],
        "comments": " ",
        "subjects": "Cryptography and Security (cs.CR)",
        "abstract": "Federated learning (FL) is a distributed machine learning approach that protects user data privacy by training models locally on clients and aggregating them on a parameter server. While effective at preserving privacy, FL systems face limitations such as single points of failure, lack of incentives, and inadequate security. To address these challenges, blockchain technology is integrated into FL systems to provide stronger security, fairness, and scalability. However, blockchain-empowered FL (BC-FL) systems introduce additional demands on network, computing, and storage resources. This survey provides a comprehensive review of recent research on BC-FL systems, analyzing the benefits and challenges associated with blockchain integration. We explore why blockchain is applicable to FL, how it can be implemented, and the challenges and existing solutions for its integration. Additionally, we offer insights on future research directions for the BC-FL system.\n    ",
        "primary_category": "cs.CR",
        "categories": [
            "cs.LG"
        ],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00874": {
        "title": "On complex algebraic singularities of some genuinely nonlinear PDEs",
        "authors": [
            "Denys Dutykh",
            "\u00c9ric Leichtnam"
        ],
        "comments": "85 pages, 15 figures, 52 references, 5 appendices, and 1 table",
        "subjects": "Analysis of PDEs (math.AP)",
        "abstract": "In this manuscript, we highlight a new phenomenon of complex algebraic singularity formation for solutions of a large class of genuinely nonlinear partial differential equations (PDEs). We start from a unique Cauchy datum, which is holomorphic ramified around the smooth locus and is sufficiently singular. Then, we expect the existence of a solution which should be holomorphic ramified around the singular locus S defined by the vanishing of the discriminant of an algebraic equation. Notice, moreover, that the monodromy of the Cauchy datum is Abelian, whereas one of the solutions is non-Abelian. Moreover, the singular locus S depends on the Cauchy datum in contrast to the Leray principle (stated for linear problems only). This phenomenon is due to the fact that the PDE is genuinely nonlinear and that the Cauchy datum is sufficiently singular. First, we investigate the case of the inviscid Burgers equation. Later, we state a general conjecture that describes the expected phenomenon. We view this Conjecture as a working programme allowing us to develop interesting new Mathematics. We also state another Conjecture 2, which is a particular case of the general Conjecture but keeps all the flavour and difficulty of the subject. Then, we propose a new algorithm with a map F such that a fixed point of F would give a solution to the problem associated with Conjecture 2. Then, we perform convincing, elaborate numerical tests that suggest that a Banach norm should exist for which the mapping F should be a contraction so that the solution (with the above specific algebraic structure) should be unique. This work is a continuation of Leichtnam (1993).\n    ",
        "primary_category": "math.AP",
        "categories": [
            "math.CV",
            "math.NA",
            "nlin.SI"
        ],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00875": {
        "title": "Enhancing Protein Predictive Models via Proteins Data Augmentation: A Benchmark and New Directions",
        "authors": [
            "Rui Sun",
            "Lirong Wu",
            "Haitao Lin",
            "Yufei Huang",
            "Stan Z. Li"
        ],
        "comments": " ",
        "subjects": "Quantitative Methods (q-bio.QM)",
        "abstract": "Augmentation is an effective alternative to utilize the small amount of labeled protein data. However, most of the existing work focuses on design-ing new architectures or pre-training tasks, and relatively little work has studied data augmentation for proteins. This paper extends data augmentation techniques previously used for images and texts to proteins and then benchmarks these techniques on a variety of protein-related tasks, providing the first comprehensive evaluation of protein augmentation. Furthermore, we propose two novel semantic-level protein augmentation methods, namely Integrated Gradients Substitution and Back Translation Substitution, which enable protein semantic-aware augmentation through saliency detection and biological knowledge. Finally, we integrate extended and proposed augmentations into an augmentation pool and propose a simple but effective framework, namely Automated Protein Augmentation (APA), which can adaptively select the most suitable augmentation combinations for different tasks. Extensive experiments have shown that APA enhances the performance of five protein related tasks by an average of 10.55% across three architectures compared to vanilla implementations without augmentation, highlighting its potential to make a great impact on the field.\n    ",
        "primary_category": "q-bio.QM",
        "categories": [
            "cs.AI",
            "cs.LG",
            "q-bio.BM"
        ],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00876": {
        "title": "Word Order and World Knowledge",
        "authors": [
            "Qinghua Zhao",
            "Vinit Ravishankar",
            "Nicolas Garneau",
            "Anders S\u00f8gaard"
        ],
        "comments": " ",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "Word order is an important concept in natural language, and in this work, we study how word order affects the induction of world knowledge from raw text using language models. We use word analogies to probe for such knowledge. Specifically, in addition to the natural word order, we first respectively extract texts of six fixed word orders from five languages and then pretrain the language models on these texts. Finally, we analyze the experimental results of the fixed word orders on word analogies and show that i) certain fixed word orders consistently outperform or underperform others, though the specifics vary across languages, and ii) the Wov2Lex hypothesis is not hold in pre-trained language models, and the natural word order typically yields mediocre results. The source code will be made publicly available at this https URL.\n    ",
        "primary_category": "cs.CL",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00878": {
        "title": "Crimson: Empowering Strategic Reasoning in Cybersecurity through Large Language Models",
        "authors": [
            "Jiandong Jin",
            "Bowen Tang",
            "Mingxuan Ma",
            "Xiao Liu",
            "Yunfei Wang",
            "Qingnan Lai",
            "Jia Yang",
            "Changling Zhou"
        ],
        "comments": "9 pages, 7 figures",
        "subjects": "Cryptography and Security (cs.CR)",
        "abstract": "We introduces Crimson, a system that enhances the strategic reasoning capabilities of Large Language Models (LLMs) within the realm of cybersecurity. By correlating CVEs with MITRE ATT&CK techniques, Crimson advances threat anticipation and strategic defense efforts. Our approach includes defining and evaluating cybersecurity strategic tasks, alongside implementing a comprehensive human-in-the-loop data-synthetic workflow to develop the CVE-to-ATT&CK Mapping (CVEM) dataset. We further enhance LLMs' reasoning abilities through a novel Retrieval-Aware Training (RAT) process and its refined iteration, RAT-R.\nOur findings demonstrate that an LLM fine-tuned with our techniques, possessing 7 billion parameters, approaches the performance level of GPT-4, showing markedly lower rates of hallucination and errors, and surpassing other models in strategic reasoning tasks. Moreover, domain-specific fine-tuning of embedding models significantly improves performance within cybersecurity contexts, underscoring the efficacy of our methodology. By leveraging Crimson to convert raw vulnerability data into structured and actionable insights, we bolster proactive cybersecurity defenses.\n    ",
        "primary_category": "cs.CR",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00880": {
        "title": "Dual-Granularity Medication Recommendation Based on Causal Inference",
        "authors": [
            "Shunpan Liang",
            "Xiang Li",
            "Xiang Li",
            "Chen Li",
            "Yu Lei",
            "Yulei Hou",
            "Tengfei Ma"
        ],
        "comments": " ",
        "subjects": "Information Retrieval (cs.IR)",
        "abstract": "As medical demands grow and machine learning technology advances, AI-based diagnostic and treatment systems are garnering increasing attention. Medication recommendation aims to integrate patients' long-term health records with medical knowledge, recommending accuracy and safe medication combinations for specific conditions. However, most existing researches treat medication recommendation systems merely as variants of traditional recommendation systems, overlooking the heterogeneity between medications and diseases. To address this challenge, we propose DGMed, a framework for medication recommendation. DGMed utilizes causal inference to uncover the connections among medical entities and presents an innovative feature alignment method to tackle heterogeneity issues. Specifically, this study first applies causal inference to analyze the quantified therapeutic effects of medications on specific diseases from historical records, uncovering potential links between medical entities. Subsequently, we integrate molecular-level knowledge, aligning the embeddings of medications and diseases within the molecular space to effectively tackle their heterogeneity. Ultimately, based on relationships at the entity level, we adaptively adjust the recommendation probabilities of medication and recommend medication combinations according to the patient's current health condition. Experimental results on a real-world dataset show that our method surpasses existing state-of-the-art baselines in four evaluation metrics, demonstrating superior performance in both accuracy and safety aspects. Compared to the sub-optimal model, our approach improved accuracy by 4.40%, reduced the risk of side effects by 6.14%, and increased time efficiency by 47.15%.\n    ",
        "primary_category": "cs.IR",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00881": {
        "title": "FedRDMA: Communication-Efficient Cross-Silo Federated LLM via Chunked RDMA Transmission",
        "authors": [
            "Zeling Zhang",
            "Dongqi Cai",
            "Yiran Zhang",
            "Mengwei Xu",
            "Shangguang Wang",
            "Ao Zhou"
        ],
        "comments": "under review",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Communication overhead is a significant bottleneck in federated learning (FL), which has been exaggerated with the increasing size of AI models. In this paper, we propose FedRDMA, a communication-efficient cross-silo FL system that integrates RDMA into the FL communication protocol. To overcome the limitations of RDMA in wide-area networks (WANs), FedRDMA divides the updated model into chunks and designs a series of optimization techniques to improve the efficiency and robustness of RDMA-based communication. We implement FedRDMA atop the industrial federated learning framework and evaluate it on a real-world cross-silo FL scenario. The experimental results show that \\sys can achieve up to 3.8$\\times$ speedup in communication efficiency compared to traditional TCP/IP-based FL systems.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.DC",
            "cs.NI"
        ],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00885": {
        "title": "Training Computer Scientists for the Challenges of Hybrid Quantum-Classical Computing",
        "authors": [
            "Vincenzo De Maio",
            "Meerzhan Kanatbekova",
            "Felix Zilk",
            "Nicolai Friis",
            "Tobias Guggemos",
            "Ivona Brandic"
        ],
        "comments": " ",
        "subjects": "Physics Education (physics.ed-ph)",
        "abstract": "As we enter the post-Moore era, we experience the rise of various non-von-Neumann-architectures to address the increasing computational demand for modern applications, with quantum computing being among the most prominent and promising technologies. However, this development creates a gap in current computer science curricula since most quantum computing lectures are strongly physics-oriented and have little intersection with the remaining curriculum of computer science. This fact makes designing an appealing course very difficult, in particular for non-physicists. Furthermore, in the academic community, there is consensus that quantum computers are going to be used only for specific computational tasks (e.g., in computational science), where hybrid systems - combined classical and quantum computers - facilitate the execution of an application on both quantum and classical computing resources. A hybrid system thus executes only certain suitable parts of an application on the quantum machine, while other parts are executed on the classical components of the system. To fully exploit the capabilities of hybrid systems and to meet future requirements in this emerging field, we need to prepare a new generation of computer scientists with skills in both distributed computing and quantum computing. To bridge this existing gap in standard computer science curricula, we designed a new lecture and exercise series on Hybrid Quantum-Classical Systems, where students learn how to decompose applications and implement computational tasks on a hybrid quantum-classical computational continuum. While learning the inherent concepts underlying quantum systems, students are obligated to apply techniques and methods they are already familiar with, making the entrance to the field of quantum computing comprehensive yet appealing and accessible to students of computer science.\n    ",
        "primary_category": "physics.ed-ph",
        "categories": [
            "cs.DC",
            "cs.ET",
            "quant-ph"
        ],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00887": {
        "title": "SEGAA: A Unified Approach to Predicting Age, Gender, and Emotion in Speech",
        "authors": [
            "Aron R",
            "Indra Sigicharla",
            "Chirag Periwal",
            "Mohanaprasad K",
            "Nithya Darisini P S",
            "Sourabh Tiwari",
            "Shivani Arora"
        ],
        "comments": " ",
        "subjects": "Audio and Speech Processing (eess.AS)",
        "abstract": "The interpretation of human voices holds importance across various applications. This study ventures into predicting age, gender, and emotion from vocal cues, a field with vast applications. Voice analysis tech advancements span domains, from improving customer interactions to enhancing healthcare and retail experiences. Discerning emotions aids mental health, while age and gender detection are vital in various contexts. Exploring deep learning models for these predictions involves comparing single, multi-output, and sequential models highlighted in this paper. Sourcing suitable data posed challenges, resulting in the amalgamation of the CREMA-D and EMO-DB datasets. Prior work showed promise in individual predictions, but limited research considered all three variables simultaneously. This paper identifies flaws in an individual model approach and advocates for our novel multi-output learning architecture Speech-based Emotion Gender and Age Analysis (SEGAA) model. The experiments suggest that Multi-output models perform comparably to individual models, efficiently capturing the intricate relationships between variables and speech inputs, all while achieving improved runtime.\n    ",
        "primary_category": "eess.AS",
        "categories": [
            "cs.AI",
            "cs.CL",
            "cs.LG",
            "cs.SD"
        ],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00888": {
        "title": "Margin Discrepancy-based Adversarial Training for Multi-Domain Text Classification",
        "authors": [
            "Yuan Wu"
        ],
        "comments": "16 pages",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "Multi-domain text classification (MDTC) endeavors to harness available resources from correlated domains to enhance the classification accuracy of the target domain. Presently, most MDTC approaches that embrace adversarial training and the shared-private paradigm exhibit cutting-edge performance. Unfortunately, these methods face a non-negligible challenge: the absence of theoretical guarantees in the design of MDTC algorithms. The dearth of theoretical underpinning poses a substantial impediment to the advancement of MDTC algorithms. To tackle this problem, we first provide a theoretical analysis of MDTC by decomposing the MDTC task into multiple domain adaptation tasks. We incorporate the margin discrepancy as the measure of domain divergence and establish a new generalization bound based on Rademacher complexity. Subsequently, we propose a margin discrepancy-based adversarial training (MDAT) approach for MDTC, in accordance with our theoretical analysis. To validate the efficacy of the proposed MDAT method, we conduct empirical studies on two MDTC benchmarks. The experimental results demonstrate that our MDAT approach surpasses state-of-the-art baselines on both datasets.\n    ",
        "primary_category": "cs.CL",
        "categories": [
            "cs.LG"
        ],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00889": {
        "title": "Time-bound Contextual Bio-ID Generation for Minimalist Wearables",
        "authors": [
            "Adiba Orzikulova",
            "Diana A. Vasile",
            "Fahim Kawsar",
            "Chulhong Min"
        ],
        "comments": " ",
        "subjects": "Cryptography and Security (cs.CR)",
        "abstract": "As wearable devices become increasingly miniaturized and powerful, a new opportunity arises for instant and dynamic device-to-device collaboration and human-to-device interaction. However, this progress presents a unique challenge: these minimalist wearables lack inherent mechanisms for real-time authentication, posing significant risks to data privacy and overall security. To address this, we introduce Proteus that realizes an innovative concept of time-bound contextual bio-IDs, which are generated from on-device sensor data and embedded into a common latent space. These bio-IDs act as a time-bound unique user identifier that can be used to identify the wearer in a certain context. Proteus enables dynamic and contextual device collaboration as well as robust human-to-device interaction. Our evaluations demonstrate the effectiveness of our method, particularly in the context of minimalist wearables.\n    ",
        "primary_category": "cs.CR",
        "categories": [
            "cs.LG",
            "eess.SP"
        ],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00891": {
        "title": "A Regularization-based Transfer Learning Method for Information Extraction via Instructed Graph Decoder",
        "authors": [
            "Kedi Chen",
            "Jie Zhou",
            "Qin Chen",
            "Shunyu Liu",
            "Liang He"
        ],
        "comments": " ",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Information extraction (IE) aims to extract complex structured information from the text. Numerous datasets have been constructed for various IE tasks, leading to time-consuming and labor-intensive data annotations. Nevertheless, most prevailing methods focus on training task-specific models, while the common knowledge among different IE tasks is not explicitly modeled. Moreover, the same phrase may have inconsistent labels in different tasks, which poses a big challenge for knowledge transfer using a unified model. In this study, we propose a regularization-based transfer learning method for IE (TIE) via an instructed graph decoder. Specifically, we first construct an instruction pool for datasets from all well-known IE tasks, and then present an instructed graph decoder, which decodes various complex structures into a graph uniformly based on corresponding instructions. In this way, the common knowledge shared with existing datasets can be learned and transferred to a new dataset with new labels. Furthermore, to alleviate the label inconsistency problem among various IE tasks, we introduce a task-specific regularization strategy, which does not update the gradients of two tasks with 'opposite direction'. We conduct extensive experiments on 12 datasets spanning four IE tasks, and the results demonstrate the great advantages of our proposed method\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.AI",
            "cs.CL"
        ],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00894": {
        "title": "A systematic evaluation of large language models for generating programming code",
        "authors": [
            "Wenpin Hou",
            "Zhicheng Ji"
        ],
        "comments": " ",
        "subjects": "Software Engineering (cs.SE)",
        "abstract": "We systematically evaluated the performance of seven large language models in generating programming code using various prompt strategies, programming languages, and task difficulties. GPT-4 substantially outperforms other large language models, including Gemini Ultra and Claude 2. The coding performance of GPT-4 varies considerably with different prompt strategies. In most LeetCode and GeeksforGeeks coding contests evaluated in this study, GPT-4 employing the optimal prompt strategy outperforms 85 percent of human participants. Additionally, GPT-4 demonstrates strong capabilities in translating code between different programming languages and in learning from past errors. The computational efficiency of the code generated by GPT-4 is comparable to that of human programmers. These results suggest that GPT-4 has the potential to serve as a reliable assistant in programming code generation and software development.\n    ",
        "primary_category": "cs.SE",
        "categories": [
            "cs.AI",
            "cs.CL",
            "cs.PL"
        ],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00896": {
        "title": "DiaHalu: A Dialogue-level Hallucination Evaluation Benchmark for Large Language Models",
        "authors": [
            "Kedi Chen",
            "Qin Chen",
            "Jie Zhou",
            "Yishen He",
            "Liang He"
        ],
        "comments": " ",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "Since large language models (LLMs) achieve significant success in recent years, the hallucination issue remains a challenge, numerous benchmarks are proposed to detect the hallucination. Nevertheless, some of these benchmarks are not naturally generated by LLMs but are intentionally induced. Also, many merely focus on the factuality hallucination while ignoring the faithfulness hallucination. Additionally, although dialogue pattern is more widely utilized in the era of LLMs, current benchmarks only concentrate on sentence-level and passage-level hallucination. In this study, we propose DiaHalu, the first dialogue-level hallucination evaluation benchmark to our knowledge. Initially, we integrate the collected topics into system prompts and facilitate a dialogue between two ChatGPT3.5. Subsequently, we manually modify the contents that do not adhere to human language conventions and then have LLMs re-generate, simulating authentic human-machine interaction scenarios. Finally, professional scholars annotate all the samples in the dataset. DiaHalu covers four common multi-turn dialogue domains and five hallucination subtypes, extended from factuality and faithfulness hallucination. Experiments through some well-known LLMs and detection methods on the dataset show that DiaHalu is a challenging benchmark, holding significant value for further research.\n    ",
        "primary_category": "cs.CL",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00897": {
        "title": "VisRec: A Semi-Supervised Approach to Radio Interferometric Data Reconstruction",
        "authors": [
            "Ruoqi Wang",
            "Haitao Wang",
            "Qiong Luo",
            "Feng Wang",
            "Hejun Wu"
        ],
        "comments": " ",
        "subjects": "Image and Video Processing (eess.IV)",
        "abstract": "Radio telescopes produce visibility data about celestial objects, but these data are sparse and noisy. As a result, images created on raw visibility data are of low quality. Recent studies have used deep learning models to reconstruct visibility data to get cleaner images. However, these methods rely on a substantial amount of labeled training data, which requires significant labeling effort from radio astronomers. Addressing this challenge, we propose VisRec, a model-agnostic semi-supervised learning approach to the reconstruction of visibility data. Specifically, VisRec consists of both a supervised learning module and an unsupervised learning module. In the supervised learning module, we introduce a set of data augmentation functions to produce diverse training examples. In comparison, the unsupervised learning module in VisRec augments unlabeled data and uses reconstructions from non-augmented visibility data as pseudo-labels for training. This hybrid approach allows VisRec to effectively leverage both labeled and unlabeled data. This way, VisRec performs well even when labeled data is scarce. Our evaluation results show that VisRec outperforms all baseline methods in reconstruction quality, robustness against common observation perturbation, and generalizability to different telescope configurations.\n    ",
        "primary_category": "eess.IV",
        "categories": [
            "astro-ph.GA",
            "cs.AI",
            "cs.CV",
            "cs.LG"
        ],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00898": {
        "title": "The Algorithm Configuration Problem",
        "authors": [
            "Gabriele Iommazzo",
            "Claudia D'Ambrosio",
            "Antonio Frangioni",
            "Leo Liberti"
        ],
        "comments": " ",
        "subjects": "Artificial Intelligence (cs.AI)",
        "abstract": "The field of algorithmic optimization has significantly advanced with the development of methods for the automatic configuration of algorithmic parameters. This article delves into the Algorithm Configuration Problem, focused on optimizing parametrized algorithms for solving specific instances of decision/optimization problems. We present a comprehensive framework that not only formalizes the Algorithm Configuration Problem, but also outlines different approaches for its resolution, leveraging machine learning models and heuristic strategies. The article categorizes existing methodologies into per-instance and per-problem approaches, distinguishing between offline and online strategies for model construction and deployment. By synthesizing these approaches, we aim to provide a clear pathway for both understanding and addressing the complexities inherent in algorithm configuration.\n    ",
        "primary_category": "cs.AI",
        "categories": [
            "cs.LG",
            "math.OC"
        ],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00930": {
        "title": "Scale-free Adversarial Reinforcement Learning",
        "authors": [
            "Mingyu Chen",
            "Xuezhou Zhang"
        ],
        "comments": " ",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "This paper initiates the study of scale-free learning in Markov Decision Processes (MDPs), where the scale of rewards/losses is unknown to the learner. We design a generic algorithmic framework, \\underline{S}cale \\underline{C}lipping \\underline{B}ound (\\texttt{SCB}), and instantiate this framework in both the adversarial Multi-armed Bandit (MAB) setting and the adversarial MDP setting. Through this framework, we achieve the first minimax optimal expected regret bound and the first high-probability regret bound in scale-free adversarial MABs, resolving an open problem raised in \\cite{hadiji2023adaptation}. On adversarial MDPs, our framework also give birth to the first scale-free RL algorithm with a $\\tilde{\\mathcal{O}}(\\sqrt{T})$ high-probability regret guarantee.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00932": {
        "title": "Differentially Private Knowledge Distillation via Synthetic Text Generation",
        "authors": [
            "James Flemings",
            "Murali Annavaram"
        ],
        "comments": " ",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Large Language models (LLMs) are achieving state-of-the-art performance in many different downstream tasks. However, the increasing urgency of data privacy requires LLMs to train with Differential Privacy (DP) on private data. Concurrently it is also necessary to compress LLMs for real-life deployments on resource-constrained devices or latency-sensitive applications. Differential privacy and model compression generally must trade off utility loss to achieve their objectives. Moreover, concurrently achieving both can result in even more utility loss. To this end, we propose a novel differentially private knowledge distillation algorithm that exploits synthetic data generated by a differentially private LLM. The knowledge of a teacher model is transferred onto the student in two ways: one way from the synthetic data itself, the hard labels, and the other way by the output distribution of the teacher model evaluated on the synthetic data, the soft labels. Furthermore, if the teacher and student share a similar architectural structure, we can further distill knowledge by exploiting hidden representations. Our results show that our framework substantially improves the utility over existing baselines with strong privacy parameters, {\\epsilon} = 2, validating that we can successfully compress autoregressive LLMs while preserving the privacy of training data.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.CL",
            "cs.CR"
        ],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00935": {
        "title": "Transfer Learning for Security: Challenges and Future Directions",
        "authors": [
            "Adrian Shuai Li",
            "Arun Iyengar",
            "Ashish Kundu",
            "Elisa Bertino"
        ],
        "comments": " ",
        "subjects": "Cryptography and Security (cs.CR)",
        "abstract": "Many machine learning and data mining algorithms rely on the assumption that the training and testing data share the same feature space and distribution. However, this assumption may not always hold. For instance, there are situations where we need to classify data in one domain, but we only have sufficient training data available from a different domain. The latter data may follow a distinct distribution. In such cases, successfully transferring knowledge across domains can significantly improve learning performance and reduce the need for extensive data labeling efforts. Transfer learning (TL) has thus emerged as a promising framework to tackle this challenge, particularly in security-related tasks. This paper aims to review the current advancements in utilizing TL techniques for security. The paper includes a discussion of the existing research gaps in applying TL in the security domain, as well as exploring potential future research directions and issues that arise in the context of TL-assisted security solutions.\n    ",
        "primary_category": "cs.CR",
        "categories": [
            "cs.LG"
        ],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00942": {
        "title": "Resilience of Entropy Model in Distributed Neural Networks",
        "authors": [
            "Milin Zhang",
            "Mohammad Abdi",
            "Shahriar Rifat",
            "Francesco Restuccia"
        ],
        "comments": " ",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Distributed deep neural networks (DNNs) have emerged as a key technique to reduce communication overhead without sacrificing performance in edge computing systems. Recently, entropy coding has been introduced to further reduce the communication overhead. The key idea is to train the distributed DNN jointly with an entropy model, which is used as side information during inference time to adaptively encode latent representations into bit streams with variable length. To the best of our knowledge, the resilience of entropy models is yet to be investigated. As such, in this paper we formulate and investigate the resilience of entropy models to intentional interference (e.g., adversarial attacks) and unintentional interference (e.g., weather changes and motion blur). Through an extensive experimental campaign with 3 different DNN architectures, 2 entropy models and 4 rate-distortion trade-off factors, we demonstrate that the entropy attacks can increase the communication overhead by up to 95%. By separating compression features in frequency and spatial domain, we propose a new defense mechanism that can reduce the transmission overhead of the attacked input by about 9% compared to unperturbed data, with only about 2% accuracy loss. Importantly, the proposed defense mechanism is a standalone approach which can be applied in conjunction with approaches such as adversarial training to further improve robustness. Code will be shared for reproducibility.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.AI",
            "cs.CR"
        ],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00943": {
        "title": "On the Hardness of Fair Allocation under Ternary Valuations",
        "authors": [
            "Zack Fitzsimmons",
            "Vignesh Viswanathan",
            "Yair Zick"
        ],
        "comments": " ",
        "subjects": "Computer Science and Game Theory (cs.GT)",
        "abstract": "We study the problem of fair allocation of indivisible items when agents have ternary additive valuations -- each agent values each item at some fixed integer values $a$, $b$, or $c$ that are common to all agents. The notions of fairness we consider are max Nash welfare (MNW), when $a$, $b$, and $c$ are non-negative, and max egalitarian welfare (MEW). We show that for any distinct non-negative $a$, $b$, and $c$, maximizing Nash welfare is APX-hard -- i.e., the problem does not admit a PTAS unless P = NP. We also show that for any distinct $a$, $b$, and $c$, maximizing egalitarian welfare is APX-hard except for a few cases when $b = 0$ that admit efficient algorithms. These results make significant progress towards completely characterizing the complexity of computing exact MNW allocations and MEW allocations. En route, we resolve open questions left by prior work regarding the complexity of computing MNW allocations under bivalued valuations, and MEW allocations under ternary mixed manna.\n    ",
        "primary_category": "cs.GT",
        "categories": [],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00944": {
        "title": "Optimizing Dynamic Balance in a Rat Robot via the Lateral Flexion of a Soft Actuated Spine",
        "authors": [
            "Yuhong Huang",
            "Zhenshan Bing",
            "Zitao Zhang",
            "Genghang Zhuang",
            "Kai Huang",
            "Alois Knoll"
        ],
        "comments": " ",
        "subjects": "Robotics (cs.RO)",
        "abstract": "Balancing oneself using the spine is a physiological alignment of the body posture in the most efficient manner by the muscular forces for mammals. For this reason, we can see many disabled quadruped animals can still stand or walk even with three limbs. This paper investigates the optimization of dynamic balance during trot gait based on the spatial relationship between the center of mass (CoM) and support area influenced by spinal flexion. During trotting, the robot balance is significantly influenced by the distance of the CoM to the support area formed by diagonal footholds. In this context, lateral spinal flexion, which is able to modify the position of footholds, holds promise for optimizing balance during trotting. This paper explores this phenomenon using a rat robot equipped with a soft actuated spine. Based on the lateral flexion of the spine, we establish a kinematic model to quantify the impact of spinal flexion on robot balance during trot gait. Subsequently, we develop an optimized controller for spinal flexion, designed to enhance balance without altering the leg locomotion. The effectiveness of our proposed controller is evaluated through extensive simulations and physical experiments conducted on a rat robot. Compared to both a non-spine based trot gait controller and a trot gait controller with lateral spinal flexion, our proposed optimized controller effectively improves the dynamic balance of the robot and retains the desired locomotion during trotting.\n    ",
        "primary_category": "cs.RO",
        "categories": [],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00946": {
        "title": "Fine-tuning with Very Large Dropout",
        "authors": [
            "Jianyu Zhang",
            "L\u00e9on Bottou"
        ],
        "comments": "13 pages",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "It is impossible today to pretend that the practice of machine learning is compatible with the idea that training and testing data follow the same distribution. Several authors have recently used ensemble techniques to show how scenarios involving multiple data distributions are best served by representations that are both richer than those obtained by regularizing for the best in-distribution performance, and richer than those obtained under the influence of the implicit sparsity bias of common stochastic gradient procedures.\nThis contribution investigates the use of very high dropout rates instead of ensembles to obtain such rich representations. Although training a deep network from scratch using such dropout rates is virtually impossible, fine-tuning a large pre-trained model under such conditions is not only possible but also achieves out-of-distribution performances that exceed those of both ensembles and weight averaging methods such as model soups. This result has practical significance because the importance of the fine-tuning scenario has considerably grown in recent years. This result also provides interesting insights on the nature of rich representations and on the intrinsically linear nature of fine-tuning a large network using a comparatively small dataset.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.CV"
        ],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00952": {
        "title": "MediSwift: Efficient Sparse Pre-trained Biomedical Language Models",
        "authors": [
            "Vithursan Thangarasa",
            "Mahmoud Salem",
            "Shreyas Saxena",
            "Kevin Leong",
            "Joel Hestness",
            "Sean Lie"
        ],
        "comments": " ",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "Large language models (LLMs) are typically trained on general source data for various domains, but a recent surge in domain-specific LLMs has shown their potential to outperform general-purpose models in domain-specific tasks (e.g., biomedicine). Although domain-specific pre-training enhances efficiency and leads to smaller models, the computational costs of training these LLMs remain high, posing budgeting challenges. We introduce MediSwift, a suite of biomedical LMs that leverage sparse pre-training on domain-specific biomedical text data. By inducing up to 75% weight sparsity during the pre-training phase, MediSwift achieves a 2-2.5x reduction in training FLOPs. Notably, all sparse pre-training was performed on the Cerebras CS-2 system, which is specifically designed to realize the acceleration benefits from unstructured weight sparsity, thereby significantly enhancing the efficiency of the MediSwift models. Through subsequent dense fine-tuning and strategic soft prompting, MediSwift models outperform existing LLMs up to 7B parameters on biomedical tasks, setting new benchmarks w.r.t efficiency-accuracy on tasks such as PubMedQA. Our results show that sparse pre-training, along with dense fine-tuning and soft prompting, offers an effective method for creating high-performing, computationally efficient models in specialized domains.\n    ",
        "primary_category": "cs.CL",
        "categories": [
            "cs.LG"
        ],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00953": {
        "title": "AutoRD: An Automatic and End-to-End System for Rare Disease Knowledge Graph Construction Based on Ontologies-enhanced Large Language Models",
        "authors": [
            "Lang Cao",
            "Jimeng Sun",
            "Adam Cross"
        ],
        "comments": " ",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "Objectives: Our objective is to create an end-to-end system called AutoRD, which automates extracting information from clinical text about rare diseases. We have conducted various tests to evaluate the performance of AutoRD and highlighted its strengths and limitations in this paper.\nMaterials and Methods: Our system, AutoRD, is a software pipeline involving data preprocessing, entity extraction, relation extraction, entity calibration, and knowledge graph construction. We implement this using large language models and medical knowledge graphs developed from open-source medical ontologies. We quantitatively evaluate our system on entity extraction, relation extraction, and the performance of knowledge graph construction.\nResults: AutoRD achieves an overall F1 score of 47.3%, a 14.4% improvement compared to the base LLM. In detail, AutoRD achieves an overall entity extraction F1 score of 56.1% (rare_disease: 83.5%, disease: 35.8%, symptom_and_sign: 46.1%, anaphor: 67.5%) and an overall relation extraction F1 score of 38.6% (produces: 34.7%, increases_risk_of: 12.4%, is_a: 37.4%, is_acronym: 44.1%, is_synonym: 16.3%, anaphora: 57.5%). Our qualitative experiment also demonstrates that the performance in constructing the knowledge graph is commendable.\nDiscussion: AutoRD demonstrates the potential of LLM applications in rare disease detection. This improvement is attributed to several design, including the integration of ontologies-enhanced LLMs.\nConclusion: AutoRD is an automated end-to-end system for extracting rare disease information from text to build knowledge graphs. It uses ontologies-enhanced LLMs for a robust medical knowledge base. The superior performance of AutoRD is validated by experimental evaluations, demonstrating the potential of LLMs in healthcare.\n    ",
        "primary_category": "cs.CL",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00954": {
        "title": "ClassInSight: Designing Conversation Support Tools to Visualize Classroom Discussion for Personalized Teacher Professional Development",
        "authors": [
            "Tricia J. Ngoon",
            "S Sushil",
            "Angela Stewart",
            "Ung-Sang Lee",
            "Saranya Venkatraman",
            "Neil Thawani",
            "Prasenjit Mitra",
            "Sherice Clarke",
            "John Zimmerman",
            "Amy Ogan"
        ],
        "comments": " ",
        "subjects": "Human-Computer Interaction (cs.HC)",
        "abstract": "Teaching is one of many professions for which personalized feedback and reflection can help improve dialogue and discussion between the professional and those they serve. However, professional development (PD) is often impersonal as human observation is labor-intensive. Data-driven PD tools in teaching are of growing interest, but open questions about how professionals engage with their data in practice remain. In this paper, we present ClassInSight, a tool that visualizes three levels of teachers' discussion data and structures reflection. Through 22 reflection sessions and interviews with 5 high school science teachers, we found themes related to dissonance, contextualization, and sustainability in how teachers engaged with their data in the tool and in how their professional vision, the use of professional expertise to interpret events, shifted over time. We discuss guidelines for these conversational support tools to support personalized PD in professions beyond teaching where conversation and interaction are important.\n    ",
        "primary_category": "cs.HC",
        "categories": [],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00955": {
        "title": "The Presence and the State-of-Practice of Software Architects in the Brazilian Industry -- A Survey",
        "authors": [
            "Valdemar Vicente Graciano Neto",
            "Diana Lorena Santos",
            "Andrey Gon\u00e7alves Fran\u00e7a",
            "Rafael Z. Frantz",
            "Edson de Oliveira-Jr",
            "Ahmad Mohsin",
            "Mohamad Kassab"
        ],
        "comments": " ",
        "subjects": "Software Engineering (cs.SE)",
        "abstract": "Context: Software architecture intensely impacts the software quality. Therefore, the professional assigned to carry out the design, maintenance and evolution of architectures needs to have certain knowledge and skills in order not to compromise the resulting application. Objective: The aim of this work is to understand the characteristics of the companies regarding the presence or absence of software architects in Brazil. Method: This work uses the Survey research as a means to collect evidence from professionals with the software architect profile, besides descriptive statistics and thematic analysis to analyze the results. Results: The study collected data from 105 professionals distributed in 24 Brazilian states. Results reveal that (i) not all companies have a software architect, (ii) in some cases, other professionals perform the activities of a software architect and (iii) there are companies that, even having a software architecture professional, have other roles also performing the duties of such a professional. Conclusions: Professionals hired as software architects have higher salaries than those hired in other roles that carry out such activity, although many of those other professionals still have duties that are typical of software architects.\n    ",
        "primary_category": "cs.SE",
        "categories": [],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00956": {
        "title": "Suturing Tasks Automation Based on Skills Learned From Demonstrations: A Simulation Study",
        "authors": [
            "Haoying Zhou",
            "Yiwei Jiang",
            "Shang Gao",
            "Shiyue Wang",
            "Peter Kazanzides",
            "Gregory S. Fischer"
        ],
        "comments": " ",
        "subjects": "Robotics (cs.RO)",
        "abstract": "In this work, we develop an open-source surgical simulation environment that includes a realistic model obtained by MRI-scanning a physical phantom, for the purpose of training and evaluating a Learning from Demonstration (LfD) algorithm for autonomous suturing. The LfD algorithm utilizes Dynamic Movement Primitives (DMP) and Locally Weighted Regression (LWR), but focuses on the needle trajectory, rather than the instruments, to obtain better generality with respect to needle grasps. We conduct a user study to collect multiple suturing demonstrations and perform a comprehensive analysis of the ability of the LfD algorithm to generalize from a demonstration at one location in one phantom to different locations in the same phantom and to a different phantom. Our results indicate good generalization, on the order of 91.5%, when learning from more experienced subjects, indicating the need to integrate skill assessment in the future.\n    ",
        "primary_category": "cs.RO",
        "categories": [],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00961": {
        "title": "Data Science Education in Undergraduate Physics: Lessons Learned from a Community of Practice",
        "authors": [
            "Karan Shah",
            "Julie Butler",
            "Alexis Knaub",
            "An\u0131l Zengino\u011flu",
            "William Ratcliff",
            "Mohammad Soltanieh-ha"
        ],
        "comments": "21 pages, 4 figures, 2 tables. The associated GItHub repository can be found at this https URL",
        "subjects": "Physics Education (physics.ed-ph)",
        "abstract": "With the increasing availability of diverse datasets, ranging from small-scale experimental data points to large and complex data repositories and powerful data analysis tools, it is increasingly important that physics educators equip their students with the skills to work with data effectively. However, many educators may lack the necessary training and expertise in data science to teach these skills. To address this gap, we created the Data Science Education Community of Practice (DSECOP), bringing together graduate students and physics educators from different institutions and backgrounds to share best practices and lessons learned in integrating data science into undergraduate physics education. In this article, we present insights and experiences from this community of practice, highlighting key strategies and challenges in incorporating data science into the introductory physics curriculum. Our goal is to provide guidance and inspiration to educators who seek to integrate data science into their teaching, helping to prepare the next generation of physicists for a data-driven world.\n    ",
        "primary_category": "physics.ed-ph",
        "categories": [
            "cs.LG",
            "physics.data-an"
        ],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00963": {
        "title": "Tree-Regularized Tabular Embeddings",
        "authors": [
            "Xuan Li",
            "Yun Wang",
            "Bo Li"
        ],
        "comments": "Table Representation Learning Workshop at NeurIPS 2023",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Tabular neural network (NN) has attracted remarkable attentions and its recent advances have gradually narrowed the performance gap with respect to tree-based models on many public datasets. While the mainstreams focus on calibrating NN to fit tabular data, we emphasize the importance of homogeneous embeddings and alternately concentrate on regularizing tabular inputs through supervised pretraining. Specifically, we extend a recent work (DeepTLF) and utilize the structure of pretrained tree ensembles to transform raw variables into a single vector (T2V), or an array of tokens (T2T). Without loss of space efficiency, these binarized embeddings can be consumed by canonical tabular NN with fully-connected or attention-based building blocks. Through quantitative experiments on 88 OpenML datasets with binary classification task, we validated that the proposed tree-regularized representation not only tapers the difference with respect to tree-based models, but also achieves on-par and better performance when compared with advanced NN models. Most importantly, it possesses better robustness and can be easily scaled and generalized as standalone encoder for tabular modality. Codes: this https URL.\n    ",
        "primary_category": "cs.LG",
        "categories": [],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00964": {
        "title": "MALTO at SemEval-2024 Task 6: Leveraging Synthetic Data for LLM Hallucination Detection",
        "authors": [
            "Federico Borra",
            "Claudio Savelli",
            "Giacomo Rosso",
            "Alkis Koudounas",
            "Flavio Giobergia"
        ],
        "comments": "Under revision at SemEval 2024",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "In Natural Language Generation (NLG), contemporary Large Language Models (LLMs) face several challenges, such as generating fluent yet inaccurate outputs and reliance on fluency-centric metrics. This often leads to neural networks exhibiting \"hallucinations\". The SHROOM challenge focuses on automatically identifying these hallucinations in the generated text. To tackle these issues, we introduce two key components, a data augmentation pipeline incorporating LLM-assisted pseudo-labelling and sentence rephrasing, and a voting ensemble from three models pre-trained on Natural Language Inference (NLI) tasks and fine-tuned on diverse datasets.\n    ",
        "primary_category": "cs.CL",
        "categories": [
            "cs.LG"
        ],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00965": {
        "title": "Binary Gaussian Copula Synthesis: A Novel Data Augmentation Technique to Advance ML-based Clinical Decision Support Systems for Early Prediction of Dialysis Among CKD Patients",
        "authors": [
            "Hamed Khosravi",
            "Srinjoy Das",
            "Abdullah Al-Mamun",
            "Imtiaz Ahmed"
        ],
        "comments": " ",
        "subjects": "Applications (stat.AP)",
        "abstract": "The Center for Disease Control estimates that over 37 million US adults suffer from chronic kidney disease (CKD), yet 9 out of 10 of these individuals are unaware of their condition due to the absence of symptoms in the early stages. It has a significant impact on patients' quality of life, particularly when it progresses to the need for dialysis. Early prediction of dialysis is crucial as it can significantly improve patient outcomes and assist healthcare providers in making timely and informed decisions. However, developing an effective machine learning (ML)-based Clinical Decision Support System (CDSS) for early dialysis prediction poses a key challenge due to the imbalanced nature of data. To address this challenge, this study evaluates various data augmentation techniques to understand their effectiveness on real-world datasets. We propose a new approach named Binary Gaussian Copula Synthesis (BGCS). BGCS is tailored for binary medical datasets and excels in generating synthetic minority data that mirrors the distribution of the original data. BGCS enhances early dialysis prediction by outperforming traditional methods in detecting dialysis patients. For the best ML model, Random Forest, BCGS achieved a 72% improvement, surpassing the state-of-the-art augmentation approaches. Also, we present a ML-based CDSS, designed to aid clinicians in making informed decisions. CDSS, which utilizes decision tree models, is developed to improve patient outcomes, identify critical variables, and thereby enable clinicians to make proactive decisions, and strategize treatment plans effectively for CKD patients who are more likely to require dialysis in the near future. Through comprehensive feature analysis and meticulous data preparation, we ensure that the CDSS's dialysis predictions are not only accurate but also actionable, providing a valuable tool in the management and treatment of CKD.\n    ",
        "primary_category": "stat.AP",
        "categories": [
            "cs.AI",
            "cs.LG"
        ],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00970": {
        "title": "Nussbaum Function Based Approach for Tracking Control of Robot Manipulators",
        "authors": [
            "Hamed Rahimi Nohooji",
            "Holger Voos"
        ],
        "comments": "6 pages, 5 figures, conference paper",
        "subjects": "Robotics (cs.RO)",
        "abstract": "This paper introduces a novel Nussbaum function-based PID control for robotic manipulators. The integration of the Nussbaum function into the PID framework provides a solution with a simple structure that effectively tackles the challenge of unknown control directions. Stability is achieved through a combination of neural network-based estimation and Lyapunov analysis, facilitating automatic gain adjustment without the need for system dynamics. Our approach offers a gain determination with minimum parameter requirements, significantly reducing the complexity and enhancing the efficiency of robotic manipulator control. The paper guarantees that all signals within the closed-loop system remain bounded. Lastly, numerical simulations validate the theoretical framework, confirming the effectiveness of the proposed control strategy in enhancing robotic manipulator control.\n    ",
        "primary_category": "cs.RO",
        "categories": [
            "eess.SY"
        ],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00971": {
        "title": "The sequence of pseudo-equilibria describes the long-time behaviour of the NNLIF model with large delay",
        "authors": [
            "Mar\u00eda J. C\u00e1ceres",
            "Jos\u00e9 A. Ca\u00f1izo",
            "Alejandro Ramos-Lora"
        ],
        "comments": " ",
        "subjects": "Analysis of PDEs (math.AP)",
        "abstract": "There is a wide range of mathematical models that describe populations of large numbers of neurons. In this article, we focus on nonlinear noisy leaky integrate and fire (NNLIF) models that describe neuronal activity at the level of the membrane potential of neurons. We introduce a set of novel states, which we call \"pseudo-equilibria\", and give evidence of their defining role in the behaviour of the NNLIF system when a significant synaptic delay is considered. The advantage is that these states are determined solely by the system's parameters and are derived from a sequence of firing rates that result from solving a recurrence equation. We propose a new strategy to show convergence to an equilibrium for a weakly connected system with large transmission delay, based on following the sequence of pseudo-equilibria. Unlike with the direct entropy dissipation method, this technique allows us to see how a large delay favours convergence. We also present a detailed numerical study to support our results. This study explores the overall behaviour of the NNLIF system and helps us understand, among other phenomena, periodic solutions in strongly inhibitory networks.\n    ",
        "primary_category": "math.AP",
        "categories": [
            "math.NA"
        ],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00972": {
        "title": "Understanding Police Force Resource Allocation using Adversarial Optimal Transport with Incomplete Information",
        "authors": [
            "Yinan Hu",
            "Juntao Chen",
            "Quanyan Zhu"
        ],
        "comments": " ",
        "subjects": "Computer Science and Game Theory (cs.GT)",
        "abstract": "Adversarial optimal transport has been proven useful as a mathematical formulation to model resource allocation problems to maximize the efficiency of transportation with an adversary, who modifies the data. It is often the case, however, that only the adversary knows which nodes are malicious and which are not. In this paper we formulate the problem of seeking adversarial optimal transport into Bayesian games. We construct the concept of Bayesian equilibrium and design a distributed algorithm that achieve those equilibria, making our model applicable to large-scale networks. Keywords: game theory, crime control, Markov games\n    ",
        "primary_category": "cs.GT",
        "categories": [
            "eess.SY"
        ],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00974": {
        "title": "Motif distribution and function of sparse deep neural networks",
        "authors": [
            "Olivia T. Zahn",
            "Thomas L. Daniel",
            "J. Nathan Kutz"
        ],
        "comments": " ",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "We characterize the connectivity structure of feed-forward, deep neural networks (DNNs) using network motif theory. To address whether a particular motif distribution is characteristic of the training task, or function of the DNN, we compare the connectivity structure of 350 DNNs trained to simulate a bio-mechanical flight control system with different randomly initialized parameters. We develop and implement algorithms for counting second- and third-order motifs and calculate their significance using their Z-score. The DNNs are trained to solve the inverse problem of the flight dynamics model in Bustamante, et al. (2022) (i.e., predict the controls necessary for controlled flight from the initial and final state-space inputs) and are sparsified through an iterative pruning and retraining algorithm Zahn, et al. (2022). We show that, despite random initialization of network parameters, enforced sparsity causes DNNs to converge to similar connectivity patterns as characterized by their motif distributions. The results suggest how neural network function can be encoded in motif distributions, suggesting a variety of experiments for informing function and control.\n    ",
        "primary_category": "cs.LG",
        "categories": [],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00975": {
        "title": "Equipment Health Assessment: Time Series Analysis for Wind Turbine Performance",
        "authors": [
            "Jana Backhus",
            "Aniruddha Rajendra Rao",
            "Chandrasekar Venkatraman",
            "Abhishek Padmanabhan",
            "A.Vinoth Kumar",
            "Chetan Gupta"
        ],
        "comments": "19 Pages, 17 Figures, 3 Tables, Submitted at Applied Sciences (MDPI)",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "In this study, we leverage SCADA data from diverse wind turbines to predict power output, employing advanced time series methods, specifically Functional Neural Networks (FNN) and Long Short-Term Memory (LSTM) networks. A key innovation lies in the ensemble of FNN and LSTM models, capitalizing on their collective learning. This ensemble approach outperforms individual models, ensuring stable and accurate power output predictions. Additionally, machine learning techniques are applied to detect wind turbine performance deterioration, enabling proactive maintenance strategies and health assessment. Crucially, our analysis reveals the uniqueness of each wind turbine, necessitating tailored models for optimal predictions. These insight underscores the importance of providing automatized customization for different turbines to keep human modeling effort low. Importantly, the methodologies developed in this analysis are not limited to wind turbines; they can be extended to predict and optimize performance in various machinery, highlighting the versatility and applicability of our research across diverse industrial contexts.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.AI",
            "math.FA",
            "stat.AP"
        ],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00976": {
        "title": "Joint Spatial-Temporal Calibration for Camera and Global Pose Sensor",
        "authors": [
            "Junlin Song",
            "Antoine Richard",
            "Miguel Olivares-Mendez"
        ],
        "comments": "Accepted by 3DV 2024",
        "subjects": "Robotics (cs.RO)",
        "abstract": "In robotics, motion capture systems have been widely used to measure the accuracy of localization algorithms. Moreover, this infrastructure can also be used for other computer vision tasks, such as the evaluation of Visual (-Inertial) SLAM dynamic initialization, multi-object tracking, or automatic annotation. Yet, to work optimally, these functionalities require having accurate and reliable spatial-temporal calibration parameters between the camera and the global pose sensor. In this study, we provide two novel solutions to estimate these calibration parameters. Firstly, we design an offline target-based method with high accuracy and consistency. Spatial-temporal parameters, camera intrinsic, and trajectory are optimized simultaneously. Then, we propose an online target-less method, eliminating the need for a calibration target and enabling the estimation of time-varying spatial-temporal parameters. Additionally, we perform detailed observability analysis for the target-less method. Our theoretical findings regarding observability are validated by simulation experiments and provide explainable guidelines for calibration. Finally, the accuracy and consistency of two proposed methods are evaluated with hand-held real-world datasets where traditional hand-eye calibration method do not work.\n    ",
        "primary_category": "cs.RO",
        "categories": [
            "cs.CV"
        ],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00977": {
        "title": "Scaling Up Adaptive Filter Optimizers",
        "authors": [
            "Jonah Casebeer",
            "Nicholas J. Bryan",
            "Paris Smaragdis"
        ],
        "comments": " ",
        "subjects": "Sound (cs.SD)",
        "abstract": "We introduce a new online adaptive filtering method called supervised multi-step adaptive filters (SMS-AF). Our method uses neural networks to control or optimize linear multi-delay or multi-channel frequency-domain filters and can flexibly scale-up performance at the cost of increased compute -- a property rarely addressed in the AF literature, but critical for many applications. To do so, we extend recent work with a set of improvements including feature pruning, a supervised loss, and multiple optimization steps per time-frame. These improvements work in a cohesive manner to unlock scaling. Furthermore, we show how our method relates to Kalman filtering and meta-adaptive filtering, making it seamlessly applicable to a diverse set of AF tasks. We evaluate our method on acoustic echo cancellation (AEC) and multi-channel speech enhancement tasks and compare against several baselines on standard synthetic and real-world datasets. Results show our method performance scales with inference cost and model capacity, yields multi-dB performance gains for both tasks, and is real-time capable on a single CPU core.\n    ",
        "primary_category": "cs.SD",
        "categories": [
            "eess.AS"
        ],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00981": {
        "title": "A Conceptual Model for Data Storytelling Highlights in Business Intelligence Environments",
        "authors": [
            "Panos Vassiliadis",
            "Patrick Marcel",
            "Faten El Outa",
            "Veronika Peralta",
            "Dimos Gkitsakis"
        ],
        "comments": "16 pages, 4 figures",
        "subjects": "Databases (cs.DB)",
        "abstract": "We introduce a conceptual model for highlights to support data analysis and storytelling in the domain of Business Intelligence, via the automated extraction, representation, and exploitation of highlights revealing key facts that are hidden in the data with which a data analyst works. The model builds on the concepts of Holistic and Elementary Highlights, along with their context, constituents and interrelationships, whose synergy can identify internal properties, patterns and key facts in a dataset being analyzed.\n    ",
        "primary_category": "cs.DB",
        "categories": [],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00982": {
        "title": "LocalRQA: From Generating Data to Locally Training, Testing, and Deploying Retrieval-Augmented QA Systems",
        "authors": [
            "Xiao Yu",
            "Yunan Lu",
            "Zhou Yu"
        ],
        "comments": " ",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "Retrieval-augmented question-answering systems combine retrieval techniques with large language models to provide answers that are more accurate and informative. Many existing toolkits allow users to quickly build such systems using off-the-shelf models, but they fall short in supporting researchers and developers to customize the model training, testing, and deployment process. We propose LocalRQA, an open-source toolkit that features a wide selection of model training algorithms, evaluation methods, and deployment tools curated from the latest research. As a showcase, we build QA systems using online documentation obtained from Databricks and Faire's websites. We find 7B-models trained and deployed using LocalRQA reach a similar performance compared to using OpenAI's text-ada-002 and GPT-4-turbo.\n    ",
        "primary_category": "cs.CL",
        "categories": [],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00987": {
        "title": "Composite Distributed Learning and Synchronization of Nonlinear Multi-Agent Systems with Complete Uncertain Dynamics",
        "authors": [
            "Emadodin Jandaghi",
            "Dalton L. Stein",
            "Adam Hoburg",
            "Mingxi Zhou",
            "Chengzhi Yuan"
        ],
        "comments": " ",
        "subjects": "Multiagent Systems (cs.MA)",
        "abstract": "This paper addresses the challenging problem of composite synchronization and learning control in a network of multi-agent robotic manipulator systems operating under heterogeneous nonlinear uncertainties within a leader-follower framework. A novel two-layer distributed adaptive learning control strategy is introduced, comprising a first-layer distributed cooperative estimator and a second-layer decentralized deterministic learning controller. The primary objective of the first layer is to facilitate each robotic agent's estimation of the leader's information. The second layer is responsible for both enabling individual robot agents to track desired reference trajectories and accurately identifying and learning their nonlinear uncertain dynamics. The proposed distributed learning control scheme represents an advancement in the existing literature due to its ability to manage robotic agents with completely uncertain dynamics including uncertain mass matrices. This framework allows the robotic control to be environment-independent which can be used in various settings, from underwater to space where identifying system dynamics parameters is challenging. The stability and parameter convergence of the closed-loop system are rigorously analyzed using the Lyapunov method. Numerical simulations conducted on multi-agent robot manipulators validate the effectiveness of the proposed scheme. The identified nonlinear dynamics can be saved and reused whenever the system restarts.\n    ",
        "primary_category": "cs.MA",
        "categories": [
            "cs.RO",
            "eess.SY"
        ],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00988": {
        "title": "Optimal Robot Formations: Balancing Range-Based Observability and User-Defined Configurations",
        "authors": [
            "Syed Shabbir Ahmed",
            "Mohammed Ayman Shalaby",
            "Jerome Le Ny",
            "James Richard Forbes"
        ],
        "comments": "8 pages, 9 figures, submitted to IEEE International Conference on Intelligent Robots and Systems 2024",
        "subjects": "Robotics (cs.RO)",
        "abstract": "This paper introduces a set of customizable and novel cost functions that enable the user to easily specify desirable robot formations, such as a ``high-coverage'' infrastructure-inspection formation, while maintaining high relative pose estimation accuracy. The overall cost function balances the need for the robots to be close together for good ranging-based relative localization accuracy and the need for the robots to achieve specific tasks, such as minimizing the time taken to inspect a given area. The formations found by minimizing the aggregated cost function are evaluated in a coverage path planning task in simulation and experiment, where the robots localize themselves and unknown landmarks using a simultaneous localization and mapping algorithm based on the extended Kalman filter. Compared to an optimal formation that maximizes ranging-based relative localization accuracy, these formations significantly reduce the time to cover a given area with minimal impact on relative pose estimation accuracy.\n    ",
        "primary_category": "cs.RO",
        "categories": [],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00989": {
        "title": "On Non-Interactive Simulation of Distributed Sources with Finite Alphabets",
        "authors": [
            "Hojat Allah Salehi",
            "Farhad Shirani"
        ],
        "comments": " ",
        "subjects": "Information Theory (cs.IT)",
        "abstract": "This work presents a Fourier analysis framework for the non-interactive source simulation (NISS) problem. Two distributed agents observe a pair of sequences $X^d$ and $Y^d$ drawn according to a joint distribution $P_{X^dY^d}$. The agents aim to generate outputs $U=f_d(X^d)$ and $V=g_d(Y^d)$ with a joint distribution sufficiently close in total variation to a target distribution $Q_{UV}$. Existing works have shown that the NISS problem with finite-alphabet outputs is decidable. For the binary-output NISS, an upper-bound to the input complexity was derived which is $O(\\exp\\operatorname{poly}(\\frac{1}{\\epsilon}))$. In this work, the input complexity and algorithm design are addressed in several classes of NISS scenarios. For binary-output NISS scenarios with doubly-symmetric binary inputs, it is shown that the input complexity is $\\Theta(\\log{\\frac{1}{\\epsilon}})$, thus providing a super-exponential improvement in input complexity. An explicit characterization of the simulating pair of functions is provided. For general finite-input scenarios, a constructive algorithm is introduced that explicitly finds the simulating functions $(f_d(X^d),g_d(Y^d))$. The approach relies on a novel Fourier analysis framework. Various numerical simulations of NISS scenarios with IID inputs are provided. Furthermore, to illustrate the general applicability of the Fourier framework, several examples with non-IID inputs, including entanglement-assisted NISS and NISS with Markovian inputs are provided.\n    ",
        "primary_category": "cs.IT",
        "categories": [
            "cs.CR",
            "eess.SP",
            "math.PR"
        ],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00990": {
        "title": "Formulation Comparison for Timeline Construction using LLMs",
        "authors": [
            "Kimihiro Hasegawa",
            "Nikhil Kandukuri",
            "Susan Holm",
            "Yukari Yamakawa",
            "Teruko Mitamura"
        ],
        "comments": " ",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "Constructing a timeline requires identifying the chronological order of events in an article. In prior timeline construction datasets, temporal orders are typically annotated by either event-to-time anchoring or event-to-event pairwise ordering, both of which suffer from missing temporal information. To mitigate the issue, we develop a new evaluation dataset, TimeSET, consisting of single-document timelines with document-level order annotation. TimeSET features saliency-based event selection and partial ordering, which enable a practical annotation workload. Aiming to build better automatic timeline construction systems, we propose a novel evaluation framework to compare multiple task formulations with TimeSET by prompting open LLMs, i.e., Llama 2 and Flan-T5. Considering that identifying temporal orders of events is a core subtask in timeline construction, we further benchmark open LLMs on existing event temporal ordering datasets to gain a robust understanding of their capabilities. Our experiments show that (1) NLI formulation with Flan-T5 demonstrates a strong performance among others, while (2) timeline construction and event temporal ordering are still challenging tasks for few-shot LLMs. Our code and data are available at this https URL.\n    ",
        "primary_category": "cs.CL",
        "categories": [],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00991": {
        "title": "SELFI: Autonomous Self-Improvement with Reinforcement Learning for Social Navigation",
        "authors": [
            "Noriaki Hirose",
            "Dhruv Shah",
            "Kyle Stachowicz",
            "Ajay Sridhar",
            "Sergey Levine"
        ],
        "comments": "11pages, 13 figures, 2 tables",
        "subjects": "Robotics (cs.RO)",
        "abstract": "Autonomous self-improving robots that interact and improve with experience are key to the real-world deployment of robotic systems. In this paper, we propose an online learning method, SELFI, that leverages online robot experience to rapidly fine-tune pre-trained control policies efficiently. SELFI applies online model-free reinforcement learning on top of offline model-based learning to bring out the best parts of both learning paradigms. Specifically, SELFI stabilizes the online learning process by incorporating the same model-based learning objective from offline pre-training into the Q-values learned with online model-free reinforcement learning. We evaluate SELFI in multiple real-world environments and report improvements in terms of collision avoidance, as well as more socially compliant behavior, measured by a human user study. SELFI enables us to quickly learn useful robotic behaviors with less human interventions such as pre-emptive behavior for the pedestrians, collision avoidance for small and transparent objects, and avoiding travel on uneven floor surfaces. We provide supplementary videos to demonstrate the performance of our fine-tuned policy on our project page.\n    ",
        "primary_category": "cs.RO",
        "categories": [
            "cs.CV",
            "cs.LG"
        ],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00992": {
        "title": "Introducing a Novel Quantum-Resistant Secret Key Establishment Method",
        "authors": [
            "Luis Adri\u00e1n Lizama-P\u00e9rez"
        ],
        "comments": "7 pages",
        "subjects": "Information Theory (cs.IT)",
        "abstract": "We introduce a new approach for secret key establishment that resists quantum cryptanalysis. The method claims full secrecy as its primary goal. Our approach guarantees private communication at a crucial moment in the quantum revolution. We will discuss how the system achieves homomorphic encryption. Comparatively, our system provides the smallest public and private key sizes available.\n    ",
        "primary_category": "cs.IT",
        "categories": [],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00993": {
        "title": "On the Role of Information Structure in Reinforcement Learning for Partially-Observable Sequential Teams and Games",
        "authors": [
            "Awni Altabaa",
            "Zhuoran Yang"
        ],
        "comments": "57 pages, 5 figures",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "In a sequential decision-making problem, the information structure is the description of how events in the system occurring at different points in time affect each other. Classical models of reinforcement learning (e.g., MDPs, POMDPs, Dec-POMDPs, and POMGs) assume a very simple and highly regular information structure, while more general models like predictive state representations do not explicitly model the information structure. By contrast, real-world sequential decision-making problems typically involve a complex and time-varying interdependence of system variables, requiring a rich and flexible representation of information structure.\nIn this paper, we argue for the perspective that explicit representation of information structures is an important component of analyzing and solving reinforcement learning problems. We propose novel reinforcement learning models with an explicit representation of information structure, capturing classical models as special cases. We show that this leads to a richer analysis of sequential decision-making problems and enables more tailored algorithm design. In particular, we characterize the \"complexity\" of the observable dynamics of any sequential decision-making problem through a graph-theoretic analysis of the DAG representation of its information structure. The central quantity in this analysis is the minimal set of variables that $d$-separates the past observations from future observations. Furthermore, through constructing a generalization of predictive state representations, we propose tailored reinforcement learning algorithms and prove that the sample complexity is in part determined by the information structure. This recovers known tractability results and gives a novel perspective on reinforcement learning in general sequential decision-making problems, providing a systematic way of identifying new tractable classes of problems.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.AI",
            "stat.ML"
        ],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00994": {
        "title": "Leveraging Prompt-Based Large Language Models: Predicting Pandemic Health Decisions and Outcomes Through Social Media Language",
        "authors": [
            "Xiaohan Ding",
            "Buse Carik",
            "Uma Sushmitha Gunturi",
            "Valerie Reyna",
            "Eugenia H. Rho"
        ],
        "comments": "20 pages, 4 figures",
        "subjects": "Human-Computer Interaction (cs.HC)",
        "abstract": "We introduce a multi-step reasoning framework using prompt-based LLMs to examine the relationship between social media language patterns and trends in national health outcomes. Grounded in fuzzy-trace theory, which emphasizes the importance of gists of causal coherence in effective health communication, we introduce Role-Based Incremental Coaching (RBIC), a prompt-based LLM framework, to identify gists at-scale. Using RBIC, we systematically extract gists from subreddit discussions opposing COVID-19 health measures (Study 1). We then track how these gists evolve across key events (Study 2) and assess their influence on online engagement (Study 3). Finally, we investigate how the volume of gists is associated with national health trends like vaccine uptake and hospitalizations (Study 4). Our work is the first to empirically link social media linguistic patterns to real-world public health trends, highlighting the potential of prompt-based LLMs in identifying critical online discussion patterns that can form the basis of public health communication strategies.\n    ",
        "primary_category": "cs.HC",
        "categories": [
            "cs.AI",
            "cs.CL",
            "cs.SI"
        ],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00995": {
        "title": "A Spark Optimizer for Adaptive, Fine-Grained Parameter Tuning",
        "authors": [
            "Chenghao Lyu",
            "Qi Fan",
            "Philippe Guyard",
            "Yanlei Diao"
        ],
        "comments": " ",
        "subjects": "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "abstract": "As Spark becomes a common big data analytics platform, its growing complexity makes automatic tuning of numerous parameters critical for performance. Our work on Spark parameter tuning is particularly motivated by two recent trends: Spark's Adaptive Query Execution (AQE) based on runtime statistics, and the increasingly popular Spark cloud deployments that make cost-performance reasoning crucial for the end user. This paper presents our design of a Spark optimizer that controls all tunable parameters (collectively called a \"configuration\") of each query in the new AQE architecture to explore its performance benefits and, at the same time, casts the tuning problem in the theoretically sound multi-objective optimization setting to better adapt to user cost-performance preferences.\nTo this end, we propose a novel hybrid compile-time/runtime approach to multi-granularity tuning of diverse, correlated Spark parameters, as well as a suite of modeling and optimization techniques to solve the tuning problem in the MOO setting while meeting the stringent time constraint of 1-2 seconds for cloud use. Our evaluation results using the TPC-H and TPC-DS benchmarks demonstrate the superior performance of our approach: (i) When prioritizing latency, it achieves an average of 61% and 64% reduction for TPC-H and TPC-DS, respectively, under the solving time of 0.62-0.83 sec, outperforming the most competitive MOO method that reduces only 18-25% latency with high solving time of 2.4-15 sec. (ii) When shifting preferences between latency and cost, our approach dominates the solutions from alternative methods by a wide margin, exhibiting superior adaptability to varying preferences.\n    ",
        "primary_category": "cs.DC",
        "categories": [],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00998": {
        "title": "Predictions from language models for multiple-choice tasks are not robust under variation of scoring methods",
        "authors": [
            "Polina Tsvilodub",
            "Hening Wang",
            "Sharon Grosch",
            "Michael Franke"
        ],
        "comments": "8 pages, 3 figures",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "This paper systematically compares different methods of deriving item-level predictions of language models for multiple-choice tasks. It compares scoring methods for answer options based on free generation of responses, various probability-based scores, a Likert-scale style rating method, and embedding similarity. In a case study on pragmatic language interpretation, we find that LLM predictions are not robust under variation of method choice, both within a single LLM and across different LLMs. As this variability entails pronounced researcher degrees of freedom in reporting results, knowledge of the variability is crucial to secure robustness of results and research integrity.\n    ",
        "primary_category": "cs.CL",
        "categories": [],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.00999": {
        "title": "Distributional Dataset Distillation with Subtask Decomposition",
        "authors": [
            "Tian Qin",
            "Zhiwei Deng",
            "David Alvarez-Melis"
        ],
        "comments": " ",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "What does a neural network learn when training from a task-specific dataset? Synthesizing this knowledge is the central idea behind Dataset Distillation, which recent work has shown can be used to compress large datasets into a small set of input-label pairs ($\\textit{prototypes}$) that capture essential aspects of the original dataset. In this paper, we make the key observation that existing methods distilling into explicit prototypes are very often suboptimal, incurring in unexpected storage cost from distilled labels. In response, we propose $\\textit{Distributional Dataset Distillation}$ (D3), which encodes the data using minimal sufficient per-class statistics and paired with a decoder, we distill dataset into a compact distributional representation that is more memory-efficient compared to prototype-based methods. To scale up the process of learning these representations, we propose $\\textit{Federated distillation}$, which decomposes the dataset into subsets, distills them in parallel using sub-task experts and then re-aggregates them. We thoroughly evaluate our algorithm on a three-dimensional metric and show that our method achieves state-of-the-art results on TinyImageNet and ImageNet-1K. Specifically, we outperform the prior art by $6.9\\%$ on ImageNet-1K under the storage budget of 2 images per class.\n    ",
        "primary_category": "cs.LG",
        "categories": [],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01002": {
        "title": "Attribute Structuring Improves LLM-Based Evaluation of Clinical Text Summaries",
        "authors": [
            "Zelalem Gero",
            "Chandan Singh",
            "Yiqing Xie",
            "Sheng Zhang",
            "Tristan Naumann",
            "Jianfeng Gao",
            "Hoifung Poon"
        ],
        "comments": "4 pages",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "Summarizing clinical text is crucial in health decision-support and clinical research. Large language models (LLMs) have shown the potential to generate accurate clinical text summaries, but still struggle with issues regarding grounding and evaluation, especially in safety-critical domains such as health. Holistically evaluating text summaries is challenging because they may contain unsubstantiated information. Here, we explore a general mitigation framework using Attribute Structuring (AS), which structures the summary evaluation process. It decomposes the evaluation process into a grounded procedure that uses an LLM for relatively simple structuring and scoring tasks, rather than the full task of holistic summary evaluation. Experiments show that AS consistently improves the correspondence between human annotations and automated metrics in clinical text summarization. Additionally, AS yields interpretations in the form of a short text span corresponding to each output, which enables efficient human auditing, paving the way towards trustworthy evaluation of clinical information in resource-constrained scenarios. We release our code, prompts, and an open-source benchmark at this https URL.\n    ",
        "primary_category": "cs.CL",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01003": {
        "title": "FlaKat: A Machine Learning-Based Categorization Framework for Flaky Tests",
        "authors": [
            "Shizhe Lin",
            "Ryan Zheng He Liu",
            "Ladan Tahvildari"
        ],
        "comments": " ",
        "subjects": "Software Engineering (cs.SE)",
        "abstract": "Flaky tests can pass or fail non-deterministically, without alterations to a software system. Such tests are frequently encountered by developers and hinder the credibility of test suites. State-of-the-art research incorporates machine learning solutions into flaky test detection and achieves reasonably good accuracy. Moreover, the majority of automated flaky test repair solutions are designed for specific types of flaky tests. This research work proposes a novel categorization framework, called FlaKat, which uses machine-learning classifiers for fast and accurate prediction of the category of a given flaky test that reflects its root cause. Sampling techniques are applied to address the imbalance between flaky test categories in the International Dataset of Flaky Test (IDoFT). A new evaluation metric, called Flakiness Detection Capacity (FDC), is proposed for measuring the accuracy of classifiers from the perspective of information theory and provides proof for its effectiveness. The final FDC results are also in agreement with F1 score regarding which classifier yields the best flakiness classification.\n    ",
        "primary_category": "cs.SE",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01004": {
        "title": "Advancing parabolic operators in thermodynamic MHD models II: Evaluating a Practical Time Step Limit for Unconditionally Stable Methods",
        "authors": [
            "Ronald M. Caplan",
            "Craig D. Johnston",
            "Lars K. S. Daldoff",
            "Jon A. Linker"
        ],
        "comments": "12 pages, 6 figures. ASTRONUM 23",
        "subjects": "Computational Engineering, Finance, and Science (cs.CE)",
        "abstract": "Unconditionally stable time stepping schemes are useful and often practically necessary for advancing parabolic operators in multi-scale systems. However, serious accuracy problems may emerge when taking time steps that far exceed the explicit stability limits. In our previous work, we compared the accuracy and performance of advancing parabolic operators in a thermodynamic MHD model using an implicit method and an explicit super time-stepping (STS) method. We found that while the STS method outperformed the implicit one with overall good results, it was not able to damp oscillatory behavior in the solution efficiently, hindering its practical use. In this follow-up work, we evaluate an easy-to-implement method for selecting a practical time step limit (PTL) for unconditionally stable schemes. This time step is used to `cycle' the operator-split thermal conduction and viscosity parabolic operators. We test the new time step with both an implicit and STS scheme for accuracy, performance, and scaling. We find that, for our test cases here, the PTL dramatically improves the STS solution, matching or improving the solution of the original implicit scheme, while retaining most of its performance and scaling advantages. The PTL shows promise to allow more accurate use of unconditionally stable schemes for parabolic operators and reliable use of STS methods.\n    ",
        "primary_category": "cs.CE",
        "categories": [
            "astro-ph.GA",
            "astro-ph.SR",
            "math.NA",
            "physics.comp-ph"
        ],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01005": {
        "title": "Policy Optimization for PDE Control with a Warm Start",
        "authors": [
            "Xiangyuan Zhang",
            "Saviz Mowlavi",
            "Mouhacine Benosman",
            "Tamer Ba\u015far"
        ],
        "comments": " ",
        "subjects": "Systems and Control (eess.SY)",
        "abstract": "Dimensionality reduction is crucial for controlling nonlinear partial differential equations (PDE) through a \"reduce-then-design\" strategy, which identifies a reduced-order model and then implements model-based control solutions. However, inaccuracies in the reduced-order modeling can substantially degrade controller performance, especially in PDEs with chaotic behavior. To address this issue, we augment the reduce-then-design procedure with a policy optimization (PO) step. The PO step fine-tunes the model-based controller to compensate for the modeling error from dimensionality reduction. This augmentation shifts the overall strategy into reduce-then-design-then-adapt, where the model-based controller serves as a warm start for PO. Specifically, we study the state-feedback tracking control of PDEs that aims to align the PDE state with a specific constant target subject to a linear-quadratic cost. Through extensive experiments, we show that a few iterations of PO can significantly improve the model-based controller performance. Our approach offers a cost-effective alternative to PDE control using end-to-end reinforcement learning.\n    ",
        "primary_category": "eess.SY",
        "categories": [
            "cs.AI",
            "math.OC"
        ],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01008": {
        "title": "BasedAI: A decentralized P2P network for Zero Knowledge Large Language Models (ZK-LLMs)",
        "authors": [
            "Sean Wellington"
        ],
        "comments": " ",
        "subjects": "Cryptography and Security (cs.CR)",
        "abstract": "BasedAI is a distributed network of machines which introduces decentralized infrastructure capable of integrating Fully Homomorphic Encryption (FHE) with any large language model (LLM) connected to its network. The proposed framework embeds a default mechanism, called \"Cerberus Squeezing\", into the mining process which enables the transformation of a standard LLMs into encrypted zero-knowledge LLMs, or \"ZK-LLMs\", leveraging insights from generative adversarial networks for data privacy. This novel quantization mechanism empowers BasedAI miners to process and respond to prompts derived from User interaction with LLMs without the need for decrypting either the queries or their corresponding responses. The introduction of Cerberus Squeezing significantly improves performance degradation caused by quantized functions in current FHE-compliant computing environments by proactively optimizing calls between users, miners, and validators.\n    ",
        "primary_category": "cs.CR",
        "categories": [
            "cs.IR"
        ],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01009": {
        "title": "Design and Evaluation of SEANet: a Software-defined Networking Platform for the Internet of Underwater Things",
        "authors": [
            "Deniz Unal",
            "Sara Falleni",
            "Kerem Enhos",
            "Emrecan Demirors",
            "Stefano Basagni",
            "Tommaso Melodia"
        ],
        "comments": "12 pages, 17 figures",
        "subjects": "Networking and Internet Architecture (cs.NI)",
        "abstract": "Investigating and safeguarding our oceans is vital for a host of applications and tasks, including combating climate change, ensuring the integrity of subsea infrastructures, and for coastal protection. Achieving these essential functions depends on the deployment of cost-effective, versatile underwater sensor networks that can efficiently collect and transmit data to land. However, the success of such networks is currently hindered by the significant limitations of existing underwater modems, which limits their operational use to a narrow range of applications. This paper presents and evaluates the performance of the SEANet software-defined networking platform, for the Internet of Underwater Things (IoUT), addressing the limitations of existing underwater communication technologies. It presents the development and comprehensive testing of an adaptable, high-data-rate, and integration-friendly underwater platform that reconfigures in real-time to meet the demands of various marine applications. With an acoustic front end, the platform significantly outperforms conventional modems, achieving more than double the data rate at 150 kbit/s. Experiments conducted in oceanic conditions demonstrate its capabilities in channel characterization, OFDM link establishment, and compatibility with the JANUS communication standard. Our platform advances the IoUT by providing a versatile, scalable solution that can incorporate multiple physical layers and support an array of tasks, making it pivotal for real-time ocean data analysis and the expansion of ocean-related digital applications.\n    ",
        "primary_category": "cs.NI",
        "categories": [
            "eess.SP"
        ],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01013": {
        "title": "A Holistic Power Optimization Approach for Microgrid Control Based on Deep Reinforcement Learning",
        "authors": [
            "Fulong Yao",
            "Wanqing Zhao",
            "Matthew Forshaw",
            "Yang Song"
        ],
        "comments": " ",
        "subjects": "Systems and Control (eess.SY)",
        "abstract": "The global energy landscape is undergoing a transformation towards decarbonization, sustainability, and cost-efficiency. In this transition, microgrid systems integrated with renewable energy sources (RES) and energy storage systems (ESS) have emerged as a crucial component. However, optimizing the operational control of such an integrated energy system lacks a holistic view of multiple environmental, infrastructural and economic considerations, not to mention the need to factor in the uncertainties from both the supply and demand. This paper presents a holistic datadriven power optimization approach based on deep reinforcement learning (DRL) for microgrid control considering the multiple needs of decarbonization, sustainability and cost-efficiency. First, two data-driven control schemes, namely the prediction-based (PB) and prediction-free (PF) schemes, are devised to formulate the control problem within a Markov decision process (MDP). Second, a multivariate objective (reward) function is designed to account for the market profits, carbon emissions, peak load, and battery degradation of the microgrid system. Third, we develop a Double Dueling Deep Q Network (D3QN) architecture to optimize the power flows for real-time energy management and determine charging/discharging strategies of ESS. Finally, extensive simulations are conducted to demonstrate the effectiveness and superiority of the proposed approach through a comparative analysis. The results and analysis also suggest the respective circumstances for using the two control schemes in practical implementations with uncertainties.\n    ",
        "primary_category": "eess.SY",
        "categories": [],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01014": {
        "title": "A Case for Validation Buffer in Pessimistic Actor-Critic",
        "authors": [
            "Michal Nauman",
            "Mateusz Ostaszewski",
            "Marek Cygan"
        ],
        "comments": "Preprint",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "In this paper, we investigate the issue of error accumulation in critic networks updated via pessimistic temporal difference objectives. We show that the critic approximation error can be approximated via a recursive fixed-point model similar to that of the Bellman value. We use such recursive definition to retrieve the conditions under which the pessimistic critic is unbiased. Building on these insights, we propose Validation Pessimism Learning (VPL) algorithm. VPL uses a small validation buffer to adjust the levels of pessimism throughout the agent training, with the pessimism set such that the approximation error of the critic targets is minimized. We investigate the proposed approach on a variety of locomotion and manipulation tasks and report improvements in sample efficiency and performance.\n    ",
        "primary_category": "cs.LG",
        "categories": [],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01015": {
        "title": "A Randomized Controlled Trial on Anonymizing Reviewers to Each Other in Peer Review Discussions",
        "authors": [
            "Charvi Rastogi",
            "Xiangchen Song",
            "Zhijing Jin",
            "Ivan Stelmakh",
            "Hal Daum\u00e9 III",
            "Kun Zhang",
            "Nihar B. Shah"
        ],
        "comments": "18 pages, 4 figures, 3 tables",
        "subjects": "Computers and Society (cs.CY)",
        "abstract": "Peer review often involves reviewers submitting their independent reviews, followed by a discussion among reviewers of each paper. A question among policymakers is whether the reviewers of a paper should be anonymous to each other during the discussion. We shed light on this by conducting a randomized controlled trial at the UAI 2022 conference. We randomly split the reviewers and papers into two conditions--one with anonymous discussions and the other with non-anonymous discussions, and conduct an anonymous survey of all reviewers, to address the following questions: 1. Do reviewers discuss more in one of the conditions? Marginally more in anonymous (n = 2281, p = 0.051). 2. Does seniority have more influence on final decisions when non-anonymous? Yes, the decisions are closer to senior reviewers' scores in the non-anonymous condition than in anonymous (n = 484, p = 0.04). 3. Are reviewers more polite in one of the conditions? No significant difference in politeness of reviewers' text-based responses (n = 1125, p = 0.72). 4. Do reviewers' self-reported experiences differ across the two conditions? No significant difference for each of the five questions asked (n = 132 and p > 0.3). 5. Do reviewers prefer one condition over the other? Yes, there is a weak preference for anonymous discussions (n = 159 and Cohen's d= 0.25). 6. What do reviewers consider important to make policy on anonymity among reviewers? Reviewers' feeling of safety in expressing their opinions was rated most important, while polite communication among reviewers was rated least important (n = 159). 7. Have reviewers experienced dishonest behavior due to non-anonymity in discussions? Yes, roughly 7% of respondents answered affirmatively (n = 167). Overall, this experiment reveals evidence supporting an anonymous discussion setup in the peer-review process, in terms of the evaluation criteria considered.\n    ",
        "primary_category": "cs.CY",
        "categories": [
            "cs.DL"
        ],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01022": {
        "title": "Autonomous Strike UAVs for Counterterrorism Missions: Challenges and Preliminary Solutions",
        "authors": [
            "Meshari Aljohani",
            "Ravi Mukkamalai",
            "Stephen Olariu"
        ],
        "comments": "12 pages, 12 figures",
        "subjects": "Robotics (cs.RO)",
        "abstract": "Unmanned Aircraft Vehicles (UAVs) are becoming a crucial tool in modern warfare, primarily due to their cost-effectiveness, risk reduction, and ability to perform a wider range of activities. The use of autonomous UAVs to conduct strike missions against highly valuable targets is the focus of this research. Due to developments in ledger technology, smart contracts, and machine learning, such activities formerly carried out by professionals or remotely flown UAVs are now feasible. Our study provides the first in-depth analysis of challenges and preliminary solutions for successful implementation of an autonomous UAV mission. Specifically, we identify challenges that have to be overcome and propose possible technical solutions for the challenges identified. We also derive analytical expressions for the success probability of an autonomous UAV mission, and describe a machine learning model to train the UAV.\n    ",
        "primary_category": "cs.RO",
        "categories": [
            "cs.LG"
        ],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01023": {
        "title": "Federated Learning via Lattice Joint Source-Channel Coding",
        "authors": [
            "Seyed Mohammad Azimi-Abarghouyi",
            "Lav R. Varshney"
        ],
        "comments": " ",
        "subjects": "Information Theory (cs.IT)",
        "abstract": "This paper introduces a universal federated learning framework that enables over-the-air computation via digital communications, using a new joint source-channel coding scheme. Without relying on channel state information at devices, this scheme employs lattice codes to both quantize model parameters and exploit interference from the devices. A novel two-layer receiver structure at the server is designed to reliably decode an integer combination of the quantized model parameters as a lattice point for the purpose of aggregation. Numerical experiments validate the effectiveness of the proposed scheme. Even with the challenges posed by channel conditions and device heterogeneity, the proposed scheme markedly surpasses other over-the-air FL strategies.\n    ",
        "primary_category": "cs.IT",
        "categories": [
            "cs.LG"
        ],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01024": {
        "title": "Reservoir Computing Using Measurement-Controlled Quantum Dynamics",
        "authors": [
            "A.H.Abbas",
            "Ivan S.Maksymov"
        ],
        "comments": " ",
        "subjects": "Neural and Evolutionary Computing (cs.NE)",
        "abstract": "Physical reservoir computing (RC) is a machine learning algorithm that employs the dynamics of a physical system to forecast highly nonlinear and chaotic phenomena. In this paper, we introduce a quantum RC system that employs the dynamics of a probed atom in a cavity. The atom experiences coherent driving at a particular rate, leading to a measurement-controlled quantum evolution. The proposed quantum reservoir can make fast and reliable forecasts using a small number of artificial neurons compared with the traditional RC algorithm. We theoretically validate the operation of the reservoir, demonstrating its potential to be used in error-tolerant applications, where approximate computing approaches may be used to make feasible forecasts in conditions of limited computational and energy resources.\n    ",
        "primary_category": "cs.NE",
        "categories": [
            "cs.AI",
            "quant-ph"
        ],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01025": {
        "title": "A Sufficient Epistemic Condition for Solving Stabilizing Agreement",
        "authors": [
            "Giorgio Cignarale",
            "Stephan Felber",
            "Hugo Rincon Galeana"
        ],
        "comments": " ",
        "subjects": "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "abstract": "In this paper we provide a first-ever epistemic formulation of stabilizing agreement, defined as the non-terminating variant of the well established consensus problem. In stabilizing agreements, agents are given (possibly different) initial values, with the goal to eventually always decide on the same value. While agents are allowed to change their decisions finitely often, they are required to agree on the same value eventually. We capture these properties in temporal epistemic logic and we use the Runs and Systems framework to formally reason about stabilizing agreement problems. We then epistemically formalize the conditions for solving stabilizing agreement, and identify the knowledge that the agents acquire during any execution to choose a particular value under our system assumptions. This first formalization of a sufficient condition for solving stabilizing agreement sets the stage for a planned necessary and sufficient epistemic characterization of stabilizing agreement.\n    ",
        "primary_category": "cs.DC",
        "categories": [
            "cs.LO"
        ],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01027": {
        "title": "Assessing the Potential for Building Sector Retrofits to Mitigate ERCOT Electricity Shortfalls During Winter Storm Uri",
        "authors": [
            "Matthew J. Skiles",
            "Joshua D. Rhodes",
            "Michael E. Webber"
        ],
        "comments": "35 pages, 13 figures",
        "subjects": "Systems and Control (eess.SY)",
        "abstract": "This analysis investigates energy performance of the residential and commercial building sectors in the Electric Reliability Council of Texas (ERCOT) during Winter Storm Uri. ERCOT electricity demand was modeled for the ERCOT baseline building stock as well as for the baseline building stock retrofitted with an efficiency upgrade package, an electrification upgrade package, and an efficiency + electrification upgrade package. The electrification scenario that retrofitted buildings with air-source heat pumps (ASHPs) would have lowered ERCOT daily peak electricity demand relative to the baseline scenario for every day of the year, except during the week of Winter Storm Uri. As the mean outdoor temperature dropped below -5\u00b0C (23\u00b0F), diminishing ASHP efficiency would have resulted in electrification scenario demand exceeding the two distinct baseline scenario daily demand peaks on February 15th and 16th (87.3 GW and 88.7 GW) to hit 111.8 GW and 117.5 GW. The efficiency package would have lowered daily peak demand on these days to 67.0 GW and 68.0 GW. The efficiency + electrification package would have lowered peak demand on these days to 81.5 GW and 85.6 GW. When electricity shortfall profiles were produced by comparing modeled electricity demand to actual ERCOT electricity generation during the storm, the results indicate that the electrification scenario electricity shortfall (1741 GWh) would have been larger than for the baseline scenario (1225 GWh) and the electricity shortfalls for the efficiency scenario (347 GWh) and efficiency + electrification scenario (704 GWh) would have been lower than the baseline. The efficiency, electrification, and efficiency + electrification scenarios would all have lowered summer daily peak demand due to improvements in building cooling efficiency and would have lowered annual electricity consumption by 5.9%, 6.8%, and 11.9%, respectively.\n    ",
        "primary_category": "eess.SY",
        "categories": [],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01031": {
        "title": "Peacock: A Family of Arabic Multimodal Large Language Models and Benchmarks",
        "authors": [
            "Fakhraddin Alwajih",
            "El Moatez Billah Nagoudi",
            "Gagan Bhatia",
            "Abdelrahman Mohamed",
            "Muhammad Abdul-Mageed"
        ],
        "comments": "Under Review",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "Multimodal large language models (MLLMs) have proven effective in a wide range of tasks requiring complex reasoning and linguistic comprehension. However, due to a lack of high-quality multimodal resources in languages other than English, success of MLLMs remains relatively limited to English-based settings. This poses significant challenges in developing comparable models for other languages, including even those with large speaker populations such as Arabic. To alleviate this challenge, we introduce a comprehensive family of Arabic MLLMs, dubbed \\textit{Peacock}, with strong vision and language capabilities. Through comprehensive qualitative and quantitative analysis, we demonstrate the solid performance of our models on various visual reasoning tasks and further show their emerging dialectal potential. Additionally, we introduce ~\\textit{Henna}, a new benchmark specifically designed for assessing MLLMs on aspects related to Arabic culture, setting the first stone for culturally-aware Arabic MLLMs.The GitHub repository for the \\textit{Peacock} project is available at \\url{this https URL}.\n    ",
        "primary_category": "cs.CL",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "1 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01036": {
        "title": "Nonlinear dynamics and stability analysis of locally-active Mott memristors using a physics-based compact model",
        "authors": [
            "Wei Yi"
        ],
        "comments": "63 pages, 33 figures",
        "subjects": "Emerging Technologies (cs.ET)",
        "abstract": "Locally-active memristors are a class of emerging nonlinear dynamic circuit elements that hold promise for scalable yet biomimetic neuromorphic circuits. Starting from a physics-based compact model, we performed small-signal linearization analyses and applied Chua's local activity theory to a one-dimensional locally-active vanadium dioxide Mott memristor based on an insulator-to-metal phase transition. This approach allows a connection between the dynamical behaviors of a Mott memristor and its physical device parameters, which could guide materials and device development for neuromorphic circuit applications. We also examined the applicability of local analyses on a second-order circuit consists of a vanadium dioxide memristor coupled to an external reactive element, specifically a parallel capacitor. Finally, we show that global nonlinear techniques including nullclines and phase portraits provide insights on instabilities and persistent oscillations near non-hyperbolic fixed points, such as the creation of a stable limit cycle in a supercritical Hopf bifurcation, with some of the bifurcation characteristics distinctive from the general predictions.\n    ",
        "primary_category": "cs.ET",
        "categories": [],
        "submitted_date": "2 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01038": {
        "title": "AutoAttacker: A Large Language Model Guided System to Implement Automatic Cyber-attacks",
        "authors": [
            "Jiacen Xu",
            "Jack W. Stokes",
            "Geoff McDonald",
            "Xuesong Bai",
            "David Marshall",
            "Siyue Wang",
            "Adith Swaminathan",
            "Zhou Li"
        ],
        "comments": " ",
        "subjects": "Cryptography and Security (cs.CR)",
        "abstract": "Large language models (LLMs) have demonstrated impressive results on natural language tasks, and security researchers are beginning to employ them in both offensive and defensive systems. In cyber-security, there have been multiple research efforts that utilize LLMs focusing on the pre-breach stage of attacks like phishing and malware generation. However, so far there lacks a comprehensive study regarding whether LLM-based systems can be leveraged to simulate the post-breach stage of attacks that are typically human-operated, or \"hands-on-keyboard\" attacks, under various attack techniques and environments.\nAs LLMs inevitably advance, they may be able to automate both the pre- and post-breach attack stages. This shift may transform organizational attacks from rare, expert-led events to frequent, automated operations requiring no expertise and executed at automation speed and scale. This risks fundamentally changing global computer security and correspondingly causing substantial economic impacts, and a goal of this work is to better understand these risks now so we can better prepare for these inevitable ever-more-capable LLMs on the horizon. On the immediate impact side, this research serves three purposes. First, an automated LLM-based, post-breach exploitation framework can help analysts quickly test and continually improve their organization's network security posture against previously unseen attacks. Second, an LLM-based penetration test system can extend the effectiveness of red teams with a limited number of human analysts. Finally, this research can help defensive systems and teams learn to detect novel attack behaviors preemptively before their use in the wild....\n    ",
        "primary_category": "cs.CR",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "2 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01042": {
        "title": "Public Projects with Preferences and Predictions",
        "authors": [
            "Mary Monroe",
            "Bo Waggoner"
        ],
        "comments": " ",
        "subjects": "Computer Science and Game Theory (cs.GT)",
        "abstract": "In the public projects problem, a group of decisionmakers aggregate their preferences to choose one alternative. Recent work on public projects has proposed the Quadratic Transfers Mechanism (QTM) and shown asymptotic welfare guarantees in some cases. We begin by giving new non-asymptotic Price of Anarchy guarantees for the QTM.\nWe then incorporate an alternative philosophy toward group decisionmaking, aggregation of information about which is the best alternative. We propose a public projects mechanism based on the QTM that aggregates both preferences and predictions, modeled as forecasts of the projects' welfare impacts. When the predictions come from a prediction market or wagering mechanism, we show the entire mechanism is robust to manipulation and give Price of Anarchy guarantees, though under strong assumptions on the mechanism's knowledge. Our results focus primarily on the case of deciding between two alternatives, showing the Price of Anarchy tends to $1$ as natural measures of the \"size\" of the population grow large. In most cases, the mechanisms achieve a balanced budget as well.\n    ",
        "primary_category": "cs.GT",
        "categories": [],
        "submitted_date": "2 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01050": {
        "title": "GraphMini: Accelerating Graph Pattern Matching Using Auxiliary Graphs",
        "authors": [
            "Juelin Liu",
            "Sandeep Polisetty",
            "Hui Guan",
            "Marco Serafini"
        ],
        "comments": " ",
        "subjects": "Databases (cs.DB)",
        "abstract": "Graph pattern matching is a fundamental problem encountered by many common graph mining tasks and the basic building block of several graph mining systems.\nThis paper explores for the first time how to proactively prune graphs to speed up graph pattern matching by leveraging the structure of the query pattern and the input graph.\nWe propose building auxiliary graphs, which are different pruned versions of the graph, during query execution.\nThis requires careful balancing between the upfront cost of building and managing auxiliary graphs and the gains of faster set operations.\nTo this end, we propose GraphMini, a new system that uses query compilation and a new cost model to minimize the cost of building and maintaining auxiliary graphs and maximize gains.\nOur evaluation shows that using GraphMini can achieve one order of magnitude speedup compared to state-of-the-art subgraph enumeration systems on commonly used benchmarks.\n    ",
        "primary_category": "cs.DB",
        "categories": [
            "cs.PF"
        ],
        "submitted_date": "2 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01055": {
        "title": "Towards Full Authorship with AI: Supporting Revision with AI-Generated Views",
        "authors": [
            "Jiho Kim",
            "Ray C. Flanagan",
            "Noelle E. Haviland",
            "ZeAi Sun",
            "Souad N. Yakubu",
            "Edom A. Maru",
            "Kenneth C. Arnold"
        ],
        "comments": "15 pages, 2 figures; Accepted to 5th Workshop on Human-AI Co-Creation with Generative Models (HAI-GEN) at ACM IUI 2024",
        "subjects": "Human-Computer Interaction (cs.HC)",
        "abstract": "Large language models (LLMs) are shaping a new user interface (UI) paradigm in writing tools by enabling users to generate text through prompts. This paradigm shifts some creative control from the user to the system, thereby diminishing the user's authorship and autonomy in the writing process. To restore autonomy, we introduce Textfocals, a UI prototype designed to investigate a human-centered approach that emphasizes the user's role in writing. Textfocals supports the writing process by providing LLM-generated summaries, questions, and advice (i.e., LLM views) in a sidebar of a text editor, encouraging reflection and self-driven revision in writing without direct text generation. Textfocals' UI affordances, including contextually adaptive views and scaffolding for prompt selection and customization, offer a novel way to interact with LLMs where users maintain full authorship of their writing. A formative user study with Textfocals showed promising evidence that this approach might help users develop underdeveloped ideas, cater to the rhetorical audience, and clarify their writing. However, the study also showed interaction design challenges related to document navigation and scoping, prompt engineering, and context management. Our work highlights the breadth of the design space of writing support interfaces powered by generative AI that maintain authorship integrity.\n    ",
        "primary_category": "cs.HC",
        "categories": [
            "cs.AI",
            "cs.CY"
        ],
        "submitted_date": "2 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01058": {
        "title": "Neural Field Classifiers via Target Encoding and Classification Loss",
        "authors": [
            "Xindi Yang",
            "Zeke Xie",
            "Xiong Zhou",
            "Boyu Liu",
            "Buhua Liu",
            "Yi Liu",
            "Haoran Wang",
            "Yunfeng Cai",
            "Mingming Sun"
        ],
        "comments": "ICLR 2024 Main Conference; 17 pages; 11 figures; 13 tables",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Neural field methods have seen great progress in various long-standing tasks in computer vision and computer graphics, including novel view synthesis and geometry reconstruction. As existing neural field methods try to predict some coordinate-based continuous target values, such as RGB for Neural Radiance Field (NeRF), all of these methods are regression models and are optimized by some regression loss. However, are regression models really better than classification models for neural field methods? In this work, we try to visit this very fundamental but overlooked question for neural fields from a machine learning perspective. We successfully propose a novel Neural Field Classifier (NFC) framework which formulates existing neural field methods as classification tasks rather than regression tasks. The proposed NFC can easily transform arbitrary Neural Field Regressor (NFR) into its classification variant via employing a novel Target Encoding module and optimizing a classification loss. By encoding a continuous regression target into a high-dimensional discrete encoding, we naturally formulate a multi-label classification task. Extensive experiments demonstrate the impressive effectiveness of NFC at the nearly free extra computational costs. Moreover, NFC also shows robustness to sparse inputs, corrupted images, and dynamic scenes.\n    ",
        "primary_category": "cs.CV",
        "categories": [
            "cs.LG"
        ],
        "submitted_date": "2 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01059": {
        "title": "Continuous Mean-Zero Disagreement-Regularized Imitation Learning (CMZ-DRIL)",
        "authors": [
            "Noah Ford",
            "Ryan W. Gardner",
            "Austin Juhl",
            "Nathan Larson"
        ],
        "comments": " ",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Machine-learning paradigms such as imitation learning and reinforcement learning can generate highly performant agents in a variety of complex environments. However, commonly used methods require large quantities of data and/or a known reward function. This paper presents a method called Continuous Mean-Zero Disagreement-Regularized Imitation Learning (CMZ-DRIL) that employs a novel reward structure to improve the performance of imitation-learning agents that have access to only a handful of expert demonstrations. CMZ-DRIL uses reinforcement learning to minimize uncertainty among an ensemble of agents trained to model the expert demonstrations. This method does not use any environment-specific rewards, but creates a continuous and mean-zero reward function from the action disagreement of the agent ensemble. As demonstrated in a waypoint-navigation environment and in two MuJoCo environments, CMZ-DRIL can generate performant agents that behave more similarly to the expert than primary previous approaches in several key metrics.\n    ",
        "primary_category": "cs.LG",
        "categories": [],
        "submitted_date": "2 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01061": {
        "title": "Reading Subtext: Evaluating Large Language Models on Short Story Summarization with Writers",
        "authors": [
            "Melanie Subbiah",
            "Sean Zhang",
            "Lydia B. Chilton",
            "Kathleen McKeown"
        ],
        "comments": " ",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "We evaluate recent Large language Models (LLMs) on the challenging task of summarizing short stories, which can be lengthy, and include nuanced subtext or scrambled timelines. Importantly, we work directly with authors to ensure that the stories have not been shared online (and therefore are unseen by the models), and to obtain informed evaluations of summary quality using judgments from the authors themselves. Through quantitative and qualitative analysis grounded in narrative theory, we compare GPT-4, Claude-2.1, and LLama-2-70B. We find that all three models make faithfulness mistakes in over 50% of summaries and struggle to interpret difficult subtext. However, at their best, the models can provide thoughtful thematic analysis of stories. We additionally demonstrate that LLM judgments of summary quality do not match the feedback from the writers.\n    ",
        "primary_category": "cs.CL",
        "categories": [],
        "submitted_date": "2 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01063": {
        "title": "FaiMA: Feature-aware In-context Learning for Multi-domain Aspect-based Sentiment Analysis",
        "authors": [
            "Songhua Yang",
            "Xinke Jiang",
            "Hanjie Zhao",
            "Wenxuan Zeng",
            "Hongde Liu",
            "Yuxiang Jia"
        ],
        "comments": " ",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "Multi-domain aspect-based sentiment analysis (ABSA) seeks to capture fine-grained sentiment across diverse domains. While existing research narrowly focuses on single-domain applications constrained by methodological limitations and data scarcity, the reality is that sentiment naturally traverses multiple domains. Although large language models (LLMs) offer a promising solution for ABSA, it is difficult to integrate effectively with established techniques, including graph-based models and linguistics, because modifying their internal architecture is not easy. To alleviate this problem, we propose a novel framework, Feature-aware In-context Learning for Multi-domain ABSA (FaiMA). The core insight of FaiMA is to utilize in-context learning (ICL) as a feature-aware mechanism that facilitates adaptive learning in multi-domain ABSA tasks. Specifically, we employ a multi-head graph attention network as a text encoder optimized by heuristic rules for linguistic, domain, and sentiment features. Through contrastive learning, we optimize sentence representations by focusing on these diverse features. Additionally, we construct an efficient indexing mechanism, allowing FaiMA to stably retrieve highly relevant examples across multiple dimensions for any given input. To evaluate the efficacy of FaiMA, we build the first multi-domain ABSA benchmark dataset. Extensive experimental results demonstrate that FaiMA achieves significant performance improvements in multiple domains compared to baselines, increasing F1 by 2.07% on average. Source code and data sets are anonymously available at this https URL.\n    ",
        "primary_category": "cs.CL",
        "categories": [],
        "submitted_date": "2 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01068": {
        "title": "Automated Continuous Force-Torque Sensor Bias Estimation",
        "authors": [
            "Philippe Nadeau",
            "Miguel Rogel Garcia",
            "Emmett Wise",
            "Jonathan Kelly"
        ],
        "comments": "Technical Report STARS-2024-001, University of Toronto Institute for Aerospace Studies (7 pages, 0 figure)",
        "subjects": "Robotics (cs.RO)",
        "abstract": "Six axis force-torque sensors are commonly attached to the wrist of serial robots to measure the external forces and torques acting on the robot's end-effector. These measurements are used for load identification, contact detection, and human-robot interaction amongst other applications. Typically, the measurements obtained from the force-torque sensor are more accurate than estimates computed from joint torque readings, as the former is independent of the robot's dynamic and kinematic models. However, the force-torque sensor measurements are affected by a bias that drifts over time, caused by the compounding effects of temperature changes, mechanical stresses, and other factors. In this work, we present a pipeline that continuously estimates the bias and the drift of the bias of a force-torque sensor attached to the wrist of a robot. The first component of the pipeline is a Kalman filter that estimates the kinematic state (position, velocity, and acceleration) of the robot's joints. The second component is a kinematic model that maps the joint-space kinematics to the task-space kinematics of the force-torque sensor. Finally, the third component is a Kalman filter that estimates the bias and the drift of the bias of the force-torque sensor assuming that the inertial parameters of the gripper attached to the distal end of the force-torque sensor are known with certainty.\n    ",
        "primary_category": "cs.RO",
        "categories": [],
        "submitted_date": "2 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01069": {
        "title": "LLMCRIT: Teaching Large Language Models to Use Criteria",
        "authors": [
            "Weizhe Yuan",
            "Pengfei Liu",
            "Matthias Gall\u00e9"
        ],
        "comments": "8 pages, 4 tables, 3 figures in the main text",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "Humans follow criteria when they execute tasks, and these criteria are directly used to assess the quality of task completion. Therefore, having models learn to use criteria to provide feedback can help humans or models to perform tasks better. However, existing research in this field tends to consider only a limited set of criteria or quality assessment aspects. To fill this gap, we propose a general framework that enables large language models (LLMs) to use comprehensive criteria for a task in delivering natural language feedback on task execution. In particular, we present a model-in-the-loop framework that semi-automatically derives criteria from collected guidelines for different writing tasks and constructs in-context demonstrations for each criterion. We choose three tasks from real-world scenarios to operationalize this idea: paper introduction writing, Python code writing, and Reddit post writing, and evaluate our feedback generation framework using different LLMs. The results reveal the fine-grained effects of incorporating criteria and demonstrations and provide valuable insights on how to teach LLMs to use criteria more effectively.\n    ",
        "primary_category": "cs.CL",
        "categories": [],
        "submitted_date": "2 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01071": {
        "title": "GraphRCG: Self-conditioned Graph Generation via Bootstrapped Representations",
        "authors": [
            "Song Wang",
            "Zhen Tan",
            "Xinyu Zhao",
            "Tianlong Chen",
            "Huan Liu",
            "Jundong Li"
        ],
        "comments": " ",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Graph generation generally aims to create new graphs that closely align with a specific graph distribution. Existing works often implicitly capture this distribution through the optimization of generators, potentially overlooking the intricacies of the distribution itself. Furthermore, these approaches generally neglect the insights offered by the learned distribution for graph generation. In contrast, in this work, we propose a novel self-conditioned graph generation framework designed to explicitly model graph distributions and employ these distributions to guide the generation process. We first perform self-conditioned modeling to capture the graph distributions by transforming each graph sample into a low-dimensional representation and optimizing a representation generator to create new representations reflective of the learned distribution. Subsequently, we leverage these bootstrapped representations as self-conditioned guidance for the generation process, thereby facilitating the generation of graphs that more accurately reflect the learned distributions. We conduct extensive experiments on generic and molecular graph datasets across various fields. Our framework demonstrates superior performance over existing state-of-the-art graph generation methods in terms of graph quality and fidelity to training data.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "2 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01072": {
        "title": "Distribution-Free Guarantees for Systems with Decision-Dependent Noise",
        "authors": [
            "Heling Zhang",
            "Lillian J. Ratliff",
            "Roy Dong"
        ],
        "comments": " ",
        "subjects": "Systems and Control (eess.SY)",
        "abstract": "In many real-world dynamical systems, obtaining precise models of system uncertainty remains a challenge. It may be difficult to estimate noise distributions or robustness bounds, especially when the distributions/robustness bounds vary with different control inputs in unknown ways. Addressing this challenge, this paper presents a novel iterative method tailored for systems with decision-dependent noise without prior knowledge of the distributions. Our approach finds the open-loop control law that minimizes the worst-case loss, given that the noise induced by this control lies in its $(1 - p)$-confidence set for a predetermined $p$. At each iteration, we use a quantile method inspired by conformal prediction to empirically estimate the confidence set shaped by the preceding control law. These derived confidence sets offer distribution-free guarantees on the system's noise, guiding a robust control formulation that targets worst-case loss minimization. Under specific regularity conditions, our method is shown to converge to a near-optimal open-loop control. While our focus is on open-loop controls, the adaptive, data-driven nature of our approach suggests its potential applicability across diverse scenarios and extensions.\n    ",
        "primary_category": "eess.SY",
        "categories": [],
        "submitted_date": "2 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01076": {
        "title": "Extracting Usable Predictions from Quantized Networks through Uncertainty Quantification for OOD Detection",
        "authors": [
            "Rishi Singhal",
            "Srinath Srinivasan"
        ],
        "comments": " ",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "OOD detection has become more pertinent with advances in network design and increased task complexity. Identifying which parts of the data a given network is misclassifying has become as valuable as the network's overall performance. We can compress the model with quantization, but it suffers minor performance loss. The loss of performance further necessitates the need to derive the confidence estimate of the network's predictions. In line with this thinking, we introduce an Uncertainty Quantification(UQ) technique to quantify the uncertainty in the predictions from a pre-trained vision model. We subsequently leverage this information to extract valuable predictions while ignoring the non-confident predictions. We observe that our technique saves up to 80% of ignored samples from being misclassified. The code for the same is available here.\n    ",
        "primary_category": "cs.CV",
        "categories": [
            "cs.LG"
        ],
        "submitted_date": "2 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01078": {
        "title": "$\u0393$-VAE: Curvature regularized variational autoencoders for uncovering emergent low dimensional geometric structure in high dimensional data",
        "authors": [
            "Jason Z. Kim",
            "Nicolas Perrin-Gilbert",
            "Erkan Narmanli",
            "Paul Klein",
            "Christopher R. Myers",
            "Itai Cohen",
            "Joshua J. Waterfall",
            "James P. Sethna"
        ],
        "comments": "8 pages, 4 figures",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Natural systems with emergent behaviors often organize along low-dimensional subsets of high-dimensional spaces. For example, despite the tens of thousands of genes in the human genome, the principled study of genomics is fruitful because biological processes rely on coordinated organization that results in lower dimensional phenotypes. To uncover this organization, many nonlinear dimensionality reduction techniques have successfully embedded high-dimensional data into low-dimensional spaces by preserving local similarities between data points. However, the nonlinearities in these methods allow for too much curvature to preserve general trends across multiple non-neighboring data clusters, thereby limiting their interpretability and generalizability to out-of-distribution data. Here, we address both of these limitations by regularizing the curvature of manifolds generated by variational autoencoders, a process we coin ``$\\Gamma$-VAE''. We demonstrate its utility using two example data sets: bulk RNA-seq from the The Cancer Genome Atlas (TCGA) and the Genotype Tissue Expression (GTEx); and single cell RNA-seq from a lineage tracing experiment in hematopoietic stem cell differentiation. We find that the resulting regularized manifolds identify mesoscale structure associated with different cancer cell types, and accurately re-embed tissues from completely unseen, out-of distribution cancers as if they were originally trained on them. Finally, we show that preserving long-range relationships to differentiated cells separates undifferentiated cells -- which have not yet specialized -- according to their eventual fate. Broadly, we anticipate that regularizing the curvature of generative models will enable more consistent, predictive, and generalizable models in any high-dimensional system with emergent low-dimensional behavior.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.AI",
            "physics.bio-ph",
            "q-bio.GN"
        ],
        "submitted_date": "2 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01079": {
        "title": "Teaching MLP More Graph Information: A Three-stage Multitask Knowledge Distillation Framework",
        "authors": [
            "Junxian Li",
            "Bin Shi",
            "Erfei Cui",
            "Hua Wei",
            "Qinghua Zheng"
        ],
        "comments": "20 pages, with Appendix",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "We study the challenging problem for inference tasks on large-scale graph datasets of Graph Neural Networks: huge time and memory consumption, and try to overcome it by reducing reliance on graph structure. Even though distilling graph knowledge to student MLP is an excellent idea, it faces two major problems of positional information loss and low generalization. To solve the problems, we propose a new three-stage multitask distillation framework. In detail, we use Positional Encoding to capture positional information. Also, we introduce Neural Heat Kernels responsible for graph data processing in GNN and utilize hidden layer outputs matching for better performance of student MLP's hidden layers. To the best of our knowledge, it is the first work to include hidden layer distillation for student MLP on graphs and to combine graph Positional Encoding with MLP. We test its performance and robustness with several settings and draw the conclusion that our work can outperform well with good stability.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "2 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01083": {
        "title": "Beyond Night Visibility: Adaptive Multi-Scale Fusion of Infrared and Visible Images",
        "authors": [
            "Shufan Pei",
            "Junhong Lin",
            "Wenxi Liu",
            "Tiesong Zhao",
            "Chia-Wen Lin"
        ],
        "comments": " ",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "In addition to low light, night images suffer degradation from light effects (e.g., glare, floodlight, etc). However, existing nighttime visibility enhancement methods generally focus on low-light regions, which neglects, or even amplifies the light effects. To address this issue, we propose an Adaptive Multi-scale Fusion network (AMFusion) with infrared and visible images, which designs fusion rules according to different illumination regions. First, we separately fuse spatial and semantic features from infrared and visible images, where the former are used for the adjustment of light distribution and the latter are used for the improvement of detection accuracy. Thereby, we obtain an image free of low light and light effects, which improves the performance of nighttime object detection. Second, we utilize detection features extracted by a pre-trained backbone that guide the fusion of semantic features. Hereby, we design a Detection-guided Semantic Fusion Module (DSFM) to bridge the domain gap between detection and semantic features. Third, we propose a new illumination loss to constrain fusion image with normal light intensity. Experimental results demonstrate the superiority of AMFusion with better visual quality and detection accuracy. The source code will be released after the peer review process.\n    ",
        "primary_category": "cs.CV",
        "categories": [],
        "submitted_date": "2 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01086": {
        "title": "phloSAR: a Portable, High-Flow Pressure Supply and Regulator Enabling Untethered Operation of Large Pneumatic Soft Robots",
        "authors": [
            "Maxwell Ahlquist",
            "Rianna Jitosho",
            "Jiawen Bao",
            "Allison M. Okamura"
        ],
        "comments": "2024 IEEE International Conference on Soft Robotics",
        "subjects": "Robotics (cs.RO)",
        "abstract": "Pneumatic actuation benefits soft robotics by facilitating compliance, enabling large volume change, and concentrating actuator weight away from the end-effector. However, portability is compromised when pneumatic actuators are tethered to cumbersome air and power supplies. While there are existing options for portable pneumatic systems, they are limited in dynamic capabilities, constraining their applicability to low pressure and/or small-volume soft robots. In this work, we propose a portable, high-flow pressure supply and regulator (phloSAR) for use in untethered, weight-constrained, dynamic soft robot applications. PhloSAR leverages high-flow proportional valves, an integrated pressure reservoir, and Venturi vacuum generation to achieve portability and dynamic performance. We present a set of models that describe the system dynamics, experimentally validate them on physical hardware, and discuss the influence of design parameters on system operation. Lastly, we integrate a proof-of-concept prototype with a soft robot arm mounted on an aerial vehicle to demonstrate the system's applicability to mobile robotics. Our system enables new opportunities in mobile soft robotics by making untethered pneumatic supply and regulation available to a wider range of soft robots.\n    ",
        "primary_category": "cs.RO",
        "categories": [],
        "submitted_date": "2 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01087": {
        "title": "Towards Accurate Lip-to-Speech Synthesis in-the-Wild",
        "authors": [
            "Sindhu Hegde",
            "Rudrabha Mukhopadhyay",
            "C.V. Jawahar",
            "Vinay Namboodiri"
        ],
        "comments": "8 pages of content, 1 page of references and 4 figures",
        "subjects": "Multimedia (cs.MM)",
        "abstract": "In this paper, we introduce a novel approach to address the task of synthesizing speech from silent videos of any in-the-wild speaker solely based on lip movements. The traditional approach of directly generating speech from lip videos faces the challenge of not being able to learn a robust language model from speech alone, resulting in unsatisfactory outcomes. To overcome this issue, we propose incorporating noisy text supervision using a state-of-the-art lip-to-text network that instills language information into our model. The noisy text is generated using a pre-trained lip-to-text model, enabling our approach to work without text annotations during inference. We design a visual text-to-speech network that utilizes the visual stream to generate accurate speech, which is in-sync with the silent input video. We perform extensive experiments and ablation studies, demonstrating our approach's superiority over the current state-of-the-art methods on various benchmark datasets. Further, we demonstrate an essential practical application of our method in assistive technology by generating speech for an ALS patient who has lost the voice but can make mouth movements. Our demo video, code, and additional details can be found at \\url{this http URL}.\n    ",
        "primary_category": "cs.MM",
        "categories": [
            "cs.CV",
            "cs.SD",
            "eess.AS"
        ],
        "submitted_date": "2 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01089": {
        "title": "Accelerating Hydrodynamic Fabrication of Microstructures using Deep Neural Networks",
        "authors": [
            "Nicholus R. Clinkinbeard",
            "Reza Montazami",
            "Nicole N. Hashemi"
        ],
        "comments": " ",
        "subjects": "Computational Engineering, Finance, and Science (cs.CE)",
        "abstract": "Manufacturing of microstructures using a microfluidic device is a largely empirical effort due to the multi-physical nature of the fabrication process. As such, models are desired that will predict microstructure performance characteristics (e.g., size, porosity, and stiffness) based on known inputs, such as sheath and core fluid flow rates. Potentially more useful is the prospect of inputting desired performance characteristics into a design model to extract appropriate manufacturing parameters. In this study, we demonstrate that deep neural networks (DNNs) trained with sparse datasets augmented by synthetic data can produce accurate predictive and design models. For our predictive model with known sheath and core flow rates and bath solution percentage, calculated solid microfiber dimensions are shown to be greater than 95% accurate, with porosity and Young's modulus exhibiting greater than 90% accuracy for a majority of conditions. Likewise, the design model is able to recover sheath and core flow rates with 95% accuracy when provided values for microfiber dimensions, porosity, and Young's modulus. As a result, DNN-based modeling of the microfiber fabrication process demonstrates high potential for reducing time to manufacture of microstructures with desired characteristics.\n    ",
        "primary_category": "cs.CE",
        "categories": [],
        "submitted_date": "2 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01090": {
        "title": "Sharing Frissons among Online Video Viewers: Exploring the Design of Affective Communication for Aesthetic Chills",
        "authors": [
            "Zeyu Huang",
            "Xinyi Cao",
            "Yuanhao Zhang",
            "Xiaojuan Ma"
        ],
        "comments": "Accepted by CHI24",
        "subjects": "Human-Computer Interaction (cs.HC)",
        "abstract": "On online video platforms, viewers often lack a channel to sense others' and express their affective state on the fly compared to co-located group-viewing. This study explored the design of complementary affective communication specifically for effortless, spontaneous sharing of frissons during video watching. Also known as aesthetic chills, frissons are instant psycho-physiological reactions like goosebumps and shivers to arousing stimuli. We proposed an approach that unobtrusively detects viewers' frissons using skin electrodermal activity sensors and presents the aggregated data alongside online videos. Following a design process of brainstorming, focus group interview (N=7), and design iterations, we proposed three different designs to encode viewers' frisson experiences, namely, ambient light, icon, and vibration. A mixed-methods within-subject study (N=48) suggested that our approach offers a non-intrusive and efficient way to share viewers' frisson moments, increases the social presence of others as if watching together, and can create affective contagion among viewers.\n    ",
        "primary_category": "cs.HC",
        "categories": [],
        "submitted_date": "2 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01091": {
        "title": "COOL: A Conjoint Perspective on Spatio-Temporal Graph Neural Network for Traffic Forecasting",
        "authors": [
            "Wei Ju",
            "Yusheng Zhao",
            "Yifang Qin",
            "Siyu Yi",
            "Jingyang Yuan",
            "Zhiping Xiao",
            "Xiao Luo",
            "Xiting Yan",
            "Ming Zhang"
        ],
        "comments": "Accepted by Information Fusion 2024",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "This paper investigates traffic forecasting, which attempts to forecast the future state of traffic based on historical situations. This problem has received ever-increasing attention in various scenarios and facilitated the development of numerous downstream applications such as urban planning and transportation management. However, the efficacy of existing methods remains sub-optimal due to their tendency to model temporal and spatial relationships independently, thereby inadequately accounting for complex high-order interactions of both worlds. Moreover, the diversity of transitional patterns in traffic forecasting makes them challenging to capture for existing approaches, warranting a deeper exploration of their diversity. Toward this end, this paper proposes Conjoint Spatio-Temporal graph neural network (abbreviated as COOL), which models heterogeneous graphs from prior and posterior information to conjointly capture high-order spatio-temporal relationships. On the one hand, heterogeneous graphs connecting sequential observation are constructed to extract composite spatio-temporal relationships via prior message passing. On the other hand, we model dynamic relationships using constructed affinity and penalty graphs, which guide posterior message passing to incorporate complementary semantic information into node representations. Moreover, to capture diverse transitional properties to enhance traffic forecasting, we propose a conjoint self-attention decoder that models diverse temporal patterns from both multi-rank and multi-scale views. Experimental results on four popular benchmark datasets demonstrate that our proposed COOL provides state-of-the-art performance compared with the competitive baselines.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.AI",
            "cs.IR",
            "cs.SI"
        ],
        "submitted_date": "2 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01092": {
        "title": "Pairwise Alignment Improves Graph Domain Adaptation",
        "authors": [
            "Shikun Liu",
            "Deyu Zou",
            "Han Zhao",
            "Pan Li"
        ],
        "comments": "Our code and data are available at: this https URL",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Graph-based methods, pivotal for label inference over interconnected objects in many real-world applications, often encounter generalization challenges, if the graph used for model training differs significantly from the graph used for testing. This work delves into Graph Domain Adaptation (GDA) to address the unique complexities of distribution shifts over graph data, where interconnected data points experience shifts in features, labels, and in particular, connecting patterns. We propose a novel, theoretically principled method, Pairwise Alignment (Pair-Align) to counter graph structure shift by mitigating conditional structure shift (CSS) and label shift (LS). Pair-Align uses edge weights to recalibrate the influence among neighboring nodes to handle CSS and adjusts the classification loss with label weights to handle LS. Our method demonstrates superior performance in real-world applications, including node classification with region shift in social networks, and the pileup mitigation task in particle colliding experiments. For the first application, we also curate the largest dataset by far for GDA studies. Our method shows strong performance in synthetic and other existing benchmark datasets.\n    ",
        "primary_category": "cs.LG",
        "categories": [],
        "submitted_date": "2 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01095": {
        "title": "Inevitable-Metaverse: A Novel Twitter Dataset for Public Sentiments on Metaverse",
        "authors": [
            "Kadhim Hayawi",
            "Sakib Shahriar",
            "Mohamed Adel Serhani",
            "Eiman Alothali"
        ],
        "comments": " ",
        "subjects": "Computers and Society (cs.CY)",
        "abstract": "Metaverse has emerged as a novel technology with the objective to merge the physical world into the virtual world. This technology has seen a lot of interest and investment in recent times from prominent organizations including Facebook which has changed its company name to Meta with the goal of being the leader in developing this technology. Although people in general are excited about the prospects of metaverse due to potential use cases such as virtual meetings and virtual learning environments, there are also concerns due to potential negative consequences. For instance, people are concerned about their data privacy as well as spending a lot of their time on the metaverse leading to negative impacts in real life. Therefore, this research aims to further investigate the public sentiments regarding metaverse on social media. A total of 86565 metaverse-related tweets were used to perform lexicon-based sentiment analysis. Furthermore, various machine and deep learning models with various text features were utilized to predict the sentiment class. The BERT transformer model was demonstrated to be the best at predicting the sentiment categories with 92.6% accuracy and 0.91 F-measure on the test dataset. Finally, the implications and future research directions were also discussed.\n    ",
        "primary_category": "cs.CY",
        "categories": [],
        "submitted_date": "2 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01098": {
        "title": "Low Complexity Deep Learning Augmented Wireless Channel Estimation for Pilot-Based OFDM on Zynq System on Chip",
        "authors": [
            "Animesh Sharma",
            "Syed Asrar Ul Haq",
            "Sumit J. Darak"
        ],
        "comments": " ",
        "subjects": "Signal Processing (eess.SP)",
        "abstract": "Channel estimation (CE) is one of the critical signal-processing tasks of the wireless physical layer (PHY). Recent deep learning (DL) based CE have outperformed statistical approaches such as least-square-based CE (LS) and linear minimum mean square error-based CE (LMMSE). However, existing CE approaches have not yet been realized on system-on-chip (SoC). The first contribution of this paper is to efficiently implement the existing state-of-the-art CE algorithms on Zynq SoC (ZSoC), comprising of ARM processor and field programmable gate array (FPGA), via hardware-software co-design and fixed point analysis. We validate the superiority of DL-based CE and LMMSE over LS for various signal-to-noise ratios (SNR) and wireless channels in terms of mean square error (MSE) and bit error rate (BER). We also highlight the high complexity, execution time, and power consumption of DL-based CE and LMMSE approaches. To address this, we propose a novel compute-efficient LS-augmented interpolated deep neural network (LSiDNN) based CE algorithm and realize it on ZSoC. The proposed LSiDNN offers 88-90% lower execution time and 38-85% lower resource utilization than state-of-the-art DL-based CE for identical MSE and BER. LSiDNN offers significantly lower MSE and BER than LMMSE, and the gain improves with increased mobility between transceivers. It offers 75% lower execution time and 90-94% lower resource utilization than LMMSE.\n    ",
        "primary_category": "eess.SP",
        "categories": [
            "cs.AR"
        ],
        "submitted_date": "2 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01100": {
        "title": "Adaptive Security in 6G for Sustainable Healthcare",
        "authors": [
            "Ijaz Ahmad",
            "Ijaz Ahmad",
            "Erkki Harjula"
        ],
        "comments": "9 pages,2 figures, accepted by NCDHWS, to be published by Springer",
        "subjects": "Cryptography and Security (cs.CR)",
        "abstract": "6G will fulfill the requirements of future digital healthcare systems through emerging decentralized computing and secure communications technologies. Digital healthcare solutions employ numerous low-power and resource-constrained connected things, such as the Internet of Medical Things (IoMT). However, the current digital healthcare solutions will face two major challenges. First, the proposed solutions are based on the traditional IoT-Cloud model that will experience latency and reliability challenges to meet the expectations and requirements of digital healthcare, while potentially inflicting heavy network load. Second, the existing digital healthcare solutions will face security challenges due to the inherent limitations of IoMT caused by the lack of resources for proper security in those devices. Therefore, in this research, we present a decentralized adaptive security architecture for the successful deployment of digital healthcare. The proposed architecture leverages the edge-cloud continuum to meet the performance, efficiency, and reliability requirements. It can adapt the security solution at run-time to meet the limited capacity of IoMT devices without compromising the security of critical data. Finally, the research outlines comprehensive methodologies for validating the proposed security architecture.\n    ",
        "primary_category": "cs.CR",
        "categories": [],
        "submitted_date": "2 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01101": {
        "title": "Feature Alignment: Rethinking Efficient Active Learning via Proxy in the Context of Pre-trained Models",
        "authors": [
            "Ziting Wen",
            "Oscar Pizarro",
            "Stefan Williams"
        ],
        "comments": " ",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Fine-tuning the pre-trained model with active learning holds promise for reducing annotation costs. However, this combination introduces significant computational costs, particularly with the growing scale of pre-trained models. Recent research has proposed proxy-based active learning, which pre-computes features to reduce computational costs. Yet, this approach often incurs a significant loss in active learning performance, which may even outweigh the computational cost savings. In this paper, we argue the performance drop stems not only from pre-computed features' inability to distinguish between categories of labeled samples, resulting in the selection of redundant samples but also from the tendency to compromise valuable pre-trained information when fine-tuning with samples selected through the proxy model. To address this issue, we propose a novel method called aligned selection via proxy to update pre-computed features while selecting a proper training method to inherit valuable pre-training information. Extensive experiments validate that our method significantly improves the total cost of efficient active learning while maintaining computational efficiency.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "2 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01102": {
        "title": "Real-time hybrid controls of energy storage and load shedding for integrated power and energy systems of ships",
        "authors": [
            "Linh Vu",
            "Thai-Thanh Nguyen",
            "Bang Le-Huy Nguyen",
            "Md Isfakul Anam",
            "Tuyen Vu"
        ],
        "comments": "15 pages, 17 figures",
        "subjects": "Systems and Control (eess.SY)",
        "abstract": "This paper presents an original energy management methodology to enhance the resilience of ship power systems. The integration of various energy storage systems (ESS), including battery energy storage systems (BESS) and super-capacitor energy storage systems (SCESS), in modern ship power systems poses challenges in designing an efficient energy management system (EMS). The EMS proposed in this paper aims to achieve multiple objectives. The primary objective is to minimize shed loads, while the secondary objective is to effectively manage different types of ESS. Considering the diverse ramp-rate characteristics of generators, SCESS, and BESS, the proposed EMS exploits these differences to determine an optimal long-term schedule for minimizing shed loads. Furthermore, the proposed EMS balances the state-of-charge (SoC) of ESS and prioritizes the SCESS's SoC levels to ensure the efficient operation of BESS and SCESS. For better computational efficiency, we introduce the receding horizon optimization method, enabling real-time EMS implementation. A comparison with the fixed horizon optimization (FHO) validates its effectiveness. Simulation studies and results demonstrate that the proposed EMS efficiently manages generators, BESS, and SCESS, ensuring system resilience under generation shortages. Additionally, the proposed methodology significantly reduces the computational burden compared to the FHO technique while maintaining acceptable resilience performance.\n    ",
        "primary_category": "eess.SY",
        "categories": [],
        "submitted_date": "2 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01105": {
        "title": "Depth Information Assisted Collaborative Mutual Promotion Network for Single Image Dehazing",
        "authors": [
            "Yafei Zhang",
            "Shen Zhou",
            "Huafeng Li"
        ],
        "comments": " ",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Recovering a clear image from a single hazy image is an open inverse problem. Although significant research progress has been made, most existing methods ignore the effect that downstream tasks play in promoting upstream dehazing. From the perspective of the haze generation mechanism, there is a potential relationship between the depth information of the scene and the hazy image. Based on this, we propose a dual-task collaborative mutual promotion framework to achieve the dehazing of a single image. This framework integrates depth estimation and dehazing by a dual-task interaction mechanism and achieves mutual enhancement of their performance. To realize the joint optimization of the two tasks, an alternative implementation mechanism with the difference perception is developed. On the one hand, the difference perception between the depth maps of the dehazing result and the ideal image is proposed to promote the dehazing network to pay attention to the non-ideal areas of the dehazing. On the other hand, by improving the depth estimation performance in the difficult-to-recover areas of the hazy image, the dehazing network can explicitly use the depth information of the hazy image to assist the clear image recovery. To promote the depth estimation, we propose to use the difference between the dehazed image and the ground truth to guide the depth estimation network to focus on the dehazed unideal areas. It allows dehazing and depth estimation to leverage their strengths in a mutually reinforcing manner. Experimental results show that the proposed method can achieve better performance than that of the state-of-the-art approaches.\n    ",
        "primary_category": "cs.CV",
        "categories": [],
        "submitted_date": "2 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01108": {
        "title": "Face Swap via Diffusion Model",
        "authors": [
            "Feifei Wang"
        ],
        "comments": " ",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "This technical report presents a diffusion model based framework for face swapping between two portrait images. The basic framework consists of three components, i.e., IP-Adapter, ControlNet, and Stable Diffusion's inpainting pipeline, for face feature encoding, multi-conditional generation, and face inpainting respectively. Besides, I introduce facial guidance optimization and CodeFormer based blending to further improve the generation quality.\nSpecifically, we engage a recent light-weighted customization method (i.e., DreamBooth-LoRA), to guarantee the identity consistency by 1) using a rare identifier \"sks\" to represent the source identity, and 2) injecting the image features of source portrait into each cross-attention layer like the text features. Then I resort to the strong inpainting ability of Stable Diffusion, and utilize canny image and face detection annotation of the target portrait as the conditions, to guide ContorlNet's generation and align source portrait with the target portrait. To further correct face alignment, we add the facial guidance loss to optimize the text embedding during the sample generation.\n    ",
        "primary_category": "cs.CV",
        "categories": [],
        "submitted_date": "2 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01110": {
        "title": "Grid-based Fast and Structural Visual Odometry",
        "authors": [
            "Zhang Zhihe"
        ],
        "comments": "7 pages",
        "subjects": "Robotics (cs.RO)",
        "abstract": "In the field of Simultaneous Localization and Mapping (SLAM), researchers have always pursued better performance in terms of accuracy and time cost. Traditional algorithms typically rely on fundamental geometric elements in images to establish connections between frames. However, these elements suffer from disadvantages such as uneven distribution and slow extraction. In addition, geometry elements like lines have not been fully utilized in the process of pose estimation. To address these challenges, we propose GFS-VO, a grid-based RGB-D visual odometry algorithm that maximizes the utilization of both point and line features. Our algorithm incorporates fast line extraction and a stable line homogenization scheme to improve feature processing. To fully leverage hidden elements in the scene, we introduce Manhattan Axes (MA) to provide constraints between local map and current frame. Additionally, we have designed an algorithm based on breadth-first search for extracting plane normal vectors. To evaluate the performance of GFS-VO, we conducted extensive experiments. The results demonstrate that our proposed algorithm exhibits significant improvements in both time cost and accuracy compared to existing approaches.\n    ",
        "primary_category": "cs.RO",
        "categories": [],
        "submitted_date": "2 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01116": {
        "title": "MulCogBench: A Multi-modal Cognitive Benchmark Dataset for Evaluating Chinese and English Computational Language Models",
        "authors": [
            "Yunhao Zhang",
            "Xiaohan Zhang",
            "Chong Li",
            "Shaonan Wang",
            "Chengqing Zong"
        ],
        "comments": " ",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "Pre-trained computational language models have recently made remarkable progress in harnessing the language abilities which were considered unique to humans. Their success has raised interest in whether these models represent and process language like humans. To answer this question, this paper proposes MulCogBench, a multi-modal cognitive benchmark dataset collected from native Chinese and English participants. It encompasses a variety of cognitive data, including subjective semantic ratings, eye-tracking, functional magnetic resonance imaging (fMRI), and magnetoencephalography (MEG). To assess the relationship between language models and cognitive data, we conducted a similarity-encoding analysis which decodes cognitive data based on its pattern similarity with textual embeddings. Results show that language models share significant similarities with human cognitive data and the similarity patterns are modulated by the data modality and stimuli complexity. Specifically, context-aware models outperform context-independent models as language stimulus complexity increases. The shallow layers of context-aware models are better aligned with the high-temporal-resolution MEG signals whereas the deeper layers show more similarity with the high-spatial-resolution fMRI. These results indicate that language models have a delicate relationship with brain language representations. Moreover, the results between Chinese and English are highly consistent, suggesting the generalizability of these findings across languages.\n    ",
        "primary_category": "cs.CL",
        "categories": [],
        "submitted_date": "2 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01118": {
        "title": "Adversarial Testing for Visual Grounding via Image-Aware Property Reduction",
        "authors": [
            "Zhiyuan Chang",
            "Mingyang Li",
            "Junjie Wang",
            "Cheng Li",
            "Boyu Wu",
            "Fanjiang Xu",
            "Qing Wang"
        ],
        "comments": "14pages, 6 figures",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Due to the advantages of fusing information from various modalities, multimodal learning is gaining increasing attention. Being a fundamental task of multimodal learning, Visual Grounding (VG), aims to locate objects in images through natural language expressions. Ensuring the quality of VG models presents significant challenges due to the complex nature of the task. In the black box scenario, existing adversarial testing techniques often fail to fully exploit the potential of both modalities of information. They typically apply perturbations based solely on either the image or text information, disregarding the crucial correlation between the two modalities, which would lead to failures in test oracles or an inability to effectively challenge VG models. To this end, we propose PEELING, a text perturbation approach via image-aware property reduction for adversarial testing of the VG model. The core idea is to reduce the property-related information in the original expression meanwhile ensuring the reduced expression can still uniquely describe the original object in the image. To achieve this, PEELING first conducts the object and properties extraction and recombination to generate candidate property reduction expressions. It then selects the satisfied expressions that accurately describe the original object while ensuring no other objects in the image fulfill the expression, through querying the image with a visual understanding technique. We evaluate PEELING on the state-of-the-art VG model, i.e. OFA-VG, involving three commonly used datasets. Results show that the adversarial tests generated by PEELING achieves 21.4% in MultiModal Impact score (MMI), and outperforms state-of-the-art baselines for images and texts by 8.2%--15.1%.\n    ",
        "primary_category": "cs.CV",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "2 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01123": {
        "title": "ELA: Efficient Local Attention for Deep Convolutional Neural Networks",
        "authors": [
            "Wei Xu",
            "Yi Wan"
        ],
        "comments": " ",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "The attention mechanism has gained significant recognition in the field of computer vision due to its ability to effectively enhance the performance of deep neural networks. However, existing methods often struggle to effectively utilize spatial information or, if they do, they come at the cost of reducing channel dimensions or increasing the complexity of neural networks. In order to address these limitations, this paper introduces an Efficient Local Attention (ELA) method that achieves substantial performance improvements with a simple structure. By analyzing the limitations of the Coordinate Attention method, we identify the lack of generalization ability in Batch Normalization, the adverse effects of dimension reduction on channel attention, and the complexity of attention generation process. To overcome these challenges, we propose the incorporation of 1D convolution and Group Normalization feature enhancement techniques. This approach enables accurate localization of regions of interest by efficiently encoding two 1D positional feature maps without the need for dimension reduction, while allowing for a lightweight implementation. We carefully design three hyperparameters in ELA, resulting in four different versions: ELA-T, ELA-B, ELA-S, and ELA-L, to cater to the specific requirements of different visual tasks such as image classification, object detection and sementic segmentation. ELA can be seamlessly integrated into deep CNN networks such as ResNet, MobileNet, and DeepLab. Extensive evaluations on the ImageNet, MSCOCO, and Pascal VOC datasets demonstrate the superiority of the proposed ELA module over current state-of-the-art methods in all three aforementioned visual tasks.\n    ",
        "primary_category": "cs.CV",
        "categories": [],
        "submitted_date": "2 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01124": {
        "title": "Text-guided Explorable Image Super-resolution",
        "authors": [
            "Kanchana Vaishnavi Gandikota",
            "Paramanand Chandramouli"
        ],
        "comments": "CVPR 2024",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "In this paper, we introduce the problem of zero-shot text-guided exploration of the solutions to open-domain image super-resolution. Our goal is to allow users to explore diverse, semantically accurate reconstructions that preserve data consistency with the low-resolution inputs for different large downsampling factors without explicitly training for these specific degradations. We propose two approaches for zero-shot text-guided super-resolution - i) modifying the generative process of text-to-image \\textit{T2I} diffusion models to promote consistency with low-resolution inputs, and ii) incorporating language guidance into zero-shot diffusion-based restoration methods. We show that the proposed approaches result in diverse solutions that match the semantic meaning provided by the text prompt while preserving data consistency with the degraded inputs. We evaluate the proposed baselines for the task of extreme super-resolution and demonstrate advantages in terms of restoration quality, diversity, and explorability of solutions.\n    ",
        "primary_category": "cs.CV",
        "categories": [],
        "submitted_date": "2 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01127": {
        "title": "Towards RehabCoach: Design and Preliminary Evaluation of a Conversational Agent Supporting Unsupervised Therapy after Stroke",
        "authors": [
            "Giada Devittori",
            "Mehdi Akeddar",
            "Alexandra Retevoi",
            "Fabian Schneider",
            "Viktoria Cvetkova",
            "Daria Dinacci",
            "Antonella Califfi",
            "Paolo Rossi",
            "Claudio Petrillo",
            "Tobias Kowatsch",
            "Olivier Lambercy"
        ],
        "comments": "6 pages, 3 figures",
        "subjects": "Human-Computer Interaction (cs.HC)",
        "abstract": "Unsupervised therapy after stroke is a promising way to boost therapy dose without significantly increasing the workload on healthcare professionals. However, it raises important challenges, such as lower adherence to therapy in the absence of social interaction with therapists. We present the initial prototype of RehabCoach, a novel smartphone-based app with conversational agent to support unsupervised therapy. RehabCoach is designed to increase patients engagement and adherence to therapy and to provide information (e.g., about stroke, health) in an interactive and user-friendly manner. We report on the design and usability evaluation of the first prototype of RehabCoach, assessed by four stroke patients and five healthcare professionals, who interacted with the app in a single testing session. Task completion time and success rates were measured for 15 representative tasks, and participants assessed usability via questionnaires and a semi-structured interview. Results show that it was feasible for stroke patients to successfully interact with RehabCoach (task success $\\geq$ 93 $\\%$) without requiring extensive training. Participants positively rated the usability of RehabCoach (mean mHealth App Usability Questionnaire score: 1.3 for primary users, 1.4 for healthcare professionals, on a scale from 1 (positive evaluation) to 7). The feedback collected in this work opens the door to further enhance RehabCoach as an interactive digital tool to support unsupervised rehabilitation.\n    ",
        "primary_category": "cs.HC",
        "categories": [],
        "submitted_date": "2 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01129": {
        "title": "Dynamic 3D Point Cloud Sequences as 2D Videos",
        "authors": [
            "Yiming Zeng",
            "Junhui Hou",
            "Qijian Zhang",
            "Siyu Ren",
            "Wenping Wang"
        ],
        "comments": " ",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Dynamic 3D point cloud sequences serve as one of the most common and practical representation modalities of dynamic real-world environments. However, their unstructured nature in both spatial and temporal domains poses significant challenges to effective and efficient processing. Existing deep point cloud sequence modeling approaches imitate the mature 2D video learning mechanisms by developing complex spatio-temporal point neighbor grouping and feature aggregation schemes, often resulting in methods lacking effectiveness, efficiency, and expressive power. In this paper, we propose a novel generic representation called \\textit{Structured Point Cloud Videos} (SPCVs). Intuitively, by leveraging the fact that 3D geometric shapes are essentially 2D manifolds, SPCV re-organizes a point cloud sequence as a 2D video with spatial smoothness and temporal consistency, where the pixel values correspond to the 3D coordinates of points. The structured nature of our SPCV representation allows for the seamless adaptation of well-established 2D image/video techniques, enabling efficient and effective processing and analysis of 3D point cloud sequences. To achieve such re-organization, we design a self-supervised learning pipeline that is geometrically regularized and driven by self-reconstructive and deformation field learning objectives. Additionally, we construct SPCV-based frameworks for both low-level and high-level 3D point cloud sequence processing and analysis tasks, including action recognition, temporal interpolation, and compression. Extensive experiments demonstrate the versatility and superiority of the proposed SPCV, which has the potential to offer new possibilities for deep learning on unstructured 3D point cloud sequences. Code will be released at this https URL.\n    ",
        "primary_category": "cs.CV",
        "categories": [],
        "submitted_date": "2 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01132": {
        "title": "MPIPN: A Multi Physics-Informed PointNet for solving parametric acoustic-structure systems",
        "authors": [
            "Chu Wang",
            "Jinhong Wu",
            "Yanzhi Wang",
            "Zhijian Zha",
            "Qi Zhou"
        ],
        "comments": "The number of figures is 16. The number of tables is 5. The number of words is 9717",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Machine learning is employed for solving physical systems governed by general nonlinear partial differential equations (PDEs). However, complex multi-physics systems such as acoustic-structure coupling are often described by a series of PDEs that incorporate variable physical quantities, which are referred to as parametric systems. There are lack of strategies for solving parametric systems governed by PDEs that involve explicit and implicit quantities. In this paper, a deep learning-based Multi Physics-Informed PointNet (MPIPN) is proposed for solving parametric acoustic-structure systems. First, the MPIPN induces an enhanced point-cloud architecture that encompasses explicit physical quantities and geometric features of computational domains. Then, the MPIPN extracts local and global features of the reconstructed point-cloud as parts of solving criteria of parametric systems, respectively. Besides, implicit physical quantities are embedded by encoding techniques as another part of solving criteria. Finally, all solving criteria that characterize parametric systems are amalgamated to form distinctive sequences as the input of the MPIPN, whose outputs are solutions of systems. The proposed framework is trained by adaptive physics-informed loss functions for corresponding computational domains. The framework is generalized to deal with new parametric conditions of systems. The effectiveness of the MPIPN is validated by applying it to solve steady parametric acoustic-structure coupling systems governed by the Helmholtz equations. An ablation experiment has been implemented to demonstrate the efficacy of physics-informed impact with a minority of supervised data. The proposed method yields reasonable precision across all computational domains under constant parametric conditions and changeable combinations of parametric conditions for acoustic-structure systems.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.SD",
            "eess.AS"
        ],
        "submitted_date": "2 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01136": {
        "title": "LLM-PQ: Serving LLM on Heterogeneous Clusters with Phase-Aware Partition and Adaptive Quantization",
        "authors": [
            "Juntao Zhao",
            "Borui Wan",
            "Yanghua Peng",
            "Haibin Lin",
            "Chuan Wu"
        ],
        "comments": " ",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Recent breakthroughs in Large-scale language models (LLMs) have demonstrated impressive performance on various tasks. The immense sizes of LLMs have led to very high resource demand and cost for running the models. Though the models are largely served using uniform high-caliber GPUs nowadays, utilizing a heterogeneous cluster with a mix of available high- and low-capacity GPUs can potentially substantially reduce the serving cost. There is a lack of designs to support efficient LLM serving using a heterogeneous cluster, while the current solutions focus on model partition and uniform compression among homogeneous devices. This paper proposes LLM-PQ, a system that advocates adaptive model quantization and phase-aware partition to improve LLM serving efficiency on heterogeneous GPU clusters. We carefully decide on mixed-precision model quantization together with phase-aware model partition and micro-batch sizing in distributed LLM serving with an efficient algorithm, to greatly enhance inference throughput while fulfilling user-specified model quality targets. Extensive experiments on production inference workloads in 11 different clusters demonstrate that LLM-PQ achieves up to 2.88x (2.26x on average) throughput improvement in inference, showing great advantages over state-of-the-art works.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.AI",
            "cs.DC"
        ],
        "submitted_date": "2 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01137": {
        "title": "Neural radiance fields-based holography [Invited]",
        "authors": [
            "Minsung Kang",
            "Fan Wang",
            "Kai Kumano",
            "Tomoyoshi Ito",
            "Tomoyoshi Shimobaba"
        ],
        "comments": " ",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "This study presents a novel approach for generating holograms based on the neural radiance fields (NeRF) technique. Generating three-dimensional (3D) data is difficult in hologram computation. NeRF is a state-of-the-art technique for 3D light-field reconstruction from 2D images based on volume rendering. The NeRF can rapidly predict new-view images that do not include a training dataset. In this study, we constructed a rendering pipeline directly from a 3D light field generated from 2D images by NeRF for hologram generation using deep neural networks within a reasonable time. The pipeline comprises three main components: the NeRF, a depth predictor, and a hologram generator, all constructed using deep neural networks. The pipeline does not include any physical calculations. The predicted holograms of a 3D scene viewed from any direction were computed using the proposed pipeline. The simulation and experimental results are presented.\n    ",
        "primary_category": "cs.CV",
        "categories": [
            "cs.GR",
            "eess.IV"
        ],
        "submitted_date": "2 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01142": {
        "title": "Edge-guided Low-light Image Enhancement with Inertial Bregman Alternating Linearized Minimization",
        "authors": [
            "Chaoyan Huang",
            "Zhongming Wu",
            "Tieyong Zeng"
        ],
        "comments": "15 pages",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Prior-based methods for low-light image enhancement often face challenges in extracting available prior information from dim images. To overcome this limitation, we introduce a simple yet effective Retinex model with the proposed edge extraction prior. More specifically, we design an edge extraction network to capture the fine edge features from the low-light image directly. Building upon the Retinex theory, we decompose the low-light image into its illumination and reflectance components and introduce an edge-guided Retinex model for enhancing low-light images. To solve the proposed model, we propose a novel inertial Bregman alternating linearized minimization algorithm. This algorithm addresses the optimization problem associated with the edge-guided Retinex model, enabling effective enhancement of low-light images. Through rigorous theoretical analysis, we establish the convergence properties of the algorithm. Besides, we prove that the proposed algorithm converges to a stationary point of the problem through nonconvex optimization theory. Furthermore, extensive experiments are conducted on multiple real-world low-light image datasets to demonstrate the efficiency and superiority of the proposed scheme.\n    ",
        "primary_category": "cs.CV",
        "categories": [
            "math.NA"
        ],
        "submitted_date": "2 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01144": {
        "title": "Extrapolated Plug-and-Play Three-Operator Splitting Methods for Nonconvex Optimization with Applications to Image Restoration",
        "authors": [
            "Zhongming Wu",
            "Chaoyan Huang",
            "Tieyong Zeng"
        ],
        "comments": "37 Pages",
        "subjects": "Numerical Analysis (math.NA)",
        "abstract": "This paper investigates the convergence properties and applications of the three-operator splitting method, also known as Davis-Yin splitting (DYS) method, integrated with extrapolation and Plug-and-Play (PnP) denoiser within a nonconvex framework. We first propose an extrapolated DYS method to effectively solve a class of structural nonconvex optimization problems that involve minimizing the sum of three possible nonconvex functions. Our approach provides an algorithmic framework that encompasses both extrapolated forward-backward splitting and extrapolated Douglas-Rachford splitting this http URL establish the convergence of the proposed method, we rigorously analyze its behavior based on the Kurdyka-\u0141ojasiewicz property, subject to some tight parameter conditions. Moreover, we introduce two extrapolated PnP-DYS methods with convergence guarantee, where the traditional regularization prior is replaced by a gradient step-based denoiser. This denoiser is designed using a differentiable neural network and can be reformulated as the proximal operator of a specific nonconvex functional. We conduct extensive experiments on image deblurring and image super-resolution problems, where our results showcase the advantage of the extrapolation strategy and the superior performance of the learning-based model that incorporates the PnP denoiser in terms of achieving high-quality recovery images.\n    ",
        "primary_category": "math.NA",
        "categories": [],
        "submitted_date": "2 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01146": {
        "title": "Mutation Analysis with Execution Taints",
        "authors": [
            "Rahul Gopinath",
            "Philipp Goerz"
        ],
        "comments": " ",
        "subjects": "Software Engineering (cs.SE)",
        "abstract": "Mutation analysis is one of the most effective, but costly means of assessing the ability of software test suites to prevent bugs. Traditional mutation analysis involves producing and evaluating syntactic variants of the original to check whether the test suite under evaluation is capable of distinguishing between the variant and the original in terms of behavior.\nEvaluating each mutant separately means a large amount of redundant computation, both between the original program and mutants, and also between different mutants. Previous work explored numerous means of removing redundancy. However, some amount of redundancy has remained especially in the post-mutation phase.\nIn this paper, we propose execution taints--A novel technique that repurposes dynamic data-flow taints for mutation analysis. Our technique is the only technique that can remove the redundancy in post-mutation phase, achieving better efficiency in mutation analysis. We further leverage memoization to eliminate redundant execution between program variants.\n    ",
        "primary_category": "cs.SE",
        "categories": [],
        "submitted_date": "2 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01147": {
        "title": "A Hybrid Model for Traffic Incident Detection based on Generative Adversarial Networks and Transformer Model",
        "authors": [
            "Xinying Lu",
            "Doudou Zhang",
            "Jianli Xiao"
        ],
        "comments": "19 pages, 8 figures",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "In addition to enhancing traffic safety and facilitating prompt emergency response, traffic incident detection plays an indispensable role in intelligent transportation systems by providing real-time traffic status information. This enables the realization of intelligent traffic control and management. Previous research has identified that apart from employing advanced algorithmic models, the effectiveness of detection is also significantly influenced by challenges related to acquiring large datasets and addressing dataset imbalances. A hybrid model combining transformer and generative adversarial networks (GANs) is proposed to address these challenges. Experiments are conducted on four real datasets to validate the superiority of the transformer in traffic incident detection. Additionally, GANs are utilized to expand the dataset and achieve a balanced ratio of 1:4, 2:3, and 1:1. The proposed model is evaluated against the baseline model. The results demonstrate that the proposed model enhances the dataset size, balances the dataset, and improves the performance of traffic incident detection in various aspects.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "2 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01152": {
        "title": "A Survey of AI-generated Text Forensic Systems: Detection, Attribution, and Characterization",
        "authors": [
            "Tharindu Kumarage",
            "Garima Agrawal",
            "Paras Sheth",
            "Raha Moraffah",
            "Aman Chadha",
            "Joshua Garland",
            "Huan Liu"
        ],
        "comments": " ",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "We have witnessed lately a rapid proliferation of advanced Large Language Models (LLMs) capable of generating high-quality text. While these LLMs have revolutionized text generation across various domains, they also pose significant risks to the information ecosystem, such as the potential for generating convincing propaganda, misinformation, and disinformation at scale. This paper offers a review of AI-generated text forensic systems, an emerging field addressing the challenges of LLM misuses. We present an overview of the existing efforts in AI-generated text forensics by introducing a detailed taxonomy, focusing on three primary pillars: detection, attribution, and characterization. These pillars enable a practical understanding of AI-generated text, from identifying AI-generated content (detection), determining the specific AI model involved (attribution), and grouping the underlying intents of the text (characterization). Furthermore, we explore available resources for AI-generated text forensics research and discuss the evolving challenges and future directions of forensic systems in an AI era.\n    ",
        "primary_category": "cs.CL",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "2 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01155": {
        "title": "Query Recovery from Easy to Hard: Jigsaw Attack against SSE",
        "authors": [
            "Hao Nie",
            "Wei Wang",
            "Peng Xu",
            "Xianglong Zhang",
            "Laurence T. Yang",
            "Kaitai Liang"
        ],
        "comments": "21 pages, accepted in USENIX Security 2024",
        "subjects": "Cryptography and Security (cs.CR)",
        "abstract": "Searchable symmetric encryption schemes often unintentionally disclose certain sensitive information, such as access, volume, and search patterns. Attackers can exploit such leakages and other available knowledge related to the user's database to recover queries. We find that the effectiveness of query recovery attacks depends on the volume/frequency distribution of keywords. Queries containing keywords with high volumes/frequencies are more susceptible to recovery, even when countermeasures are implemented. Attackers can also effectively leverage these ``special'' queries to recover all others.\nBy exploiting the above finding, we propose a Jigsaw attack that begins by accurately identifying and recovering those distinctive queries. Leveraging the volume, frequency, and co-occurrence information, our attack achieves $90\\%$ accuracy in three tested datasets, which is comparable to previous attacks (Oya et al., USENIX' 22 and Damie et al., USENIX' 21). With the same runtime, our attack demonstrates an advantage over the attack proposed by Oya et al (approximately $15\\%$ more accuracy when the keyword universe size is 15k). Furthermore, our proposed attack outperforms existing attacks against widely studied countermeasures, achieving roughly $60\\%$ and $85\\%$ accuracy against the padding and the obfuscation, respectively. In this context, with a large keyword universe ($\\geq$3k), it surpasses current state-of-the-art attacks by more than $20\\%$.\n    ",
        "primary_category": "cs.CR",
        "categories": [],
        "submitted_date": "2 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01156": {
        "title": "Auxiliary Tasks Enhanced Dual-affinity Learning for Weakly Supervised Semantic Segmentation",
        "authors": [
            "Lian Xu",
            "Mohammed Bennamoun",
            "Farid Boussaid",
            "Wanli Ouyang",
            "Ferdous Sohel",
            "Dan Xu"
        ],
        "comments": "Accepted at IEEE Transactions on Neural Networks and Learning Systems. arXiv admin note: substantial text overlap with arXiv:2107.11787",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Most existing weakly supervised semantic segmentation (WSSS) methods rely on Class Activation Mapping (CAM) to extract coarse class-specific localization maps using image-level labels. Prior works have commonly used an off-line heuristic thresholding process that combines the CAM maps with off-the-shelf saliency maps produced by a general pre-trained saliency model to produce more accurate pseudo-segmentation labels. We propose AuxSegNet+, a weakly supervised auxiliary learning framework to explore the rich information from these saliency maps and the significant inter-task correlation between saliency detection and semantic segmentation. In the proposed AuxSegNet+, saliency detection and multi-label image classification are used as auxiliary tasks to improve the primary task of semantic segmentation with only image-level ground-truth labels. We also propose a cross-task affinity learning mechanism to learn pixel-level affinities from the saliency and segmentation feature maps. In particular, we propose a cross-task dual-affinity learning module to learn both pairwise and unary affinities, which are used to enhance the task-specific features and predictions by aggregating both query-dependent and query-independent global context for both saliency detection and semantic segmentation. The learned cross-task pairwise affinity can also be used to refine and propagate CAM maps to provide better pseudo labels for both tasks. Iterative improvement of segmentation performance is enabled by cross-task affinity learning and pseudo-label updating. Extensive experiments demonstrate the effectiveness of the proposed approach with new state-of-the-art WSSS results on the challenging PASCAL VOC and MS COCO benchmarks.\n    ",
        "primary_category": "cs.CV",
        "categories": [],
        "submitted_date": "2 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01157": {
        "title": "Different Debt: An Addition to the Technical Debt Dataset and a Demonstration Using Developer Personality",
        "authors": [
            "Lorenz Graf-Vlachy",
            "Stefan Wagner"
        ],
        "comments": " ",
        "subjects": "Software Engineering (cs.SE)",
        "abstract": "Background: The \"Technical Debt Dataset\" (TDD) is a comprehensive dataset on technical debt (TD) in the main branches of more than 30 Java projects. However, some TD items produced by SonarQube are not included for many commits, for instance because the commits failed to compile. This has limited previous studies using the dataset. Aims and Method: In this paper, we provide an addition to the dataset that includes an analysis of 278,320 commits of all branches in a superset of 37 projects using Teamscale. We then demonstrate the utility of the dataset by exploring the relationship between developer personality by replicating a prior study. Results: The new dataset allows us to use a larger sample than prior work could, and we analyze the personality of 111 developers and 5,497 of their commits. The relationships we find between developer personality and the introduction and removal of TD differ from those found in prior work. Conclusions: We offer a dataset that may enable future studies into the topic of TD and we provide additional insights on how developer personality relates to TD.\n    ",
        "primary_category": "cs.SE",
        "categories": [],
        "submitted_date": "2 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01158": {
        "title": "A Bayesian Committee Machine Potential for Oxygen-containing Organic Compounds",
        "authors": [
            "Seungwon Kim",
            "D. ChangMo Yang",
            "Soohaeng Yoo Willow",
            "Chang Woo Myung"
        ],
        "comments": " ",
        "subjects": "Materials Science (cond-mat.mtrl-sci)",
        "abstract": "Understanding the pivotal role of oxygen-containing organic compounds in serving as an energy source for living organisms and contributing to protein formation is crucial in the field of biochemistry. This study addresses the challenge of comprehending protein-protein interactions (PPI) and developing predicitive models for proteins and organic compounds, with a specific focus on quantifying their binding affinity. Here, we introduce the active Bayesian Committee Machine (BCM) potential, specifically designed to predict oxygen-containing organic compounds within eight groups of CHO. The BCM potential adopts a committee-based approach to tackle scalability issues associated with kernel regressors, particularly when dealing with large datasets. Its adaptable structure allows for efficient and cost-effective expansion, maintaing both transferability and scalability. Through systematic benchmarking, we position the sparse BCM potential as a promising contender in the pursuit of a universal machine learning potential.\n    ",
        "primary_category": "cond-mat.mtrl-sci",
        "categories": [
            "cs.LG"
        ],
        "submitted_date": "2 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01163": {
        "title": "BootTOD: Bootstrap Task-oriented Dialogue Representations by Aligning Diverse Responses",
        "authors": [
            "Weihao Zeng",
            "Keqing He",
            "Yejie Wang",
            "Dayuan Fu",
            "Weiran Xu"
        ],
        "comments": "Accepted at LREC-COLING 2024",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "Pre-trained language models have been successful in many scenarios. However, their usefulness in task-oriented dialogues is limited due to the intrinsic linguistic differences between general text and task-oriented dialogues. Current task-oriented dialogue pre-training methods rely on a contrastive framework, which faces challenges such as selecting true positives and hard negatives, as well as lacking diversity. In this paper, we propose a novel dialogue pre-training model called BootTOD. It learns task-oriented dialogue representations via a self-bootstrapping framework. Unlike contrastive counterparts, BootTOD aligns context and context+response representations and dismisses the requirements of contrastive pairs. BootTOD also uses multiple appropriate response targets to model the intrinsic one-to-many diversity of human conversations. Experimental results show that BootTOD outperforms strong TOD baselines on diverse downstream dialogue tasks.\n    ",
        "primary_category": "cs.CL",
        "categories": [],
        "submitted_date": "2 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01164": {
        "title": "HeteGen: Heterogeneous Parallel Inference for Large Language Models on Resource-Constrained Devices",
        "authors": [
            "Xuanlei Zhao",
            "Bin Jia",
            "Haotian Zhou",
            "Ziming Liu",
            "Shenggan Cheng",
            "Yang You"
        ],
        "comments": "MLSys 2024",
        "subjects": "Performance (cs.PF)",
        "abstract": "In recent times, the emergence of Large Language Models (LLMs) has resulted in increasingly larger model size, posing challenges for inference on low-resource devices. Prior approaches have explored offloading to facilitate low-memory inference but often suffer from efficiency due to I/O bottlenecks. To achieve low-latency LLMs inference on resource-constrained devices, we introduce HeteGen, a novel approach that presents a principled framework for heterogeneous parallel computing using CPUs and GPUs. Based on this framework, HeteGen further employs heterogeneous parallel computing and asynchronous overlap for LLMs to mitigate I/O bottlenecks. Our experiments demonstrate a substantial improvement in inference speed, surpassing state-of-the-art methods by over 317% at most.\n    ",
        "primary_category": "cs.PF",
        "categories": [
            "cs.DC"
        ],
        "submitted_date": "2 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01165": {
        "title": "STAR: Constraint LoRA with Dynamic Active Learning for Data-Efficient Fine-Tuning of Large Language Models",
        "authors": [
            "Linhai Zhang",
            "Jialong Wu",
            "Deyu Zhou",
            "Guoqiang Xu"
        ],
        "comments": "Our code and results will be available at this https URL",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "Though Large Language Models (LLMs) have demonstrated the powerful capabilities of few-shot learning through prompting methods, supervised training is still necessary for complex reasoning tasks. Because of their extensive parameters and memory consumption, both Parameter-Efficient Fine-Tuning (PEFT) methods and Memory-Efficient Fine-Tuning methods have been proposed for LLMs. Nevertheless, the issue of large annotated data consumption, the aim of Data-Efficient Fine-Tuning, remains unexplored. One obvious way is to combine the PEFT method with active learning. However, the experimental results show that such a combination is not trivial and yields inferior results. Through probe experiments, such observation might be explained by two main reasons: uncertainty gap and poor model calibration. Therefore, in this paper, we propose a novel approach to effectively integrate uncertainty-based active learning and LoRA. Specifically, for the uncertainty gap, we introduce a dynamic uncertainty measurement that combines the uncertainty of the base model and the uncertainty of the full model during the iteration of active learning. For poor model calibration, we incorporate the regularization method during LoRA training to keep the model from being over-confident, and the Monte-Carlo dropout mechanism is employed to enhance the uncertainty estimation. Experimental results show that the proposed approach outperforms existing baseline models on three complex reasoning tasks.\n    ",
        "primary_category": "cs.CL",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "2 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01166": {
        "title": "DINER: Debiasing Aspect-based Sentiment Analysis with Multi-variable Causal Inference",
        "authors": [
            "Jialong Wu",
            "Linhai Zhang",
            "Deyu Zhou",
            "Guoqiang Xu"
        ],
        "comments": "Our code and results will be available at this https URL",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "Though notable progress has been made, neural-based aspect-based sentiment analysis (ABSA) models are prone to learn spurious correlations from annotation biases, resulting in poor robustness on adversarial data transformations. Among the debiasing solutions, causal inference-based methods have attracted much research attention, which can be mainly categorized into causal intervention methods and counterfactual reasoning methods. However, most of the present debiasing methods focus on single-variable causal inference, which is not suitable for ABSA with two input variables (the target aspect and the review). In this paper, we propose a novel framework based on multi-variable causal inference for debiasing ABSA. In this framework, different types of biases are tackled based on different causal intervention methods. For the review branch, the bias is modeled as indirect confounding from context, where backdoor adjustment intervention is employed for debiasing. For the aspect branch, the bias is described as a direct correlation with labels, where counterfactual reasoning is adopted for debiasing. Extensive experiments demonstrate the effectiveness of the proposed method compared to various baselines on the two widely used real-world aspect robustness test set datasets.\n    ",
        "primary_category": "cs.CL",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "2 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01169": {
        "title": "Learn Suspected Anomalies from Event Prompts for Video Anomaly Detection",
        "authors": [
            "Chenchen Tao",
            "Chong Wang",
            "Yuexian Zou",
            "Xiaohao Peng",
            "Jiafei Wu",
            "Jiangbo Qian"
        ],
        "comments": " ",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Most models for weakly supervised video anomaly detection (WS-VAD) rely on multiple instance learning, aiming to distinguish normal and abnormal snippets without specifying the type of anomaly. The ambiguous nature of anomaly definitions across contexts introduces bias in detecting abnormal and normal snippets within the abnormal bag. Taking the first step to show the model why it is anomalous, a novel framework is proposed to guide the learning of suspected anomalies from event prompts. Given a textual prompt dictionary of potential anomaly events and the captions generated from anomaly videos, the semantic anomaly similarity between them could be calculated to identify the suspected anomalous events for each video snippet. It enables a new multi-prompt learning process to constrain the visual-semantic features across all videos, as well as provides a new way to label pseudo anomalies for self-training. To demonstrate effectiveness, comprehensive experiments and detailed ablation studies are conducted on four datasets, namely XD-Violence, UCF-Crime, TAD, and ShanghaiTech. Our proposed model outperforms most state-of-the-art methods in terms of AP or AUC (82.6\\%, 87.7\\%, 93.1\\%, and 97.4\\%). Furthermore, it shows promising performance in open-set and cross-dataset cases.\n    ",
        "primary_category": "cs.CV",
        "categories": [],
        "submitted_date": "2 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01172": {
        "title": "Run-time Introspection of 2D Object Detection in Automated Driving Systems Using Learning Representations",
        "authors": [
            "Hakan Yekta Yatbaz",
            "Mehrdad Dianati",
            "Konstantinos Koufos",
            "Roger Woodman"
        ],
        "comments": "Submitted to IEEE Transactions on Intelligent Vehicles. 15 pages, 7 figures, 11 tables",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Reliable detection of various objects and road users in the surrounding environment is crucial for the safe operation of automated driving systems (ADS). Despite recent progresses in developing highly accurate object detectors based on Deep Neural Networks (DNNs), they still remain prone to detection errors, which can lead to fatal consequences in safety-critical applications such as ADS. An effective remedy to this problem is to equip the system with run-time monitoring, named as introspection in the context of autonomous systems. Motivated by this, we introduce a novel introspection solution, which operates at the frame level for DNN-based 2D object detection and leverages neural network activation patterns. The proposed approach pre-processes the neural activation patterns of the object detector's backbone using several different modes. To provide extensive comparative analysis and fair comparison, we also adapt and implement several state-of-the-art (SOTA) introspection mechanisms for error detection in 2D object detection, using one-stage and two-stage object detectors evaluated on KITTI and BDD datasets. We compare the performance of the proposed solution in terms of error detection, adaptability to dataset shift, and, computational and memory resource requirements. Our performance evaluation shows that the proposed introspection solution outperforms SOTA methods, achieving an absolute reduction in the missed error ratio of 9% to 17% in the BDD dataset.\n    ",
        "primary_category": "cs.CV",
        "categories": [],
        "submitted_date": "2 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01174": {
        "title": "Consistent and Asymptotically Statistically-Efficient Solution to Camera Motion Estimation",
        "authors": [
            "Guangyang Zeng",
            "Qingcheng Zeng",
            "Xinghan Li",
            "Biqiang Mu",
            "Jiming Chen",
            "Ling Shi",
            "Junfeng Wu"
        ],
        "comments": " ",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Given 2D point correspondences between an image pair, inferring the camera motion is a fundamental issue in the computer vision community. The existing works generally set out from the epipolar constraint and estimate the essential matrix, which is not optimal in the maximum likelihood (ML) sense. In this paper, we dive into the original measurement model with respect to the rotation matrix and normalized translation vector and formulate the ML problem. We then propose a two-step algorithm to solve it: In the first step, we estimate the variance of measurement noises and devise a consistent estimator based on bias elimination; In the second step, we execute a one-step Gauss-Newton iteration on manifold to refine the consistent estimate. We prove that the proposed estimate owns the same asymptotic statistical properties as the ML estimate: The first is consistency, i.e., the estimate converges to the ground truth as the point number increases; The second is asymptotic efficiency, i.e., the mean squared error of the estimate converges to the theoretical lower bound -- Cramer-Rao bound. In addition, we show that our algorithm has linear time complexity. These appealing characteristics endow our estimator with a great advantage in the case of dense point correspondences. Experiments on both synthetic data and real images demonstrate that when the point number reaches the order of hundreds, our estimator outperforms the state-of-the-art ones in terms of estimation accuracy and CPU time.\n    ",
        "primary_category": "cs.CV",
        "categories": [],
        "submitted_date": "2 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01181": {
        "title": "Shaping Multi-Robot Patrol Performance with Heterogeneity in Individual Learning Behavior",
        "authors": [
            "Connor York",
            "Zachary R Madin",
            "Paul O'Dowd",
            "Edmund R Hunt"
        ],
        "comments": " ",
        "subjects": "Robotics (cs.RO)",
        "abstract": "Individual differences in learning behavior within social groups, whether in humans, other animals, or among robots, can have significant effects on collective task performance. This is because it can affect individuals' response to the environment and their interactions with each other. In recent years there has been rising interest in the question of how individual differences, whether in learning or other traits, affect collective outcomes: studied, for example, in social insect foraging behavior. Multi-robot, 'swarm' systems have a heritage of bioinspiration from such examples, and here we consider whether heterogeneity in a learning behavior called latent inhibition (LI) may be useful for a team of patrolling robots tasked with environmental monitoring and anomaly detection. Individuals with high LI can be seen as better at learning to be inattentive to irrelevant or unrewarding stimuli, while low LI individuals might be seen as 'distractible' and yet, more positively, more exploratory. We introduce a simple model of the effects of LI as the probability of re-searching a location for a reward (anomalous reading) where it has previously been found to be unrewarding (irrelevant). In simulated patrols, we find that a negatively skewed distribution of mostly high LI robots, and just a single low LI robot, is collectively most effective at monitoring dynamic environments. These results are an example of 'functional heterogeneity' in 'swarm engineering' and could inform predictions for ecological distributions of learning traits within social groups.\n    ",
        "primary_category": "cs.RO",
        "categories": [],
        "submitted_date": "2 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01182": {
        "title": "d-DSE: Distinct Dynamic Searchable Encryption Resisting Volume Leakage in Encrypted Databases",
        "authors": [
            "Dongli Liu",
            "Wei Wang",
            "Peng Xu",
            "Laurence T. Yang",
            "Bo Luo",
            "Kaitai Liang"
        ],
        "comments": "23pages, 13 figures, will be published in USENIX Security'24",
        "subjects": "Cryptography and Security (cs.CR)",
        "abstract": "Dynamic Searchable Encryption (DSE) has emerged as a solution to efficiently handle and protect large-scale data storage in encrypted databases (EDBs). Volume leakage poses a significant threat, as it enables adversaries to reconstruct search queries and potentially compromise the security and privacy of data. Padding strategies are common countermeasures for the leakage, but they significantly increase storage and communication costs. In this work, we develop a new perspective to handle volume leakage. We start with distinct search and further explore a new concept called \\textit{distinct} DSE (\\textit{d}-DSE).\nWe also define new security notions, in particular Distinct with Volume-Hiding security, as well as forward and backward privacy, for the new concept. Based on \\textit{d}-DSE, we construct the \\textit{d}-DSE designed EDB with related constructions for distinct keyword (d-KW-\\textit{d}DSE), keyword (KW-\\textit{d}DSE), and join queries (JOIN-\\textit{d}DSE) and update queries in encrypted databases. We instantiate a concrete scheme \\textsf{BF-SRE}, employing Symmetric Revocable Encryption. We conduct extensive experiments on real-world datasets, such as Crime, Wikipedia, and Enron, for performance evaluation. The results demonstrate that our scheme is practical in data search and with comparable computational performance to the SOTA DSE scheme (\\textsf{MITRA}*, \\textsf{AURA}) and padding strategies (\\textsf{SEAL}, \\textsf{ShieldDB}). Furthermore, our proposal sharply reduces the communication cost as compared to padding strategies, with roughly 6.36 to 53.14x advantage for search queries.\n    ",
        "primary_category": "cs.CR",
        "categories": [],
        "submitted_date": "2 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01183": {
        "title": "Leveraging Self-Supervised Learning for Scene Recognition in Child Sexual Abuse Imagery",
        "authors": [
            "Pedro H. V. Valois",
            "Jo\u00e3o Macedo",
            "Leo S. F. Ribeiro",
            "Jefersson A. dos Santos",
            "Sandra Avila"
        ],
        "comments": "13 pages, 5 figures, 4 tables. Under review",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Crime in the 21st century is split into a virtual and real world. However, the former has become a global menace to people's well-being and security in the latter. The challenges it presents must be faced with unified global cooperation, and we must rely more than ever on automated yet trustworthy tools to combat the ever-growing nature of online offenses. Over 10 million child sexual abuse reports are submitted to the US National Center for Missing & Exploited Children every year, and over 80% originated from online sources. Therefore, investigation centers and clearinghouses cannot manually process and correctly investigate all imagery. In light of that, reliable automated tools that can securely and efficiently deal with this data are paramount. In this sense, the scene recognition task looks for contextual cues in the environment, being able to group and classify child sexual abuse data without requiring to be trained on sensitive material. The scarcity and limitations of working with child sexual abuse images lead to self-supervised learning, a machine-learning methodology that leverages unlabeled data to produce powerful representations that can be more easily transferred to target tasks. This work shows that self-supervised deep learning models pre-trained on scene-centric data can reach 71.6% balanced accuracy on our indoor scene classification task and, on average, 2.2 percentage points better performance than a fully supervised version. We cooperate with Brazilian Federal Police experts to evaluate our indoor classification model on actual child abuse material. The results demonstrate a notable discrepancy between the features observed in widely used scene datasets and those depicted on sensitive materials.\n    ",
        "primary_category": "cs.CV",
        "categories": [
            "cs.AI",
            "cs.CY",
            "cs.LG"
        ],
        "submitted_date": "2 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01185": {
        "title": "Balancing Exploration and Exploitation in LLM using Soft RLLF for Enhanced Negation Understanding",
        "authors": [
            "Ha-Thanh Nguyen",
            "Ken Satoh"
        ],
        "comments": "JURISIN 2024",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "Finetuning approaches in NLP often focus on exploitation rather than exploration, which may lead to suboptimal models. Given the vast search space of natural language, this limited exploration can restrict their performance in complex, high-stakes domains, where accurate negation understanding and logical reasoning abilities are crucial. To address this issue, we leverage Reinforcement Learning from Logical Feedback (RLLF) to create an effective balance between exploration and exploitation in LLMs. Our approach employs an appropriate benchmark dataset for training and evaluation, highlighting the importance of exploration in enhancing negation understanding capabilities. We compare the performance of our RLLF-enhanced LLMs with baseline models trained without RLLF, demonstrating the value of this balanced approach. Furthermore, we showcase the potential of our method in legal AI applications by employing transfer learning and evaluating its impact on negation understanding. Our experimental results exhibit the effectiveness of balancing exploration and exploitation with RLLF in improving LLMs' negation capabilities. This has implications for the development of more accurate, reliable, and logically consistent language models in high-stakes domains.\n    ",
        "primary_category": "cs.CL",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "2 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01187": {
        "title": "A Compositional Typed Semantics for Universal Dependencies",
        "authors": [
            "Laurestine Bradford",
            "Timothy John O'Donnell",
            "Siva Reddy"
        ],
        "comments": "10 pages, 6 figures, 1 table. For related code, see this https URL",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "Languages may encode similar meanings using different sentence structures. This makes it a challenge to provide a single set of formal rules that can derive meanings from sentences in many languages at once. To overcome the challenge, we can take advantage of language-general connections between meaning and syntax, and build on cross-linguistically parallel syntactic structures. We introduce UD Type Calculus, a compositional, principled, and language-independent system of semantic types and logical forms for lexical items which builds on a widely-used language-general dependency syntax framework. We explain the essential features of UD Type Calculus, which all involve giving dependency relations denotations just like those of words. These allow UD-TC to derive correct meanings for sentences with a wide range of syntactic structures by making use of dependency labels. Finally, we present evaluation results on a large existing corpus of sentences and their logical forms, showing that UD-TC can produce meanings comparable with our baseline.\n    ",
        "primary_category": "cs.CL",
        "categories": [],
        "submitted_date": "2 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01189": {
        "title": "Training Unbiased Diffusion Models From Biased Dataset",
        "authors": [
            "Yeongmin Kim",
            "Byeonghu Na",
            "Minsang Park",
            "JoonHo Jang",
            "Dongjun Kim",
            "Wanmo Kang",
            "Il-Chul Moon"
        ],
        "comments": "International Conference on Learning Representations (ICLR 2024)",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "With significant advancements in diffusion models, addressing the potential risks of dataset bias becomes increasingly important. Since generated outputs directly suffer from dataset bias, mitigating latent bias becomes a key factor in improving sample quality and proportion. This paper proposes time-dependent importance reweighting to mitigate the bias for the diffusion models. We demonstrate that the time-dependent density ratio becomes more precise than previous approaches, thereby minimizing error propagation in generative learning. While directly applying it to score-matching is intractable, we discover that using the time-dependent density ratio both for reweighting and score correction can lead to a tractable form of the objective function to regenerate the unbiased data density. Furthermore, we theoretically establish a connection with traditional score-matching, and we demonstrate its convergence to an unbiased distribution. The experimental evidence supports the usefulness of the proposed method, which outperforms baselines including time-independent importance reweighting on CIFAR-10, CIFAR-100, FFHQ, and CelebA with various bias settings. Our code is available at this https URL.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.CV"
        ],
        "submitted_date": "2 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01196": {
        "title": "Machine Translation in the Covid domain: an English-Irish case study for LoResMT 2021",
        "authors": [
            "S\u00e9amus Lankford",
            "Haithem Afli",
            "Andy Way"
        ],
        "comments": " ",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "Translation models for the specific domain of translating Covid data from English to Irish were developed for the LoResMT 2021 shared task. Domain adaptation techniques, using a Covid-adapted generic 55k corpus from the Directorate General of Translation, were applied. Fine-tuning, mixed fine-tuning and combined dataset approaches were compared with models trained on an extended in-domain dataset. As part of this study, an English-Irish dataset of Covid related data, from the Health and Education domains, was developed. The highest-performing model used a Transformer architecture trained with an extended in-domain Covid dataset. In the context of this study, we have demonstrated that extending an 8k in-domain baseline dataset by just 5k lines improved the BLEU score by 27 points.\n    ",
        "primary_category": "cs.CL",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "2 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01199": {
        "title": "The Case for Animal-Friendly AI",
        "authors": [
            "Sankalpa Ghose",
            "Yip Fai Tse",
            "Kasra Rasaee",
            "Jeff Sebo",
            "Peter Singer"
        ],
        "comments": "AAAI 2024 Workshop on Public Sector LLMs: Algorithmic and Sociotechnical Design. 12 pages, 11 figures",
        "subjects": "Artificial Intelligence (cs.AI)",
        "abstract": "Artificial intelligence is seen as increasingly important, and potentially profoundly so, but the fields of AI ethics and AI engineering have not fully recognized that these technologies, including large language models (LLMs), will have massive impacts on animals. We argue that this impact matters, because animals matter morally.\nAs a first experiment in evaluating animal consideration in LLMs, we constructed a proof-of-concept Evaluation System, which assesses LLM responses and biases from multiple perspectives. This system evaluates LLM outputs by two criteria: their truthfulness, and the degree of consideration they give to the interests of animals. We tested OpenAI ChatGPT 4 and Anthropic Claude 2.1 using a set of structured queries and predefined normative perspectives. Preliminary results suggest that the outcomes of the tested models can be benchmarked regarding the consideration they give to animals, and that generated positions and biases might be addressed and mitigated with more developed and validated systems.\nOur research contributes one possible approach to integrating animal ethics in AI, opening pathways for future studies and practical applications in various fields, including education, public policy, and regulation, that involve or relate to animals and society. Overall, this study serves as a step towards more useful and responsible AI systems that better recognize and respect the vital interests and perspectives of all sentient beings.\n    ",
        "primary_category": "cs.AI",
        "categories": [],
        "submitted_date": "2 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01203": {
        "title": "Pseudo-Label Calibration Semi-supervised Multi-Modal Entity Alignment",
        "authors": [
            "Luyao Wang",
            "Pengnian Qi",
            "Xigang Bao",
            "Chunlai Zhou",
            "Biao Qin"
        ],
        "comments": "accepted by AAAI2024",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Multi-modal entity alignment (MMEA) aims to identify equivalent entities between two multi-modal knowledge graphs for integration. Unfortunately, prior arts have attempted to improve the interaction and fusion of multi-modal information, which have overlooked the influence of modal-specific noise and the usage of labeled and unlabeled data in semi-supervised settings. In this work, we introduce a Pseudo-label Calibration Multi-modal Entity Alignment (PCMEA) in a semi-supervised way. Specifically, in order to generate holistic entity representations, we first devise various embedding modules and attention mechanisms to extract visual, structural, relational, and attribute features. Different from the prior direct fusion methods, we next propose to exploit mutual information maximization to filter the modal-specific noise and to augment modal-invariant commonality. Then, we combine pseudo-label calibration with momentum-based contrastive learning to make full use of the labeled and unlabeled data, which improves the quality of pseudo-label and pulls aligned entities closer. Finally, extensive experiments on two MMEA datasets demonstrate the effectiveness of our PCMEA, which yields state-of-the-art performance.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.CL",
            "cs.DB"
        ],
        "submitted_date": "2 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01204": {
        "title": "Stochastic gradient descent for streaming linear and rectified linear systems with Massart noise",
        "authors": [
            "Halyun Jeong",
            "Deanna Needell",
            "Elizaveta Rebrova"
        ],
        "comments": "Submitted to a journal",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "We propose SGD-exp, a stochastic gradient descent approach for linear and ReLU regressions under Massart noise (adversarial semi-random corruption model) for the fully streaming setting. We show novel nearly linear convergence guarantees of SGD-exp to the true parameter with up to $50\\%$ Massart corruption rate, and with any corruption rate in the case of symmetric oblivious corruptions. This is the first convergence guarantee result for robust ReLU regression in the streaming setting, and it shows the improved convergence rate over previous robust methods for $L_1$ linear regression due to a choice of an exponentially decaying step size, known for its efficiency in practice. Our analysis is based on the drift analysis of a discrete stochastic process, which could also be interesting on its own.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "math.NA",
            "stat.ML"
        ],
        "submitted_date": "2 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01206": {
        "title": "Boosting the Efficiency of Quantum Divider through Effective Design Space Exploration",
        "authors": [
            "Siyi Wang",
            "Eugene Lim",
            "Anupam Chattopadhyay"
        ],
        "comments": "This is accepted for publication in ISCAS 2024",
        "subjects": "Quantum Physics (quant-ph)",
        "abstract": "Rapid progress in the design of scalable, robust quantum computing necessitates efficient quantum circuit implementation for algorithms with practical relevance. For several algorithms, arithmetic kernels, in particular, division plays an important role. In this manuscript, we focus on enhancing the performance of quantum slow dividers by exploring the design choices of its sub-blocks, such as, adders. Through comprehensive design space exploration of state-of-the-art quantum addition building blocks, our work have resulted in an impressive achievement: a reduction in Toffoli Depth of up to 94.06%, accompanied by substantial reductions in both Toffoli and Qubit Count of up to 91.98% and 99.37%, respectively. This paper offers crucial perspectives on efficient design of quantum dividers, and emphasizes the importance of adopting a systematic design space exploration approach.\n    ",
        "primary_category": "quant-ph",
        "categories": [
            "cs.ET"
        ],
        "submitted_date": "2 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01208": {
        "title": "The Science of Data Collection: Insights from Surveys can Improve Machine Learning Models",
        "authors": [
            "Stephanie Eckman",
            "Barbara Plank",
            "Frauke Kreuter"
        ],
        "comments": "9 pages, 4 figures. Position paper, under review",
        "subjects": "Human-Computer Interaction (cs.HC)",
        "abstract": "Whether future AI models make the world safer or less safe for humans rests in part on our ability to efficiently collect accurate data from people about what they want the models to do. However, collecting high quality data is difficult, and most AI/ML researchers are not trained in data collection methods. The growing emphasis on data-centric AI highlights the potential of data to enhance model performance. It also reveals an opportunity to gain insights from survey methodology, the science of collecting high-quality survey data.\nIn this position paper, we summarize lessons from the survey methodology literature and discuss how they can improve the quality of training and feedback data, which in turn improve model performance. Based on the cognitive response process model, we formulate specific hypotheses about the aspects of label collection that may impact training data quality. We also suggest collaborative research ideas into how possible biases in data collection can be mitigated, making models more accurate and human-centric.\n    ",
        "primary_category": "cs.HC",
        "categories": [
            "stat.ME"
        ],
        "submitted_date": "2 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01209": {
        "title": "Data-free Multi-label Image Recognition via LLM-powered Prompt Tuning",
        "authors": [
            "Shuo Yang",
            "Zirui Shang",
            "Yongqi Wang",
            "Derong Deng",
            "Hongwei Chen",
            "Qiyuan Cheng",
            "Xinxiao Wu"
        ],
        "comments": " ",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "This paper proposes a novel framework for multi-label image recognition without any training data, called data-free framework, which uses knowledge of pre-trained Large Language Model (LLM) to learn prompts to adapt pretrained Vision-Language Model (VLM) like CLIP to multilabel classification. Through asking LLM by well-designed questions, we acquire comprehensive knowledge about characteristics and contexts of objects, which provides valuable text descriptions for learning prompts. Then we propose a hierarchical prompt learning method by taking the multi-label dependency into consideration, wherein a subset of category-specific prompt tokens are shared when the corresponding objects exhibit similar attributes or are more likely to co-occur. Benefiting from the remarkable alignment between visual and linguistic semantics of CLIP, the hierarchical prompts learned from text descriptions are applied to perform classification of images during inference. Our framework presents a new way to explore the synergies between multiple pre-trained models for novel category recognition. Extensive experiments on three public datasets (MS-COCO, VOC2007, and NUS-WIDE) demonstrate that our method achieves better results than the state-of-the-art methods, especially outperforming the zero-shot multi-label recognition methods by 4.7% in mAP on MS-COCO.\n    ",
        "primary_category": "cs.CV",
        "categories": [],
        "submitted_date": "2 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01210": {
        "title": "SAR-AE-SFP: SAR Imagery Adversarial Example in Real Physics domain with Target Scattering Feature Parameters",
        "authors": [
            "Jiahao Cui",
            "Jiale Duan",
            "Binyan Luo",
            "Hang Cao",
            "Wang Guo",
            "Haifeng Li"
        ],
        "comments": "10 pages, 9 figures, 2 tables",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Deep neural network-based Synthetic Aperture Radar (SAR) target recognition models are susceptible to adversarial examples. Current adversarial example generation methods for SAR imagery primarily operate in the 2D digital domain, known as image adversarial examples. Recent work, while considering SAR imaging scatter mechanisms, fails to account for the actual imaging process, rendering attacks in the three-dimensional physical domain infeasible, termed pseudo physics adversarial examples. To address these challenges, this paper proposes SAR-AE-SFP-Attack, a method to generate real physics adversarial examples by altering the scattering feature parameters of target objects. Specifically, we iteratively optimize the coherent energy accumulation of the target echo by perturbing the reflection coefficient and scattering coefficient in the scattering feature parameters of the three-dimensional target object, and obtain the adversarial example after echo signal processing and imaging processing in the RaySAR simulator. Experimental results show that compared to digital adversarial attack methods, SAR-AE-SFP Attack significantly improves attack efficiency on CNN-based models (over 30\\%) and Transformer-based models (over 13\\%), demonstrating significant transferability of attack effects across different models and perspectives.\n    ",
        "primary_category": "cs.CV",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "2 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01212": {
        "title": "TCIG: Two-Stage Controlled Image Generation with Quality Enhancement through Diffusion",
        "authors": [
            "Salaheldin Mohamed"
        ],
        "comments": " ",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "In recent years, significant progress has been made in the development of text-to-image generation models. However, these models still face limitations when it comes to achieving full controllability during the generation process. Often, specific training or the use of limited models is required, and even then, they have certain restrictions. To address these challenges, A two-stage method that effectively combines controllability and high quality in the generation of images is proposed. This approach leverages the expertise of pre-trained models to achieve precise control over the generated images, while also harnessing the power of diffusion models to achieve state-of-the-art quality. By separating controllability from high quality, This method achieves outstanding results. It is compatible with both latent and image space diffusion models, ensuring versatility and flexibility. Moreover, This approach consistently produces comparable outcomes to the current state-of-the-art methods in the field. Overall, This proposed method represents a significant advancement in text-to-image generation, enabling improved controllability without compromising on the quality of the generated images.\n    ",
        "primary_category": "cs.CV",
        "categories": [],
        "submitted_date": "2 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01214": {
        "title": "Boosting Box-supervised Instance Segmentation with Pseudo Depth",
        "authors": [
            "Xinyi Yu",
            "Ling Yan",
            "Pengtao Jiang",
            "Hao Chen",
            "Bo Li",
            "Lin Yuanbo Wu",
            "Linlin Ou"
        ],
        "comments": " ",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "The realm of Weakly Supervised Instance Segmentation (WSIS) under box supervision has garnered substantial attention, showcasing remarkable advancements in recent years. However, the limitations of box supervision become apparent in its inability to furnish effective information for distinguishing foreground from background within the specified target box. This research addresses this challenge by introducing pseudo-depth maps into the training process of the instance segmentation network, thereby boosting its performance by capturing depth differences between instances. These pseudo-depth maps are generated using a readily available depth predictor and are not necessary during the inference stage. To enable the network to discern depth features when predicting masks, we integrate a depth prediction layer into the mask prediction head. This innovative approach empowers the network to simultaneously predict masks and depth, enhancing its ability to capture nuanced depth-related information during the instance segmentation process. We further utilize the mask generated in the training process as supervision to distinguish the foreground from the background. When selecting the best mask for each box through the Hungarian algorithm, we use depth consistency as one calculation cost item. The proposed method achieves significant improvements on Cityscapes and COCO dataset.\n    ",
        "primary_category": "cs.CV",
        "categories": [],
        "submitted_date": "2 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01215": {
        "title": "Efficient Algorithm Level Error Detection for Number-Theoretic Transform Assessed on FPGAs",
        "authors": [
            "Kasra Ahmadi",
            "Saeed Aghapour",
            "Mehran Mozaffari Kermani",
            "Reza Azarderakhsh"
        ],
        "comments": "5 Pages, 4 Figures, and 3 Tables",
        "subjects": "Cryptography and Security (cs.CR)",
        "abstract": "Polynomial multiplication stands out as a highly demanding arithmetic process in the development of post-quantum cryptosystems. The importance of number-theoretic transform (NTT) extends beyond post-quantum cryptosystems, proving valuable in enhancing existing security protocols such as digital signature schemes and hash functions. Due to the potential for errors to significantly disrupt the operation of secure, cryptographically-protected systems, compromising data integrity, and safeguarding against side-channel attacks initiated through faults it is essential to incorporate mitigating error detection schemes. This paper introduces algorithm level fault detection schemes in NTT multiplication, representing a significant enhancement compared to previous research. We evaluate this through the simulation of a fault model, ensuring that the conducted assessments accurately mirror the obtained results. Consequently, we attain a notably comprehensive coverage of errors. Finally, we assess the performance of our efficient error detection scheme on FPGAs to showcase its implementation and resource requirements. Through implementation of our error detection approach on Xilinx/AMD Zynq Ultrascale+ and Artix-7, we achieve a comparable throughput with just a 9% increase in area and 13% increase in latency compared to the original hardware implementations.\n    ",
        "primary_category": "cs.CR",
        "categories": [],
        "submitted_date": "2 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01218": {
        "title": "Inexact Unlearning Needs More Careful Evaluations to Avoid a False Sense of Privacy",
        "authors": [
            "Jamie Hayes",
            "Ilia Shumailov",
            "Eleni Triantafillou",
            "Amr Khalifa",
            "Nicolas Papernot"
        ],
        "comments": " ",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "The high cost of model training makes it increasingly desirable to develop techniques for unlearning. These techniques seek to remove the influence of a training example without having to retrain the model from scratch. Intuitively, once a model has unlearned, an adversary that interacts with the model should no longer be able to tell whether the unlearned example was included in the model's training set or not. In the privacy literature, this is known as membership inference. In this work, we discuss adaptations of Membership Inference Attacks (MIAs) to the setting of unlearning (leading to their ``U-MIA'' counterparts). We propose a categorization of existing U-MIAs into ``population U-MIAs'', where the same attacker is instantiated for all examples, and ``per-example U-MIAs'', where a dedicated attacker is instantiated for each example. We show that the latter category, wherein the attacker tailors its membership prediction to each example under attack, is significantly stronger. Indeed, our results show that the commonly used U-MIAs in the unlearning literature overestimate the privacy protection afforded by existing unlearning techniques on both vision and language models. Our investigation reveals a large variance in the vulnerability of different examples to per-example U-MIAs. In fact, several unlearning algorithms lead to a reduced vulnerability for some, but not all, examples that we wish to unlearn, at the expense of increasing it for other examples. Notably, we find that the privacy protection for the remaining training examples may worsen as a consequence of unlearning. We also discuss the fundamental difficulty of equally protecting all examples using existing unlearning schemes, due to the different rates at which examples are unlearned. We demonstrate that naive attempts at tailoring unlearning stopping criteria to different examples fail to alleviate these issues.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.CR"
        ],
        "submitted_date": "2 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01221": {
        "title": "A Two-Stage Algorithm for Cost-Efficient Multi-instance Counterfactual Explanations",
        "authors": [
            "Andr\u00e9 Artelt",
            "Andreas Gregoriades"
        ],
        "comments": " ",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Counterfactual explanations constitute among the most popular methods for analyzing the predictions of black-box systems since they can recommend cost-efficient and actionable changes to the input to turn an undesired system's output into a desired output. While most of the existing counterfactual methods explain a single instance, several real-world use cases, such as customer satisfaction, require the identification of a single counterfactual that can satisfy multiple instances (e.g. customers) simultaneously. In this work, we propose a flexible two-stage algorithm for finding groups of instances along with cost-efficient multi-instance counterfactual explanations. This is motivated by the fact that in most previous works the aspect of finding such groups is not addressed.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "2 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01225": {
        "title": "A Cost-Effective Cooperative Exploration and Inspection Strategy for Heterogeneous Aerial System",
        "authors": [
            "Xinhang Xu",
            "Muqing Cao",
            "Shenghai Yuan",
            "Thien Hoang Nguyen",
            "Thien-Minh Nguyen",
            "Lihua Xie"
        ],
        "comments": "Baseline method of CARIC at CDC 2023, Singapore",
        "subjects": "Robotics (cs.RO)",
        "abstract": "In this paper, we propose a cost-effective strategy for heterogeneous UAV swarm systems for cooperative aerial inspection. Unlike previous swarm inspection works, the proposed method does not rely on precise prior knowledge of the environment and can complete full 3D surface coverage of objects in any shape. In this work, agents are partitioned into teams, with each drone assign a different task, including mapping, exploration, and inspection. Task allocation is facilitated by assigning optimal inspection volumes to each team, following best-first rules. A voxel map-based representation of the environment is used for pathfinding, and a rule-based path-planning method is the core of this approach. We achieved the best performance in all challenging experiments with the proposed approach, surpassing all benchmark methods for similar tasks across multiple evaluation trials. The proposed method is open source at this https URL and used as the baseline of the Cooperative Aerial Robots Inspection Challenge at the 62nd IEEE Conference on Decision and Control 2023.\n    ",
        "primary_category": "cs.RO",
        "categories": [],
        "submitted_date": "2 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01226": {
        "title": "DiffSal: Joint Audio and Video Learning for Diffusion Saliency Prediction",
        "authors": [
            "Junwen Xiong",
            "Peng Zhang",
            "Tao You",
            "Chuanyue Li",
            "Wei Huang",
            "Yufei Zha"
        ],
        "comments": "15 pages, CVPR24",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Audio-visual saliency prediction can draw support from diverse modality complements, but further performance enhancement is still challenged by customized architectures as well as task-specific loss functions. In recent studies, denoising diffusion models have shown more promising in unifying task frameworks owing to their inherent ability of generalization. Following this motivation, a novel Diffusion architecture for generalized audio-visual Saliency prediction (DiffSal) is proposed in this work, which formulates the prediction problem as a conditional generative task of the saliency map by utilizing input audio and video as the conditions. Based on the spatio-temporal audio-visual features, an extra network Saliency-UNet is designed to perform multi-modal attention modulation for progressive refinement of the ground-truth saliency map from the noisy map. Extensive experiments demonstrate that the proposed DiffSal can achieve excellent performance across six challenging audio-visual benchmarks, with an average relative improvement of 6.3\\% over the previous state-of-the-art results by six metrics.\n    ",
        "primary_category": "cs.CV",
        "categories": [],
        "submitted_date": "2 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01229": {
        "title": "REWIND Dataset: Privacy-preserving Speaking Status Segmentation from Multimodal Body Movement Signals in the Wild",
        "authors": [
            "Jose Vargas Quiros",
            "Chirag Raman",
            "Stephanie Tan",
            "Ekin Gedik",
            "Laura Cabrera-Quiros",
            "Hayley Hung"
        ],
        "comments": " ",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Recognizing speaking in humans is a central task towards understanding social interactions. Ideally, speaking would be detected from individual voice recordings, as done previously for meeting scenarios. However, individual voice recordings are hard to obtain in the wild, especially in crowded mingling scenarios due to cost, logistics, and privacy concerns. As an alternative, machine learning models trained on video and wearable sensor data make it possible to recognize speech by detecting its related gestures in an unobtrusive, privacy-preserving way. These models themselves should ideally be trained using labels obtained from the speech signal. However, existing mingling datasets do not contain high quality audio recordings. Instead, speaking status annotations have often been inferred by human annotators from video, without validation of this approach against audio-based ground truth. In this paper we revisit no-audio speaking status estimation by presenting the first publicly available multimodal dataset with high-quality individual speech recordings of 33 subjects in a professional networking event. We present three baselines for no-audio speaking status segmentation: a) from video, b) from body acceleration (chest-worn accelerometer), c) from body pose tracks. In all cases we predict a 20Hz binary speaking status signal extracted from the audio, a time resolution not available in previous datasets. In addition to providing the signals and ground truth necessary to evaluate a wide range of speaking status detection methods, the availability of audio in REWIND makes it suitable for cross-modality studies not feasible with previous mingling datasets. Finally, our flexible data consent setup creates new challenges for multimodal systems under missing modalities.\n    ",
        "primary_category": "cs.CV",
        "categories": [
            "cs.AI",
            "cs.LG",
            "eess.SP"
        ],
        "submitted_date": "2 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01234": {
        "title": "Active Deep Kernel Learning of Molecular Functionalities: Realizing Dynamic Structural Embeddings",
        "authors": [
            "Ayana Ghosh",
            "Maxim Ziatdinov and",
            "Sergei V. Kalinin"
        ],
        "comments": " ",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Exploring molecular spaces is crucial for advancing our understanding of chemical properties and reactions, leading to groundbreaking innovations in materials science, medicine, and energy. This paper explores an approach for active learning in molecular discovery using Deep Kernel Learning (DKL), a novel approach surpassing the limits of classical Variational Autoencoders (VAEs). Employing the QM9 dataset, we contrast DKL with traditional VAEs, which analyze molecular structures based on similarity, revealing limitations due to sparse regularities in latent spaces. DKL, however, offers a more holistic perspective by correlating structure with properties, creating latent spaces that prioritize molecular functionality. This is achieved by recalculating embedding vectors iteratively, aligning with the experimental availability of target properties. The resulting latent spaces are not only better organized but also exhibit unique characteristics such as concentrated maxima representing molecular functionalities and a correlation between predictive uncertainty and error. Additionally, the formation of exclusion regions around certain compounds indicates unexplored areas with potential for groundbreaking functionalities. This study underscores DKL's potential in molecular research, offering new avenues for understanding and discovering molecular functionalities beyond classical VAE limitations.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "physics.chem-ph",
            "physics.comp-ph",
            "physics.data-an"
        ],
        "submitted_date": "2 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01236": {
        "title": "Performance evaluation of acceleration of convolutional layers on OpenEdgeCGRA",
        "authors": [
            "Nicol\u00f2 Carpentieri",
            "Juan Sapriza",
            "Davide Schiavone",
            "Daniele Jahier Pagliari",
            "David Atienza",
            "Maurizio Martina",
            "Alessio Burrello"
        ],
        "comments": " ",
        "subjects": "Hardware Architecture (cs.AR)",
        "abstract": "Recently, efficiently deploying deep learning solutions on the edge has received increasing attention. New platforms are emerging to support the increasing demand for flexibility and high performance. In this work, we explore the efficient mapping of convolutional layers on an open-hardware, low-power Coarse-Grain Reconfigurable Array (CGRA), namely OpenEdgeCGRA. We explore both direct implementations of convolution and solutions that transform it into a matrix multiplication through an Im2col transformation, and experiment with various tensor parallelism axes. We show that for this hardware target, direct convolution, coupled with weight parallelism reaches the best latency and energy efficiency, outperforming a CPU implementation by 3.4x and 9.9x in terms of energy and latency, respectively.\n    ",
        "primary_category": "cs.AR",
        "categories": [],
        "submitted_date": "2 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01241": {
        "title": "IntactKV: Improving Large Language Model Quantization by Keeping Pivot Tokens Intact",
        "authors": [
            "Ruikang Liu",
            "Haoli Bai",
            "Haokun Lin",
            "Yuening Li",
            "Han Gao",
            "Zhengzhuo Xu",
            "Lu Hou",
            "Jun Yao",
            "Chun Yuan"
        ],
        "comments": " ",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "Large language models (LLMs) excel in natural language processing but demand intensive computation. To mitigate this, various quantization methods have been explored, yet they compromise LLM performance. This paper unveils a previously overlooked type of outlier in LLMs. Such outliers are found to allocate most of the attention scores on initial tokens of input, termed as pivot tokens, which is crucial to the performance of quantized LLMs. Given that, we propose IntactKV to generate the KV cache of pivot tokens losslessly from the full-precision model. The approach is simple and easy to combine with existing quantization solutions. Besides, IntactKV can be calibrated as additional LLM parameters to boost the quantized LLMs further. Mathematical analysis also proves that IntactKV effectively reduces the upper bound of quantization error. Empirical results show that IntactKV brings consistent improvement and achieves lossless weight-only INT4 quantization on various downstream tasks, leading to the new state-of-the-art for LLM quantization.\n    ",
        "primary_category": "cs.CL",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "2 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01242": {
        "title": "Augmenting Automation: Intent-Based User Instruction Classification with Machine Learning",
        "authors": [
            "Lochan Basyal",
            "Bijay Gaudel"
        ],
        "comments": "7 pages, 14 figures",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Electric automation systems offer convenience and efficiency in controlling electrical circuits and devices. Traditionally, these systems rely on predefined commands for control, limiting flexibility and adaptability. In this paper, we propose a novel approach to augment automation by introducing intent-based user instruction classification using machine learning techniques. Our system represents user instructions as intents, allowing for dynamic control of electrical circuits without relying on predefined commands. Through a machine learning model trained on a labeled dataset of user instructions, our system classifies intents from user input, enabling a more intuitive and adaptable control scheme. We present the design and implementation of our intent-based electric automation system, detailing the development of the machine learning model for intent classification. Experimental results demonstrate the effectiveness of our approach in enhancing user experience and expanding the capabilities of electric automation systems. Our work contributes to the advancement of smart technologies by providing a more seamless interaction between users and their environments.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.AI",
            "cs.CL",
            "cs.HC"
        ],
        "submitted_date": "2 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01244": {
        "title": "Mitigating Catastrophic Forgetting in Large Language Models with Self-Synthesized Rehearsal",
        "authors": [
            "Jianheng Huang",
            "Leyang Cui",
            "Ante Wang",
            "Chengyi Yang",
            "Xinting Liao",
            "Linfeng Song",
            "Junfeng Yao",
            "Jinsong Su"
        ],
        "comments": " ",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "Large language models (LLMs) suffer from catastrophic forgetting during continual learning. Conventional rehearsal-based methods rely on previous training data to retain the model's ability, which may not be feasible in real-world applications. When conducting continual learning based on a publicly-released LLM checkpoint, the availability of the original training data may be non-existent. To address this challenge, we propose a framework called Self-Synthesized Rehearsal (SSR) that uses the LLM to generate synthetic instances for rehearsal. Concretely, we first employ the base LLM for in-context learning to generate synthetic instances. Subsequently, we utilize the latest LLM to refine the instance outputs based on the synthetic inputs, preserving its acquired ability. Finally, we select diverse high-quality synthetic instances for rehearsal in future stages. Experimental results demonstrate that SSR achieves superior or comparable performance compared to conventional rehearsal-based approaches while being more data-efficient. Besides, SSR effectively preserves the generalization capabilities of LLMs in general domains.\n    ",
        "primary_category": "cs.CL",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "2 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01245": {
        "title": "AcME-AD: Accelerated Model Explanations for Anomaly Detection",
        "authors": [
            "Valentina Zaccaria",
            "David Dandolo",
            "Chiara Masiero",
            "Gian Antonio Susto"
        ],
        "comments": " ",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Pursuing fast and robust interpretability in Anomaly Detection is crucial, especially due to its significance in practical applications. Traditional Anomaly Detection methods excel in outlier identification but are often black-boxes, providing scant insights into their decision-making process. This lack of transparency compromises their reliability and hampers their adoption in scenarios where comprehending the reasons behind anomaly detection is vital. At the same time, getting explanations quickly is paramount in practical scenarios. To bridge this gap, we present AcME-AD, a novel approach rooted in Explainable Artificial Intelligence principles, designed to clarify Anomaly Detection models for tabular data. AcME-AD transcends the constraints of model-specific or resource-heavy explainability techniques by delivering a model-agnostic, efficient solution for interoperability. It offers local feature importance scores and a what-if analysis tool, shedding light on the factors contributing to each anomaly, thus aiding root cause analysis and decision-making. This paper elucidates AcME-AD's foundation, its benefits over existing methods, and validates its effectiveness with tests on both synthetic and real datasets. AcME-AD's implementation and experiment replication code is accessible in a public repository.\n    ",
        "primary_category": "cs.LG",
        "categories": [],
        "submitted_date": "2 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01246": {
        "title": "Dual Graph Attention based Disentanglement Multiple Instance Learning for Brain Age Estimation",
        "authors": [
            "Fanzhe Yan",
            "Gang Yang",
            "Yu Li",
            "Aiping Liu",
            "Xun Chen"
        ],
        "comments": "12 pages, 9 figures",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Deep learning techniques have demonstrated great potential for accurately estimating brain age by analyzing Magnetic Resonance Imaging (MRI) data from healthy individuals. However, current methods for brain age estimation often directly utilize whole input images, overlooking two important considerations: 1) the heterogeneous nature of brain aging, where different brain regions may degenerate at different rates, and 2) the existence of age-independent redundancies in brain structure. To overcome these limitations, we propose a Dual Graph Attention based Disentanglement Multi-instance Learning (DGA-DMIL) framework for improving brain age estimation. Specifically, the 3D MRI data, treated as a bag of instances, is fed into a 2D convolutional neural network backbone, to capture the unique aging patterns in MRI. A dual graph attention aggregator is then proposed to learn the backbone features by exploiting the intra- and inter-instance relationships. Furthermore, a disentanglement branch is introduced to separate age-related features from age-independent structural representations to ameliorate the interference of redundant information on age prediction. To verify the effectiveness of the proposed framework, we evaluate it on two datasets, UK Biobank and ADNI, containing a total of 35,388 healthy individuals. Our proposed model demonstrates exceptional accuracy in estimating brain age, achieving a remarkable mean absolute error of 2.12 years in the UK Biobank. The results establish our approach as state-of-the-art compared to other competing brain age estimation models. In addition, the instance contribution scores identify the varied importance of brain areas for aging prediction, which provides deeper insights into the understanding of brain aging.\n    ",
        "primary_category": "cs.CV",
        "categories": [],
        "submitted_date": "2 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01248": {
        "title": "SceneCraft: An LLM Agent for Synthesizing 3D Scene as Blender Code",
        "authors": [
            "Ziniu Hu",
            "Ahmet Iscen",
            "Aashi Jain",
            "Thomas Kipf",
            "Yisong Yue",
            "David A. Ross",
            "Cordelia Schmid",
            "Alireza Fathi"
        ],
        "comments": " ",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "This paper introduces SceneCraft, a Large Language Model (LLM) Agent converting text descriptions into Blender-executable Python scripts which render complex scenes with up to a hundred 3D assets. This process requires complex spatial planning and arrangement. We tackle these challenges through a combination of advanced abstraction, strategic planning, and library learning. SceneCraft first models a scene graph as a blueprint, detailing the spatial relationships among assets in the scene. SceneCraft then writes Python scripts based on this graph, translating relationships into numerical constraints for asset layout. Next, SceneCraft leverages the perceptual strengths of vision-language foundation models like GPT-V to analyze rendered images and iteratively refine the scene. On top of this process, SceneCraft features a library learning mechanism that compiles common script functions into a reusable library, facilitating continuous self-improvement without expensive LLM parameter tuning. Our evaluation demonstrates that SceneCraft surpasses existing LLM-based agents in rendering complex scenes, as shown by its adherence to constraints and favorable human assessments. We also showcase the broader application potential of SceneCraft by reconstructing detailed 3D scenes from the Sintel movie and guiding a video generative model with generated scenes as intermediary control signal.\n    ",
        "primary_category": "cs.CV",
        "categories": [
            "cs.AI",
            "cs.CL",
            "cs.LG"
        ],
        "submitted_date": "2 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01250": {
        "title": "Resilient Mobile Energy Storage Resources Based Distribution Network Restoration in Interdependent Power-Transportation-Information Networks",
        "authors": [
            "Jian Zhong",
            "Chen Chen",
            "Qiming Yang",
            "Dafu Liu",
            "Wentao Shen",
            "Chenlin Ji",
            "Zhaohong Bie"
        ],
        "comments": " ",
        "subjects": "Systems and Control (eess.SY)",
        "abstract": "The interactions between power, transportation, and information networks (PTIN), are becoming more profound with the advent of smart city technologies. Existing mobile energy storage resource (MESR)-based power distribution network (PDN) restoration schemes often neglect the interdependencies among PTIN, thus, efficient PDN restoration cannot be achieved. This paper outlines the interacting factors of power supply demand, traffic operation efficiency, communication coverage, electric vehicle (EV) deployment capability, and PDN controllability among PTIN and further develops a PTIN-interacting model to reflect the chained recovery effect of the MESR-based restoration process. On this basis, a two-stage PDN restoration scheme is proposed that utilizes three emergency resources, including EVs, mobile energy storage systems (MESSs), and unmanned aerial vehicles (UAVs), to restore the power supply and communication of PDNs. This scheme first improves the distribution automation function, EV deployment capability, and traffic operation efficiency by prioritizing the recovery of communication network (CN) and urban traffic network (UTN) loads. Then, EVs and MESSs are further scheduled to achieve a better PDN restoration effect with the support of the restored CNs and UTNs. Case studies on a PDN, CN, and UTN integrated test system are conducted to verify the effectiveness of the proposed scheme. The results show that the prioritized load recovery operation for CN and UTN facilities in this scheme greatly improves the PDN restoration effect.\n    ",
        "primary_category": "eess.SY",
        "categories": [],
        "submitted_date": "2 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01251": {
        "title": "Accelerating Greedy Coordinate Gradient via Probe Sampling",
        "authors": [
            "Yiran Zhao",
            "Wenyue Zheng",
            "Tianle Cai",
            "Xuan Long Do",
            "Kenji Kawaguchi",
            "Anirudh Goyal",
            "Michael Shieh"
        ],
        "comments": " ",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "Safety of Large Language Models (LLMs) has become a central issue given their rapid progress and wide applications. Greedy Coordinate Gradient (GCG) is shown to be effective in constructing prompts containing adversarial suffixes to break the presumingly safe LLMs, but the optimization of GCG is time-consuming and limits its practicality. To reduce the time cost of GCG and enable more comprehensive studies of LLM safety, in this work, we study a new algorithm called $\\texttt{Probe sampling}$ to accelerate the GCG algorithm. At the core of the algorithm is a mechanism that dynamically determines how similar a smaller draft model's predictions are to the target model's predictions for prompt candidates. When the target model is similar to the draft model, we rely heavily on the draft model to filter out a large number of potential prompt candidates to reduce the computation time. Probe sampling achieves up to $5.6$ times speedup using Llama2-7b and leads to equal or improved attack success rate (ASR) on the AdvBench.\n    ",
        "primary_category": "cs.CL",
        "categories": [],
        "submitted_date": "2 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01253": {
        "title": "Strategic SDN-based Microgrid Formation for Managing Communication Failures in Distribution System Restoration",
        "authors": [
            "Jian Zhong",
            "Chen Chen",
            "Zhaohong Bie",
            "Mohammad Shahidehpour"
        ],
        "comments": " ",
        "subjects": "Systems and Control (eess.SY)",
        "abstract": "Grid modernization has increased the reliance of power networks on cyber networks within distribution systems (DSs), heightening their vulnerability to disasters. Communication network failures significantly impede DS load recovery by diminishing observation and control. Prior research has largely ignored the need for integrated recovery of DS power and cyber networks' centralized control. Indeed, communication network restoration is critical for speedy load recovery through DS automation based microgrid formation. This paper exploits the data routing capabilities of software-defined networking (SDN) to enhance centralized control recovery in DS communication networks, incorporating it into a comprehensive DS restoration model. This model, tailored to the control requirements of load restoration, strategically allocates limited communication resources to re-establish connections between the operation center and terminal devices. Subsequently, DS automation is employed to orchestrate DS microgrid formation for power resupply. Additionally, we introduce a cyclic algorithm designed to optimize the load recovery via a multi-step, cooperative process. The efficacy of the proposed method is demonstrated on IEEE 33-node and IEEE 123-node test feeders.\n    ",
        "primary_category": "eess.SY",
        "categories": [],
        "submitted_date": "2 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01254": {
        "title": "RKHS-BA: A Semantic Correspondence-Free Multi-View Registration Framework with Global Tracking",
        "authors": [
            "Ray Zhang",
            "Jingwei Song",
            "Xiang Gao",
            "Junzhe Wu",
            "Tianyi Liu",
            "Jinyuan Zhang",
            "Ryan Eustice",
            "Maani Ghaffari"
        ],
        "comments": "16 pages, 12 figures, technical report under review",
        "subjects": "Robotics (cs.RO)",
        "abstract": "This work reports a novel Bundle Adjustment (BA) formulation using a Reproducing Kernel Hilbert Space (RKHS) representation called RKHS-BA. The proposed formulation is correspondence-free, enables the BA to use RGB-D/LiDAR and semantic labels in the optimization directly, and provides a generalization for the photometric loss function commonly used in direct methods. RKHS-BA can incorporate appearance and semantic labels within a continuous spatial-semantic functional representation that does not require optimization via image pyramids. We demonstrate its applications in sliding-window odometry and global LiDAR mapping, which show highly robust performance in extremely challenging scenes and the best trade-off of generalization and accuracy.\n    ",
        "primary_category": "cs.RO",
        "categories": [],
        "submitted_date": "2 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01256": {
        "title": "Resilient Microgrid Formation Considering Communication Interruptions",
        "authors": [
            "Jian Zhong",
            "Chen Chen",
            "Young-Jin Kim",
            "Yuxiong Huang",
            "Mengjie Teng",
            "Yiheng Bian",
            "Zhaohong Bie"
        ],
        "comments": " ",
        "subjects": "Systems and Control (eess.SY)",
        "abstract": "Distribution system (DS) communication failures following extreme events often degrade monitoring and control functions, thus preventing the acquisition of complete global DS component state information, on which existing post-disaster DS restoration methods are based. This letter proposes methods of inferring the states of DS components in the case of incomplete component state information. By using the known DS information, the operating states of unobservable DS branches and buses can be inferred, providing complete information for DS performance restoration before full communication recovery\n    ",
        "primary_category": "eess.SY",
        "categories": [],
        "submitted_date": "2 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01257": {
        "title": "Secure and Scalable Network Slicing with Plug-and-Play Support for Power Distribution System Communication Networks",
        "authors": [
            "Jian Zhong",
            "Chen Chen",
            "Yuqi Qian",
            "Yiheng Bian",
            "Yuxiong Huang",
            "Zhaohong Bie"
        ],
        "comments": " ",
        "subjects": "Systems and Control (eess.SY)",
        "abstract": "With the rapid development of power distribution systems (PDSs), the number of terminal devices and the types of delivered services involved are constantly growing. These trends make the operations of PDSs highly dependent on the support of advanced communication networks, which face two related challenges. The first is to provide sufficient flexibility, resilience, and security to meet varying demands and ensure the proper operation of gradually diversifying network services. The second is to realize the automatic identification of terminal devices, thus reducing the network maintenance burden. To solve these problems, this paper presents a novel multiservice network integration and device authentication slice-based network slicing scheme. In this scheme, the integration of PDS communication networks enables network resource sharing, and recovery from communication interruption is achieved through network slicing in the integrated network. Authentication servers periodically poll terminal devices, adjusting network slice ranges based on authentication results, thereby facilitating dynamic network slicing. Additionally, secure plug-and-play support for PDS terminal devices and network protection are achieved through device identification and dynamic adjustment of network slices. On this basis, a network optimization and upgrading methodology for load balancing and robustness enhancement is further proposed. This approach is designed to improve the performance of PDS communication networks, adapting to ongoing PDS development and the evolution of PDS services. The simulation results show that the proposed schemes endow a PDS communication network with favorable resource utilization, fault recovery, terminal device plug-and-play support, load balancing, and improved network robustness.\n    ",
        "primary_category": "eess.SY",
        "categories": [],
        "submitted_date": "2 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01260": {
        "title": "Decentralized Implicit Differentiation",
        "authors": [
            "Lucas Fuentes Valenzuela",
            "Robin Brown",
            "Marco Pavone"
        ],
        "comments": " ",
        "subjects": "Optimization and Control (math.OC)",
        "abstract": "The ability to differentiate through optimization problems has unlocked numerous applications, from optimization-based layers in machine learning models to complex design problems formulated as bilevel programs. It has been shown that exploiting problem structure can yield significant computation gains for optimization and, in some cases, enable distributed computation. One should expect that this structure can be similarly exploited for gradient computation. In this work, we discuss a decentralized framework for computing gradients of constraint-coupled optimization problems. First, we show that this framework results in significant computational gains, especially for large systems, and provide sufficient conditions for its validity. Second, we leverage exponential decay of sensitivities in graph-structured problems towards building a fully distributed algorithm with convergence guarantees. Finally, we use the methodology to rigorously estimate marginal emissions rates in power systems models. Specifically, we demonstrate how the distributed scheme allows for accurate and efficient estimation of these important emissions metrics on large dynamic power system models.\n    ",
        "primary_category": "math.OC",
        "categories": [
            "eess.SY"
        ],
        "submitted_date": "2 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01263": {
        "title": "Single-image camera calibration with model-free distortion correction",
        "authors": [
            "Katia Genovese"
        ],
        "comments": " ",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Camera calibration is a process of paramount importance in computer vision applications that require accurate quantitative measurements. The popular method developed by Zhang relies on the use of a large number of images of a planar grid of fiducial points captured in multiple poses. Although flexible and easy to implement, Zhang's method has some limitations. The simultaneous optimization of the entire parameter set, including the coefficients of a predefined distortion model, may result in poor distortion correction at the image boundaries or in miscalculation of the intrinsic parameters, even with a reasonably small reprojection error. Indeed, applications involving image stitching (e.g. multi-camera systems) require accurate mapping of distortion up to the outermost regions of the image. Moreover, intrinsic parameters affect the accuracy of camera pose estimation, which is fundamental for applications such as vision servoing in robot navigation and automated assembly. This paper proposes a method for estimating the complete set of calibration parameters from a single image of a planar speckle pattern covering the entire sensor. The correspondence between image points and physical points on the calibration target is obtained using Digital Image Correlation. The effective focal length and the extrinsic parameters are calculated separately after a prior evaluation of the principal point. At the end of the procedure, a dense and uniform model-free distortion map is obtained over the entire image. Synthetic data with different noise levels were used to test the feasibility of the proposed method and to compare its metrological performance with Zhang's method. Real-world tests demonstrate the potential of the developed method to reveal aspects of the image formation that are hidden by averaging over multiple images.\n    ",
        "primary_category": "cs.CV",
        "categories": [],
        "submitted_date": "2 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01264": {
        "title": "Efficient Alternative Finite Difference WENO Schemes for Hyperbolic Conservation Laws",
        "authors": [
            "Dinshaw S. Balsara",
            "Deepak Bhoriya",
            "Chi-Wang Shu",
            "Harish Kumar"
        ],
        "comments": "Accepted in Communications on Applied Mathematics and Computation",
        "subjects": "Numerical Analysis (math.NA)",
        "abstract": "Higher order finite difference Weighted Essentially Non-Oscillatory (WENO) schemes for conservation laws are extremely popular because, for multidimensional problems, they offer high order accuracy at a fraction of the cost of finite volume WENO or DG schemes. Such schemes come in two formulations. The very popular classical finite difference WENO (FD-WENO) method (Shu and Osher, J. Comput. Phys., 83 (1989) 32-78) relies two reconstruction steps applied to two split fluxes. However, the method cannot accommodate different types of Riemann solvers and cannot preserve free stream boundary conditions on curvilinear meshes. This limits its utility. The alternative finite difference WENO (AFD-WENO) method can overcome these deficiencies, however, much less work has been done on this method. The reasons are three-fold. First, it is difficult for the casual reader to understand the intricate logic that requires higher order derivatives of the fluxes to be evaluated at zone boundaries. The analytical methods for deriving the update equation for AFD-WENO schemes are somewhat recondite. To overcome that difficulty, we provide an easily accessible script that is based on a computer algebra system in Appendix A of this paper. Second, the method relies on interpolation rather than reconstruction, and WENO interpolation formulae have not been documented in the literature as thoroughly as WENO reconstruction formulae. In this paper, we explicitly provide all necessary WENO interpolation formulae that are needed for implementing AFD-WENO up to ninth order. The third reason is that AFD-WENO requires higher order derivatives of the fluxes to be available at zone boundaries. Since those derivatives are usually obtained by finite differencing the zone-centered fluxes, they become susceptible to a Gibbs phenomenon when the solution ...\n    ",
        "primary_category": "math.NA",
        "categories": [
            "math-ph",
            "physics.flu-dyn"
        ],
        "submitted_date": "2 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01266": {
        "title": "Efficient Alternative Finite Difference WENO Schemes for Hyperbolic Systems with Non-Conservative Products",
        "authors": [
            "Dinshaw S. Balsara",
            "Deepak Bhoriya",
            "Chi-Wang Shu",
            "Harish Kumar"
        ],
        "comments": "Accepted in Communications on Applied Mathematics and Computation",
        "subjects": "Numerical Analysis (math.NA)",
        "abstract": "Higher order finite difference Weighted Essentially Non-Oscillatory (WENO) schemes for conservation laws represent a technology that has been reasonably consolidated. They are extremely popular because, when applied to multidimensional problems, they offer high order accuracy at a fraction of the cost of finite volume WENO or DG schemes. They come in two flavors. There is the classical finite difference WENO (FD-WENO) method (Shu and Osher, J. Comput. Phys., 83 (1989) 32-78). However, in recent years there is also an alternative finite difference WENO (AFD-WENO) method which has recently been formalized into a very useful general-purpose algorithm for conservation laws (Balsara et al., Efficient Alternative Finite Difference WENO Schemes for Hyperbolic Conservation Laws, submitted to CAMC (2023)). However, the FD-WENO algorithm has only very recently been formulated for hyperbolic systems with non-conservative products (Balsara et al., Efficient Finite Difference WENO Scheme for Hyperbolic Systems with Non-Conservative Products, to appear CAMC (2023)). In this paper we show that there are substantial advantages in obtaining an AFD-WENO algorithm for hyperbolic systems with non-conservative products. Such an algorithm is documented in this paper. We present an AFD-WENO formulation in fluctuation form that is carefully engineered to retrieve the flux form when that is warranted and nevertheless extends to non-conservative products. The method is flexible because it allows any Riemann solver to be used. The formulation we arrive at is such that when non-conservative products are absent it reverts exactly to the formulation in the second citation above which is in exact flux conservation form. The ability to transition to a precise conservation form when non-conservative products are absent ensures, via the Lax-Wendroff theorem, that shock locations will be exactly ...\n    ",
        "primary_category": "math.NA",
        "categories": [
            "math-ph",
            "physics.flu-dyn"
        ],
        "submitted_date": "2 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01267": {
        "title": "Dissecting Language Models: Machine Unlearning via Selective Pruning",
        "authors": [
            "Nicholas Pochinkov",
            "Nandi Schoots"
        ],
        "comments": " ",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Understanding and shaping the behaviour of Large Language Models (LLMs) is increasingly important as applications become more powerful and more frequently adopted. This paper introduces a machine unlearning method specifically designed for LLMs. We introduce a selective pruning method for LLMs that removes neurons based on their relative importance on a targeted capability compared to overall network performance. This approach is a compute- and data-efficient method for identifying and removing neurons that enable specific behaviours. Our findings reveal that both feed-forward and attention neurons in LLMs are specialized; that is, for specific tasks, certain neurons are more crucial than others.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.CL"
        ],
        "submitted_date": "2 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01268": {
        "title": "Defending Against Data Reconstruction Attacks in Federated Learning: An Information Theory Approach",
        "authors": [
            "Qi Tan",
            "Qi Li",
            "Yi Zhao",
            "Zhuotao Liu",
            "Xiaobing Guo",
            "Ke Xu"
        ],
        "comments": "Accepted by USENIX Security '24",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Federated Learning (FL) trains a black-box and high-dimensional model among different clients by exchanging parameters instead of direct data sharing, which mitigates the privacy leak incurred by machine learning. However, FL still suffers from membership inference attacks (MIA) or data reconstruction attacks (DRA). In particular, an attacker can extract the information from local datasets by constructing DRA, which cannot be effectively throttled by existing techniques, e.g., Differential Privacy (DP).\nIn this paper, we aim to ensure a strong privacy guarantee for FL under DRA. We prove that reconstruction errors under DRA are constrained by the information acquired by an attacker, which means that constraining the transmitted information can effectively throttle DRA. To quantify the information leakage incurred by FL, we establish a channel model, which depends on the upper bound of joint mutual information between the local dataset and multiple transmitted parameters. Moreover, the channel model indicates that the transmitted information can be constrained through data space operation, which can improve training efficiency and the model accuracy under constrained information. According to the channel model, we propose algorithms to constrain the information transmitted in a single round of local training. With a limited number of training rounds, the algorithms ensure that the total amount of transmitted information is limited. Furthermore, our channel model can be applied to various privacy-enhancing techniques (such as DP) to enhance privacy guarantees against DRA. Extensive experiments with real-world datasets validate the effectiveness of our methods.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.CR",
            "cs.DC"
        ],
        "submitted_date": "2 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01269": {
        "title": "Network analysis using Krylov subspace trajectories",
        "authors": [
            "H. Robert Frost"
        ],
        "comments": " ",
        "subjects": "Physics and Society (physics.soc-ph)",
        "abstract": "We describe a set of network analysis methods based on the rows of the Krylov subspace matrix computed from a network adjacency matrix via power iteration using a non-random initial vector. We refer to these node-specific row vectors as Krylov subspace trajectories. While power iteration using a random initial starting vector is commonly applied to the network adjacency matrix to compute eigenvector centrality values, this application only uses the final vector generated after numerical convergence. Importantly, use of a random initial vector means that the intermediate results of power iteration are also random and lack a clear interpretation. To the best of our knowledge, use of intermediate power iteration results for network analysis has been limited to techniques that leverage just a single pre-convergence solution, e.g., Power Iteration Clustering. In this paper, we explore methods that apply power iteration with a non-random inital vector to the network adjacency matrix to generate Krylov subspace trajectories for each node. These non-random trajectories provide important information regarding network structure, node importance, and response to perturbations. We have created this short preprint in part to generate feedback from others in the network analysis community who might be aware of similar existing work.\n    ",
        "primary_category": "physics.soc-ph",
        "categories": [
            "cs.SI",
            "math.NA"
        ],
        "submitted_date": "2 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01270": {
        "title": "A comprehensive cross-language framework for harmful content detection with the aid of sentiment analysis",
        "authors": [
            "Mohammad Dehghani"
        ],
        "comments": " ",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "In today's digital world, social media plays a significant role in facilitating communication and content sharing. However, the exponential rise in user-generated content has led to challenges in maintaining a respectful online environment. In some cases, users have taken advantage of anonymity in order to use harmful language, which can negatively affect the user experience and pose serious social problems. Recognizing the limitations of manual moderation, automatic detection systems have been developed to tackle this problem. Nevertheless, several obstacles persist, including the absence of a universal definition for harmful language, inadequate datasets across languages, the need for detailed annotation guideline, and most importantly, a comprehensive framework. This study aims to address these challenges by introducing, for the first time, a detailed framework adaptable to any language. This framework encompasses various aspects of harmful language detection. A key component of the framework is the development of a general and detailed annotation guideline. Additionally, the integration of sentiment analysis represents a novel approach to enhancing harmful language detection. Also, a definition of harmful language based on the review of different related concepts is presented. To demonstrate the effectiveness of the proposed framework, its implementation in a challenging low-resource language is conducted. We collected a Persian dataset and applied the annotation guideline for harmful detection and sentiment analysis. Next, we present baseline experiments utilizing machine and deep learning methods to set benchmarks. Results prove the framework's high performance, achieving an accuracy of 99.4% in offensive language detection and 66.2% in sentiment analysis.\n    ",
        "primary_category": "cs.CL",
        "categories": [],
        "submitted_date": "2 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01271": {
        "title": "Employing LLMs for Incident Response Planning and Review",
        "authors": [
            "Sam Hays",
            "Dr. Jules White"
        ],
        "comments": "10 pages, 11 figures",
        "subjects": "Cryptography and Security (cs.CR)",
        "abstract": "Incident Response Planning (IRP) is essential for effective cybersecurity management, requiring detailed documentation (or playbooks) to guide security personnel during incidents. Yet, creating comprehensive IRPs is often hindered by challenges such as complex systems, high turnover rates, and legacy technologies lacking documentation. This paper argues that, despite these obstacles, the development, review, and refinement of IRPs can be significantly enhanced through the utilization of Large Language Models (LLMs) like ChatGPT. By leveraging LLMs for tasks such as drafting initial plans, suggesting best practices, and identifying documentation gaps, organizations can overcome resource constraints and improve their readiness for cybersecurity incidents. We discuss the potential of LLMs to streamline IRP processes, while also considering the limitations and the need for human oversight in ensuring the accuracy and relevance of generated content. Our findings contribute to the cybersecurity field by demonstrating a novel approach to enhancing IRP with AI technologies, offering practical insights for organizations seeking to bolster their incident response capabilities.\n    ",
        "primary_category": "cs.CR",
        "categories": [],
        "submitted_date": "2 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01272": {
        "title": "Can a Confident Prior Replace a Cold Posterior?",
        "authors": [
            "Martin Marek",
            "Brooks Paige",
            "Pavel Izmailov"
        ],
        "comments": " ",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Benchmark datasets used for image classification tend to have very low levels of label noise. When Bayesian neural networks are trained on these datasets, they often underfit, misrepresenting the aleatoric uncertainty of the data. A common solution is to cool the posterior, which improves fit to the training data but is challenging to interpret from a Bayesian perspective. We explore whether posterior tempering can be replaced by a confidence-inducing prior distribution. First, we introduce a \"DirClip\" prior that is practical to sample and nearly matches the performance of a cold posterior. Second, we introduce a \"confidence prior\" that directly approximates a cold likelihood in the limit of decreasing temperature but cannot be easily sampled. Lastly, we provide several general insights into confidence-inducing priors, such as when they might diverge and how fine-tuning can mitigate numerical instability.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "stat.ML"
        ],
        "submitted_date": "2 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01273": {
        "title": "NoMAD-Attention: Efficient LLM Inference on CPUs Through Multiply-add-free Attention",
        "authors": [
            "Tianyi Zhang",
            "Jonah Wonkyu Yi",
            "Bowen Yao",
            "Zhaozhuo Xu",
            "Anshumali Shrivastava"
        ],
        "comments": " ",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Large language model inference on Central Processing Units (CPU) is challenging due to the vast quantities of expensive Multiply-Add (MAD) matrix operations in the attention computations. In this paper, we argue that there is a rare gem in modern CPUs, Single-Instruction-Multiple-Data (SIMD) registers, which allow for ultra-low-latency lookups in batch. We leverage this unique capability of CPUs to propose NoMAD-Attention, an efficient attention algorithm that replaces MAD operations with in-register lookups. Through hardware-aware algorithmic designs, NoMAD-Attention achieves the computation of attention scores using repeated fast accesses to SIMD registers despite their highly limited sizes. Moreover, NoMAD-Attention works with pre-trained attention-based LLMs without model finetuning. Empirical evaluations demonstrate that NoMAD-Attention maintains the quality of the original LLMs well, and speeds up the 4-bit quantized LLaMA-7B-based model by up to 2$\\times$ at 16k context length. Our results are reproducible at this https URL.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.AI",
            "cs.CL"
        ],
        "submitted_date": "2 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01277": {
        "title": "Optimal Integrated Task and Path Planning and Its Application to Multi-Robot Pickup and Delivery",
        "authors": [
            "Aman Aryan",
            "Manan Modi",
            "Indranil Saha",
            "Rupak Majumdar",
            "Swarup Mohalik"
        ],
        "comments": " ",
        "subjects": "Robotics (cs.RO)",
        "abstract": "We propose a generic multi-robot planning mechanism that combines an optimal task planner and an optimal path planner to provide a scalable solution for complex multi-robot planning problems. The Integrated planner, through the interaction of the task planner and the path planner, produces optimal collision-free trajectories for the robots. We illustrate our general algorithm on an object pick-and-drop planning problem in a warehouse scenario where a group of robots is entrusted with moving objects from one location to another in the workspace. We solve the task planning problem by reducing it into an SMT-solving problem and employing the highly advanced SMT solver Z3 to solve it. To generate collision-free movement of the robots, we extend the state-of-the-art algorithm Conflict Based Search with Precedence Constraints with several domain-specific constraints. We evaluate our integrated task and path planner extensively on various instances of the object pick-and-drop planning problem and compare its performance with a state-of-the-art multi-robot classical planner. Experimental results demonstrate that our planning mechanism can deal with complex planning problems and outperforms a state-of-the-art classical planner both in terms of computation time and the quality of the generated plan.\n    ",
        "primary_category": "cs.RO",
        "categories": [
            "cs.AI",
            "cs.MA"
        ],
        "submitted_date": "2 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01278": {
        "title": "Enhancing Audio Generation Diversity with Visual Information",
        "authors": [
            "Zeyu Xie",
            "Baihan Li",
            "Xuenan Xu",
            "Mengyue Wu",
            "Kai Yu"
        ],
        "comments": " ",
        "subjects": "Sound (cs.SD)",
        "abstract": "Audio and sound generation has garnered significant attention in recent years, with a primary focus on improving the quality of generated audios. However, there has been limited research on enhancing the diversity of generated audio, particularly when it comes to audio generation within specific categories. Current models tend to produce homogeneous audio samples within a category. This work aims to address this limitation by improving the diversity of generated audio with visual information. We propose a clustering-based method, leveraging visual information to guide the model in generating distinct audio content within each category. Results on seven categories indicate that extra visual input can largely enhance audio generation diversity. Audio samples are available at this https URL.\n    ",
        "primary_category": "cs.SD",
        "categories": [
            "eess.AS"
        ],
        "submitted_date": "2 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01286": {
        "title": "Summary Paper: Use Case on Building Collaborative Safe Autonomous Systems-A Robotdog for Guiding Visually Impaired People",
        "authors": [
            "Aman Malhotra",
            "Selma Saidi"
        ],
        "comments": " ",
        "subjects": "Robotics (cs.RO)",
        "abstract": "This is a summary paper of a use case of a Robotdog dedicated to guide visually impaired people in complex environment like a smart intersection. In such scenarios, the Robotdog has to autonomously decide whether it is safe to cross the intersection or not in order to further guide the human. We leverage data sharing and collaboration between the Robotdog and other autonomous systems operating in the same environment. We propose a system architecture for autonomous systems through a separation of a collaborative decision layer, to enable collective decision making processes, where data about the environment, relevant to the Robotdog decision, together with evidences for trustworthiness about other systems and the environment are shared.\n    ",
        "primary_category": "cs.RO",
        "categories": [
            "cs.AI",
            "cs.DC",
            "cs.MA",
            "eess.SY"
        ],
        "submitted_date": "2 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01289": {
        "title": "Greed is All You Need: An Evaluation of Tokenizer Inference Methods",
        "authors": [
            "Omri Uzan",
            "Craig W. Schmidt",
            "Chris Tanner",
            "Yuval Pinter"
        ],
        "comments": " ",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "While subword tokenizers such as BPE and WordPiece are typically used to build vocabularies for NLP models, the method of decoding text into a sequence of tokens from these vocabularies is often left unspecified, or ill-suited to the method in which they were constructed. We provide a controlled analysis of seven tokenizer inference methods across four different algorithms and three vocabulary sizes, performed on a novel intrinsic evaluation suite we curated for English, combining measures rooted in morphology, cognition, and information theory. We show that for the most commonly used tokenizers, greedy inference performs surprisingly well; and that SaGe, a recently-introduced contextually-informed tokenizer, outperforms all others on morphological alignment.\n    ",
        "primary_category": "cs.CL",
        "categories": [],
        "submitted_date": "2 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01290": {
        "title": "Characterizing Ethereum Upgradable Smart Contracts and Their Security Implications",
        "authors": [
            "Xiaofan Li",
            "Jin Yang",
            "Jiaqi Chen",
            "Yuzhe Tang",
            "Xing Gao"
        ],
        "comments": "12 pages, 5 figures",
        "subjects": "Cryptography and Security (cs.CR)",
        "abstract": "Upgradeable smart contracts (USCs) have been widely adopted to enable modifying deployed smart contracts. While USCs bring great flexibility to developers, improper usage might introduce new security issues, potentially allowing attackers to hijack USCs and their users. In this paper, we conduct a large-scale measurement study to characterize USCs and their security implications in the wild. We summarize six commonly used USC patterns and develop a tool, USCDetector, to identify USCs without needing source code. Particularly, USCDetector collects various information such as bytecode and transaction information to construct upgrade chains for USCs and disclose potentially vulnerable ones. We evaluate USCDetector using verified smart contracts (i.e., with source code) as ground truth and show that USCDetector can achieve high accuracy with a precision of 96.26%. We then use USCDetector to conduct a large-scale study on Ethereum, covering a total of 60,251,064 smart contracts. USCDetecor constructs 10,218 upgrade chains and discloses multiple real-world USCs with potential security issues.\n    ",
        "primary_category": "cs.CR",
        "categories": [
            "cs.CE"
        ],
        "submitted_date": "2 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01291": {
        "title": "A fractional-order trace-dev-div inequality",
        "authors": [
            "Carsten Carstensen",
            "Norbert Heuer"
        ],
        "comments": " ",
        "subjects": "Numerical Analysis (math.NA)",
        "abstract": "The trace-dev-div inequality in $H^s$ controls the trace in the norm of $H^s$ by that of the deviatoric part plus the $H^{s-1}$ norm of the divergence of a quadratic tensor field different from the constant unit matrix. This is well known for $s=0$ and established for orders $0\\le s\\le 1$ and arbitrary space dimension in this note. For mixed and least-squares finite element error analysis in linear elasticity, this inequality allows to establish robustness with respect to the Lam\u00e9 parameter $\\lambda$.\n    ",
        "primary_category": "math.NA",
        "categories": [
            "math.AP"
        ],
        "submitted_date": "2 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01297": {
        "title": "Experimental Evaluation of the ETSI DCC Adaptive Approach and Related Algorithms",
        "authors": [
            "Oscar Amador",
            "Ignacio Soto",
            "Maria Calderon",
            "Manuel Urue\u00f1a"
        ],
        "comments": " ",
        "subjects": "Networking and Internet Architecture (cs.NI)",
        "abstract": "Decentralized Congestion Control (DCC) mechanisms have been a core part of protocol stacks for vehicular networks since their inception and standardization. The ETSI ITS-G5 protocol stack for vehicular communications considers the usage of DCC not only in the network or access layers, but also as a part of the cross-layer architecture that influences how often messages are generated and transmitted. ETSI DCC mechanisms have evolved from a reactive approach based on a finite state machine, to an adaptive approach that relies on a linear control algorithm. This linear control algorithm, called LIMERIC, is the basis of the mechanism used in the ETSI DCC Adaptive Approach. The behavior of this algorithm depends on a set of parameters. Different values for these parameters have been proposed in the literature, including those defined in the ETSI specification. A recent proposal is Dual-$\\alpha$, which chooses parameters to improve convergence and fairness when the algorithm has to react to fast changes in the use of the shared medium (transitory situations). This article evaluates, by means of simulations, the performance of the ETSI DCC Adaptive Approach and related algorithms, considering both steady state and transitory situations. Results show that a bad selection of parameters can make a DCC algorithm ineffective, that the ETSI DCC Adaptive algorithm performs well in steady state conditions, and that Dual-$\\alpha$ performs as well in steady state conditions and outperforms the ETSI DCC Adaptive Approach in transitory scenarios.\n    ",
        "primary_category": "cs.NI",
        "categories": [],
        "submitted_date": "2 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01299": {
        "title": "A Photonic Physically Unclonable Function's Resilience to Multiple-Valued Machine Learning Attacks",
        "authors": [
            "Jessie M. Henderson",
            "Elena R. Henderson",
            "Clayton A. Harper",
            "Hiva Shahoei",
            "William V. Oxford",
            "Eric C. Larson",
            "Duncan L. MacFarlane",
            "Mitchell A. Thornton"
        ],
        "comments": "6 pages, 4 figures",
        "subjects": "Cryptography and Security (cs.CR)",
        "abstract": "Physically unclonable functions (PUFs) identify integrated circuits using nonlinearly-related challenge-response pairs (CRPs). Ideally, the relationship between challenges and corresponding responses is unpredictable, even if a subset of CRPs is known. Previous work developed a photonic PUF offering improved security compared to non-optical counterparts. Here, we investigate this PUF's susceptibility to Multiple-Valued-Logic-based machine learning attacks. We find that approximately 1,000 CRPs are necessary to train models that predict response bits better than random chance. Given the significant challenge of acquiring a vast number of CRPs from a photonic PUF, our results demonstrate photonic PUF resilience against such attacks.\n    ",
        "primary_category": "cs.CR",
        "categories": [
            "cs.LG"
        ],
        "submitted_date": "2 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01301": {
        "title": "Supplier Recommendation in Online Procurement",
        "authors": [
            "Victor Coscrato",
            "Derek Bridge"
        ],
        "comments": " ",
        "subjects": "Information Retrieval (cs.IR)",
        "abstract": "Supply chain optimization is key to a healthy and profitable business. Many companies use online procurement systems to agree contracts with suppliers. It is vital that the most competitive suppliers are invited to bid for such contracts. In this work, we propose a recommender system to assist with supplier discovery in road freight online procurement. Our system is able to provide personalized supplier recommendations, taking into account customer needs and preferences. This is a novel application of recommender systems, calling for design choices that fit the unique requirements of online procurement. Our preliminary results, using real-world data, are promising.\n    ",
        "primary_category": "cs.IR",
        "categories": [
            "cs.LG"
        ],
        "submitted_date": "2 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01304": {
        "title": "Improving the Validity of Automatically Generated Feedback via Reinforcement Learning",
        "authors": [
            "Alexander Scarlatos",
            "Digory Smith",
            "Simon Woodhead",
            "Andrew Lan"
        ],
        "comments": " ",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "Automatically generating feedback via large language models (LLMs) in intelligent tutoring systems and online learning platforms has the potential to improve the learning outcomes of many students. However, both feedback generation and evaluation are challenging: feedback content has to be valid especially in subjects like math, which requires models to understand the problem, the solution, and where the student's error lies. Feedback also has to be pedagogically valid to reflect effective tutoring strategies, such as explaining possible misconceptions and encouraging the student, among other desirable features. In this work, we address both problems of automatically generating and evaluating feedback while considering both correctness and alignment. First, we propose a rubric for evaluating math feedback and show that GPT-4 is able to effectively use it to annotate human-written and LLM-generated feedback. Second, we propose a framework for feedback generation that optimizes both correctness and alignment using reinforcement learning (RL). Specifically, we use GPT-4's annotations to create preferences over feedback pairs in an augmented dataset for training via direct preference optimization (DPO). We show that our methods significantly increase the correctness and alignment of generated feedback with Llama 2, an open-source LLM, qualitatively analyze our generation and evaluation systems using case studies, and outline several areas for future work.\n    ",
        "primary_category": "cs.CL",
        "categories": [],
        "submitted_date": "2 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01306": {
        "title": "ICC: Quantifying Image Caption Concreteness for Multimodal Dataset Curation",
        "authors": [
            "Moran Yanuka",
            "Morris Alper",
            "Hadar Averbuch-Elor",
            "Raja Giryes"
        ],
        "comments": " ",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Web-scale training on paired text-image data is becoming increasingly central to multimodal learning, but is challenged by the highly noisy nature of datasets in the wild. Standard data filtering approaches succeed in removing mismatched text-image pairs, but permit semantically related but highly abstract or subjective text. These approaches lack the fine-grained ability to isolate the most concrete samples that provide the strongest signal for learning in a noisy dataset. In this work, we propose a new metric, image caption concreteness, that evaluates caption text without an image reference to measure its concreteness and relevancy for use in multimodal learning. Our approach leverages strong foundation models for measuring visual-semantic information loss in multimodal representations. We demonstrate that this strongly correlates with human evaluation of concreteness in both single-word and sentence-level texts. Moreover, we show that curation using ICC complements existing approaches: It succeeds in selecting the highest quality samples from multimodal web-scale datasets to allow for efficient training in resource-constrained settings.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.CV"
        ],
        "submitted_date": "2 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01309": {
        "title": "VNLP: Turkish NLP Package",
        "authors": [
            "Meliksah Turker",
            "Mehmet Erdi Ari",
            "Aydin Han"
        ],
        "comments": " ",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "In this work, we present VNLP: the first dedicated, complete, open-source, well-documented, lightweight, production-ready, state-of-the-art Natural Language Processing (NLP) package for the Turkish language. It contains a wide variety of tools, ranging from the simplest tasks, such as sentence splitting and text normalization, to the more advanced ones, such as text and token classification models. Its token classification models are based on \"Context Model\", a novel architecture that is both an encoder and an auto-regressive model. NLP tasks solved by VNLP models include but are not limited to Sentiment Analysis, Named Entity Recognition, Morphological Analysis \\& Disambiguation and Part-of-Speech Tagging. Moreover, it comes with pre-trained word embeddings and corresponding SentencePiece Unigram tokenizers. VNLP has an open-source GitHub repository, ReadtheDocs documentation, PyPi package for convenient installation, Python and command-line API and a demo page to test all the functionality. Consequently, our main contribution is a complete, compact, easy-to-install and easy-to-use NLP package for Turkish.\n    ",
        "primary_category": "cs.CL",
        "categories": [
            "cs.AI",
            "cs.LG"
        ],
        "submitted_date": "2 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01310": {
        "title": "Image-Based Dietary Assessment: A Healthy Eating Plate Estimation System",
        "authors": [
            "Assylzhan Izbassar",
            "Pakizar Shamoi"
        ],
        "comments": "Submitted to IEEE for consideration",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "The nutritional quality of diets has significantly deteriorated over the past two to three decades, a decline often underestimated by the people. This deterioration, coupled with a hectic lifestyle, has contributed to escalating health concerns. Recognizing this issue, researchers at Harvard have advocated for a balanced nutritional plate model to promote health. Inspired by this research, our paper introduces an innovative Image-Based Dietary Assessment system aimed at evaluating the healthiness of meals through image analysis. Our system employs advanced image segmentation and classification techniques to analyze food items on a plate, assess their proportions, and calculate meal adherence to Harvard's healthy eating recommendations. This approach leverages machine learning and nutritional science to empower individuals with actionable insights for healthier eating choices. Our four-step framework involves segmenting the image, classifying the items, conducting a nutritional assessment based on the Harvard Healthy Eating Plate research, and offering tailored recommendations. The prototype system has shown promising results in promoting healthier eating habits by providing an accessible, evidence-based tool for dietary assessment.\n    ",
        "primary_category": "cs.CV",
        "categories": [],
        "submitted_date": "2 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01314": {
        "title": "Superflows: A New Tool for Forensic Network Flow Analysis",
        "authors": [
            "Michael Collins",
            "Jyotirmoy V. Deshmukh",
            "Dristi Dinesh",
            "Mukund Raghothaman",
            "Srivatsan Ravi",
            "Yuan Xia"
        ],
        "comments": " ",
        "subjects": "Networking and Internet Architecture (cs.NI)",
        "abstract": "Network security analysts gather data from diverse sources, from high-level summaries of network flow and traffic volumes to low-level details such as service logs from servers and the contents of individual packets. They validate and check this data against traffic patterns and historical indicators of compromise. Based on the results of this analysis, a decision is made to either automatically manage the traffic or report it to an analyst for further investigation. Unfortunately, due rapidly increasing traffic volumes, there are far more events to check than operational teams can handle for effective forensic analysis. However, just as packets are grouped into flows that share a commonality, we argue that a high-level construct for grouping network flows into a set a flows that share a hypothesis is needed to significantly improve the quality of operational network response by increasing Events Per Analysts Hour (EPAH).\nIn this paper, we propose a formalism for describing a superflow construct, which we characterize as an aggregation of one or more flows based on an analyst-specific hypothesis about traffic behavior. We demonstrate simple superflow constructions and representations, and perform a case study to explain how the formalism can be used to reduce the volume of data for forensic analysis.\n    ",
        "primary_category": "cs.NI",
        "categories": [],
        "submitted_date": "2 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01315": {
        "title": "Near-optimal Per-Action Regret Bounds for Sleeping Bandits",
        "authors": [
            "Quan Nguyen",
            "Nishant A. Mehta"
        ],
        "comments": "Accepted to AISTATS 2024",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "We derive near-optimal per-action regret bounds for sleeping bandits, in which both the sets of available arms and their losses in every round are chosen by an adversary. In a setting with $K$ total arms and at most $A$ available arms in each round over $T$ rounds, the best known upper bound is $O(K\\sqrt{TA\\ln{K}})$, obtained indirectly via minimizing internal sleeping regrets. Compared to the minimax $\\Omega(\\sqrt{TA})$ lower bound, this upper bound contains an extra multiplicative factor of $K\\ln{K}$. We address this gap by directly minimizing the per-action regret using generalized versions of EXP3, EXP3-IX and FTRL with Tsallis entropy, thereby obtaining near-optimal bounds of order $O(\\sqrt{TA\\ln{K}})$ and $O(\\sqrt{T\\sqrt{AK}})$. We extend our results to the setting of bandits with advice from sleeping experts, generalizing EXP4 along the way. This leads to new proofs for a number of existing adaptive and tracking regret bounds for standard non-sleeping bandits. Extending our results to the bandit version of experts that report their confidences leads to new bounds for the confidence regret that depends primarily on the sum of experts' confidences. We prove a lower bound, showing that for any minimax optimal algorithms, there exists an action whose regret is sublinear in $T$ but linear in the number of its active rounds.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "stat.ML"
        ],
        "submitted_date": "2 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01316": {
        "title": "TUMTraf V2X Cooperative Perception Dataset",
        "authors": [
            "Walter Zimmer",
            "Gerhard Arya Wardana",
            "Suren Sritharan",
            "Xingcheng Zhou",
            "Rui Song",
            "Alois C. Knoll"
        ],
        "comments": " ",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Cooperative perception offers several benefits for enhancing the capabilities of autonomous vehicles and improving road safety. Using roadside sensors in addition to onboard sensors increases reliability and extends the sensor range. External sensors offer higher situational awareness for automated vehicles and prevent occlusions. We propose CoopDet3D, a cooperative multi-modal fusion model, and TUMTraf-V2X, a perception dataset, for the cooperative 3D object detection and tracking task. Our dataset contains 2,000 labeled point clouds and 5,000 labeled images from five roadside and four onboard sensors. It includes 30k 3D boxes with track IDs and precise GPS and IMU data. We labeled eight categories and covered occlusion scenarios with challenging driving maneuvers, like traffic violations, near-miss events, overtaking, and U-turns. Through multiple experiments, we show that our CoopDet3D camera-LiDAR fusion model achieves an increase of +14.36 3D mAP compared to a vehicle camera-LiDAR fusion model. Finally, we make our dataset, model, labeling tool, and dev-kit publicly available on our website: this https URL.\n    ",
        "primary_category": "cs.CV",
        "categories": [],
        "submitted_date": "2 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01318": {
        "title": "High-Dimensional Tail Index Regression: with An Application to Text Analyses of Viral Posts in Social Media",
        "authors": [
            "Yuya Sasaki",
            "Jing Tao",
            "Yulong Wang"
        ],
        "comments": " ",
        "subjects": "Machine Learning (stat.ML)",
        "abstract": "Motivated by the empirical power law of the distributions of credits (e.g., the number of \"likes\") of viral posts in social media, we introduce the high-dimensional tail index regression and methods of estimation and inference for its parameters. We propose a regularized estimator, establish its consistency, and derive its convergence rate. To conduct inference, we propose to debias the regularized estimate, and establish the asymptotic normality of the debiased estimator. Simulation studies support our theory. These methods are applied to text analyses of viral posts in X (formerly Twitter) concerning LGBTQ+.\n    ",
        "primary_category": "stat.ML",
        "categories": [
            "cs.LG",
            "econ.EM"
        ],
        "submitted_date": "2 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01323": {
        "title": "A non-cubic space-filling modular robot",
        "authors": [
            "Tyler Hummer",
            "Sam Kriegman"
        ],
        "comments": " ",
        "subjects": "Robotics (cs.RO)",
        "abstract": "Space-filling building blocks of diverse shape permeate nature at all levels of organization, from atoms to honeycombs, and have proven useful in artificial systems, from molecular containers to clay bricks. But, despite the wide variety of space-filling polyhedra known to mathematics, only the cube has been explored in robotics. Thus, here we roboticize a non-cubic space-filling shape: the rhombic dodecahedron. This geometry offers an appealing alternative to cubes as it greatly simplifies rotational motion of one cell about the edge of another, and increases the number of neighbors each cell can communicate with and hold on to. To better understand the challenges and opportunities of these and other space-filling machines, we manufactured 48 rhombic dodecahedral cells and used them to build various superstructures. We report locomotive ability of some of the structures we built, and discuss the dis/advantages of the different designs we tested. We also introduce a strategy for genderless passive docking of cells that generalizes to any polyhedra with radially symmetrical faces. Future work will allow the cells to freely roll/rotate about one another so that they may realize the full potential of their unique shape.\n    ",
        "primary_category": "cs.RO",
        "categories": [],
        "submitted_date": "2 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01325": {
        "title": "NeRF-VPT: Learning Novel View Representations with Neural Radiance Fields via View Prompt Tuning",
        "authors": [
            "Linsheng Chen",
            "Guangrun Wang",
            "Liuchun Yuan",
            "Keze Wang",
            "Ken Deng",
            "Philip H.S. Torr"
        ],
        "comments": "AAAI 2024",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Neural Radiance Fields (NeRF) have garnered remarkable success in novel view synthesis. Nonetheless, the task of generating high-quality images for novel views persists as a critical challenge. While the existing efforts have exhibited commendable progress, capturing intricate details, enhancing textures, and achieving superior Peak Signal-to-Noise Ratio (PSNR) metrics warrant further focused attention and advancement. In this work, we propose NeRF-VPT, an innovative method for novel view synthesis to address these challenges. Our proposed NeRF-VPT employs a cascading view prompt tuning paradigm, wherein RGB information gained from preceding rendering outcomes serves as instructive visual prompts for subsequent rendering stages, with the aspiration that the prior knowledge embedded in the prompts can facilitate the gradual enhancement of rendered image quality. NeRF-VPT only requires sampling RGB data from previous stage renderings as priors at each training stage, without relying on extra guidance or complex techniques. Thus, our NeRF-VPT is plug-and-play and can be readily integrated into existing methods. By conducting comparative analyses of our NeRF-VPT against several NeRF-based approaches on demanding real-scene benchmarks, such as Realistic Synthetic 360, Real Forward-Facing, Replica dataset, and a user-captured dataset, we substantiate that our NeRF-VPT significantly elevates baseline performance and proficiently generates more high-quality novel view images than all the compared state-of-the-art methods. Furthermore, the cascading learning of NeRF-VPT introduces adaptability to scenarios with sparse inputs, resulting in a significant enhancement of accuracy for sparse-view novel view synthesis. The source code and dataset are available at \\url{this https URL}.\n    ",
        "primary_category": "cs.CV",
        "categories": [],
        "submitted_date": "2 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01326": {
        "title": "DNA Family: Boosting Weight-Sharing NAS with Block-Wise Supervisions",
        "authors": [
            "Guangrun Wang",
            "Changlin Li",
            "Liuchun Yuan",
            "Jiefeng Peng",
            "Xiaoyu Xian",
            "Xiaodan Liang",
            "Xiaojun Chang",
            "Liang Lin"
        ],
        "comments": "T-PAMI",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Neural Architecture Search (NAS), aiming at automatically designing neural architectures by machines, has been considered a key step toward automatic machine learning. One notable NAS branch is the weight-sharing NAS, which significantly improves search efficiency and allows NAS algorithms to run on ordinary computers. Despite receiving high expectations, this category of methods suffers from low search effectiveness. By employing a generalization boundedness tool, we demonstrate that the devil behind this drawback is the untrustworthy architecture rating with the oversized search space of the possible architectures. Addressing this problem, we modularize a large search space into blocks with small search spaces and develop a family of models with the distilling neural architecture (DNA) techniques. These proposed models, namely a DNA family, are capable of resolving multiple dilemmas of the weight-sharing NAS, such as scalability, efficiency, and multi-modal compatibility. Our proposed DNA models can rate all architecture candidates, as opposed to previous works that can only access a subsearch space using heuristic algorithms. Moreover, under a certain computational complexity constraint, our method can seek architectures with different depths and widths. Extensive experimental evaluations show that our models achieve state-of-the-art top-1 accuracy of 78.9% and 83.6% on ImageNet for a mobile convolutional network and a small vision transformer, respectively. Additionally, we provide in-depth empirical analysis and insights into neural architecture ratings. Codes available: \\url{this https URL}.\n    ",
        "primary_category": "cs.CV",
        "categories": [],
        "submitted_date": "2 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01327": {
        "title": "Euclidean distance compression via deep random features",
        "authors": [
            "Brett Leroux",
            "Luis Rademacher"
        ],
        "comments": " ",
        "subjects": "Computational Geometry (cs.CG)",
        "abstract": "Motivated by the problem of compressing point sets into as few bits as possible while maintaining information about approximate distances between points, we construct random nonlinear maps $\\varphi_\\ell$ that compress point sets in the following way. For a point set $S$, the map $\\varphi_\\ell:\\mathbb{R}^d \\to N^{-1/2}\\{-1,1\\}^N$ has the property that storing $\\varphi_\\ell(S)$ (a \\emph{sketch} of $S$) allows one to report pairwise squared distances between points in $S$ up to some multiplicative $(1\\pm \\epsilon)$ error with high probability as long as the minimum distance is not too small compared to $\\epsilon$. The maps $\\varphi_\\ell$ are the $\\ell$-fold composition of a certain type of random feature mapping. Moreover, we determine how large $N$ needs to be as a function of $\\epsilon$ and other parameters of the point set.\nCompared to existing techniques, our maps offer several advantages. The standard method for compressing point sets by random mappings relies on the Johnson-Lindenstrauss lemma which implies that if a set of $n$ points is mapped by a Gaussian random matrix to $\\mathbb{R}^k$ with $k =\\Theta(\\epsilon^{-2}\\log n)$, then pairwise distances between points are preserved up to a multiplicative $(1\\pm \\epsilon)$ error with high probability. The main advantage of our maps $\\varphi_\\ell$ over random linear maps is that ours map point sets directly into the discrete cube $N^{-1/2}\\{-1,1\\}^N$ and so there is no additional step needed to convert the sketch to bits. For some range of parameters, our maps $\\varphi_\\ell$ produce sketches which require fewer bits of storage space.\n    ",
        "primary_category": "cs.CG",
        "categories": [
            "cs.DS"
        ],
        "submitted_date": "2 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01329": {
        "title": "Bespoke Non-Stationary Solvers for Fast Sampling of Diffusion and Flow Models",
        "authors": [
            "Neta Shaul",
            "Uriel Singer",
            "Ricky T. Q. Chen",
            "Matthew Le",
            "Ali Thabet",
            "Albert Pumarola",
            "Yaron Lipman"
        ],
        "comments": " ",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "This paper introduces Bespoke Non-Stationary (BNS) Solvers, a solver distillation approach to improve sample efficiency of Diffusion and Flow models. BNS solvers are based on a family of non-stationary solvers that provably subsumes existing numerical ODE solvers and consequently demonstrate considerable improvement in sample approximation (PSNR) over these baselines. Compared to model distillation, BNS solvers benefit from a tiny parameter space ($<$200 parameters), fast optimization (two orders of magnitude faster), maintain diversity of samples, and in contrast to previous solver distillation approaches nearly close the gap from standard distillation methods such as Progressive Distillation in the low-medium NFE regime. For example, BNS solver achieves 45 PSNR / 1.76 FID using 16 NFE in class-conditional ImageNet-64. We experimented with BNS solvers for conditional image generation, text-to-image generation, and text-2-audio generation showing significant improvement in sample approximation (PSNR) in all.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.AI",
            "cs.CV"
        ],
        "submitted_date": "2 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01331": {
        "title": "The legacy of Bletchley Park on UK mathematics",
        "authors": [
            "Daniel Shiu"
        ],
        "comments": "13 pages, 2 figures",
        "subjects": "History and Overview (math.HO)",
        "abstract": "The second world war saw a major influx of mathematical talent into the areas of cryptanalysis and cryptography. This was particularly true at the UK's Government Codes and Cypher School (GCCS) at Bletchley Park. The success of introducing mathematical thinking into activities previously dominated by linguists is well-studied, but the reciprocal question of how the cryptologic effort affected the field of mathematics has been less investigated. Although their cryptologic achievements are not as celebrated as those of Turing, Tutte and Welchman, Bletchley Park's effort was supplemented by more eminent mathematicians, and those who would achieve eminence and provide leadership and direction for mathematical research in the United Kingdom. Amongst their number were Ian Cassels, Sandy Green, Philip Hall, Max Newman and Henry Whitehead. This paper considers how the experience of these and other mathematicians at Bletchley Park may have informed and influenced the mathematics that was produced in their post-war careers.\n    ",
        "primary_category": "math.HO",
        "categories": [
            "cs.CR"
        ],
        "submitted_date": "2 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01332": {
        "title": "Chaining thoughts and LLMs to learn DNA structural biophysics",
        "authors": [
            "Tyler D. Ross",
            "Ashwin Gopinath"
        ],
        "comments": " ",
        "subjects": "Quantitative Methods (q-bio.QM)",
        "abstract": "The future development of an AI scientist, a tool that is capable of integrating a variety of experimental data and generating testable hypotheses, holds immense potential. So far, bespoke machine learning models have been created to specialize in singular scientific tasks, but otherwise lack the flexibility of a general purpose model. Here, we show that a general purpose large language model, chatGPT 3.5-turbo, can be fine-tuned to learn the structural biophysics of DNA. We find that both fine-tuning models to return chain-of-thought responses and chaining together models fine-tuned for subtasks have an enhanced ability to analyze and design DNA sequences and their structures.\n    ",
        "primary_category": "q-bio.QM",
        "categories": [
            "cs.AI",
            "cs.LG"
        ],
        "submitted_date": "2 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01333": {
        "title": "Quantifying Maximum Actuator Degradation for a Given $H_2/H_{\\infty}$ Performance with Full-State Feedback Control",
        "authors": [
            "Hrishav Das",
            "Eliot Nychka",
            "Raktim Bhattacharya"
        ],
        "comments": "6 pages, 6 figures",
        "subjects": "Systems and Control (eess.SY)",
        "abstract": "In this paper, we address the issue of quantifying maximum actuator degradation in linear time-invariant dynamical systems. We present a new unified framework for computing the state-feedback controller gain that meets a user-defined closed-loop performance criterion while also maximizing actuator degradation. This degradation is modeled as a first-order filter with additive noise. Our approach involves two novel convex optimization formulations that concurrently determine the controller gain, maximize actuator degradation, and maintain the desired closed-loop performance in both the $H_2$ and $H_{\\infty}$ system norms. The results are limited to open-loop stable systems. We demonstrate the application of our results through the design of a full-state feedback controller for a model representing the longitudinal motion of the F-16 aircraft.\n    ",
        "primary_category": "eess.SY",
        "categories": [
            "math.OC"
        ],
        "submitted_date": "2 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01334": {
        "title": "Implementation of Linear Parameter Varying System to Investigate the Impact of Varying Flow Rate on the Lithium-ion Batteries Thermal Management System Performance",
        "authors": [
            "Pedram Rabiee",
            "Mohammad Hassan Saidi"
        ],
        "comments": " ",
        "subjects": "Systems and Control (eess.SY)",
        "abstract": "Battery thermal management system is an indispensable part of the electric vehicles working with Lithium-ion batteries. Accordingly, lithium-ion batteries modeling, battery heat generation, and thermal management are the main focus of researchers and car manufacturers. To fulfill the need of manufacturers in the design process, a faster model than time-consuming Computational Fluid Dynamics models (CFD) is required. Reduced Order Models (ROM) address this requirement to maintain the accuracy of CFD models while could be compiled faster. Linear Time Invariant (LTI) reduced order model has been used in the literature; however, due to the limitation of LTI system, considering the constant flow rate for the cooling fluid, a Linear Parameter Varying system with three scheduling parameters was developed in this study. It is shown that LPV system results could fit accurately to CFD results in conditions that LTI system cannot maintain accuracy. Moreover, it is shown that applying varying water flow rates could result in a smoother temperature profile.\n    ",
        "primary_category": "eess.SY",
        "categories": [],
        "submitted_date": "2 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01335": {
        "title": "Making Hybrid Languages: A Recipe",
        "authors": [
            "Leif Andersen",
            "Cameron Moy",
            "Stephen Chang",
            "Matthias Felleisen"
        ],
        "comments": " ",
        "subjects": "Programming Languages (cs.PL)",
        "abstract": "The dominant programming languages support only linear text to express ideas. Visual languages offer graphical representations for entire programs, when viewed with special tools. Hybrid languages, with support from existing tools, allow developers to express their ideas with a mix of textual and graphical syntax tailored to an application domain. This mix puts both kinds of syntax on equal footing and, importantly, the enriched language does not disrupt a programmer's typical workflow. This paper presents a recipe for equipping existing textual programming languages as well as accompanying IDEs with a mechanism for creating and using graphical interactive syntax. It also presents the first hybrid language and IDE created using the recipe.\n    ",
        "primary_category": "cs.PL",
        "categories": [
            "cs.HC"
        ],
        "submitted_date": "2 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01339": {
        "title": "Uniform $\\mathcal{C}^k$ Approximation of $G$-Invariant and Antisymmetric Functions, Embedding Dimensions, and Polynomial Representations",
        "authors": [
            "Soumya Ganguly",
            "Khoa Tran",
            "Rahul Sarkar"
        ],
        "comments": "38 pages",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "For any subgroup $G$ of the symmetric group $\\mathcal{S}_n$ on $n$ symbols, we present results for the uniform $\\mathcal{C}^k$ approximation of $G$-invariant functions by $G$-invariant polynomials. For the case of totally symmetric functions ($G = \\mathcal{S}_n$), we show that this gives rise to the sum-decomposition Deep Sets ansatz of Zaheer et al. (2018), where both the inner and outer functions can be chosen to be smooth, and moreover, the inner function can be chosen to be independent of the target function being approximated. In particular, we show that the embedding dimension required is independent of the regularity of the target function, the accuracy of the desired approximation, as well as $k$. Next, we show that a similar procedure allows us to obtain a uniform $\\mathcal{C}^k$ approximation of antisymmetric functions as a sum of $K$ terms, where each term is a product of a smooth totally symmetric function and a smooth antisymmetric homogeneous polynomial of degree at most $\\binom{n}{2}$. We also provide upper and lower bounds on $K$ and show that $K$ is independent of the regularity of the target function, the desired approximation accuracy, and $k$.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "math.RT"
        ],
        "submitted_date": "2 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01342": {
        "title": "LM4OPT: Unveiling the Potential of Large Language Models in Formulating Mathematical Optimization Problems",
        "authors": [
            "Tasnim Ahmed",
            "Salimur Choudhury"
        ],
        "comments": " ",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "In the rapidly evolving field of natural language processing, the translation of linguistic descriptions into mathematical formulation of optimization problems presents a formidable challenge, demanding intricate understanding and processing capabilities from Large Language Models (LLMs). This study compares prominent LLMs, including GPT-3.5, GPT-4, and Llama-2-7b, in zero-shot and one-shot settings for this task. Our findings show GPT-4's superior performance, particularly in the one-shot scenario. A central part of this research is the introduction of `LM4OPT,' a progressive fine-tuning framework for Llama-2-7b that utilizes noisy embeddings and specialized datasets. However, this research highlights a notable gap in the contextual understanding capabilities of smaller models such as Llama-2-7b compared to larger counterparts, especially in processing lengthy and complex input contexts. Our empirical investigation, utilizing the NL4Opt dataset, unveils that GPT-4 surpasses the baseline performance established by previous research, achieving an F1-score of 0.63, solely based on the problem description in natural language, and without relying on any additional named entity information. GPT-3.5 follows closely, both outperforming the fine-tuned Llama-2-7b. These findings not only benchmark the current capabilities of LLMs in a novel application area but also lay the groundwork for future improvements in mathematical formulation of optimization problems from natural language input.\n    ",
        "primary_category": "cs.CL",
        "categories": [
            "cs.IR"
        ],
        "submitted_date": "2 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01343": {
        "title": "The Effectiveness of a Training Program Based on Health Education to Improve Health Empowerment Level among Refugees in Jordan",
        "authors": [
            "Ahmed AlSharifin",
            "Muayyad Megdadi",
            "Amani Shatnawi",
            "Anas AlSobeh",
            "Aya Akkawi"
        ],
        "comments": "Accepted in Dirasat: Human and Social Sciences",
        "subjects": "Social and Information Networks (cs.SI)",
        "abstract": "Objectives: The study aimed to evaluate the effectiveness of a health education-based training program in enhancing the level of health empowerment among refugees in Jordan. Health empowerment is a key component to promote health as it enables individuals to control and manage their health outcomes and improve them. Refugees are a vulnerable population group with limited access to healthcare.\nMethodology: The study sample consisted of 38 refugees in Irbid governorate, Jordan, who were conveniently selected in coordination with some organizations working in the field of asylum in the governorate. They were randomly divided into two groups: an experimental group (n = 19) that received the health education training program, and a control group (n = 19) that did not receive any health education training. The Health Empowerment Scale (HES), a validated tool, was used to collect data from both groups in the pre and post-tests, and a follow-up test was conducted for members of the experimental group only. Results: The results showed a statistically significant increase in the health empowerment scores for the experimental group that received the training program compared to the control group. The mean of the pre-test for the experimental group was (1.97 - 0.27), and for the control group, it was (1.84 - 0.21). The post-test mean for the experimental group became (3.88 - 0.13), while for the control group, it was (1.85 - 0.20). The follow-up test also demonstrated that the enhanced health empowerment levels were maintained in the experimental group, with no significant difference between the post-test and follow-up scores, indicating the effectiveness of the health education training program in enhancing health empowerment for refugees in Jordan.\n    ",
        "primary_category": "cs.SI",
        "categories": [],
        "submitted_date": "2 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01344": {
        "title": "Mitigating the Bias in the Model for Continual Test-Time Adaptation",
        "authors": [
            "Inseop Chung",
            "Kyomin Hwang",
            "Jayeon Yoo",
            "Nojun Kwak"
        ],
        "comments": " ",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Continual Test-Time Adaptation (CTA) is a challenging task that aims to adapt a source pre-trained model to continually changing target domains. In the CTA setting, a model does not know when the target domain changes, thus facing a drastic change in the distribution of streaming inputs during the test-time. The key challenge is to keep adapting the model to the continually changing target domains in an online manner. We find that a model shows highly biased predictions as it constantly adapts to the chaining distribution of the target data. It predicts certain classes more often than other classes, making inaccurate over-confident predictions. This paper mitigates this issue to improve performance in the CTA scenario. To alleviate the bias issue, we make class-wise exponential moving average target prototypes with reliable target samples and exploit them to cluster the target features class-wisely. Moreover, we aim to align the target distributions to the source distribution by anchoring the target feature to its corresponding source prototype. With extensive experiments, our proposed method achieves noteworthy performance gain when applied on top of existing CTA methods without substantial adaptation time overhead.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.CV"
        ],
        "submitted_date": "2 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01345": {
        "title": "ShapeBoost: Boosting Human Shape Estimation with Part-Based Parameterization and Clothing-Preserving Augmentation",
        "authors": [
            "Siyuan Bian",
            "Jiefeng Li",
            "Jiasheng Tang",
            "Cewu Lu"
        ],
        "comments": " ",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Accurate human shape recovery from a monocular RGB image is a challenging task because humans come in different shapes and sizes and wear different clothes. In this paper, we propose ShapeBoost, a new human shape recovery framework that achieves pixel-level alignment even for rare body shapes and high accuracy for people wearing different types of clothes. Unlike previous approaches that rely on the use of PCA-based shape coefficients, we adopt a new human shape parameterization that decomposes the human shape into bone lengths and the mean width of each part slice. This part-based parameterization technique achieves a balance between flexibility and validity using a semi-analytical shape reconstruction algorithm. Based on this new parameterization, a clothing-preserving data augmentation module is proposed to generate realistic images with diverse body shapes and accurate annotations. Experimental results show that our method outperforms other state-of-the-art methods in diverse body shape situations as well as in varied clothing situations.\n    ",
        "primary_category": "cs.CV",
        "categories": [],
        "submitted_date": "2 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01346": {
        "title": "Improve Cost Efficiency of Active Learning over Noisy Dataset",
        "authors": [
            "Zan-Kai Chong",
            "Hiroyuki Ohsaki",
            "Bryan Ng"
        ],
        "comments": "6 pages, 9 figures, conference",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Active learning is a learning strategy whereby the machine learning algorithm actively identifies and labels data points to optimize its learning. This strategy is particularly effective in domains where an abundance of unlabeled data exists, but the cost of labeling these data points is prohibitively expensive. In this paper, we consider cases of binary classification, where acquiring a positive instance incurs a significantly higher cost compared to that of negative instances. For example, in the financial industry, such as in money-lending businesses, a defaulted loan constitutes a positive event leading to substantial financial loss. To address this issue, we propose a shifted normal distribution sampling function that samples from a wider range than typical uncertainty sampling. Our simulation underscores that our proposed sampling function limits both noisy and positive label selection, delivering between 20% and 32% improved cost efficiency over different test datasets.\n    ",
        "primary_category": "cs.LG",
        "categories": [],
        "submitted_date": "2 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01347": {
        "title": "The Repercussions of the COVID-19 Pandemic on Higher Education and its implications for Syrian Refugees Students (An Analytical Descriptive Study)",
        "authors": [
            "Anas Alsobeh",
            "Ahlam Aloudat"
        ],
        "comments": "in Arabic language",
        "subjects": "Social and Information Networks (cs.SI)",
        "abstract": "This study aims to reveal the most important challenges and difficulties that refugee students faced in Jordanian universities (e.g., Yarmouk University, AL Al-Bayt, and the Private Zarqa University) due to the COVID-19 pandemic through measuring a different of indicators that are related, in addition, to identify some of the independent variables on e-educational challenges. In the study, the analytical description approach was used. The data collection tool is a questionnaire, which was distributed to a random sample of students electronically. Results show that the necessity to implement educational and psychological counseling programs and economic support programs to support the e-Learning costs. The study confirmed that refugees are the most affected students with the pandemic compared to the host community.\nKeywords: Syrian refugees, COVID-19, e-learning\n    ",
        "primary_category": "cs.SI",
        "categories": [],
        "submitted_date": "2 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01348": {
        "title": "SANGRIA: Stacked Autoencoder Neural Networks with Gradient Boosting for Indoor Localization",
        "authors": [
            "Danish Gufran",
            "Saideep Tiku",
            "Sudeep Pasricha"
        ],
        "comments": " ",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Indoor localization is a critical task in many embedded applications, such as asset tracking, emergency response, and realtime navigation. In this article, we propose a novel fingerprintingbased framework for indoor localization called SANGRIA that uses stacked autoencoder neural networks with gradient boosted trees. Our approach is designed to overcome the device heterogeneity challenge that can create uncertainty in wireless signal measurements across embedded devices used for localization. We compare SANGRIA to several state-of-the-art frameworks and demonstrate 42.96% lower average localization error across diverse indoor locales and heterogeneous devices.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.AI",
            "eess.SP"
        ],
        "submitted_date": "3 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01349": {
        "title": "OSM: Leveraging Model Checking for Observing Dynamic 1 behaviors in Aspect-Oriented Applications",
        "authors": [
            "Anas AlSobeh"
        ],
        "comments": " ",
        "subjects": "Software Engineering (cs.SE)",
        "abstract": "In the intricate domain of software systems verification, dynamically model checking multifaceted system characteristics remains paramount, yet challenging. This research proposes the advanced observe-based statistical model-checking (OSM) framework, devised to craft executable formal models directly from foundational system code. Leveraging model checking predicates, the framework melds seamlessly with aspect-oriented programming paradigms, yielding a potent method for the analytical verification of varied behavioral attributes. Exploiting the transformative capacity of OSM framework, primary system code undergoes a systematic metamorphosis into multifaceted analysis constructs. This not only simplifies the model verification process but also orchestrates feature interactions using an innovative observing join point abstraction mechanism. Within this framework, components encompassing parsing, formal verification, computational analytics, and rigorous validation are intrinsically interwoven. Marrying the principles of model checking with aspect-oriented (AO) modularization, OSM framework stands as a paragon, proficiently scrutinizing and affirming system specifications. This ensures the unyielding performance of electronic health record systems amidst shifting preconditions. OSM framework offers runtime verification of both object-oriented and AO deployments, positioning itself as an indispensable open-source resource, poised to automate the enhancement of system performance and scalability.\n    ",
        "primary_category": "cs.SE",
        "categories": [],
        "submitted_date": "3 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01351": {
        "title": "Efficient FIR filtering with Bit Layer Multiply Accumulator",
        "authors": [
            "Vincenzo Liguori"
        ],
        "comments": " ",
        "subjects": "Hardware Architecture (cs.AR)",
        "abstract": "Bit Layer Multiplier Accumulator (BLMAC) is an efficient method to perform dot products without multiplications that exploits the bit level sparsity of the weights. A total of 1,980,000 low, high, band pass and band stop type I FIR filters were generated by systematically sweeping through the cut off frequencies and by varying the number of taps from 55 to 255. After their coefficients were quantized to 16 bits, applying the filter using a BLMAC required, on average, from ~123.3 to ~513.6 additions, depending on the number of taps. A BLMAC dot product machine, specialised for 127 taps FIR filters, was designed for AMD FPGAs. The design footprint is ~110 LUTs, including coefficient and sample storage and is able to apply the filter in ~232 clock cycles on average. This implies a filtering rate of 1.4-3.4 Msamples/s, depending on the FPGA family.\n    ",
        "primary_category": "cs.AR",
        "categories": [
            "cs.ET"
        ],
        "submitted_date": "3 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01352": {
        "title": "Improving Uncertainty Sampling with Bell Curve Weight Function",
        "authors": [
            "Zan-Kai Chong",
            "Hiroyuki Ohsaki",
            "Bok-Min Goi"
        ],
        "comments": "9 pages, 9 figures, journal",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Typically, a supervised learning model is trained using passive learning by randomly selecting unlabelled instances to annotate. This approach is effective for learning a model, but can be costly in cases where acquiring labelled instances is expensive. For example, it can be time-consuming to manually identify spam mails (labelled instances) from thousands of emails (unlabelled instances) flooding an inbox during initial data collection. Generally, we answer the above scenario with uncertainty sampling, an active learning method that improves the efficiency of supervised learning by using fewer labelled instances than passive learning. Given an unlabelled data pool, uncertainty sampling queries the labels of instances where the predicted probabilities, p, fall into the uncertainty region, i.e., $p \\approx 0.5$. The newly acquired labels are then added to the existing labelled data pool to learn a new model. Nonetheless, the performance of uncertainty sampling is susceptible to the area of unpredictable responses (AUR) and the nature of the dataset. It is difficult to determine whether to use passive learning or uncertainty sampling without prior knowledge of a new dataset. To address this issue, we propose bell curve sampling, which employs a bell curve weight function to acquire new labels. With the bell curve centred at p=0.5, bell curve sampling selects instances whose predicted values are in the uncertainty area most of the time without neglecting the rest. Simulation results show that, most of the time bell curve sampling outperforms uncertainty sampling and passive learning in datasets of different natures and with AUR.\n    ",
        "primary_category": "cs.LG",
        "categories": [],
        "submitted_date": "3 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01354": {
        "title": "An Overview of Minimum Convex Cover and Maximum Hidden Set",
        "authors": [
            "Reilly Browne"
        ],
        "comments": " ",
        "subjects": "Computational Geometry (cs.CG)",
        "abstract": "We give a review of results on the minimum convex cover and maximum hidden set problems. In addition, we give some new results. First we show that it is NP-hard to determine whether a polygon has the same convex cover number as its hidden set number. We then give some important examples in which these quantities don't always coincide. Finally, We present some consequences of insights from Browne, Kasthurirangan, Mitchell and Polishchuk [FOCS, 2023] on other classes of simple polygons.\n    ",
        "primary_category": "cs.CG",
        "categories": [],
        "submitted_date": "3 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01355": {
        "title": "a-DCF: an architecture agnostic metric with application to spoofing-robust speaker verification",
        "authors": [
            "Hye-jin Shim",
            "Jee-weon Jung",
            "Tomi Kinnunen",
            "Nicholas Evans",
            "Jean-Francois Bonastre",
            "Itshak Lapidot"
        ],
        "comments": "8 pages, submitted to Speaker Odyssey 2024",
        "subjects": "Audio and Speech Processing (eess.AS)",
        "abstract": "Spoofing detection is today a mainstream research topic. Standard metrics can be applied to evaluate the performance of isolated spoofing detection solutions and others have been proposed to support their evaluation when they are combined with speaker detection. These either have well-known deficiencies or restrict the architectural approach to combine speaker and spoof detectors. In this paper, we propose an architecture-agnostic detection cost function (a-DCF). A generalisation of the original DCF used widely for the assessment of automatic speaker verification (ASV), the a-DCF is designed for the evaluation of spoofing-robust ASV. Like the DCF, the a-DCF reflects the cost of decisions in a Bayes risk sense, with explicitly defined class priors and detection cost model. We demonstrate the merit of the a-DCF through the benchmarking evaluation of architecturally-heterogeneous spoofing-robust ASV solutions.\n    ",
        "primary_category": "eess.AS",
        "categories": [
            "cs.LG"
        ],
        "submitted_date": "3 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01356": {
        "title": "Security and Privacy Enhancing in Blockchain-based IoT Environments via Anonym Auditing",
        "authors": [
            "Peyman Khordadpour",
            "Saeed Ahmadi"
        ],
        "comments": " ",
        "subjects": "Cryptography and Security (cs.CR)",
        "abstract": "The integration of blockchain technology in Internet of Things (IoT) environments is a revolutionary step towards ensuring robust security and enhanced privacy. This paper delves into the unique challenges and solutions associated with securing blockchain-based IoT systems, with a specific focus on anonymous auditing to reinforce privacy and security. We propose a novel framework that combines the decentralized nature of blockchain with advanced security protocols tailored for IoT contexts. Central to our approach is the implementation of anonymization techniques in auditing processes, ensuring user privacy while maintaining the integrity and transparency of blockchain transactions. We outline the architecture of blockchain in IoT environments, emphasizing the workflow and specific security mechanisms employed. Additionally, we introduce a security protocol that integrates privacy-enhancing tools and anonymous auditing methods, including the use of advanced cryptographic techniques for anonymity. This study also includes a comparative analysis of our proposed framework against existing models in the domain. Our work aims to provide a comprehensive blueprint for enhancing security and privacy in blockchain-based IoT environments, paving the way for more secure and private digital ecosystems.\n    ",
        "primary_category": "cs.CR",
        "categories": [],
        "submitted_date": "3 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01359": {
        "title": "ModelWriter: Text & Model-Synchronized Document Engineering Platform",
        "authors": [
            "Ferhat Erata",
            "Claire Gardent",
            "Bikash Gyawali",
            "Anastasia Shimorina",
            "Yvan Lussaud",
            "Bedir Tekinerdogan",
            "Geylani Kardas",
            "Anne Monceaux"
        ],
        "comments": "Published in: 2017 32nd IEEE/ACM International Conference on Automated Software Engineering (ASE)",
        "subjects": "Software Engineering (cs.SE)",
        "abstract": "The ModelWriter platform provides a generic framework for automated traceability analysis. In this paper, we demonstrate how this framework can be used to trace the consistency and completeness of technical documents that consist of a set of System Installation Design Principles used by Airbus to ensure the correctness of aircraft system installation. We show in particular, how the platform allows the integration of two types of reasoning: reasoning about the meaning of text using semantic parsing and description logic theorem proving; and reasoning about document structure using first-order relational logic and finite model finding for traceability analysis.\n    ",
        "primary_category": "cs.SE",
        "categories": [],
        "submitted_date": "3 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01361": {
        "title": "Bandit Profit-maximization for Targeted Marketing",
        "authors": [
            "Joon Suk Huh",
            "Ellen Vitercik",
            "Kirthevasan Kandasamy"
        ],
        "comments": " ",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "We study a sequential profit-maximization problem, optimizing for both price and ancillary variables like marketing expenditures. Specifically, we aim to maximize profit over an arbitrary sequence of multiple demand curves, each dependent on a distinct ancillary variable, but sharing the same price. A prototypical example is targeted marketing, where a firm (seller) wishes to sell a product over multiple markets. The firm may invest different marketing expenditures for different markets to optimize customer acquisition, but must maintain the same price across all markets. Moreover, markets may have heterogeneous demand curves, each responding to prices and marketing expenditures differently. The firm's objective is to maximize its gross profit, the total revenue minus marketing costs.\nOur results are near-optimal algorithms for this class of problems in an adversarial bandit setting, where demand curves are arbitrary non-adaptive sequences, and the firm observes only noisy evaluations of chosen points on the demand curves. We prove a regret upper bound of $\\widetilde{\\mathcal{O}}\\big(nT^{3/4}\\big)$ and a lower bound of $\\Omega\\big((nT)^{3/4}\\big)$ for monotonic demand curves, and a regret bound of $\\widetilde{\\Theta}\\big(nT^{2/3}\\big)$ for demands curves that are monotonic in price and concave in the ancillary variables.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.GT",
            "econ.GN",
            "q-fin.GN"
        ],
        "submitted_date": "3 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01362": {
        "title": "Enhancing Retinal Vascular Structure Segmentation in Images With a Novel Design Two-Path Interactive Fusion Module Model",
        "authors": [
            "Rui Yang",
            "Shunpu Zhang"
        ],
        "comments": " ",
        "subjects": "Image and Video Processing (eess.IV)",
        "abstract": "Precision in identifying and differentiating micro and macro blood vessels in the retina is crucial for the diagnosis of retinal diseases, although it poses a significant challenge. Current autoencoding-based segmentation approaches encounter limitations as they are constrained by the encoder and undergo a reduction in resolution during the encoding stage. The inability to recover lost information in the decoding phase further impedes these approaches. Consequently, their capacity to extract the retinal microvascular structure is restricted. To address this issue, we introduce Swin-Res-Net, a specialized module designed to enhance the precision of retinal vessel segmentation. Swin-Res-Net utilizes the Swin transformer which uses shifted windows with displacement for partitioning, to reduce network complexity and accelerate model convergence. Additionally, the model incorporates interactive fusion with a functional module in the Res2Net architecture. The Res2Net leverages multi-scale techniques to enlarge the receptive field of the convolutional kernel, enabling the extraction of additional semantic information from the image. This combination creates a new module that enhances the localization and separation of micro vessels in the retina. To improve the efficiency of processing vascular information, we've added a module to eliminate redundant information between the encoding and decoding steps.\nOur proposed architecture produces outstanding results, either meeting or surpassing those of other published models. The AUC reflects significant enhancements, achieving values of 0.9956, 0.9931, and 0.9946 in pixel-wise segmentation of retinal vessels across three widely utilized datasets: CHASE-DB1, DRIVE, and STARE, respectively. Moreover, Swin-Res-Net outperforms alternative architectures, demonstrating superior performance in both IOU and F1 measure metrics.\n    ",
        "primary_category": "eess.IV",
        "categories": [
            "cs.CV"
        ],
        "submitted_date": "3 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01364": {
        "title": "Improving Cross-lingual Representation for Semantic Retrieval with Code-switching",
        "authors": [
            "Mieradilijiang Maimaiti",
            "Yuanhang Zheng",
            "Ji Zhang",
            "Fei Huang",
            "Yue Zhang",
            "Wenpei Luo",
            "Kaiyu Huang"
        ],
        "comments": " ",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "Semantic Retrieval (SR) has become an indispensable part of the FAQ system in the task-oriented question-answering (QA) dialogue scenario. The demands for a cross-lingual smart-customer-service system for an e-commerce platform or some particular business conditions have been increasing recently. Most previous studies exploit cross-lingual pre-trained models (PTMs) for multi-lingual knowledge retrieval directly, while some others also leverage the continual pre-training before fine-tuning PTMs on the downstream tasks. However, no matter which schema is used, the previous work ignores to inform PTMs of some features of the downstream task, i.e. train their PTMs without providing any signals related to SR. To this end, in this work, we propose an Alternative Cross-lingual PTM for SR via code-switching. We are the first to utilize the code-switching approach for cross-lingual SR. Besides, we introduce the novel code-switched continual pre-training instead of directly using the PTMs on the SR tasks. The experimental results show that our proposed approach consistently outperforms the previous SOTA methods on SR and semantic textual similarity (STS) tasks with three business corpora and four open datasets in 20+ languages.\n    ",
        "primary_category": "cs.CL",
        "categories": [],
        "submitted_date": "3 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01365": {
        "title": "AI-Powered Reminders for Collaborative Tasks: Experiences and Futures",
        "authors": [
            "Katelyn Morrison",
            "Shamsi Iqbal",
            "Eric Horvitz"
        ],
        "comments": "18 pages, 3 figures, 3 tables, accepted to ACM CSCW 2024",
        "subjects": "Human-Computer Interaction (cs.HC)",
        "abstract": "Email continues to serve as a central medium for managing collaborations. While unstructured email messaging is lightweight and conducive to coordination, it is easy to overlook commitments and requests for collaborations that are embedded in the text of free-flowing communications. Twenty-one years ago, Bellotti et al. proposed TaskMaster with the goal of redesigning the email interface to have explicit task management capabilities. Recently, AI-based task recognition and reminder services have been introduced in major email systems as one approach to managing asynchronous collaborations. While these services have been provided to millions of people around the world, there is little understanding of how people interact with and benefit from them. We explore knowledge workers' experiences with Microsoft's Viva Daily Briefing Email to better understand how AI-powered reminders can support asynchronous collaborations. Through semi-structured interviews and surveys, we shed light on how AI-powered reminders are incorporated into workflows to support asynchronous collaborations. We identify what knowledge workers prefer AI-powered reminders to remind them about and how they would like to interact with these reminders. Using mixed methods and a self-assessment methodology, we investigate the relationship between information workers' work styles and the perceived value of the Viva Daily Briefing Email to identify users who are more likely to benefit from AI-powered reminders for asynchronous collaborations. We conclude by discussing the experiences and futures of AI-powered reminders for collaborative tasks and asynchronous collaborations.\n    ",
        "primary_category": "cs.HC",
        "categories": [],
        "submitted_date": "3 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01367": {
        "title": "Optimization decision model of vegetable stock and pricing based on TCN-Attention and genetic algorithm",
        "authors": [
            "Linhan Xia",
            "Jinyuan Zhang",
            "Bohan Wen"
        ],
        "comments": "ICCSMT2023",
        "subjects": "Computational Engineering, Finance, and Science (cs.CE)",
        "abstract": "With the expansion of operational scale of supermarkets in China, the vegetable market has grown considerably. The decision-making related to procurement costs and allocation quantities of vegetables has become a pivotal factor in determining the profitability of supermarkets. This paper analyzes the relationship between pricing and allocation faced by supermarkets in vegetable operations. Optimization algorithms are employed to determine replenishment and pricing strategies. Linear regression is utilized to model the historical data of various products, establishing the relationship between sale prices and sales volumes for 61 products. By integrating historical data on vegetable costs with time information based on the 24 solar terms, a cost prediction model is trained using TCN-Attention. The Topis evaluation model identifies the 32 most market-demanded products. A genetic algorithm is then used to search for the globally optimized vegetable product allocation-pricing decision.\n    ",
        "primary_category": "cs.CE",
        "categories": [],
        "submitted_date": "3 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01369": {
        "title": "A Closer Look at Wav2Vec2 Embeddings for On-Device Single-Channel Speech Enhancement",
        "authors": [
            "Ravi Shankar",
            "Ke Tan",
            "Buye Xu",
            "Anurag Kumar"
        ],
        "comments": "8 pages; Shorter form accepted in ICASSP 2024",
        "subjects": "Audio and Speech Processing (eess.AS)",
        "abstract": "Self-supervised learned models have been found to be very effective for certain speech tasks such as automatic speech recognition, speaker identification, keyword spotting and others. While the features are undeniably useful in speech recognition and associated tasks, their utility in speech enhancement systems is yet to be firmly established, and perhaps not properly understood. In this paper, we investigate the uses of SSL representations for single-channel speech enhancement in challenging conditions and find that they add very little value for the enhancement task. Our constraints are designed around on-device real-time speech enhancement -- model is causal, the compute footprint is small. Additionally, we focus on low SNR conditions where such models struggle to provide good enhancement. In order to systematically examine how SSL representations impact performance of such enhancement models, we propose a variety of techniques to utilize these embeddings which include different forms of knowledge-distillation and pre-training.\n    ",
        "primary_category": "eess.AS",
        "categories": [
            "cs.AI",
            "cs.LG"
        ],
        "submitted_date": "3 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01370": {
        "title": "Depth Estimation Algorithm Based on Transformer-Encoder and Feature Fusion",
        "authors": [
            "Linhan Xia",
            "Junbang Liu",
            "Tong Wu"
        ],
        "comments": "ICAACE2024",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "This research presents a novel depth estimation algorithm based on a Transformer-encoder architecture, tailored for the NYU and KITTI Depth Dataset. This research adopts a transformer model, initially renowned for its success in natural language processing, to capture intricate spatial relationships in visual data for depth estimation tasks. A significant innovation of the research is the integration of a composite loss function that combines Structural Similarity Index Measure (SSIM) with Mean Squared Error (MSE). This combined loss function is designed to ensure the structural integrity of the predicted depth maps relative to the original images (via SSIM) while minimizing pixel-wise estimation errors (via MSE). This research approach addresses the challenges of over-smoothing often seen in MSE-based losses and enhances the model's ability to predict depth maps that are not only accurate but also maintain structural coherence with the input images. Through rigorous training and evaluation using the NYU Depth Dataset, the model demonstrates superior performance, marking a significant advancement in single-image depth estimation, particularly in complex indoor and traffic environments.\n    ",
        "primary_category": "cs.CV",
        "categories": [],
        "submitted_date": "3 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01371": {
        "title": "Large-scale variational Gaussian state-space models",
        "authors": [
            "Matthew Dowling",
            "Yuan Zhao",
            "Il Memming Park"
        ],
        "comments": " ",
        "subjects": "Machine Learning (stat.ML)",
        "abstract": "We introduce an amortized variational inference algorithm and structured variational approximation for state-space models with nonlinear dynamics driven by Gaussian noise. Importantly, the proposed framework allows for efficient evaluation of the ELBO and low-variance stochastic gradient estimates without resorting to diagonal Gaussian approximations by exploiting (i) the low-rank structure of Monte-Carlo approximations to marginalize the latent state through the dynamics (ii) an inference network that approximates the update step with low-rank precision matrix updates (iii) encoding current and future observations into pseudo observations -- transforming the approximate smoothing problem into an (easier) approximate filtering problem. Overall, the necessary statistics and ELBO can be computed in $O(TL(Sr + S^2 + r^2))$ time where $T$ is the series length, $L$ is the state-space dimensionality, $S$ are the number of samples used to approximate the predict step statistics, and $r$ is the rank of the approximate precision matrix update in the update step (which can be made of much lower dimension than $L$).\n    ",
        "primary_category": "stat.ML",
        "categories": [
            "cs.LG"
        ],
        "submitted_date": "3 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01374": {
        "title": "A Novel Dynamic Light-Section 3D Reconstruction Method for Wide-Range Sensing",
        "authors": [
            "Mengjuan Chen",
            "Qing Li",
            "Kohei Shimasaki",
            "Shaopeng Hu",
            "Qingyi Gu",
            "Idaku Ishii"
        ],
        "comments": "9 pages,6 figures, Journal",
        "subjects": "Robotics (cs.RO)",
        "abstract": "Existing galvanometer-based laser scanning systems are challenging to apply in multi-scale 3D reconstruction because of the difficulty in achieving a balance between high reconstruction accuracy and a wide reconstruction range. This paper presents a novel method that synchronizes laser scanning by switching the field-of-view (FOV) of a camera using multi-galvanometers. In addition to the advanced hardware setup, we establish a comprehensive mathematical model of the system by modeling dynamic camera, dynamic laser, and their combined interaction. We then propose a high-precision and flexible calibration method by constructing an error model and minimizing the objective function. Finally, we evaluate the performance of the proposed system by scanning standard components. The evaluation results demonstrate that the accuracy of the proposed 3D reconstruction system achieves 0.3 mm when the measurement range is extended to 1100 mm $\\times$ 1300 mm $\\times$ 650 mm. With the same reconstruction accuracy, the reconstruction range is expanded by a factor of 25, indicating that the proposed method simultaneously allows for high-precision and wide-range 3D reconstruction in industrial applications.\n    ",
        "primary_category": "cs.RO",
        "categories": [],
        "submitted_date": "3 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01381": {
        "title": "SA-MixNet: Structure-aware Mixup and Invariance Learning for Scribble-supervised Road Extraction in Remote Sensing Images",
        "authors": [
            "Jie Feng",
            "Hao Huang",
            "Junpeng Zhang",
            "Weisheng Dong",
            "Dingwen Zhang",
            "Licheng Jiao"
        ],
        "comments": " ",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Mainstreamed weakly supervised road extractors rely on highly confident pseudo-labels propagated from scribbles, and their performance often degrades gradually as the image scenes tend various. We argue that such degradation is due to the poor model's invariance to scenes with different complexities, whereas existing solutions to this problem are commonly based on crafted priors that cannot be derived from scribbles. To eliminate the reliance on such priors, we propose a novel Structure-aware Mixup and Invariance Learning framework (SA-MixNet) for weakly supervised road extraction that improves the model invariance in a data-driven manner. Specifically, we design a structure-aware Mixup scheme to paste road regions from one image onto another for creating an image scene with increased complexity while preserving the road's structural integrity. Then an invariance regularization is imposed on the predictions of constructed and origin images to minimize their conflicts, which thus forces the model to behave consistently on various scenes. Moreover, a discriminator-based regularization is designed for enhancing the connectivity meanwhile preserving the structure of roads. Combining these designs, our framework demonstrates superior performance on the DeepGlobe, Wuhan, and Massachusetts datasets outperforming the state-of-the-art techniques by 1.47%, 2.12%, 4.09% respectively in IoU metrics, and showing its potential of plug-and-play. The code will be made publicly available.\n    ",
        "primary_category": "cs.CV",
        "categories": [],
        "submitted_date": "3 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01382": {
        "title": "Automatic Question-Answer Generation for Long-Tail Knowledge",
        "authors": [
            "Rohan Kumar",
            "Youngmin Kim",
            "Sunitha Ravi",
            "Haitian Sun",
            "Christos Faloutsos",
            "Ruslan Salakhutdinov",
            "Minji Yoon"
        ],
        "comments": "Accepted at KDD 2023 KnowledgeNLP",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "Pretrained Large Language Models (LLMs) have gained significant attention for addressing open-domain Question Answering (QA). While they exhibit high accuracy in answering questions related to common knowledge, LLMs encounter difficulties in learning about uncommon long-tail knowledge (tail entities). Since manually constructing QA datasets demands substantial human resources, the types of existing QA datasets are limited, leaving us with a scarcity of datasets to study the performance of LLMs on tail entities. In this paper, we propose an automatic approach to generate specialized QA datasets for tail entities and present the associated research challenges. We conduct extensive experiments by employing pretrained LLMs on our newly generated long-tail QA datasets, comparing their performance with and without external resources including Wikipedia and Wikidata knowledge graphs.\n    ",
        "primary_category": "cs.CL",
        "categories": [],
        "submitted_date": "3 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01387": {
        "title": "A Comprehensive Survey of Federated Transfer Learning: Challenges, Methods and Applications",
        "authors": [
            "Wei Guo",
            "Fuzhen Zhuang",
            "Xiao Zhang",
            "Yiqi Tong",
            "Jin Dong"
        ],
        "comments": " ",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Federated learning (FL) is a novel distributed machine learning paradigm that enables participants to collaboratively train a centralized model with privacy preservation by eliminating the requirement of data sharing. In practice, FL often involves multiple participants and requires the third party to aggregate global information to guide the update of the target participant. Therefore, many FL methods do not work well due to the training and test data of each participant may not be sampled from the same feature space and the same underlying distribution. Meanwhile, the differences in their local devices (system heterogeneity), the continuous influx of online data (incremental data), and labeled data scarcity may further influence the performance of these methods. To solve this problem, federated transfer learning (FTL), which integrates transfer learning (TL) into FL, has attracted the attention of numerous researchers. However, since FL enables a continuous share of knowledge among participants with each communication round while not allowing local data to be accessed by other participants, FTL faces many unique challenges that are not present in TL. In this survey, we focus on categorizing and reviewing the current progress on federated transfer learning, and outlining corresponding solutions and applications. Furthermore, the common setting of FTL scenarios, available datasets, and significant related research are summarized in this survey.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.DC"
        ],
        "submitted_date": "3 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01390": {
        "title": "Right for Right Reasons: Large Language Models for Verifiable Commonsense Knowledge Graph Question Answering",
        "authors": [
            "Armin Toroghi",
            "Willis Guo",
            "Mohammad Mahdi Abdollah Pour",
            "Scott Sanner"
        ],
        "comments": "8 pages",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "Knowledge Graph Question Answering (KGQA) methods seek to answer Natural Language questions using the relational information stored in Knowledge Graphs (KGs). With the recent advancements of Large Language Models (LLMs) and their remarkable reasoning abilities, there is a growing trend to leverage them for KGQA. However, existing methodologies have only focused on answering factual questions, e.g., \"In which city was Silvio Berlusconi's first wife born?\", leaving questions involving commonsense reasoning that real-world users may pose more often, e.g., \"Do I need separate visas to see the Venus of Willendorf and attend the Olympics this summer?\" unaddressed. In this work, we first observe that existing LLM-based methods for KGQA struggle with hallucination on such questions, especially on queries targeting long-tail entities (e.g., non-mainstream and recent entities), thus hindering their applicability in real-world applications especially since their reasoning processes are not easily verifiable. In response, we propose Right for Right Reasons (R3), a commonsense KGQA methodology that allows for a verifiable reasoning procedure by axiomatically surfacing intrinsic commonsense knowledge of LLMs and grounding every factual reasoning step on KG triples. Through experimental evaluations across three different tasks--question answering, claim verification, and preference matching--our findings showcase R3 as a superior approach, outperforming existing methodologies and notably reducing instances of hallucination and reasoning errors.\n    ",
        "primary_category": "cs.CL",
        "categories": [],
        "submitted_date": "3 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01394": {
        "title": "Successful Transmission Probability and SIR Meta Distribution Analysis for Multi-Antenna Cache-Enabled Networks with Interference Nulling",
        "authors": [
            "Tianming Feng",
            "Chenyu Wu",
            "Xiaodong Zheng",
            "Peilin Chen",
            "Yilong Liu",
            "Shuai Han"
        ],
        "comments": " ",
        "subjects": "Information Theory (cs.IT)",
        "abstract": "This paper investigates a multi-antenna cache-enabled network with interference nulling (IN) employed at base stations. Two IN schemes, namely, the fixed IN scheme and the flexible IN scheme are considered to improve the received signal-to-interference ratio (SIR) at users. To thoroughly explore the effects of the caching parameter and the IN parameters on the network performance, we focus on the analysis of not only the successful transmission probability (STP) but the SIR meta distribution. For each IN scheme, the expression for the STP is derived and an approximated expression for the SIR meta distribution is also obtained by deriving the first and second moments of an upper bound of the link reliability and utilizing the beta distribution. With this analytical framework, we compare the performance of these two IN schemes and gain some useful system design guidelines from the perspectives of the STP and the SIR meta distribution by numerical simulations.\n    ",
        "primary_category": "cs.IT",
        "categories": [],
        "submitted_date": "3 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01395": {
        "title": "CR-LT-KGQA: A Knowledge Graph Question Answering Dataset Requiring Commonsense Reasoning and Long-Tail Knowledge",
        "authors": [
            "Willis Guo",
            "Armin Toroghi",
            "Scott Sanner"
        ],
        "comments": "7 pages",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "Knowledge graph question answering (KGQA) is a well-established field that seeks to provide factual answers to natural language (NL) questions by leveraging knowledge graphs (KGs). However, existing KGQA datasets suffer from two significant limitations: (1) no existing KGQA dataset requires commonsense reasoning to arrive at an answer and (2) existing KGQA datasets focus on popular entities for which large language models (LLMs) can directly answer without hallucinating and without leveraging the KG. In this work, we seek a novel KGQA dataset that supports commonsense reasoning and focuses on long-tail entities (e.g., non-mainstream and recent entities) where LLMs frequently hallucinate, and thus create the need for novel methodologies that leverage the KG for factual and attributable commonsense inference. We create a novel Commonsense Reasoning (CR) and Long-Tail (LT) KGQA dataset with two subtasks -- question answering and claim verification -- that address both limitations (1) and (2). We construct CR-LT-KGQA by building extensions to existing reasoning datasets StrategyQA and CREAK over Wikidata. While existing KGQA methods are not applicable due to their lack of commonsense inference support, baseline evaluation of LLMs on CR-LT KGQA demonstrate a high rate of hallucination. Thus, CR-LT KGQA poses significant challenges for hallucination-prone LLMs, hence paving the way for future commonsense KGQA research to provide accurate and factual answers for long-tail entities in the era of LLMs.\n    ",
        "primary_category": "cs.CL",
        "categories": [],
        "submitted_date": "3 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01400": {
        "title": "Decoupling Weighing and Selecting for Integrating Multiple Graph Pre-training Tasks",
        "authors": [
            "Tianyu Fan",
            "Lirong Wu",
            "Yufei Huang",
            "Haitao Lin",
            "Cheng Tan",
            "Zhangyang Gao",
            "Stan Z. Li"
        ],
        "comments": "Published as a conference paper at ICLR 2024",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Recent years have witnessed the great success of graph pre-training for graph representation learning. With hundreds of graph pre-training tasks proposed, integrating knowledge acquired from multiple pre-training tasks has become a popular research topic. In this paper, we identify two important collaborative processes for this topic: (1) select: how to select an optimal task combination from a given task pool based on their compatibility, and (2) weigh: how to weigh the selected tasks based on their importance. While there currently has been a lot of work focused on weighing, comparatively little effort has been devoted to selecting. This paper proposes a novel instance-level framework for integrating multiple graph pre-training tasks, Weigh And Select (WAS), where the two collaborative processes, weighing and selecting, are combined by decoupled siamese networks. Specifically, it first adaptively learns an optimal combination of tasks for each instance from a given task pool, based on which a customized instance-level task weighing strategy is learned. Extensive experiments on 16 graph datasets across node-level and graph-level downstream tasks have demonstrated that by combining a few simple but classical tasks, WAS can achieve comparable performance to other leading counterparts. The code is available at this https URL.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "3 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01404": {
        "title": "What Is Missing in Multilingual Visual Reasoning and How to Fix It",
        "authors": [
            "Yueqi Song",
            "Simran Khanuja",
            "Graham Neubig"
        ],
        "comments": " ",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "NLP models today strive for supporting multiple languages and modalities, improving accessibility for diverse users. In this paper, we evaluate their multilingual, multimodal capabilities by testing on a visual reasoning task. We observe that proprietary systems like GPT-4V obtain the best performance on this task now, but open models lag in comparison. Surprisingly, GPT-4V exhibits similar performance between English and other languages, indicating the potential for equitable system development across languages. Our analysis on model failures reveals three key aspects that make this task challenging: multilinguality, complex reasoning, and multimodality. To address these challenges, we propose three targeted interventions including a translate-test approach to tackle multilinguality, a visual programming approach to break down complex reasoning, and a novel method that leverages image captioning to address multimodality. Our interventions achieve the best open performance on this task in a zero-shot setting, boosting open model LLaVA by 13.4%, while also minorly improving GPT-4V's performance.\n    ",
        "primary_category": "cs.CL",
        "categories": [],
        "submitted_date": "3 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01411": {
        "title": "OVEL: Large Language Model as Memory Manager for Online Video Entity Linking",
        "authors": [
            "Haiquan Zhao",
            "Xuwu Wang",
            "Shisong Chen",
            "Zhixu Li",
            "Xin Zheng",
            "Yanghua Xiao"
        ],
        "comments": "13 pages, 6 figures",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "In recent years, multi-modal entity linking (MEL) has garnered increasing attention in the research community due to its significance in numerous multi-modal applications. Video, as a popular means of information transmission, has become prevalent in people's daily lives. However, most existing MEL methods primarily focus on linking textual and visual mentions or offline videos's mentions to entities in multi-modal knowledge bases, with limited efforts devoted to linking mentions within online video content. In this paper, we propose a task called Online Video Entity Linking OVEL, aiming to establish connections between mentions in online videos and a knowledge base with high accuracy and timeliness. To facilitate the research works of OVEL, we specifically concentrate on live delivery scenarios and construct a live delivery entity linking dataset called LIVE. Besides, we propose an evaluation metric that considers timelessness, robustness, and accuracy. Furthermore, to effectively handle OVEL task, we leverage a memory block managed by a Large Language Model and retrieve entity candidates from the knowledge base to augment LLM performance on memory management. The experimental results prove the effectiveness and efficiency of our method.\n    ",
        "primary_category": "cs.CL",
        "categories": [],
        "submitted_date": "3 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01412": {
        "title": "LUM-ViT: Learnable Under-sampling Mask Vision Transformer for Bandwidth Limited Optical Signal Acquisition",
        "authors": [
            "Lingfeng Liu",
            "Dong Ni",
            "Hangjie Yuan"
        ],
        "comments": "Accepted to ICLR 2024",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Bandwidth constraints during signal acquisition frequently impede real-time detection applications. Hyperspectral data is a notable example, whose vast volume compromises real-time hyperspectral detection. To tackle this hurdle, we introduce a novel approach leveraging pre-acquisition modulation to reduce the acquisition volume. This modulation process is governed by a deep learning model, utilizing prior information. Central to our approach is LUM-ViT, a Vision Transformer variant. Uniquely, LUM-ViT incorporates a learnable under-sampling mask tailored for pre-acquisition modulation. To further optimize for optical calculations, we propose a kernel-level weight binarization technique and a three-stage fine-tuning strategy. Our evaluations reveal that, by sampling a mere 10% of the original image pixels, LUM-ViT maintains the accuracy loss within 1.8% on the ImageNet classification task. The method sustains near-original accuracy when implemented on real-world optical hardware, demonstrating its practicality. Code will be available at this https URL.\n    ",
        "primary_category": "cs.CV",
        "categories": [
            "eess.IV",
            "eess.SP"
        ],
        "submitted_date": "3 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01413": {
        "title": "Exploring the Design of Generative AI in Supporting Music-based Reminiscence for Older Adults",
        "authors": [
            "Yucheng Jin",
            "Wanling Cai",
            "Li Chen",
            "Yizhe Zhang",
            "Gavin Doherty",
            "Tonglin Jiang"
        ],
        "comments": " ",
        "subjects": "Human-Computer Interaction (cs.HC)",
        "abstract": "Music-based reminiscence has the potential to positively impact the psychological well-being of older adults. However, the aging process and physiological changes, such as memory decline and limited verbal communication, may impede the ability of older adults to recall their memories and life experiences. Given the advanced capabilities of generative artificial intelligence (AI) systems, such as generated conversations and images, and their potential to facilitate the reminiscing process, this study aims to explore the design of generative AI to support music-based reminiscence in older adults. This study follows a user-centered design approach incorporating various stages, including detailed interviews with two social workers and two design workshops (involving ten older adults). Our work contributes to an in-depth understanding of older adults' attitudes toward utilizing generative AI for supporting music-based reminiscence and identifies concrete design considerations for the future design of generative AI to enhance the reminiscence experience of older adults.\n    ",
        "primary_category": "cs.HC",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "3 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01417": {
        "title": "Asyn2F: An Asynchronous Federated Learning Framework with Bidirectional Model Aggregation",
        "authors": [
            "Tien-Dung Cao",
            "Nguyen T. Vuong",
            "Thai Q. Le",
            "Hoang V.N. Dao",
            "Tram Truong-Huu"
        ],
        "comments": " ",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "In federated learning, the models can be trained synchronously or asynchronously. Many research works have focused on developing an aggregation method for the server to aggregate multiple local models into the global model with improved performance. They ignore the heterogeneity of the training workers, which causes the delay in the training of the local models, leading to the obsolete information issue. In this paper, we design and develop Asyn2F, an Asynchronous Federated learning Framework with bidirectional model aggregation. By bidirectional model aggregation, Asyn2F, on one hand, allows the server to asynchronously aggregate multiple local models and results in a new global model. On the other hand, it allows the training workers to aggregate the new version of the global model into the local model, which is being trained even in the middle of a training epoch. We develop Asyn2F considering the practical implementation requirements such as using cloud services for model storage and message queuing protocols for communications. Extensive experiments with different datasets show that the models trained by Asyn2F achieve higher performance compared to the state-of-the-art techniques. The experiments also demonstrate the effectiveness, practicality, and scalability of Asyn2F, making it ready for deployment in real scenarios.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.DC"
        ],
        "submitted_date": "3 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01418": {
        "title": "A Simple-but-effective Baseline for Training-free Class-Agnostic Counting",
        "authors": [
            "Yuhao Lin",
            "Haiming Xu",
            "Lingqiao Liu",
            "Javen Qinfeng Shi"
        ],
        "comments": " ",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Class-Agnostic Counting (CAC) seeks to accurately count objects in a given image with only a few reference examples. While previous methods achieving this relied on additional training, recent efforts have shown that it's possible to accomplish this without training by utilizing pre-existing foundation models, particularly the Segment Anything Model (SAM), for counting via instance-level segmentation. Although promising, current training-free methods still lag behind their training-based counterparts in terms of performance. In this research, we present a straightforward training-free solution that effectively bridges this performance gap, serving as a strong baseline. The primary contribution of our work lies in the discovery of four key technologies that can enhance performance. Specifically, we suggest employing a superpixel algorithm to generate more precise initial point prompts, utilizing an image encoder with richer semantic knowledge to replace the SAM encoder for representing candidate objects, and adopting a multiscale mechanism and a transductive prototype scheme to update the representation of reference examples. By combining these four technologies, our approach achieves significant improvements over existing training-free methods and delivers performance on par with training-based ones.\n    ",
        "primary_category": "cs.CV",
        "categories": [],
        "submitted_date": "3 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01420": {
        "title": "The Implicit Bias of Heterogeneity towards Invariance and Causality",
        "authors": [
            "Yang Xu",
            "Yihong Gu",
            "Cong Fang"
        ],
        "comments": " ",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "It is observed empirically that the large language models (LLM), trained with a variant of regression loss using numerous corpus from the Internet, can unveil causal associations to some extent. This is contrary to the traditional wisdom that ``association is not causation'' and the paradigm of traditional causal inference in which prior causal knowledge should be carefully incorporated into the design of methods. It is a mystery why causality, in a higher layer of understanding, can emerge from the regression task that pursues associations. In this paper, we claim the emergence of causality from association-oriented training can be attributed to the coupling effects from the heterogeneity of the source data, stochasticity of training algorithms, and over-parameterization of the learning models. We illustrate such an intuition using a simple but insightful model that learns invariance, a quasi-causality, using regression loss. To be specific, we consider multi-environment low-rank matrix sensing problems where the unknown r-rank ground-truth d*d matrices diverge across the environments but contain a lower-rank invariant, causal part. In this case, running pooled gradient descent will result in biased solutions that only learn associations in general. We show that running large-batch Stochastic Gradient Descent, whose each batch being linear measurement samples randomly selected from a certain environment, can successfully drive the solution towards the invariant, causal solution under certain conditions. This step is related to the relatively strong heterogeneity of the environments, the large step size and noises in the optimization algorithm, and the over-parameterization of the model. In summary, we unveil another implicit bias that is a result of the symbiosis between the heterogeneity of data and modern algorithms, which is, to the best of our knowledge, first in the literature.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "math.OC"
        ],
        "submitted_date": "3 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01422": {
        "title": "MovieLLM: Enhancing Long Video Understanding with AI-Generated Movies",
        "authors": [
            "Zhende Song",
            "Chenchen Wang",
            "Jiamu Sheng",
            "Chi Zhang",
            "Gang Yu",
            "Jiayuan Fan",
            "Tao Chen"
        ],
        "comments": " ",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "The development of multimodal models has marked a significant step forward in how machines understand videos. These models have shown promise in analyzing short video clips. However, when it comes to longer formats like movies, they often fall short. The main hurdles are the lack of high-quality, diverse video data and the intensive work required to collect or annotate such data. In the face of these challenges, we propose MovieLLM, a novel framework designed to create synthetic, high-quality data for long videos. This framework leverages the power of GPT-4 and text-to-image models to generate detailed scripts and corresponding visuals. Our approach stands out for its flexibility and scalability, making it a superior alternative to traditional data collection methods. Our extensive experiments validate that the data produced by MovieLLM significantly improves the performance of multimodal models in understanding complex video narratives, overcoming the limitations of existing datasets regarding scarcity and bias.\n    ",
        "primary_category": "cs.CV",
        "categories": [],
        "submitted_date": "3 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01423": {
        "title": "Collective Certified Robustness against Graph Injection Attacks",
        "authors": [
            "Yuni Lai",
            "Bailin Pan",
            "Kaihuang Chen",
            "Yancheng Yuan",
            "Kai Zhou"
        ],
        "comments": " ",
        "subjects": "Cryptography and Security (cs.CR)",
        "abstract": "We investigate certified robustness for GNNs under graph injection attacks. Existing research only provides sample-wise certificates by verifying each node independently, leading to very limited certifying performance. In this paper, we present the first collective certificate, which certifies a set of target nodes simultaneously. To achieve it, we formulate the problem as a binary integer quadratic constrained linear programming (BQCLP). We further develop a customized linearization technique that allows us to relax the BQCLP into linear programming (LP) that can be efficiently solved. Through comprehensive experiments, we demonstrate that our collective certification scheme significantly improves certification performance with minimal computational overhead. For instance, by solving the LP within 1 minute on the Citeseer dataset, we achieve a significant increase in the certified ratio from 0.0% to 81.2% when the injected node number is 5% of the graph size. Our step marks a crucial step towards making provable defense more practical.\n    ",
        "primary_category": "cs.CR",
        "categories": [
            "cs.LG"
        ],
        "submitted_date": "3 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01425": {
        "title": "CRPWarner: Warning the Risk of Contract-related Rug Pull in DeFi Smart Contracts",
        "authors": [
            "Zewei Lin",
            "Jiachi Chen",
            "Zibin Zheng",
            "Jiajing Wu",
            "Weizhe Zhang",
            "Yongjuan Wang"
        ],
        "comments": "14 pages, 4 figures",
        "subjects": "Software Engineering (cs.SE)",
        "abstract": "In recent years, Decentralized Finance (DeFi) grows rapidly due to the development of blockchain technology and smart contracts. As of March 2023, the estimated global cryptocurrency market cap has reached approximately $949 billion. However, security incidents continue to plague the DeFi ecosystem, and one of the most notorious examples is the ``Rug Pull\" scam. This type of cryptocurrency scam occurs when the developer of a particular token project intentionally abandons the project and disappears with investors' funds. Despite it only emerging in recent years, Rug Pull events have already caused significant financial losses. In this work, we manually collected and analyzed 103 real-world rug pull events, categorizing them based on their scam methods. Two primary categories were identified: Contract-related Rug Pull (through malicious functions in smart contracts) and Transaction-related Rug Pull (through cryptocurrency trading without utilizing malicious functions). Based on the analysis of rug pull events, we propose CRPWarner (short for Contract-related Rug Pull Risk Warner) to identify malicious functions in smart contracts and issue warnings regarding potential rug pulls. We evaluated CRPWarner on 69 open-source smart contracts related to rug pull events and achieved a 91.8% precision, 85.9% recall and 88.7% F1-score. Additionally, when evaluating CRPWarner on 13,484 real token contracts on Ethereum, it successfully detected 4168 smart contracts with malicious functions, including zero-day examples. The precision of large-scale experiment reach 84.9%.\n    ",
        "primary_category": "cs.SE",
        "categories": [],
        "submitted_date": "3 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01426": {
        "title": "Introduction to Algogens",
        "authors": [
            "Amir Shachar"
        ],
        "comments": " ",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "This book introduces the concept of Algogens, a promising integration of generative AI with traditional algorithms aimed at improving problem-solving techniques across various fields. It provides an accessible overview of how Algogens combine AI's innovative potential with algorithms' reliability to tackle complex challenges more effectively than either could alone.\nThe text explores the basics of Algogens, their development, applications, and advantages, such as better adaptability and efficiency. Through examples and case studies, readers will learn about Algogens' practical uses today and their potential for future cybersecurity, healthcare, and environmental science innovation.\nAcknowledging new technologies' challenges and ethical considerations, the book offers a balanced look at the prospects and obstacles facing Algogens. It invites a broad audience, including experts and newcomers, to engage with the topic and consider Algogens' role in advancing our problem-solving capabilities.\nThis work is presented as a starting point for anyone interested in the intersection of AI and algorithms, encouraging further exploration and discussion on this emerging field. It aims to spark curiosity and contribute to the ongoing conversation about how technology can evolve to meet the complex demands of the AI era.\n    ",
        "primary_category": "cs.LG",
        "categories": [],
        "submitted_date": "3 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01427": {
        "title": "Logit Standardization in Knowledge Distillation",
        "authors": [
            "Shangquan Sun",
            "Wenqi Ren",
            "Jingzhi Li",
            "Rui Wang",
            "Xiaochun Cao"
        ],
        "comments": "10 pages, 5 figures, accepted by The The IEEE / CVF Computer Vision and Pattern Recognition Conference (CVPR 2024)",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Knowledge distillation involves transferring soft labels from a teacher to a student using a shared temperature-based softmax function. However, the assumption of a shared temperature between teacher and student implies a mandatory exact match between their logits in terms of logit range and variance. This side-effect limits the performance of student, considering the capacity discrepancy between them and the finding that the innate logit relations of teacher are sufficient for student to learn. To address this issue, we propose setting the temperature as the weighted standard deviation of logit and performing a plug-and-play Z-score pre-process of logit standardization before applying softmax and Kullback-Leibler divergence. Our pre-process enables student to focus on essential logit relations from teacher rather than requiring a magnitude match, and can improve the performance of existing logit-based distillation methods. We also show a typical case where the conventional setting of sharing temperature between teacher and student cannot reliably yield the authentic distillation evaluation; nonetheless, this challenge is successfully alleviated by our Z-score. We extensively evaluate our method for various student and teacher models on CIFAR-100 and ImageNet, showing its significant superiority. The vanilla knowledge distillation powered by our pre-process can achieve favorable performance against state-of-the-art methods, and other distillation variants can obtain considerable gain with the assistance of our pre-process.\n    ",
        "primary_category": "cs.CV",
        "categories": [],
        "submitted_date": "3 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01429": {
        "title": "Kubernetes in Action: Exploring the Performance of Kubernetes Distributions in the Cloud",
        "authors": [
            "Hossein Aqasizade",
            "Ehsan Ataie",
            "Mostafa Bastam"
        ],
        "comments": "18 pages, 14 figures",
        "subjects": "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "abstract": "Kubernetes has emerged as a leading open-source platform for container orchestration, allowing organizations to efficiently manage and deploy containerized applications at scale. This paper investigates the performance of four Kubernetes distributions, namely Kubeadm, K3s, MicroK8s, and K0s when running OpenFaaS as a containerized service on a cluster of computing nodes on CloudLab. For this purpose, experiments are conducted to examine the performance of two virtualization modes, namely HVM and PV, supported by Xen as the underlying hypervisor. Moreover, two container runtimes that are integrated with Kubernetes, namely Docker, and Containerd, are examined to assess their performance on both disk-intensive and CPU-intensive workloads. After determining the appropriate underlying Xen mode and container runtime, the Kubernetes distributions are set up and their performance is measured using various metrics, such as request rate, CPU utilization, and scaling behavior.\n    ",
        "primary_category": "cs.DC",
        "categories": [
            "cs.PF"
        ],
        "submitted_date": "3 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01430": {
        "title": "On Diffusion Process in SE(3)-invariant Space",
        "authors": [
            "Zihan Zhou",
            "Ruiying Liu",
            "Jiachen Zheng",
            "Xiaoxue Wang",
            "Tianshu Yu"
        ],
        "comments": " ",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Sampling viable 3D structures (e.g., molecules and point clouds) with SE(3)-invariance using diffusion-based models proved promising in a variety of real-world applications, wherein SE(3)-invariant properties can be naturally characterized by the inter-point distance manifold. However, due to the non-trivial geometry, we still lack a comprehensive understanding of the diffusion mechanism within such SE(3)-invariant space. This study addresses this gap by mathematically delineating the diffusion mechanism under SE(3)-invariance, via zooming into the interaction behavior between coordinates and the inter-point distance manifold through the lens of differential geometry. Upon this analysis, we propose accurate and projection-free diffusion SDE and ODE accordingly. Such formulations enable enhancing the performance and the speed of generation pathways; meanwhile offering valuable insights into other systems incorporating SE(3)-invariance.\n    ",
        "primary_category": "cs.LG",
        "categories": [],
        "submitted_date": "3 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01431": {
        "title": "Image2Sentence based Asymmetrical Zero-shot Composed Image Retrieval",
        "authors": [
            "Yongchao Du",
            "Min Wang",
            "Wengang Zhou",
            "Shuping Hui",
            "Houqiang Li"
        ],
        "comments": "ICLR 2024 spotlight",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "The task of composed image retrieval (CIR) aims to retrieve images based on the query image and the text describing the users' intent. Existing methods have made great progress with the advanced large vision-language (VL) model in CIR task, however, they generally suffer from two main issues: lack of labeled triplets for model training and difficulty of deployment on resource-restricted environments when deploying the large vision-language model. To tackle the above problems, we propose Image2Sentence based Asymmetric zero-shot composed image retrieval (ISA), which takes advantage of the VL model and only relies on unlabeled images for composition learning. In the framework, we propose a new adaptive token learner that maps an image to a sentence in the word embedding space of VL model. The sentence adaptively captures discriminative visual information and is further integrated with the text modifier. An asymmetric structure is devised for flexible deployment, in which the lightweight model is adopted for the query side while the large VL model is deployed on the gallery side. The global contrastive distillation and the local alignment regularization are adopted for the alignment between the light model and the VL model for CIR task. Our experiments demonstrate that the proposed ISA could better cope with the real retrieval scenarios and further improve retrieval accuracy and efficiency.\n    ",
        "primary_category": "cs.CV",
        "categories": [],
        "submitted_date": "3 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01433": {
        "title": "BrainMass: Advancing Brain Network Analysis for Diagnosis with Large-scale Self-Supervised Learning",
        "authors": [
            "Yanwu Yang",
            "Chenfei Ye",
            "Guinan Su",
            "Ziyao Zhang",
            "Zhikai Chang",
            "Hairui Chen",
            "Piu Chan",
            "Yue Yu",
            "Ting Ma"
        ],
        "comments": " ",
        "subjects": "Computational Engineering, Finance, and Science (cs.CE)",
        "abstract": "Foundation models pretrained on large-scale datasets via self-supervised learning demonstrate exceptional versatility across various tasks. Due to the heterogeneity and hard-to-collect medical data, this approach is especially beneficial for medical image analysis and neuroscience research, as it streamlines broad downstream tasks without the need for numerous costly annotations. However, there has been limited investigation into brain network foundation models, limiting their adaptability and generalizability for broad neuroscience studies. In this study, we aim to bridge this gap. In particular, (1) we curated a comprehensive dataset by collating images from 30 datasets, which comprises 70,781 samples of 46,686 participants. Moreover, we introduce pseudo-functional connectivity (pFC) to further generates millions of augmented brain networks by randomly dropping certain timepoints of the BOLD signal. (2) We propose the BrainMass framework for brain network self-supervised learning via mask modeling and feature alignment. BrainMass employs Mask-ROI Modeling (MRM) to bolster intra-network dependencies and regional specificity. Furthermore, Latent Representation Alignment (LRA) module is utilized to regularize augmented brain networks of the same participant with similar topological properties to yield similar latent representations by aligning their latent embeddings. Extensive experiments on eight internal tasks and seven external brain disorder diagnosis tasks show BrainMass's superior performance, highlighting its significant generalizability and adaptability. Nonetheless, BrainMass demonstrates powerful few/zero-shot learning abilities and exhibits meaningful interpretation to various diseases, showcasing its potential use for clinical applications.\n    ",
        "primary_category": "cs.CE",
        "categories": [
            "q-bio.NC"
        ],
        "submitted_date": "3 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01435": {
        "title": "Distributed Least-Squares Optimization Solvers with Differential Privacy",
        "authors": [
            "Weijia Liu",
            "Lei Wang",
            "Fanghong Guo",
            "Zhengguang Wu",
            "Hongye Su"
        ],
        "comments": " ",
        "subjects": "Optimization and Control (math.OC)",
        "abstract": "This paper studies the distributed least-squares optimization problem with differential privacy requirement of local cost functions, for which two differentially private distributed solvers are proposed. The first is established on the distributed gradient tracking algorithm, by appropriately perturbing the initial values and parameters that contain the privacy-sensitive data with Gaussian and truncated Laplacian noises, respectively. Rigorous proofs are established to show the achievable trade-off between the ({\\epsilon}, {\\delta})-differential privacy and the computation accuracy. The second solver is established on the combination of the distributed shuffling mechanism and the average consensus algorithm, which enables each agent to obtain a noisy version of parameters characterizing the global gradient. As a result, the least-squares optimization problem can be eventually solved by each agent locally in such a way that any given ({\\epsilon}, {\\delta})-differential privacy requirement can be preserved while the solution may be computed with the accuracy independent of the network size, which makes the latter more suitable for large-scale distributed least-squares problems. Numerical simulations are presented to show the effectiveness of both solvers.\n    ",
        "primary_category": "math.OC",
        "categories": [
            "eess.SY"
        ],
        "submitted_date": "3 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01440": {
        "title": "Pyramid Feature Attention Network for Monocular Depth Prediction",
        "authors": [
            "Yifang Xu",
            "Chenglei Peng",
            "Ming Li",
            "Yang Li",
            "Sidan Du"
        ],
        "comments": "6 pages, 5 figures",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Deep convolutional neural networks (DCNNs) have achieved great success in monocular depth estimation (MDE). However, few existing works take the contributions for MDE of different levels feature maps into account, leading to inaccurate spatial layout, ambiguous boundaries and discontinuous object surface in the prediction. To better tackle these problems, we propose a Pyramid Feature Attention Network (PFANet) to improve the high-level context features and low-level spatial features. In the proposed PFANet, we design a Dual-scale Channel Attention Module (DCAM) to employ channel attention in different scales, which aggregate global context and local information from the high-level feature maps. To exploit the spatial relationship of visual features, we design a Spatial Pyramid Attention Module (SPAM) which can guide the network attention to multi-scale detailed information in the low-level feature maps. Finally, we introduce scale-invariant gradient loss to increase the penalty on errors in depth-wise discontinuous regions. Experimental results show that our method outperforms state-of-the-art methods on the KITTI dataset.\n    ",
        "primary_category": "cs.CV",
        "categories": [],
        "submitted_date": "3 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01442": {
        "title": "Optimistic and pessimistic approaches for cooperative games",
        "authors": [
            "Ata Atay",
            "Christian Trudeau"
        ],
        "comments": " ",
        "subjects": "Theoretical Economics (econ.TH)",
        "abstract": "Cooperative game theory aims to study how to divide a joint value created by a set of players. These games are often studied through the characteristic function form with transferable utility, which represents the value obtainable by each coalition. In the presence of externalities, there are many ways to define this value. Various models that account for different levels of player cooperation and the influence of external players on coalition value have been studied. Although there are different approaches, typically, the optimistic and pessimistic approaches provide sufficient insights into strategic interactions. This paper clarifies the interpretation of these approaches by providing a unified framework. We show that making sure that no coalition receives more than their (optimistic) upper bounds is always at least as difficult as guaranteeing their (pessimistic) lower bounds. We also show that if externalities are negative, providing these guarantees is always feasible. Then, we explore applications and show how our findings can be applied to derive results from the existing literature.\n    ",
        "primary_category": "econ.TH",
        "categories": [
            "cs.GT"
        ],
        "submitted_date": "3 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01446": {
        "title": "GuardT2I: Defending Text-to-Image Models from Adversarial Prompts",
        "authors": [
            "Yijun Yang",
            "Ruiyuan Gao",
            "Xiao Yang",
            "Jianyuan Zhong",
            "Qiang Xu"
        ],
        "comments": " ",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Recent advancements in Text-to-Image (T2I) models have raised significant safety concerns about their potential misuse for generating inappropriate or Not-Safe-For-Work (NSFW) contents, despite existing countermeasures such as NSFW classifiers or model fine-tuning for inappropriate concept removal. Addressing this challenge, our study unveils GuardT2I, a novel moderation framework that adopts a generative approach to enhance T2I models' robustness against adversarial prompts. Instead of making a binary classification, GuardT2I utilizes a Large Language Model (LLM) to conditionally transform text guidance embeddings within the T2I models into natural language for effective adversarial prompt detection, without compromising the models' inherent performance. Our extensive experiments reveal that GuardT2I outperforms leading commercial solutions like OpenAI-Moderation and Microsoft Azure Moderator by a significant margin across diverse adversarial scenarios.\n    ",
        "primary_category": "cs.CV",
        "categories": [],
        "submitted_date": "3 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01451": {
        "title": "Enhancing Data Provenance and Model Transparency in Federated Learning Systems -- A Database Approach",
        "authors": [
            "Michael Gu",
            "Ramasoumya Naraparaju",
            "Dongfang Zhao"
        ],
        "comments": "14 pages, 16 figures",
        "subjects": "Cryptography and Security (cs.CR)",
        "abstract": "Federated Learning (FL) presents a promising paradigm for training machine learning models across decentralized edge devices while preserving data privacy. Ensuring the integrity and traceability of data across these distributed environments, however, remains a critical challenge. The ability to create transparent artificial intelligence, such as detailing the training process of a machine learning model, has become an increasingly prominent concern due to the large number of sensitive (hyper)parameters it utilizes; thus, it is imperative to strike a reasonable balance between openness and the need to protect sensitive information.\nIn this paper, we propose one of the first approaches to enhance data provenance and model transparency in federated learning systems. Our methodology leverages a combination of cryptographic techniques and efficient model management to track the transformation of data throughout the FL process, and seeks to increase the reproducibility and trustworthiness of a trained FL model. We demonstrate the effectiveness of our approach through experimental evaluations on diverse FL scenarios, showcasing its ability to tackle accountability and explainability across the board.\nOur findings show that our system can greatly enhance data transparency in various FL environments by storing chained cryptographic hashes and client model snapshots in our proposed design for data decoupled FL. This is made possible by also employing multiple optimization techniques which enables comprehensive data provenance without imposing substantial computational loads. Extensive experimental results suggest that integrating a database subsystem into federated learning systems can improve data provenance in an efficient manner, encouraging secure FL adoption in privacy-sensitive applications and paving the way for future advancements in FL transparency and security features.\n    ",
        "primary_category": "cs.CR",
        "categories": [
            "cs.DB",
            "cs.LG"
        ],
        "submitted_date": "3 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01454": {
        "title": "Maximum Length RLL Sequences in de Bruijn Graph",
        "authors": [
            "Yeow Meng Chee",
            "Tuvi Etzion",
            "Tien Long Nguyen",
            "Duy Hoang Ta",
            "Vinh Duc Tran",
            "Van Khu Vu"
        ],
        "comments": " ",
        "subjects": "Information Theory (cs.IT)",
        "abstract": "A timing and synchronization system based on a de Bruijn sequence has been proposed and studied recently for a channel associated with quantum communication that requires reliable synchronization. To avoid a long period of no-pulse in such a system on-off pulses are used to simulate a zero and on-on pulses are used to simulate a one. However, these sequences have high redundancy. To reduce the redundancy, run-length limited sequences in the de Bruijn graph are proposed for the same purpose. The maximum length of such sequences in the de Bruijn graph is studied and an efficient algorithm to construct a large set of these sequences is presented. A maximum length sequence for which the position of each window can be computed efficiently is constructed. Finally, an enumeration of the number of such sequences is given and some generalizations are discussed.\n    ",
        "primary_category": "cs.IT",
        "categories": [],
        "submitted_date": "3 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01456": {
        "title": "Controlling Cloze-test Question Item Difficulty with PLM-based Surrogate Models for IRT Assessment",
        "authors": [
            "Jingshen Zhang",
            "Jiajun Xie",
            "Xinying Qiu"
        ],
        "comments": " ",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "Item difficulty plays a crucial role in adaptive testing. However, few works have focused on generating questions of varying difficulty levels, especially for multiple-choice (MC) cloze tests. We propose training pre-trained language models (PLMs) as surrogate models to enable item response theory (IRT) assessment, avoiding the need for human test subjects. We also propose two strategies to control the difficulty levels of both the gaps and the distractors using ranking rules to reduce invalid distractors. Experimentation on a benchmark dataset demonstrates that our proposed framework and methods can effectively control and evaluate the difficulty levels of MC cloze tests.\n    ",
        "primary_category": "cs.CL",
        "categories": [
            "cs.AI",
            "cs.CY"
        ],
        "submitted_date": "3 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01457": {
        "title": "Logic Rules as Explanations for Legal Case Retrieval",
        "authors": [
            "Zhongxiang Sun",
            "Kepu Zhang",
            "Weijie Yu",
            "Haoyu Wang",
            "Jun Xu"
        ],
        "comments": "accepted by lrec-coling 2024",
        "subjects": "Information Retrieval (cs.IR)",
        "abstract": "In this paper, we address the issue of using logic rules to explain the results from legal case retrieval. The task is critical to legal case retrieval because the users (e.g., lawyers or judges) are highly specialized and require the system to provide logical, faithful, and interpretable explanations before making legal decisions. Recently, research efforts have been made to learn explainable legal case retrieval models. However, these methods usually select rationales (key sentences) from the legal cases as explanations, failing to provide faithful and logically correct explanations. In this paper, we propose Neural-Symbolic enhanced Legal Case Retrieval (NS-LCR), a framework that explicitly conducts reasoning on the matching of legal cases through learning case-level and law-level logic rules. The learned rules are then integrated into the retrieval process in a neuro-symbolic manner. Benefiting from the logic and interpretable nature of the logic rules, NS-LCR is equipped with built-in faithful explainability. We also show that NS-LCR is a model-agnostic framework that can be plugged in for multiple legal retrieval models. To showcase NS-LCR's superiority, we enhance existing benchmarks by adding manually annotated logic rules and introducing a novel explainability metric using Large Language Models (LLMs). Our comprehensive experiments reveal NS-LCR's effectiveness for ranking, alongside its proficiency in delivering reliable explanations for legal case retrieval.\n    ",
        "primary_category": "cs.IR",
        "categories": [
            "cs.CL"
        ],
        "submitted_date": "3 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01460": {
        "title": "One-Step Multi-View Clustering Based on Transition Probability",
        "authors": [
            "Wenhui Zhao",
            "Quanxue Gao",
            "Guangfei Li",
            "Cheng Deng",
            "Ming Yang"
        ],
        "comments": "8 pages",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "The large-scale multi-view clustering algorithms, based on the anchor graph, have shown promising performance and efficiency and have been extensively explored in recent years. Despite their successes, current methods lack interpretability in the clustering process and do not sufficiently consider the complementary information across different views. To address these shortcomings, we introduce the One-Step Multi-View Clustering Based on Transition Probability (OSMVC-TP). This method adopts a probabilistic approach, which leverages the anchor graph, representing the transition probabilities from samples to anchor points. Our method directly learns the transition probabilities from anchor points to categories, and calculates the transition probabilities from samples to categories, thus obtaining soft label matrices for samples and anchor points, enhancing the interpretability of clustering. Furthermore, to maintain consistency in labels across different views, we apply a Schatten p-norm constraint on the tensor composed of the soft labels. This approach effectively harnesses the complementary information among the views. Extensive experiments have confirmed the effectiveness and robustness of OSMVC-TP.\n    ",
        "primary_category": "cs.LG",
        "categories": [],
        "submitted_date": "3 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01461": {
        "title": "Answerability in Retrieval-Augmented Open-Domain Question Answering",
        "authors": [
            "Rustam Abdumalikov",
            "Pasquale Minervini",
            "Yova Kementchedjhieva"
        ],
        "comments": "5 pages, 3 tables",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "The performance of Open-Domain Question Answering (ODQA) retrieval systems can exhibit sub-optimal behavior, providing text excerpts with varying degrees of irrelevance. Unfortunately, many existing ODQA datasets lack examples specifically targeting the identification of irrelevant text excerpts. Previous attempts to address this gap have relied on a simplistic approach of pairing questions with random text excerpts. This paper aims to investigate the effectiveness of models trained using this randomized strategy, uncovering an important limitation in their ability to generalize to irrelevant text excerpts with high semantic overlap. As a result, we observed a substantial decrease in predictive accuracy, from 98% to 1%. To address this limitation, we discovered an efficient approach for training models to recognize such excerpts. By leveraging unanswerable pairs from the SQuAD 2.0 dataset, our models achieve a nearly perfect (~100%) accuracy when confronted with these challenging text excerpts.\n    ",
        "primary_category": "cs.CL",
        "categories": [],
        "submitted_date": "3 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01463": {
        "title": "An Authentic Algorithm for Ciphering and Deciphering Called Latin Djokovic",
        "authors": [
            "Diogen Babuc"
        ],
        "comments": "Five pages",
        "subjects": "Computational Engineering, Finance, and Science (cs.CE)",
        "abstract": "The question that is a motivation of writing is how many devote themselves to discovering something in the world of science where much is discerned and revealed, but at the same time, much is unknown. The insightful elements of this algorithm are the ciphering and deciphering algorithms of Playfair, Caesar, and Vigenere. Only a few of their main properties are taken and modified, with the aim of forming a specific functionality of the algorithm called Latin Djokovic. Specifically, a string is entered as input data. A key k is given, with a random value between the values a and b = a + 3. The obtained value is stored in a variable with the aim of being constant during the run of the algorithm. In correlation to the given key, the string is divided into several groups of substrings, and each substring has a length of k characters. The next step involves encoding each substring from the list of existing substrings. Encoding is performed using the basis of the Caesar algorithm, i.e., shifting with k characters. However, that k is incremented by 1 when moving to the next substring in that list. When the value of k becomes greater than b + 1, it will return to its initial value. The algorithm is executed, following the same procedure, until the last substring in the list is traversed. Using this polyalphabetic method, ciphering and deciphering of strings are achieved. The algorithm also works for a 100-character string. The x character is not used when the number of characters in a substring is incompatible with the expected length. The algorithm is simple to implement, but it is questionable if it works better than the other methods from the point of view of execution time and storage space.\n    ",
        "primary_category": "cs.CE",
        "categories": [],
        "submitted_date": "3 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01465": {
        "title": "Multiview Subspace Clustering of Hyperspectral Images based on Graph Convolutional Networks",
        "authors": [
            "Xianju Li",
            "Renxiang Guan",
            "Zihao Li",
            "Hao Liu",
            "Jing Yang"
        ],
        "comments": "This paper was accepted by APWEB-WAIM 2024",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "High-dimensional and complex spectral structures make clustering of hy-perspectral images (HSI) a challenging task. Subspace clustering has been shown to be an effective approach for addressing this problem. However, current subspace clustering algorithms are mainly designed for a single view and do not fully exploit spatial or texture feature information in HSI. This study proposed a multiview subspace clustering of HSI based on graph convolutional networks. (1) This paper uses the powerful classification ability of graph convolutional network and the learning ability of topologi-cal relationships between nodes to analyze and express the spatial relation-ship of HSI. (2) Pixel texture and pixel neighbor spatial-spectral infor-mation were sent to construct two graph convolutional subspaces. (3) An attention-based fusion module was used to adaptively construct a more discriminative feature map. The model was evaluated on three popular HSI datasets, including Indian Pines, Pavia University, and Houston. It achieved overall accuracies of 92.38%, 93.43%, and 83.82%, respectively and significantly outperformed the state-of-the-art clustering methods. In conclusion, the proposed model can effectively improve the clustering ac-curacy of HSI.\n    ",
        "primary_category": "cs.CV",
        "categories": [],
        "submitted_date": "3 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01467": {
        "title": "Collaborate to Adapt: Source-Free Graph Domain Adaptation via Bi-directional Adaptation",
        "authors": [
            "Zhen Zhang",
            "Meihan Liu",
            "Anhui Wang",
            "Hongyang Chen",
            "Zhao Li",
            "Jiajun Bu",
            "Bingsheng He"
        ],
        "comments": "Accepted by WWW-2024",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Unsupervised Graph Domain Adaptation (UGDA) has emerged as a practical solution to transfer knowledge from a label-rich source graph to a completely unlabelled target graph. However, most methods require a labelled source graph to provide supervision signals, which might not be accessible in the real-world settings due to regulations and privacy concerns. In this paper, we explore the scenario of source-free unsupervised graph domain adaptation, which tries to address the domain adaptation problem without accessing the labelled source graph. Specifically, we present a novel paradigm called GraphCTA, which performs model adaptation and graph adaptation collaboratively through a series of procedures: (1) conduct model adaptation based on node's neighborhood predictions in target graph considering both local and global information; (2) perform graph adaptation by updating graph structure and node attributes via neighborhood contrastive learning; and (3) the updated graph serves as an input to facilitate the subsequent iteration of model adaptation, thereby establishing a collaborative loop between model adaptation and graph adaptation. Comprehensive experiments are conducted on various public datasets. The experimental results demonstrate that our proposed model outperforms recent source-free baselines by large margins.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "3 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01470": {
        "title": "Is in-domain data beneficial in transfer learning for landmarks detection in x-ray images?",
        "authors": [
            "Roberto Di Via",
            "Matteo Santacesaria",
            "Francesca Odone",
            "Vito Paolo Pastore"
        ],
        "comments": "Accepted to ISBI 2024",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "In recent years, deep learning has emerged as a promising technique for medical image analysis. However, this application domain is likely to suffer from a limited availability of large public datasets and annotations. A common solution to these challenges in deep learning is the usage of a transfer learning framework, typically with a fine-tuning protocol, where a large-scale source dataset is used to pre-train a model, further fine-tuned on the target dataset. In this paper, we present a systematic study analyzing whether the usage of small-scale in-domain x-ray image datasets may provide any improvement for landmark detection over models pre-trained on large natural image datasets only. We focus on the multi-landmark localization task for three datasets, including chest, head, and hand x-ray images. Our results show that using in-domain source datasets brings marginal or no benefit with respect to an ImageNet out-of-domain pre-training. Our findings can provide an indication for the development of robust landmark detection systems in medical images when no large annotated dataset is available.\n    ",
        "primary_category": "cs.CV",
        "categories": [],
        "submitted_date": "3 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01471": {
        "title": "Preserving correlations: A statistical method for generating synthetic data",
        "authors": [
            "Nicklas J\u00e4verg\u00e5rd",
            "Rainey Lyons",
            "Adrian Muntean",
            "Jonas Forsman"
        ],
        "comments": " ",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "We propose a method to generate statistically representative synthetic data. The main goal is to be able to maintain in the synthetic dataset the correlations of the features present in the original one, while offering a comfortable privacy level that can be eventually tailored on specific customer demands.\nWe describe in detail our algorithm used both for the analysis of the original dataset and for the generation of the synthetic data points. The approach is tested using a large energy-related dataset. We obtain good results both qualitatively (e.g. via vizualizing correlation maps) and quantitatively (in terms of suitable $\\ell^1$-type error norms used as evaluation metrics).\nThe proposed methodology is general in the sense that it does not rely on the used test dataset. We expect it to be applicable in a much broader context than indicated here.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "math.PR",
            "physics.data-an"
        ],
        "submitted_date": "3 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01472": {
        "title": "WARDEN: Multi-Directional Backdoor Watermarks for Embedding-as-a-Service Copyright Protection",
        "authors": [
            "Anudeex Shetty",
            "Yue Teng",
            "Ke He",
            "Qiongkai Xu"
        ],
        "comments": "Work in Progress",
        "subjects": "Cryptography and Security (cs.CR)",
        "abstract": "Embedding as a Service (EaaS) has become a widely adopted solution, which offers feature extraction capabilities for addressing various downstream tasks in Natural Language Processing (NLP). Prior studies have shown that EaaS can be prone to model extraction attacks; nevertheless, this concern could be mitigated by adding backdoor watermarks to the text embeddings and subsequently verifying the attack models post-publication. Through the analysis of the recent watermarking strategy for EaaS, EmbMarker, we design a novel CSE (Clustering, Selection, Elimination) attack that removes the backdoor watermark while maintaining the high utility of embeddings, indicating that the previous watermarking approach can be breached. In response to this new threat, we propose a new protocol to make the removal of watermarks more challenging by incorporating multiple possible watermark directions. Our defense approach, WARDEN, notably increases the stealthiness of watermarks and empirically has been shown effective against CSE attack.\n    ",
        "primary_category": "cs.CR",
        "categories": [
            "cs.CL",
            "cs.LG"
        ],
        "submitted_date": "3 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01475": {
        "title": "Representation Learning on Heterophilic Graph with Directional Neighborhood Attention",
        "authors": [
            "Qincheng Lu",
            "Jiaqi Zhu",
            "Sitao Luan",
            "Xiao-Wen Chang"
        ],
        "comments": " ",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Graph Attention Network (GAT) is one of the most popular Graph Neural Network (GNN) architecture, which employs the attention mechanism to learn edge weights and has demonstrated promising performance in various applications. However, since it only incorporates information from immediate neighborhood, it lacks the ability to capture long-range and global graph information, leading to unsatisfactory performance on some datasets, particularly on heterophilic graphs. To address this limitation, we propose the Directional Graph Attention Network (DGAT) in this paper. DGAT is able to combine the feature-based attention with the global directional information extracted from the graph topology. To this end, a new class of Laplacian matrices is proposed which can provably reduce the diffusion distance between nodes. Based on the new Laplacian, topology-guided neighbour pruning and edge adding mechanisms are proposed to remove the noisy and capture the helpful long-range neighborhood information. Besides, a global directional attention is designed to enable a topological-aware information propagation. The superiority of the proposed DGAT over the baseline GAT has also been verified through experiments on real-world benchmarks and synthetic data sets. It also outperforms the state-of-the-art (SOTA) models on 6 out of 7 real-world benchmark datasets.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.AI",
            "cs.SI"
        ],
        "submitted_date": "3 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01476": {
        "title": "CCC: Color Classified Colorization",
        "authors": [
            "Mrityunjoy Gain",
            "Avi Deb Raha",
            "Rameswar Debnath"
        ],
        "comments": " ",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Automatic colorization of gray images with objects of different colors and sizes is challenging due to inter- and intra-object color variation and the small area of the main objects due to extensive backgrounds. The learning process often favors dominant features, resulting in a biased model. In this paper, we formulate the colorization problem into a multinomial classification problem and then apply a weighted function to classes. We propose a set of formulas to transform color values into color classes and vice versa. Class optimization and balancing feature distribution are the keys for good performance. Observing class appearance on various extremely large-scale real-time images in practice, we propose 215 color classes for our colorization task. During training, we propose a class-weighted function based on true class appearance in each batch to ensure proper color saturation of individual objects. We establish a trade-off between major and minor classes to provide orthodox class prediction by eliminating major classes' dominance over minor classes. As we apply regularization to enhance the stability of the minor class, occasional minor noise may appear at the object's edges. We propose a novel object-selective color harmonization method empowered by the SAM to refine and enhance these edges. We propose a new color image evaluation metric, the Chromatic Number Ratio (CNR), to quantify the richness of color components. We compare our proposed model with state-of-the-art models using five different datasets: ADE, Celeba, COCO, Oxford 102 Flower, and ImageNet, in both qualitative and quantitative approaches. The experimental results show that our proposed model outstrips other models in visualization and CNR measurement criteria while maintaining satisfactory performance in regression (MSE, PSNR), similarity (SSIM, LPIPS, UIQI), and generative criteria (FID).\n    ",
        "primary_category": "cs.CV",
        "categories": [],
        "submitted_date": "3 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01478": {
        "title": "Distributed Discrete-time Dynamic Outer Approximation of the Intersection of Ellipsoids",
        "authors": [
            "Eduardo Sebasti\u00e1n",
            "Rodrigo Aldana-L\u00f3pez",
            "Rosario Arag\u00fc\u00e9s",
            "Eduardo Montijano",
            "Carlos Sag\u00fc\u00e9s"
        ],
        "comments": "This work is currently under review",
        "subjects": "Optimization and Control (math.OC)",
        "abstract": "This paper presents the first discrete-time distributed algorithm to track the tightest ellipsoids that outer approximates the global dynamic intersection of ellipsoids. The ellipsoids are defined as time-varying positive definite matrices. On the other hand, given an undirected network, each node is equipped with one of these ellipsoids. The solution is based on a novel distributed reformulation of the original centralized semi-definite outer L\u00f6wner-John program, characterized by a non-separable objective function and global constraints. We prove finite-time convergence to the global minima of the centralized problem in the static case and finite-time bounded tracking error in the dynamic case. Moreover, we prove boundedness of estimation in the tracking of the global optimum and robustness in the estimation against time-varying inputs. As a by-product, the proposed algorithm extends min/max dynamic consensus algorithms to positive definite matrices. We illustrate the properties of the algorithm with different simulated examples, including a distributed estimation showcase where our proposal is integrated into a distributed Kalman filter to surpass the state-of-the-art in mean square error performance.\n    ",
        "primary_category": "math.OC",
        "categories": [
            "eess.SY"
        ],
        "submitted_date": "3 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01480": {
        "title": "Deep Learning-based Design of Uplink Integrated Sensing and Communication",
        "authors": [
            "Qiao Qi",
            "Xiaoming Chen",
            "Caijun Zhong",
            "Chau Yuen",
            "Zhaoyang Zhang"
        ],
        "comments": "IEEE Transactions on Wireless Communications, 2024",
        "subjects": "Information Theory (cs.IT)",
        "abstract": "In this paper, we investigate the issue of uplink integrated sensing and communication (ISAC) in 6G wireless networks where the sensing echo signal and the communication signal are received simultaneously at the base station (BS). To effectively mitigate the mutual interference between sensing and communication caused by the sharing of spectrum and hardware resources, we provide a joint sensing transmit waveform and communication receive beamforming design with the objective of maximizing the weighted sum of normalized sensing rate and normalized communication rate. It is formulated as a computationally complicated non-convex optimization problem, which is quite difficult to be solved by conventional optimization methods. To this end, we first make a series of equivalent transformation on the optimization problem to reduce the design complexity, and then develop a deep learning (DL)-based scheme to enhance the overall performance of ISAC. Both theoretical analysis and simulation results confirm the effectiveness and robustness of the proposed DL-based scheme for ISAC in 6G wireless networks.\n    ",
        "primary_category": "cs.IT",
        "categories": [
            "eess.SP"
        ],
        "submitted_date": "3 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01481": {
        "title": "Infusing Knowledge into Large Language Models with Contextual Prompts",
        "authors": [
            "Kinshuk Vasisht",
            "Balaji Ganesan",
            "Vikas Kumar",
            "Vasudha Bhatnagar"
        ],
        "comments": "5 pages, 1 figure, In Proceedings of ICON 2023",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "Knowledge infusion is a promising method for enhancing Large Language Models for domain-specific NLP tasks rather than pre-training models over large data from scratch. These augmented LLMs typically depend on additional pre-training or knowledge prompts from an existing knowledge graph, which is impractical in many applications. In contrast, knowledge infusion directly from relevant documents is more generalisable and alleviates the need for structured knowledge graphs while also being useful for entities that are usually not found in any knowledge graph. With this motivation, we propose a simple yet generalisable approach for knowledge infusion by generating prompts from the context in the input text. Our experiments show the effectiveness of our approach which we evaluate by probing the fine-tuned LLMs.\n    ",
        "primary_category": "cs.CL",
        "categories": [],
        "submitted_date": "3 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01483": {
        "title": "BronchoCopilot: Towards Autonomous Robotic Bronchoscopy via Multimodal Reinforcement Learning",
        "authors": [
            "Jianbo Zhao",
            "Hao Chen",
            "Qingyao Tian",
            "Jian Chen",
            "Bingyu Yang",
            "Hongbin Liu"
        ],
        "comments": " ",
        "subjects": "Robotics (cs.RO)",
        "abstract": "Bronchoscopy plays a significant role in the early diagnosis and treatment of lung diseases. This process demands physicians to maneuver the flexible endoscope for reaching distal lesions, particularly requiring substantial expertise when examining the airways of the upper lung lobe. With the development of artificial intelligence and robotics, reinforcement learning (RL) method has been applied to the manipulation of interventional surgical robots. However, unlike human physicians who utilize multimodal information, most of the current RL methods rely on a single modality, limiting their performance. In this paper, we propose BronchoCopilot, a multimodal RL agent designed to acquire manipulation skills for autonomous bronchoscopy. BronchoCopilot specifically integrates images from the bronchoscope camera and estimated robot poses, aiming for a higher success rate within challenging airway environment. We employ auxiliary reconstruction tasks to compress multimodal data and utilize attention mechanisms to achieve an efficient latent representation of this data, serving as input for the RL module. This framework adopts a stepwise training and fine-tuning approach to mitigate the challenges of training difficulty. Our evaluation in the realistic simulation environment reveals that BronchoCopilot, by effectively harnessing multimodal information, attains a success rate of approximately 90\\% in fifth generation airways with consistent movements. Additionally, it demonstrates a robust capacity to adapt to diverse cases.\n    ",
        "primary_category": "cs.RO",
        "categories": [],
        "submitted_date": "3 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01485": {
        "title": "Approximations to the Fisher Information Metric of Deep Generative Models for Out-Of-Distribution Detection",
        "authors": [
            "Sam Dauncey",
            "Chris Holmes",
            "Christopher Williams",
            "Fabian Falck"
        ],
        "comments": " ",
        "subjects": "Machine Learning (stat.ML)",
        "abstract": "Likelihood-based deep generative models such as score-based diffusion models and variational autoencoders are state-of-the-art machine learning models approximating high-dimensional distributions of data such as images, text, or audio. One of many downstream tasks they can be naturally applied to is out-of-distribution (OOD) detection. However, seminal work by Nalisnick et al. which we reproduce showed that deep generative models consistently infer higher log-likelihoods for OOD data than data they were trained on, marking an open problem. In this work, we analyse using the gradient of a data point with respect to the parameters of the deep generative model for OOD detection, based on the simple intuition that OOD data should have larger gradient norms than training data. We formalise measuring the size of the gradient as approximating the Fisher information metric. We show that the Fisher information matrix (FIM) has large absolute diagonal values, motivating the use of chi-square distributed, layer-wise gradient norms as features. We combine these features to make a simple, model-agnostic and hyperparameter-free method for OOD detection which estimates the joint density of the layer-wise gradient norms for a given data point. We find that these layer-wise gradient norms are weakly correlated, rendering their combined usage informative, and prove that the layer-wise gradient norms satisfy the principle of (data representation) invariance. Our empirical results indicate that this method outperforms the Typicality test for most deep generative models and image dataset pairings.\n    ",
        "primary_category": "stat.ML",
        "categories": [
            "cs.CV",
            "cs.LG"
        ],
        "submitted_date": "3 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01486": {
        "title": "An RBF partition of unity method for geometry reconstruction and PDE solution in thin structures",
        "authors": [
            "Elisabeth Larsson",
            "Pierre-Fr\u00e9d\u00e9ric Villard",
            "Igor Tominec",
            "Ulrika Sundin",
            "Andreas Michael",
            "Nicola Cacciani"
        ],
        "comments": "25 pages, 15 figures, preprint",
        "subjects": "Numerical Analysis (math.NA)",
        "abstract": "The main respiratory muscle, the diaphragm, is an example of a thin structure. We aim to perform detailed numerical simulations of the muscle mechanics based on individual patient data. This requires a representation of the diaphragm geometry extracted from medical image data. We design an adaptive reconstruction method based on a least-squares radial basis function partition of unity method. The method is adapted to thin structures by subdividing the structure rather than the surrounding space, and by introducing an anisotropic scaling of local subproblems. The resulting representation is an infinitely smooth level set function, which is stabilized such that there are no spurious zero level sets. We show reconstruction results for 2D cross sections of the diaphragm geometry as well as for the full 3D geometry. We also show solutions to basic PDE test problems in the reconstructed geometries.\n    ",
        "primary_category": "math.NA",
        "categories": [],
        "submitted_date": "3 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01487": {
        "title": "InfiMM-HD: A Leap Forward in High-Resolution Multimodal Understanding",
        "authors": [
            "Haogeng Liu",
            "Quanzeng You",
            "Xiaotian Han",
            "Yiqi Wang",
            "Bohan Zhai",
            "Yongfei Liu",
            "Yunzhe Tao",
            "Huaibo Huang",
            "Ran He",
            "Hongxia Yang"
        ],
        "comments": " ",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Multimodal Large Language Models (MLLMs) have experienced significant advancements recently. Nevertheless, challenges persist in the accurate recognition and comprehension of intricate details within high-resolution images. Despite being indispensable for the development of robust MLLMs, this area remains underinvestigated. To tackle this challenge, our work introduces InfiMM-HD, a novel architecture specifically designed for processing images of different resolutions with low computational overhead. This innovation facilitates the enlargement of MLLMs to higher-resolution capabilities. InfiMM-HD incorporates a cross-attention module and visual windows to reduce computation costs. By integrating this architectural design with a four-stage training pipeline, our model attains improved visual perception efficiently and cost-effectively. Empirical study underscores the robustness and effectiveness of InfiMM-HD, opening new avenues for exploration in related areas. Codes and models can be found at this https URL\n",
        "primary_category": "cs.CV",
        "categories": [],
        "submitted_date": "3 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01489": {
        "title": "Regeneration Based Training-free Attribution of Fake Images Generated by Text-to-Image Generative Models",
        "authors": [
            "Meiling Li",
            "Zhenxing Qian",
            "Xinpeng Zhang"
        ],
        "comments": " ",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Text-to-image generative models have recently garnered significant attention due to their ability to generate images based on prompt descriptions. While these models have shown promising performance, concerns have been raised regarding the potential misuse of the generated fake images. In response to this, we have presented a simple yet effective training-free method to attribute fake images generated by text-to-image models to their source models. Given a test image to be attributed, we first inverse the textual prompt of the image, and then put the reconstructed prompt into different candidate models to regenerate candidate fake images. By calculating and ranking the similarity of the test image and the candidate images, we can determine the source of the image. This attribution allows model owners to be held accountable for any misuse of their models. Note that our approach does not limit the number of candidate text-to-image generative models. Comprehensive experiments reveal that (1) Our method can effectively attribute fake images to their source models, achieving comparable attribution performance with the state-of-the-art method; (2) Our method has high scalability ability, which is well adapted to real-world attribution scenarios. (3) The proposed method yields satisfactory robustness to common attacks, such as Gaussian blurring, JPEG compression, and Resizing. We also analyze the factors that influence the attribution performance, and explore the boost brought by the proposed method as a plug-in to improve the performance of existing SOTA. We hope our work can shed some light on the solutions to addressing the source of AI-generated images, as well as to prevent the misuse of text-to-image generative models.\n    ",
        "primary_category": "cs.CV",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "3 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01493": {
        "title": "ConvTimeNet: A Deep Hierarchical Fully Convolutional Model for Multivariate Time Series Analysis",
        "authors": [
            "Mingyue Cheng",
            "Jiqian Yang",
            "Tingyue Pan",
            "Qi Liu",
            "Zhi Li"
        ],
        "comments": " ",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "This paper introduces ConvTimeNet, a novel deep hierarchical fully convolutional network designed to serve as a general-purpose model for time series analysis. The key design of this network is twofold, designed to overcome the limitations of traditional convolutional networks. Firstly, we propose an adaptive segmentation of time series into sub-series level patches, treating these as fundamental modeling units. This setting avoids the sparsity semantics associated with raw point-level time steps. Secondly, we design a fully convolutional block by skillfully integrating deepwise and pointwise convolution operations, following the advanced building block style employed in Transformer encoders. This backbone network allows for the effective capture of both global sequence and cross-variable dependence, as it not only incorporates the advancements of Transformer architecture but also inherits the inherent properties of convolution. Furthermore, multi-scale representations of given time series instances can be learned by controlling the kernel size flexibly. Extensive experiments are conducted on both time series forecasting and classification tasks. The results consistently outperformed strong baselines in most situations in terms of effectiveness.The code is publicly available.\n    ",
        "primary_category": "cs.LG",
        "categories": [],
        "submitted_date": "3 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01496": {
        "title": "A face-centred finite volume method for laminar and turbulent incompressible flows",
        "authors": [
            "Luan M. Vieira",
            "Matteo Giacomini",
            "Ruben Sevilla",
            "Antonio Huerta"
        ],
        "comments": "38 pages, 23 figures, 3 tables",
        "subjects": "Fluid Dynamics (physics.flu-dyn)",
        "abstract": "This work develops, for the first time, a face-centred finite volume (FCFV) solver for the simulation of laminar and turbulent viscous incompressible flows. The formulation relies on the Reynolds-averaged Navier-Stokes (RANS) equations coupled with the negative Spalart-Allmaras (SA) model and three novel convective stabilisations, inspired by Riemann solvers, are derived and compared numerically. The resulting method achieves first-order convergence of the velocity, the velocity-gradient tensor and the pressure. FCFV accurately predicts engineering quantities of interest, such as drag and lift, on unstructured meshes and, by avoiding gradient reconstruction, the method is insensitive to mesh quality, even in the presence of highly distorted and stretched cells. A monolithic and a staggered solution strategies for the RANS-SA system are derived and compared numerically. Numerical benchmarks, involving laminar and turbulent, steady and transient cases are used to assess the performance, accuracy and robustness of the proposed FCFV method.\n    ",
        "primary_category": "physics.flu-dyn",
        "categories": [
            "cs.CE",
            "math.NA"
        ],
        "submitted_date": "3 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01499": {
        "title": "Normalising Flow-based Differentiable Particle Filters",
        "authors": [
            "Xiongjie Chen",
            "Yunpeng Li"
        ],
        "comments": "18 pages, 5 figures, submitted to IEEE Transactions on Signal Processing",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Recently, there has been a surge of interest in incorporating neural networks into particle filters, e.g. differentiable particle filters, to perform joint sequential state estimation and model learning for non-linear non-Gaussian state-space models in complex environments. Existing differentiable particle filters are mostly constructed with vanilla neural networks that do not allow density estimation. As a result, they are either restricted to a bootstrap particle filtering framework or employ predefined distribution families (e.g. Gaussian distributions), limiting their performance in more complex real-world scenarios. In this paper we present a differentiable particle filtering framework that uses (conditional) normalising flows to build its dynamic model, proposal distribution, and measurement model. This not only enables valid probability densities but also allows the proposed method to adaptively learn these modules in a flexible way, without being restricted to predefined distribution families. We derive the theoretical properties of the proposed filters and evaluate the proposed normalising flow-based differentiable particle filters' performance through a series of numerical experiments.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "eess.SP"
        ],
        "submitted_date": "3 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01501": {
        "title": "Applying Self-supervised Learning to Network Intrusion Detection for Network Flows with Graph Neural Network",
        "authors": [
            "Renjie Xu",
            "Guangwei Wu",
            "Weiping Wang",
            "Xing Gao",
            "An He",
            "Zhengpeng Zhang"
        ],
        "comments": "15pages,8figures",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Graph Neural Networks (GNNs) have garnered intensive attention for Network Intrusion Detection System (NIDS) due to their suitability for representing the network traffic flows. However, most present GNN-based methods for NIDS are supervised or semi-supervised. Network flows need to be manually annotated as supervisory labels, a process that is time-consuming or even impossible, making NIDS difficult to adapt to potentially complex attacks, especially in large-scale real-world scenarios. The existing GNN-based self-supervised methods focus on the binary classification of network flow as benign or not, and thus fail to reveal the types of attack in practice. This paper studies the application of GNNs to identify the specific types of network flows in an unsupervised manner. We first design an encoder to obtain graph embedding, that introduces the graph attention mechanism and considers the edge information as the only essential factor. Then, a self-supervised method based on graph contrastive learning is proposed. The method samples center nodes, and for each center node, generates subgraph by it and its direct neighbor nodes, and corresponding contrastive subgraph from the interpolated graph, and finally constructs positive and negative samples from subgraphs. Furthermore, a structured contrastive loss function based on edge features and graph local topology is introduced. To the best of our knowledge, it is the first GNN-based self-supervised method for the multiclass classification of network flows in NIDS. Detailed experiments conducted on four real-world databases (NF-Bot-IoT, NF-Bot-IoT-v2, NF-CSE-CIC-IDS2018, and NF-CSE-CIC-IDS2018-v2) systematically compare our model with the state-of-the-art supervised and self-supervised models, illustrating the considerable potential of our method. Our code is accessible through this https URL.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.CR"
        ],
        "submitted_date": "3 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01506": {
        "title": "A new family of $2$-scattered subspaces and related MRD codes",
        "authors": [
            "Daniele Bartoli",
            "Francesco Ghiandoni",
            "Alessandro Giannoni",
            "Giuseppe Marino"
        ],
        "comments": " ",
        "subjects": "Combinatorics (math.CO)",
        "abstract": "Scattered subspaces and $h$-scattered subspaces have been extensively studied in recent decades for both theoretical purposes and their connections to various applications. While numerous constructions of scattered subspaces exist, relatively few are known about $h$-scattered subspaces with $h\\geq2$. In this paper, we establish the existence of maximum $2$-scattered $\\F_q$-subspaces in $V(r,q^6)$ whenever $r\\geq 3$, $r\\ne 5$, and $q$ is an odd power of $2$. Additionally, we explore the corresponding MRD codes.\n    ",
        "primary_category": "math.CO",
        "categories": [
            "cs.IT"
        ],
        "submitted_date": "3 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01507": {
        "title": "ISSF: The Intelligent Security Service Framework for Cloud-Native Operation",
        "authors": [
            "Yikuan Yan",
            "Keman Huang",
            "Michael Siegel"
        ],
        "comments": "17pages",
        "subjects": "Cryptography and Security (cs.CR)",
        "abstract": "The growing system complexity from microservice architectures and the bilateral enhancement of artificial intelligence (AI) for both attackers and defenders presents increasing security challenges for cloud-native operations. In particular, cloud-native operators require a holistic view of the dynamic security posture for the cloud-native environment from a defense aspect. Additionally, both attackers and defenders can adopt advanced AI technologies. This makes the dynamic interaction and benchmark among different intelligent offense and defense strategies more crucial. Hence, following the multi-agent deep reinforcement learning (RL) paradigm, this research develops an agent-based intelligent security service framework (ISSF) for cloud-native operation. It includes a dynamic access graph model to represent the cloud-native environment and an action model to represent offense and defense actions. Then we develop an approach to enable the training, publishing, and evaluating of intelligent security services using diverse deep RL algorithms and training strategies, facilitating their systematic development and benchmark. The experiments demonstrate that our framework can sufficiently model the security posture of a cloud-native system for defenders, effectively develop and quantitatively benchmark different services for both attackers and defenders and guide further service optimization.\n    ",
        "primary_category": "cs.CR",
        "categories": [],
        "submitted_date": "3 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01508": {
        "title": "Soft Reasoning on Uncertain Knowledge Graphs",
        "authors": [
            "Weizhi Fei",
            "Zihao Wang",
            "Hang Yin",
            "Yang Duan",
            "Hanghang Tong",
            "Yangqiu Song"
        ],
        "comments": "10 pages",
        "subjects": "Artificial Intelligence (cs.AI)",
        "abstract": "The study of machine learning-based logical query-answering enables reasoning with large-scale and incomplete knowledge graphs. This paper further advances this line of research by considering the uncertainty in the knowledge. The uncertain nature of knowledge is widely observed in the real world, but \\textit{does not} align seamlessly with the first-order logic underpinning existing studies. To bridge this gap, we study the setting of soft queries on uncertain knowledge, which is motivated by the establishment of soft constraint programming. We further propose an ML-based approach with both forward inference and backward calibration to answer soft queries on large-scale, incomplete, and uncertain knowledge graphs. Theoretical discussions present that our methods share the same complexity as state-of-the-art inference algorithms for first-order queries. Empirical results justify the superior performance of our approach against previous ML-based methods with number embedding extensions.\n    ",
        "primary_category": "cs.AI",
        "categories": [],
        "submitted_date": "3 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01509": {
        "title": "Fantastic Semantics and Where to Find Them: Investigating Which Layers of Generative LLMs Reflect Lexical Semantics",
        "authors": [
            "Zhu Liu",
            "Cunliang Kong",
            "Ying Liu",
            "Maosong Sun"
        ],
        "comments": "This work was completed on February 15th, 2024, and submitted to ACL 2024",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "Large language models have achieved remarkable success in general language understanding tasks. However, as a family of generative methods with the objective of next token prediction, the semantic evolution with the depth of these models are not fully explored, unlike their predecessors, such as BERT-like architectures. In this paper, we specifically investigate the bottom-up evolution of lexical semantics for a popular LLM, namely Llama2, by probing its hidden states at the end of each layer using a contextualized word identification task. Our experiments show that the representations in lower layers encode lexical semantics, while the higher layers, with weaker semantic induction, are responsible for prediction. This is in contrast to models with discriminative objectives, such as mask language modeling, where the higher layers obtain better lexical semantics. The conclusion is further supported by the monotonic increase in performance via the hidden states for the last meaningless symbols, such as punctuation, in the prompting strategy.\n    ",
        "primary_category": "cs.CL",
        "categories": [],
        "submitted_date": "3 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01510": {
        "title": "End-to-End Human Instance Matting",
        "authors": [
            "Qinglin Liu",
            "Shengping Zhang",
            "Quanling Meng",
            "Bineng Zhong",
            "Peiqiang Liu",
            "Hongxun Yao"
        ],
        "comments": " ",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Human instance matting aims to estimate an alpha matte for each human instance in an image, which is extremely challenging and has rarely been studied so far. Despite some efforts to use instance segmentation to generate a trimap for each instance and apply trimap-based matting methods, the resulting alpha mattes are often inaccurate due to inaccurate segmentation. In addition, this approach is computationally inefficient due to multiple executions of the matting method. To address these problems, this paper proposes a novel End-to-End Human Instance Matting (E2E-HIM) framework for simultaneous multiple instance matting in a more efficient manner. Specifically, a general perception network first extracts image features and decodes instance contexts into latent codes. Then, a united guidance network exploits spatial attention and semantics embedding to generate united semantics guidance, which encodes the locations and semantic correspondences of all instances. Finally, an instance matting network decodes the image features and united semantics guidance to predict all instance-level alpha mattes. In addition, we construct a large-scale human instance matting dataset (HIM-100K) comprising over 100,000 human images with instance alpha matte labels. Experiments on HIM-100K demonstrate the proposed E2E-HIM outperforms the existing methods on human instance matting with 50% lower errors and 5X faster speed (6 instances in a 640X640 image). Experiments on the PPM-100, RWP-636, and P3M datasets demonstrate that E2E-HIM also achieves competitive performance on traditional human matting.\n    ",
        "primary_category": "cs.CV",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "3 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01512": {
        "title": "Cooperative Automated Driving for Bottleneck Scenarios in Mixed Traffic",
        "authors": [
            "M.V. Baumann",
            "J. Beyerer",
            "H.S. Buck",
            "B. Deml",
            "S. Ehrhardt",
            "Ch. Frese",
            "D. Kleiser",
            "M. Lauer",
            "M. Roschani",
            "M. Ruf",
            "Ch. Stiller",
            "P. Vortisch",
            "J.R. Ziehn"
        ],
        "comments": "8 pages, 7 figures",
        "subjects": "Robotics (cs.RO)",
        "abstract": "Connected automated vehicles (CAV), which incorporate vehicle-to-vehicle (V2V) communication into their motion planning, are expected to provide a wide range of benefits for individual and overall traffic flow. A frequent constraint or required precondition is that compatible CAVs must already be available in traffic at high penetration rates. Achieving such penetration rates incrementally before providing ample benefits for users presents a chicken-and-egg problem that is common in connected driving development. Based on the example of a cooperative driving function for bottleneck traffic flows (e.g. at a roadblock), we illustrate how such an evolutionary, incremental introduction can be achieved under transparent assumptions and objectives. To this end, we analyze the challenge from the perspectives of automation technology, traffic flow, human factors and market, and present a principle that 1) accounts for individual requirements from each domain; 2) provides benefits for any penetration rate of compatible CAVs between 0 % and 100 % as well as upward-compatibility for expected future developments in traffic; 3) can strictly limit the negative effects of cooperation for any participant and 4) can be implemented with close-to-market technology. We discuss the technical implementation as well as the effect on traffic flow over a wide parameter spectrum for human and technical aspects.\n    ",
        "primary_category": "cs.RO",
        "categories": [
            "cs.HC",
            "cs.MA"
        ],
        "submitted_date": "3 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01513": {
        "title": "CDSE-UNet: Enhancing COVID-19 CT Image Segmentation with Canny Edge Detection and Dual-Path SENet Feature Fusion",
        "authors": [
            "Jiao Ding",
            "Jie Chang",
            "Renrui Han",
            "Li Yang"
        ],
        "comments": " ",
        "subjects": "Image and Video Processing (eess.IV)",
        "abstract": "Accurate segmentation of COVID-19 CT images is crucial for reducing the severity and mortality rates associated with COVID-19 infections. In response to blurred boundaries and high variability characteristic of lesion areas in COVID-19 CT images, we introduce CDSE-UNet: a novel UNet-based segmentation model that integrates Canny operator edge detection and a dual-path SENet feature fusion mechanism. This model enhances the standard UNet architecture by employing the Canny operator for edge detection in sample images, paralleling this with a similar network structure for semantic feature extraction. A key innovation is the Double SENet Feature Fusion Block, applied across corresponding network layers to effectively combine features from both image paths. Moreover, we have developed a Multiscale Convolution approach, replacing the standard Convolution in UNet, to adapt to the varied lesion sizes and shapes. This addition not only aids in accurately classifying lesion edge pixels but also significantly improves channel differentiation and expands the capacity of the model. Our evaluations on public datasets demonstrate CDSE-UNet's superior performance over other leading models, particularly in segmenting large and small lesion areas, accurately delineating lesion edges, and effectively suppressing noise\n    ",
        "primary_category": "eess.IV",
        "categories": [
            "cs.CV"
        ],
        "submitted_date": "3 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01517": {
        "title": "MatchU: Matching Unseen Objects for 6D Pose Estimation from RGB-D Images",
        "authors": [
            "Junwen Huang",
            "Hao Yu",
            "Kuan-Ting Yu",
            "Nassir Navab",
            "Slobodan Ilic",
            "Benjamin Busam"
        ],
        "comments": " ",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Recent learning methods for object pose estimation require resource-intensive training for each individual object instance or category, hampering their scalability in real applications when confronted with previously unseen objects. In this paper, we propose MatchU, a Fuse-Describe-Match strategy for 6D pose estimation from RGB-D images. MatchU is a generic approach that fuses 2D texture and 3D geometric cues for 6D pose prediction of unseen objects. We rely on learning geometric 3D descriptors that are rotation-invariant by design. By encoding pose-agnostic geometry, the learned descriptors naturally generalize to unseen objects and capture symmetries. To tackle ambiguous associations using 3D geometry only, we fuse additional RGB information into our descriptor. This is achieved through a novel attention-based mechanism that fuses cross-modal information, together with a matching loss that leverages the latent space learned from RGB data to guide the descriptor learning process. Extensive experiments reveal the generalizability of both the RGB-D fusion strategy as well as the descriptor efficacy. Benefiting from the novel designs, MatchU surpasses all existing methods by a significant margin in terms of both accuracy and speed, even without the requirement of expensive re-training or rendering.\n    ",
        "primary_category": "cs.CV",
        "categories": [],
        "submitted_date": "3 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01518": {
        "title": "Revisiting Dynamic Evaluation: Online Adaptation for Large Language Models",
        "authors": [
            "Amal Rannen-Triki",
            "Jorg Bornschein",
            "Razvan Pascanu",
            "Marcus Hutter",
            "Andras Gy\u00f6rgy",
            "Alexandre Galashov",
            "Yee Whye Teh",
            "Michalis K. Titsias"
        ],
        "comments": " ",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "We consider the problem of online fine tuning the parameters of a language model at test time, also known as dynamic evaluation. While it is generally known that this approach improves the overall predictive performance, especially when considering distributional shift between training and evaluation data, we here emphasize the perspective that online adaptation turns parameters into temporally changing states and provides a form of context-length extension with memory in weights, more in line with the concept of memory in neuroscience. We pay particular attention to the speed of adaptation (in terms of sample efficiency),sensitivity to the overall distributional drift, and the computational overhead for performing gradient computations and parameter updates. Our empirical study provides insights on when online adaptation is particularly interesting. We highlight that with online adaptation the conceptual distinction between in-context learning and fine tuning blurs: both are methods to condition the model on previously observed tokens.\n    ",
        "primary_category": "cs.CL",
        "categories": [
            "cs.LG"
        ],
        "submitted_date": "3 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01521": {
        "title": "Fast Algorithm for Quasi-2D Coulomb Systems",
        "authors": [
            "Zecheng Gan",
            "Xuanzhao Gao",
            "Jiuyang Liang",
            "Zhenli Xu"
        ],
        "comments": "39 pages",
        "subjects": "Numerical Analysis (math.NA)",
        "abstract": "Quasi-2D Coulomb systems are of fundamental importance and have attracted much attention in many areas nowadays. Their reduced symmetry gives rise to interesting collective behaviors, but also brings great challenges for particle-based simulations. Here, we propose a novel algorithm framework to address the $\\mathcal O(N^2)$ simulation complexity associated with the long-range nature of Coulomb interactions. First, we introduce an efficient Sum-of-Exponentials (SOE) approximation for the long-range kernel associated with Ewald splitting, achieving uniform convergence in terms of inter-particle distance, which reduces the complexity to $\\mathcal{O}(N^{7/5})$. We then introduce a random batch sampling method in the periodic dimensions, the stochastic approximation is proven to be both unbiased and with reduced variance via a tailored importance sampling strategy, further reducing the computational cost to $\\mathcal{O}(N)$. The performance of our algorithm is demonstrated via varies numerical examples. Notably, it achieves a speedup of $2\\sim 3$ orders of magnitude comparing with Ewald2D method, enabling molecular dynamics (MD) simulations with up to $10^6$ particles on a single core. The present approach is therefore well-suited for large-scale particle-based simulations of Coulomb systems under confinement, making it possible to investigate the role of Coulomb interaction in many practical situations.\n    ",
        "primary_category": "math.NA",
        "categories": [
            "physics.comp-ph"
        ],
        "submitted_date": "3 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01523": {
        "title": "Data-driven local operator finding for reduced-order modelling of plasma systems: I. Concept and verifications",
        "authors": [
            "Farbod Faraji",
            "Maryam Reza",
            "Aaron Knoll",
            "J. Nathan Kutz"
        ],
        "comments": "27 pages, 18 figures",
        "subjects": "Plasma Physics (physics.plasm-ph)",
        "abstract": "Reduced-order plasma models that can efficiently predict plasma behavior across various settings and configurations are highly sought after yet elusive. The demand for such models has surged in the past decade due to their potential to facilitate scientific research and expedite the development of plasma technologies. In line with the advancements in computational power and data-driven methods, we introduce the \"Phi Method\" in this two-part article. Part I presents this novel algorithm, which employs constrained regression on a candidate term library informed by numerical discretization schemes to discover discretized systems of differential equations. We demonstrate Phi Method's efficacy in deriving reliable and robust reduced-order models (ROMs) for three test cases: the Lorenz attractor, flow past a cylinder, and a 1D Hall-thruster-representative plasma. Part II will delve into the method's application for parametric dynamics discovery. Our results show that ROMs derived from the Phi Method provide remarkably accurate predictions of systems' behavior, whether derived from steady-state or transient-state data. This underscores the method's potential for transforming plasma system modeling.\n    ",
        "primary_category": "physics.plasm-ph",
        "categories": [
            "cs.LG",
            "physics.comp-ph"
        ],
        "submitted_date": "3 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01529": {
        "title": "Deep Incremental Model Based Reinforcement Learning: A One-Step Lookback Approach for Continuous Robotics Control",
        "authors": [
            "Cong Li"
        ],
        "comments": " ",
        "subjects": "Robotics (cs.RO)",
        "abstract": "Model-based reinforcement learning (MBRL) attempts to use an available or a learned model to improve the data efficiency of reinforcement learning. This work proposes a one-step lookback approach that jointly learns the latent-space model and the policy to realize the sample-efficient continuous robotic control, wherein the control-theoretical knowledge is utilized to decrease the model learning difficulty. Specifically, the so-called one-step backward data is utilized to facilitate the incremental evolution model, an alternative structured representation of the robotics evolution model in the MBRL field. The incremental evolution model accurately predicts the robotics movement but with low sample complexity. This is because the formulated incremental evolution model degrades the model learning difficulty into a parametric matrix learning problem, which is especially favourable to high-dimensional robotics applications. The imagined data from the learned incremental evolution model is used to supplement training data to enhance the sample efficiency. Comparative numerical simulations on benchmark continuous robotics control problems are conducted to validate the efficiency of our proposed one-step lookback approach.\n    ",
        "primary_category": "cs.RO",
        "categories": [
            "eess.SY"
        ],
        "submitted_date": "3 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01532": {
        "title": "Data-driven local operator finding for reduced-order modelling of plasma systems: II. Application to parametric dynamics",
        "authors": [
            "Farbod Faraji",
            "Maryam Reza",
            "Aaron Knoll",
            "J. Nathan Kutz"
        ],
        "comments": "24 pages, 17 figures",
        "subjects": "Plasma Physics (physics.plasm-ph)",
        "abstract": "Real-world systems often exhibit dynamics influenced by various parameters, either inherent or externally controllable, necessitating models capable of reliably capturing these parametric behaviors. Plasma technologies exemplify such systems. For example, phenomena governing global dynamics in Hall thrusters (a spacecraft propulsion technology) vary with various parameters, such as the \"self-sustained electric field\". In this Part II, following on the introduction of our novel data-driven local operator finding algorithm, Phi Method, in Part I, we showcase the method's effectiveness in learning parametric dynamics to predict system behavior across unseen parameter spaces. We present two adaptations: the \"parametric Phi Method\" and the \"ensemble Phi Method\", which are demonstrated through 2D fluid-flow-past-a-cylinder and 1D Hall-thruster-plasma-discharge problems. Comparative evaluation against parametric OPT-DMD in the fluid case demonstrates superior predictive performance of the parametric Phi Method. Across both test cases, parametric and ensemble Phi Method reliably recover governing parametric PDEs and offer accurate predictions over test parameters. Ensemble ROM analysis underscores Phi Method's robust learning of dominant dynamic coefficients with high confidence.\n    ",
        "primary_category": "physics.plasm-ph",
        "categories": [
            "cs.LG",
            "physics.comp-ph"
        ],
        "submitted_date": "3 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01533": {
        "title": "Machine learning predicts long-term mortality after acute myocardial infarction using systolic time intervals and routinely collected clinical data",
        "authors": [
            "Bijan Roudini",
            "Boshra Khajehpiri",
            "Hamid Abrishami Moghaddam",
            "Mohamad Forouzanfar"
        ],
        "comments": "Accepted for publication in \"Intelligent Medicine\"",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Precise estimation of cardiac patients' current and future comorbidities is an important factor in prioritizing continuous physiological monitoring and new therapies. ML models have shown satisfactory performance in short-term mortality prediction of patients with heart disease, while their utility in long-term predictions is limited. This study aims to investigate the performance of tree-based ML models on long-term mortality prediction and the effect of two recently introduced biomarkers on long-term mortality. This study utilized publicly available data from CCHIA at the Ministry of Health and Welfare, Taiwan, China. Medical records were used to gather demographic and clinical data, including age, gender, BMI, percutaneous coronary intervention (PCI) status, and comorbidities such as hypertension, dyslipidemia, ST-segment elevation myocardial infarction (STEMI), and non-STEMI. Using medical and demographic records as well as two recently introduced biomarkers, brachial pre-ejection period (bPEP) and brachial ejection time (bET), collected from 139 patients with acute myocardial infarction, we investigated the performance of advanced ensemble tree-based ML algorithms (random forest, AdaBoost, and XGBoost) to predict all-cause mortality within 14 years. The developed ML models achieved significantly better performance compared to the baseline LR (C-Statistic, 0.80 for random forest, 0.79 for AdaBoost, and 0.78 for XGBoost, vs 0.77 for LR) (P-RF<0.001, PAdaBoost<0.001, PXGBoost<0.05). Adding bPEP and bET to our feature set significantly improved the algorithms' performance, leading to an absolute increase in C-Statistic of up to 0.03 (C-Statistic, 0.83 for random forest, 0.82 for AdaBoost, and 0.80 for XGBoost, vs 0.74 for LR) (P-RF<0.001, PAdaBoost<0.001, PXGBoost<0.05). This advancement may enable better treatment prioritization for high-risk individuals.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.AI",
            "eess.SP"
        ],
        "submitted_date": "3 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01534": {
        "title": "Conditional normality and finite-state dimensions revisited",
        "authors": [
            "Alexander Shen"
        ],
        "comments": " ",
        "subjects": "Information Theory (cs.IT)",
        "abstract": "The notion of a normal bit sequence was introduced by Borel in 1909; it was the first definition of an individual random object. Normality is a weak notion of randomness requiring only that all $2^n$ factors (substrings) of arbitrary length~$n$ appear with the same limit frequency $2^{-n}$. Later many stronger definitions of randomness were introduced, and in this context normality found its place as ``randomness against a finite-memory adversary''. A quantitative measure of finite-state compressibility was also introduced (the finite-state dimension) and normality means that the finite state dimension is maximal (equals~$1$).\nRecently Nandakumar, Pulari and S (2023) introduced the notion of relative finite-state dimension for a binary sequence with respect to some other binary sequence (treated as an oracle), and the corresponding notion of conditional (relative) normality. (Different notions of conditional randomness were considered before, but not for the finite memory case.) They establish equivalence between the block frequency and the gambling approaches to conditional normality and finite-state dimensions.\nIn this note we revisit their definitions and explain how this equivalence can be obtained easily by generalizing known characterizations of (unconditional) normality and dimension in terms of compressibility (finite-state complexity), superadditive complexity measures and gambling (finite-state gales), thus also answering some questions left open in the above-mentioned paper.\n    ",
        "primary_category": "cs.IT",
        "categories": [
            "math.ST"
        ],
        "submitted_date": "3 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01536": {
        "title": "Fast Ergodic Search with Kernel Functions",
        "authors": [
            "Muchen Sun",
            "Ayush Gaggar",
            "Peter Trautman",
            "Todd Murphey"
        ],
        "comments": " ",
        "subjects": "Robotics (cs.RO)",
        "abstract": "Ergodic search enables optimal exploration of an information distribution while guaranteeing the asymptotic coverage of the search space. However, current methods typically have exponential computation complexity in the search space dimension and are restricted to Euclidean space. We introduce a computationally efficient ergodic search method. Our contributions are two-fold. First, we develop a kernel-based ergodic metric and generalize it from Euclidean space to Lie groups. We formally prove the proposed metric is consistent with the standard ergodic metric while guaranteeing linear complexity in the search space dimension. Secondly, we derive the first-order optimality condition of the kernel ergodic metric for nonlinear systems, which enables efficient trajectory optimization. Comprehensive numerical benchmarks show that the proposed method is at least two orders of magnitude faster than the state-of-the-art algorithm. Finally, we demonstrate the proposed algorithm with a peg-in-hole insertion task. We formulate the problem as a coverage task in the space of SE(3) and use a 30-second-long human demonstration as the prior distribution for ergodic coverage. Ergodicity guarantees the asymptotic solution of the peg-in-hole problem so long as the solution resides within the prior information distribution, which is seen in the 100\\% success rate.\n    ",
        "primary_category": "cs.RO",
        "categories": [
            "cs.LG"
        ],
        "submitted_date": "3 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01538": {
        "title": "A Preliminary Exploration of the Disruption of a Generative AI Systems: Faculty/Staff and Student Perceptions of ChatGPT and its Capability of Completing Undergraduate Engineering Coursework",
        "authors": [
            "Lance White",
            "Trini Balart",
            "Sara Amani",
            "Dr. Kristi J. Shryock",
            "Dr. Karan L. Watson"
        ],
        "comments": "22 pages, 13 figures",
        "subjects": "Human-Computer Interaction (cs.HC)",
        "abstract": "The authors of this study aim to assess the capabilities of the OpenAI ChatGPT tool to understand just how effective such a system might be for students to utilize in their studies as well as deepen understanding of faculty/staff and student perceptions about ChatGPT in general. The purpose of what is learned from the study is to continue the design of a model to facilitate the development of faculty for becoming adept at embracing change, the DANCE model (Designing Adaptations for the Next Changes in Education). This model is used in this study to help faculty with examining the impact that a disruptive new tool, such as ChatGPT, can pose for the learning environment.\nThe authors analyzed the performance of ChatGPT used to complete course assignments at a variety of levels by novice engineering students working as research assistants. Those completed works have been assessed by the faculty who created those assignments to understand how these completed assignments might compare with the performance of a typical student. A set of surveys conducted by the authors of this work are discussed where students, faculty, and staff respondents in March of 2023 addressed their perceptions of ChatGPT (A follow-up survey is being administered now, February 2024). These survey instruments were analyzed, and the data visualized in this work to bring attention to relevant findings by the researchers. This work reports the findings of the researchers with the purpose of sharing the current state of this work at Texas A&M University with the intention to provide insights to scholars both at our own institution and around the world. This work is not intended to be a finished work but reports these findings with full transparency that this work is currently continuing as the researchers gather new data and develop and validate various measurement instruments.\n    ",
        "primary_category": "cs.HC",
        "categories": [],
        "submitted_date": "3 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01540": {
        "title": "Quantized Hierarchical Federated Learning: A Robust Approach to Statistical Heterogeneity",
        "authors": [
            "Seyed Mohammad Azimi-Abarghouyi",
            "Viktoria Fodor"
        ],
        "comments": " ",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "This paper presents a novel hierarchical federated learning algorithm within multiple sets that incorporates quantization for communication-efficiency and demonstrates resilience to statistical heterogeneity. Unlike conventional hierarchical federated learning algorithms, our approach combines gradient aggregation in intra-set iterations with model aggregation in inter-set iterations. We offer a comprehensive analytical framework to evaluate its optimality gap and convergence rate, comparing these aspects with those of conventional algorithms. Additionally, we develop a problem formulation to derive optimal system parameters in a closed-form solution. Our findings reveal that our algorithm consistently achieves high learning accuracy over a range of parameters and significantly outperforms other hierarchical algorithms, particularly in scenarios with heterogeneous data distributions.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.IT"
        ],
        "submitted_date": "3 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01542": {
        "title": "Human Robot Pacing Mismatch",
        "authors": [
            "Muchen Sun",
            "Peter Trautman",
            "Todd Murphey"
        ],
        "comments": "Accepted to 2022 Robotics: Science and Systems (RSS) Workshop in Close Proximity Human-Robot Collaboration",
        "subjects": "Robotics (cs.RO)",
        "abstract": "A widely accepted explanation for robots planning overcautious or overaggressive trajectories alongside human is that the crowd density exceeds a threshold such that all feasible trajectories are considered unsafe -- the freezing robot problem. However, even with low crowd density, the robot's navigation performance could still drop drastically when in close proximity to human. In this work, we argue that a broader cause of suboptimal navigation performance near human is due to the robot's misjudgement for the human's willingness (flexibility) to share space with others, particularly when the robot assumes the human's flexibility holds constant during interaction, a phenomenon of what we call human robot pacing mismatch. We show that the necessary condition for solving pacing mismatch is to model the evolution of both the robot and the human's flexibility during decision making, a strategy called distribution space modeling. We demonstrate the advantage of distribution space coupling through an anecdotal case study and discuss the future directions of solving human robot pacing mismatch.\n    ",
        "primary_category": "cs.RO",
        "categories": [
            "cs.HC"
        ],
        "submitted_date": "3 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01545": {
        "title": "It Takes a Village: A Distributed Training Model for AI-based Chatbots",
        "authors": [
            "Colleen Estes",
            "Beth Twomey",
            "Annie Johnson"
        ],
        "comments": " ",
        "subjects": "Digital Libraries (cs.DL)",
        "abstract": "In Summer 2023, staff from the information technology and reference departments at the University of Delaware Library, Museums and Press came together in a unique partnership to pilot a low-cost AI-powered chatbot. The goal of the pilot is to learn more about student and faculty interest in engaging with this tool, and to better understand the labor required on the staff side. Reference librarians and other public facing staff, including student workers, were instrumental in helping to train the chatbot. This article discusses the development of prompts, leveraging of existing data sources for training materials, and workflows involved in the pilot. It argues that, when implementing AI-based tools in the academic library, involving staff from across the organization is essential to ensure buy-in and success. Although chatbots are designed to hide the effort of the people behind them, such labor can be substantial and needs to be recognized.\n    ",
        "primary_category": "cs.DL",
        "categories": [],
        "submitted_date": "3 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01546": {
        "title": "Hyperspectral Image Analysis in Single-Modal and Multimodal setting using Deep Learning Techniques",
        "authors": [
            "Shivam Pande"
        ],
        "comments": "253 pages",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Hyperspectral imaging provides precise classification for land use and cover due to its exceptional spectral resolution. However, the challenges of high dimensionality and limited spatial resolution hinder its effectiveness. This study addresses these challenges by employing deep learning techniques to efficiently process, extract features, and classify data in an integrated manner. To enhance spatial resolution, we integrate information from complementary modalities such as LiDAR and SAR data through multimodal learning. Moreover, adversarial learning and knowledge distillation are utilized to overcome issues stemming from domain disparities and missing modalities. We also tailor deep learning architectures to suit the unique characteristics of HSI data, utilizing 1D convolutional and recurrent neural networks to handle its continuous spectral dimension. Techniques like visual attention and feedback connections within the architecture bolster the robustness of feature extraction. Additionally, we tackle the issue of limited training samples through self-supervised learning methods, employing autoencoders for dimensionality reduction and exploring semi-supervised learning techniques that leverage unlabeled data. Our proposed approaches are evaluated across various HSI datasets, consistently outperforming existing state-of-the-art techniques.\n    ",
        "primary_category": "cs.CV",
        "categories": [
            "cs.LG"
        ],
        "submitted_date": "3 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01547": {
        "title": "Constructions of Control Sequence Set for Hierarchical Access in Data Link Network",
        "authors": [
            "Niu Xianhua",
            "Ma Jiabei",
            "Zhou Enzhi",
            "Wang Yaoxuan",
            "Zeng Bosen",
            "Li Zhiping"
        ],
        "comments": " ",
        "subjects": "Cryptography and Security (cs.CR)",
        "abstract": "Time slots are a valuable channel resource in the data link network with time division multiple access architecture. The need for finding a secure and efficient way to meet the requirements of large access capacity, differentiated access, maximum utilization of time slot resource and strong anti-eavesdropping ability in data link networks is well this http URL this paper, a control sequence-based hierarchical access control scheme is proposed, which not only achieves differentiated time slots allocation for the different needs and levels of nodes, but also enhances randomness and anti-interception performance in data link networks.Based on the scheme, a new theoretical bound is derived to characterize parameter relationships for designing optimal hierarchical control sequence(HCS) set. Moreover, two flexible classes of optimal hierarchical control sequence sets are this http URL our construction, the terminal user in the data link can access hierarchically and randomly and transmit data packets during its own hopping time slots of the successive frames to prevent eavesdropping while maintaining high throughput.\n    ",
        "primary_category": "cs.CR",
        "categories": [],
        "submitted_date": "3 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01549": {
        "title": "Self-Supervised Representation Learning with Meta Comprehensive Regularization",
        "authors": [
            "Huijie Guo",
            "Ying Ba",
            "Jie Hu",
            "Lingyu Si",
            "Wenwen Qiang",
            "Lei Shi"
        ],
        "comments": " ",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Self-Supervised Learning (SSL) methods harness the concept of semantic invariance by utilizing data augmentation strategies to produce similar representations for different deformations of the same input. Essentially, the model captures the shared information among multiple augmented views of samples, while disregarding the non-shared information that may be beneficial for downstream tasks. To address this issue, we introduce a module called CompMod with Meta Comprehensive Regularization (MCR), embedded into existing self-supervised frameworks, to make the learned representations more comprehensive. Specifically, we update our proposed model through a bi-level optimization mechanism, enabling it to capture comprehensive features. Additionally, guided by the constrained extraction of features using maximum entropy coding, the self-supervised learning model learns more comprehensive features on top of learning consistent features. In addition, we provide theoretical support for our proposed method from information theory and causal counterfactual perspective. Experimental results show that our method achieves significant improvement in classification, object detection and instance segmentation tasks on multiple benchmark datasets.\n    ",
        "primary_category": "cs.CV",
        "categories": [],
        "submitted_date": "3 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01550": {
        "title": "Spectral antisymmetry of twisted graph adjacency",
        "authors": [
            "Ye Luo",
            "Arindam Roy"
        ],
        "comments": "5 figures",
        "subjects": "Combinatorics (math.CO)",
        "abstract": "We address a prime counting problem across the homology classes of a graph, presenting a graph-theoretical Dirichlet-type analogue of the prime number theorem. The main machinery we have developed and employed is a spectral antisymmetry theorem, revealing that the spectra of the twisted graph adjacency matrices have an antisymmetric distribution over the character group of the graph. Additionally, we derive some trace formulas based on the twisted adjacency matrices as part of our analysis.\n    ",
        "primary_category": "math.CO",
        "categories": [
            "cs.DM",
            "math.NT",
            "math.SP"
        ],
        "submitted_date": "3 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01554": {
        "title": "Transformers for Supervised Online Continual Learning",
        "authors": [
            "Jorg Bornschein",
            "Yazhe Li",
            "Amal Rannen-Triki"
        ],
        "comments": " ",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Transformers have become the dominant architecture for sequence modeling tasks such as natural language processing or audio processing, and they are now even considered for tasks that are not naturally sequential such as image classification. Their ability to attend to and to process a set of tokens as context enables them to develop in-context few-shot learning abilities. However, their potential for online continual learning remains relatively unexplored. In online continual learning, a model must adapt to a non-stationary stream of data, minimizing the cumulative nextstep prediction loss. We focus on the supervised online continual learning setting, where we learn a predictor $x_t \\rightarrow y_t$ for a sequence of examples $(x_t, y_t)$. Inspired by the in-context learning capabilities of transformers and their connection to meta-learning, we propose a method that leverages these strengths for online continual learning. Our approach explicitly conditions a transformer on recent observations, while at the same time online training it with stochastic gradient descent, following the procedure introduced with Transformer-XL. We incorporate replay to maintain the benefits of multi-epoch training while adhering to the sequential protocol. We hypothesize that this combination enables fast adaptation through in-context learning and sustained longterm improvement via parametric learning. Our method demonstrates significant improvements over previous state-of-the-art results on CLOC, a challenging large-scale real-world benchmark for image geo-localization.\n    ",
        "primary_category": "cs.LG",
        "categories": [],
        "submitted_date": "3 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01558": {
        "title": "Adapt or Wait: Quality Adaptation for Cache-aided Channels",
        "authors": [
            "Eleftherios Lampiris",
            "Giuseppe Caire"
        ],
        "comments": "Submitted to Transactions on Communications",
        "subjects": "Information Theory (cs.IT)",
        "abstract": "This work focuses on quality adaptation as a means to counter the effects of channel degradation in wireless, cache-aided channels. We design a delivery scheme which combines coded caching, superposition coding, and scalable source coding, while keeping the caching scheme oblivious to channel qualities. By properly adjusting the quality at the degraded users we are able to satisfy all demands in a time-efficient manner. In addition, superposition coding allows us to serve high-rate users with high content quality without subjecting them to a delay penalty caused by users with lower rate channels. We design a communication framework that covers all possible channel rate and quality configurations and we further provide algorithms that can optimise the served quality. An interesting outcome of this work is that a modest quality reduction at the degraded users can counter the effects of significant channel degradation. For example, in a 100-user system with normalized cache size 1/10 at each user, if 10 users experience channel degradation of 60% compared to the rate of the non-degraded users, we show that our transmission strategy leads to a 85% quality at the degraded users and perfect quality at the non-degraded users.\n    ",
        "primary_category": "cs.IT",
        "categories": [],
        "submitted_date": "3 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01560": {
        "title": "Rethinking CLIP-based Video Learners in Cross-Domain Open-Vocabulary Action Recognition",
        "authors": [
            "Kun-Yu Lin",
            "Henghui Ding",
            "Jiaming Zhou",
            "Yi-Xing Peng",
            "Zhilin Zhao",
            "Chen Change Loy",
            "Wei-Shi Zheng"
        ],
        "comments": " ",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Contrastive Language-Image Pretraining (CLIP) has shown remarkable open-vocabulary abilities across various image understanding tasks. Building upon this impressive success, recent pioneer works have proposed to adapt the powerful CLIP to video data, leading to efficient and effective video learners for open-vocabulary action recognition. Inspired by the fact that humans perform actions in diverse environments, our work delves into an intriguing question: Can CLIP-based video learners effectively generalize to video domains they have not encountered during training? To answer this, we establish a CROSS-domain Open-Vocabulary Action recognition benchmark named XOV-Action, and conduct a comprehensive evaluation of five state-of-the-art CLIP-based video learners under various types of domain gaps. Our evaluation demonstrates that previous methods exhibit limited action recognition performance in unseen video domains, revealing potential challenges of the cross-domain open-vocabulary action recognition task. To address this task, our work focuses on a critical challenge, namely scene bias, and we accordingly contribute a novel scene-aware video-text alignment method. Our key idea is to distinguish video representations apart from scene-encoded text representations, aiming to learn scene-agnostic video representations for recognizing actions across domains. Extensive experimental results demonstrate the effectiveness of our method. The benchmark and code will be available at this https URL.\n    ",
        "primary_category": "cs.CV",
        "categories": [],
        "submitted_date": "3 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01567": {
        "title": "ReMatch: Retrieval Enhanced Schema Matching with LLMs",
        "authors": [
            "Eitam Sheetrit",
            "Menachem Brief",
            "Moshik Mishaeli",
            "Oren Elisha"
        ],
        "comments": " ",
        "subjects": "Databases (cs.DB)",
        "abstract": "Schema matching is a crucial task in data integration, involving the alignment of a source database schema with a target schema to establish correspondence between their elements. This task is challenging due to textual and semantic heterogeneity, as well as differences in schema sizes. Although machine-learning-based solutions have been explored in numerous studies, they often suffer from low accuracy, require manual mapping of the schemas for model training, or need access to source schema data which might be unavailable due to privacy concerns. In this paper we present a novel method, named ReMatch, for matching schemas using retrieval-enhanced Large Language Models (LLMs). Our method avoids the need for predefined mapping, any model training, or access to data in the source database. In the ReMatch method the tables of the target schema and the attributes of the source schema are first represented as structured passage-based documents. For each source attribute document, we retrieve $J$ documents, representing target schema tables, according to their semantic relevance. Subsequently, we create a prompt for every source table, comprising all its attributes and their descriptions, alongside all attributes from the set of top $J$ target tables retrieved previously. We employ LLMs using this prompt for the matching task, yielding a ranked list of $K$ potential matches for each source attribute. Our experimental results on large real-world schemas demonstrate that ReMatch significantly improves matching capabilities and outperforms other machine learning approaches. By eliminating the requirement for training data, ReMatch becomes a viable solution for real-world scenarios.\n    ",
        "primary_category": "cs.DB",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "3 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01568": {
        "title": "Approximations and Hardness of Packing Partially Ordered Items",
        "authors": [
            "Ilan Doron-Arad",
            "Guy Kortsarz",
            "Joseph Naor",
            "Baruch Schieber",
            "Hadas Shachnai"
        ],
        "comments": " ",
        "subjects": "Data Structures and Algorithms (cs.DS)",
        "abstract": "Motivated by applications in production planning and storage allocation in hierarchical databases, we initiate the study of covering partially ordered items (CPO). Given a capacity $k \\in \\mathbb{Z}^+$, and a directed graph $G=(V,E)$ where each vertex has a size in $\\{0,1, \\ldots,k\\}$, we seek a collection of subsets of vertices $S_1, \\ldots, S_m$ that cover all the vertices, such that for any $1 \\leq j \\leq m$, the total size of vertices in $S_j$ is bounded by $k$, and there are no edges from $V \\setminus S_j$ to $S_j$. The objective is to minimize the number of subsets $m$. CPO is closely related to the rule caching problem (RCP) that is of wide interest in the networking area. The input for RCP is a directed graph $G=(V,E)$, a profit function $p:V \\rightarrow \\mathbb{Z}_{0}^+$, and $k \\in \\mathbb{Z}^+$. The output is a subset $S \\subseteq V$ of maximum profit such that $|S| \\leq k$ and there are no edges from $V \\setminus S$ to $S$.\nOur main result is a $2$-approximation algorithm for CPO on out-trees, complemented by an asymptotic $1.5$-hardness of approximation result. We also give a two-way reduction between RCP and the densest $k$-subhypergraph problem, surprisingly showing that the problems are equivalent w.r.t. polynomial-time approximation within any factor $\\rho \\geq 1$. This implies that RCP cannot be approximated within factor $|V|^{1-\\eps}$ for any fixed $\\eps>0$, under standard complexity assumptions. Prior to this work, RCP was just known to be strongly NP-hard. We further show that there is no EPTAS for the special case of RCP where the profits are uniform, assuming Gap-ETH. Since this variant admits a PTAS, we essentially resolve the complexity status of this problem.\n    ",
        "primary_category": "cs.DS",
        "categories": [],
        "submitted_date": "3 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01569": {
        "title": "Kick Back & Relax++: Scaling Beyond Ground-Truth Depth with SlowTV & CribsTV",
        "authors": [
            "Jaime Spencer",
            "Chris Russell",
            "Simon Hadfield",
            "Richard Bowden"
        ],
        "comments": " ",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Self-supervised learning is the key to unlocking generic computer vision systems. By eliminating the reliance on ground-truth annotations, it allows scaling to much larger data quantities. Unfortunately, self-supervised monocular depth estimation (SS-MDE) has been limited by the absence of diverse training data. Existing datasets have focused exclusively on urban driving in densely populated cities, resulting in models that fail to generalize beyond this domain.\nTo address these limitations, this paper proposes two novel datasets: SlowTV and CribsTV. These are large-scale datasets curated from publicly available YouTube videos, containing a total of 2M training frames. They offer an incredibly diverse set of environments, ranging from snowy forests to coastal roads, luxury mansions and even underwater coral reefs. We leverage these datasets to tackle the challenging task of zero-shot generalization, outperforming every existing SS-MDE approach and even some state-of-the-art supervised methods.\nThe generalization capabilities of our models are further enhanced by a range of components and contributions: 1) learning the camera intrinsics, 2) a stronger augmentation regime targeting aspect ratio changes, 3) support frame randomization, 4) flexible motion estimation, 5) a modern transformer-based architecture. We demonstrate the effectiveness of each component in extensive ablation experiments. To facilitate the development of future research, we make the datasets, code and pretrained models available to the public at this https URL.\n    ",
        "primary_category": "cs.CV",
        "categories": [
            "cs.AI",
            "cs.RO"
        ],
        "submitted_date": "3 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01571": {
        "title": "Limits to classification performance by relating Kullback-Leibler divergence to Cohen's Kappa",
        "authors": [
            "L. Crow",
            "S. J. Watts"
        ],
        "comments": "Presented at the American Statistical Association Symposium on Data Science and Statistics, St. Louis, USA, May 2023",
        "subjects": "Machine Learning (stat.ML)",
        "abstract": "The performance of machine learning classification algorithms are evaluated by estimating metrics, often from the confusion matrix, using training data and cross-validation. However, these do not prove that the best possible performance has been achieved. Fundamental limits to error rates can be estimated using information distance measures. To this end, the confusion matrix has been formulated to comply with the Chernoff-Stein Lemma. This links the error rates to the Kullback-Leibler divergences between the probability density functions describing the two classes. This leads to a key result that relates Cohen's Kappa to the Resistor Average Distance which is the parallel resistor combination of the two Kullback-Leibler divergences. The Resistor Average Distance has units of bits and is estimated from the same training data used by the classification algorithm, using kNN estimates of the KullBack-Leibler divergences. The classification algorithm gives the confusion matrix and Kappa. Theory and methods are discussed in detail and then applied to Monte Carlo data and real datasets. Four very different real datasets - Breast Cancer, Coronary Heart Disease, Bankruptcy, and Particle Identification - are analysed, with both continuous and discrete values, and their classification performance compared to the expected theoretical limit. In all cases this analysis shows that the algorithms could not have performed any better due to the underlying probability density functions for the two classes. Important lessons are learnt on how to predict the performance of algorithms for imbalanced data using training datasets that are approximately balanced. Machine learning is very powerful but classification performance ultimately depends on the quality of the data and the relevance of the variables to the problem.\n    ",
        "primary_category": "stat.ML",
        "categories": [
            "cs.LG",
            "physics.data-an"
        ],
        "submitted_date": "3 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01572": {
        "title": "Deeply Embedded Wages: Navigating Digital Payments in Data Work",
        "authors": [
            "Julian Posada"
        ],
        "comments": " ",
        "subjects": "Computers and Society (cs.CY)",
        "abstract": "Many of the world's workers rely on digital platforms for their income. In Venezuela, a nation grappling with extreme inflation and where most of the workforce is self-employed, data production platforms for machine learning have emerged as a viable opportunity for many to earn a flexible income in US dollars. Platform workers are deeply interconnected within a vast network of firms and entities that act as intermediaries for wage payments in digital currencies and its subsequent conversion to the national currency, the bolivar. Past research on embeddedness has noted that being intertwined in multi-tiered socioeconomic networks of companies and individuals can offer significant rewards to social participants, while also connoting a particular set of limitations. This paper furnishes qualitative evidence regarding how this deep embeddedness impacts platform workers in Venezuela. Given the backdrop of a national crisis and rampant hyperinflation, the perks of receiving wages through various financial platforms include access to a more stable currency and the ability to save and invest outside the national financial system. However, relying on numerous digital and local intermediaries often diminishes income due to transaction fees. Moreover, this introduces heightened financial risks, particularly due to the unpredictable nature of cryptocurrencies as an investment. The over-reliance on external financial platforms erodes worker autonomy through power dynamics that lean in favor of the platforms that set the transaction rules and prices. These findings present a multifaceted perspective on deep embeddedness in platform labor, highlighting how the rewards of financial intermediation often come at a substantial cost for the workers in unstable situations, who are saddled with escalating financial risks.\n    ",
        "primary_category": "cs.CY",
        "categories": [],
        "submitted_date": "3 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01575": {
        "title": "SARD: A Human-AI Collaborative Story Generation",
        "authors": [
            "Ahmed Y. Radwan",
            "Khaled M. Alasmari",
            "Omar A. Abdulbagi",
            "Emad A. Alghamdi"
        ],
        "comments": " ",
        "subjects": "Human-Computer Interaction (cs.HC)",
        "abstract": "Generative artificial intelligence (GenAI) has ushered in a new era for storytellers, providing a powerful tool to ignite creativity and explore uncharted narrative territories. As technology continues to advance, the synergy between human creativity and AI-generated content holds the potential to redefine the landscape of storytelling. In this work, we propose SARD, a drag-and-drop visual interface for generating a multi-chapter story using large language models. Our evaluation of the usability of SARD and its creativity support shows that while node-based visualization of the narrative may help writers build a mental model, it exerts unnecessary mental overhead to the writer and becomes a source of distraction as the story becomes more elaborated. We also found that AI generates stories that are less lexically diverse, irrespective of the complexity of the story. We identified some patterns and limitations of our tool that can guide the development of future human-AI co-writing tools.\n    ",
        "primary_category": "cs.HC",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "3 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01579": {
        "title": "A Continuous Benchmarking Infrastructure for High-Performance Computing Applications",
        "authors": [
            "Christoph Alt",
            "Martin Lanser",
            "Jonas Plewinski",
            "Atin Janki",
            "Axel Klawonn",
            "Harald K\u00f6stler",
            "Michael Selzer",
            "Ulrich R\u00fcde"
        ],
        "comments": " ",
        "subjects": "Performance (cs.PF)",
        "abstract": "For scientific software, especially those used for large-scale simulations, achieving good performance and efficiently using the available hardware resources is essential. It is important to regularly perform benchmarks to ensure the efficient use of hardware and software when systems are changing and the software evolves. However, this can become quickly very tedious when many options for parameters, solvers, and hardware architectures are available. We present a continuous benchmarking strategy that automates benchmarking new code changes on high-performance computing clusters. This makes it possible to track how each code change affects the performance and how it evolves.\n    ",
        "primary_category": "cs.PF",
        "categories": [],
        "submitted_date": "3 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01580": {
        "title": "Enhancing Neural Machine Translation of Low-Resource Languages: Corpus Development, Human Evaluation and Explainable AI Architectures",
        "authors": [
            "S\u00e9amus Lankford"
        ],
        "comments": "PhD thesis",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "In the current machine translation (MT) landscape, the Transformer architecture stands out as the gold standard, especially for high-resource language pairs. This research delves into its efficacy for low-resource language pairs including both the English$\\leftrightarrow$Irish and English$\\leftrightarrow$Marathi language pairs. Notably, the study identifies the optimal hyperparameters and subword model type to significantly improve the translation quality of Transformer models for low-resource language pairs.\nThe scarcity of parallel datasets for low-resource languages can hinder MT development. To address this, gaHealth was developed, the first bilingual corpus of health data for the Irish language. Focusing on the health domain, models developed using this in-domain dataset exhibited very significant improvements in BLEU score when compared with models from the LoResMT2021 Shared Task. A subsequent human evaluation using the multidimensional quality metrics error taxonomy showcased the superior performance of the Transformer system in reducing both accuracy and fluency errors compared to an RNN-based counterpart.\nFurthermore, this thesis introduces adaptNMT and adaptMLLM, two open-source applications streamlined for the development, fine-tuning, and deployment of neural machine translation models. These tools considerably simplify the setup and evaluation process, making MT more accessible to both developers and translators. Notably, adaptNMT, grounded in the OpenNMT ecosystem, promotes eco-friendly natural language processing research by highlighting the environmental footprint of model development. Fine-tuning of MLLMs by adaptMLLM demonstrated advancements in translation performance for two low-resource language pairs: English$\\leftrightarrow$Irish and English$\\leftrightarrow$Marathi, compared to baselines from the LoResMT2021 Shared Task.\n    ",
        "primary_category": "cs.CL",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "3 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01582": {
        "title": "On the Model-Agnostic Multi-Source-Free Unsupervised Domain Adaptation",
        "authors": [
            "Jiangbo Pei",
            "Ruizhe Li",
            "Qingchao Chen"
        ],
        "comments": " ",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Multi-Source-Free Unsupervised Domain Adaptation (MSFDA) aims to transfer knowledge from multiple well-labeled source domains to an unlabeled target domain, using source models instead of source data. Existing MSFDA methods limited that each source domain provides only a single model, with a uniform structure. This paper introduces a new MSFDA setting: Model-Agnostic Multi-Source-Free Unsupervised Domain Adaptation (MMDA), allowing diverse source models with varying architectures, without quantitative restrictions. While MMDA holds promising potential, incorporating numerous source models poses a high risk of including undesired models, which highlights the source model selection problem. To address it, we first provide a theoretical analysis of this problem. We reveal two fundamental selection principles: transferability principle and diversity principle, and introduce a selection algorithm to integrate them. Then, considering the measure of transferability is challenging, we propose a novel Source-Free Unsupervised Transferability Estimation (SUTE). This novel formulation enables the assessment and comparison of transferability across multiple source models with different architectures in the context of domain shift, without requiring access to any target labels or source data. Based on the above, we introduce a new framework to address MMDA. Specifically, we first conduct source model selection based on the proposed selection principles. Subsequently, we design two modules to aggregate knowledge from included models and recycle useful knowledge from excluded models. These modules enable us to leverage source knowledge efficiently and effectively, thereby supporting us in learning a discriminative target model via adaptation. We validate the effectiveness of our method through numerous experimental results, and demonstrate that our approach achieves state-of-the-art performance.\n    ",
        "primary_category": "cs.LG",
        "categories": [],
        "submitted_date": "3 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01586": {
        "title": "IoT Device Labeling Using Large Language Models",
        "authors": [
            "Bar Meyuhas",
            "Anat Bremler-Barr",
            "Tal Shapira"
        ],
        "comments": " ",
        "subjects": "Cryptography and Security (cs.CR)",
        "abstract": "The IoT market is diverse and characterized by a multitude of vendors that support different device functions (e.g., speaker, camera, vacuum cleaner, etc.). Within this market, IoT security and observability systems use real-time identification techniques to manage these devices effectively. Most existing IoT identification solutions employ machine learning techniques that assume the IoT device, labeled by both its vendor and function, was observed during their training phase. We tackle a key challenge in IoT labeling: how can an AI solution label an IoT device that has never been seen before and whose label is unknown?\nOur solution extracts textual features such as domain names and hostnames from network traffic, and then enriches these features using Google search data alongside catalog of vendors and device functions. The solution also integrates an auto-update mechanism that uses Large Language Models (LLMs) to update these catalogs with emerging device types. Based on the information gathered, the device's vendor is identified through string matching with the enriched features. The function is then deduced by LLMs and zero-shot classification from a predefined catalog of IoT functions.\nIn an evaluation of our solution on 97 unique IoT devices, our function labeling approach achieved HIT1 and HIT2 scores of 0.7 and 0.77, respectively. As far as we know, this is the first research to tackle AI-automated IoT labeling.\n    ",
        "primary_category": "cs.CR",
        "categories": [
            "cs.NI"
        ],
        "submitted_date": "3 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01587": {
        "title": "Monitoring the Seismic Behavior of a Scaled RC Frame with Intermediate Ductility in a Shaking Table Test",
        "authors": [
            "Mohammad Vasef",
            "Mohammad Sadegh Marefat",
            "Sina Shid-Moosavi",
            "Peng \"Patrick\" Sun"
        ],
        "comments": "8th World Conference on Structural Control and Monitoring (8WCSCM), Orlando, FL. (2022)",
        "subjects": "Computational Engineering, Finance, and Science (cs.CE)",
        "abstract": "One of the commonly used seismic force-resisting systems in structures is Reinforced Concrete (RC) Intermediate Moment Frames (IMF). Although using the IMF is not allowed in high seismic hazard zones according to ASCE 7-10, it is permitted in both Iran's 2800 Seismic Standard and New Zealand's Seismic Code. This study investigates the seismic behavior of a reinforced concrete IMF subjected to earthquake excitations using shaking table tests on a 2D RC structural model which is designed under the regulations of ACI318-19. The scale factor of 1/2.78 is selected for the frame fabrication due to the size limit of the shaking table. The constructed model has three stories with a height as 115 cm for each story, the clear length of beams as 151 cm, and cross-sectional dimensions of columns and beams as 11 $\\times$ 11 cm and 12 $\\times$ 11 cm, respectively. The whole structure is supported by a foundation that is 173 cm long, 52 cm wide, and 22 cm deep. Columns and beams are reinforced with 8 mm diameter longitudinal ribbed bars and stirrups with 6 mm diameter. The tests are conducted in stages with increasing peak ground acceleration (PGA) till the failure of the frame. Sarpol-E-Zahab earthquake seismic record is adopted for the experiment. The structural responses (e.g., displacements, longitudinal bars' strain, crack propagation, accelerations) are monitored during the test using both conventional sensors and vison-based sensors. As a comparative study, both conventional sensors and computer vision techniques are used to monitor the health state and to analyze the structural dynamics of the scaled RC frame structure.\n    ",
        "primary_category": "cs.CE",
        "categories": [],
        "submitted_date": "3 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01594": {
        "title": "Never Tell the Trick: Covert Interactive Mixed Reality System for Immersive Storytelling",
        "authors": [
            "Chanwoo Lee",
            "Kyubeom Shim",
            "Sanggyo Seo",
            "Gwonu Ryu",
            "Yongsoon Choi"
        ],
        "comments": "To be presented in IEEE VR 2024",
        "subjects": "Human-Computer Interaction (cs.HC)",
        "abstract": "This study explores the integration of Ultra-Wideband (UWB) technology into Mixed Reality (MR) Systems for immersive storytelling. Addressing the limitations of existing technologies like Microsoft Kinect and HTC Vive, the research focuses on overcoming challenges in robustness to occlusion, tracking volume, and cost efficiency in props tracking. Utilizing UWB technology, the interactive MR system enhances the scope of performance art by enabling larger tracking areas, more reliable and cheaper multi-prop tracking, and reducing occlusion issues. Preliminary user tests suggest meaningful improvements in immersive experience, promising a new possibility in Extended Reality (XR) theater, performance art and immersive game.\n    ",
        "primary_category": "cs.HC",
        "categories": [],
        "submitted_date": "3 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01596": {
        "title": "Optimizing Near Field Computation in the MLFMA Algorithm with Data Redundancy and Performance Modeling on a Single GPU",
        "authors": [
            "Morteza Sadeghi",
            "Abdolreza Torabi"
        ],
        "comments": " ",
        "subjects": "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "abstract": "The Multilevel Fast Multipole Algorithm (MLFMA) has known applications in scientific modeling in the fields of telecommunications, physics, mechanics, and chemistry. Accelerating calculation of far-field using GPUs and GPU clusters for large-scale problems has been studied for more than a decade. The acceleration of the Near Field Computation (P2P operator) however was less of a concern because it does not face the challenges of distributed processing which does far field. This article proposes a modification of the P2P algorithm and uses performance models to determine its optimality criteria. By modeling the speedup, we found that making threads independence by creating redundancy in the data makes the algorithm for lower dense (higher frequency) problems nearly 13 times faster than non-redundant mode.\n    ",
        "primary_category": "cs.DC",
        "categories": [
            "cs.PF",
            "physics.comp-ph"
        ],
        "submitted_date": "3 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01599": {
        "title": "SCHEMA: State CHangEs MAtter for Procedure Planning in Instructional Videos",
        "authors": [
            "Yulei Niu",
            "Wenliang Guo",
            "Long Chen",
            "Xudong Lin",
            "Shih-Fu Chang"
        ],
        "comments": "Accepted by ICLR 2024",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "We study the problem of procedure planning in instructional videos, which aims to make a goal-oriented sequence of action steps given partial visual state observations. The motivation of this problem is to learn a structured and plannable state and action space. Recent works succeeded in sequence modeling of steps with only sequence-level annotations accessible during training, which overlooked the roles of states in the procedures. In this work, we point out that State CHangEs MAtter (SCHEMA) for procedure planning in instructional videos. We aim to establish a more structured state space by investigating the causal relations between steps and states in procedures. Specifically, we explicitly represent each step as state changes and track the state changes in procedures. For step representation, we leveraged the commonsense knowledge in large language models (LLMs) to describe the state changes of steps via our designed chain-of-thought prompting. For state change tracking, we align visual state observations with language state descriptions via cross-modal contrastive learning, and explicitly model the intermediate states of the procedure using LLM-generated state descriptions. Experiments on CrossTask, COIN, and NIV benchmark datasets demonstrate that our proposed SCHEMA model achieves state-of-the-art performance and obtains explainable visualizations.\n    ",
        "primary_category": "cs.CV",
        "categories": [
            "cs.AI",
            "cs.CL",
            "cs.LG"
        ],
        "submitted_date": "3 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01600": {
        "title": "Can Poverty Be Reduced by Acting on Discrimination? An Agent-based Model for Policy Making",
        "authors": [
            "Alba Aguilera",
            "Nieves Montes",
            "Georgina Curto",
            "Carles Sierra",
            "Nardine Osman"
        ],
        "comments": " ",
        "subjects": "Multiagent Systems (cs.MA)",
        "abstract": "In the last decades, there has been a deceleration in the rates of poverty reduction, suggesting that traditional redistributive approaches to poverty mitigation could be losing effectiveness, and alternative insights to advance the number one UN Sustainable Development Goal are required. The criminalization of poor people has been denounced by several NGOs, and an increasing number of voices suggest that discrimination against the poor (a phenomenon known as \\emph{aporophobia}) could be an impediment to mitigating poverty. In this paper, we present the novel Aporophobia Agent-Based Model (AABM) to provide evidence of the correlation between aporophobia and poverty computationally. We present our use case built with real-world demographic data and poverty-mitigation public policies (either enforced or under parliamentary discussion) for the city of Barcelona. We classify policies as discriminatory or non-discriminatory against the poor, with the support of specialized NGOs, and we observe the results in the AABM in terms of the impact on wealth inequality. The simulation provides evidence of the relationship between aporophobia and the increase of wealth inequality levels, paving the way for a new generation of poverty reduction policies that act on discrimination and tackle poverty as a societal problem (not only a problem of the poor).\n    ",
        "primary_category": "cs.MA",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "3 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01601": {
        "title": "Measuring Technological Convergence in Encryption Technologies with Proximity Indices: A Text Mining and Bibliometric Analysis using OpenAlex",
        "authors": [
            "Alessandro Tavazzi",
            "Dimitri Percia David",
            "Julian Jang-Jaccard",
            "Alain Mermoud"
        ],
        "comments": "27 pages, 10 figures",
        "subjects": "Computers and Society (cs.CY)",
        "abstract": "Identifying technological convergence among emerging technologies in cybersecurity is crucial for advancing science and fostering innovation. Unlike previous studies focusing on the binary relationship between a paper and the concept it attributes to technology, our approach utilizes attribution scores to enhance the relationships between research papers, combining keywords, citation rates, and collaboration status with specific technological concepts. The proposed method integrates text mining and bibliometric analyses to formulate and predict technological proximity indices for encryption technologies using the \"OpenAlex\" catalog. Our case study findings highlight a significant convergence between blockchain and public-key cryptography, evidenced by the increasing proximity indices. These results offer valuable strategic insights for those contemplating investments in these domains.\n    ",
        "primary_category": "cs.CY",
        "categories": [
            "cs.CR",
            "cs.IR"
        ],
        "submitted_date": "3 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01605": {
        "title": "Towards Provable Log Density Policy Gradient",
        "authors": [
            "Pulkit Katdare",
            "Anant Joshi",
            "Katherine Driggs-Campbell"
        ],
        "comments": " ",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Policy gradient methods are a vital ingredient behind the success of modern reinforcement learning. Modern policy gradient methods, although successful, introduce a residual error in gradient estimation. In this work, we argue that this residual term is significant and correcting for it could potentially improve sample-complexity of reinforcement learning methods. To that end, we propose log density gradient to estimate the policy gradient, which corrects for this residual error term. Log density gradient method computes policy gradient by utilising the state-action discounted distributional formulation. We first present the equations needed to exactly find the log density gradient for a tabular Markov Decision Processes (MDPs). For more complex environments, we propose a temporal difference (TD) method that approximates log density gradient by utilizing backward on-policy samples. Since backward sampling from a Markov chain is highly restrictive we also propose a min-max optimization that can approximate log density gradient using just on-policy samples. We also prove uniqueness, and convergence under linear function approximation, for this min-max optimization. Finally, we show that the sample complexity of our min-max optimization to be of the order of $m^{-1/2}$, where $m$ is the number of on-policy samples. We also demonstrate a proof-of-concept for our log density gradient method on gridworld environment, and observe that our method is able to improve upon the classical policy gradient method by a clear margin, thus indicating a promising novel direction to develop reinforcement learning algorithms that require fewer samples.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.AI",
            "stat.ML"
        ],
        "submitted_date": "3 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01607": {
        "title": "Respiratory motion forecasting with online learning of recurrent neural networks for safety enhancement in externally guided radiotherapy",
        "authors": [
            "Michel Pohl",
            "Mitsuru Uesaka",
            "Hiroyuki Takahashi",
            "Kazuyuki Demachi",
            "Ritu Bhusal Chhatkuli"
        ],
        "comments": "34 pages, 11 figures",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "In lung radiotherapy, infrared cameras can record the location of reflective objects on the chest to infer the position of the tumor moving due to breathing, but treatment system latencies hinder radiation beam precision. Real-time recurrent learning (RTRL), is a potential solution as it can learn patterns within non-stationary respiratory data but has high complexity. This study assesses the capabilities of resource-efficient online RNN algorithms, namely unbiased online recurrent optimization (UORO), sparse-1 step approximation (SnAp-1), and decoupled neural interfaces (DNI) to forecast respiratory motion during radiotherapy treatment accurately. We use time series containing the 3D position of external markers on the chest of healthy subjects. We propose efficient implementations for SnAp-1 and DNI based on compression of the influence and immediate Jacobian matrices and an accurate update of the linear coefficients used in credit assignment estimation, respectively. The original sampling frequency was 10Hz; we performed resampling at 3.33Hz and 30Hz. We use UORO, SnAp-1, and DNI to forecast each marker's 3D position with horizons (the time interval in advance for which the prediction is made) h<=2.1s and compare them with RTRL, least mean squares, and linear regression. RNNs trained online achieved similar or better accuracy than most previous works using larger training databases and deep learning, even though we used only the first minute of each sequence to predict motion within that exact sequence. SnAp-1 had the lowest normalized root mean square errors (nRMSE) averaged over the horizon values considered, equal to 0.335 and 0.157, at 3.33Hz and 10.0Hz, respectively. Similarly, UORO had the highest accuracy at 30Hz, with an nRMSE of 0.0897. DNI's inference time, equal to 6.8ms per time step at 30Hz (Intel Core i7-13700 CPU), was the lowest among the RNN methods examined.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.NE",
            "eess.IV",
            "eess.SP"
        ],
        "submitted_date": "3 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01611": {
        "title": "The Grasp Loop Signature: A Topological Representation for Manipulation Planning with Ropes and Cables",
        "authors": [
            "Peter Mitrano",
            "Dmitry Berenson"
        ],
        "comments": "Accept to ICRA 2024; Project Website: this https URL",
        "subjects": "Robotics (cs.RO)",
        "abstract": "Robotic manipulation of deformable, one-dimensional objects (DOOs) like ropes or cables has important potential applications in manufacturing, agriculture, and surgery. In such environments, the task may involve threading through or avoiding becoming tangled with objects like racks or frames. Grasping with multiple grippers can create closed loops between the robot and DOO, and If an obstacle lies within this loop, it may be impossible to reach the goal. However, prior work has only considered the topology of the DOO in isolation, ignoring the arms that are manipulating it. Searching over possible grasps to accomplish the task without considering such topological information is very inefficient, as many grasps will not lead to progress on the task due to topological constraints. Therefore, we propose a grasp loop signature which categorizes the topology of these grasp loops and show how it can be used to guide planning. We perform experiments in simulation on two DOO manipulation tasks to show that using the signature is faster and succeeds more often than methods that rely on local geometry or finite-horizon planning. Finally, we demonstrate using the signature in the real world to manipulate a cable in a scene with obstacles using a dual-arm robot.\n    ",
        "primary_category": "cs.RO",
        "categories": [],
        "submitted_date": "3 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01614": {
        "title": "Real-time optimization of thermoelectric coolers' performance based on energy and exergy analysis",
        "authors": [
            "Alireza Amiri-Margavi",
            "Reza Jamali",
            "Seyed Aria Hosseini",
            "Farschad Torabi"
        ],
        "comments": "14 pages, 7 figures",
        "subjects": "Systems and Control (eess.SY)",
        "abstract": "New strategy is presented to optimize the performance of Thermoelectric (TE) coolers. This approach breaks optimizing TE coolers free from traditional methods of controlling temperature or engineering materials and the structural properties of the junctions. We introduced a dimensionless figure, {\\gamma}, that shows the ratio of the unavailable cooling capacity to the available cooling capacity. This parameter relates the TE coolers' coefficient of performance (COP) to the COP of the reversible cycle (second law of thermodynamics efficiency) for a given electrical current. The theoretical description of the model is presented, and it is shown that controlling {\\gamma} during the TE performance minimizes entropy generation and energy loss, which leads to the maximum pumped heat. We validated this model against a designed TE cooler. In this cooler, contrary to conventional TE coolers, where the temperature of the cold space is generally controlled at a specific temperature, and the performance of the cooler overlooked, the entropy generation and heat loss are engineered, and the electrical current is tuned to minimize {\\gamma} by the controller so that the TE cooler works near to its optimum performance at any time.\n    ",
        "primary_category": "eess.SY",
        "categories": [],
        "submitted_date": "3 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01615": {
        "title": "Partial Federated Learning",
        "authors": [
            "Tiantian Feng",
            "Anil Ramakrishna",
            "Jimit Majmudar",
            "Charith Peris",
            "Jixuan Wang",
            "Clement Chung",
            "Richard Zemel",
            "Morteza Ziyadi",
            "Rahul Gupta"
        ],
        "comments": " ",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Federated Learning (FL) is a popular algorithm to train machine learning models on user data constrained to edge devices (for example, mobile phones) due to privacy concerns. Typically, FL is trained with the assumption that no part of the user data can be egressed from the edge. However, in many production settings, specific data-modalities/meta-data are limited to be on device while others are not. For example, in commercial SLU systems, it is typically desired to prevent transmission of biometric signals (such as audio recordings of the input prompt) to the cloud, but egress of locally (i.e. on the edge device) transcribed text to the cloud may be possible. In this work, we propose a new algorithm called Partial Federated Learning (PartialFL), where a machine learning model is trained using data where a subset of data modalities or their intermediate representations can be made available to the server. We further restrict our model training by preventing the egress of data labels to the cloud for better privacy, and instead use a contrastive learning based model objective. We evaluate our approach on two different multi-modal datasets and show promising results with our proposed approach.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.DC"
        ],
        "submitted_date": "3 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01619": {
        "title": "Spectrum AUC Difference (SAUCD): Human-aligned 3D Shape Evaluation",
        "authors": [
            "Tianyu Luan",
            "Zhong Li",
            "Lele Chen",
            "Xuan Gong",
            "Lichang Chen",
            "Yi Xu",
            "Junsong Yuan"
        ],
        "comments": "Accepted by CVPR 2024. Project page: this https URL",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Existing 3D mesh shape evaluation metrics mainly focus on the overall shape but are usually less sensitive to local details. This makes them inconsistent with human evaluation, as human perception cares about both overall and detailed shape. In this paper, we propose an analytic metric named Spectrum Area Under the Curve Difference (SAUCD) that demonstrates better consistency with human evaluation. To compare the difference between two shapes, we first transform the 3D mesh to the spectrum domain using the discrete Laplace-Beltrami operator and Fourier transform. Then, we calculate the Area Under the Curve (AUC) difference between the two spectrums, so that each frequency band that captures either the overall or detailed shape is equitably considered. Taking human sensitivity across frequency bands into account, we further extend our metric by learning suitable weights for each frequency band which better aligns with human perception. To measure the performance of SAUCD, we build a 3D mesh evaluation dataset called Shape Grading, along with manual annotations from more than 800 subjects. By measuring the correlation between our metric and human evaluation, we demonstrate that SAUCD is well aligned with human evaluation, and outperforms previous 3D mesh metrics.\n    ",
        "primary_category": "cs.CV",
        "categories": [
            "cs.GR"
        ],
        "submitted_date": "3 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01621": {
        "title": "Machine Learning vs Deep Learning: The Generalization Problem",
        "authors": [
            "Yong Yi Bay",
            "Kathleen A. Yearick"
        ],
        "comments": "10 pages, 2 figures",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "The capacity to generalize beyond the range of training data is a pivotal challenge, often synonymous with a model's utility and robustness. This study investigates the comparative abilities of traditional machine learning (ML) models and deep learning (DL) algorithms in terms of extrapolation -- a more challenging aspect of generalization because it requires the model to make inferences about data points that lie outside the domain it has been trained on. We present an empirical analysis where both ML and DL models are trained on an exponentially growing function and then tested on values outside the training domain. The choice of this function allows us to distinctly showcase the divergence in performance when models are required to predict beyond the scope of their training data. Our findings suggest that deep learning models possess inherent capabilities to generalize beyond the training scope, an essential feature for real-world applications where data is often incomplete or extends beyond the observed range. This paper argues for a nuanced understanding of the structural differences between ML and DL models, with an emphasis on the implications for both theoretical research and practical deployment.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "3 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01622": {
        "title": "A Human-Centered Approach for Bootstrapping Causal Graph Creation",
        "authors": [
            "Minh Q. Tram",
            "Nolan B. Gutierrez",
            "William J. Beksi"
        ],
        "comments": "To be presented at the 2024 ACM/IEEE International Conference on Human-Robot Interaction (HRI) Workshop on Causal Learning for Human-Robot Interaction (Causal-HRI)",
        "subjects": "Robotics (cs.RO)",
        "abstract": "Causal inference, a cornerstone in disciplines such as economics, genomics, and medicine, is increasingly being recognized as fundamental to advancing the field of robotics. In particular, the ability to reason about cause and effect from observational data is crucial for robust generalization in robotic systems. However, the construction of a causal graphical model, a mechanism for representing causal relations, presents an immense challenge. Currently, a nuanced grasp of causal inference, coupled with an understanding of causal relationships, must be manually programmed into a causal graphical model. To address this difficulty, we present initial results towards a human-centered augmented reality framework for creating causal graphical models. Concretely, our system bootstraps the causal discovery process by involving humans in selecting variables, establishing relationships, performing interventions, generating counterfactual explanations, and evaluating the resulting causal graph at every step. We highlight the potential of our framework via a physical robot manipulator on a pick-and-place task.\n    ",
        "primary_category": "cs.RO",
        "categories": [],
        "submitted_date": "3 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01623": {
        "title": "ML4PhySim : Machine Learning for Physical Simulations Challenge (The airfoil design)",
        "authors": [
            "Mouadh Yagoubi",
            "Milad Leyli-Abadi",
            "David Danan",
            "Jean-Patrick Brunet",
            "Jocelyn Ahmed Mazari",
            "Florent Bonnet",
            "Asma Farjallah",
            "Marc Schoenauer",
            "Patrick Gallinari"
        ],
        "comments": " ",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "The use of machine learning (ML) techniques to solve complex physical problems has been considered recently as a promising approach. However, the evaluation of such learned physical models remains an important issue for industrial use. The aim of this competition is to encourage the development of new ML techniques to solve physical problems using a unified evaluation framework proposed recently, called Learning Industrial Physical Simulations (LIPS). We propose learning a task representing a well-known physical use case: the airfoil design simulation, using a dataset called AirfRANS. The global score calculated for each submitted solution is based on three main categories of criteria covering different aspects, namely: ML-related, Out-Of-Distribution, and physical compliance criteria. To the best of our knowledge, this is the first competition addressing the use of ML-based surrogate approaches to improve the trade-off computational cost/accuracy of physical simulation.The competition is hosted by the Codabench platform with online training and evaluation of all submitted solutions.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.CE"
        ],
        "submitted_date": "3 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01626": {
        "title": "Using LLMs for Tabletop Exercises within the Security Domain",
        "authors": [
            "Sam Hays",
            "Dr. Jules White"
        ],
        "comments": "7 pages, 11 figures",
        "subjects": "Cryptography and Security (cs.CR)",
        "abstract": "Tabletop exercises are a crucial component of many company's strategy to test and evaluate its preparedness for security incidents in a realistic way. Traditionally led by external firms specializing in cybersecurity, these exercises can be costly, time-consuming, and may not always align precisely with the client's specific needs. Large Language Models (LLMs) like ChatGPT offer a compelling alternative. They enable faster iteration, provide rich and adaptable simulations, and offer infinite patience in handling feedback and recommendations. This approach can enhances the efficiency and relevance of security preparedness exercises.\n    ",
        "primary_category": "cs.CR",
        "categories": [],
        "submitted_date": "3 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01627": {
        "title": "Acceleration of digital memcomputing by jumps",
        "authors": [
            "Yuriy V. Pershin"
        ],
        "comments": " ",
        "subjects": "Emerging Technologies (cs.ET)",
        "abstract": "In this article, we present the potential benefits of incorporating jumps into the dynamics of digital memcomputing machines (DMMs), which have been developed to address complex optimization problems. We illustrate the potential speed improvement of a DMM solver with jumps over an unmodified DMM solver by solving Boolean satisfiability (SAT) problems of different complicatedness. Our findings suggest that jumps can modify scaling exponents and improve solving times by up to 75 %. Interestingly, the advantages of jumps can be seen in cases where the size of the jump is so large that otherwise the continuous dynamics of voltage variables becomes almost binary.\n    ",
        "primary_category": "cs.ET",
        "categories": [
            "nlin.CD"
        ],
        "submitted_date": "3 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01630": {
        "title": "Relational to RDF Data Migration by Query Co-Evaluation",
        "authors": [
            "Ryan Wisnesky",
            "Daniel Filonik"
        ],
        "comments": " ",
        "subjects": "Databases (cs.DB)",
        "abstract": "In this paper we define a new algorithm to convert an input relational database to an output set of RDF triples. The algorithm can be used to e.g. load CSV data into a financial OWL ontology such as FIBO. The algorithm takes as input a set of relational conjunctive (select-from-where) queries, one for each input table, from the three column (subject, predicate, object) output RDF schema to the input table's relational schema. The algorithm's output is the only set of RDF triples for which a unique round-trip of the input data under the relational queries exists. The output may contain blank nodes, is unique up to unique isomorphism, and can be obtained using elementary formal methods (equational theorem proving and term model construction specifically). We also describe how (generalized) homomorphisms between graphs can be used to write such relational conjunctive (select-from-where) queries, which, due to the lack of structure in the three-column RDF schema, tend to be large in practice. We demonstrate examples of both the algorithm and mapping language on the FIBO financial ontology.\n    ",
        "primary_category": "cs.DB",
        "categories": [],
        "submitted_date": "3 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01631": {
        "title": "TreeTracker Join: Turning the Tide When a Tuple Fails to Join",
        "authors": [
            "Zeyuan Hu",
            "Daniel P. Miranker"
        ],
        "comments": " ",
        "subjects": "Databases (cs.DB)",
        "abstract": "Many important query processing methods proactively use semijoins or semijoin-like filters to delete dangling tuples, i.e., tuples that do not appear in the final query result. Semijoin methods can achieve formal optimality but have high upfront cost in practice. Filter methods reduce the cost but lose the optimality guarantee.\nWe propose a new join algorithm, TreeTracker Join ($\\mathsf{TTJ}$), that achieves the data complexity optimality for acyclic conjunctive queries (ACQs) without semijoins or semijoin-like filters. $\\mathsf{TTJ}$ leverages join failure events, where a tuple from one of the relations of a binary join operator fails to match any tuples from the other relation. $\\mathsf{TTJ}$ starts join evaluation immediately and when join fails, $\\mathsf{TTJ}$ identifies the tuple as dangling and prevents it from further consideration in the execution of the query. The design of $\\mathsf{TTJ}$ exploits the connection between query evaluation and constraint satisfaction problem (CSP) by treating a join tree of an ACQ as a constraint network and the query evaluation as a CSP search problem. $\\mathsf{TTJ}$ is a direct extension of a CSP algorithm, TreeTracker, that embodies two search techniques backjumping and no-good. We establish that join tree and plan can be constructed from each other in order to incorporate the search techniques into physical operators in the iterator form. We compare $\\mathsf{TTJ}$ with hash-join, a classic semijoin method: Yannakakis's algorithm, and two contemporary filter methods: Predicate Transfer and Lookahead Information Passing. Favorable empirical results are developed using standard query benchmarks: JOB, TPC-H, and SSB.\n    ",
        "primary_category": "cs.DB",
        "categories": [],
        "submitted_date": "3 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01633": {
        "title": "Critical windows: non-asymptotic theory for feature emergence in diffusion models",
        "authors": [
            "Marvin Li",
            "Sitan Chen"
        ],
        "comments": " ",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "We develop theory to understand an intriguing property of diffusion models for image generation that we term critical windows. Empirically, it has been observed that there are narrow time intervals in sampling during which particular features of the final image emerge, e.g. the image class or background color (Ho et al., 2020b; Georgiev et al., 2023; Raya & Ambrogioni, 2023; Sclocchi et al., 2024; Biroli et al., 2024). While this is advantageous for interpretability as it implies one can localize properties of the generation to a small segment of the trajectory, it seems at odds with the continuous nature of the diffusion. We propose a formal framework for studying these windows and show that for data coming from a mixture of strongly log-concave densities, these windows can be provably bounded in terms of certain measures of inter- and intra-group separation. We also instantiate these bounds for concrete examples like well-conditioned Gaussian mixtures. Finally, we use our bounds to give a rigorous interpretation of diffusion models as hierarchical samplers that progressively \"decide\" output features over a discrete sequence of times. We validate our bounds with synthetic experiments. Additionally, preliminary experiments on Stable Diffusion suggest critical windows may serve as a useful tool for diagnosing fairness and privacy violations in real-world diffusion models.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.CV",
            "stat.ML"
        ],
        "submitted_date": "3 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01635": {
        "title": "Application of Neural Ordinary Differential Equations for Tokamak Plasma Dynamics Analysis",
        "authors": [
            "Zefang Liu",
            "Weston M. Stacey"
        ],
        "comments": "11 pages, 10 figures",
        "subjects": "Plasma Physics (physics.plasm-ph)",
        "abstract": "In the quest for controlled thermonuclear fusion, tokamaks present complex challenges in understanding burning plasma dynamics. This study introduces a multi-region multi-timescale transport model, employing Neural Ordinary Differential Equations (Neural ODEs) to simulate the intricate energy transfer processes within tokamaks. Our methodology leverages Neural ODEs for the numerical derivation of diffusivity parameters from DIII-D tokamak experimental data, enabling the precise modeling of energy interactions between electrons and ions across various regions, including the core, edge, and scrape-off layer. These regions are conceptualized as distinct nodes, capturing the critical timescales of radiation and transport processes essential for efficient tokamak operation. Validation against DIII-D plasmas under various auxiliary heating conditions demonstrates the model's effectiveness, ultimately shedding light on ways to enhance tokamak performance with deep learning.\n    ",
        "primary_category": "physics.plasm-ph",
        "categories": [
            "cs.LG"
        ],
        "submitted_date": "3 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01638": {
        "title": "Multi-level Product Category Prediction through Text Classification",
        "authors": [
            "Wesley Ferreira Maia",
            "Angelo Carmignani",
            "Gabriel Bortoli",
            "Lucas Maretti",
            "David Luz",
            "Daniel Camilo Fuentes Guzman",
            "Marcos Jardel Henriques",
            "Francisco Louzada Neto"
        ],
        "comments": " ",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "This article investigates applying advanced machine learning models, specifically LSTM and BERT, for text classification to predict multiple categories in the retail sector. The study demonstrates how applying data augmentation techniques and the focal loss function can significantly enhance accuracy in classifying products into multiple categories using a robust Brazilian retail dataset. The LSTM model, enriched with Brazilian word embedding, and BERT, known for its effectiveness in understanding complex contexts, were adapted and optimized for this specific task. The results showed that the BERT model, with an F1 Macro Score of up to $99\\%$ for segments, $96\\%$ for categories and subcategories and $93\\%$ for name products, outperformed LSTM in more detailed categories. However, LSTM also achieved high performance, especially after applying data augmentation and focal loss techniques. These results underscore the effectiveness of NLP techniques in retail and highlight the importance of the careful selection of modelling and preprocessing strategies. This work contributes significantly to the field of NLP in retail, providing valuable insights for future research and practical applications.\n    ",
        "primary_category": "cs.CL",
        "categories": [],
        "submitted_date": "3 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01639": {
        "title": "Theoretical Insights for Diffusion Guidance: A Case Study for Gaussian Mixture Models",
        "authors": [
            "Yuchen Wu",
            "Minshuo Chen",
            "Zihao Li",
            "Mengdi Wang",
            "Yuting Wei"
        ],
        "comments": "41 pages, 12 figures",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Diffusion models benefit from instillation of task-specific information into the score function to steer the sample generation towards desired properties. Such information is coined as guidance. For example, in text-to-image synthesis, text input is encoded as guidance to generate semantically aligned images. Proper guidance inputs are closely tied to the performance of diffusion models. A common observation is that strong guidance promotes a tight alignment to the task-specific information, while reducing the diversity of the generated samples. In this paper, we provide the first theoretical study towards understanding the influence of guidance on diffusion models in the context of Gaussian mixture models. Under mild conditions, we prove that incorporating diffusion guidance not only boosts classification confidence but also diminishes distribution diversity, leading to a reduction in the differential entropy of the output distribution. Our analysis covers the widely adopted sampling schemes including DDPM and DDIM, and leverages comparison inequalities for differential equations as well as the Fokker-Planck equation that characterizes the evolution of probability density function, which may be of independent theoretical interest.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "stat.ML"
        ],
        "submitted_date": "3 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01641": {
        "title": "AIO2: Online Correction of Object Labels for Deep Learning with Incomplete Annotation in Remote Sensing Image Segmentation",
        "authors": [
            "Chenying Liu",
            "Conrad M Albrecht",
            "Yi Wang",
            "Qingyu Li",
            "Xiao Xiang Zhu"
        ],
        "comments": "This work has been accepted by IEEE Transactions on Geoscience and Remote Sensing (TGRS)",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "While the volume of remote sensing data is increasing daily, deep learning in Earth Observation faces lack of accurate annotations for supervised optimization. Crowdsourcing projects such as OpenStreetMap distribute the annotation load to their community. However, such annotation inevitably generates noise due to insufficient control of the label quality, lack of annotators, frequent changes of the Earth's surface as a result of natural disasters and urban development, among many other factors. We present Adaptively trIggered Online Object-wise correction (AIO2) to address annotation noise induced by incomplete label sets. AIO2 features an Adaptive Correction Trigger (ACT) module that avoids label correction when the model training under- or overfits, and an Online Object-wise Correction (O2C) methodology that employs spatial information for automated label modification. AIO2 utilizes a mean teacher model to enhance training robustness with noisy labels to both stabilize the training accuracy curve for fitting in ACT and provide pseudo labels for correction in O2C. Moreover, O2C is implemented online without the need to store updated labels every training epoch. We validate our approach on two building footprint segmentation datasets with different spatial resolutions. Experimental results with varying degrees of building label noise demonstrate the robustness of AIO2. Source code will be available at this https URL.\n    ",
        "primary_category": "cs.CV",
        "categories": [],
        "submitted_date": "3 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01642": {
        "title": "Blue and Green-Mode Energy-Efficient Chemiresistive Sensor Array Realized by Rapid Ensemble Learning",
        "authors": [
            "Zeheng Wang",
            "James Cooper",
            "Muhammad Usman",
            "Timothy van der Laan"
        ],
        "comments": "First version before submission",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "The rapid advancement of Internet of Things (IoT) necessitates the development of optimized Chemiresistive Sensor (CRS) arrays that are both energy-efficient and capable. This study introduces a novel optimization strategy that employs a rapid ensemble learning-based model committee approach to achieve these goals. Utilizing machine learning models such as Elastic Net Regression, Random Forests, and XGBoost, among others, the strategy identifies the most impactful sensors in a CRS array for accurate classification: A weighted voting mechanism is introduced to aggregate the models' opinions in sensor selection, thereby setting up wo distinct working modes, termed \"Blue\" and \"Green\". The Blue mode operates with all sensors for maximum detection capability, while the Green mode selectively activates only key sensors, significantly reducing energy consumption without compromising detection accuracy. The strategy is validated through theoretical calculations and Monte Carlo simulations, demonstrating its effectiveness and accuracy. The proposed optimization strategy not only elevates the detection capability of CRS arrays but also brings it closer to theoretical limits, promising significant implications for the development of low-cost, easily fabricable next-generation IoT sensor terminals.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.CE",
            "eess.SY"
        ],
        "submitted_date": "3 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01643": {
        "title": "You Need to Pay Better Attention",
        "authors": [
            "Mehran Hosseini",
            "Peyman Hosseini"
        ],
        "comments": " ",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "We introduce three new attention mechanisms that outperform standard multi-head attention in terms of efficiency and learning capabilities, thereby improving the performance and broader deployability of Transformer models. Our first contribution is Optimised Attention, which performs similarly to standard attention, but has 3/4 as many parameters and one matrix multiplication fewer per head. Next, we introduce Efficient Attention, which performs on par with standard attention with only 1/2 as many parameters as many parameters and two matrix multiplications fewer per head and is up to twice as fast as standard attention. Lastly, we introduce Super Attention, which surpasses standard attention by a significant margin in both vision and natural language processing tasks while having fewer parameters and matrix multiplications. In addition to providing rigorous mathematical comparisons, we evaluate the presented attention mechanisms on MNIST, CIFAR100, IMDB Movie Reviews, and Amazon Reviews datasets.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.AI",
            "cs.CL",
            "cs.CV"
        ],
        "submitted_date": "3 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01646": {
        "title": "TweetInfo: An Interactive System to Mitigate Online Harm",
        "authors": [
            "Gautam Kishore Shahi"
        ],
        "comments": "3 pages",
        "subjects": "Social and Information Networks (cs.SI)",
        "abstract": "The increase in active users on social networking sites (SNSs) has also observed an increase in harmful content on social media sites. Harmful content is described as an inappropriate activity to harm or deceive an individual or a group of users. Alongside existing methods to detect misinformation and hate speech, users still need to be well-informed about the harmfulness of the content on SNSs. This study proposes a user-interactive system TweetInfo for mitigating the consumption of harmful content by providing metainformation about the posts. It focuses on two types of harmful content: hate speech and misinformation. TweetInfo provides insights into tweets by doing content analysis. Based on previous research, we have selected a list of metainformation. We offer the option to filter content based on metainformation Bot, Hate Speech, Misinformation, Verified Account, Sentiment, Tweet Category, Language. The proposed user interface allows customising the user's timeline to mitigate harmful content. This study present the demo version of the propose user interface of TweetInfo.\n    ",
        "primary_category": "cs.SI",
        "categories": [
            "cs.HC",
            "cs.IR"
        ],
        "submitted_date": "3 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01647": {
        "title": "Neural Network Assisted Lifting Steps For Improved Fully Scalable Lossy Image Compression in JPEG 2000",
        "authors": [
            "Xinyue Li",
            "Aous Naman",
            "David Taubman"
        ],
        "comments": "This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "This work proposes to augment the lifting steps of the conventional wavelet transform with additional neural network assisted lifting steps. These additional steps reduce residual redundancy (notably aliasing information) amongst the wavelet subbands, and also improve the visual quality of reconstructed images at reduced resolutions. The proposed approach involves two steps, a high-to-low step followed by a low-to-high step. The high-to-low step suppresses aliasing in the low-pass band by using the detail bands at the same resolution, while the low-to-high step aims to further remove redundancy from detail bands, so as to achieve higher energy compaction. The proposed two lifting steps are trained in an end-to-end fashion; we employ a backward annealing approach to overcome the non-differentiability of the quantization and cost functions during back-propagation. Importantly, the networks employed in this paper are compact and with limited non-linearities, allowing a fully scalable system; one pair of trained network parameters are applied for all levels of decomposition and for all bit-rates of interest. By employing the proposed approach within the JPEG 2000 image coding standard, our method can achieve up to 17.4% average BD bit-rate saving over a wide range of bit-rates, while retaining quality and resolution scalability features of JPEG 2000.\n    ",
        "primary_category": "cs.CV",
        "categories": [
            "eess.IV"
        ],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01648": {
        "title": "\"I just hated it and I want my money back\": Data-driven Understanding of Mobile VPN Service Switching Preferences in The Wild",
        "authors": [
            "Rohit Raj",
            "Mridul Newar",
            "Mainack Mondal"
        ],
        "comments": "This extended version of our USENIX Security '24 paper on users' VPN-switching behavior includes appendices for interested readers",
        "subjects": "Cryptography and Security (cs.CR)",
        "abstract": "Virtual Private Networks (VPNs) are a crucial Privacy-Enhancing Technology (PET) leveraged by millions of users and catered by multiple VPN providers worldwide; thus, understanding the user preferences for the choice of VPN apps should be of importance and interest to the security community. To that end, prior studies looked into the usage, awareness and adoption of VPN users and the perceptions of providers. However, no study so far has looked into the user preferences and underlying reasons for switching among VPN providers and identified features that presumably enhance users' VPN experience. This work aims to bridge this gap and shed light on the underlying factors that drive existing users when they switch from one VPN to another. In this work, we analyzed over 1.3 million reviews from 20 leading VPN apps, identifying 1,305 explicit mentions and intents to switch. Our NLP-based analysis unveiled distinct clusters of factors motivating users to switch. An examination of 376 blogs from six popular VPN recommendation sites revealed biases in the content, and we found ignorance towards user preferences. We conclude by identifying the key implications of our work for different stakeholders. The data and code for this work is available at this https URL.\n    ",
        "primary_category": "cs.CR",
        "categories": [
            "cs.HC"
        ],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01649": {
        "title": "Recommendations for Government Development and Use of Advanced Automated Systems to Make Decisions about Individuals",
        "authors": [
            "Susan Landau",
            "James X. Dempsey",
            "Ece Kamar",
            "Steven M. Bellovin"
        ],
        "comments": " ",
        "subjects": "Computers and Society (cs.CY)",
        "abstract": "Contestability -- the ability to effectively challenge a decision -- is critical to the implementation of fairness. In the context of governmental decision making about individuals, contestability is often constitutionally required as an element of due process; specific procedures may be required by state or federal law relevant to a particular program. In addition, contestability can be a valuable way to discover systemic errors, contributing to ongoing assessments and system improvement.\nOn January 24-25, 2024, with support from the National Science Foundation and the William and Flora Hewlett Foundation, we convened a diverse group of government officials, representatives of leading technology companies, technology and policy experts from academia and the non-profit sector, advocates, and stakeholders for a workshop on advanced automated decision making, contestability, and the law. Informed by the workshop's rich and wide-ranging discussion, we offer these recommendations. A full report summarizing the discussion is in preparation.\n    ",
        "primary_category": "cs.CY",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01652": {
        "title": "Towards Memory-Efficient Traffic Policing in Time-Sensitive Networking",
        "authors": [
            "Xuyan Jiang",
            "Xiangrui Yang",
            "Tongqing Zhou",
            "Wenwen Fu",
            "Wei Quan",
            "Yihao Jiao",
            "Yinhan Sun",
            "Zhigang Sun"
        ],
        "comments": " ",
        "subjects": "Networking and Internet Architecture (cs.NI)",
        "abstract": "Time-Sensitive Networking (TSN) is an emerging real-time Ethernet technology that provides deterministic communication for time-critical traffic. At its core, TSN relies on Time-Aware Shaper (TAS) for pre-allocating frames in specific time intervals and Per-Stream Filtering and Policing (PSFP) for mitigating the fatal disturbance of unavoidable frame drift. However, as first identified in this work, PSFP incurs heavy memory consumption during policing, hindering normal switching functionalities.\nThis work proposes a lightweight policing design called FooDog, which could facilitate sub-microsecond jitter with ultra-low memory consumption. FooDog employs a period-wise and stream-wise structure to realize the memory-efficient PSFP without loss of determinism. Results using commercial FPGAs in typical aerospace scenarios show that FooDog could keep end-to-end time-sensitive traffic jitter <150 nanoseconds in the presence of abnormal traffic, comparable to typical TSN performance without anomalies. Meanwhile, it consumes merely hundreds of kilobits of memory, reducing >90% of on-chip memory overheads than unoptimized PSFP design.\n    ",
        "primary_category": "cs.NI",
        "categories": [],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01653": {
        "title": "Day-ahead regional solar power forecasting with hierarchical temporal convolutional neural networks using historical power generation and weather data",
        "authors": [
            "Maneesha Perera",
            "Julian De Hoog",
            "Kasun Bandara",
            "Damith Senanayake",
            "Saman Halgamuge"
        ],
        "comments": "37 pages, 16 figures, Accepted to the journal of Applied Energy",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Regional solar power forecasting, which involves predicting the total power generation from all rooftop photovoltaic systems in a region holds significant importance for various stakeholders in the energy sector. However, the vast amount of solar power generation and weather time series from geographically dispersed locations that need to be considered in the forecasting process makes accurate regional forecasting challenging. Therefore, previous work has limited the focus to either forecasting a single time series (i.e., aggregated time series) which is the addition of all solar generation time series in a region, disregarding the location-specific weather effects or forecasting solar generation time series of each PV site (i.e., individual time series) independently using location-specific weather data, resulting in a large number of forecasting models. In this work, we propose two deep-learning-based regional forecasting methods that can effectively leverage both types of time series (aggregated and individual) with weather data in a region. We propose two hierarchical temporal convolutional neural network architectures (HTCNN) and two strategies to adapt HTCNNs for regional solar power forecasting. At first, we explore generating a regional forecast using a single HTCNN. Next, we divide the region into multiple sub-regions based on weather information and train separate HTCNNs for each sub-region; the forecasts of each sub-region are then added to generate a regional forecast. The proposed work is evaluated using a large dataset collected over a year from 101 locations across Western Australia to provide a day ahead forecast. We compare our approaches with well-known alternative methods and show that the sub-region HTCNN requires fewer individual networks and achieves a forecast skill score of 40.2% reducing a statistically significant error by 6.5% compared to the best counterpart.\n    ",
        "primary_category": "cs.LG",
        "categories": [],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01655": {
        "title": "Bayesian inference via geometric optics approximation",
        "authors": [
            "Zejun Sun",
            "Guang-Hui Zheng"
        ],
        "comments": " ",
        "subjects": "Numerical Analysis (math.NA)",
        "abstract": "Markov chain Monte Carlo (MCMC) simulations have been widely used to generate samples from the complex posterior distribution in Bayesian inferences. However, these simulations often require multiple computations of the forward model in the likelihood function for each drawn sample. This computational burden renders MCMC sampling impractical when the forward model is computationally expensive, such as in the case of partial differential equation models. In this paper, we propose a novel sampling approach called the geometric optics approximation method (GOAM) for Bayesian inverse problems, which entirely circumvents the need for MCMC simulations. Our method is rooted in the problem of reflector shape design, which focuses on constructing a reflecting surface that redirects rays from a source, with a predetermined density, towards a target domain while achieving a desired density distribution. The key idea is to consider the unnormalized Bayesian posterior as the density on the target domain within the optical system and define a geometric optics approximation measure with respect to posterior by a reflecting surface. Consequently, once such a reflecting surface is obtained, we can utilize it to draw an arbitrary number of independent and uncorrelated samples from the posterior measure for Bayesian inverse problems. In theory, we have shown that the geometric optics approximation measure is well-posed. The efficiency and robustness of our proposed sampler, employing the geometric optics approximation method, are demonstrated through several numerical examples provided in this paper.\n    ",
        "primary_category": "math.NA",
        "categories": [
            "math.ST"
        ],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01657": {
        "title": "Generalized pair-wise logit dynamic and its connection to a mean field game: theoretical and computational investigations focusing on resource management",
        "authors": [
            "Hidekazu Yoshioka",
            "Motoh Tsujimura"
        ],
        "comments": " ",
        "subjects": "Optimization and Control (math.OC)",
        "abstract": "Logit dynamics are evolution equations that describe transitions to equilibria of actions among many players. We formulate a pair-wise logit dynamic in a continuous action space with a generalized exponential function, which we call a generalized pair-wise logit dynamic, depicted by a new evolution equation nonlocal in space. We prove the well-posedness and approximability of the generalized pair-wise logit dynamic to show that it is computationally implementable. We also show that this dynamic has an explicit connection to a mean field game of a controlled pure-jump process, with which the two different mathematical models can be understood in a unified way. Particularly, we show that the generalized pair-wise logit dynamic is derived as a myopic version of the corresponding mean field game, and that the conditions to guarantee the existence of unique solutions are different from each other. The key in this procedure is to find the objective function to be optimized in the mean field game based on the logit function. The monotonicity of the utility is unnecessary for the generalized pair-wise logit dynamic but crucial for the mean field game. Finally, we present applications of the two approaches to fisheries management problems with collected data.\n    ",
        "primary_category": "math.OC",
        "categories": [
            "eess.SY",
            "math.NA"
        ],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01660": {
        "title": "Geometry and Stability of Supervised Learning Problems",
        "authors": [
            "Facundo M\u00e9moli",
            "Brantley Vose",
            "Robert C. Williamson"
        ],
        "comments": "87 pages",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "We introduce a notion of distance between supervised learning problems, which we call the Risk distance. This optimal-transport-inspired distance facilitates stability results; one can quantify how seriously issues like sampling bias, noise, limited data, and approximations might change a given problem by bounding how much these modifications can move the problem under the Risk distance. With the distance established, we explore the geometry of the resulting space of supervised learning problems, providing explicit geodesics and proving that the set of classification problems is dense in a larger class of problems. We also provide two variants of the Risk distance: one that incorporates specified weights on a problem's predictors, and one that is more sensitive to the contours of a problem's risk landscape.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "math.MG"
        ],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01662": {
        "title": "Atropos-k is PSPACE-complete",
        "authors": [
            "Chao Yang",
            "Zhujun Zhang"
        ],
        "comments": " ",
        "subjects": "Computational Complexity (cs.CC)",
        "abstract": "Burke and Teng introduced a two-player combinatorial game Atropos based on Sperner's lemma, and showed that deciding whether one has a winning strategy for Atropos is PSPACE-complete. In the original Atropos game, the players must color a node adjacent to the last colored node. Burke and Teng also mentioned a variant Atropos-k in which each move is at most of distance k of the previous move, and asked a question on determining the computational complexity of this variant. In this paper, we answer this question by showing that for any fixed integer k (k>=2), Atropos-k is PSPACE-complete by reduction from True Quantified Boolean Formula (TQBF).\n    ",
        "primary_category": "cs.CC",
        "categories": [
            "cs.DM",
            "math.CO"
        ],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01666": {
        "title": "Improving Adversarial Energy-Based Model via Diffusion Process",
        "authors": [
            "Cong Geng",
            "Tian Han",
            "Peng-Tao Jiang",
            "Hao Zhang",
            "Jinwei Chen",
            "S\u00f8ren Hauberg",
            "Bo Li"
        ],
        "comments": " ",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Generative models have shown strong generation ability while efficient likelihood estimation is less explored. Energy-based models~(EBMs) define a flexible energy function to parameterize unnormalized densities efficiently but are notorious for being difficult to train. Adversarial EBMs introduce a generator to form a minimax training game to avoid expensive MCMC sampling used in traditional EBMs, but a noticeable gap between adversarial EBMs and other strong generative models still exists. Inspired by diffusion-based models, we embedded EBMs into each denoising step to split a long-generated process into several smaller steps. Besides, we employ a symmetric Jeffrey divergence and introduce a variational posterior distribution for the generator's training to address the main challenges that exist in adversarial EBMs. Our experiments show significant improvement in generation compared to existing adversarial EBMs, while also providing a useful energy function for efficient density estimation.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.CV"
        ],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01669": {
        "title": "Quantifying and Predicting Residential Building Flexibility Using Machine Learning Methods",
        "authors": [
            "Patrick Salter",
            "Qiuhua Huang",
            "Paulo Cesar Tabares-Velasco"
        ],
        "comments": " ",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Residential buildings account for a significant portion (35\\%) of the total electricity consumption in the U.S. as of 2022. As more distributed energy resources are installed in buildings, their potential to provide flexibility to the grid increases. To tap into that flexibility provided by buildings, aggregators or system operators need to quantify and forecast flexibility. Previous works in this area primarily focused on commercial buildings, with little work on residential buildings. To address the gap, this paper first proposes two complementary flexibility metrics (i.e., power and energy flexibility) and then investigates several mainstream machine learning-based models for predicting the time-variant and sporadic flexibility of residential buildings at four-hour and 24-hour forecast horizons. The long-short-term-memory (LSTM) model achieves the best performance and can predict power flexibility for up to 24 hours ahead with the average error around 0.7 kW. However, for energy flexibility, the LSTM model is only successful for loads with consistent operational patterns throughout the year and faces challenges when predicting energy flexibility associated with HVAC systems.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "eess.SY"
        ],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01670": {
        "title": "6DoF SELD: Sound Event Localization and Detection Using Microphones and Motion Tracking Sensors on self-motioning human",
        "authors": [
            "Masahiro Yasuda",
            "Shoichiro Saito",
            "Akira Nakayama",
            "Noboru Harada"
        ],
        "comments": "ICASSP2024 accepted",
        "subjects": "Audio and Speech Processing (eess.AS)",
        "abstract": "We aim to perform sound event localization and detection (SELD) using wearable equipment for a moving human, such as a pedestrian. Conventional SELD tasks have dealt only with microphone arrays located in static positions. However, self-motion with three rotational and three translational degrees of freedom (6DoF) shall be considered for wearable microphone arrays. A system trained only with a dataset using microphone arrays in a fixed position would be unable to adapt to the fast relative motion of sound events associated with self-motion, resulting in the degradation of SELD performance. To address this, we designed 6DoF SELD Dataset for wearable systems, the first SELD dataset considering the self-motion of microphones. Furthermore, we proposed a multi-modal SELD system that jointly utilizes audio and motion tracking sensor signals. These sensor signals are expected to help the system find useful acoustic cues for SELD on the basis of the current self-motion state. Experimental results on our dataset show that the proposed method effectively improves SELD performance with a mechanism to extract acoustic features conditioned by sensor signals.\n    ",
        "primary_category": "eess.AS",
        "categories": [
            "cs.SD"
        ],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01671": {
        "title": "Permutation invariant functions: statistical tests, dimension reduction in metric entropy and estimation",
        "authors": [
            "Wee Chaimanowong",
            "Ying Zhu"
        ],
        "comments": "24 pages, 3 figures",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Permutation invariance is among the most common symmetry that can be exploited to simplify complex problems in machine learning (ML). There has been a tremendous surge of research activities in building permutation invariant ML architectures. However, less attention is given to how to statistically test for permutation invariance of variables in a multivariate probability distribution where the dimension is allowed to grow with the sample size. Also, in terms of a statistical theory, little is known about how permutation invariance helps with estimation in reducing dimensions. In this paper, we take a step back and examine these questions in several fundamental problems: (i) testing the assumption of permutation invariance of multivariate distributions; (ii) estimating permutation invariant densities; (iii) analyzing the metric entropy of smooth permutation invariant function classes and compare them with their counterparts without imposing permutation invariance; (iv) kernel ridge regression of permutation invariant functions in reproducing kernel Hilbert space. In particular, our methods for (i) and (iv) are based on a sorting trick and (ii) is based on an averaging trick. These tricks substantially simplify the exploitation of permutation invariance.\n    ",
        "primary_category": "cs.LG",
        "categories": [],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01673": {
        "title": "CATS: Enhancing Multivariate Time Series Forecasting by Constructing Auxiliary Time Series as Exogenous Variables",
        "authors": [
            "Jiecheng Lu",
            "Xu Han",
            "Yan Sun",
            "Shihao Yang"
        ],
        "comments": " ",
        "subjects": "Machine Learning (stat.ML)",
        "abstract": "For Multivariate Time Series Forecasting (MTSF), recent deep learning applications show that univariate models frequently outperform multivariate ones. To address the difficiency in multivariate models, we introduce a method to Construct Auxiliary Time Series (CATS) that functions like a 2D temporal-contextual attention mechanism, which generates Auxiliary Time Series (ATS) from Original Time Series (OTS) to effectively represent and incorporate inter-series relationships for forecasting. Key principles of ATS - continuity, sparsity, and variability - are identified and implemented through different modules. Even with a basic 2-layer MLP as core predictor, CATS achieves state-of-the-art, significantly reducing complexity and parameters compared to previous multivariate models, marking it an efficient and transferable MTSF solution.\n    ",
        "primary_category": "stat.ML",
        "categories": [
            "cs.AI",
            "cs.LG"
        ],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01674": {
        "title": "ASPIRe: An Informative Trajectory Planner with Mutual Information Approximation for Target Search and Tracking",
        "authors": [
            "Kangjie Zhou",
            "Pengying Wu",
            "Yao Su",
            "Han Gao",
            "Ji Ma",
            "Hangxin Liu",
            "Chang Liu"
        ],
        "comments": "accepted to ICRA 2024",
        "subjects": "Robotics (cs.RO)",
        "abstract": "This paper proposes an informative trajectory planning approach, namely, \\textit{adaptive particle filter tree with sigma point-based mutual information reward approximation} (ASPIRe), for mobile target search and tracking (SAT) in cluttered environments with limited sensing field of view. We develop a novel sigma point-based approximation to accurately estimate mutual information (MI) for general, non-Gaussian distributions utilizing particle representation of the belief state, while simultaneously maintaining high computational efficiency. Building upon the MI approximation, we develop the Adaptive Particle Filter Tree (APFT) approach with MI as the reward, which features belief state tree nodes for informative trajectory planning in continuous state and measurement spaces. An adaptive criterion is proposed in APFT to adjust the planning horizon based on the expected information gain. Simulations and physical experiments demonstrate that ASPIRe achieves real-time computation and outperforms benchmark methods in terms of both search efficiency and estimation accuracy.\n    ",
        "primary_category": "cs.RO",
        "categories": [],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01680": {
        "title": "Zero-shot Generalizable Incremental Learning for Vision-Language Object Detection",
        "authors": [
            "Jieren Deng",
            "Haojian Zhang",
            "Kun Ding",
            "Jianhua Hu",
            "Xingxuan Zhang",
            "Yunkuan Wang"
        ],
        "comments": " ",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "This paper presents Incremental Vision-Language Object Detection (IVLOD), a novel learning task designed to incrementally adapt pre-trained Vision-Language Object Detection Models (VLODMs) to various specialized domains, while simultaneously preserving their zero-shot generalization capabilities for the generalized domain. To address this new challenge, we present the Zero-interference Reparameterizable Adaptation (ZiRa), a novel method that introduces Zero-interference Loss and reparameterization techniques to tackle IVLOD without incurring additional inference costs or a significant increase in memory usage. Comprehensive experiments on COCO and ODinW-13 datasets demonstrate that ZiRa effectively safeguards the zero-shot generalization ability of VLODMs while continuously adapting to new tasks. Specifically, after training on ODinW-13 datasets, ZiRa exhibits superior performance compared to CL-DETR and iDETR, boosting zero-shot generalizability by substantial 13.91 and 8.71 AP, respectively.\n    ",
        "primary_category": "cs.CV",
        "categories": [],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01690": {
        "title": "Singular value decompositions of third-order reduced biquaternion tensors",
        "authors": [
            "Cui-E Yu",
            "Xin Liu",
            "Yang Zhang"
        ],
        "comments": " ",
        "subjects": "Numerical Analysis (math.NA)",
        "abstract": "In this paper, we introduce the applications of third-order reduced biquaternion tensors in color video processing. We first develop algorithms for computing the singular value decomposition (SVD) of a third-order reduced biquaternion tensor via a new Ht-product. As theoretical applications, we define the Moore-Penrose inverse of a third-order reduced biquaternion tensor and develop its characterizations. In addition, we discuss the general (or Hermitian) solutions to reduced biquaternion tensor equation $\\mathcal{A}\\ast_{Ht} \\mathcal{X}=\\mathcal{B}$ as well as its least-square solution. Finally, we compress the color video by this SVD, and the experimental data shows that our method is faster than the compared scheme.\n    ",
        "primary_category": "math.NA",
        "categories": [],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01692": {
        "title": "PI-AstroDeconv: A Physics-Informed Unsupervised Learning Method for Astronomical Image Deconvolution",
        "authors": [
            "Shulei Ni",
            "Yisheng Qiu",
            "Yunchun Chen",
            "Zihao Song",
            "Hao Chen",
            "Xuejian Jiang",
            "Huaxi Chen"
        ],
        "comments": " ",
        "subjects": "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
        "abstract": "In the imaging process of an astronomical telescope, the deconvolution of its beam or Point Spread Function (PSF) is a crucial task. However, deconvolution presents a classical and challenging inverse computation problem. In scenarios where the beam or PSF is complex or inaccurately measured, such as in interferometric arrays and certain radio telescopes, the resultant blurry images are often challenging to interpret visually or analyze using traditional physical detection methods. We argue that traditional methods frequently lack specific prior knowledge, thereby leading to suboptimal performance. To address this issue and achieve image deconvolution and reconstruction, we propose an unsupervised network architecture that incorporates prior physical information. The network adopts an encoder-decoder structure while leveraging the telescope's PSF as prior knowledge. During network training, we introduced accelerated Fast Fourier Transform (FFT) convolution to enable efficient processing of high-resolution input images and PSFs. We explored various classic regression networks, including autoencoder (AE) and U-Net, and conducted a comprehensive performance evaluation through comparative analysis.\n    ",
        "primary_category": "astro-ph.IM",
        "categories": [
            "astro-ph.GA",
            "cs.CV",
            "eess.IV"
        ],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01694": {
        "title": "Tac-Man: Tactile-Informed Prior-Free Manipulation of Articulated Objects",
        "authors": [
            "Zihang Zhao",
            "Yuyang Li",
            "Wanlin Li",
            "Zhenghao Qi",
            "Lecheng Ruan",
            "Yixin Zhu",
            "Kaspar Althoefer"
        ],
        "comments": "18 pages, 13 figures, 5 tables",
        "subjects": "Robotics (cs.RO)",
        "abstract": "Integrating robotics into human-centric environments such as homes, necessitates advanced manipulation skills as robotic devices will need to engage with articulated objects like doors and drawers. Key challenges in robotic manipulation are the unpredictability and diversity of these objects' internal structures, which render models based on priors, both explicit and implicit, inadequate. Their reliability is significantly diminished by pre-interaction ambiguities, imperfect structural parameters, encounters with unknown objects, and unforeseen disturbances. Here, we present a prior-free strategy, Tac-Man, focusing on maintaining stable robot-object contact during manipulation. Utilizing tactile feedback, but independent of object priors, Tac-Man enables robots to proficiently handle a variety of articulated objects, including those with complex joints, even when influenced by unexpected disturbances. Demonstrated in both real-world experiments and extensive simulations, it consistently achieves near-perfect success in dynamic and varied settings, outperforming existing methods. Our results indicate that tactile sensing alone suffices for managing diverse articulated objects, offering greater robustness and generalization than prior-based approaches. This underscores the importance of detailed contact modeling in complex manipulation tasks, especially with articulated objects. Advancements in tactile sensors significantly expand the scope of robotic applications in human-centric environments, particularly where accurate models are difficult to obtain.\n    ",
        "primary_category": "cs.RO",
        "categories": [],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01695": {
        "title": "DyCE: Dynamic Configurable Exiting for Deep Learning Compression and Scaling",
        "authors": [
            "Qingyuan Wang",
            "Barry Cardiff",
            "Antoine Frapp\u00e9",
            "Benoit Larras",
            "Deepu John"
        ],
        "comments": " ",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Modern deep learning (DL) models necessitate the employment of scaling and compression techniques for effective deployment in resource-constrained environments. Most existing techniques, such as pruning and quantization are generally static. On the other hand, dynamic compression methods, such as early exits, reduce complexity by recognizing the difficulty of input samples and allocating computation as needed. Dynamic methods, despite their superior flexibility and potential for co-existing with static methods, pose significant challenges in terms of implementation due to any changes in dynamic parts will influence subsequent processes. Moreover, most current dynamic compression designs are monolithic and tightly integrated with base models, thereby complicating the adaptation to novel base models. This paper introduces DyCE, an dynamic configurable early-exit framework that decouples design considerations from each other and from the base model. Utilizing this framework, various types and positions of exits can be organized according to predefined configurations, which can be dynamically switched in real-time to accommodate evolving performance-complexity requirements. We also propose techniques for generating optimized configurations based on any desired trade-off between performance and computational complexity. This empowers future researchers to focus on the improvement of individual exits without latent compromise of overall system performance. The efficacy of this approach is demonstrated through image classification tasks with deep CNNs. DyCE significantly reduces the computational complexity by 23.5% of ResNet152 and 25.9% of ConvNextv2-tiny on ImageNet, with accuracy reductions of less than 0.5%. Furthermore, DyCE offers advantages over existing dynamic methods in terms of real-time configuration and fine-grained performance tuning.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01697": {
        "title": "Dismantling Gender Blindness in Online Discussion of a Crime/Gender Dichotomy",
        "authors": [
            "Yigang Qin",
            "Weilun Duan",
            "Qunfang Wu",
            "Zhicong Lu"
        ],
        "comments": "31 pages, 3 figures, Accepted for publication in Proceedings of the ACM on Human-Computer Interaction (CSCW 2024)",
        "subjects": "Human-Computer Interaction (cs.HC)",
        "abstract": "Contemporary feminists utilize social media for activism, while backlashes come along. The gender-related discourses are often diminished when addressing public events regarding sexism and gender inequality on social media platforms. The dichotomized debate around the Tangshan beating incident in China epitomized how criminal interpretations of gender-related violence became a backlash against feminist expressions. By analyzing posts on Weibo using mixed methods, we describe the emerging discursive patterns around crime and gender, uncovering the inherent gender-blind sexism that refutes feminist discourses on the social platform. We also highlight the critical restrictions facing grassroots feminist activism in Chinese cyberspace and propose implications for the design and research related to digital feminist activism.\n    ",
        "primary_category": "cs.HC",
        "categories": [],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01698": {
        "title": "Hypertext Entity Extraction in Webpage",
        "authors": [
            "Yifei Yang",
            "Tianqiao Liu",
            "Bo Shao",
            "Hai Zhao",
            "Linjun Shou",
            "Ming Gong",
            "Daxin Jiang"
        ],
        "comments": " ",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "Webpage entity extraction is a fundamental natural language processing task in both research and applications. Nowadays, the majority of webpage entity extraction models are trained on structured datasets which strive to retain textual content and its structure information. However, existing datasets all overlook the rich hypertext features (e.g., font color, font size) which show their effectiveness in previous works. To this end, we first collect a \\textbf{H}ypertext \\textbf{E}ntity \\textbf{E}xtraction \\textbf{D}ataset (\\textit{HEED}) from the e-commerce domains, scraping both the text and the corresponding explicit hypertext features with high-quality manual entity annotations. Furthermore, we present the \\textbf{Mo}E-based \\textbf{E}ntity \\textbf{E}xtraction \\textbf{F}ramework (\\textit{MoEEF}), which efficiently integrates multiple features to enhance model performance by Mixture of Experts and outperforms strong baselines, including the state-of-the-art small-scale models and GPT-3.5-turbo. Moreover, the effectiveness of hypertext features in \\textit{HEED} and several model components in \\textit{MoEEF} are analyzed.\n    ",
        "primary_category": "cs.CL",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01700": {
        "title": "Robust Wake Word Spotting With Frame-Level Cross-Modal Attention Based Audio-Visual Conformer",
        "authors": [
            "Haoxu Wang",
            "Ming Cheng",
            "Qiang Fu",
            "Ming Li"
        ],
        "comments": "Accepted by ICASSP 2024",
        "subjects": "Sound (cs.SD)",
        "abstract": "In recent years, neural network-based Wake Word Spotting achieves good performance on clean audio samples but struggles in noisy environments. Audio-Visual Wake Word Spotting (AVWWS) receives lots of attention because visual lip movement information is not affected by complex acoustic scenes. Previous works usually use simple addition or concatenation for multi-modal fusion. The inter-modal correlation remains relatively under-explored. In this paper, we propose a novel module called Frame-Level Cross-Modal Attention (FLCMA) to improve the performance of AVWWS systems. This module can help model multi-modal information at the frame-level through synchronous lip movements and speech signals. We train the end-to-end FLCMA based Audio-Visual Conformer and further improve the performance by fine-tuning pre-trained uni-modal models for the AVWWS task. The proposed system achieves a new state-of-the-art result (4.57% WWS score) on the far-field MISP dataset.\n    ",
        "primary_category": "cs.SD",
        "categories": [
            "cs.MM",
            "eess.AS"
        ],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01709": {
        "title": "Can LLMs Generate Architectural Design Decisions? -An Exploratory Empirical study",
        "authors": [
            "Rudra Dhar",
            "Karthik Vaidhyanathan",
            "Vasudeva Varma"
        ],
        "comments": "This paper has been accepted to IEEE ICSA 2024 (Main Track - Research Track)",
        "subjects": "Software Engineering (cs.SE)",
        "abstract": "Architectural Knowledge Management (AKM) involves the organized handling of information related to architectural decisions and design within a project or organization. An essential artifact of AKM is the Architecture Decision Records (ADR), which documents key design decisions. ADRs are documents that capture decision context, decision made and various aspects related to a design decision, thereby promoting transparency, collaboration, and understanding. Despite their benefits, ADR adoption in software development has been slow due to challenges like time constraints and inconsistent uptake. Recent advancements in Large Language Models (LLMs) may help bridge this adoption gap by facilitating ADR generation. However, the effectiveness of LLM for ADR generation or understanding is something that has not been explored. To this end, in this work, we perform an exploratory study that aims to investigate the feasibility of using LLM for the generation of ADRs given the decision context. In our exploratory study, we utilize GPT and T5-based models with 0-shot, few-shot, and fine-tuning approaches to generate the Decision of an ADR given its Context. Our results indicate that in a 0-shot setting, state-of-the-art models such as GPT-4 generate relevant and accurate Design Decisions, although they fall short of human-level performance. Additionally, we observe that more cost-effective models like GPT-3.5 can achieve similar outcomes in a few-shot setting, and smaller models such as Flan-T5 can yield comparable results after fine-tuning. To conclude, this exploratory study suggests that LLM can generate Design Decisions, but further research is required to attain human-level generation and establish standardized widespread adoption.\n    ",
        "primary_category": "cs.SE",
        "categories": [
            "cs.AI",
            "cs.LG"
        ],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01713": {
        "title": "MCA: Moment Channel Attention Networks",
        "authors": [
            "Yangbo Jiang",
            "Zhiwei Jiang",
            "Le Han",
            "Zenan Huang",
            "Nenggan Zheng"
        ],
        "comments": " ",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Channel attention mechanisms endeavor to recalibrate channel weights to enhance representation abilities of networks. However, mainstream methods often rely solely on global average pooling as the feature squeezer, which significantly limits the overall potential of models. In this paper, we investigate the statistical moments of feature maps within a neural network. Our findings highlight the critical role of high-order moments in enhancing model capacity. Consequently, we introduce a flexible and comprehensive mechanism termed Extensive Moment Aggregation (EMA) to capture the global spatial context. Building upon this mechanism, we propose the Moment Channel Attention (MCA) framework, which efficiently incorporates multiple levels of moment-based information while minimizing additional computation costs through our Cross Moment Convolution (CMC) module. The CMC module via channel-wise convolution layer to capture multiple order moment information as well as cross channel features. The MCA block is designed to be lightweight and easily integrated into a variety of neural network architectures. Experimental results on classical image classification, object detection, and instance segmentation tasks demonstrate that our proposed method achieves state-of-the-art results, outperforming existing channel attention methods.\n    ",
        "primary_category": "cs.CV",
        "categories": [],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01715": {
        "title": "Collaborative Job Seeking for People with Autism: Challenges and Design Opportunities",
        "authors": [
            "Zinat Ara",
            "Amrita Ganguly",
            "Donna Peppard",
            "Dongjun Chung",
            "Slobodan Vucetic",
            "Vivian Genaro Motti",
            "Sungsoo Ray Hong"
        ],
        "comments": " ",
        "subjects": "Human-Computer Interaction (cs.HC)",
        "abstract": "Successful job search results from job seekers' well-shaped social communication. While well-known differences in communication exist between people with autism and neurotypicals, little is known about how people with autism collaborate with their social surroundings to strive in the job market. To better understand the practices and challenges of collaborative job seeking for people with autism, we interviewed 20 participants including applicants with autism, their social surroundings, and career experts. Through the interviews, we identified social challenges that people with autism face during their job seeking; the social support they leverage to be successful; and the technological limitations that hinder their collaboration. We designed four probes that represent major collaborative features found from the interviews--executive planning, communication, stage-wise preparation, and neurodivergent community formation--and discussed their potential usefulness and impact through three focus groups. We provide implications regarding how our findings can enhance collaborative job seeking experiences for people with autism through new designs.\n    ",
        "primary_category": "cs.HC",
        "categories": [],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01722": {
        "title": "Closing the Knowledge Gap in Designing Data Annotation Interfaces for AI-powered Disaster Management Analytic Systems",
        "authors": [
            "Zinat Ara",
            "Hossein Salemi",
            "Sungsoo Ray Hong",
            "Yasas Senarath",
            "Steve Peterson",
            "Amanda Lee Hughes",
            "Hemant Purohit"
        ],
        "comments": " ",
        "subjects": "Human-Computer Interaction (cs.HC)",
        "abstract": "Data annotation interfaces predominantly leverage ground truth labels to guide annotators toward accurate responses. With the growing adoption of Artificial Intelligence (AI) in domain-specific professional tasks, it has become increasingly important to help beginning annotators identify how their early-stage knowledge can lead to inaccurate answers, which in turn, helps to ensure quality annotations at scale. To investigate this issue, we conducted a formative study involving eight individuals from the field of disaster management, each possessing varying levels of expertise. The goal was to understand the prevalent factors contributing to disagreements among annotators when classifying Twitter messages related to disasters and to analyze their respective responses. Our analysis identified two primary causes of disagreement between expert and beginner annotators: 1) a lack of contextual knowledge or uncertainty about the situation, and 2) the absence of visual or supplementary cues. Based on these findings, we designed a Context interface, which generates aids that help beginners identify potential mistakes and provide the hidden context of the presented tweet. The summative study compares Context design with two widely used designs in data annotation UI, Highlight and Reasoning-based interfaces. We found significant differences between these designs in terms of attitudinal and behavioral data. We conclude with implications for designing future interfaces aiming at closing the knowledge gap among annotators.\n    ",
        "primary_category": "cs.HC",
        "categories": [],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01723": {
        "title": "Statistical Mechanics of Dynamical System Identification",
        "authors": [
            "Andrei A. Klishin",
            "Joseph Bakarji",
            "J. Nathan Kutz",
            "Krithika Manohar"
        ],
        "comments": "21 RevTeX page, 9 figures",
        "subjects": "Statistical Mechanics (cond-mat.stat-mech)",
        "abstract": "Recovering dynamical equations from observed noisy data is the central challenge of system identification. We develop a statistical mechanical approach to analyze sparse equation discovery algorithms, which typically balance data fit and parsimony through a trial-and-error selection of hyperparameters. In this framework, statistical mechanics offers tools to analyze the interplay between complexity and fitness, in analogy to that done between entropy and energy. To establish this analogy, we define the optimization procedure as a two-level Bayesian inference problem that separates variable selection from coefficient values and enables the computation of the posterior parameter distribution in closed form. A key advantage of employing statistical mechanical concepts, such as free energy and the partition function, is in the quantification of uncertainty, especially in in the low-data limit; frequently encountered in real-world applications. As the data volume increases, our approach mirrors the thermodynamic limit, leading to distinct sparsity- and noise-induced phase transitions that delineate correct from incorrect identification. This perspective of sparse equation discovery, is versatile and can be adapted to various other equation discovery algorithms.\n    ",
        "primary_category": "cond-mat.stat-mech",
        "categories": [
            "cs.LG",
            "math.OC",
            "physics.comp-ph"
        ],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01731": {
        "title": "RISeg: Robot Interactive Object Segmentation via Body Frame-Invariant Features",
        "authors": [
            "Howard H. Qian",
            "Yangxiao Lu",
            "Kejia Ren",
            "Gaotian Wang",
            "Ninad Khargonkar",
            "Yu Xiang",
            "Kaiyu Hang"
        ],
        "comments": "7 pages, 5 figures, ICRA 2024",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "In order to successfully perform manipulation tasks in new environments, such as grasping, robots must be proficient in segmenting unseen objects from the background and/or other objects. Previous works perform unseen object instance segmentation (UOIS) by training deep neural networks on large-scale data to learn RGB/RGB-D feature embeddings, where cluttered environments often result in inaccurate segmentations. We build upon these methods and introduce a novel approach to correct inaccurate segmentation, such as under-segmentation, of static image-based UOIS masks by using robot interaction and a designed body frame-invariant feature. We demonstrate that the relative linear and rotational velocities of frames randomly attached to rigid bodies due to robot interactions can be used to identify objects and accumulate corrected object-level segmentation masks. By introducing motion to regions of segmentation uncertainty, we are able to drastically improve segmentation accuracy in an uncertainty-driven manner with minimal, non-disruptive interactions (ca. 2-3 per scene). We demonstrate the effectiveness of our proposed interactive perception pipeline in accurately segmenting cluttered scenes by achieving an average object segmentation accuracy rate of 80.7%, an increase of 28.2% when compared with other state-of-the-art UOIS methods.\n    ",
        "primary_category": "cs.CV",
        "categories": [
            "cs.RO"
        ],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01733": {
        "title": "3D Hand Reconstruction via Aggregating Intra and Inter Graphs Guided by Prior Knowledge for Hand-Object Interaction Scenario",
        "authors": [
            "Feng Shuang",
            "Wenbo He",
            "Shaodong Li"
        ],
        "comments": " ",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Recently, 3D hand reconstruction has gained more attention in human-computer cooperation, especially for hand-object interaction scenario. However, it still remains huge challenge due to severe hand-occlusion caused by interaction, which contain the balance of accuracy and physical plausibility, highly nonlinear mapping of model parameters and occlusion feature enhancement. To overcome these issues, we propose a 3D hand reconstruction network combining the benefits of model-based and model-free approaches to balance accuracy and physical plausibility for hand-object interaction scenario. Firstly, we present a novel MANO pose parameters regression module from 2D joints directly, which avoids the process of highly nonlinear mapping from abstract image feature and no longer depends on accurate 3D joints. Moreover, we further propose a vertex-joint mutual graph-attention model guided by MANO to jointly refine hand meshes and joints, which model the dependencies of vertex-vertex and joint-joint and capture the correlation of vertex-joint for aggregating intra-graph and inter-graph node features respectively. The experimental results demonstrate that our method achieves a competitive performance on recently benchmark datasets HO3DV2 and Dex-YCB, and outperforms all only model-base approaches and model-free approaches.\n    ",
        "primary_category": "cs.CV",
        "categories": [],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01734": {
        "title": "Offline Goal-Conditioned Reinforcement Learning for Safety-Critical Tasks with Recovery Policy",
        "authors": [
            "Chenyang Cao",
            "Zichen Yan",
            "Renhao Lu",
            "Junbo Tan",
            "Xueqian Wang"
        ],
        "comments": "Accepted by ICRA24",
        "subjects": "Robotics (cs.RO)",
        "abstract": "Offline goal-conditioned reinforcement learning (GCRL) aims at solving goal-reaching tasks with sparse rewards from an offline dataset. While prior work has demonstrated various approaches for agents to learn near-optimal policies, these methods encounter limitations when dealing with diverse constraints in complex environments, such as safety constraints. Some of these approaches prioritize goal attainment without considering safety, while others excessively focus on safety at the expense of training efficiency. In this paper, we study the problem of constrained offline GCRL and propose a new method called Recovery-based Supervised Learning (RbSL) to accomplish safety-critical tasks with various goals. To evaluate the method performance, we build a benchmark based on the robot-fetching environment with a randomly positioned obstacle and use expert or random policies to generate an offline dataset. We compare RbSL with three offline GCRL algorithms and one offline safe RL algorithm. As a result, our method outperforms the existing state-of-the-art methods to a large extent. Furthermore, we validate the practicality and effectiveness of RbSL by deploying it on a real Panda manipulator. Code is available at this https URL.\n    ",
        "primary_category": "cs.RO",
        "categories": [
            "cs.AI",
            "cs.LG"
        ],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01736": {
        "title": "Lightweight Object Detection: A Study Based on YOLOv7 Integrated with ShuffleNetv2 and Vision Transformer",
        "authors": [
            "Wenkai Gong"
        ],
        "comments": " ",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "As mobile computing technology rapidly evolves, deploying efficient object detection algorithms on mobile devices emerges as a pivotal research area in computer vision. This study zeroes in on optimizing the YOLOv7 algorithm to boost its operational efficiency and speed on mobile platforms while ensuring high accuracy. Leveraging a synergy of advanced techniques such as Group Convolution, ShuffleNetV2, and Vision Transformer, this research has effectively minimized the model's parameter count and memory usage, streamlined the network architecture, and fortified the real-time object detection proficiency on resource-constrained devices. The experimental outcomes reveal that the refined YOLO model demonstrates exceptional performance, markedly enhancing processing velocity while sustaining superior detection accuracy.\n    ",
        "primary_category": "cs.CV",
        "categories": [],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01738": {
        "title": "ComS2T: A complementary spatiotemporal learning system for data-adaptive model evolution",
        "authors": [
            "Zhengyang Zhou",
            "Qihe Huang",
            "Binwu Wang",
            "Jianpeng Hou",
            "Kuo Yang",
            "Yuxuan Liang",
            "Yang Wang"
        ],
        "comments": " ",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Spatiotemporal (ST) learning has become a crucial technique to enable smart cities and sustainable urban development. Current ST learning models capture the heterogeneity via various spatial convolution and temporal evolution blocks. However, rapid urbanization leads to fluctuating distributions in urban data and city structures over short periods, resulting in existing methods suffering generalization and data adaptation issues. Despite efforts, existing methods fail to deal with newly arrived observations and those methods with generalization capacity are limited in repeated training. Motivated by complementary learning in neuroscience, we introduce a prompt-based complementary spatiotemporal learning termed ComS2T, to empower the evolution of models for data adaptation. ComS2T partitions the neural architecture into a stable neocortex for consolidating historical memory and a dynamic hippocampus for new knowledge update. We first disentangle two disjoint structures into stable and dynamic weights, and then train spatial and temporal prompts by characterizing distribution of main observations to enable prompts adaptive to new data. This data-adaptive prompt mechanism, combined with a two-stage training process, facilitates fine-tuning of the neural architecture conditioned on prompts, thereby enabling efficient adaptation during testing. Extensive experiments validate the efficacy of ComS2T in adapting to various spatiotemporal out-of-distribution scenarios while maintaining efficient inference capabilities.\n    ",
        "primary_category": "cs.LG",
        "categories": [],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01740": {
        "title": "DEMOS: Dynamic Environment Motion Synthesis in 3D Scenes via Local Spherical-BEV Perception",
        "authors": [
            "Jingyu Gong",
            "Min Wang",
            "Wentao Liu",
            "Chen Qian",
            "Zhizhong Zhang",
            "Yuan Xie",
            "Lizhuang Ma"
        ],
        "comments": " ",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Motion synthesis in real-world 3D scenes has recently attracted much attention. However, the static environment assumption made by most current methods usually cannot be satisfied especially for real-time motion synthesis in scanned point cloud scenes, if multiple dynamic objects exist, e.g., moving persons or vehicles. To handle this problem, we propose the first Dynamic Environment MOtion Synthesis framework (DEMOS) to predict future motion instantly according to the current scene, and use it to dynamically update the latent motion for final motion synthesis. Concretely, we propose a Spherical-BEV perception method to extract local scene features that are specifically designed for instant scene-aware motion prediction. Then, we design a time-variant motion blending to fuse the new predicted motions into the latent motion, and the final motion is derived from the updated latent motions, benefitting both from motion-prior and iterative methods. We unify the data format of two prevailing datasets, PROX and GTA-IM, and take them for motion synthesis evaluation in 3D scenes. We also assess the effectiveness of the proposed method in dynamic environments from GTA-IM and Semantic3D to check the responsiveness. The results show our method outperforms previous works significantly and has great performance in handling dynamic environments.\n    ",
        "primary_category": "cs.CV",
        "categories": [],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01747": {
        "title": "Towards Self-Contained Answers: Entity-Based Answer Rewriting in Conversational Search",
        "authors": [
            "Ivan Sekuli\u0107",
            "Krisztian Balog",
            "Fabio Crestani"
        ],
        "comments": " ",
        "subjects": "Information Retrieval (cs.IR)",
        "abstract": "Conversational information-seeking (CIS) is an emerging paradigm for knowledge acquisition and exploratory search. Traditional web search interfaces enable easy exploration of entities, but this is limited in conversational settings due to the limited-bandwidth interface. This paper explore ways to rewrite answers in CIS, so that users can understand them without having to resort to external services or sources. Specifically, we focus on salient entities -- entities that are central to understanding the answer. As our first contribution, we create a dataset of conversations annotated with entities for saliency. Our analysis of the collected data reveals that the majority of answers contain salient entities. As our second contribution, we propose two answer rewriting strategies aimed at improving the overall user experience in CIS. One approach expands answers with inline definitions of salient entities, making the answer self-contained. The other approach complements answers with follow-up questions, offering users the possibility to learn more about specific entities. Results of a crowdsourcing-based study indicate that rewritten answers are clearly preferred over the original ones. We also find that inline definitions tend to be favored over follow-up questions, but this choice is highly subjective, thereby providing a promising future direction for personalization.\n    ",
        "primary_category": "cs.IR",
        "categories": [
            "cs.CL"
        ],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01749": {
        "title": "Differentially Private Synthetic Data via Foundation Model APIs 2: Text",
        "authors": [
            "Chulin Xie",
            "Zinan Lin",
            "Arturs Backurs",
            "Sivakanth Gopi",
            "Da Yu",
            "Huseyin A Inan",
            "Harsha Nori",
            "Haotian Jiang",
            "Huishuai Zhang",
            "Yin Tat Lee",
            "Bo Li",
            "Sergey Yekhanin"
        ],
        "comments": " ",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "Text data has become extremely valuable due to the emergence of machine learning algorithms that learn from it. A lot of high-quality text data generated in the real world is private and therefore cannot be shared or used freely due to privacy concerns. Generating synthetic replicas of private text data with a formal privacy guarantee, i.e., differential privacy (DP), offers a promising and scalable solution. However, existing methods necessitate DP finetuning of large language models (LLMs) on private data to generate DP synthetic data. This approach is not viable for proprietary LLMs (e.g., GPT-3.5) and also demands considerable computational resources for open-source LLMs. Lin et al. (2024) recently introduced the Private Evolution (PE) algorithm to generate DP synthetic images with only API access to diffusion models. In this work, we propose an augmented PE algorithm, named Aug-PE, that applies to the complex setting of text. We use API access to an LLM and generate DP synthetic text without any model training. We conduct comprehensive experiments on three benchmark datasets. Our results demonstrate that Aug-PE produces DP synthetic text that yields competitive utility with the SOTA DP finetuning baselines. This underscores the feasibility of relying solely on API access of LLMs to produce high-quality DP synthetic texts, thereby facilitating more accessible routes to privacy-preserving LLM applications. Our code and data are available at this https URL.\n    ",
        "primary_category": "cs.CL",
        "categories": [],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01752": {
        "title": "Cooperative and Interaction-aware Driver Model for Lane Change Maneuver",
        "authors": [
            "Jemin Woo",
            "Changsun Ahn"
        ],
        "comments": " ",
        "subjects": "Systems and Control (eess.SY)",
        "abstract": "To achieve complete autonomous vehicles, it is crucial for autonomous vehicles to communicate and interact with their surrounding vehicles. Especially, since the lane change scenarios do not have traffic signals and traffic rules, the interactions between vehicles need to be considered for the autonomous vehicles. To address this issue, we propose a cooperative and interaction-aware decision-making algorithm for autonomous vehicles that stochastically considers the future behavior of surrounding vehicles based on actual driving data. The algorithm is designed for both lane changing and lane keeping vehicles, and effectively considers interaction by using an interaction model based on relative information between vehicles with fewer states. To design the decision-making, the interaction model is defined as Markov decision process, and stochastic dynamic programming is used to solve the Markov decision process. We validate the effectiveness of our proposed algorithm in lane change scenarios that require interaction. Our results demonstrate that the proposed algorithm enables cooperative and interaction-aware decision-making while accommodating various driving styles. Additionally, by comparing it with other methods, such as the intelligent driver model and game theory-based decision-making, we validate the safety and comfortable decision-making of our proposed algorithm. Furthermore, through driving with a human-driven vehicle, it is confirmed that the proposed decision-making enables to cooperatively and effectively drive with humans.\n    ",
        "primary_category": "eess.SY",
        "categories": [],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01754": {
        "title": "Derivative-Free Optimization for Low-Rank Adaptation in Large Language Models",
        "authors": [
            "Feihu Jin",
            "Yin Liu",
            "Ying Tan"
        ],
        "comments": "14 pages, 4 figures, 5 tables",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "Parameter-efficient tuning methods such as LoRA could achieve comparable performance to model tuning by tuning a small portion of the parameters. However, substantial computational resources are still required, as this process involves calculating gradients and performing back-propagation throughout the model. Much effort has recently been devoted to utilizing the derivative-free optimization method to eschew the computation of gradients and showcase an augmented level of robustness in few-shot settings. In this paper, we prepend the low-rank modules into each self-attention layer of the model and employ two derivative-free optimization methods to optimize these low-rank modules at each layer alternately. Extensive results on various tasks and language models demonstrate that our proposed method achieves substantial improvement and exhibits clear advantages in memory usage and convergence speed compared to existing gradient-based parameter-efficient tuning and derivative-free optimization methods in few-shot settings.\n    ",
        "primary_category": "cs.CL",
        "categories": [],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01755": {
        "title": "AI Language Models Could Both Help and Harm Equity in Marine Policymaking: The Case Study of the BBNJ Question-Answering Bot",
        "authors": [
            "Matt Ziegler",
            "Sarah Lothian",
            "Brian O'Neill",
            "Richard Anderson",
            "Yoshitaka Ota"
        ],
        "comments": " ",
        "subjects": "Computers and Society (cs.CY)",
        "abstract": "AI Large Language Models (LLMs) like ChatGPT are set to reshape some aspects of policymaking processes. Policy practitioners are already using ChatGPT for help with a variety of tasks: from drafting statements, submissions, and presentations, to conducting background research. We are cautiously hopeful that LLMs could be used to promote a marginally more balanced footing among decision makers in policy negotiations by assisting with certain tedious work, particularly benefiting developing countries who face capacity constraints that put them at a disadvantage in negotiations. However, the risks are particularly concerning for environmental and marine policy uses, due to the urgency of crises like climate change, high uncertainty, and trans-boundary impact.\nTo explore the realistic potentials, limitations, and equity risks for LLMs in marine policymaking, we present a case study of an AI chatbot for the recently adopted Biodiversity Beyond National Jurisdiction Agreement (BBNJ), and critique its answers to key policy questions. Our case study demonstrates the dangers of LLMs in marine policymaking via their potential bias towards generating text that favors the perspectives of mainly Western economic centers of power, while neglecting developing countries' viewpoints. We describe several ways these biases can enter the system, including: (1) biases in the underlying foundational language models; (2) biases arising from the chatbot's connection to UN negotiation documents, and (3) biases arising from the application design. We urge caution in the use of generative AI in ocean policy processes and call for more research on its equity and fairness implications. Our work also underscores the need for developing countries' policymakers to develop the technical capacity to engage with AI on their own terms.\n    ",
        "primary_category": "cs.CY",
        "categories": [],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01757": {
        "title": "How Multimodal Integration Boost the Performance of LLM for Optimization: Case Study on Capacitated Vehicle Routing Problems",
        "authors": [
            "Yuxiao Huang",
            "Wenjie Zhang",
            "Liang Feng",
            "Xingyu Wu",
            "Kay Chen Tan"
        ],
        "comments": "8pages,3 figures, 2 tables",
        "subjects": "Artificial Intelligence (cs.AI)",
        "abstract": "Recently, large language models (LLMs) have notably positioned them as capable tools for addressing complex optimization challenges. Despite this recognition, a predominant limitation of existing LLM-based optimization methods is their struggle to capture the relationships among decision variables when relying exclusively on numerical text prompts, especially in high-dimensional problems. Keeping this in mind, we first propose to enhance the optimization performance using multimodal LLM capable of processing both textual and visual prompts for deeper insights of the processed optimization problem. This integration allows for a more comprehensive understanding of optimization problems, akin to human cognitive processes. We have developed a multimodal LLM-based optimization framework that simulates human problem-solving workflows, thereby offering a more nuanced and effective analysis. The efficacy of this method is evaluated through extensive empirical studies focused on a well-known combinatorial optimization problem, i.e., capacitated vehicle routing problem. The results are compared against those obtained from the LLM-based optimization algorithms that rely solely on textual prompts, demonstrating the significant advantages of our multimodal approach.\n    ",
        "primary_category": "cs.AI",
        "categories": [
            "cs.CL",
            "cs.LG",
            "cs.NE",
            "math.OC"
        ],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01758": {
        "title": "AFBT GAN: enhanced explainability and diagnostic performance for cognitive decline by counterfactual generative adversarial network",
        "authors": [
            "Xiongri Shen",
            "Zhenxi Song",
            "Zhiguo Zhang"
        ],
        "comments": "10 pages, 5 figures",
        "subjects": "Image and Video Processing (eess.IV)",
        "abstract": "Existing explanation results of functional connectivity (FC) are normally generated by using classification result labels and correlation analysis methods such as Pearson's correlation or gradient backward. However, the diagnostic model is still trained on the black box model and might lack the attention of FCs in important regions during the training. To enhance the explainability and improve diagnostic performance, providing prior knowledge on neurodegeneration-related regions when healthy subjects (HC) develop into subject cognitive decline (SCD) and mild cognitive impairment (MCI) for the diagnostic model is a key step. To better determine the neurodegeneration-related regions, we employ counterfactual reasoning to generate the target label FC matrices derived from source label FC and then subtract source label FC with target label FC. The counterfactual reasoning architecture is constructed by adaptive forward and backward transformer generative adversarial network (AFBT GAN), which is specifically designed by network property in FC and inverse patch embedding operation in the transformer. The specific design can make the model focus more on the current network correlation and employ the global insight of the transformer to reconstruct FC, which both help the generation of high-quality target label FC. The validation experiments are conducted on both clinical and public datasets, the generated attention map are both vital correlated to cognitive function and the diagnostic performance is also significant. The code is available at this https URL.\n    ",
        "primary_category": "eess.IV",
        "categories": [
            "cs.CV",
            "cs.LG"
        ],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01768": {
        "title": "Canonical Form of Datatic Description in Control Systems",
        "authors": [
            "Guojian Zhan",
            "Ziang Zheng",
            "Shengbo Eben Li"
        ],
        "comments": " ",
        "subjects": "Systems and Control (eess.SY)",
        "abstract": "The design of feedback controllers is undergoing a paradigm shift from modelic (i.e., model-driven) control to datatic (i.e., data-driven) control. Canonical form of state space model is an important concept in modelic control systems, exemplified by Jordan form, controllable form and observable form, whose purpose is to facilitate system analysis and controller synthesis. In the realm of datatic control, there is a notable absence in the standardization of data-based system representation. This paper for the first time introduces the concept of canonical data form for the purpose of achieving more effective design of datatic controllers. In a control system, the data sample in canonical form consists of a transition component and an attribute component. The former encapsulates the plant dynamics at the sampling time independently, which is a tuple containing three elements: a state, an action and their corresponding next state. The latter describes one or some artificial characteristics of the current sample, whose calculation must be performed in an online manner. The attribute of each sample must adhere to two requirements: (1) causality, ensuring independence from any future samples; and (2) locality, allowing dependence on historical samples but constrained to a finite neighboring set. The purpose of adding attribute is to offer some kinds of benefits for controller design in terms of effectiveness and efficiency. To provide a more close-up illustration, we present two canonical data forms: temporal form and spatial form, and demonstrate their advantages in reducing instability and enhancing training efficiency in two datatic control systems.\n    ",
        "primary_category": "eess.SY",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01769": {
        "title": "A Safe Screening Rule with Bi-level Optimization of $\u03bd$ Support Vector Machine",
        "authors": [
            "Zhiji Yang",
            "Wanyi Chen",
            "Huan Zhang",
            "Yitian Xu",
            "Lei Shi",
            "Jianhua Zhao"
        ],
        "comments": " ",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Support vector machine (SVM) has achieved many successes in machine learning, especially for a small sample problem. As a famous extension of the traditional SVM, the $\\nu$ support vector machine ($\\nu$-SVM) has shown outstanding performance due to its great model interpretability. However, it still faces challenges in training overhead for large-scale problems. To address this issue, we propose a safe screening rule with bi-level optimization for $\\nu$-SVM (SRBO-$\\nu$-SVM) which can screen out inactive samples before training and reduce the computational cost without sacrificing the prediction accuracy. Our SRBO-$\\nu$-SVM is strictly deduced by integrating the Karush-Kuhn-Tucker (KKT) conditions, the variational inequalities of convex problems and the $\\nu$-property. Furthermore, we develop an efficient dual coordinate descent method (DCDM) to further improve computational speed. Finally, a unified framework for SRBO is proposed to accelerate many SVM-type models, and it is successfully applied to one-class SVM. Experimental results on 6 artificial data sets and 30 benchmark data sets have verified the effectiveness and safety of our proposed methods in supervised and unsupervised tasks.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.AI",
            "math.OC"
        ],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01771": {
        "title": "Weakly modular graphs with diamond condition, the interval function and axiomatic characterizations",
        "authors": [
            "Lekshmi Kamal Kamalolbhavan-Sheela",
            "Jeny Jacob",
            "Manoj Changat"
        ],
        "comments": "21 pages, 2 figures",
        "subjects": "Combinatorics (math.CO)",
        "abstract": "Weakly modular graphs are defined as the class of graphs that satisfy the \\emph{triangle condition ($TC$)} and the \\emph{quadrangle condition ($QC$)}. We study an interesting subclass of weakly modular graphs that satisfies a stronger version of the triangle condition, known as the \\emph{triangle diamond condition ($TDC$)}. and term this subclass of weakly modular graphs as the \\emph{diamond-weakly modular graphs}. It is observed that this class contains the class of bridged graphs and the class of weakly bridged graphs.\nThe interval function $I_G$ of a connected graph $G$ with vertex set $V$ is an important concept in metric graph theory and is one of the prime example of a transit function; a set function defined on the Cartesian product $V\\times V$ to the power set of $V$ satisfying the expansive, symmetric and idempotent axioms.\nIn this paper, we derive an interesting axiom denoted as $(J0')$, obtained from a well-known axiom introduced by Marlow Sholander in 1952, denoted as $(J0)$. It is proved that the axiom $(J0')$ is a characterizing axiom of the diamond-weakly modular graphs. We propose certain types of independent first-order betweenness axioms on an arbitrary transit function $R$ and prove that an arbitrary transit function becomes the interval function of a diamond-weakly modular graph if and only if $R$ satisfies these betweenness axioms. Similar characterizations are obtained for the interval function of bridged graphs and weakly bridged graphs.\n    ",
        "primary_category": "math.CO",
        "categories": [
            "cs.DM"
        ],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01773": {
        "title": "Improving out-of-distribution generalization in graphs via hierarchical semantic environments",
        "authors": [
            "Yinhua Piao",
            "Sangseon Lee",
            "Yijingxiu Lu",
            "Sun Kim"
        ],
        "comments": "Accepted by CVPR 2024",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Out-of-distribution (OOD) generalization in the graph domain is challenging due to complex distribution shifts and a lack of environmental contexts. Recent methods attempt to enhance graph OOD generalization by generating flat environments. However, such flat environments come with inherent limitations to capture more complex data distributions. Considering the DrugOOD dataset, which contains diverse training environments (e.g., scaffold, size, etc.), flat contexts cannot sufficiently address its high heterogeneity. Thus, a new challenge is posed to generate more semantically enriched environments to enhance graph invariant learning for handling distribution shifts. In this paper, we propose a novel approach to generate hierarchical semantic environments for each graph. Firstly, given an input graph, we explicitly extract variant subgraphs from the input graph to generate proxy predictions on local environments. Then, stochastic attention mechanisms are employed to re-extract the subgraphs for regenerating global environments in a hierarchical manner. In addition, we introduce a new learning objective that guides our model to learn the diversity of environments within the same hierarchy while maintaining consistency across different hierarchies. This approach enables our model to consider the relationships between environments and facilitates robust graph invariant learning. Extensive experiments on real-world graph data have demonstrated the effectiveness of our framework. Particularly, in the challenging dataset DrugOOD, our method achieves up to 1.29\\% and 2.83\\% improvement over the best baselines on IC50 and EC50 prediction tasks, respectively.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01774": {
        "title": "WebCiteS: Attributed Query-Focused Summarization on Chinese Web Search Results with Citations",
        "authors": [
            "Haolin Deng",
            "Chang Wang",
            "Xin Li",
            "Dezhang Yuan",
            "Junlang Zhan",
            "Tianhua Zhou",
            "Jin Ma",
            "Jun Gao",
            "Ruifeng Xu"
        ],
        "comments": "19 pages, 7 figures",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "Enhancing the attribution in large language models (LLMs) is a crucial task. One feasible approach is to enable LLMs to cite external sources that support their generations. However, existing datasets and evaluation methods in this domain still exhibit notable limitations. In this work, we formulate the task of attributed query-focused summarization (AQFS) and present WebCiteS, a Chinese dataset featuring 7k human-annotated summaries with citations. WebCiteS derives from real-world user queries and web search results, offering a valuable resource for model training and evaluation. Prior works in attribution evaluation do not differentiate between groundedness errors and citation errors. They also fall short in automatically verifying sentences that draw partial support from multiple sources. We tackle these issues by developing detailed metrics and enabling the automatic evaluator to decompose the sentences into sub-claims for fine-grained verification. Our comprehensive evaluation of both open-source and proprietary models on WebCiteS highlights the challenge LLMs face in correctly citing sources, underscoring the necessity for further improvement. The dataset and code will be open-sourced to facilitate further research in this crucial field.\n    ",
        "primary_category": "cs.CL",
        "categories": [],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01776": {
        "title": "Hybrid data-driven and physics-informed regularized learning of cyclic plasticity with Neural Networks",
        "authors": [
            "Stefan Hildebrand",
            "Sandra Klinge"
        ],
        "comments": " ",
        "subjects": "Materials Science (cond-mat.mtrl-sci)",
        "abstract": "An extendable, efficient and explainable Machine Learning approach is proposed to represent cyclic plasticity and replace conventional material models based on the Radial Return Mapping algorithm. High accuracy and stability by means of a limited amount of training data is achieved by implementing physics-informed regularizations and the back stress information. The off-loading of the Neural Network is applied to the maximal extent. The proposed model architecture is simpler and more efficient compared to existing solutions from the literature, while representing a complete three-dimensional material model. The validation of the approach is carried out by means of surrogate data obtained with the Armstrong-Frederick kinematic hardening model. The Mean Squared Error is assumed as the loss function which stipulates several restrictions: deviatoric character of internal variables, compliance with the flow rule, the differentiation of elastic and plastic steps and the associativity of the flow rule. The latter, however, has a minor impact on the accuracy, which implies the generalizability of the model for a broad spectrum of evolution laws for internal variables. Numerical tests simulating several load cases are shown in detail and validated for accuracy and stability.\n    ",
        "primary_category": "cond-mat.mtrl-sci",
        "categories": [
            "cs.LG",
            "nlin.AO",
            "physics.comp-ph"
        ],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01778": {
        "title": "HOSCF: Efficient decoupling algorithms for finding the best rank-one approximation of higher-order tensors",
        "authors": [
            "Chuanfu Xiao",
            "Zeyu Li",
            "Chao Yang"
        ],
        "comments": " ",
        "subjects": "Numerical Analysis (math.NA)",
        "abstract": "Best rank-one approximation is one of the most fundamental tasks in tensor computation. In order to fully exploit modern multi-core parallel computers, it is necessary to develop decoupling algorithms for computing the best rank-one approximation of higher-order tensors at large scales. In this paper, we first build a bridge between the rank-one approximation of tensors and the eigenvector-dependent nonlinear eigenvalue problem (NEPv), and then develop an efficient decoupling algorithm, namely the higher-order self-consistent field (HOSCF) algorithm, inspired by the famous self-consistent field (SCF) iteration frequently used in computational chemistry. The convergence theory of the HOSCF algorithm and an estimation of the convergence speed are further presented. In addition, we propose an improved HOSCF (iHOSCF) algorithm that incorporates the Rayleigh quotient iteration, which can significantly accelerate the convergence of HOSCF. Numerical experiments show that the proposed algorithms can efficiently converge to the best rank-one approximation of both synthetic and real-world tensors and can scale with high parallel scalability on a modern parallel computer.\n    ",
        "primary_category": "math.NA",
        "categories": [
            "math.OC"
        ],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01780": {
        "title": "Graph neural network for in-network placement of real-time metaverse tasks in next-generation network",
        "authors": [
            "Sulaiman Muhammad Rashid",
            "Ibrahim Aliyu",
            "Il-Kwon Jeong",
            "Tai-Won Um",
            "Jinsul Kim"
        ],
        "comments": " ",
        "subjects": "Networking and Internet Architecture (cs.NI)",
        "abstract": "This study addresses the challenge of real-time metaverse applications by proposing an in-network placement and task-offloading solution for delay-constrained computing tasks in next-generation networks. The metaverse, envisioned as a parallel virtual world, requires seamless real-time experiences across diverse applications. The study introduces a software-defined networking (SDN)-based architecture and employs graph neural network (GNN) techniques for intelligent and adaptive task allocation in in-network computing (INC). Considering time constraints and computing capabilities, the proposed model optimally decides whether to offload rendering tasks to INC nodes or edge server. Extensive experiments demonstrate the superior performance of the proposed GNN model, achieving 97% accuracy compared to 72% for multilayer perceptron (MLP) and 70% for decision trees (DTs). The study fills the research gap in in-network placement for real-time metaverse applications, offering insights into efficient rendering task handling.\n    ",
        "primary_category": "cs.NI",
        "categories": [
            "cs.DC"
        ],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01781": {
        "title": "Integrating Efficient Optimal Transport and Functional Maps For Unsupervised Shape Correspondence Learning",
        "authors": [
            "Tung Le",
            "Khai Nguyen",
            "Shanlin Sun",
            "Nhat Ho",
            "Xiaohui Xie"
        ],
        "comments": "accepted by CVPR 2024",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "In the realm of computer vision and graphics, accurately establishing correspondences between geometric 3D shapes is pivotal for applications like object tracking, registration, texture transfer, and statistical shape analysis. Moving beyond traditional hand-crafted and data-driven feature learning methods, we incorporate spectral methods with deep learning, focusing on functional maps (FMs) and optimal transport (OT). Traditional OT-based approaches, often reliant on entropy regularization OT in learning-based framework, face computational challenges due to their quadratic cost. Our key contribution is to employ the sliced Wasserstein distance (SWD) for OT, which is a valid fast optimal transport metric in an unsupervised shape matching framework. This unsupervised framework integrates functional map regularizers with a novel OT-based loss derived from SWD, enhancing feature alignment between shapes treated as discrete probability measures. We also introduce an adaptive refinement process utilizing entropy regularized OT, further refining feature alignments for accurate point-to-point correspondences. Our method demonstrates superior performance in non-rigid shape matching, including near-isometric and non-isometric scenarios, and excels in downstream tasks like segmentation transfer. The empirical results on diverse datasets highlight our framework's effectiveness and generalization capabilities, setting new standards in non-rigid shape matching with efficient OT metrics and an adaptive refinement module.\n    ",
        "primary_category": "cs.CV",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01782": {
        "title": "Tuning and Testing an Online Feedback Optimization Controller to Provide Curative Distribution Grid Flexibility",
        "authors": [
            "Lukas Ortmann",
            "Fabian B\u00f6hm",
            "Florian Klein-Helmkamp",
            "Andreas Ulbig",
            "Saverio Bolognani",
            "Florian D\u00f6rfler"
        ],
        "comments": " ",
        "subjects": "Systems and Control (eess.SY)",
        "abstract": "Due to more volatile generation, flexibility will become more important in transmission grids. One potential source of this flexibility can be distribution grids. A flexibility request from the transmission grid to a distribution grid then needs to be split up onto the different flexibility providing units (FPU) in the distribution grid. One potential way to do this is Online Feedback Optimization (OFO). OFO is a new control method that steers power systems to the optimal solution of an optimization problem using minimal model information and computation power. This paper will show how to choose the optimization problem and how to tune the OFO controller. Afterward, we test the resulting controller on a real distribution grid laboratory and show its performance, its interaction with other controllers in the grid, and how it copes with disturbances. Overall, the paper makes a clear recommendation on how to phrase the optimization problem and tune the OFO controller. Furthermore, it experimentally verifies that an OFO controller is a powerful tool to disaggregate flexibility requests onto FPUs while satisfying operational constraints inside the flexibility providing distribution grid.\n    ",
        "primary_category": "eess.SY",
        "categories": [],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01783": {
        "title": "Towards A Diffractive Analysis of Prompt-Based Generative AI",
        "authors": [
            "Nina Rajcic",
            "Maria Teresa Llano",
            "Jon McCormack"
        ],
        "comments": "Preprint of paper accepted for CHI 2024",
        "subjects": "Human-Computer Interaction (cs.HC)",
        "abstract": "Recent developments in prompt-based generative AI has given rise to discourse surrounding the perceived ethical concerns, economic implications, and consequences for the future of cultural production. As generative imagery becomes pervasive in mainstream society, dominated primarily by emerging industry leaders, we encourage that the role of the CHI community be one of inquiry; to investigate the numerous ways in which generative AI has the potential to, and already is, augmenting human creativity. In this paper, we conducted a diffractive analysis exploring the potential role of prompt-based interfaces in artists' creative practice. Over a two week period, seven visual artists were given access to a personalised instance of Stable Diffusion, fine-tuned on a dataset of their work. In the following diffractive analysis, we identified two dominant modes adopted by participants, AI for ideation, and AI for production. We furthermore present a number of ethical design considerations for the future development of generative AI interfaces.\n    ",
        "primary_category": "cs.HC",
        "categories": [],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01784": {
        "title": "CatCode: A Comprehensive Evaluation Framework for LLMs On the Mixture of Code and Text",
        "authors": [
            "Zhenru Lin",
            "Yiqun Yao",
            "Yang Yuan"
        ],
        "comments": "10 pages, 5 figures",
        "subjects": "Artificial Intelligence (cs.AI)",
        "abstract": "Large language models (LLMs) such as ChatGPT are increasingly proficient in understanding and generating a mixture of code and text. Evaluation based on such $\\textit{mixture}$ can lead to a more comprehensive understanding of the models' abilities in solving coding problems. However, in this context, current evaluation methods are either limited in task coverage or lack standardization. To address this issue, we propose using category theory as a framework for evaluation. Specifically, morphisms within a code category can represent code debugging and transformation, functors between two categories represent code translation, and functors between a code category and a natural language category represent code generation, explanation, and reproduction. We present an automatic evaluation framework called $\\textbf{CatCode}$ ($\\textbf{Cat}$egory $\\textbf{Code}$) that can comprehensively assess the coding abilities of LLMs, including ChatGPT, Text-Davinci, and CodeGeeX.\n    ",
        "primary_category": "cs.AI",
        "categories": [
            "cs.PL"
        ],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01785": {
        "title": "What do neural networks listen to? Exploring the crucial bands in Speech Enhancement using Sinc-convolution",
        "authors": [
            "Kuan-Hsun Ho",
            "Jeih-weih Hung",
            "Berlin Chen"
        ],
        "comments": " ",
        "subjects": "Sound (cs.SD)",
        "abstract": "This study introduces a reformed Sinc-convolution (Sincconv) framework tailored for the encoder component of deep networks for speech enhancement (SE). The reformed Sincconv, based on parametrized sinc functions as band-pass filters, offers notable advantages in terms of training efficiency, filter diversity, and interpretability. The reformed Sinc-conv is evaluated in conjunction with various SE models, showcasing its ability to boost SE performance. Furthermore, the reformed Sincconv provides valuable insights into the specific frequency components that are prioritized in an SE scenario. This opens up a new direction of SE research and improving our knowledge of their operating dynamics.\n    ",
        "primary_category": "cs.SD",
        "categories": [
            "eess.AS"
        ],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01786": {
        "title": "Exposing the Deception: Uncovering More Forgery Clues for Deepfake Detection",
        "authors": [
            "Zhongjie Ba",
            "Qingyu Liu",
            "Zhenguang Liu",
            "Shuang Wu",
            "Feng Lin",
            "Li Lu",
            "Kui Ren"
        ],
        "comments": "AAAI2024",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Deepfake technology has given rise to a spectrum of novel and compelling applications. Unfortunately, the widespread proliferation of high-fidelity fake videos has led to pervasive confusion and deception, shattering our faith that seeing is believing. One aspect that has been overlooked so far is that current deepfake detection approaches may easily fall into the trap of overfitting, focusing only on forgery clues within one or a few local regions. Moreover, existing works heavily rely on neural networks to extract forgery features, lacking theoretical constraints guaranteeing that sufficient forgery clues are extracted and superfluous features are eliminated. These deficiencies culminate in unsatisfactory accuracy and limited generalizability in real-life scenarios.\nIn this paper, we try to tackle these challenges through three designs: (1) We present a novel framework to capture broader forgery clues by extracting multiple non-overlapping local representations and fusing them into a global semantic-rich feature. (2) Based on the information bottleneck theory, we derive Local Information Loss to guarantee the orthogonality of local representations while preserving comprehensive task-relevant information. (3) Further, to fuse the local representations and remove task-irrelevant information, we arrive at a Global Information Loss through the theoretical analysis of mutual information. Empirically, our method achieves state-of-the-art performance on five benchmark datasets.Our code is available at \\url{this https URL}, hoping to inspire researchers.\n    ",
        "primary_category": "cs.CV",
        "categories": [
            "cs.IT"
        ],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01788": {
        "title": "K-stars LDP: A Novel Framework for (p, q)-clique Enumeration under Local Differential Privacy",
        "authors": [
            "Henan Sun",
            "Zhengyu Wu",
            "Rong-Hua Li",
            "Guoren Wang",
            "Zening Li"
        ],
        "comments": " ",
        "subjects": "Cryptography and Security (cs.CR)",
        "abstract": "(p,q)-clique enumeration on a bipartite graph is critical for calculating clustering coefficient and detecting densest subgraph. It is necessary to carry out subgraph enumeration while protecting users' privacy from any potential attacker as the count of subgraph may contain sensitive information. Most recent studies focus on the privacy protection algorithms based on edge LDP (Local Differential Privacy). However, these algorithms suffer a large estimation error due to the great amount of required noise. In this paper, we propose a novel idea of k-stars LDP and a novel k-stars LDP algorithm for (p, q)-clique enumeration with a small estimation error, where a k-stars is a star-shaped graph with k nodes connecting to one node. The effectiveness of edge LDP relies on its capacity to obfuscate the existence of an edge between the user and his one-hop neighbors. This is based on the premise that a user should be aware of the existence of his one-hop neighbors. Similarly, we can apply this premise to k-stars as well, where an edge is a specific genre of 1-stars. Based on this fact, we first propose the k-stars neighboring list to enable our algorithm to obfuscate the existence of k-stars with Warner' s RR. Then, we propose the absolute value correction technique and the k-stars sampling technique to further reduce the estimation error. Finally, with the two-round user-collector interaction mechanism, we propose our k-stars LDP algorithm to count the number of (p, q)-clique while successfully protecting users' privacy. Both the theoretical analysis and experiments have showed the superiority of our algorithm over the algorithms based on edge LDP.\n    ",
        "primary_category": "cs.CR",
        "categories": [
            "cs.CY",
            "cs.DS"
        ],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01789": {
        "title": "DECOR: Enhancing Logic Locking Against Machine Learning-Based Attacks",
        "authors": [
            "Yinghua Hu",
            "Kaixin Yang",
            "Subhajit Dutta Chowdhury",
            "Pierluigi Nuzzo"
        ],
        "comments": "8 pages. Accepted at the International Symposium on Quality Electronic Design (ISQED), 2024",
        "subjects": "Cryptography and Security (cs.CR)",
        "abstract": "Logic locking (LL) has gained attention as a promising intellectual property protection measure for integrated circuits. However, recent attacks, facilitated by machine learning (ML), have shown the potential to predict the correct key in multiple LL schemes by exploiting the correlation of the correct key value with the circuit structure. This paper presents a generic LL enhancement method based on a randomized algorithm that can significantly decrease the correlation between locked circuit netlist and correct key values in an LL scheme. Numerical results show that the proposed method can efficiently degrade the accuracy of state-of-the-art ML-based attacks down to around 50%, resulting in negligible advantage versus random guessing.\n    ",
        "primary_category": "cs.CR",
        "categories": [
            "eess.SY"
        ],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01791": {
        "title": "Beyond Recommender: An Exploratory Study of the Effects of Different AI Roles in AI-Assisted Decision Making",
        "authors": [
            "Shuai Ma",
            "Chenyi Zhang",
            "Xinru Wang",
            "Xiaojuan Ma",
            "Ming Yin"
        ],
        "comments": " ",
        "subjects": "Human-Computer Interaction (cs.HC)",
        "abstract": "Artificial Intelligence (AI) is increasingly employed in various decision-making tasks, typically as a Recommender, providing recommendations that the AI deems correct. However, recent studies suggest this may diminish human analytical thinking and lead to humans' inappropriate reliance on AI, impairing the synergy in human-AI teams. In contrast, human advisors in group decision-making perform various roles, such as analyzing alternative options or criticizing decision-makers to encourage their critical thinking. This diversity of roles has not yet been empirically explored in AI assistance. In this paper, we examine three AI roles: Recommender, Analyzer, and Devil's Advocate, and evaluate their effects across two AI performance levels. Our results show each role's distinct strengths and limitations in task performance, reliance appropriateness, and user experience. Notably, the Recommender role is not always the most effective, especially if the AI performance level is low, the Analyzer role may be preferable. These insights offer valuable implications for designing AI assistants with adaptive functional roles according to different situations.\n    ",
        "primary_category": "cs.HC",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01792": {
        "title": "ConSep: a Noise- and Reverberation-Robust Speech Separation Framework by Magnitude Conditioning",
        "authors": [
            "Kuan-Hsun Ho",
            "Jeih-weih Hung",
            "Berlin Chen"
        ],
        "comments": " ",
        "subjects": "Sound (cs.SD)",
        "abstract": "Speech separation has recently made significant progress thanks to the fine-grained vision used in time-domain methods. However, several studies have shown that adopting Short-Time Fourier Transform (STFT) for feature extraction could be beneficial when encountering harsher conditions, such as noise or reverberation. Therefore, we propose a magnitude-conditioned time-domain framework, ConSep, to inherit the beneficial characteristics. The experiment shows that ConSep promotes performance in anechoic, noisy, and reverberant settings compared to two celebrated methods, SepFormer and Bi-Sep. Furthermore, we visualize the components of ConSep to strengthen the advantages and cohere with the actualities we have found in preliminary studies.\n    ",
        "primary_category": "cs.SD",
        "categories": [
            "eess.AS"
        ],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01797": {
        "title": "Unleashing Graph Partitioning for Large-Scale Nearest Neighbor Search",
        "authors": [
            "Lars Gottesb\u00fcren",
            "Laxman Dhulipala",
            "Rajesh Jayaram",
            "Jakub Lacki"
        ],
        "comments": " ",
        "subjects": "Data Structures and Algorithms (cs.DS)",
        "abstract": "We consider the fundamental problem of decomposing a large-scale approximate nearest neighbor search (ANNS) problem into smaller sub-problems. The goal is to partition the input points into neighborhood-preserving shards, so that the nearest neighbors of any point are contained in only a few shards. When a query arrives, a routing algorithm is used to identify the shards which should be searched for its nearest neighbors. This approach forms the backbone of distributed ANNS, where the dataset is so large that it must be split across multiple machines.\nIn this paper, we design simple and highly efficient routing methods, and prove strong theoretical guarantees on their performance. A crucial characteristic of our routing algorithms is that they are inherently modular, and can be used with any partitioning method. This addresses a key drawback of prior approaches, where the routing algorithms are inextricably linked to their associated partitioning method. In particular, our new routing methods enable the use of balanced graph partitioning, which is a high-quality partitioning method without a naturally associated routing algorithm. Thus, we provide the first methods for routing using balanced graph partitioning that are extremely fast to train, admit low latency, and achieve high recall. We provide a comprehensive evaluation of our full partitioning and routing pipeline on billion-scale datasets, where it outperforms existing scalable partitioning methods by significant margins, achieving up to 2.14x higher QPS at 90% recall$@10$ than the best competitor.\n    ",
        "primary_category": "cs.DS",
        "categories": [
            "cs.IR"
        ],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01798": {
        "title": "Towards Fair and Efficient Learning-based Congestion Control",
        "authors": [
            "Xudong Liao",
            "Han Tian",
            "Chaoliang Zeng",
            "Xinchen Wan",
            "Kai Chen"
        ],
        "comments": " ",
        "subjects": "Networking and Internet Architecture (cs.NI)",
        "abstract": "Recent years have witnessed a plethora of learning-based solutions for congestion control (CC) that demonstrate better performance over traditional TCP schemes. However, they fail to provide consistently good convergence properties, including {\\em fairness}, {\\em fast convergence} and {\\em stability}, due to the mismatch between their objective functions and these properties. Despite being intuitive, integrating these properties into existing learning-based CC is challenging, because: 1) their training environments are designed for the performance optimization of single flow but incapable of cooperative multi-flow optimization, and 2) there is no directly measurable metric to represent these properties into the training objective function.\nWe present Astraea, a new learning-based congestion control that ensures fast convergence to fairness with stability. At the heart of Astraea is a multi-agent deep reinforcement learning framework that explicitly optimizes these convergence properties during the training process by enabling the learning of interactive policy between multiple competing flows, while maintaining high performance. We further build a faithful multi-flow environment that emulates the competing behaviors of concurrent flows, explicitly expressing convergence properties to enable their optimization during training. We have fully implemented Astraea and our comprehensive experiments show that Astraea can quickly converge to fairness point and exhibit better stability than its counterparts. For example, \\sys achieves near-optimal bandwidth sharing (i.e., fairness) when multiple flows compete for the same bottleneck, delivers up to 8.4$\\times$ faster convergence speed and 2.8$\\times$ smaller throughput deviation, while achieving comparable or even better performance over prior solutions.\n    ",
        "primary_category": "cs.NI",
        "categories": [
            "cs.LG"
        ],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01799": {
        "title": "Superpixel Graph Contrastive Clustering with Semantic-Invariant Augmentations for Hyperspectral Images",
        "authors": [
            "Jianhan Qi",
            "Yuheng Jia",
            "Hui Liu",
            "Junhui Hou"
        ],
        "comments": " ",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Hyperspectral images (HSI) clustering is an important but challenging task. The state-of-the-art (SOTA) methods usually rely on superpixels, however, they do not fully utilize the spatial and spectral information in HSI 3-D structure, and their optimization targets are not clustering-oriented. In this work, we first use 3-D and 2-D hybrid convolutional neural networks to extract the high-order spatial and spectral features of HSI through pre-training, and then design a superpixel graph contrastive clustering (SPGCC) model to learn discriminative superpixel representations. Reasonable augmented views are crucial for contrastive clustering, and conventional contrastive learning may hurt the cluster structure since different samples are pushed away in the embedding space even if they belong to the same class. In SPGCC, we design two semantic-invariant data augmentations for HSI superpixels: pixel sampling augmentation and model weight augmentation. Then sample-level alignment and clustering-center-level contrast are performed for better intra-class similarity and inter-class dissimilarity of superpixel embeddings. We perform clustering and network optimization alternatively. Experimental results on several HSI datasets verify the advantages of the proposed method, e.g., on India Pines, our model improves the clustering accuracy from 58.79% to 67.59% compared to the SOTA method.\n    ",
        "primary_category": "cs.CV",
        "categories": [],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01801": {
        "title": "COLA: Cross-city Mobility Transformer for Human Trajectory Simulation",
        "authors": [
            "Yu Wang",
            "Tongya Zheng",
            "Yuxuan Liang",
            "Shunyu Liu",
            "Mingli Song"
        ],
        "comments": "Accepted by WWW 2024",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Human trajectory data produced by daily mobile devices has proven its usefulness in various substantial fields such as urban planning and epidemic prevention. In terms of the individual privacy concern, human trajectory simulation has attracted increasing attention from researchers, targeting at offering numerous realistic mobility data for downstream tasks. Nevertheless, the prevalent issue of data scarcity undoubtedly degrades the reliability of existing deep learning models. In this paper, we are motivated to explore the intriguing problem of mobility transfer across cities, grasping the universal patterns of human trajectories to augment the powerful Transformer with external mobility data. There are two crucial challenges arising in the knowledge transfer across cities: 1) how to transfer the Transformer to adapt for domain heterogeneity; 2) how to calibrate the Transformer to adapt for subtly different long-tail frequency distributions of locations. To address these challenges, we have tailored a Cross-city mObiLity trAnsformer (COLA) with a dedicated model-agnostic transfer framework by effectively transferring cross-city knowledge for human trajectory simulation. Firstly, COLA divides the Transformer into the private modules for city-specific characteristics and the shared modules for city-universal mobility patterns. Secondly, COLA leverages a lightweight yet effective post-hoc adjustment strategy for trajectory simulation, without disturbing the complex bi-level optimization of model-agnostic knowledge transfer. Extensive experiments of COLA compared to state-of-the-art single-city baselines and our implemented cross-city baselines have demonstrated its superiority and effectiveness. The code is available at this https URL.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01803": {
        "title": "SAQIEL: Ultra-Light and Safe Manipulator with Passive 3D Wire Alignment Mechanism",
        "authors": [
            "Temma Suzuki",
            "Masahiro Bando",
            "Kento Kawaharazuka",
            "Kei Okada",
            "Masayuki Inaba"
        ],
        "comments": "accepted at IEEE Robotics and Automation Letters (RA-L), website -this https URL",
        "subjects": "Robotics (cs.RO)",
        "abstract": "Improving the safety of collaborative manipulators necessitates the reduction of inertia in the moving part. Within this paper, we introduce a novel approach in the form of a passive 3D wire aligner, serving as a lightweight and low-friction power transmission mechanism, thus achieving the desired low inertia in the manipulator's operation. Through the utilization of this innovation, the consolidation of hefty actuators onto the root link becomes feasible, consequently enabling a supple drive characterized by minimal friction. To demonstrate the efficacy of this device, we fabricate an ultralight 7 degrees of freedom (DoF) manipulator named SAQIEL, boasting a mere 1.5 kg weight for its moving components. Notably, to mitigate friction within SAQIEL's actuation system, we employ a distinctive mechanism that directly winds wires using motors, obviating the need for traditional gear or belt-based speed reduction mechanisms. Through a series of empirical trials, we substantiate that SAQIEL adeptly strikes balance between lightweight design, substantial payload capacity, elevated velocity, precision, and adaptability.\n    ",
        "primary_category": "cs.RO",
        "categories": [],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01804": {
        "title": "PointCore: Efficient Unsupervised Point Cloud Anomaly Detector Using Local-Global Features",
        "authors": [
            "Baozhu Zhao",
            "Qiwei Xiong",
            "Xiaohan Zhang",
            "Jingfeng Guo",
            "Qi Liu",
            "Xiaofen Xing",
            "Xiangmin Xu"
        ],
        "comments": " ",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Three-dimensional point cloud anomaly detection that aims to detect anomaly data points from a training set serves as the foundation for a variety of applications, including industrial inspection and autonomous driving. However, existing point cloud anomaly detection methods often incorporate multiple feature memory banks to fully preserve local and global representations, which comes at the high cost of computational complexity and mismatches between features. To address that, we propose an unsupervised point cloud anomaly detection framework based on joint local-global features, termed PointCore. To be specific, PointCore only requires a single memory bank to store local (coordinate) and global (PointMAE) representations and different priorities are assigned to these local-global features, thereby reducing the computational cost and mismatching disturbance in inference. Furthermore, to robust against the outliers, a normalization ranking method is introduced to not only adjust values of different scales to a notionally common scale, but also transform densely-distributed data into a uniform distribution. Extensive experiments on Real3D-AD dataset demonstrate that PointCore achieves competitive inference time and the best performance in both detection and localization as compared to the state-of-the-art Reg3D-AD approach and several competitors.\n    ",
        "primary_category": "cs.CV",
        "categories": [],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01805": {
        "title": "Tsallis Entropy Regularization for Linearly Solvable MDP and Linear Quadratic Regulator",
        "authors": [
            "Yota Hashizume",
            "Koshi Oishi",
            "Kenji Kashima"
        ],
        "comments": "6 figures",
        "subjects": "Optimization and Control (math.OC)",
        "abstract": "Shannon entropy regularization is widely adopted in optimal control due to its ability to promote exploration and enhance robustness, e.g., maximum entropy reinforcement learning known as Soft Actor-Critic. In this paper, Tsallis entropy, which is a one-parameter extension of Shannon entropy, is used for the regularization of linearly solvable MDP and linear quadratic regulators. We derive the solution for these problems and demonstrate its usefulness in balancing between exploration and sparsity of the obtained control law.\n    ",
        "primary_category": "math.OC",
        "categories": [
            "cs.LG",
            "eess.SY"
        ],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01807": {
        "title": "ViewDiff: 3D-Consistent Image Generation with Text-to-Image Models",
        "authors": [
            "Lukas H\u00f6llein",
            "Alja\u017e Bo\u017ei\u010d",
            "Norman M\u00fcller",
            "David Novotny",
            "Hung-Yu Tseng",
            "Christian Richardt",
            "Michael Zollh\u00f6fer",
            "Matthias Nie\u00dfner"
        ],
        "comments": "Accepted to CVPR 2024, project page: this https URL, video: this https URL, code: this https URL",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "3D asset generation is getting massive amounts of attention, inspired by the recent success of text-guided 2D content creation. Existing text-to-3D methods use pretrained text-to-image diffusion models in an optimization problem or fine-tune them on synthetic data, which often results in non-photorealistic 3D objects without backgrounds. In this paper, we present a method that leverages pretrained text-to-image models as a prior, and learn to generate multi-view images in a single denoising process from real-world data. Concretely, we propose to integrate 3D volume-rendering and cross-frame-attention layers into each block of the existing U-Net network of the text-to-image model. Moreover, we design an autoregressive generation that renders more 3D-consistent images at any viewpoint. We train our model on real-world datasets of objects and showcase its capabilities to generate instances with a variety of high-quality shapes and textures in authentic surroundings. Compared to the existing methods, the results generated by our method are consistent, and have favorable visual quality (-30% FID, -37% KID).\n    ",
        "primary_category": "cs.CV",
        "categories": [],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01809": {
        "title": "Deployment Challenges of Industrial Intrusion Detection Systems",
        "authors": [
            "Konrad Wolsing",
            "Eric Wagner",
            "Frederik Basels",
            "Patrick Wagner",
            "Klaus Wehrle"
        ],
        "comments": " ",
        "subjects": "Cryptography and Security (cs.CR)",
        "abstract": "With the escalating threats posed by cyberattacks on Industrial Control Systems (ICSs), the development of customized Industrial Intrusion Detection Systems (IIDSs) received significant attention in research. While existing literature proposes effective IIDS solutions evaluated in controlled environments, their deployment in real-world industrial settings poses several challenges. This paper highlights two critical yet often overlooked aspects that significantly impact their practical deployment, i.e., the need for sufficient amounts of data to train the IIDS models and the challenges associated with finding suitable hyperparameters, especially for IIDSs training only on genuine ICS data. Through empirical experiments conducted on multiple state-of-the-art IIDSs and diverse datasets, we establish the criticality of these issues in deploying IIDSs. Our findings show the necessity of extensive malicious training data for supervised IIDSs, which can be impractical considering the complexity of recording and labeling attacks in actual industrial environments. Furthermore, while other IIDSs circumvent the previous issue by requiring only benign training data, these can suffer from the difficulty of setting appropriate hyperparameters, which likewise can diminish their performance. By shedding light on these challenges, we aim to enhance the understanding of the limitations and considerations necessary for deploying effective cybersecurity solutions in ICSs, which might be one reason why IIDSs see few deployments.\n    ",
        "primary_category": "cs.CR",
        "categories": [],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01812": {
        "title": "Simulation-based High-Speed Elongational Rheometer for Carreau-type Materials",
        "authors": [
            "Lukas Kannengiesser",
            "Walter Arne",
            "Alexander Bier",
            "Nicole Marheineke",
            "Dirk W. Schubert",
            "Raimund Wegener"
        ],
        "comments": " ",
        "subjects": "Numerical Analysis (math.NA)",
        "abstract": "For the simulation-based design of fiber melt spinning processes, the accurate modeling of the processed polymer with regard to its material behavior is crucial. In this work, we develop a high-speed elongational rheometer for Carreau-type materials, making use of process simulations and fiber diameter measurements. The procedure is based on a unified formulation of the fiber spinning model for all material types (Newtonian and non-Newtonian), whose material laws are strictly monotone in the strain rate. The parametrically described material law for the elongational viscosity implies a nonlinear optimization problem for the parameter identification, for which we propose an efficient, robust gradient-based method. The work can be understood as a proof of concept, a generalization to other, more complex materials is possible.\n    ",
        "primary_category": "math.NA",
        "categories": [],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01813": {
        "title": "A Simple Baseline for Efficient Hand Mesh Reconstruction",
        "authors": [
            "Zhishan Zhou",
            "Shihao.zhou",
            "Zhi Lv",
            "Minqiang Zou",
            "Yao Tang",
            "Jiajun Liang"
        ],
        "comments": " ",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "3D hand pose estimation has found broad application in areas such as gesture recognition and human-machine interaction tasks. As performance improves, the complexity of the systems also increases, which can limit the comparative analysis and practical implementation of these methods. In this paper, we propose a simple yet effective baseline that not only surpasses state-of-the-art (SOTA) methods but also demonstrates computational efficiency. To establish this baseline, we abstract existing work into two components: a token generator and a mesh regressor, and then examine their core structures. A core structure, in this context, is one that fulfills intrinsic functions, brings about significant improvements, and achieves excellent performance without unnecessary complexities. Our proposed approach is decoupled from any modifications to the backbone, making it adaptable to any modern models. Our method outperforms existing solutions, achieving state-of-the-art (SOTA) results across multiple datasets. On the FreiHAND dataset, our approach produced a PA-MPJPE of 5.7mm and a PA-MPVPE of 6.0mm. Similarly, on the Dexycb dataset, we observed a PA-MPJPE of 5.5mm and a PA-MPVPE of 5.0mm. As for performance speed, our method reached up to 33 frames per second (fps) when using HRNet and up to 70 fps when employing FastViT-MA36\n    ",
        "primary_category": "cs.CV",
        "categories": [],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01816": {
        "title": "SMAUG: A Sliding Multidimensional Task Window-Based MARL Framework for Adaptive Real-Time Subtask Recognition",
        "authors": [
            "Wenjing Zhang",
            "Wei Zhang"
        ],
        "comments": " ",
        "subjects": "Artificial Intelligence (cs.AI)",
        "abstract": "Instead of making behavioral decisions directly from the exponentially expanding joint observational-action space, subtask-based multi-agent reinforcement learning (MARL) methods enable agents to learn how to tackle different subtasks. Most existing subtask-based MARL methods are based on hierarchical reinforcement learning (HRL). However, these approaches often limit the number of subtasks, perform subtask recognition periodically, and can only identify and execute a specific subtask within the predefined fixed time period, which makes them inflexible and not suitable for diverse and dynamic scenarios with constantly changing subtasks. To break through above restrictions, a \\textbf{S}liding \\textbf{M}ultidimensional t\\textbf{A}sk window based m\\textbf{U}ti-agent reinforcement learnin\\textbf{G} framework (SMAUG) is proposed for adaptive real-time subtask recognition. It leverages a sliding multidimensional task window to extract essential information of subtasks from trajectory segments concatenated based on observed and predicted trajectories in varying lengths. An inference network is designed to iteratively predict future trajectories with the subtask-oriented policy network. Furthermore, intrinsic motivation rewards are defined to promote subtask exploration and behavior diversity. SMAUG can be integrated with any Q-learning-based approach. Experiments on StarCraft II show that SMAUG not only demonstrates performance superiority in comparison with all baselines but also presents a more prominent and swift rise in rewards during the initial training stage.\n    ",
        "primary_category": "cs.AI",
        "categories": [
            "cs.MA"
        ],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01817": {
        "title": "NusaBERT: Teaching IndoBERT to be Multilingual and Multicultural",
        "authors": [
            "Wilson Wongso",
            "David Samuel Setiawan",
            "Steven Limcorn",
            "Ananto Joyoadikusumo"
        ],
        "comments": " ",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "Indonesia's linguistic landscape is remarkably diverse, encompassing over 700 languages and dialects, making it one of the world's most linguistically rich nations. This diversity, coupled with the widespread practice of code-switching and the presence of low-resource regional languages, presents unique challenges for modern pre-trained language models. In response to these challenges, we developed NusaBERT, building upon IndoBERT by incorporating vocabulary expansion and leveraging a diverse multilingual corpus that includes regional languages and dialects. Through rigorous evaluation across a range of benchmarks, NusaBERT demonstrates state-of-the-art performance in tasks involving multiple languages of Indonesia, paving the way for future natural language understanding research for under-represented languages.\n    ",
        "primary_category": "cs.CL",
        "categories": [],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01820": {
        "title": "Macroscopic auxiliary asymptotic preserving neural networks for the linear radiative transfer equations",
        "authors": [
            "Hongyan Li",
            "Song Jiang",
            "Wenjun Sun",
            "Liwei Xu",
            "Guanyu Zhou"
        ],
        "comments": "24 pages, 29 figures",
        "subjects": "Numerical Analysis (math.NA)",
        "abstract": "We develop a Macroscopic Auxiliary Asymptotic-Preserving Neural Network (MA-APNN) method to solve the time-dependent linear radiative transfer equations (LRTEs), which have a multi-scale nature and high dimensionality. To achieve this, we utilize the Physics-Informed Neural Networks (PINNs) framework and design a new adaptive exponentially weighted Asymptotic-Preserving (AP) loss function, which incorporates the macroscopic auxiliary equation that is derived from the original transfer equation directly and explicitly contains the information of the diffusion limit equation. Thus, as the scale parameter tends to zero, the loss function gradually transitions from the transport state to the diffusion limit state. In addition, the initial data, boundary conditions, and conservation laws serve as the regularization terms for the loss. We present several numerical examples to demonstrate the effectiveness of MA-APNNs.\n    ",
        "primary_category": "math.NA",
        "categories": [
            "cs.LG"
        ],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01823": {
        "title": "RT-H: Action Hierarchies Using Language",
        "authors": [
            "Suneel Belkhale",
            "Tianli Ding",
            "Ted Xiao",
            "Pierre Sermanet",
            "Quon Vuong",
            "Jonathan Tompson",
            "Yevgen Chebotar",
            "Debidatta Dwibedi",
            "Dorsa Sadigh"
        ],
        "comments": " ",
        "subjects": "Robotics (cs.RO)",
        "abstract": "Language provides a way to break down complex concepts into digestible pieces. Recent works in robot imitation learning use language-conditioned policies that predict actions given visual observations and the high-level task specified in language. These methods leverage the structure of natural language to share data between semantically similar tasks (e.g., \"pick coke can\" and \"pick an apple\") in multi-task datasets. However, as tasks become more semantically diverse (e.g., \"pick coke can\" and \"pour cup\"), sharing data between tasks becomes harder, so learning to map high-level tasks to actions requires much more demonstration data. To bridge tasks and actions, our insight is to teach the robot the language of actions, describing low-level motions with more fine-grained phrases like \"move arm forward\". Predicting these language motions as an intermediate step between tasks and actions forces the policy to learn the shared structure of low-level motions across seemingly disparate tasks. Furthermore, a policy that is conditioned on language motions can easily be corrected during execution through human-specified language motions. This enables a new paradigm for flexible policies that can learn from human intervention in language. Our method RT-H builds an action hierarchy using language motions: it first learns to predict language motions, and conditioned on this and the high-level task, it predicts actions, using visual context at all stages. We show that RT-H leverages this language-action hierarchy to learn policies that are more robust and flexible by effectively tapping into multi-task datasets. We show that these policies not only allow for responding to language interventions, but can also learn from such interventions and outperform methods that learn from teleoperated interventions. Our website and videos are found at this https URL.\n    ",
        "primary_category": "cs.RO",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01826": {
        "title": "A Novel Shortest Path Query Algorithm Based on Optimized Adaptive Topology Structure",
        "authors": [
            "Xiao Fang",
            "Xuyang Song",
            "Jiyuan Ma",
            "Guanhua Liu",
            "Shurong Pang",
            "Wenbo Zhao",
            "Cong Cao",
            "Ling Fan"
        ],
        "comments": " ",
        "subjects": "Computational Engineering, Finance, and Science (cs.CE)",
        "abstract": "Urban rail transit is a fundamental component of public transportation, however, commonly station-based path search algorithms often overlook the impact of transfer times on search results, leading to decreased accuracy. To solve this problem, this paper proposes a novel shortest path query algorithm based on adaptive topology optimization called the Adaptive Topology Extension Road Network Structure (ATEN). This algorithm categorizes transfer stations into different types and treats travel time and transfer time equivalently as weights for edges in the topological graph. The proposed algorithm introduces virtual stations to differentiate between pedestrian paths and train paths, eliminating the need for additional operations on transfer stations. The algorithm controls the extent of expansion in the urban rail transit topology, overcoming query errors caused by mishandling of transfer stations in the existing algorithm. Finally, a series of simulation experiments were conducted on Beijing's urban rail transit network to validate both correctness and efficiency of the proposed adaptive topology optimization algorithm. The results demonstrate significant advantages compared to existing similar algorithms.\n    ",
        "primary_category": "cs.CE",
        "categories": [],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01830": {
        "title": "Progressive Smoothing for Motion Planning in Real-Time NMPC",
        "authors": [
            "Rudolf Reiter",
            "Katrin Baumg\u00e4rtner",
            "Rien Quirynen",
            "Moritz Diehl"
        ],
        "comments": " ",
        "subjects": "Systems and Control (eess.SY)",
        "abstract": "Nonlinear model predictive control (NMPC) is a popular strategy for solving motion planning problems, including obstacle avoidance constraints, in autonomous driving applications. Non-smooth obstacle shapes, such as rectangles, introduce additional local minima in the underlying optimization problem. Smooth over-approximations, e.g., ellipsoidal shapes, limit the performance due to their conservativeness. We propose to vary the smoothness and the related over-approximation by a homotopy. Instead of varying the smoothness in consecutive sequential quadratic programming iterations, we use formulations that decrease the smooth over-approximation from the end towards the beginning of the prediction horizon. Thus, the real-time iterations algorithm is applicable to the proposed NMPC formulation. Different formulations are compared in simulation experiments and shown to successfully improve performance indicators without increasing the computation time.\n    ",
        "primary_category": "eess.SY",
        "categories": [
            "math.OC"
        ],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01832": {
        "title": "Model-Based Data-Centric AI: Bridging the Divide Between Academic Ideals and Industrial Pragmatism",
        "authors": [
            "Chanjun Park",
            "Minsoo Khang",
            "Dahyun Kim"
        ],
        "comments": "Accepted for Data-centric Machine Learning Research (DMLR) Workshop at ICLR 2024",
        "subjects": "Artificial Intelligence (cs.AI)",
        "abstract": "This paper delves into the contrasting roles of data within academic and industrial spheres, highlighting the divergence between Data-Centric AI and Model-Agnostic AI approaches. We argue that while Data-Centric AI focuses on the primacy of high-quality data for model performance, Model-Agnostic AI prioritizes algorithmic flexibility, often at the expense of data quality considerations. This distinction reveals that academic standards for data quality frequently do not meet the rigorous demands of industrial applications, leading to potential pitfalls in deploying academic models in real-world settings. Through a comprehensive analysis, we address these disparities, presenting both the challenges they pose and strategies for bridging the gap. Furthermore, we propose a novel paradigm: Model-Based Data-Centric AI, which aims to reconcile these differences by integrating model considerations into data optimization processes. This approach underscores the necessity for evolving data requirements that are sensitive to the nuances of both academic research and industrial deployment. By exploring these discrepancies, we aim to foster a more nuanced understanding of data's role in AI development and encourage a convergence of academic and industrial standards to enhance AI's real-world applicability.\n    ",
        "primary_category": "cs.AI",
        "categories": [
            "cs.CL"
        ],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01839": {
        "title": "Fully Polynomial-time Algorithms Parameterized by Vertex Integrity Using Fast Matrix Multiplication",
        "authors": [
            "Matthias Bentert",
            "Klaus Heeger",
            "Tomohiro Koana"
        ],
        "comments": " ",
        "subjects": "Data Structures and Algorithms (cs.DS)",
        "abstract": "We study the computational complexity of several polynomial-time-solvable graph problems parameterized by vertex integrity, a measure of a graph's vulnerability to vertex removal in terms of connectivity. Vertex integrity is the smallest number $\\iota$ such that there is a set $S$ of $\\iota' \\le \\iota$ vertices such that every connected component of $G-S$ contains at most $\\iota-\\iota'$ vertices. It is known that the vertex integrity lies between the well-studied parameters vertex cover number and tree-depth.\nAlon and Yuster [ESA 2007] designed algorithms for graphs with small vertex cover number using fast matrix multiplications. We demonstrate that fast matrix multiplication can also be effectively used when parameterizing by vertex integrity $\\iota$ by developing efficient algorithms for problems including an $O(\\iota^{\\omega-1}n)$-time algorithm for computing the girth of a graph, randomized $O(\\iota^{\\omega - 1}n)$-time algorithms for Maximum Matching and for finding any induced four-vertex subgraph except for a clique or an independent set, and an $O(\\iota^{(\\omega-1)/2}n^2) \\subseteq O(\\iota^{0.687} n^2)$-time algorithm for All-Pairs Shortest Paths. These algorithms can be faster than previous algorithms parameterized by tree-depth, for which fast matrix multiplication is not known to be effective.\n    ",
        "primary_category": "cs.DS",
        "categories": [],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01840": {
        "title": "FreeA: Human-object Interaction Detection using Free Annotation Labels",
        "authors": [
            "Yuxiao Wang",
            "Zhenao Wei",
            "Xinyu Jiang",
            "Yu Lei",
            "Weiying Xue",
            "Jinxiu Liu",
            "Qi Liu"
        ],
        "comments": "11 pages, 7 figures, 6 tables",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Recent human-object interaction (HOI) detection approaches rely on high cost of manpower and require comprehensive annotated image datasets. In this paper, we propose a novel self-adaption language-driven HOI detection method, termed as FreeA, without labeling by leveraging the adaptability of CLIP to generate latent HOI labels. To be specific, FreeA matches image features of human-object pairs with HOI text templates, and a priori knowledge-based mask method is developed to suppress improbable interactions. In addition, FreeA utilizes the proposed interaction correlation matching method to enhance the likelihood of actions related to a specified action, further refine the generated HOI labels. Experiments on two benchmark datasets show that FreeA achieves state-of-the-art performance among weakly supervised HOI models. Our approach is +8.58 mean Average Precision (mAP) on HICO-DET and +1.23 mAP on V-COCO more accurate in localizing and classifying the interactive actions than the newest weakly model, and +1.68 mAP and +7.28 mAP than the latest weakly+ model, respectively. Code will be available at this https URL.\n    ",
        "primary_category": "cs.CV",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01847": {
        "title": "Numerical Simulation of Phase Transition with the Hyperbolic Godunov-Peshkov-Romenski Model",
        "authors": [
            "Pascal Mossier",
            "Steven J\u00f6ns",
            "Simone Chiocchetti",
            "Andrea D. Beck",
            "Claus-Dieter Munz"
        ],
        "comments": " ",
        "subjects": "Numerical Analysis (math.NA)",
        "abstract": "In this paper, a thermodynamically consistent solution of the interfacial Riemann problem for the first-order hyperbolic continuum model of Godunov, Peshkov and Romenski (GPR model) is presented. In the presence of phase transition, interfacial physics are governed by molecular interaction on a microscopic scale, beyond the scope of the macroscopic continuum model in the bulk phases. The developed two-phase Riemann solvers tackle this multi-scale problem, by incorporating a local thermodynamic model to predict the interfacial entropy production. Using phenomenological relations of non-equilibrium thermodynamics, interfacial mass and heat fluxes are derived from the entropy production and provide closure at the phase boundary. We employ the proposed Riemann solvers in an efficient sharp interface level-set Ghost-Fluid framework to provide coupling conditions at phase interfaces under phase transition. As a single-phase benchmark, a Rayleigh-B\u00e9nard convection is studied to compare the hyperbolic thermal relaxation formulation of the GPR model against the hyperbolic-parabolic Euler-Fourier system. The novel interfacial Riemann solvers are validated against molecular dynamics simulations of evaporating shock tubes with the Lennard-Jones shifted and truncated potential. On a macroscopic scale, evaporating shock tubes are computed for the material n-Dodecane and compared against Euler-Fourier results. Finally, the efficiency and robustness of the scheme is demonstrated with shock-droplet interaction simulations that involve both phase transfer and surface tension, while featuring severe interface deformations.\n    ",
        "primary_category": "math.NA",
        "categories": [],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01848": {
        "title": "CET2: Modelling Topic Transitions for Coherent and Engaging Knowledge-Grounded Conversations",
        "authors": [
            "Lin Xu",
            "Qixian Zhou",
            "Jinlan Fu",
            "See-Kiong Ng"
        ],
        "comments": "Accepted by TASLP",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "Knowledge-grounded dialogue systems aim to generate coherent and engaging responses based on the dialogue contexts and selected external knowledge. Previous knowledge selection methods tend to rely too heavily on the dialogue contexts or over-emphasize the new information in the selected knowledge, resulting in the selection of repetitious or incongruous knowledge and further generating repetitive or incoherent responses, as the generation of the response depends on the chosen knowledge. To address these shortcomings, we introduce a Coherent and Engaging Topic Transition (CET2) framework to model topic transitions for selecting knowledge that is coherent to the context of the conversations while providing adequate knowledge diversity for topic development. Our CET2 framework considers multiple factors for knowledge selection, including valid transition logic from dialogue contexts to the following topics and systematic comparisons between available knowledge candidates. Extensive experiments on two public benchmarks demonstrate the superiority and the better generalization ability of CET2 on knowledge selection. This is due to our well-designed transition features and comparative knowledge selection strategy, which are more transferable to conversations about unseen topics. Analysis of fine-grained knowledge selection accuracy also shows that CET2 can better balance topic entailment (contextual coherence) and development (knowledge diversity) in dialogue than existing approaches.\n    ",
        "primary_category": "cs.CL",
        "categories": [],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01849": {
        "title": "One Prompt Word is Enough to Boost Adversarial Robustness for Pre-trained Vision-Language Models",
        "authors": [
            "Lin Li",
            "Haoyan Guan",
            "Jianing Qiu",
            "Michael Spratling"
        ],
        "comments": "CVPR2024",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Large pre-trained Vision-Language Models (VLMs) like CLIP, despite having remarkable generalization ability, are highly vulnerable to adversarial examples. This work studies the adversarial robustness of VLMs from the novel perspective of the text prompt instead of the extensively studied model weights (frozen in this work). We first show that the effectiveness of both adversarial attack and defense are sensitive to the used text prompt. Inspired by this, we propose a method to improve resilience to adversarial attacks by learning a robust text prompt for VLMs. The proposed method, named Adversarial Prompt Tuning (APT), is effective while being both computationally and data efficient. Extensive experiments are conducted across 15 datasets and 4 data sparsity schemes (from 1-shot to full training data settings) to show APT's superiority over hand-engineered prompts and other state-of-the-art adaption methods. APT demonstrated excellent abilities in terms of the in-distribution performance and the generalization under input distribution shift and across datasets. Surprisingly, by simply adding one learned word to the prompts, APT can significantly boost the accuracy and robustness (epsilon=4/255) over the hand-engineered prompts by +13% and +8.5% on average respectively. The improvement further increases, in our most effective setting, to +26.4% for accuracy and +16.7% for robustness. Code is available at this https URL.\n    ",
        "primary_category": "cs.CV",
        "categories": [
            "cs.AI",
            "cs.LG"
        ],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01851": {
        "title": "Rethinking LLM Language Adaptation: A Case Study on Chinese Mixtral",
        "authors": [
            "Yiming Cui",
            "Xin Yao"
        ],
        "comments": "13 pages",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "Mixtral, a representative sparse mixture of experts (SMoE) language model, has received significant attention due to its unique model design and superior performance. Based on Mixtral-8x7B-v0.1, in this paper, we propose Chinese-Mixtral and Chinese-Mixtral-Instruct with improved Chinese language abilities by adopting further pre-training and instruction fine-tuning. Experimental results show that our Chinese-Mixtral and Chinese-Mixtral-Instruct successfully improve Chinese understanding and generation performance while retaining the original English abilities. Then, we discuss several key questions when performing language adaptation on large language models, including the necessity of extending the language-specific vocabulary and the choice of the initialization model (foundation model v.s. instruction model), by providing empirical results and analysis. We also present the visualizations of each expert to examine their importance on downstream tasks. Our resources are publicly available through \\url{this https URL}.\n    ",
        "primary_category": "cs.CL",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01852": {
        "title": "PLACE: Adaptive Layout-Semantic Fusion for Semantic Image Synthesis",
        "authors": [
            "Zhengyao Lv",
            "Yuxiang Wei",
            "Wangmeng Zuo",
            "Kwan-Yee K. Wong"
        ],
        "comments": " ",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Recent advancements in large-scale pre-trained text-to-image models have led to remarkable progress in semantic image synthesis. Nevertheless, synthesizing high-quality images with consistent semantics and layout remains a challenge. In this paper, we propose the adaPtive LAyout-semantiC fusion modulE (PLACE) that harnesses pre-trained models to alleviate the aforementioned issues. Specifically, we first employ the layout control map to faithfully represent layouts in the feature space. Subsequently, we combine the layout and semantic features in a timestep-adaptive manner to synthesize images with realistic details. During fine-tuning, we propose the Semantic Alignment (SA) loss to further enhance layout alignment. Additionally, we introduce the Layout-Free Prior Preservation (LFP) loss, which leverages unlabeled data to maintain the priors of pre-trained models, thereby improving the visual quality and semantic consistency of synthesized images. Extensive experiments demonstrate that our approach performs favorably in terms of visual quality, semantic consistency, and layout alignment. The source code and model are available at this https URL.\n    ",
        "primary_category": "cs.CV",
        "categories": [],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01857": {
        "title": "Reward Model Learning vs. Direct Policy Optimization: A Comparative Analysis of Learning from Human Preferences",
        "authors": [
            "Andi Nika",
            "Debmalya Mandal",
            "Parameswaran Kamalaruban",
            "Georgios Tzannetos",
            "Goran Radanovi\u0107",
            "Adish Singla"
        ],
        "comments": " ",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "In this paper, we take a step towards a deeper understanding of learning from human preferences by systematically comparing the paradigm of reinforcement learning from human feedback (RLHF) with the recently proposed paradigm of direct preference optimization (DPO). We focus our attention on the class of loglinear policy parametrization and linear reward functions. In order to compare the two paradigms, we first derive minimax statistical bounds on the suboptimality gap induced by both RLHF and DPO, assuming access to an oracle that exactly solves the optimization problems. We provide a detailed discussion on the relative comparison between the two paradigms, simultaneously taking into account the sample size, policy and reward class dimensions, and the regularization temperature. Moreover, we extend our analysis to the approximate optimization setting and derive exponentially decaying convergence rates for both RLHF and DPO. Next, we analyze the setting where the ground-truth reward is not realizable and find that, while RLHF incurs a constant additional error, DPO retains its asymptotically decaying gap by just tuning the temperature accordingly. Finally, we extend our comparison to the Markov decision process setting, where we generalize our results with exact optimization. To the best of our knowledge, we are the first to provide such a comparative analysis for RLHF and DPO.\n    ",
        "primary_category": "cs.LG",
        "categories": [],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01858": {
        "title": "An Improved Traditional Chinese Evaluation Suite for Foundation Model",
        "authors": [
            "Zhi-Rui Tam",
            "Ya-Ting Pai",
            "Yen-Wei Lee",
            "Sega Cheng",
            "Hong-Han Shuai"
        ],
        "comments": " ",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "We present TMMLU+, a comprehensive dataset designed for the Traditional Chinese massive multitask language understanding dataset. TMMLU+ is a multiple-choice question-answering dataset with 66 subjects from elementary to professional level. Compared to its predecessor, TMMLU, TMMLU+ is six times larger and boasts a more balanced subject distribution. We included benchmark results in TMMLU+ from closed-source models and 24 open-weight Chinese large language models of parameters ranging from 1.8B to 72B. Our findings reveal that Traditional Chinese models still trail behind their Simplified Chinese counterparts. Additionally, current large language models have yet to outperform human performance in average scores. We publicly release our dataset and the corresponding benchmark source code.\n    ",
        "primary_category": "cs.CL",
        "categories": [],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01859": {
        "title": "CSE: Surface Anomaly Detection with Contrastively Selected Embedding",
        "authors": [
            "Simon Thomine",
            "Hichem Snoussi"
        ],
        "comments": "9 pages, VISAPP 2024 conference",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Detecting surface anomalies of industrial materials poses a significant challenge within a myriad of industrial manufacturing processes. In recent times, various methodologies have emerged, capitalizing on the advantages of employing a network pre-trained on natural images for the extraction of representative features. Subsequently, these features are subjected to processing through a diverse range of techniques including memory banks, normalizing flow, and knowledge distillation, which have exhibited exceptional accuracy. This paper revisits approaches based on pre-trained features by introducing a novel method centered on target-specific embedding. To capture the most representative features of the texture under consideration, we employ a variant of a contrastive training procedure that incorporates both artificially generated defective samples and anomaly-free samples during training. Exploiting the intrinsic properties of surfaces, we derived a meaningful representation from the defect-free samples during training, facilitating a straightforward yet effective calculation of anomaly scores. The experiments conducted on the MVTEC AD and TILDA datasets demonstrate the competitiveness of our approach compared to state-of-the-art methods.\n    ",
        "primary_category": "cs.CV",
        "categories": [],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01860": {
        "title": "MaliGNNoma: GNN-Based Malicious Circuit Classifier for Secure Cloud FPGAs",
        "authors": [
            "Lilas Alrahis",
            "Hassan Nassar",
            "Jonas Krautter",
            "Dennis Gnad",
            "Lars Bauer",
            "Jorg Henkel",
            "Mehdi Tahoori"
        ],
        "comments": "Will appear in the 2024 IEEE International Symposium on Hardware Oriented Security and Trust (HOST)",
        "subjects": "Cryptography and Security (cs.CR)",
        "abstract": "The security of cloud field-programmable gate arrays (FPGAs) faces challenges from untrusted users attempting fault and side-channel attacks through malicious circuit configurations. Fault injection attacks can result in denial of service, disrupting functionality or leaking secret information. This threat is further amplified in multi-tenancy scenarios. Detecting such threats before loading onto the FPGA is crucial, but existing methods face difficulty identifying sophisticated attacks.\nWe present MaliGNNoma, a machine learning-based solution that accurately identifies malicious FPGA configurations. Serving as a netlist scanning mechanism, it can be employed by cloud service providers as an initial security layer within a necessary multi-tiered security system. By leveraging the inherent graph representation of FPGA netlists, MaliGNNoma employs a graph neural network (GNN) to learn distinctive malicious features, surpassing current approaches. To enhance transparency, MaliGNNoma utilizes a parameterized explainer for the GNN, labeling the FPGA configuration and pinpointing the sub-circuit responsible for the malicious classification.\nThrough extensive experimentation on the ZCU102 board with a Xilinx UltraScale+ FPGA, we validate the effectiveness of MaliGNNoma in detecting malicious configurations, including sophisticated attacks, such as those based on benign modules, like cryptography accelerators. MaliGNNoma achieves a classification accuracy and precision of 98.24% and 97.88%, respectively, surpassing state-of-the-art. We compare MaliGNNoma with five state-of-the-art scanning methods, revealing that not all attack vectors detected by MaliGNNoma are recognized by existing solutions, further emphasizing its effectiveness. Additionally, we make MaliGNNoma and its associated dataset publicly available.\n    ",
        "primary_category": "cs.CR",
        "categories": [],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01862": {
        "title": "MTS: Bringing Multi-Tenancy to Virtual Networking",
        "authors": [
            "Kashyap Thimmaraju",
            "Saad Hermak",
            "G\u00e1bor R\u00e9tv\u00e1ri",
            "Stefan Schmid"
        ],
        "comments": " ",
        "subjects": "Cryptography and Security (cs.CR)",
        "abstract": "Multi-tenant cloud computing provides great benefits in terms of resource sharing, elastic pricing, and scalability, however, it also changes the security landscape and introduces the need for strong isolation between the tenants, also inside the network. This paper is motivated by the observation that while multi-tenancy is widely used in cloud computing, the virtual switch designs currently used for network virtualization lack sufficient support for tenant isolation. Hence, we present, implement, and evaluate a virtual switch architecture, MTS, which brings secure design best-practice to the context of multi-tenant virtual networking: compartmentalization of virtual switches, least-privilege execution, complete mediation of all network communication, and reducing the trusted computing base shared between tenants. We build MTS from commodity components, providing an incrementally deployable and inexpensive upgrade path to cloud operators. Our extensive experiments, extending to both micro-benchmarks and cloud applications, show that, depending on the way it is deployed, MTS may produce 1.5-2x the throughput compared to state-of-the-art, with similar or better latency and modest resource overhead (1 extra CPU). MTS is available as open source software.\n    ",
        "primary_category": "cs.CR",
        "categories": [
            "cs.NI"
        ],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01863": {
        "title": "Schema-Based Query Optimisation for Graph Databases",
        "authors": [
            "Chandan Sharma",
            "Pierre Genev\u00e8s",
            "Nils Gesbert",
            "Nabil Laya\u00efda"
        ],
        "comments": " ",
        "subjects": "Databases (cs.DB)",
        "abstract": "Recursive graph queries are increasingly popular for extracting information from interconnected data found in various domains such as social networks, life sciences, and business analytics. Graph data often come with schema information that describe how nodes and edges are organized. We propose a type inference mechanism that enriches recursive graph queries with relevant structural information contained in a graph schema. We show that this schema information can be useful in order to improve the performance when evaluating acylic recursive graph queries. Furthermore, we prove that the proposed method is sound and complete, ensuring that the semantics of the query is preserved during the schema-enrichment process.\n    ",
        "primary_category": "cs.DB",
        "categories": [],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01864": {
        "title": "RCoCo: Contrastive Collective Link Prediction across Multiplex Network in Riemannian Space",
        "authors": [
            "Li Sun",
            "Mengjie Li",
            "Yong Yang",
            "Xiao Li",
            "Lin Liu",
            "Pengfei Zhang",
            "Haohua Du"
        ],
        "comments": "Accepted by Springer International Journal of Machine Learning and Cybernetics (JMLC), 2024",
        "subjects": "Social and Information Networks (cs.SI)",
        "abstract": "Link prediction typically studies the probability of future interconnection among nodes with the observation in a single social network. More often than not, real scenario is presented as a multiplex network with common (anchor) users active in multiple social networks. In the literature, most existing works study either the intra-link prediction in a single network or inter-link prediction among networks (a.k.a. network alignment), and consider two learning tasks are independent from each other, which is still away from the fact. On the representation space, the vast majority of existing methods are built upon the traditional Euclidean space, unaware of the inherent geometry of social networks. The third issue is on the scarce anchor users. Annotating anchor users is laborious and expensive, and thus it is impractical to work with quantities of anchor users. Herein, in light of the issues above, we propose to study a challenging yet practical problem of Geometry-aware Collective Link Prediction across Multiplex Network. To address this problem, we present a novel contrastive model, RCoCo, which collaborates intra- and inter-network behaviors in Riemannian spaces. In RCoCo, we design a curvature-aware graph attention network ($\\kappa-$GAT), conducting attention mechanism in Riemannian manifold whose curvature is estimated by the Ricci curvatures over the network. Thereafter, we formulate intra- and inter-contrastive loss in the manifolds, in which we augment graphs by exploring the high-order structure of community and information transfer on anchor users. Finally, we conduct extensive experiments with 14 strong baselines on 8 real-world datasets, and show the effectiveness of RCoCo.\n    ",
        "primary_category": "cs.SI",
        "categories": [
            "cs.LG"
        ],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01866": {
        "title": "Circular Programs and Self-Referential Structures",
        "authors": [
            "Lloyd Allison"
        ],
        "comments": " ",
        "subjects": "Programming Languages (cs.PL)",
        "abstract": "A circular program creates a data structure whose computation depends upon itself or refers to itself. The technique is used to implement the classic data structures circular and doubly-linked lists, threaded trees and queues, in a functional programming language. These structures are normally thought to require updatable variables found in imperative languages. For example, a functional program to perform the breadth-first traversal of a tree is given. Some of the examples result in circular data structures when evaluated. Some examples are particularly space-efficient by avoiding the creation of intermediate temporary structures which would otherwise later become garbage. Lastly, the technique can be applied in an imperative language to give an elegant program.\n    ",
        "primary_category": "cs.PL",
        "categories": [],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01867": {
        "title": "Deciding Separation Logic with Pointer Arithmetic and Inductive Definitions",
        "authors": [
            "Wanyun Su",
            "Zhilin Wu",
            "Mihaela Sighireanu"
        ],
        "comments": " ",
        "subjects": "Logic in Computer Science (cs.LO)",
        "abstract": "Pointer arithmetic is widely used in low-level programs, e.g. memory allocators. The specification of such programs usually requires using pointer arithmetic inside inductive definitions to define the common data structures, e.g. heap lists in memory allocators. In this work, we investigate decision problems for SLAH, a separation logic fragment that allows pointer arithmetic inside inductive definitions, thus enabling specification of properties for programs manipulating heap lists. Pointer arithmetic inside inductive definitions is challenging for automated reasoning. We tackle this challenge and achieve decision procedures for both satisfiability and entailment of SLAH formulas. The crux of our decision procedure for satisfiability is to compute summaries of inductive definitions. We show that although the summary is naturally expressed as an existentially quantified non-linear arithmetic formula, it can actually be transformed into an equivalent linear arithmetic formula. The decision procedure for entailment, on the other hand, has to match and split the spatial atoms according to the arithmetic relation between address variables. We report on the implementation of these decision procedures and their good performance in solving problems issued from the verification of building block programs used in memory allocators.\n    ",
        "primary_category": "cs.LO",
        "categories": [],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01868": {
        "title": "Map-aided annotation for pole base detection",
        "authors": [
            "Benjamin Missaoui",
            "Maxime Noizet",
            "Philippe Xu"
        ],
        "comments": " ",
        "subjects": "Image and Video Processing (eess.IV)",
        "abstract": "For autonomous navigation, high definition maps are a widely used source of information. Pole-like features encoded in HD maps such as traffic signs, traffic lights or street lights can be used as landmarks for localization. For this purpose, they first need to be detected by the vehicle using its embedded sensors. While geometric models can be used to process 3D point clouds retrieved by lidar sensors, modern image-based approaches rely on deep neural network and therefore heavily depend on annotated training data. In this paper, a 2D HD map is used to automatically annotate pole-like features in images. In the absence of height information, the map features are represented as pole bases at the ground level. We show how an additional lidar sensor can be used to filter out occluded features and refine the ground projection. We also demonstrate how an object detector can be trained to detect a pole base. To evaluate our methodology, it is first validated with data manually annotated from semantic segmentation and then compared to our own automatically generated annotated data recorded in the city of Compi{\u00e8}gne, France. Erratum: In the original version [1], an error occurred in the accuracy evaluation of the different models studied and the evaluation method applied on the detection results was not clearly defined. In this revision, we offer a rectification to this segment, presenting updated results, especially in terms of Mean Absolute Errors (MAE).\n    ",
        "primary_category": "eess.IV",
        "categories": [
            "cs.CV"
        ],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01871": {
        "title": "Penetration Testing of 5G Core Network Web Technologies",
        "authors": [
            "Filippo Giambartolomei",
            "Marc Barcel\u00f3",
            "Alessandro Brighente",
            "Aitor Urbieta",
            "Mauro Conti"
        ],
        "comments": " ",
        "subjects": "Cryptography and Security (cs.CR)",
        "abstract": "Thanks to technologies such as virtual network function the Fifth Generation (5G) of mobile networks dynamically allocate resources to different types of users in an on-demand fashion. Virtualization extends up to the 5G core, where software-defined networks and network slicing implement a customizable environment. These technologies can be controlled via application programming interfaces and web technologies, inheriting hence their security risks and settings. An attacker exploiting vulnerable implementations of the 5G core may gain privileged control of the network assets and disrupt its availability. However, there is currently no security assessment of the web security of the 5G core network.\nIn this paper, we present the first security assessment of the 5G core from a web security perspective. We use the STRIDE threat modeling approach to define a complete list of possible threat vectors and associated attacks. Thanks to a suite of security testing tools, we cover all of these threats and test the security of the 5G core. In particular, we test the three most relevant open-source 5G core implementations, i.e., Open5GS, Free5Gc, and OpenAirInterface. Our analysis shows that all these cores are vulnerable to at least two of our identified attack vectors, demanding increased security measures in the development of future 5G core networks.\n    ",
        "primary_category": "cs.CR",
        "categories": [],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01873": {
        "title": "Recommending Missed Citations Identified by Reviewers: A New Task, Dataset and Baselines",
        "authors": [
            "Kehan Long",
            "Shasha Li",
            "Pancheng Wang",
            "Chenlong Bao",
            "Jintao Tang",
            "Ting Wang"
        ],
        "comments": "COLING 2024",
        "subjects": "Information Retrieval (cs.IR)",
        "abstract": "Citing comprehensively and appropriately has become a challenging task with the explosive growth of scientific publications. Current citation recommendation systems aim to recommend a list of scientific papers for a given text context or a draft paper. However, none of the existing work focuses on already included citations of full papers, which are imperfect and still have much room for improvement. In the scenario of peer reviewing, it is a common phenomenon that submissions are identified as missing vital citations by reviewers. This may lead to a negative impact on the credibility and validity of the research presented. To help improve citations of full papers, we first define a novel task of Recommending Missed Citations Identified by Reviewers (RMC) and construct a corresponding expert-labeled dataset called CitationR. We conduct an extensive evaluation of several state-of-the-art methods on CitationR. Furthermore, we propose a new framework RMCNet with an Attentive Reference Encoder module mining the relevance between papers, already-made citations, and missed citations. Empirical results prove that RMC is challenging, with the proposed architecture outperforming previous methods in all metrics. We release our dataset and benchmark models to motivate future research on this challenging new task.\n    ",
        "primary_category": "cs.IR",
        "categories": [],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01874": {
        "title": "A Survey on Evaluation of Out-of-Distribution Generalization",
        "authors": [
            "Han Yu",
            "Jiashuo Liu",
            "Xingxuan Zhang",
            "Jiayun Wu",
            "Peng Cui"
        ],
        "comments": " ",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Machine learning models, while progressively advanced, rely heavily on the IID assumption, which is often unfulfilled in practice due to inevitable distribution shifts. This renders them susceptible and untrustworthy for deployment in risk-sensitive applications. Such a significant problem has consequently spawned various branches of works dedicated to developing algorithms capable of Out-of-Distribution (OOD) generalization. Despite these efforts, much less attention has been paid to the evaluation of OOD generalization, which is also a complex and fundamental problem. Its goal is not only to assess whether a model's OOD generalization capability is strong or not, but also to evaluate where a model generalizes well or poorly. This entails characterizing the types of distribution shifts that a model can effectively address, and identifying the safe and risky input regions given a model. This paper serves as the first effort to conduct a comprehensive review of OOD evaluation. We categorize existing research into three paradigms: OOD performance testing, OOD performance prediction, and OOD intrinsic property characterization, according to the availability of test data. Additionally, we briefly discuss OOD evaluation in the context of pretrained models. In closing, we propose several promising directions for future research in OOD evaluation.\n    ",
        "primary_category": "cs.LG",
        "categories": [],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01875": {
        "title": "ICLN: Input Convex Loss Network for Decision Focused Learning",
        "authors": [
            "Haeun Jeon",
            "Hyunglip Bae",
            "Minsu Park",
            "Chanyeong Kim",
            "Woo Chang Kim"
        ],
        "comments": " ",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "In decision-making problem under uncertainty, predicting unknown parameters is often considered independent of the optimization part. Decision-focused Learning (DFL) is a task-oriented framework to integrate prediction and optimization by adapting predictive model to give better decision for the corresponding task. Here, an inevitable challenge arises when computing gradients of the optimal decision with respect to the parameters. Existing researches cope this issue by smoothly reforming surrogate optimization or construct surrogate loss function that mimic task loss. However, they are applied to restricted optimization domain or build functions in a local manner leading a large computational time. In this paper, we propose Input Convex Loss Network (ICLN), a novel global surrogate loss which can be implemented in a general DFL paradigm. ICLN learns task loss via Input Convex Neural Networks which is guaranteed to be convex for some inputs, while keeping the global structure for the other inputs. This enables ICLN to admit general DFL through only a single surrogate loss without any sense for choosing appropriate parametric forms. We confirm effectiveness and flexibility of ICLN by evaluating our proposed model with three stochastic decision-making problems.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01876": {
        "title": "D\u00e9j\u00e0Vu: KV-cache Streaming for Fast, Fault-tolerant Generative LLM Serving",
        "authors": [
            "Foteini Strati",
            "Sara Mcallister",
            "Amar Phanishayee",
            "Jakub Tarnawski",
            "Ana Klimovic"
        ],
        "comments": " ",
        "subjects": "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "abstract": "Distributed LLM serving is costly and often underutilizes hardware accelerators due to three key challenges: bubbles in pipeline-parallel deployments caused by the bimodal latency of prompt and token processing, GPU memory overprovisioning, and long recovery times in case of failures. In this paper, we propose D\u00e9j\u00e0Vu, a system to address all these challenges using a versatile and efficient KV cache streaming library (D\u00e9j\u00e0VuLib). Using D\u00e9j\u00e0VuLib, we propose and implement efficient prompt-token disaggregation to reduce pipeline bubbles, microbatch swapping for efficient GPU memory management, and state replication for fault-tolerance. We highlight the efficacy of these solutions on a range of large models across cloud deployments.\n    ",
        "primary_category": "cs.DC",
        "categories": [],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01878": {
        "title": "I DPID It My Way! A Covert Timing Channel in Software-Defined Networks",
        "authors": [
            "Robert Kr\u00f6sche",
            "Kashyap Thimmaraju",
            "Liron Schiff",
            "Stefan Schmid"
        ],
        "comments": " ",
        "subjects": "Cryptography and Security (cs.CR)",
        "abstract": "Software-defined networking is considered a promising new paradigm, enabling more reliable and formally verifiable communication networks. However, this paper shows that the separation of the control plane from the data plane, which lies at the heart of Software-Defined Networks (SDNs), can be exploited for covert channels based on SDN Teleportation, even when the data planes are physically disconnected.\nThis paper describes the theoretical model and design of our covert timing channel based on SDN Teleportation. We implement our covert channel using a popular SDN switch, Open vSwitch, and a popular SDN controller, ONOS. Our evaluation of the prototype shows that even under load at the controller, throughput rates of 20 bits per second are possible, with a communication accuracy of approximately 90\\%. We also discuss techniques to increase the throughput further.\n    ",
        "primary_category": "cs.CR",
        "categories": [
            "cs.NI"
        ],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01882": {
        "title": "Using Virtual Reality for Detection and Intervention of Depression -- A Systematic Literature Review",
        "authors": [
            "Mohammad Waqas",
            "Y Pawankumar Gururaj",
            "V D Shanmukha Mitra",
            "Sai Anirudh Karri",
            "Raghu Reddy",
            "Syed Azeemuddin"
        ],
        "comments": "8 pages, 2 figures, 3 tables, Conference full paper",
        "subjects": "Human-Computer Interaction (cs.HC)",
        "abstract": "The use of emerging technologies like Virtual Reality (VR) in therapeutic settings has increased in the past few years. By incorporating VR, a mental health condition like depression can be assessed effectively, while also providing personalized motivation and meaningful engagement for treatment purposes. The integration of external sensors further enhances the engagement of the subjects with the VR scenes. This paper presents a comprehensive review of existing literature on the detection and treatment of depression using VR. It explores various types of VR scenes, external hardware, innovative metrics, and targeted user studies conducted by researchers and professionals in the field. The paper also discusses potential requirements for designing VR scenes specifically tailored for depression assessment and treatment, with the aim of guiding future practitioners in this area.\n    ",
        "primary_category": "cs.HC",
        "categories": [],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01886": {
        "title": "FCDS: Fusing Constituency and Dependency Syntax into Document-Level Relation Extraction",
        "authors": [
            "Xudong Zhu",
            "Zhao Kang",
            "Bei Hui"
        ],
        "comments": "Appear in COLING 2024",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "Document-level Relation Extraction (DocRE) aims to identify relation labels between entities within a single document. It requires handling several sentences and reasoning over them. State-of-the-art DocRE methods use a graph structure to connect entities across the document to capture dependency syntax information. However, this is insufficient to fully exploit the rich syntax information in the document. In this work, we propose to fuse constituency and dependency syntax into DocRE. It uses constituency syntax to aggregate the whole sentence information and select the instructive sentences for the pairs of targets. It exploits the dependency syntax in a graph structure with constituency syntax enhancement and chooses the path between entity pairs based on the dependency graph. The experimental results on datasets from various domains demonstrate the effectiveness of the proposed method. The code is publicly available at this url.\n    ",
        "primary_category": "cs.CL",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01887": {
        "title": "On $3$-dimensional MRD codes of type $\\langle x^{q^t},x+\u03b4x^{q^{2t}},G(x) \\rangle$",
        "authors": [
            "Daniele Bartoli",
            "Francesco Ghiandoni"
        ],
        "comments": " ",
        "subjects": "Information Theory (cs.IT)",
        "abstract": "In this work we present results on the classification of $\\mathbb{F}_{q^n}$-linear MRD codes of dimension three. In particular, using connections with certain algebraic varieties over finite fields, we provide non-existence results for MRD codes $\\mathcal{C}=\\langle x^{q^t}, F(x), G(x) \\rangle \\subseteq \\mathcal{L}_{n,q}$ of exceptional type, i.e. such that $\\mathcal{C}$ is MRD over infinite many extensions of the field $\\mathbb{F}_{q^n}$. These results partially address a conjecture of Bartoli, Zini and Zullo in 2023.\n    ",
        "primary_category": "cs.IT",
        "categories": [
            "math.AG"
        ],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01891": {
        "title": "Gotta catch 'em all, safely! Aerial-deployed soft underwater gripper",
        "authors": [
            "Luca Romanello",
            "Daniel Joseph Amir",
            "Heinrich Stengel",
            "Mirko Kovac",
            "Sophie F. Armanini"
        ],
        "comments": "8 pages, 10 figures, Accepted in IEEE International Conference on Soft Robotics 2024 (Robosoft)",
        "subjects": "Robotics (cs.RO)",
        "abstract": "Underwater soft grippers exhibit potential for applications such as monitoring, research, and object retrieval. However, existing underwater gripping techniques frequently cause disturbances to ecosystems. In response to this challenge, we present a novel underwater gripping framework comprising a lightweight gripper affixed to a custom submarine pod deployable via drone. This approach minimizes water disturbance and enables efficient navigation to target areas, enhancing overall mission effectiveness. The pod allows for underwater motion and is characterized by four degrees of freedom. It is provided with a custom buoyancy system, two water pumps for differential thrust and two for pitching. The system allows for buoyancy adjustments up to a depth of 6 meters, as well as motion in the plane. The 3-fingered gripper is manufactured out of silicone and was successfully tested on objects with different shapes and sizes, demonstrating a maximum pulling force of up to 8 N when underwater. The reliability of the submarine pod was tested in a water tank by tracking its attitude and energy consumption during grasping maneuvers. The system also accomplished a successful mission in a lake, where it was deployed on a hexacopter. Overall, the integration of this system expands the operational capabilities of underwater grasping, makes grasping missions more efficient and easy to automate, as well as causing less disturbance to the water ecosystem.\n    ",
        "primary_category": "cs.RO",
        "categories": [],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01892": {
        "title": "Information Lower Bounds for Robust Mean Estimation",
        "authors": [
            "R\u00e9my Degenne",
            "Timoth\u00e9e Mathieu"
        ],
        "comments": " ",
        "subjects": "Statistics Theory (math.ST)",
        "abstract": "We prove lower bounds on the error of any estimator for the mean of a real probability distribution under the knowledge that the distribution belongs to a given set. We apply these lower bounds both to parametric and nonparametric estimation. In the nonparametric case, we apply our results to the question of sub-Gaussian estimation for distributions with finite variance to obtain new lower bounds in the small error probability regime, and present an optimal estimator in that regime. In the (semi-)parametric case, we use the Fisher information to provide distribution-dependent lower bounds that are constant-tight asymptotically, of order $\\sqrt{2\\log(1/\\delta)/(nI)}$ where $I$ is the Fisher information of the distribution. We use known minimizers of the Fisher information on some nonparametric set of distributions to give lower bounds in cases such as corrupted distributions, or bounded/semi-bounded distributions.\n    ",
        "primary_category": "math.ST",
        "categories": [
            "cs.IT"
        ],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01895": {
        "title": "Unsupervised Distance Metric Learning for Anomaly Detection Over Multivariate Time Series",
        "authors": [
            "Hanyang Yuan",
            "Qinglin Cai",
            "Keting Yin"
        ],
        "comments": " ",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Distance-based time series anomaly detection methods are prevalent due to their relative non-parametric nature and interpretability. However, the commonly used Euclidean distance is sensitive to noise. While existing works have explored dynamic time warping (DTW) for its robustness, they only support supervised tasks over multivariate time series (MTS), leaving a scarcity of unsupervised methods. In this work, we propose FCM-wDTW, an unsupervised distance metric learning method for anomaly detection over MTS, which encodes raw data into latent space and reveals normal dimension relationships through cluster centers. FCM-wDTW introduces locally weighted DTW into fuzzy C-means clustering and learns the optimal latent space efficiently, enabling anomaly identification via data reconstruction. Experiments with 11 different types of benchmarks demonstrate our method's competitive accuracy and efficiency.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01896": {
        "title": "Robustness Bounds on the Successful Adversarial Examples: Theory and Practice",
        "authors": [
            "Hiroaki Maeshima",
            "Akira Otsuka"
        ],
        "comments": " ",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Adversarial example (AE) is an attack method for machine learning, which is crafted by adding imperceptible perturbation to the data inducing misclassification. In the current paper, we investigated the upper bound of the probability of successful AEs based on the Gaussian Process (GP) classification. We proved a new upper bound that depends on AE's perturbation norm, the kernel function used in GP, and the distance of the closest pair with different labels in the training dataset. Surprisingly, the upper bound is determined regardless of the distribution of the sample dataset. We showed that our theoretical result was confirmed through the experiment using ImageNet. In addition, we showed that changing the parameters of the kernel function induces a change of the upper bound of the probability of successful AEs.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.CR",
            "stat.ML"
        ],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01898": {
        "title": "Revisiting Learning-based Video Motion Magnification for Real-time Processing",
        "authors": [
            "Hyunwoo Ha",
            "Oh Hyun-Bin",
            "Kim Jun-Seong",
            "Kwon Byung-Ki",
            "Kim Sung-Bin",
            "Linh-Tam Tran",
            "Ji-Yun Kim",
            "Sung-Ho Bae",
            "Tae-Hyun Oh"
        ],
        "comments": "19 pages",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Video motion magnification is a technique to capture and amplify subtle motion in a video that is invisible to the naked eye. The deep learning-based prior work successfully demonstrates the modelling of the motion magnification problem with outstanding quality compared to conventional signal processing-based ones. However, it still lags behind real-time performance, which prevents it from being extended to various online applications. In this paper, we investigate an efficient deep learning-based motion magnification model that runs in real time for full-HD resolution videos. Due to the specified network design of the prior art, i.e. inhomogeneous architecture, the direct application of existing neural architecture search methods is complicated. Instead of automatic search, we carefully investigate the architecture module by module for its role and importance in the motion magnification task. Two key findings are 1) Reducing the spatial resolution of the latent motion representation in the decoder provides a good trade-off between computational efficiency and task quality, and 2) surprisingly, only a single linear layer and a single branch in the encoder are sufficient for the motion magnification task. Based on these findings, we introduce a real-time deep learning-based motion magnification model with4.2X fewer FLOPs and is 2.7X faster than the prior art while maintaining comparable quality.\n    ",
        "primary_category": "cs.CV",
        "categories": [
            "eess.IV"
        ],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01900": {
        "title": "Universality of reservoir systems with recurrent neural networks",
        "authors": [
            "Hiroki Yasumoto",
            "Toshiyuki Tanaka"
        ],
        "comments": " ",
        "subjects": "Neural and Evolutionary Computing (cs.NE)",
        "abstract": "Approximation capability of reservoir systems whose reservoir is a recurrent neural network (RNN) is discussed. In our problem setting, a reservoir system approximates a set of functions just by adjusting its linear readout while the reservoir is fixed. We will show what we call uniform strong universality of a family of RNN reservoir systems for a certain class of functions to be approximated. This means that, for any positive number, we can construct a sufficiently large RNN reservoir system whose approximation error for each function in the class of functions to be approximated is bounded from above by the positive number. Such RNN reservoir systems are constructed via parallel concatenation of RNN reservoirs.\n    ",
        "primary_category": "cs.NE",
        "categories": [
            "cs.LG"
        ],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01902": {
        "title": "Random Generation of Git Graphs",
        "authors": [
            "Julien Courtiel",
            "Martin P\u00e9pin"
        ],
        "comments": " ",
        "subjects": "Data Structures and Algorithms (cs.DS)",
        "abstract": "Version Control Systems, such as Git and Mercurial, manage the history of a project as a Directed Acyclic Graph encoding the various divergences and synchronizations happening in its life cycle. A popular workflow in the industry, called the feature branch workflow, constrains these graphs to be of a particular shape: a unique main branch, and non-interfering feature branches. Here we focus on the uniform random generation of those graphs with n vertices, including k on the main branch, for which we provide three algorithms, for three different use-cases. The first, based on rejection, is efficient when aiming for small values of k (more precisely whenever k = O($\\sqrt$ n)). The second takes as input any number k of commits in the main branch, but requires costly precalculation. The last one is a Boltzmann generator and enables us to generate very large graphs while targeting a constant k/n ratio. All these algorithms are linear in the size of their outputs.\n    ",
        "primary_category": "cs.DS",
        "categories": [
            "math.CO"
        ],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01907": {
        "title": "Capacity of the Hebbian-Hopfield network associative memory",
        "authors": [
            "Mihailo Stojnic"
        ],
        "comments": " ",
        "subjects": "Machine Learning (stat.ML)",
        "abstract": "In \\cite{Hop82}, Hopfield introduced a \\emph{Hebbian} learning rule based neural network model and suggested how it can efficiently operate as an associative memory. Studying random binary patterns, he also uncovered that, if a small fraction of errors is tolerated in the stored patterns retrieval, the capacity of the network (maximal number of memorized patterns, $m$) scales linearly with each pattern's size, $n$. Moreover, he famously predicted $\\alpha_c=\\lim_{n\\rightarrow\\infty}\\frac{m}{n}\\approx 0.14$. We study this very same scenario with two famous pattern's basins of attraction: \\textbf{\\emph{(i)}} The AGS one from \\cite{AmiGutSom85}; and \\textbf{\\emph{(ii)}} The NLT one from \\cite{Newman88,Louk94,Louk94a,Louk97,Tal98}. Relying on the \\emph{fully lifted random duality theory} (fl RDT) from \\cite{Stojnicflrdt23}, we obtain the following explicit capacity characterizations on the first level of lifting:\n\\begin{equation}\n\\alpha_c^{(AGS,1)} = \\left ( \\max_{\\delta\\in \\left ( 0,\\frac{1}{2}\\right ) }\\frac{1-2\\delta}{\\sqrt{2} \\mbox{erfinv} \\left ( 1-2\\delta\\right )} - \\frac{2}{\\sqrt{2\\pi}} e^{-\\left ( \\mbox{erfinv}\\left ( 1-2\\delta \\right )\\right )^2}\\right )^2 \\approx \\mathbf{0.137906} \\end{equation}\n\\begin{equation}\n\\alpha_c^{(NLT,1)} = \\frac{\\mbox{erf}(x)^2}{2x^2}-1+\\mbox{erf}(x)^2 \\approx \\mathbf{0.129490}, \\quad 1-\\mbox{erf}(x)^2- \\frac{2\\mbox{erf}(x)e^{-x^2}}{\\sqrt{\\pi}x}+\\frac{2e^{-2x^2}}{\\pi}=0. \\end{equation}\nA substantial numerical work gives on the second level of lifting $\\alpha_c^{(AGS,2)} \\approx \\mathbf{0.138186}$ and $\\alpha_c^{(NLT,2)} \\approx \\mathbf{0.12979}$, effectively uncovering a remarkably fast lifting convergence. Moreover, the obtained AGS characterizations exactly match the replica symmetry based ones of \\cite{AmiGutSom85} and the corresponding symmetry breaking ones of \\cite{SteKuh94}.\n    ",
        "primary_category": "stat.ML",
        "categories": [
            "cond-mat.dis-nn",
            "cs.IT",
            "cs.LG",
            "math.PR"
        ],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01909": {
        "title": "Semi-Supervised Semantic Segmentation Based on Pseudo-Labels: A Survey",
        "authors": [
            "Lingyan Ran",
            "Yali Li",
            "Guoqiang Liang",
            "Yanning Zhang"
        ],
        "comments": " ",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Semantic segmentation is an important and popular research area in computer vision that focuses on classifying pixels in an image based on their semantics. However, supervised deep learning requires large amounts of data to train models and the process of labeling images pixel by pixel is time-consuming and laborious. This review aims to provide a first comprehensive and organized overview of the state-of-the-art research results on pseudo-label methods in the field of semi-supervised semantic segmentation, which we categorize from different perspectives and present specific methods for specific application areas. In addition, we explore the application of pseudo-label technology in medical and remote-sensing image segmentation. Finally, we also propose some feasible future research directions to address the existing challenges.\n    ",
        "primary_category": "cs.CV",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01915": {
        "title": "xT: Nested Tokenization for Larger Context in Large Images",
        "authors": [
            "Ritwik Gupta",
            "Shufan Li",
            "Tyler Zhu",
            "Jitendra Malik",
            "Trevor Darrell",
            "Karttikeya Mangalam"
        ],
        "comments": " ",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Modern computer vision pipelines handle large images in one of two sub-optimal ways: down-sampling or cropping. These two methods incur significant losses in the amount of information and context present in an image. There are many downstream applications in which global context matters as much as high frequency details, such as in real-world satellite imagery; in such cases researchers have to make the uncomfortable choice of which information to discard. We introduce xT, a simple framework for vision transformers which effectively aggregates global context with local details and can model large images end-to-end on contemporary GPUs. We select a set of benchmark datasets across classic vision tasks which accurately reflect a vision model's ability to understand truly large images and incorporate fine details over large scales and assess our method's improvement on them. By introducing a nested tokenization scheme for large images in conjunction with long-sequence length models normally used for natural language processing, we are able to increase accuracy by up to 8.6% on challenging classification tasks and $F_1$ score by 11.6 on context-dependent segmentation in large images.\n    ",
        "primary_category": "cs.CV",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01918": {
        "title": "Towards Continuous Assurance Case Creation for ADS with the Evidential Tool Bus",
        "authors": [
            "Lev Sorokin",
            "Radouane Bouchekir",
            "Tewodros A. Beyene",
            "Brian Hsuan-Cheng Liao",
            "Adam Molin"
        ],
        "comments": "Accepted at International SafeAutonomy Workshop at EDCC '24",
        "subjects": "Software Engineering (cs.SE)",
        "abstract": "An assurance case has become an integral component for the certification of safety-critical systems. While manually defining assurance case patterns can be not avoided, system-specific instantiations of assurance case patterns are both costly and time-consuming. It becomes especially complex to maintain an assurance case for a system when the requirements of the System-Under-Assurance change, or an assurance claim becomes invalid due to, e.g., degradation of a systems component, as common when deploying learning-enabled components. In this paper, we report on our preliminary experience leveraging the tool integration framework Evidential Tool Bus (ETB) for the construction and continuous maintenance of an assurance case from a predefined assurance case pattern. Specifically, we demonstrate the assurance process on an industrial Automated Valet Parking system from the automotive domain. We present the formalization of the provided assurance case pattern in the ETB processable logical specification language of workflows. Our findings show that ETB is able to create and maintain evidence required for the construction of an assurance case.\n    ",
        "primary_category": "cs.SE",
        "categories": [
            "cs.LG"
        ],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01920": {
        "title": "Projected Newton method for large-scale Bayesian linear inverse problems",
        "authors": [
            "Haibo Li"
        ],
        "comments": " ",
        "subjects": "Numerical Analysis (math.NA)",
        "abstract": "Computing the regularized solution of Bayesian linear inverse problems as well as the corresponding regularization parameter is highly desirable in many applications. This paper proposes a novel iterative method, termed the Projected Newton method (PNT), that can simultaneously update the regularization parameter and solution step by step without requiring any high-cost matrix inversions or decompositions. By reformulating the Tikhonov regularization as a constrained minimization problem and writing its Lagrangian function, a Newton-type method coupled with a Krylov subspace method, called the generalized Golub-Kahan bidiagonalization, is employed for the unconstrained Lagrangian function. The resulting PNT algorithm only needs solving a small-scale linear system to get a descent direction of a merit function at each iteration, thus significantly reducing computational overhead. Rigorous convergence results are proved, showing that PNT always converges to the unique regularized solution and the corresponding Lagrangian multiplier. Experimental results on both small and large-scale Bayesian inverse problems demonstrate its excellent convergence property, robustness and efficiency. Given that the most demanding computational tasks in PNT are primarily matrix-vector products, it is particularly well-suited for large-scale problems.\n    ",
        "primary_category": "math.NA",
        "categories": [],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01921": {
        "title": "Arabic Text Sentiment Analysis: Reinforcing Human-Performed Surveys with Wider Topic Analysis",
        "authors": [
            "Latifah Almurqren",
            "Ryan Hodgson",
            "Alexandra Cristea"
        ],
        "comments": " ",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "Sentiment analysis (SA) has been, and is still, a thriving research area. However, the task of Arabic sentiment analysis (ASA) is still underrepresented in the body of research. This study offers the first in-depth and in-breadth analysis of existing ASA studies of textual content and identifies their common themes, domains of application, methods, approaches, technologies and algorithms used. The in-depth study manually analyses 133 ASA papers published in the English language between 2002 and 2020 from four academic databases (SAGE, IEEE, Springer, WILEY) and from Google Scholar. The in-breadth study uses modern, automatic machine learning techniques, such as topic modelling and temporal analysis, on Open Access resources, to reinforce themes and trends identified by the prior study, on 2297 ASA publications between 2010-2020. The main findings show the different approaches used for ASA: machine learning, lexicon-based and hybrid approaches. Other findings include ASA 'winning' algorithms (SVM, NB, hybrid methods). Deep learning methods, such as LSTM can provide higher accuracy, but for ASA sometimes the corpora are not large enough to support them. Additionally, whilst there are some ASA corpora and lexicons, more are required. Specifically, Arabic tweets corpora and datasets are currently only moderately sized. Moreover, Arabic lexicons that have high coverage contain only Modern Standard Arabic (MSA) words, and those with Arabic dialects are quite small. Thus, new corpora need to be created. On the other hand, ASA tools are stringently lacking. There is a need to develop ASA tools that can be used in industry, as well as in academia, for Arabic text SA. Hence, our study offers insights into the challenges associated with ASA research and provides suggestions for ways to move the field forward such as lack of Dialectical Arabic resource, Arabic tweets, corpora and data sets for SA.\n    ",
        "primary_category": "cs.CL",
        "categories": [],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01922": {
        "title": "FlowPrecision: Advancing FPGA-Based Real-Time Fluid Flow Estimation with Linear Quantization",
        "authors": [
            "Tianheng Ling",
            "Julian Hoever",
            "Chao Qian",
            "Gregor Schiele"
        ],
        "comments": "6 pages, 3 figures, The 22nd International Conference on Pervasive Computing and Communications (PerCom 2024), PerConAI Workshop",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "In industrial and environmental monitoring, achieving real-time and precise fluid flow measurement remains a critical challenge. This study applies linear quantization in FPGA-based soft sensors for fluid flow estimation, significantly enhancing Neural Network model precision by overcoming the limitations of traditional fixed-point quantization. Our approach achieves up to a 10.10% reduction in Mean Squared Error and a notable 9.39% improvement in inference speed through targeted hardware optimizations. Validated across multiple data sets, our findings demonstrate that the optimized FPGA-based quantized models can provide efficient, accurate real-time inference, offering a viable alternative to cloud-based processing in pervasive autonomous systems.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "physics.flu-dyn"
        ],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01924": {
        "title": "To Generate or to Retrieve? On the Effectiveness of Artificial Contexts for Medical Open-Domain Question Answering",
        "authors": [
            "Giacomo Frisoni",
            "Alessio Cocchieri",
            "Alex Presepi",
            "Gianluca Moro",
            "Zaiqiao Meng"
        ],
        "comments": " ",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "Medical open-domain question answering demands substantial access to specialized knowledge. Recent efforts have sought to decouple knowledge from model parameters, counteracting architectural scaling and allowing for training on common low-resource hardware. The retrieve-then-read paradigm has become ubiquitous, with model predictions grounded on relevant knowledge pieces from external repositories such as PubMed, textbooks, and UMLS. An alternative path, still under-explored but made possible by the advent of domain-specific large language models, entails constructing artificial contexts through prompting. As a result, \"to generate or to retrieve\" is the modern equivalent of Hamlet's dilemma. This paper presents MedGENIE, the first generate-then-read framework for multiple-choice question answering in medicine. We conduct extensive experiments on MedQA-USMLE, MedMCQA, and MMLU, incorporating a practical perspective by assuming a maximum of 24GB VRAM. MedGENIE sets a new state-of-the-art (SOTA) in the open-book setting of each testbed, even allowing a small-scale reader to outcompete zero-shot closed-book 175B baselines while using up to 706$\\times$ fewer parameters. Overall, our findings reveal that generated passages are more effective than retrieved counterparts in attaining higher accuracy.\n    ",
        "primary_category": "cs.CL",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01926": {
        "title": "IndicVoices: Towards building an Inclusive Multilingual Speech Dataset for Indian Languages",
        "authors": [
            "Tahir Javed",
            "Janki Atul Nawale",
            "Eldho Ittan George",
            "Sakshi Joshi",
            "Kaushal Santosh Bhogale",
            "Deovrat Mehendale",
            "Ishvinder Virender Sethi",
            "Aparna Ananthanarayanan",
            "Hafsah Faquih",
            "Pratiti Palit",
            "Sneha Ravishankar",
            "Saranya Sukumaran",
            "Tripura Panchagnula",
            "Sunjay Murali",
            "Kunal Sharad Gandhi",
            "Ambujavalli R",
            "Manickam K M",
            "C Venkata Vaijayanthi",
            "Krishnan Srinivasa Raghavan Karunganni",
            "Pratyush Kumar",
            "Mitesh M Khapra"
        ],
        "comments": " ",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "We present INDICVOICES, a dataset of natural and spontaneous speech containing a total of 7348 hours of read (9%), extempore (74%) and conversational (17%) audio from 16237 speakers covering 145 Indian districts and 22 languages. Of these 7348 hours, 1639 hours have already been transcribed, with a median of 73 hours per language. Through this paper, we share our journey of capturing the cultural, linguistic and demographic diversity of India to create a one-of-its-kind inclusive and representative dataset. More specifically, we share an open-source blueprint for data collection at scale comprising of standardised protocols, centralised tools, a repository of engaging questions, prompts and conversation scenarios spanning multiple domains and topics of interest, quality control mechanisms, comprehensive transcription guidelines and transcription tools. We hope that this open source blueprint will serve as a comprehensive starter kit for data collection efforts in other multilingual regions of the world. Using INDICVOICES, we build IndicASR, the first ASR model to support all the 22 languages listed in the 8th schedule of the Constitution of India. All the data, tools, guidelines, models and other materials developed as a part of this work will be made publicly available\n    ",
        "primary_category": "cs.CL",
        "categories": [],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01927": {
        "title": "Advancing Gene Selection in Oncology: A Fusion of Deep Learning and Sparsity for Precision Gene Selection",
        "authors": [
            "Akhila Krishna",
            "Ravi Kant Gupta",
            "Pranav Jeevan",
            "Amit Sethi"
        ],
        "comments": " ",
        "subjects": "Genomics (q-bio.GN)",
        "abstract": "Gene selection plays a pivotal role in oncology research for improving outcome prediction accuracy and facilitating cost-effective genomic profiling for cancer patients. This paper introduces two gene selection strategies for deep learning-based survival prediction models. The first strategy uses a sparsity-inducing method while the second one uses importance based gene selection for identifying relevant genes. Our overall approach leverages the power of deep learning to model complex biological data structures, while sparsity-inducing methods ensure the selection process focuses on the most informative genes, minimizing noise and redundancy. Through comprehensive experimentation on diverse genomic and survival datasets, we demonstrate that our strategy not only identifies gene signatures with high predictive power for survival outcomes but can also streamlines the process for low-cost genomic profiling. The implications of this research are profound as it offers a scalable and effective tool for advancing personalized medicine and targeted cancer therapies. By pushing the boundaries of gene selection methodologies, our work contributes significantly to the ongoing efforts in cancer genomics, promising improved diagnostic and prognostic capabilities in clinical settings.\n    ",
        "primary_category": "q-bio.GN",
        "categories": [
            "cs.CV",
            "q-bio.QM",
            "q-bio.TO"
        ],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01928": {
        "title": "ZSL-RPPO: Zero-Shot Learning for Quadrupedal Locomotion in Challenging Terrains using Recurrent Proximal Policy Optimization",
        "authors": [
            "Yao Zhao",
            "Tao Wu",
            "Yijie Zhu",
            "Xiang Lu",
            "Jun Wang",
            "Haitham Bou-Ammar",
            "Xinyu Zhang",
            "Peng Du"
        ],
        "comments": " ",
        "subjects": "Robotics (cs.RO)",
        "abstract": "We present ZSL-RPPO, an improved zero-shot learning architecture that overcomes the limitations of teacher-student neural networks and enables generating robust, reliable, and versatile locomotion for quadrupedal robots in challenging terrains. We propose a new algorithm RPPO (Recurrent Proximal Policy Optimization) that directly trains recurrent neural network in partially observable environments and results in more robust training using domain randomization. Our locomotion controller supports extensive perturbation across simulation-to-reality transfer for both intrinsic and extrinsic physical parameters without further fine-tuning. This can avoid the significant decline of student's performance during simulation-to-reality transfer and therefore enhance the robustness and generalization of the locomotion controller. We deployed our controller on the Unitree A1 and Aliengo robots in real environment and exteroceptive perception is provided by either a solid-state Lidar or a depth camera. Our locomotion controller was tested in various challenging terrains like slippery surfaces, Grassy Terrain, and stairs. Our experiment results and comparison show that our approach significantly outperforms the state-of-the-art.\n    ",
        "primary_category": "cs.RO",
        "categories": [],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01929": {
        "title": "Analyzing and Adapting Large Language Models for Few-Shot Multilingual NLU: Are We There Yet?",
        "authors": [
            "Evgeniia Razumovskaia",
            "Ivan Vuli\u0107",
            "Anna Korhonen"
        ],
        "comments": " ",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "Supervised fine-tuning (SFT), supervised instruction tuning (SIT) and in-context learning (ICL) are three alternative, de facto standard approaches to few-shot learning. ICL has gained popularity recently with the advent of LLMs due to its simplicity and sample efficiency. Prior research has conducted only limited investigation into how these approaches work for multilingual few-shot learning, and the focus so far has been mostly on their performance. In this work, we present an extensive and systematic comparison of the three approaches, testing them on 6 high- and low-resource languages, three different NLU tasks, and a myriad of language and domain setups. Importantly, performance is only one aspect of the comparison, where we also analyse the approaches through the optics of their computational, inference and financial costs. Our observations show that supervised instruction tuning has the best trade-off between performance and resource requirements. As another contribution, we analyse the impact of target language adaptation of pretrained LLMs and find that the standard adaptation approaches can (superficially) improve target language generation capabilities, but language understanding elicited through ICL does not improve and remains limited, with low scores especially for low-resource languages.\n    ",
        "primary_category": "cs.CL",
        "categories": [],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01931": {
        "title": "VariErr NLI: Separating Annotation Error from Human Label Variation",
        "authors": [
            "Leon Weber-Genzel",
            "Siyao Peng",
            "Marie-Catherine de Marneffe",
            "Barbara Plank"
        ],
        "comments": "13 pages, under review",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "Human label variation arises when annotators assign different labels to the same item for valid reasons, while annotation errors occur when labels are assigned for invalid reasons. These two issues are prevalent in NLP benchmarks, yet existing research has studied them in isolation. To the best of our knowledge, there exists no prior work that focuses on teasing apart error from signal, especially in cases where signal is beyond black-and-white. To fill this gap, we introduce a systematic methodology and a new dataset, VariErr (variation versus error), focusing on the NLI task in English. We propose a 2-round annotation scheme with annotators explaining each label and subsequently judging the validity of label-explanation pairs. \\name{} contains 7,574 validity judgments on 1,933 explanations for 500 re-annotated NLI items. We assess the effectiveness of various automatic error detection (AED) methods and GPTs in uncovering errors versus human label variation. We find that state-of-the-art AED methods significantly underperform compared to GPTs and humans. While GPT-4 is the best system, it still falls short of human performance. Our methodology is applicable beyond NLI, offering fertile ground for future research on error versus plausible variation, which in turn can yield better and more trustworthy NLP systems.\n    ",
        "primary_category": "cs.CL",
        "categories": [],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01939": {
        "title": "A Type Theory with a Tiny Object",
        "authors": [
            "Mitchell Riley"
        ],
        "comments": "29 pages",
        "subjects": "Category Theory (math.CT)",
        "abstract": "We present an extension of Martin-L\u00f6f Type Theory that contains a tiny object; a type for which there is a right adjoint to the formation of function types as well as the expected left adjoint. We demonstrate the practicality of this type theory by proving various properties related to tininess internally and suggest a few potential applications.\n    ",
        "primary_category": "math.CT",
        "categories": [
            "cs.PL",
            "math.LO"
        ],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01942": {
        "title": "Mitigating Label Noise on Graph via Topological Sample Selection",
        "authors": [
            "Yuhao Wu",
            "Jiangchao Yao",
            "Xiaobo Xia",
            "Jun Yu",
            "Ruxin Wang",
            "Bo Han",
            "Tongliang Liu"
        ],
        "comments": " ",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Despite the success of the carefully-annotated benchmarks, the effectiveness of existing graph neural networks (GNNs) can be considerably impaired in practice when the real-world graph data is noisily labeled. Previous explorations in sample selection have been demonstrated as an effective way for robust learning with noisy labels, however, the conventional studies focus on i.i.d data, and when moving to non-iid graph data and GNNs, two notable challenges remain: (1) nodes located near topological class boundaries are very informative for classification but cannot be successfully distinguished by the heuristic sample selection. (2) there is no available measure that considers the graph topological information to promote sample selection in a graph. To address this dilemma, we propose a $\\textit{Topological Sample Selection}$ (TSS) method that boosts the informative sample selection process in a graph by utilising topological information. We theoretically prove that our procedure minimizes an upper bound of the expected risk under target clean distribution, and experimentally show the superiority of our method compared with state-of-the-art baselines.\n    ",
        "primary_category": "cs.LG",
        "categories": [],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01946": {
        "title": "A Generative Model of Symmetry Transformations",
        "authors": [
            "James Urquhart Allingham",
            "Bruno Kacper Mlodozeniec",
            "Shreyas Padhy",
            "Javier Antor\u00e1n",
            "David Krueger",
            "Richard E. Turner",
            "Eric Nalisnick",
            "Jos\u00e9 Miguel Hern\u00e1ndez-Lobato"
        ],
        "comments": " ",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Correctly capturing the symmetry transformations of data can lead to efficient models with strong generalization capabilities, though methods incorporating symmetries often require prior knowledge. While recent advancements have been made in learning those symmetries directly from the dataset, most of this work has focused on the discriminative setting. In this paper, we construct a generative model that explicitly aims to capture symmetries in the data, resulting in a model that learns which symmetries are present in an interpretable way. We provide a simple algorithm for efficiently learning our generative model and demonstrate its ability to capture symmetries under affine and color transformations. Combining our symmetry model with existing generative models results in higher marginal test-log-likelihoods and robustness to data sparsification.\n    ",
        "primary_category": "cs.LG",
        "categories": [],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01947": {
        "title": "Characterization of Chordal Circular-arc Graphs: I. Split Graphs",
        "authors": [
            "Yixin Cao",
            "Jan Derbisz",
            "Tomasz Krawczyk"
        ],
        "comments": " ",
        "subjects": "Combinatorics (math.CO)",
        "abstract": "The most elusive problem around the class of circular-arc graphs is identifying all minimal graphs that are not in this class. The main obstacle is the lack of a systematic way of enumerating these minimal graphs. McConnell [FOCS 2001] presented a transformation from circular-arc graphs to interval graphs with certain patterns of representations. We fully characterize these interval patterns for circular-arc graphs that are split graphs, thereby building a connection between minimal split graphs that are not circular-arc graphs and minimal non-interval graphs. This connection enables us to identify all minimal split graphs that are not circular-arc graphs. As a byproduct, we develop a linear-time certifying recognition algorithm for circular-arc graphs when the input is a split graph.\n    ",
        "primary_category": "math.CO",
        "categories": [
            "cs.DM"
        ],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01948": {
        "title": "On Fractional Moment Estimation from Polynomial Chaos Expansion",
        "authors": [
            "Luk\u00e1\u0161 Nov\u00e1k",
            "Marcos Valdebenito",
            "Matthias Faes"
        ],
        "comments": " ",
        "subjects": "Methodology (stat.ME)",
        "abstract": "Fractional statistical moments are utilized for various tasks of uncertainty quantification, including the estimation of probability distributions. However, an estimation of fractional statistical moments of costly mathematical models by statistical sampling is challenging since it is typically not possible to create a large experimental design due to limitations in computing capacity. This paper presents a novel approach for the analytical estimation of fractional moments, directly from polynomial chaos expansions. Specifically, the first four statistical moments obtained from the deterministic PCE coefficients are used for an estimation of arbitrary fractional moments via H\u00f6lder's inequality. The proposed approach is utilized for an estimation of statistical moments and probability distributions in three numerical examples of increasing complexity. Obtained results show that the proposed approach achieves a superior performance in estimating the distribution of the response, in comparison to a standard Latin hypercube sampling in the presented examples.\n    ",
        "primary_category": "stat.ME",
        "categories": [
            "cs.LG"
        ],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01952": {
        "title": "On the Challenges of Transforming UVL to IVML",
        "authors": [
            "Prankur Agarwal",
            "Kevin Feichtinger",
            "Klaus Schmid",
            "Holger Eichelberger",
            "Rick Rabiser"
        ],
        "comments": "Presented at 6th International Workshop on Languages for Modelling Variability (MODEVAR'24) (arXiv:cs/2402.15511)",
        "subjects": "Software Engineering (cs.SE)",
        "abstract": "Software product line techniques encourage the reuse and adaptation of software components for creating customized products or software systems. These different product variants have commonalities and differences, which are managed by variability modeling. Over the past three decades, both academia and industry have developed numerous variability modeling methods, each with its own advantages and disadvantages. Many of these methods have demonstrated their utility within specific domains or applications. However, comprehending the capabilities and differences among these approaches to pinpoint the most suitable one for a particular use case remains challenging. Thus, new modeling techniques and tailored tools for handling variability are frequently created. Transitioning between variability models through transformations from different approaches can help in understanding the benefits and drawbacks of different modeling approaches. However, implementing such transformations presents challenges, such as semantic preservation and avoiding information loss. TRAVART is a tool that helps with transitioning between different approaches by enabling the transformation of variability models into other variability models of different types. This paper discusses the challenges for such transformations between UVL and IVML. It also presents a one-way transformation from the UVL to IVML with as little information loss as possible.\n    ",
        "primary_category": "cs.SE",
        "categories": [],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01954": {
        "title": "DECIDER: A Rule-Controllable Decoding Strategy for Language Generation by Imitating Dual-System Cognitive Theory",
        "authors": [
            "Chen Xu",
            "Tian Lan",
            "Changlong Yu",
            "Wei Wang",
            "Jun Gao",
            "Yu Ji",
            "Qunxi Dong",
            "Kun Qian",
            "Piji Li",
            "Wei Bi",
            "Bin Hu"
        ],
        "comments": "Submitted to IEEE TKDE, 12 pages, 6 figures",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "Lexicon-based constrained decoding approaches aim to control the meaning or style of the generated text through certain target concepts. Existing approaches over-focus the targets themselves, leading to a lack of high-level reasoning about how to achieve them. However, human usually tackles tasks by following certain rules that not only focuses on the targets but also on semantically relevant concepts that induce the occurrence of targets. In this work, we present DECIDER, a rule-controllable decoding strategy for constrained language generation inspired by dual-system cognitive theory. Specifically, in DECIDER, a pre-trained language model (PLM) is equiped with a logic reasoner that takes high-level rules as input. Then, the DECIDER allows rule signals to flow into the PLM at each decoding step. Extensive experimental results demonstrate that DECIDER can effectively follow given rules to guide generation direction toward the targets in a more human-like manner.\n    ",
        "primary_category": "cs.CL",
        "categories": [
            "cs.AI",
            "cs.LO"
        ],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01956": {
        "title": "Hybrid Active-Passive RIS Transmitter Enabled Energy-Efficient Multi-User Communications",
        "authors": [
            "Ao Huang",
            "Xidong Mu",
            "Li Guo",
            "Guangyu Zhu"
        ],
        "comments": " ",
        "subjects": "Information Theory (cs.IT)",
        "abstract": "A novel hybrid active-passive reconfigurable intelligent surface (RIS) transmitter enabled downlink multi-user communication system is investigated. Specifically, RISs are exploited to serve as transmitter antennas, where each element can flexibly switch between active and passive modes to deliver information to multiple users. The system energy efficiency (EE) maximization problem is formulated by jointly optimizing the RIS element scheduling and beamforming coefficients, as well as the power allocation coefficients, subject to the user's individual rate requirement and the maximum RIS amplification power constraint. Using the Dinkelbach relaxation, the original mixed-integer nonlinear programming problem is transformed into a nonfractional optimization problem with a two-layer structure, which is solved by the alternating optimization approach. In particular, an exhaustive search method is proposed to determine the optimal operating mode for each RIS element. Then, the RIS beamforming and power allocation coefficients are properly designed in an alternating manner. To overcome the potentially high complexity caused by exhaustive searching, we further develop a joint RIS element mode and beamforming optimization scheme by exploiting the Big-M formulation technique. Numerical results validate that: 1) The proposed hybrid RIS scheme yields higher EE than the baseline multi-antenna schemes employing fully active/passive RIS or conventional radio frequency chains; 2) Both proposed algorithms are effective in improving the system performance, especially the latter can achieve precise design of RIS elements with low complexity; and 3) For a fixed-size hybrid RIS, maximum EE can be reaped by setting only a minority of elements to operate in the active mode.\n    ",
        "primary_category": "cs.IT",
        "categories": [
            "eess.SP"
        ],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01960": {
        "title": "A robust audio deepfake detection system via multi-view feature",
        "authors": [
            "Yujie Yang",
            "Haochen Qin",
            "Hang Zhou",
            "Chengcheng Wang",
            "Tianyu Guo",
            "Kai Han",
            "Yunhe Wang"
        ],
        "comments": "5 pages, 2 figures",
        "subjects": "Sound (cs.SD)",
        "abstract": "With the advancement of generative modeling techniques, synthetic human speech becomes increasingly indistinguishable from real, and tricky challenges are elicited for the audio deepfake detection (ADD) system. In this paper, we exploit audio features to improve the generalizability of ADD systems. Investigation of the ADD task performance is conducted over a broad range of audio features, including various handcrafted features and learning-based features. Experiments show that learning-based audio features pretrained on a large amount of data generalize better than hand-crafted features on out-of-domain scenarios. Subsequently, we further improve the generalizability of the ADD system using proposed multi-feature approaches to incorporate complimentary information from features of different views. The model trained on ASV2019 data achieves an equal error rate of 24.27\\% on the In-the-Wild dataset.\n    ",
        "primary_category": "cs.SD",
        "categories": [
            "eess.AS"
        ],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01964": {
        "title": "The Heterogeneous Productivity Effects of Generative AI",
        "authors": [
            "David Kreitmeir",
            "Paul A. Raschky"
        ],
        "comments": " ",
        "subjects": "General Economics (econ.GN)",
        "abstract": "We analyse the individual productivity effects of Italy's ban on ChatGPT, a generative pretrained transformer chatbot. We compile data on the daily coding output quantity and quality of over 36,000 GitHub users in Italy and other European countries and combine these data with the sudden announcement of the ban in a difference-in-differences framework. Among the affected users in Italy, we find a short-term increase in output quantity and quality for less experienced users and a decrease in productivity on more routine tasks for experienced users.\n    ",
        "primary_category": "econ.GN",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01965": {
        "title": "Towards Deterministic Algorithms for Constant-Depth Factors of Constant-Depth Circuits",
        "authors": [
            "Mrinal Kumar",
            "Varun Ramanathan",
            "Ramprasad Saptharishi",
            "Ben Lee Volk"
        ],
        "comments": " ",
        "subjects": "Computational Complexity (cs.CC)",
        "abstract": "We design a deterministic subexponential time algorithm that takes as input a multivariate polynomial $f$ computed by a constant-depth circuit over rational numbers, and outputs a list $L$ of circuits (of unbounded depth and possibly with division gates) that contains all irreducible factors of $f$ computable by constant-depth circuits. This list $L$ might also include circuits that are spurious: they either do not correspond to factors of $f$ or are not even well-defined, e.g. the input to a division gate is a sub-circuit that computes the identically zero polynomial.\nThe key technical ingredient of our algorithm is a notion of the pseudo-resultant of $f$ and a factor $g$, which serves as a proxy for the resultant of $g$ and $f/g$, with the advantage that the circuit complexity of the pseudo-resultant is comparable to that of the circuit complexity of $f$ and $g$. This notion, which might be of independent interest, together with the recent results of Limaye, Srinivasan and Tavenas, helps us derandomize one key step of multivariate polynomial factorization algorithms - that of deterministically finding a good starting point for Newton Iteration for the case when the input polynomial as well as the irreducible factor of interest have small constant-depth circuits.\n    ",
        "primary_category": "cs.CC",
        "categories": [
            "cs.DS"
        ],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01966": {
        "title": "Enhancing Information Maximization with Distance-Aware Contrastive Learning for Source-Free Cross-Domain Few-Shot Learning",
        "authors": [
            "Huali Xu",
            "Li Liu",
            "Shuaifeng Zhi",
            "Shaojing Fu",
            "Zhuo Su",
            "Ming-Ming Cheng",
            "Yongxiang Liu"
        ],
        "comments": "Accepted by TIP, 16 pages, 11 figures, 8 tables",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Existing Cross-Domain Few-Shot Learning (CDFSL) methods require access to source domain data to train a model in the pre-training phase. However, due to increasing concerns about data privacy and the desire to reduce data transmission and training costs, it is necessary to develop a CDFSL solution without accessing source data. For this reason, this paper explores a Source-Free CDFSL (SF-CDFSL) problem, in which CDFSL is addressed through the use of existing pretrained models instead of training a model with source data, avoiding accessing source data. This paper proposes an Enhanced Information Maximization with Distance-Aware Contrastive Learning (IM-DCL) method to address these challenges. Firstly, we introduce the transductive mechanism for learning the query set. Secondly, information maximization (IM) is explored to map target samples into both individual certainty and global diversity predictions, helping the source model better fit the target data distribution. However, IM fails to learn the decision boundary of the target task. This motivates us to introduce a novel approach called Distance-Aware Contrastive Learning (DCL), in which we consider the entire feature set as both positive and negative sets, akin to Schrodinger's concept of a dual state. Instead of a rigid separation between positive and negative sets, we employ a weighted distance calculation among features to establish a soft classification of the positive and negative sets for the entire feature set. Furthermore, we address issues related to IM by incorporating contrastive constraints between object features and their corresponding positive and negative sets. Evaluations of the 4 datasets in the BSCD-FSL benchmark indicate that the proposed IM-DCL, without accessing the source domain, demonstrates superiority over existing methods, especially in the distant domain task.\n    ",
        "primary_category": "cs.CV",
        "categories": [],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01968": {
        "title": "Explicit Motion Handling and Interactive Prompting for Video Camouflaged Object Detection",
        "authors": [
            "Xin Zhang",
            "Tao Xiao",
            "Gepeng Ji",
            "Xuan Wu",
            "Keren Fu",
            "Qijun Zhao"
        ],
        "comments": "9 pages, 6 figures",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Camouflage poses challenges in distinguishing a static target, whereas any movement of the target can break this disguise. Existing video camouflaged object detection (VCOD) approaches take noisy motion estimation as input or model motion implicitly, restricting detection performance in complex dynamic scenes. In this paper, we propose a novel Explicit Motion handling and Interactive Prompting framework for VCOD, dubbed EMIP, which handles motion cues explicitly using a frozen pre-trained optical flow fundamental model. EMIP is characterized by a two-stream architecture for simultaneously conducting camouflaged segmentation and optical flow estimation. Interactions across the dual streams are realized in an interactive prompting way that is inspired by emerging visual prompt learning. Two learnable modules, i.e. the camouflaged feeder and motion collector, are designed to incorporate segmentation-to-motion and motion-to-segmentation prompts, respectively, and enhance outputs of the both streams. The prompt fed to the motion stream is learned by supervising optical flow in a self-supervised manner. Furthermore, we show that long-term historical information can also be incorporated as a prompt into EMIP and achieve more robust results with temporal consistency. Experimental results demonstrate that our EMIP achieves new state-of-the-art records on popular VCOD benchmarks. The code will be publicly available.\n    ",
        "primary_category": "cs.CV",
        "categories": [],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01969": {
        "title": "AS-ES Learning: Towards Efficient CoT Learning in Small Models",
        "authors": [
            "Nuwa Xi",
            "Yuhan Chen",
            "Sendong Zhao",
            "Haochun Wang",
            "Bing Qin",
            "Ting Liu"
        ],
        "comments": " ",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "Chain-of-Thought (CoT) serves as a critical emerging ability in LLMs, especially when it comes to logical reasoning. Attempts have been made to induce such ability in small models as well by distilling from the data with CoT generated by Large Language Models (LLMs). However, existing methods often simply generate and incorporate more data from LLMs and fail to note the importance of efficiently utilizing existing CoT data. We here propose a new training paradigm AS-ES (Abstractive Segments - Extractive Segments) learning, which exploits the inherent information in CoT for iterative generation. Experiments show that our methods surpass the direct seq2seq training on CoT-extensive tasks like MWP and PET summarization, without data augmentation or altering the model itself. Furthermore, we explore the reason behind the inefficiency of small models in learning CoT and provide an explanation of why AS-ES learning works, giving insights into the underlying mechanism of CoT.\n    ",
        "primary_category": "cs.CL",
        "categories": [],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01972": {
        "title": "Multi-perspective Improvement of Knowledge Graph Completion with Large Language Models",
        "authors": [
            "Derong Xu",
            "Ziheng Zhang",
            "Zhenxi Lin",
            "Xian Wu",
            "Zhihong Zhu",
            "Tong Xu",
            "Xiangyu Zhao",
            "Yefeng Zheng",
            "Enhong Chen"
        ],
        "comments": "Accepted by LREC-COLING 2024",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "Knowledge graph completion (KGC) is a widely used method to tackle incompleteness in knowledge graphs (KGs) by making predictions for missing links. Description-based KGC leverages pre-trained language models to learn entity and relation representations with their names or descriptions, which shows promising results. However, the performance of description-based KGC is still limited by the quality of text and the incomplete structure, as it lacks sufficient entity descriptions and relies solely on relation names, leading to sub-optimal results. To address this issue, we propose MPIKGC, a general framework to compensate for the deficiency of contextualized knowledge and improve KGC by querying large language models (LLMs) from various perspectives, which involves leveraging the reasoning, explanation, and summarization capabilities of LLMs to expand entity descriptions, understand relations, and extract structures, respectively. We conducted extensive evaluation of the effectiveness and improvement of our framework based on four description-based KGC models and four datasets, for both link prediction and triplet classification tasks.\n    ",
        "primary_category": "cs.CL",
        "categories": [],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01975": {
        "title": "OCEL (Object-Centric Event Log) 2.0 Specification",
        "authors": [
            "Alessandro Berti",
            "Istvan Koren",
            "Jan Niklas Adams",
            "Gyunam Park",
            "Benedikt Knopp",
            "Nina Graves",
            "Majid Rafiei",
            "Lukas Li\u00df",
            "Leah Tacke Genannt Unterberg",
            "Yisong Zhang",
            "Christopher Schwanen",
            "Marco Pegoraro",
            "Wil M.P. van der Aalst"
        ],
        "comments": " ",
        "subjects": "Databases (cs.DB)",
        "abstract": "Object-Centric Event Logs (OCELs) form the basis for Object-Centric Process Mining (OCPM). OCEL 1.0 was first released in 2020 and triggered the development of a range of OCPM techniques. OCEL 2.0 forms the new, more expressive standard, allowing for more extensive process analyses while remaining in an easily exchangeable format. In contrast to the first OCEL standard, it can depict changes in objects, provide information on object relationships, and qualify these relationships to other objects or specific events. Compared to XES, it is more expressive, less complicated, and better readable. OCEL 2.0 offers three exchange formats: a relational database (SQLite), XML, and JSON format. This OCEL 2.0 specification document provides an introduction to the standard, its metamodel, and its exchange formats, aimed at practitioners and researchers alike.\n    ",
        "primary_category": "cs.DB",
        "categories": [],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01978": {
        "title": "Leveraging Anchor-based LiDAR 3D Object Detection via Point Assisted Sample Selection",
        "authors": [
            "Shitao Chen",
            "Haolin Zhang",
            "Nanning Zheng"
        ],
        "comments": " ",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "3D object detection based on LiDAR point cloud and prior anchor boxes is a critical technology for autonomous driving environment perception and understanding. Nevertheless, an overlooked practical issue in existing methods is the ambiguity in training sample allocation based on box Intersection over Union (IoU_box). This problem impedes further enhancements in the performance of anchor-based LiDAR 3D object detectors. To tackle this challenge, this paper introduces a new training sample selection method that utilizes point cloud distribution for anchor sample quality measurement, named Point Assisted Sample Selection (PASS). This method has undergone rigorous evaluation on two widely utilized datasets. Experimental results demonstrate that the application of PASS elevates the average precision of anchor-based LiDAR 3D object detectors to a novel state-of-the-art, thereby proving the effectiveness of the proposed approach. The codes will be made available at this https URL.\n    ",
        "primary_category": "cs.CV",
        "categories": [],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01981": {
        "title": "Evaluating the Explainability of Neural Rankers",
        "authors": [
            "Saran Pandian",
            "Debasis Ganguly",
            "Sean MacAvaney"
        ],
        "comments": " ",
        "subjects": "Information Retrieval (cs.IR)",
        "abstract": "Information retrieval models have witnessed a paradigm shift from unsupervised statistical approaches to feature-based supervised approaches to completely data-driven ones that make use of the pre-training of large language models. While the increasing complexity of the search models have been able to demonstrate improvements in effectiveness (measured in terms of relevance of top-retrieved results), a question worthy of a thorough inspection is - \"how explainable are these models?\", which is what this paper aims to evaluate. In particular, we propose a common evaluation platform to systematically evaluate the explainability of any ranking model (the explanation algorithm being identical for all the models that are to be evaluated). In our proposed framework, each model, in addition to returning a ranked list of documents, also requires to return a list of explanation units or rationales for each document. This meta-information from each document is then used to measure how locally consistent these rationales are as an intrinsic measure of interpretability - one that does not require manual relevance assessments. Additionally, as an extrinsic measure, we compute how relevant these rationales are by leveraging sub-document level relevance assessments. Our findings show a number of interesting observations, such as sentence-level rationales are more consistent, an increase in complexity mostly leads to less consistent explanations, and that interpretability measures offer a complementary dimension of evaluation of IR systems because consistency is not well-correlated with nDCG at top ranks.\n    ",
        "primary_category": "cs.IR",
        "categories": [],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01982": {
        "title": "OCEL 2.0 Resources -- www.ocel-standard.org",
        "authors": [
            "Istvan Koren",
            "Niklas Adams",
            "Alessandro Berti"
        ],
        "comments": " ",
        "subjects": "Databases (cs.DB)",
        "abstract": "Process mining has become a cornerstone of process analysis and improvement over the last few years. With the widespread adoption of process mining tools and libraries, the limitations of traditional process mining to deal with event data with multiple case identifiers, i.e., object-centric event data, have become apparent. As a response, the subfield of object-centric process mining has formed, including a file format standardization attempt in the form of OCEL 1.0, unifying the insights of previous developments in capturing object-centric event data. However, discussions among researchers and practitioners have shown that the proposed OCEL 1.0 standard does not go far enough. OCEL 2.0 has been proposed as an advanced refinement, including normative and explicit object-to-object relationships, qualifiers for object-to-object and event-to-object relationships, and evolving object attribute values. This demonstration presents the OCEL 2.0 website available under the URL this https URL as a one-stop shop for the detailed specification, example event logs, and broad tool support to facilitate the adoption of the format.\n    ",
        "primary_category": "cs.DB",
        "categories": [],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01983": {
        "title": "Language and Speech Technology for Central Kurdish Varieties",
        "authors": [
            "Sina Ahmadi",
            "Daban Q. Jaff",
            "Md Mahfuz Ibn Alam",
            "Antonios Anastasopoulos"
        ],
        "comments": "Accepted to LREC-COLING 2024",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "Kurdish, an Indo-European language spoken by over 30 million speakers, is considered a dialect continuum and known for its diversity in language varieties. Previous studies addressing language and speech technology for Kurdish handle it in a monolithic way as a macro-language, resulting in disparities for dialects and varieties for which there are few resources and tools available. In this paper, we take a step towards developing resources for language and speech technology for varieties of Central Kurdish, creating a corpus by transcribing movies and TV series as an alternative to fieldwork. Additionally, we report the performance of machine translation, automatic speech recognition, and language identification as downstream tasks evaluated on Central Kurdish varieties. Data and models are publicly available under an open license at this https URL.\n    ",
        "primary_category": "cs.CL",
        "categories": [],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01985": {
        "title": "Transformers for Low-Resource Languages:Is F\u00e9idir Linn!",
        "authors": [
            "S\u00e9amus Lankford",
            "Haithem Afli",
            "Andy Way"
        ],
        "comments": "13 pages",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "The Transformer model is the state-of-the-art in Machine Translation. However, in general, neural translation models often under perform on language pairs with insufficient training data. As a consequence, relatively few experiments have been carried out using this architecture on low-resource language pairs. In this study, hyperparameter optimization of Transformer models in translating the low-resource English-Irish language pair is evaluated. We demonstrate that choosing appropriate parameters leads to considerable performance improvements. Most importantly, the correct choice of subword model is shown to be the biggest driver of translation performance. SentencePiece models using both unigram and BPE approaches were appraised. Variations on model architectures included modifying the number of layers, testing various regularisation techniques and evaluating the optimal number of heads for attention. A generic 55k DGT corpus and an in-domain 88k public admin corpus were used for evaluation. A Transformer optimized model demonstrated a BLEU score improvement of 7.8 points when compared with a baseline RNN model. Improvements were observed across a range of metrics, including TER, indicating a substantially reduced post editing effort for Transformer optimized models with 16k BPE subword models. Bench-marked against Google Translate, our translation engines demonstrated significant improvements. The question of whether or not Transformers can be used effectively in a low-resource setting of English-Irish translation has been addressed. Is f\u00e9idir linn - yes we can.\n    ",
        "primary_category": "cs.CL",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01988": {
        "title": "FakeNewsGPT4: Advancing Multimodal Fake News Detection through Knowledge-Augmented LVLMs",
        "authors": [
            "Xuannan Liu",
            "Peipei Li",
            "Huaibo Huang",
            "Zekun Li",
            "Xing Cui",
            "Jiahao Liang",
            "Lixiong Qin",
            "Weihong Deng",
            "Zhaofeng He"
        ],
        "comments": " ",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "The massive generation of multimodal fake news exhibits substantial distribution discrepancies, prompting the need for generalized detectors. However, the insulated nature of training within specific domains restricts the capability of classical detectors to obtain open-world facts. In this paper, we propose FakeNewsGPT4, a novel framework that augments Large Vision-Language Models (LVLMs) with forgery-specific knowledge for manipulation reasoning while inheriting extensive world knowledge as complementary. Knowledge augmentation in FakeNewsGPT4 involves acquiring two types of forgery-specific knowledge, i.e., semantic correlation and artifact trace, and merging them into LVLMs. Specifically, we design a multi-level cross-modal reasoning module that establishes interactions across modalities for extracting semantic correlations. Concurrently, a dual-branch fine-grained verification module is presented to comprehend localized details to encode artifact traces. The generated knowledge is translated into refined embeddings compatible with LVLMs. We also incorporate candidate answer heuristics and soft prompts to enhance input informativeness. Extensive experiments on the public benchmark demonstrate that FakeNewsGPT4 achieves superior cross-domain performance compared to previous methods. Code will be available.\n    ",
        "primary_category": "cs.CL",
        "categories": [],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01991": {
        "title": "Skater: A Novel Bi-modal Bi-copter Robot for Adaptive Locomotion in Air and Diverse Terrain",
        "authors": [
            "Junxiao Lin",
            "Ruibin Zhang",
            "Neng Pan",
            "Chao Xu",
            "Fei Gao"
        ],
        "comments": " ",
        "subjects": "Robotics (cs.RO)",
        "abstract": "In this letter, we present a novel bi-modal bi-copter robot called Skater, which is adaptable to air and various ground surfaces. Skater consists of a bi-copter moving along its longitudinal direction with two passive wheels on both sides. Using longitudinally arranged bi-copter as the unified actuation system for both aerial and ground modes, this robot not only keeps concise and lightweight mechanism, but also possesses exceptional terrain traversing capability and strong steering capacity. Moreover, leveraging the vectored thrust characteristic of bi-copters, Skater can actively generate the centripetal force needed for steering, enabling it to achieve stable movement even on slippery surfaces. Furthermore, we model the comprehensive dynamics of Skater, analyze its differential flatness and introduce a controller using nonlinear model predictive control for trajectory tracking. The outstanding performance of the system is verified by extensive real-world experiments and benchmark comparisons.\n    ",
        "primary_category": "cs.RO",
        "categories": [],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01993": {
        "title": "Physics-Informed Learning for Time-Resolved Angiographic Contrast Agent Concentration Reconstruction",
        "authors": [
            "Noah Maul",
            "Annette Birkhold",
            "Fabian Wagner",
            "Mareike Thies",
            "Maximilian Rohleder",
            "Philipp Berg",
            "Markus Kowarschik",
            "Andreas Maier"
        ],
        "comments": " ",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Three-dimensional Digital Subtraction Angiography (3D-DSA) is a well-established X-ray-based technique for visualizing vascular anatomy. Recently, four-dimensional DSA (4D-DSA) reconstruction algorithms have been developed to enable the visualization of volumetric contrast flow dynamics through time-series of volumes. . This reconstruction problem is ill-posed mainly due to vessel overlap in the projection direction and geometric vessel foreshortening, which leads to information loss in the recorded projection images. However, knowledge about the underlying fluid dynamics can be leveraged to constrain the solution space. In our work, we implicitly include this information in a neural network-based model that is trained on a dataset of image-based blood flow simulations. The model predicts the spatially averaged contrast agent concentration for each centerline point of the vasculature over time, lowering the overall computational demand. The trained network enables the reconstruction of relative contrast agent concentrations with a mean absolute error of 0.02 $\\pm$ 0.02 and a mean absolute percentage error of 5.31 % $\\pm$ 9.25 %. Moreover, the network is robust to varying degrees of vessel overlap and vessel foreshortening. Our approach demonstrates the potential of the integration of machine learning and blood flow simulations in time-resolved angiographic flow reconstruction.\n    ",
        "primary_category": "cs.CV",
        "categories": [],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01994": {
        "title": "Vanilla Transformers are Transfer Capability Teachers",
        "authors": [
            "Xin Lu",
            "Yanyan Zhao",
            "Bing Qin"
        ],
        "comments": " ",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "Recently, Mixture of Experts (MoE) Transformers have garnered increasing attention due to their advantages in model capacity and computational efficiency. However, studies have indicated that MoE Transformers underperform vanilla Transformers in many downstream tasks, significantly diminishing the practical value of MoE models. To explain this issue, we propose that the pre-training performance and transfer capability of a model are joint determinants of its downstream task performance. MoE models, in comparison to vanilla models, have poorer transfer capability, leading to their subpar performance in downstream tasks. To address this issue, we introduce the concept of transfer capability distillation, positing that although vanilla models have weaker performance, they are effective teachers of transfer capability. The MoE models guided by vanilla models can achieve both strong pre-training performance and transfer capability, ultimately enhancing their performance in downstream tasks. We design a specific distillation method and conduct experiments on the BERT architecture. Experimental results show a significant improvement in downstream performance of MoE models, and many further evidences also strongly support the concept of transfer capability distillation. Finally, we attempt to interpret transfer capability distillation and provide some insights from the perspective of model feature.\n    ",
        "primary_category": "cs.CL",
        "categories": [],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.01999": {
        "title": "LLM-Oriented Retrieval Tuner",
        "authors": [
            "Si Sun",
            "Hanqing Zhang",
            "Zhiyuan Liu",
            "Jie Bao",
            "Dawei Song"
        ],
        "comments": "16 pages, 8 figures, 5 tables",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "Dense Retrieval (DR) is now considered as a promising tool to enhance the memorization capacity of Large Language Models (LLM) such as GPT3 and GPT-4 by incorporating external memories. However, due to the paradigm discrepancy between text generation of LLM and DR, it is still an open challenge to integrate the retrieval and generation tasks in a shared LLM. In this paper, we propose an efficient LLM-Oriented Retrieval Tuner, namely LMORT, which decouples DR capacity from base LLM and non-invasively coordinates the optimally aligned and uniform layers of the LLM towards a unified DR space, achieving an efficient and effective DR without tuning the LLM itself. The extensive experiments on six BEIR datasets show that our approach could achieve competitive zero-shot retrieval performance compared to a range of strong DR models while maintaining the generation ability of LLM.\n    ",
        "primary_category": "cs.CL",
        "categories": [],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.02002": {
        "title": "Fine-Grained Quantitative Emotion Editing for Speech Generation",
        "authors": [
            "Sho Inoue",
            "Kun Zhou",
            "Shuai Wang",
            "Haizhou Li"
        ],
        "comments": "This paper is submitted to IEEE Signal Processing Letters",
        "subjects": "Sound (cs.SD)",
        "abstract": "It remains a significant challenge how to quantitatively control the expressiveness of speech emotion in speech generation. In this work, we present a novel approach for manipulating the rendering of emotions for speech generation. We propose a hierarchical emotion distribution extractor, i.e. Hierarchical ED, that quantifies the intensity of emotions at different levels of granularity. Support vector machines (SVMs) are employed to rank emotion intensity, resulting in a hierarchical emotional embedding. Hierarchical ED is subsequently integrated into the FastSpeech2 framework, guiding the model to learn emotion intensity at phoneme, word, and utterance levels. During synthesis, users can manually edit the emotional intensity of the generated voices. Both objective and subjective evaluations demonstrate the effectiveness of the proposed network in terms of fine-grained quantitative emotion editing.\n    ",
        "primary_category": "cs.SD",
        "categories": [
            "eess.AS"
        ],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.02009": {
        "title": "Topic Aware Probing: From Sentence Length Prediction to Idiom Identification how reliant are Neural Language Models on Topic?",
        "authors": [
            "Vasudevan Nedumpozhimana",
            "John D. Kelleher"
        ],
        "comments": " ",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "Transformer-based Neural Language Models achieve state-of-the-art performance on various natural language processing tasks. However, an open question is the extent to which these models rely on word-order/syntactic or word co-occurrence/topic-based information when processing natural language. This work contributes to this debate by addressing the question of whether these models primarily use topic as a signal, by exploring the relationship between Transformer-based models' (BERT and RoBERTa's) performance on a range of probing tasks in English, from simple lexical tasks such as sentence length prediction to complex semantic tasks such as idiom token identification, and the sensitivity of these tasks to the topic information. To this end, we propose a novel probing method which we call topic-aware probing. Our initial results indicate that Transformer-based models encode both topic and non-topic information in their intermediate layers, but also that the facility of these models to distinguish idiomatic usage is primarily based on their ability to identify and encode topic. Furthermore, our analysis of these models' performance on other standard probing tasks suggests that tasks that are relatively insensitive to the topic information are also tasks that are relatively difficult for these models.\n    ",
        "primary_category": "cs.CL",
        "categories": [],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.02010": {
        "title": "SA-SOT: Speaker-Aware Serialized Output Training for Multi-Talker ASR",
        "authors": [
            "Zhiyun Fan",
            "Linhao Dong",
            "Jun Zhang",
            "Lu Lu",
            "Zejun Ma"
        ],
        "comments": " ",
        "subjects": "Sound (cs.SD)",
        "abstract": "Multi-talker automatic speech recognition plays a crucial role in scenarios involving multi-party interactions, such as meetings and conversations. Due to its inherent complexity, this task has been receiving increasing attention. Notably, the serialized output training (SOT) stands out among various approaches because of its simplistic architecture and exceptional performance. However, the frequent speaker changes in token-level SOT (t-SOT) present challenges for the autoregressive decoder in effectively utilizing context to predict output sequences. To address this issue, we introduce a masked t-SOT label, which serves as the cornerstone of an auxiliary training loss. Additionally, we utilize a speaker similarity matrix to refine the self-attention mechanism of the decoder. This strategic adjustment enhances contextual relationships within the same speaker's tokens while minimizing interactions between different speakers' tokens. We denote our method as speaker-aware SOT (SA-SOT). Experiments on the Librispeech datasets demonstrate that our SA-SOT obtains a relative cpWER reduction ranging from 12.75% to 22.03% on the multi-talker test sets. Furthermore, with more extensive training, our method achieves an impressive cpWER of 3.41%, establishing a new state-of-the-art result on the LibrispeechMix dataset.\n    ",
        "primary_category": "cs.SD",
        "categories": [
            "eess.AS"
        ],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.02011": {
        "title": "Bipartite Graph Variational Auto-Encoder with Fair Latent Representation to Account for Sampling Bias in Ecological Networks",
        "authors": [
            "Emre Anakok",
            "Pierre Barbillon",
            "Colin Fontaine",
            "Elisa Thebault"
        ],
        "comments": " ",
        "subjects": "Machine Learning (stat.ML)",
        "abstract": "We propose a method to represent bipartite networks using graph embeddings tailored to tackle the challenges of studying ecological networks, such as the ones linking plants and pollinators, where many covariates need to be accounted for, in particular to control for sampling bias. We adapt the variational graph auto-encoder approach to the bipartite case, which enables us to generate embeddings in a latent space where the two sets of nodes are positioned based on their probability of connection. We translate the fairness framework commonly considered in sociology in order to address sampling bias in ecology. By incorporating the Hilbert-Schmidt independence criterion (HSIC) as an additional penalty term in the loss we optimize, we ensure that the structure of the latent space is independent of continuous variables, which are related to the sampling process. Finally, we show how our approach can change our understanding of ecological networks when applied to the Spipoll data set, a citizen science monitoring program of plant-pollinator interactions to which many observers contribute, making it prone to sampling bias.\n    ",
        "primary_category": "stat.ML",
        "categories": [
            "cs.LG",
            "cs.SI"
        ],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.02012": {
        "title": "OTFS vs OFDM: Which is Superior in Multiuser LEO Satellite Communications",
        "authors": [
            "Yu Liu",
            "Ming Chen",
            "Cunhua Pan",
            "Tantao Gong",
            "Jinhong Yuan",
            "Jiangzhou Wang"
        ],
        "comments": "13 pages, 9 figures",
        "subjects": "Information Theory (cs.IT)",
        "abstract": "Orthogonal time frequency space (OTFS) modulation, a delay-Doppler (DD) domain communication scheme exhibiting strong robustness against the Doppler shifts, has the potentials to be employed in LEO satellite communications. However, the performance comparison with the orthogonal frequency division multiplexing (OFDM) modulation and the resource allocation scheme for multiuser OTFS-based LEO satellite communication system have rarely been investigated. In this paper, we conduct a performance comparison under various channel conditions between the OTFS and OFDM modulations, encompassing evaluations of sum-rate and bit error ratio (BER). Additionally, we investigate the joint optimal allocation of power and delay-Doppler resource blocks aiming at maximizing sum-rate for multiuser downlink OTFS-based LEO satellite communication systems. Unlike the conventional modulations relaying on complex input-output relations within the Time-Frequency (TF) domain, the OTFS modulation exploits both time and frequency diversities, i.e., delay and Doppler shifts remain constant during a OTFS frame, which facilitates a DD domain input-output simple relation for our investigation. We transform the resulting non-convex and combinatorial optimization problem into an equivalent difference of convex problem by decoupling the conditional constraints, and solve the transformed problem via penalty convex-concave procedure algorithm. Simulation results demonstrate that the OTFS modulation is robust to carrier frequency offsets (CFO) caused by high-mobility of LEO satellites, and has superior performance to the OFDM modulation. Moreover, numerical results indicate that our proposed resource allocation scheme has higher sum-rate than existed schemes for the OTFS modulation, such as delay divided multiple access and Doppler divided multiple access, especially in the high signal-to-noise ratio (SNR) regime.\n    ",
        "primary_category": "cs.IT",
        "categories": [
            "eess.SP"
        ],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.02014": {
        "title": "Unveiling Hidden Links Between Unseen Security Entities",
        "authors": [
            "Daniel Alfasi",
            "Tal Shapira",
            "Anat Bremler Barr"
        ],
        "comments": " ",
        "subjects": "Cryptography and Security (cs.CR)",
        "abstract": "The proliferation of software vulnerabilities poses a significant challenge for security databases and analysts tasked with their timely identification, classification, and remediation. With the National Vulnerability Database (NVD) reporting an ever-increasing number of vulnerabilities, the traditional manual analysis becomes untenably time-consuming and prone to errors. This paper introduces VulnScopper, an innovative approach that utilizes multi-modal representation learning, combining Knowledge Graphs (KG) and Natural Language Processing (NLP), to automate and enhance the analysis of software vulnerabilities. Leveraging ULTRA, a knowledge graph foundation model, combined with a Large Language Model (LLM), VulnScopper effectively handles unseen entities, overcoming the limitations of previous KG approaches. We evaluate VulnScopper on two major security datasets, the NVD and the Red Hat CVE database. Our method significantly improves the link prediction accuracy between Common Vulnerabilities and Exposures (CVEs), Common Weakness Enumeration (CWEs), and Common Platform Enumerations (CPEs). Our results show that VulnScopper outperforms existing methods, achieving up to 78% Hits@10 accuracy in linking CVEs to CPEs and CWEs and presenting an 11.7% improvement over large language models in predicting CWE labels based on the Red Hat database. Based on the NVD, only 6.37% of the linked CPEs are being published during the first 30 days; many of them are related to critical and high-risk vulnerabilities which, according to multiple compliance frameworks (such as CISA and PCI), should be remediated within 15-30 days. Our model can uncover new products linked to vulnerabilities, reducing remediation time and improving vulnerability management. We analyzed several CVEs from 2023 to showcase this ability.\n    ",
        "primary_category": "cs.CR",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.02018": {
        "title": "Cross Domain Policy Transfer with Effect Cycle-Consistency",
        "authors": [
            "Ruiqi Zhu",
            "Tianhong Dai",
            "Oya Celiktutan"
        ],
        "comments": "Accepted to International Conference on Robotics and Automation (ICRA), 2024",
        "subjects": "Robotics (cs.RO)",
        "abstract": "Training a robotic policy from scratch using deep reinforcement learning methods can be prohibitively expensive due to sample inefficiency. To address this challenge, transferring policies trained in the source domain to the target domain becomes an attractive paradigm. Previous research has typically focused on domains with similar state and action spaces but differing in other aspects. In this paper, our primary focus lies in domains with different state and action spaces, which has broader practical implications, i.e. transfer the policy from robot A to robot B. Unlike prior methods that rely on paired data, we propose a novel approach for learning the mapping functions between state and action spaces across domains using unpaired data. We propose effect cycle consistency, which aligns the effects of transitions across two domains through a symmetrical optimization structure for learning these mapping functions. Once the mapping functions are learned, we can seamlessly transfer the policy from the source domain to the target domain. Our approach has been tested on three locomotion tasks and two robotic manipulation tasks. The empirical results demonstrate that our method can reduce alignment errors significantly and achieve better performance compared to the state-of-the-art method.\n    ",
        "primary_category": "cs.RO",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.02019": {
        "title": "Active Learning of Mealy Machines with Timers",
        "authors": [
            "V\u00e9ronique Bruy\u00e8re",
            "Bharat Garhewal",
            "Guillermo A. P\u00e9rez",
            "Ga\u00ebtan Staquet",
            "Frits W. Vaandrager"
        ],
        "comments": "77 pages, 19 figures",
        "subjects": "Formal Languages and Automata Theory (cs.FL)",
        "abstract": "We present the first algorithm for query learning of a general class of Mealy machines with timers (MMTs) in a black-box context. Our algorithm is an extension of the L# algorithm of Vaandrager et al. to a timed setting. Like the algorithm for learning timed automata proposed by Waga, our algorithm is inspired by ideas of Maler & Pnueli. Based on the elementary languages of, both Waga's and our algorithm use symbolic queries, which are then implemented using finitely many concrete queries. However, whereas Waga needs exponentially many concrete queries to implement a single symbolic query, we only need a polynomial number. This is because in order to learn a timed automaton, a learner needs to determine the exact guard and reset for each transition (out of exponentially many possibilities), whereas for learning an MMT a learner only needs to figure out which of the preceding transitions caused a timeout. As shown in our previous work, this can be done efficiently for a subclass of MMTs that are race-avoiding: if a timeout is caused by a preceding input then a slight change in the timing of this input will induce a corresponding change in the timing of the timeout (\"wiggling\"). Experiments with a prototype implementation, written in Rust, show that our algorithm is able to efficiently learn realistic benchmarks.\n    ",
        "primary_category": "cs.FL",
        "categories": [
            "cs.LG"
        ],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.02026": {
        "title": "Graph drawing applications in combinatorial theory of maturity models",
        "authors": [
            "\u0160pela Kajzer",
            "Alexander Dobler",
            "Janja Jerebic",
            "Martin N\u00f6llenburg",
            "Joachim Orthaber",
            "Drago Bokal"
        ],
        "comments": "39 pages, 12 figures",
        "subjects": "Discrete Mathematics (cs.DM)",
        "abstract": "In this paper, we introduce tiled graphs as models of learning and maturing processes. We show how tiled graphs can combine graphs of learning spaces or antimatroids (partial hypercubes) and maturity models (total orders) to yield models of learning processes. For the visualization of these processes it is a natural approach to aim for certain optimal drawings. We show for most of the more detailed models that the drawing problems resulting from them are NP-complete. The terse model of a maturing process that ignores the details of learning, however, results in a polynomially solvable graph drawing problem. In addition, this model provides insight into the process by ordering the subjects at each test of their maturity. We investigate extremal and random instances of this problem, and provide exact results and bounds on their optimal crossing number.\nGraph-theoretic models offer two approaches to the design of optimal maturity models given observed data: (1) minimizing intra-subject inconsistencies, which manifest as regressions of subjects, is modeled as the well-known feedback arc set problem. We study the alternative of (2) finding a maturity model by minimizing the inter-subject inconsistencies, which manifest as crossings in the respective drawing. We show this to be NP-complete.\n    ",
        "primary_category": "cs.DM",
        "categories": [],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.02029": {
        "title": "Improving the accuracy of the Newmark method through backward error analysis",
        "authors": [
            "Don\u00e1t M. Tak\u00e1cs",
            "Tam\u00e1s F\u00fcl\u00f6p"
        ],
        "comments": "27 pages, 14 figures",
        "subjects": "Numerical Analysis (math.NA)",
        "abstract": "We use backward error analysis for differential equations to obtain modified or distorted equations describing the behaviour of the Newmark scheme applied to the transient structural dynamics equation. Using these results, we show how to construct compensation terms from the original parameters of the system, which improve the performance of Newmark simulations without changing the time step or modifying the scheme itself. Two such compensations are given: one eliminates numerical damping, while the other achieves fourth-order accurate calculations using the traditionally second-order Newmark method.\n    ",
        "primary_category": "math.NA",
        "categories": [],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.02035": {
        "title": "Exponential Expressivity of ReLU$^k$ Neural Networks on Gevrey Classes with Point Singularities",
        "authors": [
            "Joost A. A. Opschoor",
            "Christoph Schwab"
        ],
        "comments": " ",
        "subjects": "Numerical Analysis (math.NA)",
        "abstract": "We analyze deep Neural Network emulation rates of smooth functions with point singularities in bounded, polytopal domains $\\mathrm{D} \\subset \\mathbb{R}^d$, $d=2,3$. We prove exponential emulation rates in Sobolev spaces in terms of the number of neurons and in terms of the number of nonzero coefficients for Gevrey-regular solution classes defined in terms of weighted Sobolev scales in $\\mathrm{D}$, comprising the countably-normed spaces of I.M. Babu\u0161ka and B.Q. Guo.\nAs intermediate result, we prove that continuous, piecewise polynomial high order (``$p$-version'') finite elements with elementwise polynomial degree $p\\in\\mathbb{N}$ on arbitrary, regular, simplicial partitions of polyhedral domains $\\mathrm{D} \\subset \\mathbb{R}^d$, $d\\geq 2$ can be exactly emulated by neural networks combining ReLU and ReLU$^2$ activations. On shape-regular, simplicial partitions of polytopal domains $\\mathrm{D}$, both the number of neurons and the number of nonzero parameters are proportional to the number of degrees of freedom of the finite element space, in particular for the $hp$-Finite Element Method of I.M. Babu\u0161ka and B.Q. Guo.\n    ",
        "primary_category": "math.NA",
        "categories": [
            "cs.LG"
        ],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.02037": {
        "title": "Scalable Vision-Based 3D Object Detection and Monocular Depth Estimation for Autonomous Driving",
        "authors": [
            "Yuxuan Liu"
        ],
        "comments": "HKUST PhD Thesis; this https URL",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "This dissertation is a multifaceted contribution to the advancement of vision-based 3D perception technologies. In the first segment, the thesis introduces structural enhancements to both monocular and stereo 3D object detection algorithms. By integrating ground-referenced geometric priors into monocular detection models, this research achieves unparalleled accuracy in benchmark evaluations for monocular 3D detection. Concurrently, the work refines stereo 3D detection paradigms by incorporating insights and inferential structures gleaned from monocular networks, thereby augmenting the operational efficiency of stereo detection systems. The second segment is devoted to data-driven strategies and their real-world applications in 3D vision detection. A novel training regimen is introduced that amalgamates datasets annotated with either 2D or 3D labels. This approach not only augments the detection models through the utilization of a substantially expanded dataset but also facilitates economical model deployment in real-world scenarios where only 2D annotations are readily available. Lastly, the dissertation presents an innovative pipeline tailored for unsupervised depth estimation in autonomous driving contexts. Extensive empirical analyses affirm the robustness and efficacy of this newly proposed pipeline. Collectively, these contributions lay a robust foundation for the widespread adoption of vision-based 3D perception technologies in autonomous driving applications.\n    ",
        "primary_category": "cs.CV",
        "categories": [
            "cs.RO"
        ],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.02039": {
        "title": "A Frequency-Domain Approach for Enhanced Performance and Task Flexibility in Finite-Time ILC",
        "authors": [
            "Max van Haren",
            "Kentaro Tsurumoto",
            "Masahiro Mae",
            "Lennart Blanken",
            "Wataru Ohnishi",
            "Tom Oomen"
        ],
        "comments": " ",
        "subjects": "Systems and Control (eess.SY)",
        "abstract": "Iterative learning control (ILC) is capable of improving the tracking performance of repetitive control systems by utilizing data from past iterations. The aim of this paper is to achieve both task flexibility, which is often achieved by ILC with basis functions, and the performance of frequency-domain ILC, with an intuitive design procedure. The cost function of norm-optimal ILC is determined that recovers frequency-domain ILC, and consequently, the feedforward signal is parameterized in terms of basis functions and frequency-domain ILC. The resulting method has the performance and design procedure of frequency-domain ILC and the task flexibility of basis functions ILC, and are complimentary to each other. Validation on a benchmark example confirms the capabilities of the framework.\n    ",
        "primary_category": "eess.SY",
        "categories": [],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.02042": {
        "title": "Deep Neural Network for Constraint Acquisition through Tailored Loss Function",
        "authors": [
            "Eduardo Vyhmeister",
            "Rocio Paez",
            "Gabriel Gonzalez"
        ],
        "comments": " ",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "The significance of learning constraints from data is underscored by its potential applications in real-world problem-solving. While constraints are popular for modeling and solving, the approaches to learning constraints from data remain relatively scarce. Furthermore, the intricate task of modeling demands expertise and is prone to errors, thus constraint acquisition methods offer a solution by automating this process through learnt constraints from examples or behaviours of solutions and non-solutions. This work introduces a novel approach grounded in Deep Neural Network (DNN) based on Symbolic Regression that, by setting suitable loss functions, constraints can be extracted directly from datasets. Using the present approach, direct formulation of constraints was achieved. Furthermore, given the broad pre-developed architectures and functionalities of DNN, connections and extensions with other frameworks could be foreseen.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.SC"
        ],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.02043": {
        "title": "Iterative Occlusion-Aware Light Field Depth Estimation using 4D Geometrical Cues",
        "authors": [
            "Rui Louren\u00e7o",
            "Lucas Thomaz",
            "Eduardo A. B. Silva",
            "Sergio M. M. Faria"
        ],
        "comments": " ",
        "subjects": "Image and Video Processing (eess.IV)",
        "abstract": "Light field cameras and multi-camera arrays have emerged as promising solutions for accurately estimating depth by passively capturing light information. This is possible because the 3D information of a scene is embedded in the 4D light field geometry. Commonly, depth estimation methods extract this information relying on gradient information, heuristic-based optimisation models, or learning-based approaches. This paper focuses mainly on explicitly understanding and exploiting 4D geometrical cues for light field depth estimation. Thus, a novel method is proposed, based on a non-learning-based optimisation approach for depth estimation that explicitly considers surface normal accuracy and occlusion regions by utilising a fully explainable 4D geometric model of the light field. The 4D model performs depth/disparity estimation by determining the orientations and analysing the intersections of key 2D planes in 4D space, which are the images of 3D-space points in the 4D light field. Experimental results show that the proposed method outperforms both learning-based and non-learning-based state-of-the-art methods in terms of surface normal angle accuracy, achieving a Median Angle Error on planar surfaces, on average, 26.3\\% lower than the state-of-the-art, and still being competitive with state-of-the-art methods in terms of Mean Squared Error $\\vc{\\times}$ 100 and Badpix 0.07.\n    ",
        "primary_category": "eess.IV",
        "categories": [
            "cs.CV"
        ],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.02044": {
        "title": "Time-Reversal of Stochastic Maximum Principle",
        "authors": [
            "Amirhossein Taghvaei"
        ],
        "comments": " ",
        "subjects": "Systems and Control (eess.SY)",
        "abstract": "Stochastic maximum principle (SMP) specifies a necessary condition for the solution of a stochastic optimal control problem. The condition involves a coupled system of forward and backward stochastic differential equations (FBSDE) for the state and the adjoint processes. Numerical solution of the FBSDE is challenging because the boundary condition of the adjoint process is specified at the terminal time, while the solution should be adaptable to the forward in time filtration of a Wiener process. In this paper, a \"time-reversal\" of the FBSDE system is proposed that involves integration with respect to a backward in time Wiener process. The time-reversal is used to propose an iterative Monte-Carlo procedure to solves the FBSDE system and its time-reversal simultaneously. The procedure involves approximating the {F\u00f6llmer's drift} and solving a regression problem between the state and its adjoint at each time. The procedure is illustrated for the linear quadratic (LQ) optimal control problem with a numerical example.\n    ",
        "primary_category": "eess.SY",
        "categories": [
            "math.OC"
        ],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.02051": {
        "title": "Differential Privacy of Noisy (S)GD under Heavy-Tailed Perturbations",
        "authors": [
            "Umut \u015eim\u015fekli",
            "Mert G\u00fcrb\u00fczbalaban",
            "Sinan Y\u0131ld\u0131r\u0131m",
            "Lingjiong Zhu"
        ],
        "comments": " ",
        "subjects": "Machine Learning (stat.ML)",
        "abstract": "Injecting heavy-tailed noise to the iterates of stochastic gradient descent (SGD) has received increasing attention over the past few years. While various theoretical properties of the resulting algorithm have been analyzed mainly from learning theory and optimization perspectives, their privacy preservation properties have not yet been established. Aiming to bridge this gap, we provide differential privacy (DP) guarantees for noisy SGD, when the injected noise follows an $\\alpha$-stable distribution, which includes a spectrum of heavy-tailed distributions (with infinite variance) as well as the Gaussian distribution. Considering the $(\\epsilon, \\delta)$-DP framework, we show that SGD with heavy-tailed perturbations achieves $(0, \\tilde{\\mathcal{O}}(1/n))$-DP for a broad class of loss functions which can be non-convex, where $n$ is the number of data points. As a remarkable byproduct, contrary to prior work that necessitates bounded sensitivity for the gradients or clipping the iterates, our theory reveals that under mild assumptions, such a projection step is not actually necessary. We illustrate that the heavy-tailed noising mechanism achieves similar DP guarantees compared to the Gaussian case, which suggests that it can be a viable alternative to its light-tailed counterparts.\n    ",
        "primary_category": "stat.ML",
        "categories": [
            "cs.CR",
            "cs.LG",
            "math.ST"
        ],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.02053": {
        "title": "A Scoping Review of Energy-Efficient Driving Behaviors and Applied State-of-the-Art AI Methods",
        "authors": [
            "Zhipeng Ma",
            "Bo N\u00f8rregaard J\u00f8rgensen",
            "Zheng Ma"
        ],
        "comments": " ",
        "subjects": "Artificial Intelligence (cs.AI)",
        "abstract": "The transportation sector remains a major contributor to greenhouse gas emissions. The understanding of energy-efficient driving behaviors and utilization of energy-efficient driving strategies are essential to reduce vehicles' fuel consumption. However, there is no comprehensive investigation into energy-efficient driving behaviors and strategies. Furthermore, many state-of-the-art AI models have been applied for the analysis of eco-friendly driving styles, but no overview is available. To fill the gap, this paper conducts a thorough literature review on ecological driving behaviors and styles and analyzes the driving factors influencing energy consumption and state-of-the-art methodologies. With a thorough scoping review process, the methodological and related data are compared. The results show that the factors that impact driving behaviors can be summarized into eleven features including speed, acceleration, deceleration, pedal, and so on. This paper finds that supervised/unsupervised learning algorithms and reinforcement learning frameworks have been popularly used to model the vehicle's energy consumption with multi-dimensional data. Furthermore, the literature shows that the driving data are collected from either simulators or real-world experiments, and the real-world data are mainly stored and transmitted by meters, controller area networks, onboard data services, smartphones, and additional sensors installed in the vehicle. Based on driving behavior factors, driver characteristics, and safety rules, this paper recommends nine energy-efficient driving styles including four guidelines for the drivers' selection and adjustment of the vehicle parameters, three recommendations for the energy-efficient driving styles in different driving scenarios, and two subjective suggestions for different types of drivers and employers.\n    ",
        "primary_category": "cs.AI",
        "categories": [],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.02054": {
        "title": "Large Language Model-Based Evolutionary Optimizer: Reasoning with elitism",
        "authors": [
            "Shuvayan Brahmachary",
            "Subodh M. Joshi",
            "Aniruddha Panda",
            "Kaushik Koneripalli",
            "Arun Kumar Sagotra",
            "Harshil Patel",
            "Ankush Sharma",
            "Ameya D. Jagtap",
            "Kaushic Kalyanaraman"
        ],
        "comments": " ",
        "subjects": "Artificial Intelligence (cs.AI)",
        "abstract": "Large Language Models (LLMs) have demonstrated remarkable reasoning abilities, prompting interest in their application as black-box optimizers. This paper asserts that LLMs possess the capability for zero-shot optimization across diverse scenarios, including multi-objective and high-dimensional problems. We introduce a novel population-based method for numerical optimization using LLMs called Language-Model-Based Evolutionary Optimizer (LEO). Our hypothesis is supported through numerical examples, spanning benchmark and industrial engineering problems such as supersonic nozzle shape optimization, heat transfer, and windfarm layout optimization. We compare our method to several gradient-based and gradient-free optimization approaches. While LLMs yield comparable results to state-of-the-art methods, their imaginative nature and propensity to hallucinate demand careful handling. We provide practical guidelines for obtaining reliable answers from LLMs and discuss method limitations and potential research directions.\n    ",
        "primary_category": "cs.AI",
        "categories": [],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.02059": {
        "title": "Multi-Spectral Remote Sensing Image Retrieval Using Geospatial Foundation Models",
        "authors": [
            "Benedikt Blumenstiel",
            "Viktoria Moor",
            "Romeo Kienzler",
            "Thomas Brunschwiler"
        ],
        "comments": " ",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Image retrieval enables an efficient search through vast amounts of satellite imagery and returns similar images to a query. Deep learning models can identify images across various semantic concepts without the need for annotations. This work proposes to use Geospatial Foundation Models, like Prithvi, for remote sensing image retrieval with multiple benefits: i) the models encode multi-spectral satellite data and ii) generalize without further fine-tuning. We introduce two datasets to the retrieval task and observe a strong performance: Prithvi processes six bands and achieves a mean Average Precision of 97.62\\% on BigEarthNet-43 and 44.51\\% on ForestNet-12, outperforming other RGB-based models. Further, we evaluate three compression methods with binarized embeddings balancing retrieval speed and accuracy. They match the retrieval speed of much shorter hash codes while maintaining the same accuracy as floating-point embeddings but with a 32-fold compression. The code is available at this https URL.\n    ",
        "primary_category": "cs.CV",
        "categories": [],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.02063": {
        "title": "Depth-Guided Robust and Fast Point Cloud Fusion NeRF for Sparse Input Views",
        "authors": [
            "Shuai Guo",
            "Qiuwen Wang",
            "Yijie Gao",
            "Rong Xie",
            "Li Song"
        ],
        "comments": " ",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Novel-view synthesis with sparse input views is important for real-world applications like AR/VR and autonomous driving. Recent methods have integrated depth information into NeRFs for sparse input synthesis, leveraging depth prior for geometric and spatial understanding. However, most existing works tend to overlook inaccuracies within depth maps and have low time efficiency. To address these issues, we propose a depth-guided robust and fast point cloud fusion NeRF for sparse inputs. We perceive radiance fields as an explicit voxel grid of features. A point cloud is constructed for each input view, characterized within the voxel grid using matrices and vectors. We accumulate the point cloud of each input view to construct the fused point cloud of the entire scene. Each voxel determines its density and appearance by referring to the point cloud of the entire scene. Through point cloud fusion and voxel grid fine-tuning, inaccuracies in depth values are refined or substituted by those from other views. Moreover, our method can achieve faster reconstruction and greater compactness through effective vector-matrix decomposition. Experimental results underline the superior performance and time efficiency of our approach compared to state-of-the-art baselines.\n    ",
        "primary_category": "cs.CV",
        "categories": [],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.02071": {
        "title": "On Efficient Approximation of the Maximum Distance to A Point Over an Intersection of Balls",
        "authors": [
            "Beniamin Costandin",
            "Marius Costandin"
        ],
        "comments": " ",
        "subjects": "Computational Geometry (cs.CG)",
        "abstract": "In this paper we study the NP-Hard problem of maximizing the distance over an intersection of balls to a given point. We expand the results found in \\cite{funcos1}, where the authors characterize the farthest in an intersection of balls $\\mathcal{Q}$ to the given point $C_0$ by constructing some intersection of halfspaces. In this paper, by slightly modifying the technique found in literature, we characterize the farthest in an intersection of balls $\\mathcal{Q}$ with another intersection of balls $\\mathcal{Q}_1$. As such, going backwards, we are naturally able to find the given intersection of balls $\\mathcal{Q}$ as the max indicator intersection of balls of another one $\\mathcal{Q}_{-1}$. By repeating the process, we find a sequence of intersection of balls $(\\mathcal{Q}_{i})_{i \\in \\mathbb{Z}}$, which has $\\mathcal{Q}$ as an element, namely $\\mathcal{Q}_{0}$ and show that $\\mathcal{Q}_{-\\infty} = \\mathcal{B}(C_0,R_0)$ where $R_0$ is the maximum distance from $C_0$ to a point in $\\mathcal{Q}$. As a final application of the proposed theory we give a polynomial algorithm for computing the maximum distance under an oracle which returns the volume of an intersection of balls, showing that the later is NP-Hard. Finally, we present a randomized method %of polynomial complexity which allows an approximation of the maximum distance.\n    ",
        "primary_category": "cs.CG",
        "categories": [
            "math.OC"
        ],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.02074": {
        "title": "Modality-Aware and Shift Mixer for Multi-modal Brain Tumor Segmentation",
        "authors": [
            "Zhongzhen Huang",
            "Linda Wei",
            "Shaoting Zhang",
            "Xiaofan Zhang"
        ],
        "comments": " ",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Combining images from multi-modalities is beneficial to explore various information in computer vision, especially in the medical domain. As an essential part of clinical diagnosis, multi-modal brain tumor segmentation aims to delineate the malignant entity involving multiple modalities. Although existing methods have shown remarkable performance in the task, the information exchange for cross-scale and high-level representations fusion in spatial and modality are limited in these methods. In this paper, we present a novel Modality Aware and Shift Mixer that integrates intra-modality and inter-modality dependencies of multi-modal images for effective and robust brain tumor segmentation. Specifically, we introduce a Modality-Aware module according to neuroimaging studies for modeling the specific modality pair relationships at low levels, and a Modality-Shift module with specific mosaic patterns is developed to explore the complex relationships across modalities at high levels via the self-attention. Experimentally, we outperform previous state-of-the-art approaches on the public Brain Tumor Segmentation (BraTS 2021 segmentation) dataset. Further qualitative experiments demonstrate the efficacy and robustness of MASM.\n    ",
        "primary_category": "cs.CV",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.02076": {
        "title": "VTG-GPT: Tuning-Free Zero-Shot Video Temporal Grounding with GPT",
        "authors": [
            "Yifang Xu",
            "Yunzhuo Sun",
            "Zien Xie",
            "Benxiang Zhai",
            "Sidan Du"
        ],
        "comments": "15 pages, 7 figures",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Video temporal grounding (VTG) aims to locate specific temporal segments from an untrimmed video based on a linguistic query. Most existing VTG models are trained on extensive annotated video-text pairs, a process that not only introduces human biases from the queries but also incurs significant computational costs. To tackle these challenges, we propose VTG-GPT, a GPT-based method for zero-shot VTG without training or fine-tuning. To reduce prejudice in the original query, we employ Baichuan2 to generate debiased queries. To lessen redundant information in videos, we apply MiniGPT-v2 to transform visual content into more precise captions. Finally, we devise the proposal generator and post-processing to produce accurate segments from debiased queries and image captions. Extensive experiments demonstrate that VTG-GPT significantly outperforms SOTA methods in zero-shot settings and surpasses unsupervised approaches. More notably, it achieves competitive performance comparable to supervised methods. The code is available on this https URL\n",
        "primary_category": "cs.CV",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.02078": {
        "title": "Automated Generation of Multiple-Choice Cloze Questions for Assessing English Vocabulary Using GPT-turbo 3.5",
        "authors": [
            "Qiao Wang",
            "Ralph Rose",
            "Naho Orita",
            "Ayaka Sugawara"
        ],
        "comments": " ",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "A common way of assessing language learners' mastery of vocabulary is via multiple-choice cloze (i.e., fill-in-the-blank) questions. But the creation of test items can be laborious for individual teachers or in large-scale language programs. In this paper, we evaluate a new method for automatically generating these types of questions using large language models (LLM). The VocaTT (vocabulary teaching and training) engine is written in Python and comprises three basic steps: pre-processing target word lists, generating sentences and candidate word options using GPT, and finally selecting suitable word options. To test the efficiency of this system, 60 questions were generated targeting academic words. The generated items were reviewed by expert reviewers who judged the well-formedness of the sentences and word options, adding comments to items judged not well-formed. Results showed a 75% rate of well-formedness for sentences and 66.85% rate for suitable word options. This is a marked improvement over the generator used earlier in our research which did not take advantage of GPT's capabilities. Post-hoc qualitative analysis reveals several points for improvement in future work including cross-referencing part-of-speech tagging, better sentence validation, and improving GPT prompts.\n    ",
        "primary_category": "cs.CL",
        "categories": [],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.02080": {
        "title": "Hybrid Quantum Neural Network Advantage for Radar-Based Drone Detection and Classification in Low Signal-to-Noise Ratio",
        "authors": [
            "Aiswariya Sweety Malarvanan"
        ],
        "comments": "9 pages, 18 figures",
        "subjects": "Quantum Physics (quant-ph)",
        "abstract": "In this paper, we investigate the performance of a Hybrid Quantum Neural Network (HQNN) and a comparable classical Convolution Neural Network (CNN) for detection and classification problem using a radar. Specifically, we take a fairly complex radar time-series model derived from electromagnetic theory, namely the Martin-Mulgrew model, that is used to simulate radar returns of objects with rotating blades, such as drones. We find that when that signal-to-noise ratio (SNR) is high, CNN outperforms the HQNN for detection and classification. However, in the low SNR regime (which is of greatest interest in practice) the performance of HQNN is found to be superior to that of the CNN of a similar architecture.\n    ",
        "primary_category": "quant-ph",
        "categories": [
            "cs.LG",
            "eess.SP",
            "physics.app-ph"
        ],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.02084": {
        "title": "ResAdapter: Domain Consistent Resolution Adapter for Diffusion Models",
        "authors": [
            "Jiaxiang Cheng",
            "Pan Xie",
            "Xin Xia",
            "Jiashi Li",
            "Jie Wu",
            "Yuxi Ren",
            "Huixia Li",
            "Xuefeng Xiao",
            "Min Zheng",
            "Lean Fu"
        ],
        "comments": "21 pages, 16 figures",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Recent advancement in text-to-image models (e.g., Stable Diffusion) and corresponding personalized technologies (e.g., DreamBooth and LoRA) enables individuals to generate high-quality and imaginative images. However, they often suffer from limitations when generating images with resolutions outside of their trained domain. To overcome this limitation, we present the Resolution Adapter (ResAdapter), a domain-consistent adapter designed for diffusion models to generate images with unrestricted resolutions and aspect ratios. Unlike other multi-resolution generation methods that process images of static resolution with complex post-process operations, ResAdapter directly generates images with the dynamical resolution. Especially, after learning a deep understanding of pure resolution priors, ResAdapter trained on the general dataset, generates resolution-free images with personalized diffusion models while preserving their original style domain. Comprehensive experiments demonstrate that ResAdapter with only 0.5M can process images with flexible resolutions for arbitrary diffusion models. More extended experiments demonstrate that ResAdapter is compatible with other modules (e.g., ControlNet, IP-Adapter and LCM-LoRA) for image generation across a broad range of resolutions, and can be integrated into other multi-resolution model (e.g., ElasticDiffusion) for efficiently generating higher-resolution images. Project link is this https URL\n",
        "primary_category": "cs.CV",
        "categories": [],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.02095": {
        "title": "Homotopy Methods for Convex Optimization",
        "authors": [
            "Andreas Klingler",
            "Tim Netzer"
        ],
        "comments": "29 pages, 10 figures",
        "subjects": "Optimization and Control (math.OC)",
        "abstract": "Convex optimization encompasses a wide range of optimization problems, containing many efficiently solvable subclasses. Interior point methods are currently the state-of-the-art approach for solving such problems, particularly effective for classes like semidefinite programming, quadratic programming, and geometric programming. However, their success hinges on the construction of self-concordant barrier functions for the feasible sets. In this work, we introduce an alternative method for tackling convex optimization problems, employing a homotopy. With this technique, the feasible set of a trivial optimization problem is continuously transformed into the target one, while tracking the solutions. We conduct an analysis of this approach, focusing on its application to semidefinite programs, hyperbolic programs, and convex optimization problems with a single convexity constraint. Moreover, we demonstrate that our approach numerically outperforms state-of-the-art methods in several interesting cases.\n    ",
        "primary_category": "math.OC",
        "categories": [
            "math.AG",
            "math.NA"
        ],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.02107": {
        "title": "Iterated $Q$-Network: Beyond the One-Step Bellman Operator",
        "authors": [
            "Th\u00e9o Vincent",
            "Daniel Palenicek",
            "Boris Belousov",
            "Jan Peters",
            "Carlo D'Eramo"
        ],
        "comments": "Preprint",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Value-based Reinforcement Learning (RL) methods rely on the application of the Bellman operator, which needs to be approximated from samples. Most approaches consist of an iterative scheme alternating the application of the Bellman operator and a subsequent projection step onto a considered function space. However, we observe that these algorithms can be improved by considering multiple iterations of the Bellman operator at once. Thus, we introduce iterated $Q$-Networks (iQN), a novel approach that learns a sequence of $Q$-function approximations where each $Q$-function serves as the target for the next one in a chain of consecutive Bellman iterations. We demonstrate that iQN is theoretically sound and show how it can be seamlessly used in value-based and actor-critic methods. We empirically demonstrate its advantages on Atari $2600$ games and in continuous-control MuJoCo environments.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.02112": {
        "title": "A New Perspective on Smiling and Laughter Detection: Intensity Levels Matter",
        "authors": [
            "Hugo Bohy",
            "Kevin El Haddad",
            "Thierry Dutoit"
        ],
        "comments": " ",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Smiles and laughs detection systems have attracted a lot of attention in the past decade contributing to the improvement of human-agent interaction systems. But very few considered these expressions as distinct, although no prior work clearly proves them to belong to the same category or not. In this work, we present a deep learning-based multimodal smile and laugh classification system, considering them as two different entities. We compare the use of audio and vision-based models as well as a fusion approach. We show that, as expected, the fusion leads to a better generalization on unseen data. We also present an in-depth analysis of the behavior of these models on the smiles and laughs intensity levels. The analyses on the intensity levels show that the relationship between smiles and laughs might not be as simple as a binary one or even grouping them in a single category, and so, a more complex approach should be taken when dealing with them. We also tackle the problem of limited resources by showing that transfer learning allows the models to improve the detection of confusing intensity levels.\n    ",
        "primary_category": "cs.CV",
        "categories": [],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.02116": {
        "title": "Inf2Guard: An Information-Theoretic Framework for Learning Privacy-Preserving Representations against Inference Attacks",
        "authors": [
            "Sayedeh Leila Noorbakhsh",
            "Binghui Zhang",
            "Yuan Hong",
            "Binghui Wang"
        ],
        "comments": "Accepted by Usenix Security 2024",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Machine learning (ML) is vulnerable to inference (e.g., membership inference, property inference, and data reconstruction) attacks that aim to infer the private information of training data or dataset. Existing defenses are only designed for one specific type of attack and sacrifice significant utility or are soon broken by adaptive attacks. We address these limitations by proposing an information-theoretic defense framework, called Inf2Guard, against the three major types of inference attacks. Our framework, inspired by the success of representation learning, posits that learning shared representations not only saves time/costs but also benefits numerous downstream tasks. Generally, Inf2Guard involves two mutual information objectives, for privacy protection and utility preservation, respectively. Inf2Guard exhibits many merits: it facilitates the design of customized objectives against the specific inference attack; it provides a general defense framework which can treat certain existing defenses as special cases; and importantly, it aids in deriving theoretical results, e.g., inherent utility-privacy tradeoff and guaranteed privacy leakage. Extensive evaluations validate the effectiveness of Inf2Guard for learning privacy-preserving representations against inference attacks and demonstrate the superiority over the baselines.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.CR"
        ],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.02121": {
        "title": "Leveraging Weakly Annotated Data for Hate Speech Detection in Code-Mixed Hinglish: A Feasibility-Driven Transfer Learning Approach with Large Language Models",
        "authors": [
            "Sargam Yadav",
            "Abhishek Kaushik",
            "Kevin McDaid"
        ],
        "comments": "This paper is accepted in the 16th ISDSI-Global Conference 2023 this https URL",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "The advent of Large Language Models (LLMs) has advanced the benchmark in various Natural Language Processing (NLP) tasks. However, large amounts of labelled training data are required to train LLMs. Furthermore, data annotation and training are computationally expensive and time-consuming. Zero and few-shot learning have recently emerged as viable options for labelling data using large pre-trained models. Hate speech detection in mix-code low-resource languages is an active problem area where the use of LLMs has proven beneficial. In this study, we have compiled a dataset of 100 YouTube comments, and weakly labelled them for coarse and fine-grained misogyny classification in mix-code Hinglish. Weak annotation was applied due to the labor-intensive annotation process. Zero-shot learning, one-shot learning, and few-shot learning and prompting approaches have then been applied to assign labels to the comments and compare them to human-assigned labels. Out of all the approaches, zero-shot classification using the Bidirectional Auto-Regressive Transformers (BART) large model and few-shot prompting using Generative Pre-trained Transformer- 3 (ChatGPT-3) achieve the best results\n    ",
        "primary_category": "cs.CL",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.02127": {
        "title": "LOCR: Location-Guided Transformer for Optical Character Recognition",
        "authors": [
            "Yu Sun",
            "Dongzhan Zhou",
            "Chen Lin",
            "Conghui He",
            "Wanli Ouyang",
            "Han-Sen Zhong"
        ],
        "comments": " ",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Academic documents are packed with texts, equations, tables, and figures, requiring comprehensive understanding for accurate Optical Character Recognition (OCR). While end-to-end OCR methods offer improved accuracy over layout-based approaches, they often grapple with significant repetition issues, especially with complex layouts in Out-Of-Domain (OOD) this http URL tackle this issue, we propose LOCR, a model that integrates location guiding into the transformer architecture during autoregression. We train the model on a dataset comprising over 77M text-location pairs from 125K academic document pages, including bounding boxes for words, tables and mathematical symbols. LOCR adeptly handles various formatting elements and generates content in Markdown language. It outperforms all existing methods in our test set constructed from arXiv, as measured by edit distance, BLEU, METEOR and F-measure.LOCR also reduces repetition frequency from 4.4% of pages to 0.5% in the arXiv dataset, from 13.2% to 1.3% in OOD quantum physics documents and from 8.1% to 1.8% in OOD marketing documents. Additionally, LOCR features an interactive OCR mode, facilitating the generation of complex documents through a few location prompts from human.\n    ",
        "primary_category": "cs.CV",
        "categories": [
            "cs.AI",
            "cs.CL"
        ],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.02129": {
        "title": "Demeter: Resource-Efficient Distributed Stream Processing under Dynamic Loads with Multi-Configuration Optimization",
        "authors": [
            "Morgan Geldenhuys",
            "Dominik Scheinert",
            "Odej Kao",
            "Lauritz Thamsen"
        ],
        "comments": "12 pages, 14 figures, published at ICPE 2024",
        "subjects": "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "abstract": "Distributed Stream Processing (DSP) focuses on the near real-time processing of large streams of unbounded data. To increase processing capacities, DSP systems are able to dynamically scale across a cluster of commodity nodes, ensuring a good Quality of Service despite variable workloads. However, selecting scaleout configurations which maximize resource utilization remains a challenge. This is especially true in environments where workloads change over time and node failures are all but inevitable. Furthermore, configuration parameters such as memory allocation and checkpointing intervals impact performance and resource usage as well. Sub-optimal configurations easily lead to high operational costs, poor performance, or unacceptable loss of service.\nIn this paper, we present Demeter, a method for dynamically optimizing key DSP system configuration parameters for resource efficiency. Demeter uses Time Series Forecasting to predict future workloads and Multi-Objective Bayesian Optimization to model runtime behaviors in relation to parameter settings and workload rates. Together, these techniques allow us to determine whether or not enough is known about the predicted workload rate to proactively initiate short-lived parallel profiling runs for data gathering. Once trained, the models guide the adjustment of multiple, potentially dependent system configuration parameters ensuring optimized performance and resource usage in response to changing workload rates. Our experiments on a commodity cluster using Apache Flink demonstrate that Demeter significantly improves the operational efficiency of long-running benchmark jobs.\n    ",
        "primary_category": "cs.DC",
        "categories": [],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.02132": {
        "title": "UB-FineNet: Urban Building Fine-grained Classification Network for Open-access Satellite Images",
        "authors": [
            "Zhiyi He",
            "Wei Yao",
            "Jie Shao",
            "Puzuo Wang"
        ],
        "comments": " ",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Fine classification of city-scale buildings from satellite remote sensing imagery is a crucial research area with significant implications for urban planning, infrastructure development, and population distribution analysis. However, the task faces big challenges due to low-resolution overhead images acquired from high altitude space-borne platforms and the long-tail sample distribution of fine-grained urban building categories, leading to severe class imbalance problem. To address these issues, we propose a deep network approach to fine-grained classification of urban buildings using open-access satellite images. A Denoising Diffusion Probabilistic Model (DDPM) based super-resolution method is first introduced to enhance the spatial resolution of satellite images, which benefits from domain-adaptive knowledge distillation. Then, a new fine-grained classification network with Category Information Balancing Module (CIBM) and Contrastive Supervision (CS) technique is proposed to mitigate the problem of class imbalance and improve the classification robustness and accuracy. Experiments on Hong Kong data set with 11 fine building types revealed promising classification results with a mean Top-1 accuracy of 60.45\\%, which is on par with street-view image based approaches. Extensive ablation study shows that CIBM and CS improve Top-1 accuracy by 2.6\\% and 3.5\\% compared to the baseline method, respectively. And both modules can be easily inserted into other classification networks and similar enhancements have been achieved. Our research contributes to the field of urban analysis by providing a practical solution for fine classification of buildings in challenging mega city scenarios solely using open-access satellite images. The proposed method can serve as a valuable tool for urban planners, aiding in the understanding of economic, industrial, and population distribution.\n    ",
        "primary_category": "cs.CV",
        "categories": [],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.02135": {
        "title": "Memoro: Using Large Language Models to Realize a Concise Interface for Real-Time Memory Augmentation",
        "authors": [
            "Wazeer Zulfikar",
            "Samantha Chan",
            "Pattie Maes"
        ],
        "comments": "18 pages, 9 figures, project page at this https URL",
        "subjects": "Human-Computer Interaction (cs.HC)",
        "abstract": "People have to remember an ever-expanding volume of information. Wearables that use information capture and retrieval for memory augmentation can help but can be disruptive and cumbersome in real-world tasks, such as in social settings. To address this, we developed Memoro, a wearable audio-based memory assistant with a concise user interface. Memoro uses a large language model (LLM) to infer the user's memory needs in a conversational context, semantically search memories, and present minimal suggestions. The assistant has two interaction modes: Query Mode for voicing queries and Queryless Mode for on-demand predictive assistance, without explicit query. Our study of (N=20) participants engaged in a real-time conversation demonstrated that using Memoro reduced device interaction time and increased recall confidence while preserving conversational quality. We report quantitative results and discuss the preferences and experiences of users. This work contributes towards utilizing LLMs to design wearable memory augmentation systems that are minimally disruptive.\n    ",
        "primary_category": "cs.HC",
        "categories": [],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.02136": {
        "title": "Point2Building: Reconstructing Buildings from Airborne LiDAR Point Clouds",
        "authors": [
            "Yujia Liu",
            "Anton Obukhov",
            "Jan Dirk Wegner",
            "Konrad Schindler"
        ],
        "comments": " ",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "We present a learning-based approach to reconstruct buildings as 3D polygonal meshes from airborne LiDAR point clouds. What makes 3D building reconstruction from airborne LiDAR hard is the large diversity of building designs and especially roof shapes, the low and varying point density across the scene, and the often incomplete coverage of building facades due to occlusions by vegetation or to the viewing angle of the sensor. To cope with the diversity of shapes and inhomogeneous and incomplete object coverage, we introduce a generative model that directly predicts 3D polygonal meshes from input point clouds. Our autoregressive model, called Point2Building, iteratively builds up the mesh by generating sequences of vertices and faces. This approach enables our model to adapt flexibly to diverse geometries and building structures. Unlike many existing methods that rely heavily on pre-processing steps like exhaustive plane detection, our model learns directly from the point cloud data, thereby reducing error propagation and increasing the fidelity of the reconstruction. We experimentally validate our method on a collection of airborne LiDAR data of Zurich, Berlin and Tallinn. Our method shows good generalization to diverse urban styles.\n    ",
        "primary_category": "cs.CV",
        "categories": [],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.02138": {
        "title": "Self-Supervised Facial Representation Learning with Facial Region Awareness",
        "authors": [
            "Zheng Gao",
            "Ioannis Patras"
        ],
        "comments": " ",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Self-supervised pre-training has been proved to be effective in learning transferable representations that benefit various visual tasks. This paper asks this question: can self-supervised pre-training learn general facial representations for various facial analysis tasks? Recent efforts toward this goal are limited to treating each face image as a whole, i.e., learning consistent facial representations at the image-level, which overlooks the consistency of local facial representations (i.e., facial regions like eyes, nose, etc). In this work, we make a first attempt to propose a novel self-supervised facial representation learning framework to learn consistent global and local facial representations, Facial Region Awareness (FRA). Specifically, we explicitly enforce the consistency of facial regions by matching the local facial representations across views, which are extracted with learned heatmaps highlighting the facial regions. Inspired by the mask prediction in supervised semantic segmentation, we obtain the heatmaps via cosine similarity between the per-pixel projection of feature maps and facial mask embeddings computed from learnable positional embeddings, which leverage the attention mechanism to globally look up the facial image for facial regions. To learn such heatmaps, we formulate the learning of facial mask embeddings as a deep clustering problem by assigning the pixel features from the feature maps to them. The transfer learning results on facial classification and regression tasks show that our FRA outperforms previous pre-trained models and more importantly, using ResNet as the unified backbone for various tasks, our FRA achieves comparable or even better performance compared with SOTA methods in facial analysis tasks.\n    ",
        "primary_category": "cs.CV",
        "categories": [],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.02139": {
        "title": "Analysis on aggregation and block smoothers in multigrid methods for block Toeplitz linear systems",
        "authors": [
            "Matthias Bolten",
            "Marco Donatelli",
            "Paola Ferrari",
            "Isabella Furci"
        ],
        "comments": " ",
        "subjects": "Numerical Analysis (math.NA)",
        "abstract": "We present novel improvements in the context of symbol-based multigrid procedures for solving large block structured linear systems. We study the application of an aggregation-based grid transfer operator that transforms the symbol of a block Toeplitz matrix from matrix-valued to scalar-valued at the coarser level. Our convergence analysis of the Two-Grid Method (TGM) reveals the connection between the features of the scalar-valued symbol at the coarser level and the properties of the original matrix-valued one. This allows us to prove the convergence of a V-cycle multigrid with standard grid transfer operators for scalar Toeplitz systems at the coarser levels. Consequently, we extend the class of suitable smoothers for block Toeplitz matrices, focusing on the efficiency of block strategies, particularly the relaxed block Jacobi method. General conditions on smoothing parameters are derived, with emphasis on practical applications where these parameters can be calculated with negligible computational cost. We test the proposed strategies on linear systems stemming from the discretization of differential problems with $\\mathbb{Q}_{d} $ Lagrangian FEM or B-spline with non-maximal regularity. The numerical results show in both cases computational advantages compared to existing methods for block structured linear systems.\n    ",
        "primary_category": "math.NA",
        "categories": [],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.02140": {
        "title": "Matching Algorithms in the Sparse Stochastic Block Model",
        "authors": [
            "Anna Brandenberger",
            "Byron Chin",
            "Nathan S. Sheffield",
            "Divya Shyamal"
        ],
        "comments": "28 pages",
        "subjects": "Data Structures and Algorithms (cs.DS)",
        "abstract": "The stochastic block model (SBM) is a generalization of the Erd\u0151s--R\u00e9nyi model of random graphs that describes the interaction of a finite number of distinct communities. In sparse Erd\u0151s--R\u00e9nyi graphs, it is known that a linear-time algorithm of Karp and Sipser achieves near-optimal matching sizes asymptotically almost surely, giving a law-of-large numbers for the matching sizes of such graphs in terms of solutions to an ODE. We provide an extension of this analysis, identifying broad ranges of stochastic block model parameters for which the Karp--Sipser algorithm achieves near-optimal matching sizes, but demonstrating that it cannot perform optimally on general SBM instances.\nWe also consider the problem of constructing a matching online, in which the vertices of one half of a bipartite stochastic block model arrive one-at-a-time, and must be matched as they arrive. We show that the competitive ratio lower bound of 0.837 found by Mastin and Jaillet for the Erd\u0151s--R\u00e9nyi case is tight whenever the expected degrees in all communities are equal. We propose several linear-time algorithms for online matching in the general stochastic block model, but prove that despite very good experimental performance, none of these achieve online asymptotic optimality.\n    ",
        "primary_category": "cs.DS",
        "categories": [
            "cs.DM"
        ],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.02141": {
        "title": "Multi-Derivative Runge-Kutta Flux Reconstruction for hyperbolic conservation laws",
        "authors": [
            "Arpit Babbar",
            "Praveen Chandrashekar"
        ],
        "comments": " ",
        "subjects": "Numerical Analysis (math.NA)",
        "abstract": "We extend the fourth order, two stage Multi-Derivative Runge Kutta (MDRK) scheme of Li and Du to the Flux Reconstruction (FR) framework by writing both of the stages in terms of a time averaged flux and then use the approximate Lax-Wendroff procedure. Numerical flux is computed in each stage using D2 dissipation and EA flux, enhancing Fourier CFL stability and accuracy respectively. A subcell based blending limiter is developed for the MDRK scheme, which ensures that the limited scheme is provably admissibility preserving. Along with being admissibility preserving, the blending scheme is constructed to minimize dissipation errors by using Gauss-Legendre solution points and performing MUSCL-Hancock reconstruction on subcells. The accuracy enhancement of the blending scheme is numerically verified on compressible Euler's equations, with test cases involving shocks and small-scale structures.\n    ",
        "primary_category": "math.NA",
        "categories": [
            "physics.comp-ph"
        ],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.02145": {
        "title": "'SSL?! What on earth is that?': Towards Designing Age-Inclusive Secure Smartphone Browsing",
        "authors": [
            "Pavithren V. S. Pakianathan",
            "L. Siddharth",
            "Sujithra Raviselvam",
            "Kristin L. Wood",
            "Hyowon Lee",
            "Pin Sym Foong",
            "Jianying Zhou",
            "Simon Tangi Perrault"
        ],
        "comments": "This version was last submitted to EuroUSEC 2023 - European Symposium on Usable Security. It was later invited for poster submission at the same conference",
        "subjects": "Human-Computer Interaction (cs.HC)",
        "abstract": "Owing to the increase in 'certified' phishing websites, there is a steady increase in the number of phishing cases and general susceptibility to phishing. Trust mechanisms (e.g., HTTPS Lock Indicators, SSL Certificates) that help differentiate genuine and phishing websites should therefore be evaluated for their effectiveness in preventing vulnerable users from accessing phishing websites. In this article, we present a study involving 18 adults (male-6; female-12) and 12 older adults (male-4; female-8) to understand the usability of current trust mechanisms and preferred modalities in a conceptualized mechanism. In the first part of the study, using Chrome browser on Android, we asked the participants to browse a banking website and a government website for digital particulars. We asked them to identify which one of the two was a phishing website, rate the usability of both websites and provide qualitative feedback on the trust mechanisms. In the second part, we conceptualized an alternative trust mechanism, which allows seeking social, community and AI-based support to make website trust-related decisions. Herein, we asked the participants as to which modality (social, community or AI) they prefer to seek support from and why it is preferred. Using the current trust mechanisms, none of the participants were able to identify the phishing website. As the participants rated the current mechanisms poorly in terms of usability, they expressed various difficulties that largely did not differ between adults and older adults. In the conceptualized mechanism, we observed a notable difference in the preferred modalities, in that, older adults primarily preferred social support. In addition to these overall findings, specific observations suggest that future trust mechanisms should not only consider age-specific needs but also incorporate substantial improvement in terms of usability.\n    ",
        "primary_category": "cs.HC",
        "categories": [
            "cs.CY"
        ],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.02150": {
        "title": "Recency-Weighted Temporally-Segmented Ensemble for Time-Series Modeling",
        "authors": [
            "P\u00e5l V. Johnsen",
            "Eivind B\u00f8hn",
            "S\u00f8lve Eidnes",
            "Filippo Remonato",
            "Signe Riemer-S\u00f8rensen"
        ],
        "comments": "Main article with 23 pages including 12 figures and 4 tables. Supplementary File with 11 pages including 9 figures",
        "subjects": "Machine Learning (stat.ML)",
        "abstract": "Time-series modeling in process industries faces the challenge of dealing with complex, multi-faceted, and evolving data characteristics. Conventional single model approaches often struggle to capture the interplay of diverse dynamics, resulting in suboptimal forecasts. Addressing this, we introduce the Recency-Weighted Temporally-Segmented (ReWTS, pronounced `roots') ensemble model, a novel chunk-based approach for multi-step forecasting. The key characteristics of the ReWTS model are twofold: 1) It facilitates specialization of models into different dynamics by segmenting the training data into `chunks' of data and training one model per chunk. 2) During inference, an optimization procedure assesses each model on the recent past and selects the active models, such that the appropriate mixture of previously learned dynamics can be recalled to forecast the future. This method not only captures the nuances of each period, but also adapts more effectively to changes over time compared to conventional `global' models trained on all data in one go. We present a comparative analysis, utilizing two years of data from a wastewater treatment plant and a drinking water treatment plant in Norway, demonstrating the ReWTS ensemble's superiority. It consistently outperforms the global model in terms of mean squared forecasting error across various model architectures by 10-70\\% on both datasets, notably exhibiting greater resilience to outliers. This approach shows promise in developing automatic, adaptable forecasting models for decision-making and control systems in process industries and other complex systems.\n    ",
        "primary_category": "stat.ML",
        "categories": [
            "cs.LG"
        ],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.02151": {
        "title": "TripoSR: Fast 3D Object Reconstruction from a Single Image",
        "authors": [
            "Dmitry Tochilkin",
            "David Pankratz",
            "Zexiang Liu",
            "Zixuan Huang",
            "Adam Letts",
            "Yangguang Li",
            "Ding Liang",
            "Christian Laforte",
            "Varun Jampani",
            "Yan-Pei Cao"
        ],
        "comments": "Model: this https URL Code: this https URL Demo: this https URL",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "This technical report introduces TripoSR, a 3D reconstruction model leveraging transformer architecture for fast feed-forward 3D generation, producing 3D mesh from a single image in under 0.5 seconds. Building upon the LRM network architecture, TripoSR integrates substantial improvements in data processing, model design, and training techniques. Evaluations on public datasets show that TripoSR exhibits superior performance, both quantitatively and qualitatively, compared to other open-source alternatives. Released under the MIT license, TripoSR is intended to empower researchers, developers, and creatives with the latest advancements in 3D generative AI.\n    ",
        "primary_category": "cs.CV",
        "categories": [],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.02161": {
        "title": "LiveRec: Prototyping Probes by Framing Debug Protocols",
        "authors": [
            "Jean-Baptiste D\u00f6derlein",
            "Riemer van Rozen",
            "Tijs van der Storm"
        ],
        "comments": " ",
        "subjects": "Programming Languages (cs.PL)",
        "abstract": "Context:  In the first part of his 2012 presentation \"Inventing on Principle\", Bret Victor gives a demo of a live code editor for Javascript which shows the dynamic history of values of variables in real time. This form of live programming has become known as \"probes\". Probes provide the programmer with permanent and continuous insight into the dynamic evolution of function or method variables, thus improving feedback and developer experience.\nInquiry: Although Victor shows a working prototype of live probes in the context of Javascript, he does not discuss strategies for implementing them. Later work provides an implementation approach, but this requires a programming language to be implemented on top of the GraalVM runtime. In this paper we present **LiveRec**, a generic approach for implementing probes which can be applied in the context of many programming languages, without requiring the modification of compilers or run-time systems.\nApproach:  **LiveRec** is based on reusing existing debug protocols to implement probes. Methods or functions are compiled after every code change and executed inside the debugger. During execution the evolution of all local variables in the current stack frame are recorded and communicated back to the editor or IDE for display to the user.\nKnowledge:  It turns out that mainstream debug protocols are rich enough for implementing live probes. Step-wise execution, code hot swapping, and stack frame inspection provide the right granularity and sufficient information to realize live probes, without modifying compilers or language runtimes. Furthermore, it turns out that the recently proposed Debugger Adapter Protocol (DAP) provides an even more generic approach of implementing live probes, but, in some cases, at the cost of a significant performance penalty.\nGrounding:  We have applied **LiveRec** to implement probes using stack recording natively for Java through the Java Debug Interface (JDI), and through the DAP for Java, Python, C, and Javascript, all requiring just modest amounts of configuration code. We evaluate the run-time performance of all four probes prototypes, decomposed into: compile-after-change, hot swap, single step overhead, and stack recording overhead. Our initial results show that live probes on top of native debug APIs can be performant enough for interactive use. In the case of DAP, however, it highly depends on characteristics of the programming language implementation and its associated debugging infrastructure.\nImportance: Live programming improves the programmer experience by providing immediate feedback about a program's execution and eliminating disruptive edit-compile-restart sequences. Probes are one way to shorten the programmer feedback loop at the level of functions and methods. Although probes are not new, and have been implemented in (prototype) systems, **LiveRec**'s approach of building live probes on top of existing and generic debug protocols promises a path towards probes for a host of mainstream programming languages, with reasonable effort.\n    ",
        "primary_category": "cs.PL",
        "categories": [],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.02163": {
        "title": "REAL-Colon: A dataset for developing real-world AI applications in colonoscopy",
        "authors": [
            "Carlo Biffi",
            "Giulio Antonelli",
            "Sebastian Bernhofer",
            "Cesare Hassan",
            "Daizen Hirata",
            "Mineo Iwatate",
            "Andreas Maieron",
            "Pietro Salvagnini",
            "Andrea Cherubini"
        ],
        "comments": "12 pages, 5 tables, 7 figures",
        "subjects": "Image and Video Processing (eess.IV)",
        "abstract": "Detection and diagnosis of colon polyps are key to preventing colorectal cancer. Recent evidence suggests that AI-based computer-aided detection (CADe) and computer-aided diagnosis (CADx) systems can enhance endoscopists' performance and boost colonoscopy effectiveness. However, most available public datasets primarily consist of still images or video clips, often at a down-sampled resolution, and do not accurately represent real-world colonoscopy procedures. We introduce the REAL-Colon (Real-world multi-center Endoscopy Annotated video Library) dataset: a compilation of 2.7M native video frames from sixty full-resolution, real-world colonoscopy recordings across multiple centers. The dataset contains 350k bounding-box annotations, each created under the supervision of expert gastroenterologists. Comprehensive patient clinical data, colonoscopy acquisition information, and polyp histopathological information are also included in each video. With its unprecedented size, quality, and heterogeneity, the REAL-Colon dataset is a unique resource for researchers and developers aiming to advance AI research in colonoscopy. Its openness and transparency facilitate rigorous and reproducible research, fostering the development and benchmarking of more accurate and reliable colonoscopy-related algorithms and models.\n    ",
        "primary_category": "eess.IV",
        "categories": [
            "cs.CV"
        ],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.02167": {
        "title": "Speech emotion recognition from voice messages recorded in the wild",
        "authors": [
            "Luc\u00eda G\u00f3mez-Zaragoz\u00e1",
            "\u00d3scar Valls",
            "Roc\u00edo del Amor",
            "Mar\u00eda Jos\u00e9 Castro-Bleda",
            "Valery Naranjo",
            "Mariano Alca\u00f1iz Raya",
            "Javier Mar\u00edn-Morales"
        ],
        "comments": "This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible",
        "subjects": "Audio and Speech Processing (eess.AS)",
        "abstract": "Emotion datasets used for Speech Emotion Recognition (SER) often contain acted or elicited speech, limiting their applicability in real-world scenarios. In this work, we used the Emotional Voice Messages (EMOVOME) database, including spontaneous voice messages from conversations of 100 Spanish speakers on a messaging app, labeled in continuous and discrete emotions by expert and non-expert annotators. We created speaker-independent SER models using the eGeMAPS features, transformer-based models and their combination. We compared the results with reference databases and analyzed the influence of annotators and gender fairness. The pre-trained Unispeech-L model and its combination with eGeMAPS achieved the highest results, with 61.64% and 55.57% Unweighted Accuracy (UA) for 3-class valence and arousal prediction respectively, a 10% improvement over baseline models. For the emotion categories, 42.58% UA was obtained. EMOVOME performed lower than the acted RAVDESS database. The elicited IEMOCAP database also outperformed EMOVOME in the prediction of emotion categories, while similar results were obtained in valence and arousal. Additionally, EMOVOME outcomes varied with annotator labels, showing superior results and better fairness when combining expert and non-expert annotations. This study significantly contributes to the evaluation of SER models in real-life situations, advancing in the development of applications for analyzing spontaneous voice messages.\n    ",
        "primary_category": "eess.AS",
        "categories": [
            "cs.AI",
            "cs.CL",
            "cs.SD"
        ],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.02170": {
        "title": "VITAMIN: A Compositional Framework for Model Checking of Multi-Agent Systems",
        "authors": [
            "Angelo Ferrando",
            "Vadim Malvone"
        ],
        "comments": " ",
        "subjects": "Multiagent Systems (cs.MA)",
        "abstract": "The verification of Multi-Agent Systems (MAS) poses a significant challenge. Various approaches and methodologies exist to address this challenge; however, tools that support them are not always readily available. Even when such tools are accessible, they tend to be hard-coded, lacking in compositionality, and challenging to use due to a steep learning curve. In this paper, we introduce a methodology designed for the formal verification of MAS in a modular and versatile manner, along with an initial prototype, that we named VITAMIN. Unlike existing verification methodologies and frameworks for MAS, VITAMIN is constructed for easy extension to accommodate various logics (for specifying the properties to verify) and models (for determining on what to verify such properties).\n    ",
        "primary_category": "cs.MA",
        "categories": [
            "cs.LO",
            "cs.SE"
        ],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.02171": {
        "title": "Predicting large scale cosmological structure evolution with GAN-based autoencoders",
        "authors": [
            "Marion Ullmo",
            "Nabila Aghnim",
            "Aur\u00e9lien Decelle",
            "Miguel Aragon-Calvo"
        ],
        "comments": "11 pages, 11 figures",
        "subjects": "Cosmology and Nongalactic Astrophysics (astro-ph.CO)",
        "abstract": "Cosmological simulations play a key role in the prediction and understanding of large scale structure formation from initial conditions. We make use of GAN-based Autoencoders (AEs) in an attempt to predict structure evolution within simulations. The AEs are trained on images and cubes issued from respectively 2D and 3D N-body simulations describing the evolution of the dark matter (DM) field. We find that while the AEs can predict structure evolution for 2D simulations of DM fields well, using only the density fields as input, they perform significantly more poorly in similar conditions for 3D simulations. However, additionally providing velocity fields as inputs greatly improves results, with similar predictions regardless of time-difference between input and target.\n    ",
        "primary_category": "astro-ph.CO",
        "categories": [
            "cs.LG"
        ],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.02172": {
        "title": "Mirage: Defense against CrossPath Attacks in Software Defined Networks",
        "authors": [
            "Shariq Murtuza",
            "Krishna Asawa"
        ],
        "comments": " ",
        "subjects": "Cryptography and Security (cs.CR)",
        "abstract": "The Software-Defined Networks (SDNs) face persistent threats from various adversaries that attack them using different methods to mount Denial of Service attacks. These attackers have different motives and follow diverse tactics to achieve their nefarious objectives. In this work, we focus on the impact of CrossPath attacks in SDNs and introduce our framework, Mirage, which not only detects but also mitigates this attack. Our framework, Mirage, detects SDN switches that become unreachable due to being under attack, takes proactive measures to prevent Adversarial Path Reconnaissance, and effectively mitigates CrossPath attacks in SDNs. A CrossPath attack is a form of link flood attack that indirectly attacks the control plane by overwhelming the shared links that connect the data and control planes with data plane traffic. This attack is exclusive to in band SDN, where the data and the control plane, both utilize the same physical links for transmitting and receiving traffic. Our framework, Mirage, prevents attackers from launching adversarial path reconnaissance to identify shared links in a network, thereby thwarting their abuse and preventing this attack. Mirage not only stops adversarial path reconnaissance but also includes features to quickly counter ongoing attacks once detected. Mirage uses path diversity to reroute network packet to prevent timing based measurement. Mirage can also enforce short lived flow table rules to prevent timing attacks. These measures are carefully designed to enhance the security of the SDN environment. Moreover, we share the results of our experiments, which clearly show Mirage's effectiveness in preventing path reconnaissance, detecting CrossPath attacks, and mitigating ongoing threats. Our framework successfully protects the network from these harmful activities, giving valuable insights into SDN security.\n    ",
        "primary_category": "cs.CR",
        "categories": [],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.02173": {
        "title": "What has LeBenchmark Learnt about French Syntax?",
        "authors": [
            "Zdravko Dugonji\u0107",
            "Adrien Pupier",
            "Benjamin Lecouteux",
            "Maximin Coavoux"
        ],
        "comments": "Accepted to LREC-COLING 2024",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "The paper reports on a series of experiments aiming at probing LeBenchmark, a pretrained acoustic model trained on 7k hours of spoken French, for syntactic information. Pretrained acoustic models are increasingly used for downstream speech tasks such as automatic speech recognition, speech translation, spoken language understanding or speech parsing. They are trained on very low level information (the raw speech signal), and do not have explicit lexical knowledge. Despite that, they obtained reasonable results on tasks that requires higher level linguistic knowledge. As a result, an emerging question is whether these models encode syntactic information. We probe each representation layer of LeBenchmark for syntax, using the Orf\u00e9o treebank, and observe that it has learnt some syntactic information. Our results show that syntactic information is more easily extractable from the middle layers of the network, after which a very sharp decrease is observed.\n    ",
        "primary_category": "cs.CL",
        "categories": [],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.02176": {
        "title": "EEE-QA: Exploring Effective and Efficient Question-Answer Representations",
        "authors": [
            "Zhanghao Hu",
            "Yijun Yang",
            "Junjie Xu",
            "Yifu Qiu",
            "Pinzhen Chen"
        ],
        "comments": "LREC-COLING 2024",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "Current approaches to question answering rely on pre-trained language models (PLMs) like RoBERTa. This work challenges the existing question-answer encoding convention and explores finer representations. We begin with testing various pooling methods compared to using the begin-of-sentence token as a question representation for better quality. Next, we explore opportunities to simultaneously embed all answer candidates with the question. This enables cross-reference between answer choices and improves inference throughput via reduced memory usage. Despite their simplicity and effectiveness, these methods have yet to be widely studied in current frameworks. We experiment with different PLMs, and with and without the integration of knowledge graphs. Results prove that the memory efficacy of the proposed techniques with little sacrifice in performance. Practically, our work enhances 38-100% throughput with 26-65% speedups on consumer-grade GPUs by allowing for considerably larger batch sizes. Our work sends a message to the community with promising directions in both representation quality and efficiency for the question-answering task in natural language processing.\n    ",
        "primary_category": "cs.CL",
        "categories": [],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.02177": {
        "title": "ProTrix: Building Models for Planning and Reasoning over Tables with Sentence Context",
        "authors": [
            "Zirui Wu",
            "Yansong Feng"
        ],
        "comments": "under review",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "Tables play a crucial role in conveying information in various domains, serving as indispensable tools for organizing and presenting data in a structured manner. We propose a Plan-then-Reason framework to answer different types of user queries over tables with sentence context. The framework first plans the reasoning paths over the context, then assigns each step to program-based or textual reasoning to reach the final answer. We construct an instruction tuning set TrixInstruct following the framework. Our dataset cover queries that are program-unsolvable or need combining information from tables and sentences to obtain planning and reasoning abilities. We present ProTrix by finetuning Llama-2-7B on TrixInstruct. Our experiments show that ProTrix generalizes to diverse tabular tasks and achieves comparable performance to GPT-3.5-turbo. We further demonstrate that ProTrix can generate accurate and faithful explanations to answer complex free-form questions. Our work underscores the importance of the planning and reasoning abilities towards a model over tabular tasks with generalizability and interpretability. We will release our dataset and model at this https URL.\n    ",
        "primary_category": "cs.CL",
        "categories": [],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.02178": {
        "title": "Masked Thought: Simply Masking Partial Reasoning Steps Can Improve Mathematical Reasoning Learning of Language Models",
        "authors": [
            "Changyu Chen",
            "Xiting Wang",
            "Ting-En Lin",
            "Ang Lv",
            "Yuchuan Wu",
            "Xin Gao",
            "Ji-Rong Wen",
            "Rui Yan",
            "Yongbin Li"
        ],
        "comments": " ",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "In reasoning tasks, even a minor error can cascade into inaccurate results, leading to suboptimal performance of large language models in such domains. Earlier fine-tuning approaches sought to mitigate this by leveraging more precise supervisory signals from human labeling, larger models, or self-sampling, although at a high cost. Conversely, we develop a method that avoids external resources, relying instead on introducing perturbations to the input. Our training approach randomly masks certain tokens within the chain of thought, a technique we found to be particularly effective for reasoning tasks. When applied to fine-tuning with GSM8K, this method achieved a 5% improvement in accuracy over standard supervised fine-tuning with a few codes modified and no additional labeling effort. Furthermore, it is complementary to existing methods. When integrated with related data augmentation methods, it leads to an average improvement of 3% improvement in GSM8K accuracy and 1% improvement in MATH accuracy across five datasets of various quality and size, as well as two base models. We further investigate the mechanisms behind this improvement through case studies and quantitative analysis, suggesting that our approach may provide superior support for the model in capturing long-distance dependencies, especially those related to questions. This enhancement could deepen understanding of premises in questions and prior steps. Our code is available at Github.\n    ",
        "primary_category": "cs.CL",
        "categories": [
            "cs.AI",
            "cs.LG"
        ],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.02183": {
        "title": "Collective Allocator Abstraction to Control Object Spatial Locality in C++",
        "authors": [
            "Takato Hideshima",
            "Shigeyuki Sato",
            "Tomoharu Ugawa"
        ],
        "comments": " ",
        "subjects": "Programming Languages (cs.PL)",
        "abstract": "Disaggregated memory is promising for improving memory utilization in computer clusters in which memory demands significantly vary across computer nodes under utilization. It allows applications with high memory demands to use memory in other computer nodes.\nHowever, disaggregated memory is not easy to use for implementing data structures in C++ because the C++ standard does not provide an adequate abstraction to use it efficiently in a high-level, modular manner. Because accessing remote memory involves high latency, disaggregated memory is often used as a far-memory system, which forms a kind of swap memory where part of local memory is used as a cache area, while the remaining memory is not subject to swapping. To pursue performance, programmers have to be aware of this nonuniform memory view and place data appropriately to minimize swapping.\nIn this work, we model the address space of memory-disaggregated systems as the far-memory model, present the collective allocator abstraction, which enables us to specify object placement aware of memory address subspaces, and apply it to programming aware of the far-memory model.\nThe far-memory model provides a view of the nonuniform memory space while hiding the details. In the model, the virtual address space is divided into two subspaces; one is subject to swapping and the other is not. The swapping subspace is further divided into even-sized pages, which are units of swapping. The collective allocator abstraction forms an allocator as a collection of sub-allocators, each of which owns a distinct subspace, where every allocation is done via sub-allocators. It enables us to control object placement at allocation time by selecting an appropriate sub-allocator according to different criteria, such as subspace characteristics and object collocation. It greatly facilitates implementing container data structures aware of the far-memory model.\nWe develop an allocator based on the collective allocator abstraction by extending the C++ standard allocator for container data structures on the far-memory model and experimentally demonstrate that it facilitates implementing containers equipped with object placement strategies aware of spatial locality under the far-memory model in a high-level, modular manner. More specifically, we have successfully implemented B-trees and skip lists with the combined use of two placement strategies. The modifications therein for the original implementations are fairly modest: addition is mostly due to specifying object placement; deletion and modification are at most 1.2 % and 3.2 % of lines of the original code, respectively. We have experimentally confirmed that the modified implementations successfully have data layouts suppressing swapping.\nWe forecast that the collective allocator abstraction would be a key to high-level integration with different memory hardware technologies because it straightforwardly accommodates new interfaces for subspaces.\n    ",
        "primary_category": "cs.PL",
        "categories": [],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.02185": {
        "title": "Distilled ChatGPT Topic & Sentiment Modeling with Applications in Finance",
        "authors": [
            "Olivier Gandouet",
            "Mouloud Belbahri",
            "Armelle Jezequel",
            "Yuriy Bodjov"
        ],
        "comments": "Edge Intelligence Workshop at AAAI24",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "In this study, ChatGPT is utilized to create streamlined models that generate easily interpretable features. These features are then used to evaluate financial outcomes from earnings calls. We detail a training approach that merges knowledge distillation and transfer learning, resulting in lightweight topic and sentiment classification models without significant loss in accuracy. These models are assessed through a dataset annotated by experts. The paper also delves into two practical case studies, highlighting how the generated features can be effectively utilized in quantitative investing scenarios.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.CE",
            "cs.CL"
        ],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.02198": {
        "title": "Payment Scheduling in the Interval Debt Model",
        "authors": [
            "Tom Friedetzky",
            "David C. Kutner",
            "George B. Mertzios",
            "Iain A. Stewart",
            "Amitabh Trehan"
        ],
        "comments": "30 pages, 17 figures",
        "subjects": "Discrete Mathematics (cs.DM)",
        "abstract": "The network-based study of financial systems has received considerable attention in recent years but has seldom explicitly incorporated the dynamic aspects of such systems. We consider this problem setting from the temporal point of view and introduce the Interval Debt Model (IDM) and some scheduling problems based on it, namely: Bankruptcy Minimization/Maximization, in which the aim is to produce a payment schedule with at most/at least a given number of bankruptcies; Perfect Scheduling, the special case of the minimization variant where the aim is to produce a schedule with no bankruptcies (that is, a perfect schedule); and Bailout Minimization, in which a financial authority must allocate a smallest possible bailout package to enable a perfect schedule. We show that each of these problems is NP-complete, in many cases even on very restricted input instances. On the positive side, we provide for Perfect Scheduling a polynomial-time algorithm on (rooted) out-trees although in contrast we prove NP-completeness on directed acyclic graphs, as well as on instances with a constant number of nodes (and hence also constant treewidth). When we allow non-integer payments, we show by a linear programming argument that the problem Bailout Minimization can be solved in polynomial time.\n    ",
        "primary_category": "cs.DM",
        "categories": [
            "cs.CC",
            "cs.CE"
        ],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.02199": {
        "title": "Piet: Facilitating Color Authoring for Motion Graphics Video",
        "authors": [
            "Xinyu Shi",
            "Yinghou Wang",
            "Yun Wang",
            "Jian Zhao"
        ],
        "comments": "Accepted by CHI 2024",
        "subjects": "Human-Computer Interaction (cs.HC)",
        "abstract": "Motion graphic (MG) videos are effective and compelling for presenting complex concepts through animated visuals; and colors are important to convey desired emotions, maintain visual continuity, and signal narrative transitions. However, current video color authoring workflows are fragmented, lacking contextual previews, hindering rapid theme adjustments, and not aligning with progressive authoring flows of designers. To bridge this gap, we introduce Piet, the first tool tailored for MG video color authoring. Piet features an interactive palette to visually represent color distributions, support controllable focus levels, and enable quick theme probing via grouped color shifts. We interviewed 6 domain experts to identify the frustrations in current tools and inform the design of Piet. An in-lab user study with 13 expert designers showed that Piet effectively simplified the MG video color authoring and reduced the friction in creative color theme exploration.\n    ",
        "primary_category": "cs.HC",
        "categories": [],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.02200": {
        "title": "Scheduling Garbage Collection for Energy Efficiency on Asymmetric Multicore Processors",
        "authors": [
            "Marina Shimchenko",
            "Erik \u00d6sterlund",
            "Tobias Wrigstad"
        ],
        "comments": " ",
        "subjects": "Programming Languages (cs.PL)",
        "abstract": "The growing concern for energy efficiency in the Information and Communication Technology (ICT) sector has prompted the exploration of resource management techniques. While hardware architectures, such as single-ISA asymmetric multicore processors (AMP), offer potential energy savings, there is still untapped potential for software optimizations. This paper aims to bridge this gap by investigating the scheduling of garbage collection (GC) activities on a heterogeneous architecture with both performance cores (\"p-cores\") and energy cores (\"e-cores\") to achieve energy savings.\nOur study focuses on the concurrent ZGC collector in the context of Java Virtual Machines (JVM), as the energy aspect is not well studied in the context of latency-sensitive Java workloads. By comparing the energy efficiency, performance, latency, and memory utilization of executing GC on p-cores versus e-cores, we present compelling findings.\nWe demonstrate that scheduling GC work on e-cores overall leads to approximately 3% energy savings without performance and mean latency degradation while requiring no additional effort from developers. Overall energy reduction can increase to 5.3$\\pm$0.0225% by tuning the number of e-cores (still not changing the program!).\nOur findings highlight the practicality and benefits of scheduling GC on e-cores, showcasing the potential for energy savings in heterogeneous architectures running Java workloads while meeting critical latency requirements. Our research contributes to the ongoing efforts toward achieving a more sustainable and efficient ICT sector.\n    ",
        "primary_category": "cs.PL",
        "categories": [],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.02202": {
        "title": "Exploring Interactive Color Palettes for Abstraction-Driven Exploratory Image Colorization",
        "authors": [
            "Xinyu Shi",
            "Mingyu Liu",
            "Ziqi Zhou",
            "Ali Neshati",
            "Ryan Rossi",
            "Jian Zhao"
        ],
        "comments": "Accepted by CHI 2024",
        "subjects": "Human-Computer Interaction (cs.HC)",
        "abstract": "Color design is essential in areas such as product, graphic, and fashion design. However, current tools like Photoshop, with their concrete-driven color manipulation approach, often stumble during early ideation, favoring polished end results over initial exploration. We introduced Mondrian as a test-bed for abstraction-driven approach using interactive color palettes for image colorization. Through a formative study with six design experts, we selected three design options for visual abstractions in color design and developed Mondrian where humans work with abstractions and AI manages the concrete aspects. We carried out a user study to understand the benefits and challenges of each abstraction format and compare the Mondrian with Photoshop. A survey involving 100 participants further examined the influence of each abstraction format on color composition perceptions. Findings suggest that interactive visual abstractions encourage a non-linear exploration workflow and an open mindset during ideation, thus providing better creative affordance.\n    ",
        "primary_category": "cs.HC",
        "categories": [],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.02210": {
        "title": "Unknown Biases and Timing Constraints in Timed Automata",
        "authors": [
            "Darion Haase",
            "Joost-Pieter Katoen"
        ],
        "comments": " ",
        "subjects": "Logic in Computer Science (cs.LO)",
        "abstract": "Timed automata are the formal model for real-time systems. Extensions with discrete probabilistic branching have been considered in the literature and successfully applied. Probabilistic timed automata (PTA) do require all branching probabilities and clock constraints to be constants. This report investigates PTA in which this constraint is relaxed: both branching probabilities and clock constraints can be parametric. We formally define this PTA variant and define its semantics by an uncountable parametric Markov Decision Process (pMDP). We show that reachability probabilities in parametric L/U-PTA can be reduced to considering PTA with only parametric branching probabilities. This enables the usage of existing techniques from the literature. Finally, we generalize the symbolic backward and digital clock semantics of PTA to the setting with parametric probabilities and constraints.\n    ",
        "primary_category": "cs.LO",
        "categories": [
            "cs.FL"
        ],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.02211": {
        "title": "Perceptive self-supervised learning network for noisy image watermark removal",
        "authors": [
            "Chunwei Tian",
            "Menghua Zheng",
            "Bo Li",
            "Yanning Zhang",
            "Shichao Zhang",
            "David Zhang"
        ],
        "comments": " ",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Popular methods usually use a degradation model in a supervised way to learn a watermark removal model. However, it is true that reference images are difficult to obtain in the real world, as well as collected images by cameras suffer from noise. To overcome these drawbacks, we propose a perceptive self-supervised learning network for noisy image watermark removal (PSLNet) in this paper. PSLNet depends on a parallel network to remove noise and watermarks. The upper network uses task decomposition ideas to remove noise and watermarks in sequence. The lower network utilizes the degradation model idea to simultaneously remove noise and watermarks. Specifically, mentioned paired watermark images are obtained in a self supervised way, and paired noisy images (i.e., noisy and reference images) are obtained in a supervised way. To enhance the clarity of obtained images, interacting two sub-networks and fusing obtained clean images are used to improve the effects of image watermark removal in terms of structural information and pixel enhancement. Taking into texture information account, a mixed loss uses obtained images and features to achieve a robust model of noisy image watermark removal. Comprehensive experiments show that our proposed method is very effective in comparison with popular convolutional neural networks (CNNs) for noisy image watermark removal. Codes can be obtained at this https URL.\n    ",
        "primary_category": "cs.CV",
        "categories": [],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.02212": {
        "title": "Constraint Satisfaction Problems with Advice",
        "authors": [
            "Suprovat Ghoshal",
            "Konstantin Makarychev",
            "Yury Makarychev"
        ],
        "comments": " ",
        "subjects": "Data Structures and Algorithms (cs.DS)",
        "abstract": "We initiate the study of algorithms for constraint satisfaction problems with ML oracle advice. We introduce two models of advice and then design an approximation algorithm for Max Cut and Max 2-Lin in these models.\n    ",
        "primary_category": "cs.DS",
        "categories": [],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.02217": {
        "title": "DragTex: Generative Point-Based Texture Editing on 3D Mesh",
        "authors": [
            "Yudi Zhang",
            "Qi Xu",
            "Lei Zhang"
        ],
        "comments": " ",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Creating 3D textured meshes using generative artificial intelligence has garnered significant attention recently. While existing methods support text-based generative texture generation or editing on 3D meshes, they often struggle to precisely control pixels of texture images through more intuitive interaction. While 2D images can be edited generatively using drag interaction, applying this type of methods directly to 3D mesh textures still leads to issues such as the lack of local consistency among multiple views, error accumulation and long training times. To address these challenges, we propose a generative point-based 3D mesh texture editing method called DragTex. This method utilizes a diffusion model to blend locally inconsistent textures in the region near the deformed silhouette between different views, enabling locally consistent texture editing. Besides, we fine-tune a decoder to reduce reconstruction errors in the non-drag region, thereby mitigating overall error accumulation. Moreover, we train LoRA using multi-view images instead of training each view individually, which significantly shortens the training time. The experimental results show that our method effectively achieves dragging textures on 3D meshes and generates plausible textures that align with the desired intent of drag interaction.\n    ",
        "primary_category": "cs.CV",
        "categories": [],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.02220": {
        "title": "Emergence of Multivariate Extremes in Multilayer Inhomogeneous Random Graphs",
        "authors": [
            "Daniel Cirkovic",
            "Tiandong Wang",
            "Daren B.H. Cline"
        ],
        "comments": " ",
        "subjects": "Probability (math.PR)",
        "abstract": "In this paper, we propose a multilayer inhomogeneous random graph model (MIRG), whose layers may consist of both single-edge and multi-edge graphs. In the single layer case, it has been shown that the regular variation of the weight distribution underlying the inhomogeneous random graph implies the regular variation of the typical degree distribution. We extend this correspondence to the multilayer case by showing that the multivariate regular variation of the weight distribution implies the multivariate regular variation of the asymptotic degree distribution. Furthermore, in certain circumstances, the extremal dependence structure present in the weight distribution will be adopted by the asymptotic degree distribution. By considering the asymptotic degree distribution, a wider class of Chung-Lu and Norros-Reittu graphs may be incorporated into the MIRG layers. Additionally, we prove consistency of the Hill estimator when applied to degrees of the MIRG that have a tail index greater than 1. Simulation results indicate that, in practice, hidden regular variation may be consistently detected from an observed MIRG.\n    ",
        "primary_category": "math.PR",
        "categories": [
            "cs.SI",
            "math.ST",
            "physics.soc-ph"
        ],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.02225": {
        "title": "Building Trust in Data for IoT Systems",
        "authors": [
            "Davide Margaria",
            "Alberto Carelli",
            "Andrea Vesco"
        ],
        "comments": " ",
        "subjects": "Cryptography and Security (cs.CR)",
        "abstract": "Nowadays, Internet of Things platforms are being deployed in a wide range of application domains. Some of these include use cases with security requirements, where the data generated by an IoT node is the basis for making safety-critical or liability-critical decisions at system level. The challenge is to develop a solution for data exchange while proving and verifying the authenticity of the data from end-to-end. In line with this objective, this paper proposes a novel solution with the proper protocols to provide Trust in Data, making use of two Roots of Trust that are the IOTA Distributed Ledger Technology and the Trusted Platform Module. The paper presents the design of the proposed solution and discusses the key design aspects and relevant trade-offs. The paper concludes with a Proof-of-Concept implementation and an experimental evaluation to confirm its feasibility and to assess the achievable performance.\n    ",
        "primary_category": "cs.CR",
        "categories": [],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.02227": {
        "title": "Policy Space Response Oracles: A Survey",
        "authors": [
            "Ariyan Bighashdel",
            "Yongzhao Wang",
            "Stephen McAleer",
            "Rahul Savani",
            "Frans A. Oliehoek"
        ],
        "comments": "Ariyan Bighashdel and Yongzhao Wang contributed equally",
        "subjects": "Computer Science and Game Theory (cs.GT)",
        "abstract": "In game theory, a game refers to a model of interaction among rational decision-makers or players, making choices with the goal of achieving their individual objectives. Understanding their behavior in games is often referred to as game reasoning. This survey provides a comprehensive overview of a fast-developing game-reasoning framework for large games, known as Policy Space Response Oracles (PSRO). We first motivate PSRO, provide historical context, and position PSRO within game-reasoning approaches. We then focus on the strategy exploration issue for PSRO, the challenge of assembling an effective strategy portfolio for modeling the underlying game with minimum computational cost. We also survey current research directions for enhancing the efficiency of PSRO, and explore the applications of PSRO across various domains. We conclude by discussing open questions and future research.\n    ",
        "primary_category": "cs.GT",
        "categories": [
            "cs.AI",
            "cs.MA"
        ],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.02231": {
        "title": "CODE-ACCORD: A Corpus of Building Regulatory Data for Rule Generation towards Automatic Compliance Checking",
        "authors": [
            "Hansi Hettiarachchi",
            "Amna Dridi",
            "Mohamed Medhat Gaber",
            "Pouyan Parsafard",
            "Nicoleta Bocaneala",
            "Katja Breitenfelder",
            "Gon\u00e7al Costa",
            "Maria Hedblom",
            "Mihaela Juganaru-Mathieu",
            "Thamer Mecharnia",
            "Sumee Park",
            "He Tan",
            "Abdel-Rahman H. Tawil",
            "Edlira Vakaj"
        ],
        "comments": "This is a preprint of an article submitted to the Data in Brief Journal, Elsevier",
        "subjects": "Information Retrieval (cs.IR)",
        "abstract": "Automatic Compliance Checking (ACC) within the Architecture, Engineering, and Construction (AEC) sector necessitates automating the interpretation of building regulations to achieve its full potential. However, extracting information from textual rules to convert them to a machine-readable format has been a challenge due to the complexities associated with natural language and the limited resources that can support advanced machine-learning techniques. To address this challenge, we introduce CODE-ACCORD, a unique dataset compiled under the EU Horizon ACCORD project. CODE-ACCORD comprises 862 self-contained sentences extracted from the building regulations of England and Finland. Aligned with our core objective of facilitating information extraction from text for machine-readable rule generation, each sentence was annotated with entities and relations. Entities represent specific components such as \"window\" and \"smoke detectors\", while relations denote semantic associations between these entities, collectively capturing the conveyed ideas in natural language. We manually annotated all the sentences using a group of 12 annotators. Each sentence underwent annotations by multiple annotators and subsequently careful data curation to finalise annotations, ensuring their accuracy and reliability, thereby establishing the dataset as a solid ground truth. CODE-ACCORD offers a rich resource for diverse machine learning and natural language processing (NLP) related tasks in ACC, including text classification, entity recognition and relation extraction. To the best of our knowledge, this is the first entity and relation-annotated dataset in compliance checking, which is also publicly available.\n    ",
        "primary_category": "cs.IR",
        "categories": [],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.02233": {
        "title": "Transformers Provably Learn Feature-Position Correlations in Masked Image Modeling",
        "authors": [
            "Yu Huang",
            "Zixin Wen",
            "Yuejie Chi",
            "Yingbin Liang"
        ],
        "comments": "52 pages, 3 figures",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Masked image modeling (MIM), which predicts randomly masked patches from unmasked ones, has emerged as a promising approach in self-supervised vision pretraining. However, the theoretical understanding of MIM is rather limited, especially with the foundational architecture of transformers. In this paper, to the best of our knowledge, we provide the first end-to-end theory of learning one-layer transformers with softmax attention in MIM self-supervised pretraining. On the conceptual side, we posit a theoretical mechanism of how transformers, pretrained with MIM, produce empirically observed local and diverse attention patterns on data distributions with spatial structures that highlight feature-position correlations. On the technical side, our end-to-end analysis of the training dynamics of softmax-based transformers accommodates both input and position embeddings simultaneously, which is developed based on a novel approach to track the interplay between the attention of feature-position and position-wise correlations.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "math.OC",
            "stat.ML"
        ],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.02235": {
        "title": "Structure from WiFi (SfW): RSSI-based Geometric Mapping of Indoor Environments",
        "authors": [
            "Junseo Kim",
            "Jill Aghyourli Zalat",
            "Yeganeh Bahoo",
            "Sajad Saeedi"
        ],
        "comments": "Accepted at American Control Conference 2024",
        "subjects": "Robotics (cs.RO)",
        "abstract": "With the rising prominence of WiFi in common spaces, efforts have been made in the robotics community to take advantage of this fact by incorporating WiFi signal measurements in indoor SLAM (Simultaneous Localization and Mapping) systems. SLAM is essential in a wide range of applications, especially in the control of autonomous robots. This paper describes recent work in the development of WiFi-based localization and addresses the challenges currently faced in achieving WiFi-based geometric mapping. Inspired by the field of research into k-visibility, this paper presents the concept of inverse k-visibility and proposes a novel algorithm that allows robots to build a map of the free space of an unknown environment, essential for planning, navigation, and avoiding obstacles. Experiments performed in simulated and real-world environments demonstrate the effectiveness of the proposed algorithm.\n    ",
        "primary_category": "cs.RO",
        "categories": [],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.02236": {
        "title": "Interpretable Models for Detecting and Monitoring Elevated Intracranial Pressure",
        "authors": [
            "Darryl Hannan",
            "Steven C. Nesbit",
            "Ximing Wen",
            "Glen Smith",
            "Qiao Zhang",
            "Alberto Goffi",
            "Vincent Chan",
            "Michael J. Morris",
            "John C. Hunninghake",
            "Nicholas E. Villalobos",
            "Edward Kim",
            "Rosina O. Weber",
            "Christopher J. MacLellan"
        ],
        "comments": "5 pages, 2 figures, ISBI 2024",
        "subjects": "Image and Video Processing (eess.IV)",
        "abstract": "Detecting elevated intracranial pressure (ICP) is crucial in diagnosing and managing various neurological conditions. These fluctuations in pressure are transmitted to the optic nerve sheath (ONS), resulting in changes to its diameter, which can then be detected using ultrasound imaging devices. However, interpreting sonographic images of the ONS can be challenging. In this work, we propose two systems that actively monitor the ONS diameter throughout an ultrasound video and make a final prediction as to whether ICP is elevated. To construct our systems, we leverage subject matter expert (SME) guidance, structuring our processing pipeline according to their collection procedure, while also prioritizing interpretability and computational efficiency. We conduct a number of experiments, demonstrating that our proposed systems are able to outperform various baselines. One of our SMEs then manually validates our top system's performance, lending further credibility to our approach while demonstrating its potential utility in a clinical setting.\n    ",
        "primary_category": "eess.IV",
        "categories": [
            "cs.CV"
        ],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.02237": {
        "title": "Analytic continuations and numerical evaluation of the Appell $F_1$, $F_3$, Lauricella $F_D^{(3)}$ and Lauricella-Saran $F_S^{(3)}$ and their Application to Feynman Integrals",
        "authors": [
            "Souvik Bera",
            "Tanay Pathak"
        ],
        "comments": "25 pages, 1 figure, Repository see this https URL",
        "subjects": "High Energy Physics - Phenomenology (hep-ph)",
        "abstract": "We present our investigation of the study of two variable hypergeometric series, namely Appell $F_{1}$ and $F_{3}$ series, and obtain a comprehensive list of its analytic continuations enough to cover the whole real $(x,y)$ plane, except on their singular loci. We also derive analytic continuations of their 3-variable generalization, the Lauricella $F_{D}^{(3)}$ series and the Lauricella-Saran $F_{S}^{(3)}$ series, leveraging the analytic continuations of $F_{1}$ and $F_{3}$, which ensures that the whole real $(x,y,z)$ space is covered, except on the singular loci of these functions. While these studies are motivated by the frequent occurrence of these multivariable hypergeometric functions in Feynman integral evaluation, they can also be used whenever they appear in other branches of mathematical physics. To facilitate their practical use, we provide four packages: $\\texttt{AppellF1.wl}$, $\\texttt{AppellF3.wl}$, $\\texttt{LauricellaFD.wl}$, and $\\texttt{LauricellaSaranFS.wl}$ in $\\textit{MATHEMATICA}$. These packages are applicable for generic as well as non-generic values of parameters, keeping in mind their utilities in the evaluation of the Feynman integrals. We explicitly present various physical applications of these packages in the context of Feynman integral evaluation and compare the results using other means as well. Various $\\textit{MATHEMATICA}$ notebooks demonstrating different numerical results are also provided along with this paper.\n    ",
        "primary_category": "hep-ph",
        "categories": [
            "cs.MS",
            "hep-th",
            "math-ph"
        ],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.02238": {
        "title": "Towards Intent-Based Network Management: Large Language Models for Intent Extraction in 5G Core Networks",
        "authors": [
            "Dimitrios Michael Manias",
            "Ali Chouman",
            "Abdallah Shami"
        ],
        "comments": "Submitted to: International Conference on the Design of Reliable Communication Networks 2024",
        "subjects": "Networking and Internet Architecture (cs.NI)",
        "abstract": "The integration of Machine Learning and Artificial Intelligence (ML/AI) into fifth-generation (5G) networks has made evident the limitations of network intelligence with ever-increasing, strenuous requirements for current and next-generation devices. This transition to ubiquitous intelligence demands high connectivity, synchronicity, and end-to-end communication between users and network operators, and will pave the way towards full network automation without human intervention. Intent-based networking is a key factor in the reduction of human actions, roles, and responsibilities while shifting towards novel extraction and interpretation of automated network management. This paper presents the development of a custom Large Language Model (LLM) for 5G and next-generation intent-based networking and provides insights into future LLM developments and integrations to realize end-to-end intent-based networking for fully automated network intelligence.\n    ",
        "primary_category": "cs.NI",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.02243": {
        "title": "Better Schedules for Low Precision Training of Deep Neural Networks",
        "authors": [
            "Cameron R. Wolfe",
            "Anastasios Kyrillidis"
        ],
        "comments": "20 pages, 8 figures, 1 table, ACML 2023",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Low precision training can significantly reduce the computational overhead of training deep neural networks (DNNs). Though many such techniques exist, cyclic precision training (CPT), which dynamically adjusts precision throughout training according to a cyclic schedule, achieves particularly impressive improvements in training efficiency, while actually improving DNN performance. Existing CPT implementations take common learning rate schedules (e.g., cyclical cosine schedules) and use them for low precision training without adequate comparisons to alternative scheduling options. We define a diverse suite of CPT schedules and analyze their performance across a variety of DNN training regimes, some of which are unexplored in the low precision training literature (e.g., node classification with graph neural networks). From these experiments, we discover alternative CPT schedules that offer further improvements in training efficiency and model performance, as well as derive a set of best practices for choosing CPT schedules. Going further, we find that a correlation exists between model performance and training cost, and that changing the underlying CPT schedule can control the tradeoff between these two variables. To explain the direct correlation between model performance and training cost, we draw a connection between quantized training and critical learning periods, suggesting that aggressive quantization is a form of learning impairment that can permanently damage model performance.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.02247": {
        "title": "Birbal: An efficient 7B instruct-model fine-tuned with curated datasets",
        "authors": [
            "Ashvini Kumar Jindal",
            "Pawan Kumar Rajpoot",
            "Ankur Parikh"
        ],
        "comments": " ",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "LLMOps incur significant costs due to hardware requirements, hindering their widespread accessibility. Additionally, a lack of transparency in model training methods and data contributes to the majority of models being non-reproducible. To tackle these challenges, the LLM Efficiency Challenge was introduced at NeurIPS Workshop, aiming to adapt foundation models on a diverse set of tasks via fine-tuning on a single GPU (RTX 4090 or A100 with 40GB) within a 24-hour timeframe. In this system description paper, we introduce Birbal, our Mistral-7B based winning model, fine-tuned on a single RTX 4090 for 16 hours. Birbal's success lies in curating high-quality instructions covering diverse tasks, resulting in a 35% performance improvement over second-best Qwen-14B based submission.\n    ",
        "primary_category": "cs.CL",
        "categories": [],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.02249": {
        "title": "Non-autoregressive Sequence-to-Sequence Vision-Language Models",
        "authors": [
            "Kunyu Shi",
            "Qi Dong",
            "Luis Goncalves",
            "Zhuowen Tu",
            "Stefano Soatto"
        ],
        "comments": "Accepted to CVPR 2024",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Sequence-to-sequence vision-language models are showing promise, but their applicability is limited by their inference latency due to their autoregressive way of generating predictions. We propose a parallel decoding sequence-to-sequence vision-language model, trained with a Query-CTC loss, that marginalizes over multiple inference paths in the decoder. This allows us to model the joint distribution of tokens, rather than restricting to conditional distribution as in an autoregressive model. The resulting model, NARVL, achieves performance on-par with its state-of-the-art autoregressive counterpart, but is faster at inference time, reducing from the linear complexity associated with the sequential generation of tokens to a paradigm of constant time joint inference.\n    ",
        "primary_category": "cs.CV",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.02251": {
        "title": "A prediction rigidity formalism for low-cost uncertainties in trained neural networks",
        "authors": [
            "Filippo Bigi",
            "Sanggyu Chong",
            "Michele Ceriotti",
            "Federico Grasselli"
        ],
        "comments": " ",
        "subjects": "Machine Learning (stat.ML)",
        "abstract": "Regression methods are fundamental for scientific and technological applications. However, fitted models can be highly unreliable outside of their training domain, and hence the quantification of their uncertainty is crucial in many of their applications. Based on the solution of a constrained optimization problem, we propose \"prediction rigidities\" as a method to obtain uncertainties of arbitrary pre-trained regressors. We establish a strong connection between our framework and Bayesian inference, and we develop a last-layer approximation that allows the new method to be applied to neural networks. This extension affords cheap uncertainties without any modification to the neural network itself or its training procedure. We show the effectiveness of our method on a wide range of regression tasks, ranging from simple toy models to applications in chemistry and meteorology.\n    ",
        "primary_category": "stat.ML",
        "categories": [
            "cs.LG"
        ],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.02253": {
        "title": "KnowPhish: Large Language Models Meet Multimodal Knowledge Graphs for Enhancing Reference-Based Phishing Detection",
        "authors": [
            "Yuexin Li",
            "Chengyu Huang",
            "Shumin Deng",
            "Mei Lin Lock",
            "Tri Cao",
            "Nay Oo",
            "Bryan Hooi",
            "Hoon Wei Lim"
        ],
        "comments": " ",
        "subjects": "Cryptography and Security (cs.CR)",
        "abstract": "Phishing attacks have inflicted substantial losses on individuals and businesses alike, necessitating the development of robust and efficient automated phishing detection approaches. Reference-based phishing detectors (RBPDs), which compare the logos on a target webpage to a known set of logos, have emerged as the state-of-the-art approach. However, a major limitation of existing RBPDs is that they rely on a manually constructed brand knowledge base, making it infeasible to scale to a large number of brands, which results in false negative errors due to the insufficient brand coverage of the knowledge base. To address this issue, we propose an automated knowledge collection pipeline, using which we collect and release a large-scale multimodal brand knowledge base, KnowPhish, containing 20k brands with rich information about each brand. KnowPhish can be used to boost the performance of existing RBPDs in a plug-and-play manner. A second limitation of existing RBPDs is that they solely rely on the image modality, ignoring useful textual information present in the webpage HTML. To utilize this textual information, we propose a Large Language Model (LLM)-based approach to extract brand information of webpages from text. Our resulting multimodal phishing detection approach, KnowPhish Detector (KPD), can detect phishing webpages with or without logos. We evaluate KnowPhish and KPD on a manually validated dataset, and on a field study under Singapore's local context, showing substantial improvements in effectiveness and efficiency compared to state-of-the-art baselines.\n    ",
        "primary_category": "cs.CR",
        "categories": [
            "cs.AI",
            "cs.CL",
            "cs.LG"
        ],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.02254": {
        "title": "Probabilistic Fault-Tolerant Robust Traffic Grooming in OTN-over-DWDM Networks",
        "authors": [
            "Dimitrios Michael Manias",
            "Joe Naoum-Sawaya",
            "Abbas Javadtalab",
            "Abdallah Shami"
        ],
        "comments": "Submitted to: International Conference on the Design of Reliable Communication Networks 2024",
        "subjects": "Networking and Internet Architecture (cs.NI)",
        "abstract": "The development of next-generation networks is revolutionizing network operators' management and orchestration practices worldwide. The critical services supported by these networks require increasingly stringent performance requirements, especially when considering the aspect of network reliability. This increase in reliability, coupled with the mass generation and consumption of information stemming from the increasing complexity of the network and the integration of artificial intelligence agents, affects transport networks, which will be required to allow the feasibility of such services to materialize. To this end, traditional recovery schemes are inadequate to ensure the resilience requirements of next-generation critical services given the increasingly dynamic nature of the network. The work presented in this paper proposes a probabilistic and fault-tolerant robust traffic grooming model for OTN-over-DWDM networks. The model's parameterization gives network operators the ability to control the level of protection and reliability required to meet their quality of service and service level agreement guarantees. The results demonstrate that the robust solution can ensure fault tolerance even in the face of demand uncertainty without service disruptions and the need for reactive network maintenance.\n    ",
        "primary_category": "cs.NI",
        "categories": [],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.02255": {
        "title": "Astronomy in Colombia: a bibliometric perspective",
        "authors": [
            "Sof\u00eda Guevara-Montoya",
            "Felipe Ortiz-Ferreira",
            "Mar\u00eda Paula Silva-Ar\u00e9valo",
            "Paola A. Ni\u00f1o-Mu\u00f1oz",
            "Jaime E. Forero-Romero"
        ],
        "comments": "34 pages, in Spanish language, 7 figures, 7 tables. Submitted to the Revista de la Academia Colombiana de Ciencias Exactas, F\u00edsicas y Naturales (ACCEFYN). Texto en espa\u00f1ol",
        "subjects": "Digital Libraries (cs.DL)",
        "abstract": "In Colombia, astronomical research is experiencing accelerated growth. In order to better understand its evolution and current state, we conducted a bibliometric study using data from the Astrophysics Data System (ADS) and Web of Science (WoS). In ADS, we identified 422 peer-reviewed publications from 1980, the year of the first publication, until 2023, which was the cutoff date for our study. Among the 25 Colombian institutions identified as participants in at least one publication, the contributions of four universities stand out: Universidad de los Andes, Universidad Nacional de Colombia, Universidad Industrial de Santander, and Universidad de Antioquia, with 104, 78, 68, and 67 publications, respectively. By cross-referencing information from ADS and WoS, we found that the areas with the greatest impact in publications are threefold: high-energy and fundamental physics, stars and stellar physics, and galaxies and cosmology. Globally, according to WoS, Colombia ranks 52nd in the number of peer-reviewed publications between 2019 and 2023, and fifth in Latin America. Additionally, we identified three highly cited publications (top 1% worldwide) belonging to the field of observational cosmology. When analyzing countries with equal or greater bibliographic production, we estimate that Colombian production is approximately four times lower than expected considering its population and GDP.\n    ",
        "primary_category": "cs.DL",
        "categories": [
            "astro-ph.IM"
        ],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.02259": {
        "title": "Human-AI Collaboration Increases Skill Tagging Speed but Degrades Accuracy",
        "authors": [
            "Cheng Ren",
            "Zachary Pardos",
            "Zhi Li"
        ],
        "comments": " ",
        "subjects": "Human-Computer Interaction (cs.HC)",
        "abstract": "AI approaches are progressing besting humans at game-related tasks (e.g. chess). The next stage is expected to be Human-AI collaboration; however, the research on this subject has been mixed and is in need of additional data points. We add to this nascent literature by studying Human-AI collaboration on a common administrative educational task. Education is a special domain in its relation to AI and has been slow to adopt AI approaches in practice, concerned with the educational enterprise losing its humanistic touch and because standard of quality is demanded because of the impact on a person's career and developmental trajectory. In this study (N = 22), we design an experiment to explore the effect of Human-AI collaboration on the task of tagging educational content with skills from the US common core taxonomy. Our results show that the experiment group (with AI recommendations) saved around 50% time (p < 0.01) in the execution of their tagging task but at the sacrifice of 7.7% recall (p = 0.267) and 35% accuracy (p= 0.1170) compared with the non-AI involved control group, placing the AI+human group in between the AI alone (lowest performance) and the human alone (highest performance). We further analyze log data from this AI collaboration experiment to explore under what circumstances humans still exercised their discernment when receiving recommendations. Finally, we outline how this study can assist in implementing AI tools, like ChatGPT, in education.\n    ",
        "primary_category": "cs.HC",
        "categories": [],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.02265": {
        "title": "DaReNeRF: Direction-aware Representation for Dynamic Scenes",
        "authors": [
            "Ange Lou",
            "Benjamin Planche",
            "Zhongpai Gao",
            "Yamin Li",
            "Tianyu Luan",
            "Hao Ding",
            "Terrence Chen",
            "Jack Noble",
            "Ziyan Wu"
        ],
        "comments": "Accepted at CVPR 2024. Paper + supplementary material",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Addressing the intricate challenge of modeling and re-rendering dynamic scenes, most recent approaches have sought to simplify these complexities using plane-based explicit representations, overcoming the slow training time issues associated with methods like Neural Radiance Fields (NeRF) and implicit representations. However, the straightforward decomposition of 4D dynamic scenes into multiple 2D plane-based representations proves insufficient for re-rendering high-fidelity scenes with complex motions. In response, we present a novel direction-aware representation (DaRe) approach that captures scene dynamics from six different directions. This learned representation undergoes an inverse dual-tree complex wavelet transformation (DTCWT) to recover plane-based information. DaReNeRF computes features for each space-time point by fusing vectors from these recovered planes. Combining DaReNeRF with a tiny MLP for color regression and leveraging volume rendering in training yield state-of-the-art performance in novel view synthesis for complex dynamic scenes. Notably, to address redundancy introduced by the six real and six imaginary direction-aware wavelet coefficients, we introduce a trainable masking approach, mitigating storage issues without significant performance decline. Moreover, DaReNeRF maintains a 2x reduction in training time compared to prior art while delivering superior performance.\n    ",
        "primary_category": "cs.CV",
        "categories": [
            "cs.GR"
        ],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.02268": {
        "title": "Subjective $\\textit{Isms}$? On the Danger of Conflating Hate and Offence in Abusive Language Detection",
        "authors": [
            "Amanda Cercas Curry",
            "Gavin Abercrombie",
            "Zeerak Talat"
        ],
        "comments": " ",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "Natural language processing research has begun to embrace the notion of annotator subjectivity, motivated by variations in labelling. This approach understands each annotator's view as valid, which can be highly suitable for tasks that embed subjectivity, e.g., sentiment analysis. However, this construction may be inappropriate for tasks such as hate speech detection, as it affords equal validity to all positions on e.g., sexism or racism. We argue that the conflation of hate and offence can invalidate findings on hate speech, and call for future work to be situated in theory, disentangling hate from its orthogonal concept, offence.\n    ",
        "primary_category": "cs.CL",
        "categories": [
            "cs.AI",
            "cs.CY"
        ],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.02271": {
        "title": "RIFF: Learning to Rephrase Inputs for Few-shot Fine-tuning of Language Models",
        "authors": [
            "Saeed Najafi",
            "Alona Fyshe"
        ],
        "comments": "Version Submitted to ACL2024. Review Discussion here: this https URL",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "Pre-trained Language Models (PLMs) can be accurately fine-tuned for downstream text processing tasks. Recently, researchers have introduced several parameter-efficient fine-tuning methods that optimize input prompts or adjust a small number of model parameters (e.g LoRA). In this study, we explore the impact of altering the input text of the original task in conjunction with parameter-efficient fine-tuning methods. To most effectively rewrite the input text, we train a few-shot paraphrase model with a Maximum-Marginal Likelihood objective. Using six few-shot text classification datasets, we show that enriching data with paraphrases at train and test time enhances the performance beyond what can be achieved with parameter-efficient fine-tuning alone.\n    ",
        "primary_category": "cs.CL",
        "categories": [
            "cs.LG"
        ],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.02273": {
        "title": "Let a Thousand Flowers Bloom: An Algebraic Representation for Edge Graphs",
        "authors": [
            "Jack Liell-Cock",
            "Tom Schrijvers"
        ],
        "comments": " ",
        "subjects": "Programming Languages (cs.PL)",
        "abstract": "Context: Edge graphs are graphs whose edges are labelled with identifiers, and nodes can have multiple edges between them. They are used to model a wide range of systems, including networks with distances or degrees of connection and complex relational data.\nInquiry: Unfortunately, the homogeneity of this graph structure prevents an effective representation in (functional) programs. Either their interface is riddled with partial functions, or the representations are computationally inefficient to process.\nApproach: We present a novel data type for edge graphs, based on total and recursive definitions, that prevents usage errors from partial APIs and promotes structurally recursive computations. We follow an algebraic approach and provide a set of primitive constructors and combinators, along with equational laws that identify semantically equivalent constructions.\nKnowledge: This algebra translates directly into an implementation using algebraic data types, and its homomorphisms give rise to functions for manipulating and transforming these edge graphs.\nGrounding: We exploit the fact that many common graph algorithms are such homomorphisms to implement them in our framework.\nImportance: In giving a theoretical grounding for the edge graph data type, we can formalise properties such as soundness and completeness of the representation while also minimising usage errors and maximising re-usability.\n    ",
        "primary_category": "cs.PL",
        "categories": [],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.02274": {
        "title": "NatSGD: A Dataset with Speech, Gestures, and Demonstrations for Robot Learning in Natural Human-Robot Interaction",
        "authors": [
            "Snehesh Shrestha",
            "Yantian Zha",
            "Saketh Banagiri",
            "Ge Gao",
            "Yiannis Aloimonos",
            "Cornelia Fermuller"
        ],
        "comments": " ",
        "subjects": "Robotics (cs.RO)",
        "abstract": "Recent advancements in multimodal Human-Robot Interaction (HRI) datasets have highlighted the fusion of speech and gesture, expanding robots' capabilities to absorb explicit and implicit HRI insights. However, existing speech-gesture HRI datasets often focus on elementary tasks, like object pointing and pushing, revealing limitations in scaling to intricate domains and prioritizing human command data over robot behavior records. To bridge these gaps, we introduce NatSGD, a multimodal HRI dataset encompassing human commands through speech and gestures that are natural, synchronized with robot behavior demonstrations. NatSGD serves as a foundational resource at the intersection of machine learning and HRI research, and we demonstrate its effectiveness in training robots to understand tasks through multimodal human commands, emphasizing the significance of jointly considering speech and gestures. We have released our dataset, simulator, and code to facilitate future research in human-robot interaction system learning; access these resources at this https URL\n",
        "primary_category": "cs.RO",
        "categories": [
            "cs.LG"
        ],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.02275": {
        "title": "Bounded Depth Frege Lower Bounds for Random 3-CNFs via Deterministic Restrictions",
        "authors": [
            "Svyatoslav Gryaznov",
            "Navid Talebanfard"
        ],
        "comments": " ",
        "subjects": "Computational Complexity (cs.CC)",
        "abstract": "A major open problem in proof complexity is to show that random 3-CNFs with linear number of clauses require super-polynomial size refutations in bounded depth Frege. We make a first step towards this question by showing a super-linear lower bound: for every $k$, there exists $\\epsilon > 0$ such that any depth-$k$ Frege refutation of a random $n$-variable 3-CNF with $\\Theta(n)$ clauses has $\\Omega(n^{1 + \\epsilon})$ steps w.h.p. Our proof involves a novel adaptation of the deterministic restriction technique of Chaudhuri and Radhakrishnan (STOC'96).\n    ",
        "primary_category": "cs.CC",
        "categories": [],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.02280": {
        "title": "Tightly-Coupled LiDAR-Visual-Inertial SLAM and Large-Scale Volumetric Occupancy Mapping",
        "authors": [
            "Simon Boche",
            "Sebasti\u00e1n Barbas Laina",
            "Stefan Leutenegger"
        ],
        "comments": "IEEE International Conference on Robotics and Automation (ICRA) 2024",
        "subjects": "Robotics (cs.RO)",
        "abstract": "Autonomous navigation is one of the key requirements for every potential application of mobile robots in the real-world. Besides high-accuracy state estimation, a suitable and globally consistent representation of the 3D environment is indispensable. We present a fully tightly-coupled LiDAR-Visual-Inertial SLAM system and 3D mapping framework applying local submapping strategies to achieve scalability to large-scale environments. A novel and correspondence-free, inherently probabilistic, formulation of LiDAR residuals is introduced, expressed only in terms of the occupancy fields and its respective gradients. These residuals can be added to a factor graph optimisation problem, either as frame-to-map factors for the live estimates or as map-to-map factors aligning the submaps with respect to one another. Experimental validation demonstrates that the approach achieves state-of-the-art pose accuracy and furthermore produces globally consistent volumetric occupancy submaps which can be directly used in downstream tasks such as navigation or exploration.\n    ",
        "primary_category": "cs.RO",
        "categories": [],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.02281": {
        "title": "Emotion Granularity from Text: An Aggregate-Level Indicator of Mental Health",
        "authors": [
            "Krishnapriya Vishnubhotla",
            "Daniela Teodorescu",
            "Mallory J. Feldman",
            "Kristen A. Lindquist",
            "Saif M. Mohammad"
        ],
        "comments": "9 pages plus appendices",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "We are united in how emotions are central to shaping our experiences; and yet, individuals differ greatly in how we each identify, categorize, and express emotions. In psychology, variation in the ability of individuals to differentiate between emotion concepts is called emotion granularity (determined through self-reports of one's emotions). High emotion granularity has been linked with better mental and physical health; whereas low emotion granularity has been linked with maladaptive emotion regulation strategies and poor health outcomes. In this work, we propose computational measures of emotion granularity derived from temporally-ordered speaker utterances in social media (in lieu of self-reports that suffer from various biases). We then investigate the effectiveness of such text-derived measures of emotion granularity in functioning as markers of various mental health conditions (MHCs). We establish baseline measures of emotion granularity derived from textual utterances, and show that, at an aggregate level, emotion granularities are significantly lower for people self-reporting as having an MHC than for the control population. This paves the way towards a better understanding of the MHCs, and specifically the role emotions play in our well-being.\n    ",
        "primary_category": "cs.CL",
        "categories": [],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.02284": {
        "title": "Graphical Quadratic Algebra",
        "authors": [
            "Dario Stein",
            "Fabio Zanasi",
            "Richard Samuelson",
            "Robin Piedeleu"
        ],
        "comments": " ",
        "subjects": "Logic in Computer Science (cs.LO)",
        "abstract": "We introduce Graphical Quadratic Algebra (GQA), a string diagrammatic calculus extending the language of Graphical Affine Algebra with a new generator characterised by invariance under rotation matrices. We show that GQA is a sound and complete axiomatisation for three different models: quadratic relations, which are a compositional formalism for least-squares problems, Gaussian stochastic processes, and Gaussian stochastic processes extended with non-determinisms. The equational theory of GQA sheds light on the connections between these perspectives, giving an algebraic interpretation to the interplay of stochastic behaviour, relational behaviour, non-determinism, and conditioning. As applications, we discuss various case studies, including linear regression, probabilistic programming, and electrical circuits with realistic (noisy) components.\n    ",
        "primary_category": "cs.LO",
        "categories": [
            "math.CT",
            "math.OC"
        ],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.02285": {
        "title": "Detection of Non-recorded Word Senses in English and Swedish",
        "authors": [
            "Jonathan Lautenschlager",
            "Emma Sk\u00f6ldberg",
            "Simon Hengchen",
            "Dominik Schlechtweg"
        ],
        "comments": "9 pages",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "This study addresses the task of Unknown Sense Detection in English and Swedish. The primary objective of this task is to determine whether the meaning of a particular word usage is documented in a dictionary or not. For this purpose, sense entries are compared with word usages from modern and historical corpora using a pre-trained Word-in-Context embedder that allows us to model this task in a few-shot scenario. Additionally, we use human annotations to adapt and evaluate our models. Compared to a random sample from a corpus, our model is able to considerably increase the detected number of word usages with non-recorded senses.\n    ",
        "primary_category": "cs.CL",
        "categories": [],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.02286": {
        "title": "Stage: Query Execution Time Prediction in Amazon Redshift",
        "authors": [
            "Ziniu Wu",
            "Ryan Marcus",
            "Zhengchun Liu",
            "Parimarjan Negi",
            "Vikram Nathan",
            "Pascal Pfeil",
            "Gaurav Saxena",
            "Mohammad Rahman",
            "Balakrishnan Narayanaswamy",
            "Tim Kraska"
        ],
        "comments": "15 pages",
        "subjects": "Databases (cs.DB)",
        "abstract": "Query performance (e.g., execution time) prediction is a critical component of modern DBMSes. As a pioneering cloud data warehouse, Amazon Redshift relies on an accurate execution time prediction for many downstream tasks, ranging from high-level optimizations, such as automatically creating materialized views, to low-level tasks on the critical path of query execution, such as admission, scheduling, and execution resource control. Unfortunately, many existing execution time prediction techniques, including those used in Redshift, suffer from cold start issues, inaccurate estimation, and are not robust against workload/data changes.\nIn this paper, we propose a novel hierarchical execution time predictor: the Stage predictor. The Stage predictor is designed to leverage the unique characteristics and challenges faced by Redshift. The Stage predictor consists of three model states: an execution time cache, a lightweight local model optimized for a specific DB instance with uncertainty measurement, and a complex global model that is transferable across all instances in Redshift. We design a systematic approach to use these models that best leverages optimality (cache), instance-optimization (local model), and transferable knowledge about Redshift (global model). Experimentally, we show that the Stage predictor makes more accurate and robust predictions while maintaining a practical inference latency and memory overhead. Overall, the Stage predictor can improve the average query execution latency by $20\\%$ on these instances compared to the prior query performance predictor in Redshift.\n    ",
        "primary_category": "cs.DB",
        "categories": [],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.02290": {
        "title": "Koopman-Assisted Reinforcement Learning",
        "authors": [
            "Preston Rozwood",
            "Edward Mehrez",
            "Ludger Paehler",
            "Wen Sun",
            "Steven L. Brunton"
        ],
        "comments": "35 pages, 12 figures",
        "subjects": "Artificial Intelligence (cs.AI)",
        "abstract": "The Bellman equation and its continuous form, the Hamilton-Jacobi-Bellman (HJB) equation, are ubiquitous in reinforcement learning (RL) and control theory. However, these equations quickly become intractable for systems with high-dimensional states and nonlinearity. This paper explores the connection between the data-driven Koopman operator and Markov Decision Processes (MDPs), resulting in the development of two new RL algorithms to address these limitations. We leverage Koopman operator techniques to lift a nonlinear system into new coordinates where the dynamics become approximately linear, and where HJB-based methods are more tractable. In particular, the Koopman operator is able to capture the expectation of the time evolution of the value function of a given system via linear dynamics in the lifted coordinates. By parameterizing the Koopman operator with the control actions, we construct a ``Koopman tensor'' that facilitates the estimation of the optimal value function. Then, a transformation of Bellman's framework in terms of the Koopman tensor enables us to reformulate two max-entropy RL algorithms: soft value iteration and soft actor-critic (SAC). This highly flexible framework can be used for deterministic or stochastic systems as well as for discrete or continuous-time dynamics. Finally, we show that these Koopman Assisted Reinforcement Learning (KARL) algorithms attain state-of-the-art (SOTA) performance with respect to traditional neural network-based SAC and linear quadratic regulator (LQR) baselines on four controlled dynamical systems: a linear state-space system, the Lorenz system, fluid flow past a cylinder, and a double-well potential with non-isotropic stochastic forcing.\n    ",
        "primary_category": "cs.AI",
        "categories": [
            "cs.LG",
            "math.DS",
            "math.OC"
        ],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.02296": {
        "title": "Reactive Programming without Functions",
        "authors": [
            "Bjarno Oeyen",
            "Joeri De Koster",
            "Wolfgang De Meuter"
        ],
        "comments": " ",
        "subjects": "Programming Languages (cs.PL)",
        "abstract": "Context: Reactive programming (RP) is a declarative programming paradigm suitable for expressing the handling of events. It enables programmers to create applications that react automatically to changes over time. Whenever a time-varying signal changes -- e.g. in response to values produced by event stream (e.g., sensor data, user input...) -- the program state is updated automatically in tandem with that change. This makes RP well-suited for building interactive applications and reactive (soft real-time) systems.\nInquiry: RP Language implementations are often built on top of an existing (host) language as an Embedded Domain Specific Language (EDSL). This results in application code in which reactive code and non-reactive code is inherently entangled. Using a mechanism known as lifting, one usually has access to the full feature set of the (non-reactive) host language in the RP program. However, lifting is also dangerous. First, host code expressed in a Turing-complete language may diverge, resulting in unresponsive programs: i.e. reactive programs that are not actually reactive. Second, the bi-directional integration of reactive and non-reactive code results in a paradigmatic mismatch that, when unchecked, leads to faulty behaviour in programs.\nApproach: We propose a new reactive programming language, that has been meticulously designed to be reactive-only. We start with a simple (first-order) model for reactivity, based on reactors (i.e. uninstantiated descriptions of signals and their dependencies) and deployments (i.e. instances of reactors) that consist of signals. The language does not have the notion of functions, and thus unlike other RP languages there is no lifting either. We extend this simple model incrementally with additional features found in other programming languages, RP or otherwise. These features include stateful reactors (that allow for time-based accumulation), signals with dynamic dependencies by means of conditionals and polymorphic deployments, recursively-defined reactors, and (anonymous) reactors with lexical scope.\nKnowledge: In our description of these language features, we not only describe the syntax and semantics, but also how each features compares to the problems that exist in (EDSL) RP languages. I.e. by starting from a reactive-only model, we identify which reactive features (that, in other RP languages are typically expressed in non-reactive code) affect the reactive guarantees that can be enforced by the language.\nGrounding: We base our arguments by analysing the effect that each feature has on our language: e.g., by analysing how signals are updated, how they are created and how dependencies between signals can be affected. When applicable, we draw parallels with other languages: i.e. similarities shared with other RP languages will be highlighted and thoroughly analysed, and where relevant the same will also be done with non-reactive languages.\nImportance: Our language shows how a purely reactive programming is able to express the same kinds of programs as in other RP languages that require the use of (unchecked) functions. By considering reactive programs as a collection of pure (reactive-only) reactors, we aim to increase how reactive programming is comprehended by both language designers and its users.\n    ",
        "primary_category": "cs.PL",
        "categories": [],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.02297": {
        "title": "Uncertainty-Aware Prediction and Application in Planning for Autonomous Driving: Definitions, Methods, and Comparison",
        "authors": [
            "Wenbo Shao",
            "Jiahui Xu",
            "Zhong Cao",
            "Hong Wang",
            "Jun Li"
        ],
        "comments": "14 pages, 7 figures",
        "subjects": "Robotics (cs.RO)",
        "abstract": "Autonomous driving systems face the formidable challenge of navigating intricate and dynamic environments with uncertainty. This study presents a unified prediction and planning framework that concurrently models short-term aleatoric uncertainty (SAU), long-term aleatoric uncertainty (LAU), and epistemic uncertainty (EU) to predict and establish a robust foundation for planning in dynamic contexts. The framework uses Gaussian mixture models and deep ensemble methods, to concurrently capture and assess SAU, LAU, and EU, where traditional methods do not integrate these uncertainties simultaneously. Additionally, uncertainty-aware planning is introduced, considering various uncertainties. The study's contributions include comparisons of uncertainty estimations, risk modeling, and planning methods in comparison to existing approaches. The proposed methods were rigorously evaluated using the CommonRoad benchmark and settings with limited perception. These experiments illuminated the advantages and roles of different uncertainty factors in autonomous driving processes. In addition, comparative assessments of various uncertainty modeling strategies underscore the benefits of modeling multiple types of uncertainties, thus enhancing planning accuracy and reliability. The proposed framework facilitates the development of methods for UAP and surpasses existing uncertainty-aware risk models, particularly when considering diverse traffic scenarios. Project page: this https URL.\n    ",
        "primary_category": "cs.RO",
        "categories": [],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.02298": {
        "title": "Minimum acyclic number and maximum dichromatic number of oriented triangle-free graphs of a given order",
        "authors": [
            "Pierre Aboulker",
            "Fr\u00e9d\u00e9ric Havet",
            "Fran\u00e7ois Pirot",
            "Juliette Schabanel"
        ],
        "comments": "19 pages, 5 figures",
        "subjects": "Combinatorics (math.CO)",
        "abstract": "Let $D$ be a digraph. Its acyclic number $\\vec{\\alpha}(D)$ is the maximum order of an acyclic induced subdigraph and its dichromatic number $\\vec{\\chi}(D)$ is the least integer $k$ such that $V(D)$ can be partitioned into $k$ subsets inducing acyclic subdigraphs. We study ${\\vec a}(n)$ and $\\vec t(n)$ which are the minimum of $\\vec\\alpha(D)$ and the maximum of $\\vec{\\chi}(D)$, respectively, over all oriented triangle-free graphs of order $n$. For every $\\epsilon>0$ and $n$ large enough, we show $(1/\\sqrt{2} - \\epsilon) \\sqrt{n\\log n} \\leq \\vec{a}(n) \\leq \\frac{107}{8} \\sqrt n \\log n$ and $\\frac{8}{107} \\sqrt n/\\log n \\leq \\vec{t}(n) \\leq (\\sqrt 2 + \\epsilon) \\sqrt{n/\\log n}$. We also construct an oriented triangle-free graph on 25 vertices with dichromatic number~3, and show that every oriented triangle-free graph of order at most 17 has dichromatic number at most 2.\n    ",
        "primary_category": "math.CO",
        "categories": [
            "cs.DM"
        ],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.02300": {
        "title": "Statistical Query Lower Bounds for Learning Truncated Gaussians",
        "authors": [
            "Ilias Diakonikolas",
            "Daniel M. Kane",
            "Thanasis Pittas",
            "Nikos Zarifis"
        ],
        "comments": " ",
        "subjects": "Data Structures and Algorithms (cs.DS)",
        "abstract": "We study the problem of estimating the mean of an identity covariance Gaussian in the truncated setting, in the regime when the truncation set comes from a low-complexity family $\\mathcal{C}$ of sets. Specifically, for a fixed but unknown truncation set $S \\subseteq \\mathbb{R}^d$, we are given access to samples from the distribution $\\mathcal{N}(\\boldsymbol{ \\mu}, \\mathbf{ I})$ truncated to the set $S$. The goal is to estimate $\\boldsymbol\\mu$ within accuracy $\\epsilon>0$ in $\\ell_2$-norm. Our main result is a Statistical Query (SQ) lower bound suggesting a super-polynomial information-computation gap for this task. In more detail, we show that the complexity of any SQ algorithm for this problem is $d^{\\mathrm{poly}(1/\\epsilon)}$, even when the class $\\mathcal{C}$ is simple so that $\\mathrm{poly}(d/\\epsilon)$ samples information-theoretically suffice. Concretely, our SQ lower bound applies when $\\mathcal{C}$ is a union of a bounded number of rectangles whose VC dimension and Gaussian surface are small. As a corollary of our construction, it also follows that the complexity of the previously known algorithm for this task is qualitatively best possible.\n    ",
        "primary_category": "cs.DS",
        "categories": [
            "cs.LG",
            "math.ST",
            "stat.ML"
        ],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.02307": {
        "title": "Harnessing Intra-group Variations Via a Population-Level Context for Pathology Detection",
        "authors": [
            "P. Bilha Githinji",
            "Xi Yuan",
            "Zhenglin Chen",
            "Ijaz Gul",
            "Dingqi Shang",
            "Wen Liang",
            "Jianming Deng",
            "Dan Zeng",
            "Dongmei yu",
            "Chenggang Yan",
            "Peiwu Qin"
        ],
        "comments": " ",
        "subjects": "Image and Video Processing (eess.IV)",
        "abstract": "Realizing sufficient separability between the distributions of healthy and pathological samples is a critical obstacle for pathology detection convolutional models. Moreover, these models exhibit a bias for contrast-based images, with diminished performance on texture-based medical images. This study introduces the notion of a population-level context for pathology detection and employs a graph theoretic approach to model and incorporate it into the latent code of an autoencoder via a refinement module we term PopuSense. PopuSense seeks to capture additional intra-group variations inherent in biomedical data that a local or global context of the convolutional model might miss or smooth out. Experiments on contrast-based and texture-based images, with minimal adaptation, encounter the existing preference for intensity-based input. Nevertheless, PopuSense demonstrates improved separability in contrast-based images, presenting an additional avenue for refining representations learned by a model.\n    ",
        "primary_category": "eess.IV",
        "categories": [
            "cs.CV"
        ],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.02310": {
        "title": "Taming Throughput-Latency Tradeoff in LLM Inference with Sarathi-Serve",
        "authors": [
            "Amey Agrawal",
            "Nitin Kedia",
            "Ashish Panwar",
            "Jayashree Mohan",
            "Nipun Kwatra",
            "Bhargav S. Gulavani",
            "Alexey Tumanov",
            "Ramachandran Ramjee"
        ],
        "comments": " ",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Each LLM serving request goes through two phases. The first is prefill which processes the entire input prompt to produce one output token and the second is decode which generates the rest of output tokens, one-at-a-time. Prefill iterations have high latency but saturate GPU compute due to parallel processing of the input prompt. In contrast, decode iterations have low latency but also low compute utilization because a decode iteration processes only a single token per request. This makes batching highly effective for decodes and consequently for overall throughput. However, batching multiple requests leads to an interleaving of prefill and decode iterations which makes it challenging to achieve both high throughput and low latency.\nWe introduce an efficient LLM inference scheduler Sarathi-Serve inspired by the techniques we originally proposed for optimizing throughput in Sarathi. Sarathi-Serve leverages chunked-prefills from Sarathi to create stall-free schedules that can add new requests in a batch without pausing ongoing decodes. Stall-free scheduling unlocks the opportunity to improve throughput with large batch sizes while minimizing the effect of batching on latency. Our evaluation shows that Sarathi-Serve improves serving throughput within desired latency SLOs of Mistral-7B by up to 2.6x on a single A100 GPU and up to 6.9x for Falcon-180B on 8 A100 GPUs over Orca and vLLM.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.DC"
        ],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.02311": {
        "title": "Bayesian Uncertainty Estimation by Hamiltonian Monte Carlo: Applications to Cardiac MRI Segmentation",
        "authors": [
            "Yidong Zhao",
            "Joao Tourais",
            "Iain Pierce",
            "Christian Nitsche",
            "Thomas A. Treibel",
            "Sebastian Weing\u00e4rtner",
            "Artur M. Schweidtmann",
            "Qian Tao"
        ],
        "comments": " ",
        "subjects": "Image and Video Processing (eess.IV)",
        "abstract": "Deep learning (DL)-based methods have achieved state-of-the-art performance for a wide range of medical image segmentation tasks. Nevertheless, recent studies show that deep neural networks (DNNs) can be miscalibrated and overconfident, leading to \"silent failures\" that are risky} for clinical applications. Bayesian statistics provide an intuitive approach to DL failure detection, based on posterior probability estimation. However, Bayesian DL, and in particular the posterior estimation, is intractable for large medical image segmentation DNNs. To tackle this challenge, we propose a Bayesian learning framework by Hamiltonian Monte Carlo (HMC), tempered by cold posterior (CP) to accommodate medical data augmentation, named HMC-CP. For HMC computation, we further propose a cyclical annealing strategy, which captures both local and global geometries of the posterior distribution, enabling highly efficient Bayesian DNN training with the same computational budget requirements as training a single DNN. The resulting Bayesian DNN outputs an ensemble segmentation along with the segmentation uncertainty. We evaluate the proposed HMC-CP extensively on cardiac magnetic resonance image (MRI) segmentation, using in-domain steady-state free precession (SSFP) cine images as well as out-of-domain datasets of quantitative $T_1$ and $T_2$ mapping.\n    ",
        "primary_category": "eess.IV",
        "categories": [
            "cs.CV"
        ],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.02317": {
        "title": "Contract Design for Pandora's Box",
        "authors": [
            "Martin Hoefer",
            "Conrad Schecker",
            "Kevin Schewior"
        ],
        "comments": " ",
        "subjects": "Computer Science and Game Theory (cs.GT)",
        "abstract": "We study a natural application of contract design to search problems with probabilistic prior and exploration costs. These problems have a plethora of applications and are expressed concisely within the Pandora's Box model. Its optimal solution is the ingenious index policy proposed originally by Weitzman in 1979.\nIn our principal-agent setting, the search task is delegated to an agent. The agent performs a sequential exploration of $n$ boxes, suffers the exploration cost for each inspected box, and selects the content (called the prize) of one inspected box as outcome. Agent and principal obtain an individual value based on the selected prize. To influence the search, the principal a-priori designs a contract with a non-negative payment to the agent for each potential prize. The goal of the principal to maximize her expected reward, i.e., value minus payment. We show how to compute optimal contracts for the principal in several scenarios.\nA popular and important subclass are linear contracts, and we show how to compute optimal linear contracts in polynomial time. For general contracts, we consider the standard assumption that the agent suffers cost but obtains value only from the transfers by the principal. Interestingly, a suitable adaptation of the index policy results in an optimal contract here. More generally, for general contracts with non-zero agent values for outcomes we show how to compute an optimal contract in two cases: (1) when each box has only one prize with non-zero value for principal and agent, (2) for i.i.d. boxes with a single prize with positive value for the principal. These results show that optimal contracts can be highly non-trivial, and their design goes significantly beyond the application or re-interpretation of the index policy.\n    ",
        "primary_category": "cs.GT",
        "categories": [
            "cs.DS"
        ],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.02325": {
        "title": "Contrastive Region Guidance: Improving Grounding in Vision-Language Models without Training",
        "authors": [
            "David Wan",
            "Jaemin Cho",
            "Elias Stengel-Eskin",
            "Mohit Bansal"
        ],
        "comments": "Project website: this https URL",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Highlighting particularly relevant regions of an image can improve the performance of vision-language models (VLMs) on various vision-language (VL) tasks by guiding the model to attend more closely to these regions of interest. For example, VLMs can be given a \"visual prompt\", where visual markers such as bounding boxes delineate key image regions. However, current VLMs that can incorporate visual guidance are either proprietary and expensive or require costly training on curated data that includes visual prompts. We introduce Contrastive Region Guidance (CRG), a training-free guidance method that enables open-source VLMs to respond to visual prompts. CRG contrasts model outputs produced with and without visual prompts, factoring out biases revealed by the model when answering without the information required to produce a correct answer (i.e., the model's prior). CRG achieves substantial improvements in a wide variety of VL tasks: When region annotations are provided, CRG increases absolute accuracy by up to 11.1% on ViP-Bench, a collection of six diverse region-based tasks such as recognition, math, and object relationship reasoning. We also show CRG's applicability to spatial reasoning, with 10% improvement on What'sUp, as well as to compositional generalization -- improving accuracy by 11.5% and 7.5% on two challenging splits from SugarCrepe -- and to image-text alignment for generated images, where we improve by up to 8.4 AUROC and 6.8 F1 points on SeeTRUE. When reference regions are absent, CRG allows us to re-rank proposed regions in referring expression comprehension and phrase grounding benchmarks like RefCOCO/+/g and Flickr30K Entities, with an average gain of 3.2% in accuracy. Our analysis explores alternative masking strategies for CRG, quantifies CRG's probability shift, and evaluates the role of region guidance strength, empirically validating CRG's design choices.\n    ",
        "primary_category": "cs.CV",
        "categories": [
            "cs.AI",
            "cs.CL",
            "cs.LG"
        ],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.02327": {
        "title": "Model Lakes",
        "authors": [
            "Koyena Pal",
            "David Bau",
            "Ren\u00e9e J. Miller"
        ],
        "comments": " ",
        "subjects": "Databases (cs.DB)",
        "abstract": "Given a set of deep learning models, it can be hard to find models appropriate to a task, understand the models, and characterize how models are different one from another. Currently, practitioners rely on manually-written documentation to understand and choose models. However, not all models have complete and reliable documentation. As the number of machine learning models increases, this issue of finding, differentiating, and understanding models is becoming more crucial. Inspired from research on data lakes, we introduce and define the concept of model lakes. We discuss fundamental research challenges in the management of large models. And we discuss what principled data management techniques can be brought to bear on the study of large model management.\n    ",
        "primary_category": "cs.DB",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.02329": {
        "title": "COMMIT: Certifying Robustness of Multi-Sensor Fusion Systems against Semantic Attacks",
        "authors": [
            "Zijian Huang",
            "Wenda Chu",
            "Linyi Li",
            "Chejian Xu",
            "Bo Li"
        ],
        "comments": " ",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Multi-sensor fusion systems (MSFs) play a vital role as the perception module in modern autonomous vehicles (AVs). Therefore, ensuring their robustness against common and realistic adversarial semantic transformations, such as rotation and shifting in the physical world, is crucial for the safety of AVs. While empirical evidence suggests that MSFs exhibit improved robustness compared to single-modal models, they are still vulnerable to adversarial semantic transformations. Despite the proposal of empirical defenses, several works show that these defenses can be attacked again by new adaptive attacks. So far, there is no certified defense proposed for MSFs. In this work, we propose the first robustness certification framework COMMIT certify robustness of multi-sensor fusion systems against semantic attacks. In particular, we propose a practical anisotropic noise mechanism that leverages randomized smoothing with multi-modal data and performs a grid-based splitting method to characterize complex semantic transformations. We also propose efficient algorithms to compute the certification in terms of object detection accuracy and IoU for large-scale MSF models. Empirically, we evaluate the efficacy of COMMIT in different settings and provide a comprehensive benchmark of certified robustness for different MSF models using the CARLA simulation platform. We show that the certification for MSF models is at most 48.39% higher than that of single-modal models, which validates the advantages of MSF models. We believe our certification framework and benchmark will contribute an important step towards certifiably robust AVs in practice.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.CR",
            "cs.CV"
        ],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.02330": {
        "title": "RegionGPT: Towards Region Understanding Vision Language Model",
        "authors": [
            "Qiushan Guo",
            "Shalini De Mello",
            "Hongxu Yin",
            "Wonmin Byeon",
            "Ka Chun Cheung",
            "Yizhou Yu",
            "Ping Luo",
            "Sifei Liu"
        ],
        "comments": "Accepted by CVPR 2024",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Vision language models (VLMs) have experienced rapid advancements through the integration of large language models (LLMs) with image-text pairs, yet they struggle with detailed regional visual understanding due to limited spatial awareness of the vision encoder, and the use of coarse-grained training data that lacks detailed, region-specific captions. To address this, we introduce RegionGPT (short as RGPT), a novel framework designed for complex region-level captioning and understanding. RGPT enhances the spatial awareness of regional representation with simple yet effective modifications to existing visual encoders in VLMs. We further improve performance on tasks requiring a specific output scope by integrating task-guided instruction prompts during both training and inference phases, while maintaining the model's versatility for general-purpose tasks. Additionally, we develop an automated region caption data generation pipeline, enriching the training set with detailed region-level captions. We demonstrate that a universal RGPT model can be effectively applied and significantly enhancing performance across a range of region-level tasks, including but not limited to complex region descriptions, reasoning, object classification, and referring expressions comprehension.\n    ",
        "primary_category": "cs.CV",
        "categories": [],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.02334": {
        "title": "Gradient Correlation Subspace Learning against Catastrophic Forgetting",
        "authors": [
            "Tammuz Dubnov",
            "Vishal Thengane"
        ],
        "comments": "5 figures; Code will be available here: this https URL",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Efficient continual learning techniques have been a topic of significant research over the last few years. A fundamental problem with such learning is severe degradation of performance on previously learned tasks, known also as catastrophic forgetting. This paper introduces a novel method to reduce catastrophic forgetting in the context of incremental class learning called Gradient Correlation Subspace Learning (GCSL). The method detects a subspace of the weights that is least affected by previous tasks and projects the weights to train for the new task into said subspace. The method can be applied to one or more layers of a given network architectures and the size of the subspace used can be altered from layer to layer and task to task. Code will be available at \\href{this https URL}{this https URL}\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.AI",
            "cs.CV"
        ],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.02336": {
        "title": "Brand Visibility in Packaging: A Deep Learning Approach for Logo Detection, Saliency-Map Prediction, and Logo Placement Analysis",
        "authors": [
            "Alireza Hosseini",
            "Kiana Hooshanfar",
            "Pouria Omrani",
            "Reza Toosi",
            "Ramin Toosi",
            "Zahra Ebrahimian",
            "Mohammad Ali Akhaee"
        ],
        "comments": " ",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "In the highly competitive area of product marketing, the visibility of brand logos on packaging plays a crucial role in shaping consumer perception, directly influencing the success of the product. This paper introduces a comprehensive framework to measure the brand logo's attention on a packaging design. The proposed method consists of three steps. The first step leverages YOLOv8 for precise logo detection across prominent datasets, FoodLogoDet-1500 and LogoDet-3K. The second step involves modeling the user's visual attention with a novel saliency prediction model tailored for the packaging context. The proposed saliency model combines the visual elements with text maps employing a transformers-based architecture to predict user attention maps. In the third step, by integrating logo detection with a saliency map generation, the framework provides a comprehensive brand attention score. The effectiveness of the proposed method is assessed module by module, ensuring a thorough evaluation of each component. Comparing logo detection and saliency map prediction with state-of-the-art models shows the superiority of the proposed methods. To investigate the robustness of the proposed brand attention score, we collected a unique dataset to examine previous psychophysical hypotheses related to brand visibility. the results show that the brand attention score is in line with all previous studies. Also, we introduced seven new hypotheses to check the impact of position, orientation, presence of person, and other visual elements on brand attention. This research marks a significant stride in the intersection of cognitive psychology, computer vision, and marketing, paving the way for advanced, consumer-centric packaging designs.\n    ",
        "primary_category": "cs.CV",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.02338": {
        "title": "Twisting Lids Off with Two Hands",
        "authors": [
            "Toru Lin",
            "Zhao-Heng Yin",
            "Haozhi Qi",
            "Pieter Abbeel",
            "Jitendra Malik"
        ],
        "comments": "Project page can be found at this https URL",
        "subjects": "Robotics (cs.RO)",
        "abstract": "Manipulating objects with two multi-fingered hands has been a long-standing challenge in robotics, attributed to the contact-rich nature of many manipulation tasks and the complexity inherent in coordinating a high-dimensional bimanual system. In this work, we consider the problem of twisting lids of various bottle-like objects with two hands, and demonstrate that policies trained in simulation using deep reinforcement learning can be effectively transferred to the real world. With novel engineering insights into physical modeling, real-time perception, and reward design, the policy demonstrates generalization capabilities across a diverse set of unseen objects, showcasing dynamic and dexterous behaviors. Our findings serve as compelling evidence that deep reinforcement learning combined with sim-to-real transfer remains a promising approach for addressing manipulation problems of unprecedented complexity.\n    ",
        "primary_category": "cs.RO",
        "categories": [
            "cs.AI",
            "cs.CV",
            "cs.LG"
        ],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    },
    "2403.02339": {
        "title": "Exploring Well-Posedness and Asymptotic Behavior in an Advection-Diffusion-Reaction (ADR) Model",
        "authors": [
            "Mohammed Elghandouri",
            "Khalil Ezzinbi",
            "Lamiae Saidi"
        ],
        "comments": " ",
        "subjects": "Analysis of PDEs (math.AP)",
        "abstract": "In this paper, the existence, uniqueness, and positivity of solutions, as well as the asymptotic behavior through a finite fractal dimensional global attractor for a general Advection-Diffusion-Reaction (ADR) equation, are investigated. Our findings are innovative, as we employ semigroups and global attractors theories to achieve these results. Also, an analytical solution of a two-dimensional Advection-Diffusion Equation is presented. And finally, two Explicit Finite Difference schemes are used to simulate solutions in the two- and three-dimensional cases. The numerical simulations are conducted with predefined initial and Dirichlet boundary conditions.\n    ",
        "primary_category": "math.AP",
        "categories": [
            "math.DS",
            "math.NA"
        ],
        "submitted_date": "4 Mar 2024",
        "last_revised_date": " "
    }
}