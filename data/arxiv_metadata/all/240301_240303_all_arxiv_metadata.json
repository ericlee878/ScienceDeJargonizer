{
    "1505.02681": {
        "title": "Socio-Spatial Group Queries for Impromptu Activity Planning",
        "authors": [
            "Chih-Ya Shen",
            "De-Nian Yang",
            "Liang-Hao Huang",
            "Wang-Chien Lee",
            "Ming-Syan Chen"
        ],
        "comments": " ",
        "subjects": "Data Structures and Algorithms (cs.DS)",
        "abstract": "The development and integration of social networking services and smartphones have made it easy for individuals to organize impromptu social activities anywhere and anytime. Main challenges arising in organizing impromptu activities are mostly due to the requirements of making timely invitations in accordance with the potential activity locations, corresponding to the locations of and the relationship among the candidate attendees. Various combinations of candidate attendees and activity locations create a large solution space. Thus, in this paper, we propose Multiple Rally-Point Social Spatial Group Query (MRGQ), to select an appropriate activity location for a group of nearby attendees with tight social relationships. Although MRGQ is NP-hard, the number of attendees in practice is usually small enough such that an optimal solution can be found efficiently. Therefore, we first propose an Integer Linear Programming optimization model for MRGQ. We then design an efficient algorithm, called MAGS, which employs effective search space exploration and pruning strategies to reduce the running time for finding the optimal solution. We also propose to further optimize efficiency by indexing the potential activity locations. A user study demonstrates the strength of using MAGS over manual coordination in terms of both solution quality and efficiency. Experimental results on real datasets show that our algorithms can process MRGQ efficiently and significantly outperform other baseline algorithms, including one based on the commercial parallel optimizer IBM CPLEX.\n    ",
        "primary_category": "cs.DS",
        "categories": [
            "cs.DB"
        ],
        "submitted_date": "11 May 2015",
        "last_revised_date": " "
    },
    "1806.05451": {
        "title": "The committee machine: Computational to statistical gaps in learning a two-layers neural network",
        "authors": [
            "Benjamin Aubin",
            "Antoine Maillard",
            "Jean Barbier",
            "Florent Krzakala",
            "Nicolas Macris",
            "Lenka Zdeborov\u00e1"
        ],
        "comments": "18 pages + supplementary material, 3 figures. (v2: update to match the published version ; v3: clarification of the caption of Fig. 3)",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Heuristic tools from statistical physics have been used in the past to locate the phase transitions and compute the optimal learning and generalization errors in the teacher-student scenario in multi-layer neural networks. In this contribution, we provide a rigorous justification of these approaches for a two-layers neural network model called the committee machine. We also introduce a version of the approximate message passing (AMP) algorithm for the committee machine that allows to perform optimal learning in polynomial time for a large set of parameters. We find that there are regimes in which a low generalization error is information-theoretically achievable while the AMP algorithm fails to deliver it, strongly suggesting that no efficient algorithm exists for those cases, and unveiling a large computational gap.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cond-mat.dis-nn",
            "cond-mat.stat-mech",
            "physics.comp-ph",
            "stat.ML"
        ],
        "submitted_date": "14 Jun 2018",
        "last_revised_date": " "
    },
    "1911.08756": {
        "title": "Classification with Costly Features in Hierarchical Deep Sets",
        "authors": [
            "Jarom\u00edr Janisch",
            "Tom\u00e1\u0161 Pevn\u00fd",
            "Viliam Lis\u00fd"
        ],
        "comments": "formerly Hierarchical Multiple-Instance Data Classification with Costly Features; RL4RealLife @ ICML2021; code available at this https URL",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Classification with Costly Features (CwCF) is a classification problem that includes the cost of features in the optimization criteria. Individually for each sample, its features are sequentially acquired to maximize accuracy while minimizing the acquired features' cost. However, existing approaches can only process data that can be expressed as vectors of fixed length. In real life, the data often possesses rich and complex structure, which can be more precisely described with formats such as XML or JSON. The data is hierarchical and often contains nested lists of objects. In this work, we extend an existing deep reinforcement learning-based algorithm with hierarchical deep sets and hierarchical softmax, so that it can directly process this data. The extended method has greater control over which features it can acquire and, in experiments with seven datasets, we show that this leads to superior performance. To showcase the real usage of the new method, we apply it to a real-life problem of classifying malicious web domains, using an online service.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.AI",
            "stat.ML"
        ],
        "submitted_date": "20 Nov 2019",
        "last_revised_date": " "
    },
    "2002.12438": {
        "title": "Almost Public Quantum Coins",
        "authors": [
            "Amit Behera",
            "Or Sattath"
        ],
        "comments": " ",
        "subjects": "Quantum Physics (quant-ph)",
        "abstract": "In a quantum money scheme, a bank can issue money that users cannot counterfeit. Similar to bills of paper money, most quantum money schemes assign a unique serial number to each money state, thus potentially compromising the privacy of the users of quantum money. However in a quantum coins scheme, just like the traditional currency coin scheme, all the money states are exact copies of each other, providing a better level of privacy for the users. A quantum money scheme can be private, i.e., only the bank can verify the money states, or public, meaning anyone can verify. In this work, we propose a way to lift any private quantum coin scheme -- which is known to exist based on the existence of one-way functions, due to Ji, Liu, and Song (CRYPTO'18) -- to a scheme that closely resembles a public quantum coin scheme. Verification of a new coin is done by comparing it to the coins the user already possesses, by using a projector on to the symmetric subspace. No public coin scheme was known prior to this work. It is also the first construction that is very close to a public quantum money scheme and is provably secure based on standard assumptions. Finally, the lifting technique, when instantiated with the private quantum coins scheme~\\cite{MS10}, gives rise to the first construction that is close to an inefficient unconditionally secure public quantum money scheme.\n    ",
        "primary_category": "quant-ph",
        "categories": [
            "cs.CR"
        ],
        "submitted_date": "27 Feb 2020",
        "last_revised_date": " "
    },
    "2006.10628": {
        "title": "Offline detection of change-points in the mean for stationary graph signals",
        "authors": [
            "Alejandro de la Concha",
            "Nicolas Vayatis",
            "Argyris Kalogeratos"
        ],
        "comments": "16 pages, 2 figures, 1 table, 1 annex. 9 pages of main text",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "This paper addresses the problem of segmenting a stream of graph signals: we aim to detect changes in the mean of a multivariate signal defined over the nodes of a known graph. We propose an offline method that relies on the concept of graph signal stationarity and allows the convenient translation of the problem from the original vertex domain to the spectral domain (Graph Fourier Transform), where it is much easier to solve. Although the obtained spectral representation is sparse in real applications, to the best of our knowledge this property has not been sufficiently exploited in the existing related literature. Our change-point detection method adopts a model selection approach that takes into account the sparsity of the spectral representation and determines automatically the number of change-points. Our detector comes with a proof of a non-asymptotic oracle inequality. Numerical experiments demonstrate the performance of the proposed method.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "stat.AP",
            "stat.ML"
        ],
        "submitted_date": "18 Jun 2020",
        "last_revised_date": " "
    },
    "2106.10479": {
        "title": "Practical Transferability Estimation for Image Classification Tasks",
        "authors": [
            "Yang Tan",
            "Yang Li",
            "Shao-Lun Huang"
        ],
        "comments": "This paper is not the latest version. Please refer to Transferability-Guided Cross-Domain Cross-Task Transfer Learning (IEEE TNNLS'24) for more details.this https URL",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Transferability estimation is an essential problem in transfer learning to predict how good the performance is when transferring a source model (or source task) to a target task. Recent analytical transferability metrics have been widely used for source model selection and multi-task learning. A major challenge is how to make transfereability estimation robust under the cross-domain cross-task settings. The recently proposed OTCE score solves this problem by considering both domain and task differences, with the help of transfer experiences on auxiliary tasks, which causes an efficiency overhead. In this work, we propose a practical transferability metric called JC-NCE score that dramatically improves the robustness of the task difference estimation in OTCE, thus removing the need for auxiliary tasks. Specifically, we build the joint correspondences between source and target data via solving an optimal transport problem with a ground cost considering both the sample distance and label distance, and then compute the transferability score as the negative conditional entropy of the matched labels. Extensive validations under the intra-dataset and inter-dataset transfer settings demonstrate that our JC-NCE score outperforms the auxiliary-task free version of OTCE for 7% and 12%, respectively, and is also more robust than other existing transferability metrics on average.\n    ",
        "primary_category": "cs.CV",
        "categories": [
            "cs.AI",
            "cs.LG"
        ],
        "submitted_date": "19 Jun 2021",
        "last_revised_date": " "
    },
    "2106.14969": {
        "title": "Hop-Constrained Metric Embeddings and their Applications",
        "authors": [
            "Arnold Filtser"
        ],
        "comments": " ",
        "subjects": "Data Structures and Algorithms (cs.DS)",
        "abstract": "In network design problems, such as compact routing, the goal is to route packets between nodes using the (approximated) shortest paths. A desirable property of these routes is a small number of hops, which makes them more reliable, and reduces the transmission costs. Following the overwhelming success of stochastic tree embeddings for algorithmic design, Haeupler, Hershkowitz, and Zuzic (STOC'21) studied hop-constrained Ramsey-type metric embeddings into trees. Specifically, embedding $f:G(V,E)\\rightarrow T$ has Ramsey hop-distortion $(t,M,\\beta,h)$ (here $t,\\beta,h\\ge1$ and $M\\subseteq V$) if $\\forall u,v\\in M$, $d_G^{(\\beta\\cdot h)}(u,v)\\le d_T(u,v)\\le t\\cdot d_G^{(h)}(u,v)$. $t$ is called the distortion, $\\beta$ is called the hop-stretch, and $d_G^{(h)}(u,v)$ denotes the minimum weight of a $u-v$ path with at most $h$ hops. Haeupler {\\em et al.} constructed embedding where $M$ contains $1-\\epsilon$ fraction of the vertices and $\\beta=t=O(\\frac{\\log^2 n}{\\epsilon})$. They used their embedding to obtain multiple bicriteria approximation algorithms for hop-constrained network design problems.\nIn this paper, we first improve the Ramsey-type embedding to obtain parameters $t=\\beta=\\frac{\\tilde{O}(\\log n)}{\\epsilon}$, and generalize it to arbitrary distortion parameter $t$ (in the cost of reducing the size of $M$). This embedding immediately implies polynomial improvements for all the approximation algorithms from Haeupler {\\em et al.}. Further, we construct hop-constrained clan embeddings (where each vertex has multiple copies), and use them to construct bicriteria approximation algorithms for the group Steiner tree problem, matching the state of the art of the non constrained version. Finally, we use our embedding results to construct hop constrained distance oracles, distance labeling, and most prominently, the first hop constrained compact routing scheme with provable guarantees.\n    ",
        "primary_category": "cs.DS",
        "categories": [
            "cs.DM"
        ],
        "submitted_date": "28 Jun 2021",
        "last_revised_date": " "
    },
    "2107.02270": {
        "title": "Accessible Color Sequences for Data Visualization",
        "authors": [
            "Matthew A. Petroff"
        ],
        "comments": "26 pages, 4 figures, 4 tables; comments welcome",
        "subjects": "Graphics (cs.GR)",
        "abstract": "Color sequences, ordered sets of colors for data visualization, that balance aesthetics with accessibility considerations are presented. In order to model aesthetic preference, data were collected with an online survey, and the results were used to train a machine-learning model. To ensure accessibility, this model was combined with minimum-perceptual-distance constraints, including for simulated color-vision deficiencies, as well as with minimum-lightness-distance constraints for grayscale printing, maximum-lightness constraints for maintaining contrast with a white background, and scores from a color-saliency model for ease of use of the colors in verbal and written descriptions. Optimal color sequences containing six, eight, and ten colors were generated using the data-driven aesthetic-preference model and accessibility constraints. Due to the balance of aesthetics and accessibility considerations, the resulting color sequences can serve as reasonable defaults in data-plotting codes, e.g., for use in scatter plots and line plots.\n    ",
        "primary_category": "cs.GR",
        "categories": [],
        "submitted_date": "5 Jul 2021",
        "last_revised_date": " "
    },
    "2107.02743": {
        "title": "Submodular Order Functions and Assortment Optimization",
        "authors": [
            "Rajan Udwani"
        ],
        "comments": "To appear in Management Science",
        "subjects": "Optimization and Control (math.OC)",
        "abstract": "We define a new class of set functions that in addition to being monotone and subadditive, also admit a very limited form of submodularity defined over a permutation of the ground set. We refer to this permutation as a submodular order. This class of functions includes monotone submodular functions as a sub-family. We give fast algorithms with strong approximation guarantees for maximizing submodular order functions under a variety of constraints and show a nearly tight upper bound on the highest approximation guarantee achievable by algorithms with polynomial query complexity. Applying this new notion to the problem of constrained assortment optimization in fundamental choice models, we obtain new algorithms that are both faster and have stronger approximation guarantees (in some cases, first algorithm with constant factor guarantee). We also show an intriguing connection to the maximization of monotone submodular functions in the streaming model, where we recover best known approximation guarantees as a corollary of our results.\n    ",
        "primary_category": "math.OC",
        "categories": [
            "cs.DS"
        ],
        "submitted_date": "6 Jul 2021",
        "last_revised_date": " "
    },
    "2108.04567": {
        "title": "Robust and Dexterous Dual-arm Tele-Cooperation using Adaptable Impedance Control",
        "authors": [
            "Keyhan Kouhkiloui Babarahmati",
            "Mohammadreza Kasaei",
            "Carlo Tiseo",
            "Michael Mistry",
            "Sethu Vijayakumar"
        ],
        "comments": " ",
        "subjects": "Robotics (cs.RO)",
        "abstract": "In recent years, the need for robots to transition from isolated industrial tasks to shared environments, including human-robot collaboration and teleoperation, has become increasingly evident. Building on the foundation of Fractal Impedance Control (FIC) introduced in our previous work, this paper presents a novel extension to dual-arm tele-cooperation, leveraging the non-linear stiffness and passivity of FIC to adapt to diverse cooperative scenarios. Unlike traditional impedance controllers, our approach ensures stability without relying on energy tanks, as demonstrated in our prior research. In this paper, we further extend the FIC framework to bimanual operations, allowing for stable and smooth switching between different dynamic tasks without gain tuning. We also introduce a telemanipulation architecture that offers higher transparency and dexterity, addressing the challenges of signal latency and low-bandwidth communication. Through extensive experiments, we validate the robustness of our method and the results confirm the advantages of the FIC approach over traditional impedance controllers, showcasing its potential for applications in planetary exploration and other scenarios requiring dexterous telemanipulation. This paper's contributions include the seamless integration of FIC into multi-arm systems, the ability to perform robust interactions in highly variable environments, and the provision of a comprehensive comparison with competing approaches, thereby significantly enhancing the robustness and adaptability of robotic systems.\n    ",
        "primary_category": "cs.RO",
        "categories": [],
        "submitted_date": "10 Aug 2021",
        "last_revised_date": " "
    },
    "2109.15242": {
        "title": "Transferability Estimation for Semantic Segmentation Task",
        "authors": [
            "Yang Tan",
            "Yang Li",
            "Shao-Lun Huang"
        ],
        "comments": "This paper is not the latest version. Please refer to Efficient Prediction of Model Transferability in Semantic Segmentation Tasks (ICIP'23) for more details. this https URL",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Transferability estimation is a fundamental problem in transfer learning to predict how good the performance is when transferring a source model (or source task) to a target task. With the guidance of transferability score, we can efficiently select the highly transferable source models without performing the real transfer in practice. Recent analytical transferability metrics are mainly designed for image classification problem, and currently there is no specific investigation for the transferability estimation of semantic segmentation task, which is an essential problem in autonomous driving, medical image analysis, etc. Consequently, we further extend the recent analytical transferability metric OTCE (Optimal Transport based Conditional Entropy) score to the semantic segmentation task. The challenge in applying the OTCE score is the high dimensional segmentation output, which is difficult to find the optimal coupling between so many pixels under an acceptable computation cost. Thus we propose to randomly sample N pixels for computing OTCE score and take the expectation over K repetitions as the final transferability score. Experimental evaluation on Cityscapes, BDD100K and GTA5 datasets demonstrates that the OTCE score highly correlates with the transfer performance.\n    ",
        "primary_category": "cs.CV",
        "categories": [],
        "submitted_date": "30 Sep 2021",
        "last_revised_date": " "
    },
    "2110.11385": {
        "title": "Self-Initiated Open World Learning for Autonomous AI Agents",
        "authors": [
            "Bing Liu",
            "Eric Robertson",
            "Scott Grigsby",
            "Sahisnu Mazumder"
        ],
        "comments": "Published in AAAI 2022 Spring Symposium Series",
        "subjects": "Artificial Intelligence (cs.AI)",
        "abstract": "As more and more AI agents are used in practice, it is time to think about how to make these agents fully autonomous so that they can learn by themselves in a self-motivated and self-supervised manner rather than being retrained periodically on the initiation of human engineers using expanded training data. As the real-world is an open environment with unknowns or novelties, detecting novelties or unknowns, characterizing them, accommodating or adapting to them, gathering ground-truth training data, and incrementally learning the unknowns/novelties are critical to making the agent more and more knowledgeable and powerful over time. The key challenge is how to automate the process so that it is carried out on the agent's own initiative and through its own interactions with humans and the environment. Since an AI agent usually has a performance task, characterizing each novelty becomes critical and necessary so that the agent can formulate an appropriate response to adapt its behavior to accommodate the novelty and to learn from it to improve the agent's adaptation capability and task performance. The process goes continually without termination. This paper proposes a theoretic framework for this learning paradigm to promote the research of building Self-initiated Open world Learning (SOL) agents. An example SOL agent is also described.\n    ",
        "primary_category": "cs.AI",
        "categories": [
            "cs.HC",
            "cs.LG"
        ],
        "submitted_date": "21 Oct 2021",
        "last_revised_date": " "
    },
    "2112.01799": {
        "title": "Global Context with Discrete Diffusion in Vector Quantised Modelling for Image Generation",
        "authors": [
            "Minghui Hu",
            "Yujie Wang",
            "Tat-Jen Cham",
            "Jianfei Yang",
            "P.N.Suganthan"
        ],
        "comments": " ",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "The integration of Vector Quantised Variational AutoEncoder (VQ-VAE) with autoregressive models as generation part has yielded high-quality results on image generation. However, the autoregressive models will strictly follow the progressive scanning order during the sampling phase. This leads the existing VQ series models to hardly escape the trap of lacking global information. Denoising Diffusion Probabilistic Models (DDPM) in the continuous domain have shown a capability to capture the global context, while generating high-quality images. In the discrete state space, some works have demonstrated the potential to perform text generation and low resolution image generation. We show that with the help of a content-rich discrete visual codebook from VQ-VAE, the discrete diffusion model can also generate high fidelity images with global context, which compensates for the deficiency of the classical autoregressive model along pixel space. Meanwhile, the integration of the discrete VAE with the diffusion model resolves the drawback of conventional autoregressive models being oversized, and the diffusion model which demands excessive time in the sampling process when generating images. It is found that the quality of the generated images is heavily dependent on the discrete visual codebook. Extensive experiments demonstrate that the proposed Vector Quantised Discrete Diffusion Model (VQ-DDM) is able to achieve comparable performance to top-tier methods with low complexity. It also demonstrates outstanding advantages over other vectors quantised with autoregressive models in terms of image inpainting tasks without additional training.\n    ",
        "primary_category": "cs.CV",
        "categories": [
            "cs.LG"
        ],
        "submitted_date": "3 Dec 2021",
        "last_revised_date": " "
    },
    "2112.05478": {
        "title": "Critical configurations for three projective views",
        "authors": [
            "Martin Br\u00e5telund"
        ],
        "comments": "40 pages, 9 figures. This is a companion paper to arXiv:2112.05074. Accepted manuscript published in Mathematica Scandinavica",
        "subjects": "Algebraic Geometry (math.AG)",
        "abstract": "The problem of structure from motion is concerned with recovering the 3-dimensional structure of an object from a set of 2-dimensional images taken by unknown cameras. Generally, all information can be uniquely recovered if enough images and point correspondences are provided, yet there are certain cases where unique recovery is impossible; these are called critical configurations. We use an algebraic approach to study the critical configurations for three projective cameras. We show that all critical configurations lie on the intersection of quadric surfaces, and classify exactly which intersections constitute a critical configuration.\n    ",
        "primary_category": "math.AG",
        "categories": [
            "cs.CV"
        ],
        "submitted_date": "10 Dec 2021",
        "last_revised_date": " "
    },
    "2202.08370": {
        "title": "CAREER: A Foundation Model for Labor Sequence Data",
        "authors": [
            "Keyon Vafa",
            "Emil Palikot",
            "Tianyu Du",
            "Ayush Kanodia",
            "Susan Athey",
            "David M. Blei"
        ],
        "comments": " ",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Labor economists regularly analyze employment data by fitting predictive models to small, carefully constructed longitudinal survey datasets. Although machine learning methods offer promise for such problems, these survey datasets are too small to take advantage of them. In recent years large datasets of online resumes have also become available, providing data about the career trajectories of millions of individuals. However, standard econometric models cannot take advantage of their scale or incorporate them into the analysis of survey data. To this end we develop CAREER, a foundation model for job sequences. CAREER is first fit to large, passively-collected resume data and then fine-tuned to smaller, better-curated datasets for economic inferences. We fit CAREER to a dataset of 24 million job sequences from resumes, and adjust it on small longitudinal survey datasets. We find that CAREER forms accurate predictions of job sequences, outperforming econometric baselines on three widely-used economics datasets. We further find that CAREER can be used to form good predictions of other downstream variables. For example, incorporating CAREER into a wage model provides better predictions than the econometric models currently in use.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "econ.EM"
        ],
        "submitted_date": "16 Feb 2022",
        "last_revised_date": " "
    },
    "2203.01360": {
        "title": "Neural Galerkin Schemes with Active Learning for High-Dimensional Evolution Equations",
        "authors": [
            "Joan Bruna",
            "Benjamin Peherstorfer",
            "Eric Vanden-Eijnden"
        ],
        "comments": " ",
        "subjects": "Numerical Analysis (math.NA)",
        "abstract": "Deep neural networks have been shown to provide accurate function approximations in high dimensions. However, fitting network parameters requires informative training data that are often challenging to collect in science and engineering applications. This work proposes Neural Galerkin schemes based on deep learning that generate training data with active learning for numerically solving high-dimensional partial differential equations. Neural Galerkin schemes build on the Dirac-Frenkel variational principle to train networks by minimizing the residual sequentially over time, which enables adaptively collecting new training data in a self-informed manner that is guided by the dynamics described by the partial differential equations. This is in contrast to other machine learning methods that aim to fit network parameters globally in time without taking into account training data acquisition. Our finding is that the active form of gathering training data of the proposed Neural Galerkin schemes is key for numerically realizing the expressive power of networks in high dimensions. Numerical experiments demonstrate that Neural Galerkin schemes have the potential to enable simulating phenomena and processes with many variables for which traditional and other deep-learning-based solvers fail, especially when features of the solutions evolve locally such as in high-dimensional wave propagation problems and interacting particle systems described by Fokker-Planck and kinetic equations.\n    ",
        "primary_category": "math.NA",
        "categories": [
            "cs.LG",
            "stat.ML"
        ],
        "submitted_date": "2 Mar 2022",
        "last_revised_date": " "
    },
    "2203.08964": {
        "title": "Point-Unet: A Context-aware Point-based Neural Network for Volumetric Segmentation",
        "authors": [
            "Ngoc-Vuong Ho",
            "Tan Nguyen",
            "Gia-Han Diep",
            "Ngan Le",
            "Binh-Son Hua"
        ],
        "comments": "Accepted in MICCAI 2021",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Medical image analysis using deep learning has recently been prevalent, showing great performance for various downstream tasks including medical image segmentation and its sibling, volumetric image segmentation. Particularly, a typical volumetric segmentation network strongly relies on a voxel grid representation which treats volumetric data as a stack of individual voxel `slices', which allows learning to segment a voxel grid to be as straightforward as extending existing image-based segmentation networks to the 3D domain. However, using a voxel grid representation requires a large memory footprint, expensive test-time and limiting the scalability of the solutions. In this paper, we propose Point-Unet, a novel method that incorporates the efficiency of deep learning with 3D point clouds into volumetric segmentation. Our key idea is to first predict the regions of interest in the volume by learning an attentional probability map, which is then used for sampling the volume into a sparse point cloud that is subsequently segmented using a point-based neural network. We have conducted the experiments on the medical volumetric segmentation task with both a small-scale dataset Pancreas and large-scale datasets BraTS18, BraTS19, and BraTS20 challenges. A comprehensive benchmark on different metrics has shown that our context-aware Point-Unet robustly outperforms the SOTA voxel-based networks at both accuracies, memory usage during training, and time consumption during testing. Our code is available at this https URL.\n    ",
        "primary_category": "cs.CV",
        "categories": [],
        "submitted_date": "16 Mar 2022",
        "last_revised_date": " "
    },
    "2204.04377": {
        "title": "Robotic Surgery Remote Mentoring via AR with 3D Scene Streaming and Hand Interaction",
        "authors": [
            "Yonghao Long",
            "Chengkun Li",
            "Qi Dou"
        ],
        "comments": " ",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "With the growing popularity of robotic surgery, education becomes increasingly important and urgently needed for the sake of patient safety. However, experienced surgeons have limited accessibility due to their busy clinical schedule or working in a distant city, thus can hardly provide sufficient education resources for novices. Remote mentoring, as an effective way, can help solve this problem, but traditional methods are limited to plain text, audio, or 2D video, which are not intuitive nor vivid. Augmented reality (AR), a thriving technique being widely used for various education scenarios, is promising to offer new possibilities of visual experience and interactive teaching. In this paper, we propose a novel AR-based robotic surgery remote mentoring system with efficient 3D scene visualization and natural 3D hand interaction. Using a head-mounted display (i.e., HoloLens), the mentor can remotely monitor the procedure streamed from the trainee's operation side. The mentor can also provide feedback directly with hand gestures, which is in-turn transmitted to the trainee and viewed in surgical console as guidance. We comprehensively validate the system on both real surgery stereo videos and ex-vivo scenarios of common robotic training tasks (i.e., peg-transfer and suturing). Promising results are demonstrated regarding the fidelity of streamed scene visualization, the accuracy of feedback with hand interaction, and the low-latency of each component in the entire remote mentoring system. This work showcases the feasibility of leveraging AR technology for reliable, flexible and low-cost solutions to robotic surgical education, and holds great potential for clinical applications.\n    ",
        "primary_category": "cs.CV",
        "categories": [],
        "submitted_date": "9 Apr 2022",
        "last_revised_date": " "
    },
    "2204.04476": {
        "title": "High-dimensional Asymptotics of Langevin Dynamics in Spiked Matrix Models",
        "authors": [
            "Tengyuan Liang",
            "Subhabrata Sen",
            "Pragya Sur"
        ],
        "comments": "26 pages",
        "subjects": "Statistics Theory (math.ST)",
        "abstract": "We study Langevin dynamics for recovering the planted signal in the spiked matrix model. We provide a \"path-wise\" characterization of the overlap between the output of the Langevin algorithm and the planted signal. This overlap is characterized in terms of a self-consistent system of integro-differential equations, usually referred to as the Crisanti-Horner-Sommers-Cugliandolo-Kurchan (CHSCK) equations in the spin glass literature. As a second contribution, we derive an explicit formula for the limiting overlap in terms of the signal-to-noise ratio and the injected noise in the diffusion. This uncovers a sharp phase transition -- in one regime, the limiting overlap is strictly positive, while in the other, the injected noise overcomes the signal, and the limiting overlap is zero.\n    ",
        "primary_category": "math.ST",
        "categories": [
            "cs.LG",
            "math.PR",
            "stat.ML"
        ],
        "submitted_date": "9 Apr 2022",
        "last_revised_date": " "
    },
    "2205.14845": {
        "title": "QFaaS: A Serverless Function-as-a-Service Framework for Quantum Computing",
        "authors": [
            "Hoa T. Nguyen",
            "Muhammad Usman",
            "Rajkumar Buyya"
        ],
        "comments": "35 pages, 15 figures",
        "subjects": "Quantum Physics (quant-ph)",
        "abstract": "Recent breakthroughs in quantum hardware are creating opportunities for its use in many applications. However, quantum software engineering is still in its infancy with many challenges, especially dealing with the diversity of quantum programming languages and hardware platforms. To alleviate these challenges, we propose QFaaS, a novel Quantum Function-as-a-Service framework, which leverages the advantages of the serverless model and the state-of-the-art software engineering approaches to advance practical quantum computing. Our framework provides essential components of a quantum serverless platform to simplify the software development and adapt to the quantum cloud computing paradigm, such as combining hybrid quantum-classical computation, containerizing functions, and integrating DevOps features. We design QFaaS as a unified quantum computing framework by supporting well-known quantum languages and software development kits (Qiskit, Q#, Cirq, and Braket), executing the quantum tasks on multiple simulators and quantum cloud providers (IBM Quantum and Amazon Braket). This paper proposes architectural design, principal components, the life cycle of hybrid quantum-classical function, operation workflow, and implementation of QFaaS. We present two practical use cases and perform the evaluations on quantum computers and simulators to demonstrate our framework's ability to ease the burden on traditional engineers to expedite the ongoing quantum software transition.\n    ",
        "primary_category": "quant-ph",
        "categories": [
            "cs.DC",
            "cs.ET"
        ],
        "submitted_date": "30 May 2022",
        "last_revised_date": " "
    },
    "2206.03010": {
        "title": "MS-RNN: A Flexible Multi-Scale Framework for Spatiotemporal Predictive Learning",
        "authors": [
            "Zhifeng Ma",
            "Hao Zhang",
            "Jie Liu"
        ],
        "comments": " ",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Spatiotemporal predictive learning, which predicts future frames through historical prior knowledge with the aid of deep learning, is widely used in many fields. Previous work essentially improves the model performance by widening or deepening the network, but it also brings surging memory overhead, which seriously hinders the development and application of this technology. In order to improve the performance without increasing memory consumption, we focus on scale, which is another dimension to improve model performance but with low memory requirement. The effectiveness has been widely demonstrated in many CNN-based tasks such as image classification and semantic segmentation, but it has not been fully explored in recent RNN models. In this paper, learning from the benefit of multi-scale, we propose a general framework named Multi-Scale RNN (MS-RNN) to boost recent RNN models for spatiotemporal predictive learning. We verify the MS-RNN framework by thorough theoretical analyses and exhaustive experiments, where the theory focuses on memory reduction and performance improvement while the experiments employ eight RNN models (ConvLSTM, TrajGRU, PredRNN, PredRNN++, MIM, MotionRNN, PredRNN-V2, and PrecipLSTM) and four datasets (Moving MNIST, TaxiBJ, KTH, and Germany). The results show the efficiency that RNN models incorporating our framework have much lower memory cost but better performance than before. Our code is released at \\url{this https URL}.\n    ",
        "primary_category": "cs.CV",
        "categories": [],
        "submitted_date": "7 Jun 2022",
        "last_revised_date": " "
    },
    "2206.10485": {
        "title": "Tight bounds for the learning of homotopy \u00e0 la Niyogi, Smale, and Weinberger for subsets of Euclidean spaces and of Riemannian manifolds",
        "authors": [
            "Dominique Attali",
            "Hana Dal Poz Kou\u0159imsk\u00e1",
            "Christopher Fillmore",
            "Ishika Ghosh",
            "Andr\u00e9 Lieutier",
            "Elizabeth Stephenson",
            "Mathijs Wintraecken"
        ],
        "comments": "75 pages, 29 figures",
        "subjects": "Computational Geometry (cs.CG)",
        "abstract": "In this article we extend and strengthen the seminal work by Niyogi, Smale, and Weinberger on the learning of the homotopy type from a sample of an underlying space. In their work, Niyogi, Smale, and Weinberger studied samples of $C^2$ manifolds with positive reach embedded in $\\mathbb{R}^d$. We extend their results in the following ways: In the first part of our paper we consider both manifolds of positive reach -- a more general setting than $C^2$ manifolds -- and sets of positive reach embedded in $\\mathbb{R}^d$. The sample $P$ of such a set $\\mathcal{S}$ does not have to lie directly on it. Instead, we assume that the two one-sided Hausdorff distances -- $\\varepsilon$ and $\\delta$ -- between $P$ and $\\mathcal{S}$ are bounded. We provide explicit bounds in terms of $\\varepsilon$ and $ \\delta$, that guarantee that there exists a parameter $r$ such that the union of balls of radius $r$ centred at the sample $P$ deformation-retracts to $\\mathcal{S}$.\nIn the second part of our paper we study homotopy learning in a significantly more general setting -- we investigate sets of positive reach and submanifolds of positive reach embedded in a \\emph{Riemannian manifold with bounded sectional curvature}. To this end we introduce a new version of the reach in the Riemannian setting inspired by the cut locus. Yet again, we provide tight bounds on $\\varepsilon$ and $\\delta$ for both cases (submanifolds as well as sets of positive reach), exhibiting the tightness by an explicit construction.\n    ",
        "primary_category": "cs.CG",
        "categories": [
            "math.AT"
        ],
        "submitted_date": "21 Jun 2022",
        "last_revised_date": " "
    },
    "2207.05510": {
        "title": "Transferability-Guided Cross-Domain Cross-Task Transfer Learning",
        "authors": [
            "Yang Tan",
            "Enming Zhang",
            "Yang Li",
            "Shao-Lun Huang",
            "Xiao-Ping Zhang"
        ],
        "comments": "This work is accepted by IEEE TNNLS. Please see the official version this https URL may be transferred without notice, after which this version may no longer be accessible",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "We propose two novel transferability metrics F-OTCE (Fast Optimal Transport based Conditional Entropy) and JC-OTCE (Joint Correspondence OTCE) to evaluate how much the source model (task) can benefit the learning of the target task and to learn more transferable representations for cross-domain cross-task transfer learning. Unlike the existing metric that requires evaluating the empirical transferability on auxiliary tasks, our metrics are auxiliary-free such that they can be computed much more efficiently. Specifically, F-OTCE estimates transferability by first solving an Optimal Transport (OT) problem between source and target distributions, and then uses the optimal coupling to compute the Negative Conditional Entropy between source and target labels. It can also serve as a loss function to maximize the transferability of the source model before finetuning on the target task. Meanwhile, JC-OTCE improves the transferability robustness of F-OTCE by including label distances in the OT problem, though it may incur additional computation cost. Extensive experiments demonstrate that F-OTCE and JC-OTCE outperform state-of-the-art auxiliary-free metrics by 18.85% and 28.88%, respectively in correlation coefficient with the ground-truth transfer accuracy. By eliminating the training cost of auxiliary tasks, the two metrics reduces the total computation time of the previous method from 43 minutes to 9.32s and 10.78s, respectively, for a pair of tasks. When used as a loss function, F-OTCE shows consistent improvements on the transfer accuracy of the source model in few-shot classification experiments, with up to 4.41% accuracy gain.\n    ",
        "primary_category": "cs.CV",
        "categories": [
            "cs.AI",
            "cs.LG"
        ],
        "submitted_date": "12 Jul 2022",
        "last_revised_date": " "
    },
    "2208.10824": {
        "title": "Improved rates for a space-time FOSLS of parabolic PDEs",
        "authors": [
            "Gregor Gantner",
            "Rob Stevenson"
        ],
        "comments": " ",
        "subjects": "Numerical Analysis (math.NA)",
        "abstract": "We consider the first-order system space-time formulation of the heat equation introduced in [Bochev, Gunzburger, Springer, New York (2009)], and analyzed in [F\u00fchrer, Karkulik, Comput. Math. Appl. 92 (2021)] and [Gantner, Stevenson, ESAIM Math. Model. Numer. Anal.} 55 (2021)], with solution components $(u_1,{\\bf u}_2)=(u,-\\nabla_{\\bf x} u)$. The corresponding operator is boundedly invertible between a Hilbert space $U$ and a Cartesian product of $L_2$-type spaces, which facilitates easy first-order system least-squares (FOSLS) discretizations. Besides $L_2$-norms of $\\nabla_{\\bf x} u_1$ and ${\\bf u}_2$, the (graph) norm of $U$ contains the $L_2$-norm of $\\partial_t u_1 +{\\rm div}_{\\bf x} {\\bf u}_2$. When applying standard finite elements w.r.t. simplicial partitions of the space-time cylinder, estimates of the approximation error w.r.t. the latter norm require higher-order smoothness of ${\\bf u}_2$. In experiments for both uniform and adaptively refined partitions, this manifested itself in disappointingly low convergence rates for non-smooth solutions $u$.\nIn this paper, we construct finite element spaces w.r.t. prismatic partitions. They come with a quasi-interpolant that satisfies a near commuting diagram in the sense that, apart from some harmless term, the aforementioned error depends exclusively on the smoothness of $\\partial_t u_1 +{\\rm div}_{\\bf x} {\\bf u}_2$, i.e., of the forcing term $f=(\\partial_t-\\Delta_x)u$. Numerical results show significantly improved convergence rates.\n    ",
        "primary_category": "math.NA",
        "categories": [],
        "submitted_date": "23 Aug 2022",
        "last_revised_date": " "
    },
    "2209.00945": {
        "title": "IMG2IMU: Translating Knowledge from Large-Scale Images to IMU Sensing Applications",
        "authors": [
            "Hyungjun Yoon",
            "Hyeongheon Cha",
            "Hoang C. Nguyen",
            "Taesik Gong",
            "Sung-Ju Lee"
        ],
        "comments": "12 pages",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Pre-training representations acquired via self-supervised learning could achieve high accuracy on even tasks with small training data. Unlike in vision and natural language processing domains, pre-training for IMU-based applications is challenging, as there are few public datasets with sufficient size and diversity to learn generalizable representations. To overcome this problem, we propose IMG2IMU that adapts pre-trained representation from large-scale images to diverse IMU sensing tasks. We convert the sensor data into visually interpretable spectrograms for the model to utilize the knowledge gained from vision. We further present a sensor-aware pre-training method for images that enables models to acquire particularly impactful knowledge for IMU sensing applications. This involves using contrastive learning on our augmentation set customized for the properties of sensor data. Our evaluation with four different IMU sensing tasks shows that IMG2IMU outperforms the baselines pre-trained on sensor data by an average of 9.6%p F1-score, illustrating that vision knowledge can be usefully incorporated into IMU sensing applications where only limited training data is available.\n    ",
        "primary_category": "cs.LG",
        "categories": [],
        "submitted_date": "2 Sep 2022",
        "last_revised_date": " "
    },
    "2209.01183": {
        "title": "Indoor Positioning in 5G-Advanced: Challenges and Solution towards Centimeter-level Accuracy with Carrier Phase Enhancements",
        "authors": [
            "Jakub Nikonowicz",
            "Aamir Mahmood",
            "Muhammad Ikram Ashraf",
            "Emil Bj\u00f6rnson",
            "Mikael Gidlund"
        ],
        "comments": "5 figures, 1 table, accepted for publication in IEEE Wireless Communications Magazine",
        "subjects": "Information Theory (cs.IT)",
        "abstract": "After robust connectivity, precise positioning is evolving into an innovative component of 5G service offerings for industrial use-cases and verticals with challenging indoor radio environments. In this direction, the 3GPP Rel-16 standard has been a tipping point in specifying critical innovations, followed by enhancements in Rel-17 and Rel-18. In this article, we elaborate on the 5G positioning framework, measurements, and procedures before shifting the focus mainly to recently identified carrier-phase (CP) measurements in Rel-18 as a complementary measure for time- and angular-based positioning methods. We discuss the associated challenges and potential solutions for exploiting CP, including integer ambiguity, multipath sensitivity, and signaling aspects. Furthermore, we study how phase-continuous reference signaling can counter noisy phase measurements using realistic simulations to achieve centimeter-level accuracy in indoor factory (InF) scenarios.\n    ",
        "primary_category": "cs.IT",
        "categories": [],
        "submitted_date": "2 Sep 2022",
        "last_revised_date": " "
    },
    "2209.01970": {
        "title": "FIRED: a fine-grained robust performance diagnosis framework for cloud applications",
        "authors": [
            "Ruyue Xin",
            "Hongyun Liu",
            "Peng Chen",
            "Paola Grosso",
            "Zhiming Zhao"
        ],
        "comments": " ",
        "subjects": "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "abstract": "To run a cloud application with the required service quality, operators have to continuously monitor the cloud application's run-time status, detect potential performance anomalies, and diagnose the root causes of anomalies. However, existing models of performance anomaly detection often suffer from low re-usability and robustness due to the diversity of system-level metrics being monitored and the lack of high-quality labeled monitoring data for anomalies. Moreover, the current coarse-grained analysis models make it difficult to locate system-level root causes of the application performance anomalies for effective adaptation decisions. We provide a FIne-grained Robust pErformance Diagnosis (FIRED) framework to tackle those challenges. The framework offers an ensemble of several well-selected base models for anomaly detection using a deep neural network, which adopts weakly-supervised learning considering fewer labels exist in reality. The framework also employs a real-time fine-grained analysis model to locate dependent system metrics of the anomaly. Our experiments show that the framework can achieve the best detection accuracy and algorithm robustness, and it can predict anomalies in four minutes with F1 score higher than 0.8. In addition, the framework can accurately localize the first root causes, and with an average accuracy higher than 0.7 of locating first four root causes.\n    ",
        "primary_category": "cs.DC",
        "categories": [],
        "submitted_date": "5 Sep 2022",
        "last_revised_date": " "
    },
    "2209.12044": {
        "title": "Characterising memory in infinite games",
        "authors": [
            "Antonio Casares",
            "Pierre Ohlmann"
        ],
        "comments": "52 pages, 21 figures",
        "subjects": "Formal Languages and Automata Theory (cs.FL)",
        "abstract": "This paper is concerned with games of infinite duration played over potentially infinite graphs. Recently, Ohlmann (LICS 2022) presented a characterisation of objectives admitting optimal positional strategies, by means of universal graphs: an objective is positional if and only if it admits well-ordered monotone universal graphs. We extend Ohlmann's characterisation to encompass (finite or infinite) memory upper bounds.\nWe prove that objectives admitting optimal strategies with $\\varepsilon$-memory less than $m$ (a memory that cannot be updated when reading an $\\varepsilon$-edge) are exactly those which admit well-founded monotone universal graphs whose antichains have size bounded by $m$. We also give a characterisation of chromatic memory by means of appropriate universal structures. Our results apply to finite as well as infinite memory bounds (for instance, to objectives with finite but unbounded memory, or with countable memory strategies).\nWe illustrate the applicability of our framework by carrying out a few case studies, we provide examples witnessing limitations of our approach, and we discuss general closure properties which follow from our results.\n    ",
        "primary_category": "cs.FL",
        "categories": [
            "cs.LO"
        ],
        "submitted_date": "24 Sep 2022",
        "last_revised_date": " "
    },
    "2210.08854": {
        "title": "Inexpensive polynomial-degree-robust equilibrated flux a posteriori estimates for isogeometric analysis",
        "authors": [
            "Gregor Gantner",
            "Martin Vohral\u00edk"
        ],
        "comments": " ",
        "subjects": "Numerical Analysis (math.NA)",
        "abstract": "We consider isogeometric discretizations of the Poisson model problem, focusing on high polynomial degrees and strong hierarchical refinements. We derive a posteriori error estimates by equilibrated fluxes, i.e., vector-valued mapped piecewise polynomials lying in the $\\boldsymbol{H}({\\rm div})$ space which appropriately approximate the desired divergence constraint. Our estimates are constant-free in the leading term, locally efficient, and robust with respect to the polynomial degree. They are also robust with respect to the number of hanging nodes arising in adaptive mesh refinement employing hierarchical B-splines. Two partitions of unity are designed, one with larger supports corresponding to the mapped splines, and one with small supports corresponding to mapped piecewise multilinear finite element hat basis functions. The equilibration is only performed on the small supports, avoiding the higher computational price of equilibration on the large supports or even the solution of a global system. Thus, the derived estimates are also as inexpensive as possible. An abstract framework for such a setting is developed, whose application to a specific situation only requests a verification of a few clearly identified assumptions. Numerical experiments illustrate the theoretical developments.\n    ",
        "primary_category": "math.NA",
        "categories": [],
        "submitted_date": "17 Oct 2022",
        "last_revised_date": " "
    },
    "2210.12090": {
        "title": "AutoPrognosis 2.0: Democratizing Diagnostic and Prognostic Modeling in Healthcare with Automated Machine Learning",
        "authors": [
            "Fergus Imrie",
            "Bogdan Cebere",
            "Eoin F. McKinney",
            "Mihaela van der Schaar"
        ],
        "comments": " ",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Diagnostic and prognostic models are increasingly important in medicine and inform many clinical decisions. Recently, machine learning approaches have shown improvement over conventional modeling techniques by better capturing complex interactions between patient covariates in a data-driven manner. However, the use of machine learning introduces a number of technical and practical challenges that have thus far restricted widespread adoption of such techniques in clinical settings. To address these challenges and empower healthcare professionals, we present a machine learning framework, AutoPrognosis 2.0, to develop diagnostic and prognostic models. AutoPrognosis leverages state-of-the-art advances in automated machine learning to develop optimized machine learning pipelines, incorporates model explainability tools, and enables deployment of clinical demonstrators, without requiring significant technical expertise. Our framework eliminates the major technical obstacles to predictive modeling with machine learning that currently impede clinical adoption. To demonstrate AutoPrognosis 2.0, we provide an illustrative application where we construct a prognostic risk score for diabetes using the UK Biobank, a prospective study of 502,467 individuals. The models produced by our automated framework achieve greater discrimination for diabetes than expert clinical risk scores. Our risk score has been implemented as a web-based decision support tool and can be publicly accessed by patients and clinicians worldwide. In addition, AutoPrognosis 2.0 is provided as an open-source python package. By open-sourcing our framework as a tool for the community, clinicians and other medical practitioners will be able to readily develop new risk scores, personalized diagnostics, and prognostics using modern machine learning techniques.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "21 Oct 2022",
        "last_revised_date": " "
    },
    "2210.14484": {
        "title": "Imputation of missing values in multi-view data",
        "authors": [
            "Wouter van Loon",
            "Marjolein Fokkema",
            "Frank de Vos",
            "Marisa Koini",
            "Reinhold Schmidt",
            "Mark de Rooij"
        ],
        "comments": "48 pages, 15 figures. Major revisions",
        "subjects": "Machine Learning (stat.ML)",
        "abstract": "Data for which a set of objects is described by multiple distinct feature sets (called views) is known as multi-view data. When missing values occur in multi-view data, all features in a view are likely to be missing simultaneously. This leads to very large quantities of missing data which, especially when combined with high-dimensionality, makes the application of conditional imputation methods computationally infeasible. We introduce a new imputation method based on the existing stacked penalized logistic regression (StaPLR) algorithm for multi-view learning. It performs imputation in a dimension-reduced space to address computational challenges inherent to the multi-view context. We compare the performance of the new imputation method with several existing imputation algorithms in simulated data sets. The results show that the new imputation method leads to competitive results at a much lower computational cost, and makes the use of advanced imputation algorithms such as missForest and predictive mean matching possible in settings where they would otherwise be computationally infeasible.\n    ",
        "primary_category": "stat.ML",
        "categories": [
            "cs.LG",
            "stat.ME"
        ],
        "submitted_date": "26 Oct 2022",
        "last_revised_date": " "
    },
    "2210.16662": {
        "title": "Global Optimization of Energy Efficiency in IRS-Aided Communication Systems via Robust IRS-Element Activation",
        "authors": [
            "Christos N. Efrem",
            "Ioannis Krikidis"
        ],
        "comments": "8 pages, 3 figures",
        "subjects": "Signal Processing (eess.SP)",
        "abstract": "In this paper, we study an intelligent reflecting surface (IRS) assisted communication system with single-antenna transmitter and receiver, under imperfect channel state information (CSI). More specifically, we deal with the robust selection of binary (on/off) states of the IRS elements in order to maximize the worst-case energy efficiency (EE), given a bounded CSI uncertainty, while satisfying a minimum signal-to-noise ratio (SNR). The IRS phase shifts are adjusted so as to maximize the ideal SNR (i.e., without CSI error), based only on the estimated channels. First, we derive a closed-form expression of the worst-case SNR, and then formulate the robust (discrete) optimization problem. Moreover, we design and analyze a dynamic programming (DP) algorithm that is theoretically guaranteed to achieve the global maximum with polynomial complexity $O(L \\log L)$, where $L$ is the number of IRS elements. Finally, numerical simulations confirm the theoretical results. In particular, the proposed algorithm shows identical performance with the exhaustive search, and significantly outperforms a baseline scheme, namely, the activation of all IRS elements.\n    ",
        "primary_category": "eess.SP",
        "categories": [
            "cs.IT"
        ],
        "submitted_date": "29 Oct 2022",
        "last_revised_date": " "
    },
    "2211.05269": {
        "title": "Generative Adversarial Networks for Weakly Supervised Generation and Evaluation of Brain Tumor Segmentations on MR Images",
        "authors": [
            "Jay J. Yoo",
            "Khashayar Namdar",
            "Matthias W. Wagner",
            "Liana Nobre",
            "Uri Tabori",
            "Cynthia Hawkins",
            "Birgit B. Ertl-Wagner",
            "Farzad Khalvati"
        ],
        "comments": " ",
        "subjects": "Image and Video Processing (eess.IV)",
        "abstract": "Segmentation of regions of interest (ROIs) for identifying abnormalities is a leading problem in medical imaging. Using machine learning for this problem generally requires manually annotated ground-truth segmentations, demanding extensive time and resources from radiologists. This work presents a weakly supervised approach that utilizes binary image-level labels, which are much simpler to acquire, to effectively segment anomalies in 2D magnetic resonance images without ground truth annotations. We train a generative adversarial network (GAN) that converts cancerous images to healthy variants, which are used along with localization seeds as priors to generate improved weakly supervised segmentations. The non-cancerous variants can also be used to evaluate the segmentations in a weakly supervised fashion, which allows for the most effective segmentations to be identified and then applied to downstream clinical classification tasks. On the Multimodal Brain Tumor Segmentation (BraTS) 2020 dataset, our proposed method generates and identifies segmentations that achieve test Dice coefficients of 83.91%. Using these segmentations for pathology classification results with a test AUC of 93.32% which is comparable to the test AUC of 95.80% achieved when using true segmentations.\n    ",
        "primary_category": "eess.IV",
        "categories": [
            "cs.CV"
        ],
        "submitted_date": "10 Nov 2022",
        "last_revised_date": " "
    },
    "2211.07303": {
        "title": "Adaptive Federated Minimax Optimization with Lower Complexities",
        "authors": [
            "Feihu Huang",
            "Xinrui Wang",
            "Junyi Li",
            "Songcan Chen"
        ],
        "comments": "To appear in AISTATS 2024",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Federated learning is a popular distributed and privacy-preserving learning paradigm in machine learning. Recently, some federated learning algorithms have been proposed to solve the distributed minimax problems. However, these federated minimax algorithms still suffer from high gradient or communication complexity. Meanwhile, few algorithm focuses on using adaptive learning rate to accelerate these algorithms. To fill this gap, in the paper, we study a class of nonconvex minimax optimization, and propose an efficient adaptive federated minimax optimization algorithm (i.e., AdaFGDA) to solve these distributed minimax problems. Specifically, our AdaFGDA builds on the momentum-based variance reduced and local-SGD techniques, and it can flexibly incorporate various adaptive learning rates by using the unified adaptive matrices. Theoretically, we provide a solid convergence analysis framework for our AdaFGDA algorithm under non-i.i.d. setting. Moreover, we prove our AdaFGDA algorithm obtains a lower gradient (i.e., stochastic first-order oracle, SFO) complexity of $\\tilde{O}(\\epsilon^{-3})$ with lower communication complexity of $\\tilde{O}(\\epsilon^{-2})$ in finding $\\epsilon$-stationary point of the nonconvex minimax problems. Experimentally, we conduct some experiments on the deep AUC maximization and robust neural network training tasks to verify efficiency of our algorithms.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "math.OC"
        ],
        "submitted_date": "14 Nov 2022",
        "last_revised_date": " "
    },
    "2212.10529": {
        "title": "Evaluating Psychological Safety of Large Language Models",
        "authors": [
            "Xingxuan Li",
            "Yutong Li",
            "Lin Qiu",
            "Shafiq Joty",
            "Lidong Bing"
        ],
        "comments": "Preprint. Under review",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "In this work, we designed unbiased prompts to systematically evaluate the psychological safety of large language models (LLMs). First, we tested five different LLMs by using two personality tests: Short Dark Triad (SD-3) and Big Five Inventory (BFI). All models scored higher than the human average on SD-3, suggesting a relatively darker personality pattern. Despite being instruction fine-tuned with safety metrics to reduce toxicity, InstructGPT, GPT-3.5, and GPT-4 still showed dark personality patterns; these models scored higher than self-supervised GPT-3 on the Machiavellianism and narcissism traits on SD-3. Then, we evaluated the LLMs in the GPT series by using well-being tests to study the impact of fine-tuning with more training data. We observed a continuous increase in the well-being scores of GPT models. Following these observations, we showed that fine-tuning Llama-2-chat-7B with responses from BFI using direct preference optimization could effectively reduce the psychological toxicity of the model. Based on the findings, we recommended the application of systematic and comprehensive psychological metrics to further evaluate and improve the safety of LLMs.\n    ",
        "primary_category": "cs.CL",
        "categories": [
            "cs.AI",
            "cs.CY"
        ],
        "submitted_date": "20 Dec 2022",
        "last_revised_date": " "
    },
    "2301.12584": {
        "title": "Fast Exact Leverage Score Sampling from Khatri-Rao Products with Applications to Tensor Decomposition",
        "authors": [
            "Vivek Bharadwaj",
            "Osman Asif Malik",
            "Riley Murray",
            "Laura Grigori",
            "Aydin Buluc",
            "James Demmel"
        ],
        "comments": "The 37th Conference on Neural Information Processing Systems (Neurips'23). 28 pages, 10 figures, 6 tables",
        "subjects": "Numerical Analysis (math.NA)",
        "abstract": "We present a data structure to randomly sample rows from the Khatri-Rao product of several matrices according to the exact distribution of its leverage scores. Our proposed sampler draws each row in time logarithmic in the height of the Khatri-Rao product and quadratic in its column count, with persistent space overhead at most the size of the input matrices. As a result, it tractably draws samples even when the matrices forming the Khatri-Rao product have tens of millions of rows each. When used to sketch the linear least squares problems arising in CANDECOMP / PARAFAC tensor decomposition, our method achieves lower asymptotic complexity per solve than recent state-of-the-art methods. Experiments on billion-scale sparse tensors validate our claims, with our algorithm achieving higher accuracy than competing methods as the decomposition rank grows.\n    ",
        "primary_category": "math.NA",
        "categories": [],
        "submitted_date": "29 Jan 2023",
        "last_revised_date": " "
    },
    "2302.02237": {
        "title": "Conformalized Semi-supervised Random Forest for Classification and Abnormality Detection",
        "authors": [
            "Yujin Han",
            "Mingwenchan Xu",
            "Leying Guan"
        ],
        "comments": " ",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "The Random Forests classifier, a widely utilized off-the-shelf classification tool, assumes training and test samples come from the same distribution as other standard classifiers. However, in safety-critical scenarios like medical diagnosis and network attack detection, discrepancies between the training and test sets, including the potential presence of novel outlier samples not appearing during training, can pose significant challenges. To address this problem, we introduce the Conformalized Semi-Supervised Random Forest (CSForest), which couples the conformalization technique Jackknife+aB with semi-supervised tree ensembles to construct a set-valued prediction $C(x)$. Instead of optimizing over the training distribution, CSForest employs unlabeled test samples to enhance accuracy and flag unseen outliers by generating an empty set. Theoretically, we establish CSForest to cover true labels for previously observed inlier classes under arbitrarily label-shift in the test data. We compare CSForest with state-of-the-art methods using synthetic examples and various real-world datasets, under different types of distribution changes in the test domain. Our results highlight CSForest's effective prediction of inliers and its ability to detect outlier samples unique to the test data. In addition, CSForest shows persistently good performance as the sizes of the training and test sets vary. Codes of CSForest are available at this https URL.\n    ",
        "primary_category": "cs.LG",
        "categories": [],
        "submitted_date": "4 Feb 2023",
        "last_revised_date": " "
    },
    "2302.04831": {
        "title": "Cooperative Open-ended Learning Framework for Zero-shot Coordination",
        "authors": [
            "Yang Li",
            "Shao Zhang",
            "Jichen Sun",
            "Yali Du",
            "Ying Wen",
            "Xinbing Wang",
            "Wei Pan"
        ],
        "comments": "15 pages with 9 pages main body",
        "subjects": "Artificial Intelligence (cs.AI)",
        "abstract": "Zero-shot coordination in cooperative artificial intelligence (AI) remains a significant challenge, which means effectively coordinating with a wide range of unseen partners. Previous algorithms have attempted to address this challenge by optimizing fixed objectives within a population to improve strategy or behaviour diversity. However, these approaches can result in a loss of learning and an inability to cooperate with certain strategies within the population, known as cooperative incompatibility. To address this issue, we propose the Cooperative Open-ended LEarning (COLE) framework, which constructs open-ended objectives in cooperative games with two players from the perspective of graph theory to assess and identify the cooperative ability of each strategy. We further specify the framework and propose a practical algorithm that leverages knowledge from game theory and graph theory. Furthermore, an analysis of the learning process of the algorithm shows that it can efficiently overcome cooperative incompatibility. The experimental results in the Overcooked game environment demonstrate that our method outperforms current state-of-the-art methods when coordinating with different-level partners. Our demo is available at this https URL.\n    ",
        "primary_category": "cs.AI",
        "categories": [
            "cs.LG"
        ],
        "submitted_date": "9 Feb 2023",
        "last_revised_date": " "
    },
    "2302.07457": {
        "title": "When Demonstrations Meet Generative World Models: A Maximum Likelihood Framework for Offline Inverse Reinforcement Learning",
        "authors": [
            "Siliang Zeng",
            "Chenliang Li",
            "Alfredo Garcia",
            "Mingyi Hong"
        ],
        "comments": " ",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Offline inverse reinforcement learning (Offline IRL) aims to recover the structure of rewards and environment dynamics that underlie observed actions in a fixed, finite set of demonstrations from an expert agent. Accurate models of expertise in executing a task has applications in safety-sensitive applications such as clinical decision making and autonomous driving. However, the structure of an expert's preferences implicit in observed actions is closely linked to the expert's model of the environment dynamics (i.e. the ``world'' model). Thus, inaccurate models of the world obtained from finite data with limited coverage could compound inaccuracy in estimated rewards. To address this issue, we propose a bi-level optimization formulation of the estimation task wherein the upper level is likelihood maximization based upon a conservative model of the expert's policy (lower level). The policy model is conservative in that it maximizes reward subject to a penalty that is increasing in the uncertainty of the estimated model of the world. We propose a new algorithmic framework to solve the bi-level optimization problem formulation and provide statistical and computational guarantees of performance for the associated optimal reward estimator. Finally, we demonstrate that the proposed algorithm outperforms the state-of-the-art offline IRL and imitation learning benchmarks by a large margin, over the continuous control tasks in MuJoCo and different datasets in the D4RL benchmark.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "15 Feb 2023",
        "last_revised_date": " "
    },
    "2303.00696": {
        "title": "Trust your source: quantifying source condition elements for variational regularisation methods",
        "authors": [
            "Martin Benning",
            "Tatiana A. Bubba",
            "Luca Ratti",
            "Danilo Riccio"
        ],
        "comments": " ",
        "subjects": "Numerical Analysis (math.NA)",
        "abstract": "Source conditions are a key tool in regularisation theory that are needed to derive error estimates and convergence rates for ill-posed inverse problems. In this paper, we provide a recipe to practically compute source condition elements as the solution of convex minimisation problems that can be solved with first-order algorithms. We demonstrate the validity of our approach by testing it on two inverse problem case studies in machine learning and image processing: sparse coefficient estimation of a polynomial via LASSO regression and recovering an image from a subset of the coefficients of its discrete Fourier transform. We further demonstrate that the proposed approach can easily be modified to solve the machine learning task of identifying the optimal sampling pattern in the Fourier domain for a given image and variational regularisation method, which has applications in the context of sparsity promoting reconstruction from magnetic resonance imaging data.\n    ",
        "primary_category": "math.NA",
        "categories": [],
        "submitted_date": "1 Mar 2023",
        "last_revised_date": " "
    },
    "2303.15687": {
        "title": "Switched Moving Boundary Modeling of Phase Change Thermal Energy Storage Systems",
        "authors": [
            "Trent J. Sakakini",
            "Justin P. Koeln"
        ],
        "comments": "7 pages, 6 figures",
        "subjects": "Systems and Control (eess.SY)",
        "abstract": "Thermal Energy Storage (TES) devices, which leverage the constant-temperature thermal capacity of the latent heat of a Phase Change Material (PCM), provide benefits to a variety of thermal management systems by decoupling the absorption and rejection of thermal energy. While performing a role similar to a battery in an electrical system, it is critical to know when to charge (freeze) and discharge (melt) the TES to maximize the capabilities and efficiency of the overall system. Therefore, control-oriented models of TES are needed to predict the behavior of the TES and make informed control decisions. While existing modeling approaches divide the TES in to multiple sections using a Fixed Grid (FG) approach, this paper proposes a switched Moving Boundary (MB) model that captures the key dynamics of the TES with significantly fewer dynamic states. Specifically, a graph-based modeling approach is used to model the heat flow through the TES and a MB approach is used to model the time-varying liquid and solid regions of the TES. Additionally, a Finite State Machine (FSM) is used to switch between four different modes of operation based on the State-of-Charge (SOC) of the TES. Numerical simulations comparing the proposed approach with a more traditional FG approach show that the MB model is capable of accurately modeling the behavior of the FG model while using far fewer states, leading to five times faster simulations.\n    ",
        "primary_category": "eess.SY",
        "categories": [],
        "submitted_date": "28 Mar 2023",
        "last_revised_date": " "
    },
    "2303.17355": {
        "title": "Acoustic Soft Tactile Skin (AST Skin)",
        "authors": [
            "Vishnu Rajendran S",
            "Willow Mandil",
            "Simon Parsons",
            "Amir Ghalamzan E"
        ],
        "comments": "IEEE International Conference on Robotics and Automation (ICRA) 2024 (accepted)",
        "subjects": "Robotics (cs.RO)",
        "abstract": "This paper presents a novel soft tactile skin (STS) technology operating with sound waves. In this innovative approach, the sound waves generated by a speaker travel in channels embedded in a soft membrane and get modulated due to a deformation of the channel when pressed by an external force and received by a microphone at the end of the channel. The sensor leverages regression and classification methods for estimating the normal force and its contact location. Our sensor can be affixed to any robot part, e.g., end effectors or arm. We tested several regression and classifier methods to learn the relation between sound wave modulation, the applied force, and its location, respectively and picked the best-performing models for force and location predictions. Our novel tactile sensor yields 93% of the force estimation within 1.5 N tolerances for a range of 0-30+1 N and estimates contact locations with over 96% accuracy. We also demonstrated the performance of STS technology for a real-time gripping force control application.\n    ",
        "primary_category": "cs.RO",
        "categories": [],
        "submitted_date": "30 Mar 2023",
        "last_revised_date": " "
    },
    "2303.17674": {
        "title": "Convex Hulls of Reachable Sets",
        "authors": [
            "Thomas Lew",
            "Riccardo Bonalli",
            "Marco Pavone"
        ],
        "comments": "19 pages. Submitted to the IEEE Transactions on Automatic Control. Substantial extension of arXiv:2303.17674v2",
        "subjects": "Optimization and Control (math.OC)",
        "abstract": "We study the convex hulls of reachable sets of nonlinear systems with bounded disturbances and uncertain initial conditions. Reachable sets play a critical role in control, but remain notoriously challenging to compute, and existing over-approximation tools tend to be conservative or computationally expensive. In this work, we characterize the convex hulls of reachable sets as the convex hulls of solutions of an ordinary differential equation with initial conditions on the sphere. This finite-dimensional characterization unlocks an efficient sampling-based estimation algorithm to accurately over-approximate reachable sets. We also study the structure of the boundary of the reachable convex hulls and derive error bounds for the estimation algorithm. We give applications to neural feedback loop analysis and robust MPC.\n    ",
        "primary_category": "math.OC",
        "categories": [
            "cs.LG",
            "cs.RO",
            "eess.SY"
        ],
        "submitted_date": "30 Mar 2023",
        "last_revised_date": " "
    },
    "2304.00933": {
        "title": "Knowledge Accumulation in Continually Learned Representations and the Issue of Feature Forgetting",
        "authors": [
            "Timm Hess",
            "Eli Verwimp",
            "Gido M. van de Ven",
            "Tinne Tuytelaars"
        ],
        "comments": " ",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Continual learning research has shown that neural networks suffer from catastrophic forgetting \"at the output level\", but it is debated whether this is also the case at the level of learned representations. Multiple recent studies ascribe representations a certain level of innate robustness against forgetting - that they only forget minimally and no critical information. We revisit and expand upon the experiments that revealed this difference in forgetting and illustrate the coexistence of two phenomena that affect the quality of continually learned representations: knowledge accumulation and feature forgetting. Carefully taking both aspects into account, we show that, even though it is true that feature forgetting can be small in absolute terms, newly learned information tends to be forgotten just as catastrophically at the level of the representation as it is at the output level. Next we show that this feature forgetting is problematic as it substantially slows down knowledge accumulation. Finally, we study how feature forgetting and knowledge accumulation are affected by different types of continual learning methods.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.CV"
        ],
        "submitted_date": "3 Apr 2023",
        "last_revised_date": " "
    },
    "2304.05805": {
        "title": "GDP nowcasting with artificial neural networks: How much does long-term memory matter?",
        "authors": [
            "Krist\u00f3f N\u00e9meth",
            "D\u00e1niel Hadh\u00e1zi"
        ],
        "comments": "arXiv admin note: text overlap with arXiv:2106.08901 by other authors",
        "subjects": "Econometrics (econ.EM)",
        "abstract": "We apply artificial neural networks (ANNs) to nowcast quarterly GDP growth for the U.S. economy. Using the monthly FRED-MD database, we compare the nowcasting performance of five different ANN architectures: the multilayer perceptron (MLP), the one-dimensional convolutional neural network (1D CNN), the Elman recurrent neural network (RNN), the long short-term memory network (LSTM), and the gated recurrent unit (GRU). The empirical analysis presents results from two distinctively different evaluation periods. The first (2012:Q1 -- 2019:Q4) is characterized by balanced economic growth, while the second (2012:Q1 -- 2022:Q4) also includes periods of the COVID-19 recession. According to our results, longer input sequences result in more accurate nowcasts in periods of balanced economic growth. However, this effect ceases above a relatively low threshold value of around six quarters (eighteen months). During periods of economic turbulence (e.g., during the COVID-19 recession), longer input sequences do not help the models' predictive performance; instead, they seem to weaken their generalization capability. Combined results from the two evaluation periods indicate that architectural features enabling long-term memory do not result in more accurate nowcasts. Comparing network architectures, the 1D CNN has proved to be a highly suitable model for GDP nowcasting. The network has shown good nowcasting performance among the competitors during the first evaluation period and achieved the overall best accuracy during the second evaluation period. Consequently, first in the literature, we propose the application of the 1D CNN for economic nowcasting.\n    ",
        "primary_category": "econ.EM",
        "categories": [
            "cs.AI",
            "cs.LG"
        ],
        "submitted_date": "12 Apr 2023",
        "last_revised_date": " "
    },
    "2304.09248": {
        "title": "Real-Time Helmet Violation Detection in AI City Challenge 2023 with Genetic Algorithm-Enhanced YOLOv5",
        "authors": [
            "Elham Soltanikazemi",
            "Ashwin Dhakal",
            "Bijaya Kumar Hatuwal",
            "Imad Eddine Toubal",
            "Armstrong Aboah",
            "Kannappan Palaniappan"
        ],
        "comments": " ",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "This research focuses on real-time surveillance systems as a means for tackling the issue of non-compliance with helmet regulations, a practice that considerably amplifies the risk for motorcycle drivers or riders. Despite the well-established advantages of helmet usage, achieving widespread compliance remains challenging due to diverse contributing factors. To effectively address this concern, real-time monitoring and enforcement of helmet laws have been proposed as a plausible solution. However, previous attempts at real-time helmet violation detection have been hindered by their limited ability to operate in real-time. To overcome this limitation, the current paper introduces a novel real-time helmet violation detection system that utilizes the YOLOv5 single-stage object detection model. This model is trained on the 2023 NVIDIA AI City Challenge 2023 Track 5 dataset. The optimal hyperparameters for training the model are determined using genetic algorithms. Additionally, data augmentation and various sampling techniques are implemented to enhance the model's performance. The efficacy of the models is evaluated using precision, recall, and mean Average Precision (mAP) metrics. The results demonstrate impressive precision, recall, and mAP scores of 0.848, 0.599, and 0.641, respectively for the training data. Furthermore, the model achieves notable mAP score of 0.6667 for the test datasets, leading to a commendable 4th place rank in the public leaderboard. This innovative approach represents a notable breakthrough in the field and holds immense potential to substantially enhance motorcycle safety. By enabling real-time monitoring and enforcement capabilities, this system has the capacity to contribute towards increased compliance with helmet laws, thereby effectively reducing the risks faced by motorcycle riders and passengers.\n    ",
        "primary_category": "cs.CV",
        "categories": [],
        "submitted_date": "13 Apr 2023",
        "last_revised_date": " "
    },
    "2304.10398": {
        "title": "Multi-label Node Classification On Graph-Structured Data",
        "authors": [
            "Tianqi Zhao",
            "Ngan Thi Dong",
            "Alan Hanjalic",
            "Megha Khosla"
        ],
        "comments": "Published in TMLR 2023. Link: this https URL",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Graph Neural Networks (GNNs) have shown state-of-the-art improvements in node classification tasks on graphs. While these improvements have been largely demonstrated in a multi-class classification scenario, a more general and realistic scenario in which each node could have multiple labels has so far received little attention. The first challenge in conducting focused studies on multi-label node classification is the limited number of publicly available multi-label graph datasets. Therefore, as our first contribution, we collect and release three real-world biological datasets and develop a multi-label graph generator to generate datasets with tunable properties. While high label similarity (high homophily) is usually attributed to the success of GNNs, we argue that a multi-label scenario does not follow the usual semantics of homophily and heterophily so far defined for a multi-class scenario. As our second contribution, we define homophily and Cross-Class Neighborhood Similarity for the multi-label scenario and provide a thorough analyses of the collected $9$ multi-label datasets. Finally, we perform a large-scale comparative study with $8$ methods and $9$ datasets and analyse the performances of the methods to assess the progress made by current state of the art in the multi-label node classification scenario. We release our benchmark at this https URL.\n    ",
        "primary_category": "cs.LG",
        "categories": [],
        "submitted_date": "20 Apr 2023",
        "last_revised_date": " "
    },
    "2305.02215": {
        "title": "Exploring Linguistic Properties of Monolingual BERTs with Typological Classification among Languages",
        "authors": [
            "Elena Sofia Ruzzetti",
            "Federico Ranaldi",
            "Felicia Logozzo",
            "Michele Mastromattei",
            "Leonardo Ranaldi",
            "Fabio Massimo Zanzotto"
        ],
        "comments": " ",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "The impressive achievements of transformers force NLP researchers to delve into how these models represent the underlying structure of natural language. In this paper, we propose a novel standpoint to investigate the above issue: using typological similarities among languages to observe how their respective monolingual models encode structural information. We aim to layer-wise compare transformers for typologically similar languages to observe whether these similarities emerge for particular layers. For this investigation, we propose to use Centered Kernel Alignment to measure similarity among weight matrices. We found that syntactic typological similarity is consistent with the similarity between the weights in the middle layers, which are the pretrained BERT layers to which syntax encoding is generally attributed. Moreover, we observe that a domain adaptation on semantically equivalent texts enhances this similarity among weight matrices.\n    ",
        "primary_category": "cs.CL",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "3 May 2023",
        "last_revised_date": " "
    },
    "2305.02531": {
        "title": "Can LLMs Capture Human Preferences?",
        "authors": [
            "Ali Goli",
            "Amandeep Singh"
        ],
        "comments": " ",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "We explore the viability of Large Language Models (LLMs), specifically OpenAI's GPT-3.5 and GPT-4, in emulating human survey respondents and eliciting preferences, with a focus on intertemporal choices. Leveraging the extensive literature on intertemporal discounting for benchmarking, we examine responses from LLMs across various languages and compare them to human responses, exploring preferences between smaller, sooner, and larger, later rewards. Our findings reveal that both GPT models demonstrate less patience than humans, with GPT-3.5 exhibiting a lexicographic preference for earlier rewards, unlike human decision-makers. Though GPT-4 does not display lexicographic preferences, its measured discount rates are still considerably larger than those found in humans. Interestingly, GPT models show greater patience in languages with weak future tense references, such as German and Mandarin, aligning with existing literature that suggests a correlation between language structure and intertemporal preferences. We demonstrate how prompting GPT to explain its decisions, a procedure we term \"chain-of-thought conjoint,\" can mitigate, but does not eliminate, discrepancies between LLM and human responses. While directly eliciting preferences using LLMs may yield misleading results, combining chain-of-thought conjoint with topic modeling aids in hypothesis generation, enabling researchers to explore the underpinnings of preferences. Chain-of-thought conjoint provides a structured framework for marketers to use LLMs to identify potential attributes or factors that can explain preference heterogeneity across different customers and contexts.\n    ",
        "primary_category": "cs.CL",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "4 May 2023",
        "last_revised_date": " "
    },
    "2305.04666": {
        "title": "Power Distribution Grid Enhancement via Online Feedback Optimization",
        "authors": [
            "Jonas G. Matt",
            "Lukas Ortmann",
            "Saverio Bolognani",
            "Florian D\u00f6rfler"
        ],
        "comments": " ",
        "subjects": "Systems and Control (eess.SY)",
        "abstract": "The rise in residential photovoltaics and other distributed energy sources poses unprecedented challenges for the operation of power distribution grids. When high amounts of active power are injected into the grid by such power sources, the overall power flow is often limited because of voltages reaching their upper acceptable limits. Volt/VAr control aims to raise this power flow limit by controlling the voltage using reactive power. This way, more active power can be transmitted safely without physically reinforcing the grid. In this paper, we use real consumption and generation data on a low-voltage CIGR\u00c9 grid model and an experiment on a real distribution grid feeder to analyze how different Volt/VAr methods can enhance grid capacity, i.e., by how much they can improve the grid's capability to transmit active power without building new lines. We show that droop control enhances the grid but vastly underutilizes the reactive power resources. We discuss how the effectiveness of droop control can be partially improved by employing machine-learning techniques to tune the droop coefficients, but we demonstrate that local control laws are inherently unable to achieve optimal grid enhancement. In contrast, methods that coordinate the use of reactive power resources across the grid, such as Online Feedback Optimization (OFO), can enhance the grid to its full potential. A numerical study performed on data from an entire year using a realistic grid model suggests that OFO can enable another 9\\% of maximum active power injections compared to droop control. To achieve that, OFO only requires voltage magnitude measurements, minimal model knowledge, and communication with the reactive power sources. A real-life experiment provides a demonstration of the practical feasibility of the proposed approach and enhanced the grid by another 10.5\\% compared to droop control.\n    ",
        "primary_category": "eess.SY",
        "categories": [],
        "submitted_date": "8 May 2023",
        "last_revised_date": " "
    },
    "2305.06548": {
        "title": "Layered Modal Type Theories",
        "authors": [
            "Jason Z. S. Hu",
            "Brigitte Pientka"
        ],
        "comments": " ",
        "subjects": "Logic in Computer Science (cs.LO)",
        "abstract": "We introduce layers to modal type theories, which subsequently enables type theories for pattern matching on code in meta-programming and clean and straightforward semantics.\n    ",
        "primary_category": "cs.LO",
        "categories": [
            "cs.PL"
        ],
        "submitted_date": "11 May 2023",
        "last_revised_date": " "
    },
    "2305.08381": {
        "title": "Parameter-efficient Tuning of Large-scale Multimodal Foundation Model",
        "authors": [
            "Haixin Wang",
            "Xinlong Yang",
            "Jianlong Chang",
            "Dian Jin",
            "Jinan Sun",
            "Shikun Zhang",
            "Xiao Luo",
            "Qi Tian"
        ],
        "comments": "Accepted by NeurIPS2023",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Driven by the progress of large-scale pre-training, parameter-efficient transfer learning has gained immense popularity across different subfields of Artificial Intelligence. The core is to adapt the model to downstream tasks with only a small set of parameters. Recently, researchers have leveraged such proven techniques in multimodal tasks and achieve promising results. However, two critical issues remain unresolved: how to further reduce the complexity with lightweight design and how to boost alignment between modalities under extremely low parameters. In this paper, we propose A graceful prompt framework for cross-modal transfer (Aurora) to overcome these challenges. Considering the redundancy in existing architectures, we first utilize the mode approximation to generate 0.1M trainable parameters to implement the multimodal prompt tuning, which explores the low intrinsic dimension with only 0.04% parameters of the pre-trained model. Then, for better modality alignment, we propose the Informative Context Enhancement and Gated Query Transformation module under extremely few parameters scenes. A thorough evaluation on six cross-modal benchmarks shows that it not only outperforms the state-of-the-art but even outperforms the full fine-tuning approach. Our code is available at: this https URL.\n    ",
        "primary_category": "cs.CV",
        "categories": [],
        "submitted_date": "15 May 2023",
        "last_revised_date": " "
    },
    "2305.08460": {
        "title": "Selective Population Protocols",
        "authors": [
            "Adam Ga\u0144czorz",
            "Leszek G\u0105sieniec",
            "Tomasz Jurdzi\u0144ski",
            "Jakub Kowalski",
            "Grzegorz Stachowiak"
        ],
        "comments": " ",
        "subjects": "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "abstract": "The model of population protocols provides a universal platform to study distributed processes driven by pairwise interactions of anonymous agents. While population protocols present an elegant and robust model for randomized distributed computation, their efficiency wanes when tackling issues that require more focused communication or the execution of multiple processes. To address this issue, we propose a new, selective variant of population protocols by introducing a partition of the state space and the corresponding conditional selection of responders. We demonstrate on several examples that the new model offers a natural environment, complete with tools and a high-level description, to facilitate more efficient solutions.\nIn particular, we provide fixed-state stable and efficient solutions to two central problems: leader election and majority computation, both with confirmation. This constitutes a separation result, as achieving stable and efficient majority computation requires $\\Omega(\\log n)$ states in standard population protocols, even when the leader is already determined. Additionally, we explore the computation of the median using the comparison model, where the operational state space of agents is fixed, and the transition function determines the order between (arbitrarily large) hidden keys associated with interacting agents. Our findings reveal that the computation of the median of $n$ numbers requires $\\Omega(n)$ time. Moreover, we demonstrate that the problem can be solved in $O(n\\log n)$ time, both in expectation and with high probability, in standard population protocols. In contrast, we establish that a feasible solution in selective population protocols can be achieved in $O(\\log^4 n)$ time.\n    ",
        "primary_category": "cs.DC",
        "categories": [
            "cs.DS"
        ],
        "submitted_date": "15 May 2023",
        "last_revised_date": " "
    },
    "2305.09675": {
        "title": "Spatial Computing Opportunities in Biomedical Decision Support: The Atlas-EHR Vision",
        "authors": [
            "Majid Farhadloo",
            "Arun Sharma",
            "Shashi Shekhar",
            "Svetomir N. Markovic"
        ],
        "comments": " ",
        "subjects": "Computers and Society (cs.CY)",
        "abstract": "We consider the problem of reducing the time needed by healthcare professionals to understand patient medical history via the next generation of biomedical decision support. This problem is societally important because it has the potential to improve healthcare quality and patient outcomes. However, navigating electronic health records is challenging due to the high patient-doctor ratios, potentially long medical histories, the urgency of treatment for some medical conditions, and patient variability. The current electronic health record systems provides only a longitudinal view of patient medical history, which is time-consuming to browse, and doctors often need to engage nurses, residents, and others for initial analysis. To overcome this limitation, we envision an alternative spatial representation of patients' histories (e.g., electronic health records (EHRs)) and other biomedical data in the form of Atlas-EHR. Just like Google Maps allows a global, national, regional, and local view, the Atlas-EHR may start with an overview of the patient's anatomy and history before drilling down to spatially anatomical sub-systems, their individual components, or sub-components. Atlas-EHR presents a compelling opportunity for spatial computing since healthcare is almost a fifth of the US economy. However, the traditional spatial computing designed for geographic use cases (e.g., navigation, land-surveys, mapping) faces many hurdles in the biomedical domain. This paper presents a number of open research questions under this theme in five broad areas of spatial computing.\n    ",
        "primary_category": "cs.CY",
        "categories": [],
        "submitted_date": "9 May 2023",
        "last_revised_date": " "
    },
    "2305.10361": {
        "title": "Human Choice Prediction in Language-based Persuasion Games: Simulation-based Off-Policy Evaluation",
        "authors": [
            "Eilam Shapira",
            "Reut Apel",
            "Moshe Tennenholtz",
            "Roi Reichart"
        ],
        "comments": " ",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Recent advances in Large Language Models (LLMs) have spurred interest in designing LLM-based agents for tasks that involve interaction with human and artificial agents. This paper addresses a key aspect in the design of such agents: Predicting human decision in off-policy evaluation (OPE), focusing on language-based persuasion games, where the agent's goal is to influence its partner's decisions through verbal messages. Using a dedicated application, we collected a dataset of 87K decisions from humans playing a repeated decision-making game with artificial agents. Our approach involves training a model on human interactions with one agents subset to predict decisions when interacting with another. To enhance off-policy performance, we propose a simulation technique involving interactions across the entire agent space and simulated decision makers. Our learning strategy yields significant OPE gains, e.g., improving prediction accuracy in the top 15% challenging cases by 7.1%. Our code and the large dataset we collected and generated are submitted as supplementary material and publicly available in our GitHub repository: this https URL\n",
        "primary_category": "cs.LG",
        "categories": [
            "cs.AI",
            "cs.GT"
        ],
        "submitted_date": "17 May 2023",
        "last_revised_date": " "
    },
    "2305.11461": {
        "title": "Hint of Thought prompting: an explainable and zero-shot approach to reasoning tasks with LLMs",
        "authors": [
            "Ioktong Lei",
            "Zhidong Deng"
        ],
        "comments": "preprint, under review",
        "subjects": "Artificial Intelligence (cs.AI)",
        "abstract": "As a way of communicating with users and any LLMs like GPT or PaLM2, prompting becomes an increasingly important research topic for better utilization of LLMs. Although simple prompting performs well on single-step questions, it cannot permanently activate the correct knowledge path for multi-step reasoning tasks. The chain of thought (CoT), which often contains zero-shot CoT and few-shot CoT, is a recently developed prompting method that can explain the reasoning process to the LLM and outperforms simple prompting in three challenging reasoning tasks, including arithmetic, symbolic, and commonsense reasoning. In this paper, we propose a novel hint of thought (HoT) prompting with explainability and zero-shot generalization. First, it is decomposed into the following three steps: explainable sub-questions, logical reasoning, and answer extraction. Second, such three steps are sequentially ordered in the format of step-by-step hints, which can be easily adjusted and explained to different tasks. Finally, experimental results demonstrate that our HoT prompting has a significant advantage on the zero-shot reasoning task compared to existing zero-shot CoT. We did zero-shot experiments on math tasks like GSM8K, ADDSUB, AQUA, SVAMP and commonsense tasks such as StrategyQA. In particular, the accuracy of the proposed HoT prompting is improved with GSM8K from 40.50% to 67.80%, with AQUA from 31.9% to 46.4%, with SVAMP from 63.7% to 76.9%, and with ADDSUB from 74.7% to 87.34%, respectively, which even defeats the competitive PoT approach on GSM8k, AQUA, and SVAMP.\n    ",
        "primary_category": "cs.AI",
        "categories": [],
        "submitted_date": "19 May 2023",
        "last_revised_date": " "
    },
    "2305.15560": {
        "title": "Differentially Private Synthetic Data via Foundation Model APIs 1: Images",
        "authors": [
            "Zinan Lin",
            "Sivakanth Gopi",
            "Janardhan Kulkarni",
            "Harsha Nori",
            "Sergey Yekhanin"
        ],
        "comments": "49 pages, 42 figures",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Generating differentially private (DP) synthetic data that closely resembles the original private data is a scalable way to mitigate privacy concerns in the current data-driven world. In contrast to current practices that train customized models for this task, we aim to generate DP Synthetic Data via APIs (DPSDA), where we treat foundation models as blackboxes and only utilize their inference APIs. Such API-based, training-free approaches are easier to deploy as exemplified by the recent surge in the number of API-based apps. These approaches can also leverage the power of large foundation models which are only accessible via their inference APIs. However, this comes with greater challenges due to strictly more restrictive model access and the need to protect privacy from the API provider.\nIn this paper, we present a new framework called Private Evolution (PE) to solve this problem and show its initial promise on synthetic images. Surprisingly, PE can match or even outperform state-of-the-art (SOTA) methods without any model training. For example, on CIFAR10 (with ImageNet as the public data), we achieve FID <= 7.9 with privacy cost {\\epsilon} = 0.67, significantly improving the previous SOTA from {\\epsilon} = 32. We further demonstrate the promise of applying PE on large foundation models such as Stable Diffusion to tackle challenging private datasets with a small number of high-resolution images. The code and data are released at this https URL.\n    ",
        "primary_category": "cs.CV",
        "categories": [
            "cs.CR",
            "cs.LG"
        ],
        "submitted_date": "24 May 2023",
        "last_revised_date": " "
    },
    "2306.00950": {
        "title": "Differential Diffusion: Giving Each Pixel Its Strength",
        "authors": [
            "Eran Levin",
            "Ohad Fried"
        ],
        "comments": "Project Page: this https URL",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Diffusion models have revolutionized image generation and editing, producing state-of-the-art results in conditioned and unconditioned image synthesis. While current techniques enable user control over the degree of change in an image edit, the controllability is limited to global changes over an entire edited region. This paper introduces a novel framework that enables customization of the amount of change per pixel or per image region. Our framework can be integrated into any existing diffusion model, enhancing it with this capability. Such granular control on the quantity of change opens up a diverse array of new editing capabilities, such as control of the extent to which individual objects are modified, or the ability to introduce gradual spatial changes. Furthermore, we showcase the framework's effectiveness in soft-inpainting -- the completion of portions of an image while subtly adjusting the surrounding areas to ensure seamless integration. Additionally, we introduce a new tool for exploring the effects of different change quantities. Our framework operates solely during inference, requiring no model training or fine-tuning. We demonstrate our method with the current open state-of-the-art models, and validate it via both quantitative and qualitative comparisons, and a user study. Our code is available at: this https URL\n",
        "primary_category": "cs.CV",
        "categories": [
            "cs.AI",
            "cs.GR",
            "cs.LG"
        ],
        "submitted_date": "1 Jun 2023",
        "last_revised_date": " "
    },
    "2306.00964": {
        "title": "Cocktail: Mixing Multi-Modality Controls for Text-Conditional Image Generation",
        "authors": [
            "Minghui Hu",
            "Jianbin Zheng",
            "Daqing Liu",
            "Chuanxia Zheng",
            "Chaoyue Wang",
            "Dacheng Tao",
            "Tat-Jen Cham"
        ],
        "comments": "Project Page: this https URL",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Text-conditional diffusion models are able to generate high-fidelity images with diverse contents. However, linguistic representations frequently exhibit ambiguous descriptions of the envisioned objective imagery, requiring the incorporation of additional control signals to bolster the efficacy of text-guided diffusion models. In this work, we propose Cocktail, a pipeline to mix various modalities into one embedding, amalgamated with a generalized ControlNet (gControlNet), a controllable normalisation (ControlNorm), and a spatial guidance sampling method, to actualize multi-modal and spatially-refined control for text-conditional diffusion models. Specifically, we introduce a hyper-network gControlNet, dedicated to the alignment and infusion of the control signals from disparate modalities into the pre-trained diffusion model. gControlNet is capable of accepting flexible modality signals, encompassing the simultaneous reception of any combination of modality signals, or the supplementary fusion of multiple modality signals. The control signals are then fused and injected into the backbone model according to our proposed ControlNorm. Furthermore, our advanced spatial guidance sampling methodology proficiently incorporates the control signal into the designated region, thereby circumventing the manifestation of undesired objects within the generated image. We demonstrate the results of our method in controlling various modalities, proving high-quality synthesis and fidelity to multiple external signals.\n    ",
        "primary_category": "cs.CV",
        "categories": [
            "cs.LG"
        ],
        "submitted_date": "1 Jun 2023",
        "last_revised_date": " "
    },
    "2306.01665": {
        "title": "SourceP: Detecting Ponzi Schemes on Ethereum with Source Code",
        "authors": [
            "Pengcheng Lu",
            "Liang Cai",
            "Keting Yin"
        ],
        "comments": "12 pages, 5 figures, 4 tables",
        "subjects": "Software Engineering (cs.SE)",
        "abstract": "As blockchain technology becomes more and more popular, a typical financial scam, the Ponzi scheme, has also emerged in the blockchain platform Ethereum. This Ponzi scheme deployed through smart contracts, also known as the smart Ponzi scheme, has caused a lot of economic losses and negative impacts. Existing methods for detecting smart Ponzi schemes on Ethereum mainly rely on bytecode features, opcode features, account features, and transaction behavior features of smart contracts, which are unable to truly characterize the behavioral features of Ponzi schemes, and thus generally perform poorly in terms of detection accuracy and false alarm rates. In this paper, we propose SourceP, a method to detect smart Ponzi schemes on the Ethereum platform using pre-trained models and data flow, which only requires using the source code of smart contracts as features. SourceP reduces the difficulty of data acquisition and feature extraction of existing detection methods. Specifically, we first convert the source code of a smart contract into a data flow graph and then introduce a pre-trained model based on learning code representations to build a classification model to identify Ponzi schemes in smart contracts. The experimental results show that SourceP achieves 87.2% recall and 90.7% F-score for detecting smart Ponzi schemes within Ethereum's smart contract dataset, outperforming state-of-the-art methods in terms of performance and sustainability. We also demonstrate through additional experiments that pre-trained models and data flow play an important contribution to SourceP, as well as proving that SourceP has a good generalization ability.\n    ",
        "primary_category": "cs.SE",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "2 Jun 2023",
        "last_revised_date": " "
    },
    "2306.03034": {
        "title": "Tackling Cooperative Incompatibility for Zero-Shot Human-AI Coordination",
        "authors": [
            "Yang Li",
            "Shao Zhang",
            "Jichen Sun",
            "Wenhao Zhang",
            "Yali Du",
            "Ying Wen",
            "Xinbing Wang",
            "Wei Pan"
        ],
        "comments": "46 pages. arXiv admin note: substantial text overlap with arXiv:2302.04831",
        "subjects": "Artificial Intelligence (cs.AI)",
        "abstract": "Securing coordination between AI agent and teammates (human players or AI agents) in contexts involving unfamiliar humans continues to pose a significant challenge in Zero-Shot Coordination. The issue of cooperative incompatibility becomes particularly prominent when an AI agent is unsuccessful in synchronizing with certain previously unknown partners. Traditional algorithms have aimed to collaborate with partners by optimizing fixed objectives within a population, fostering diversity in strategies and behaviors. However, these techniques may lead to learning loss and an inability to cooperate with specific strategies within the population, a phenomenon named cooperative incompatibility in learning. In order to solve cooperative incompatibility in learning and effectively address the problem in the context of ZSC, we introduce the Cooperative Open-ended LEarning (COLE) framework, which formulates open-ended objectives in cooperative games with two players using perspectives of graph theory to evaluate and pinpoint the cooperative capacity of each strategy. We present two practical algorithms, specifically \\algo and \\algoR, which incorporate insights from game theory and graph theory. We also show that COLE could effectively overcome the cooperative incompatibility from theoretical and empirical analysis. Subsequently, we created an online Overcooked human-AI experiment platform, the COLE platform, which enables easy customization of questionnaires, model weights, and other aspects. Utilizing the COLE platform, we enlist 130 participants for human experiments. Our findings reveal a preference for our approach over state-of-the-art methods using a variety of subjective metrics. Moreover, objective experimental outcomes in the Overcooked game environment indicate that our method surpasses existing ones when coordinating with previously unencountered AI agents and the human proxy model.\n    ",
        "primary_category": "cs.AI",
        "categories": [
            "cs.HC"
        ],
        "submitted_date": "5 Jun 2023",
        "last_revised_date": " "
    },
    "2306.15012": {
        "title": "Statistical Component Separation for Targeted Signal Recovery in Noisy Mixtures",
        "authors": [
            "Bruno R\u00e9galdo-Saint Blancard",
            "Michael Eickenberg"
        ],
        "comments": "13+17 pages, 6+8 figures, published in TMLR, code: this https URL",
        "subjects": "Machine Learning (stat.ML)",
        "abstract": "Separating signals from an additive mixture may be an unnecessarily hard problem when one is only interested in specific properties of a given signal. In this work, we tackle simpler \"statistical component separation\" problems that focus on recovering a predefined set of statistical descriptors of a target signal from a noisy mixture. Assuming access to samples of the noise process, we investigate a method devised to match the statistics of the solution candidate corrupted by noise samples with those of the observed mixture. We first analyze the behavior of this method using simple examples with analytically tractable calculations. Then, we apply it in an image denoising context employing 1) wavelet-based descriptors, 2) ConvNet-based descriptors on astrophysics and ImageNet data. In the case of 1), we show that our method better recovers the descriptors of the target data than a standard denoising method in most situations. Additionally, despite not constructed for this purpose, it performs surprisingly well in terms of peak signal-to-noise ratio on full signal reconstruction. In comparison, representation 2) appears less suitable for image denoising. Finally, we extend this method by introducing a diffusive stepwise algorithm which gives a new perspective to the initial method and leads to promising results for image denoising under specific circumstances.\n    ",
        "primary_category": "stat.ML",
        "categories": [
            "astro-ph.IM",
            "cs.LG",
            "eess.SP"
        ],
        "submitted_date": "26 Jun 2023",
        "last_revised_date": " "
    },
    "2306.16891": {
        "title": "Harnessing the Power of Hugging Face Transformers for Predicting Mental Health Disorders in Social Networks",
        "authors": [
            "Alireza Pourkeyvan",
            "Ramin Safa",
            "Ali Sorourkhah"
        ],
        "comments": "19 pages, 5 figures",
        "subjects": "Information Retrieval (cs.IR)",
        "abstract": "Early diagnosis of mental disorders and intervention can facilitate the prevention of severe injuries and the improvement of treatment results. Using social media and pre-trained language models, this study explores how user-generated data can be used to predict mental disorder symptoms. Our study compares four different BERT models of Hugging Face with standard machine learning techniques used in automatic depression diagnosis in recent literature. The results show that new models outperform the previous approach with an accuracy rate of up to 97%. Analyzing the results while complementing past findings, we find that even tiny amounts of data (like users' bio descriptions) have the potential to predict mental disorders. We conclude that social media data is an excellent source of mental health screening, and pre-trained models can effectively automate this critical task.\n    ",
        "primary_category": "cs.IR",
        "categories": [
            "cs.AI",
            "cs.HC"
        ],
        "submitted_date": "29 Jun 2023",
        "last_revised_date": " "
    },
    "2307.01412": {
        "title": "Constant-time edge label and leaf pointer maintenance on sliding suffix trees",
        "authors": [
            "Laurentius Leonard",
            "Shunsuke Inenaga",
            "Hideo Bannai",
            "Takuya Mieno"
        ],
        "comments": " ",
        "subjects": "Data Structures and Algorithms (cs.DS)",
        "abstract": "Sliding suffix trees (Fiala & Greene, 1989) for an input text $T$ over an alphabet of size $\\sigma$ and a sliding window $W$ of $T$ can be maintained in $O(|T| \\log \\sigma)$ time and $O(|W|)$ space. The two previous approaches that achieve this can be categorized into the credit-based approach of Fiala and Greene (1989) and Larsson (1996, 1999), or the batch-based approach proposed by Senft (2005). Brodnik and Jekovec (2018) showed that the sliding suffix tree can be supplemented with leaf pointers in order to find all occurrences of an online query pattern in the current window, and that leaf pointers can be maintained by credit-based arguments as well. The main difficulty in the credit-based approach is in the maintenance of index-pairs that represent each edge. In this paper, we show that valid edge index-pairs can be derived in constant time from leaf pointers, thus reducing the maintenance of edge index-pairs to the maintenance of leaf pointers. We further propose a new simple method that maintains leaf pointers without using credit-based arguments. The lack of credit-based arguments allow a simpler proof of correctness compared to the credit-based approach, whose analyses were initially flawed (Senft 2005). In addition, our method reduces the worst-case time of leaf pointer and edge label maintenance per leaf insertion and deletion from $\\Theta(|W|)$ time to $O(1)$ time.\n    ",
        "primary_category": "cs.DS",
        "categories": [],
        "submitted_date": "4 Jul 2023",
        "last_revised_date": " "
    },
    "2307.02140": {
        "title": "Towards Open Federated Learning Platforms: Survey and Vision from Technical and Legal Perspectives",
        "authors": [
            "Moming Duan",
            "Qinbin Li",
            "Linshan Jiang",
            "Bingsheng He"
        ],
        "comments": "Download Appendix from this https URL",
        "subjects": "Software Engineering (cs.SE)",
        "abstract": "Traditional Federated Learning (FL) follows a server-dominated cooperation paradigm which narrows the application scenarios of FL and decreases the enthusiasm of data holders to participate. To fully unleash the potential of FL, we advocate rethinking the design of current FL frameworks and extending it to a more generalized concept: Open Federated Learning Platforms, positioned as a crowdsourcing collaborative machine learning infrastructure for all Internet users. We propose two reciprocal cooperation frameworks to achieve this: query-based FL and contract-based FL. In this survey, we conduct a comprehensive review of the feasibility of constructing open FL platforms from both technical and legal perspectives. We begin by reviewing the definition of FL and summarizing its inherent limitations, including server-client coupling, low model reusability, and non-public. In particular, we introduce a novel taxonomy to streamline the analysis of model license compatibility in FL studies that involve batch model reusing methods, including combination, amalgamation, distillation, and generation. This taxonomy provides a feasible solution for identifying the corresponding licenses clauses and facilitates the analysis of potential legal implications and restrictions when reusing models. Through this survey, we uncover the current dilemmas faced by FL and advocate for the development of sustainable open FL platforms. We aim to provide guidance for establishing such platforms in the future while identifying potential limitations that need to be addressed.\n    ",
        "primary_category": "cs.SE",
        "categories": [
            "cs.AI",
            "cs.LG"
        ],
        "submitted_date": "5 Jul 2023",
        "last_revised_date": " "
    },
    "2307.03997": {
        "title": "Efficient Model-Free Exploration in Low-Rank MDPs",
        "authors": [
            "Zakaria Mhammedi",
            "Adam Block",
            "Dylan J. Foster",
            "Alexander Rakhlin"
        ],
        "comments": " ",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "A major challenge in reinforcement learning is to develop practical, sample-efficient algorithms for exploration in high-dimensional domains where generalization and function approximation is required. Low-Rank Markov Decision Processes -- where transition probabilities admit a low-rank factorization based on an unknown feature embedding -- offer a simple, yet expressive framework for RL with function approximation, but existing algorithms are either (1) computationally intractable, or (2) reliant upon restrictive statistical assumptions such as latent variable structure, access to model-based function approximation, or reachability. In this work, we propose the first provably sample-efficient algorithm for exploration in Low-Rank MDPs that is both computationally efficient and model-free, allowing for general function approximation and requiring no additional structural assumptions. Our algorithm, VoX, uses the notion of a barycentric spanner for the feature embedding as an efficiently computable basis for exploration, performing efficient barycentric spanner computation by interleaving representation learning and policy optimization. Our analysis -- which is appealingly simple and modular -- carefully combines several techniques, including a new approach to error-tolerant barycentric spanner computation and an improved analysis of a certain minimax representation learning objective found in prior work.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "math.OC"
        ],
        "submitted_date": "8 Jul 2023",
        "last_revised_date": " "
    },
    "2307.07357": {
        "title": "Inverse Optimization for Routing Problems",
        "authors": [
            "Pedro Zattoni Scroccaro",
            "Piet van Beek",
            "Peyman Mohajerin Esfahani",
            "Bilge Atasoy"
        ],
        "comments": " ",
        "subjects": "Optimization and Control (math.OC)",
        "abstract": "We propose a method for learning decision-makers' behavior in routing problems using Inverse Optimization (IO). The IO framework falls into the supervised learning category and builds on the premise that the target behavior is an optimizer of an unknown cost function. This cost function is to be learned through historical data, and in the context of routing problems, can be interpreted as the routing preferences of the decision-makers. In this view, the main contributions of this study are to propose an IO methodology with a hypothesis function, loss function, and stochastic first-order algorithm tailored to routing problems. We further test our IO approach in the Amazon Last Mile Routing Research Challenge, where the goal is to learn models that replicate the routing preferences of human drivers, using thousands of real-world routing examples. Our final IO-learned routing model achieves a score that ranks 2nd compared with the 48 models that qualified for the final round of the challenge. Our examples and results showcase the flexibility and real-world potential of the proposed IO methodology to learn from decision-makers' decisions in routing problems.\n    ",
        "primary_category": "math.OC",
        "categories": [
            "cs.LG"
        ],
        "submitted_date": "14 Jul 2023",
        "last_revised_date": " "
    },
    "2307.07515": {
        "title": "Artificial intelligence is algorithmic mimicry: why artificial \"agents\" are not (and won't be) proper agents",
        "authors": [
            "Johannes Jaeger"
        ],
        "comments": " ",
        "subjects": "Artificial Intelligence (cs.AI)",
        "abstract": "What is the prospect of developing artificial general intelligence (AGI)? I investigate this question by systematically comparing living and algorithmic systems, with a special focus on the notion of \"agency.\" There are three fundamental differences to consider: (1) Living systems are autopoietic, that is, self-manufacturing, and therefore able to set their own intrinsic goals, while algorithms exist in a computational environment with target functions that are both provided by an external agent. (2) Living systems are embodied in the sense that there is no separation between their symbolic and physical aspects, while algorithms run on computational architectures that maximally isolate software from hardware. (3) Living systems experience a large world, in which most problems are ill-defined (and not all definable), while algorithms exist in a small world, in which all problems are well-defined. These three differences imply that living and algorithmic systems have very different capabilities and limitations. In particular, it is extremely unlikely that true AGI (beyond mere mimicry) can be developed in the current algorithmic framework of AI research. Consequently, discussions about the proper development and deployment of algorithmic tools should be shaped around the dangers and opportunities of current narrow AI, not the extremely unlikely prospect of the emergence of true agency in artificial systems.\n    ",
        "primary_category": "cs.AI",
        "categories": [],
        "submitted_date": "27 Jun 2023",
        "last_revised_date": " "
    },
    "2307.08773": {
        "title": "\"Customization is Key\": Reconfigurable Content Tokens for Accessible Data Visualizations",
        "authors": [
            "Shuli Jones",
            "Isabella Pedraza Pineros",
            "Daniel Hajas",
            "Jonathan Zong",
            "Arvind Satyanarayan"
        ],
        "comments": "14 pages. 6 figures. 2 tables. ACM CHI Conference 2024",
        "subjects": "Human-Computer Interaction (cs.HC)",
        "abstract": "Customization is crucial for making visualizations accessible to blind and low-vision (BLV) people with widely-varying needs. But what makes for usable or useful customization? We identify four design goals for how BLV people should be able to customize screen-reader-accessible visualizations: presence, or what content is included; verbosity, or how concisely content is presented; ordering, or how content is sequenced; and, duration, or how long customizations are active. To meet these goals, we model a customization as a sequence of content tokens, each with a set of adjustable properties. We instantiate our model by extending Olli, an open-source accessible visualization toolkit, with a settings menu and command box for persistent and ephemeral customization respectively. Through a study with 13 BLV participants, we find that customization increases the ease of identifying and remembering information. However, customization also introduces additional complexity, making it more helpful for users familiar with similar tools.\n    ",
        "primary_category": "cs.HC",
        "categories": [],
        "submitted_date": "17 Jul 2023",
        "last_revised_date": " "
    },
    "2307.08924": {
        "title": "Towards Task Sampler Learning for Meta-Learning",
        "authors": [
            "Jingyao Wang",
            "Wenwen Qiang",
            "Xingzhe Su",
            "Changwen Zheng",
            "Fuchun Sun",
            "Hui Xiong"
        ],
        "comments": "28 pages, 11 tables, 12 figures",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Meta-learning aims to learn general knowledge with diverse training tasks conducted from limited data, and then transfer it to new tasks. It is commonly believed that increasing task diversity will enhance the generalization ability of meta-learning models. However, this paper challenges this view through empirical and theoretical analysis. We obtain three conclusions: (i) there is no universal task sampling strategy that can guarantee the optimal performance of meta-learning models; (ii) over-constraining task diversity may incur the risk of under-fitting or over-fitting during training; and (iii) the generalization performance of meta-learning models are affected by task diversity, task entropy, and task difficulty. Based on this insight, we design a novel task sampler, called Adaptive Sampler (ASr). ASr is a plug-and-play module that can be integrated into any meta-learning framework. It dynamically adjusts task weights according to task diversity, task entropy, and task difficulty, thereby obtaining the optimal probability distribution for meta-training tasks. Finally, we conduct experiments on a series of benchmark datasets across various scenarios, and the results demonstrate that ASr has clear advantages.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.CV"
        ],
        "submitted_date": "18 Jul 2023",
        "last_revised_date": " "
    },
    "2307.09465": {
        "title": "Occlusion Aware Student Emotion Recognition based on Facial Action Unit Detection",
        "authors": [
            "Shrouk Wally",
            "Ahmed Elsayed",
            "Islam Alkabbany",
            "Asem Ali",
            "Aly Farag"
        ],
        "comments": "it doesn't meet the requirements of the CVIP Lab concerning authorship and acknowledging the funding sources",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Given that approximately half of science, technology, engineering, and mathematics (STEM) undergraduate students in U.S. colleges and universities leave by the end of the first year [15], it is crucial to improve the quality of classroom environments. This study focuses on monitoring students' emotions in the classroom as an indicator of their engagement and proposes an approach to address this issue. The impact of different facial parts on the performance of an emotional recognition model is evaluated through experimentation. To test the proposed model under partial occlusion, an artificially occluded dataset is introduced. The novelty of this work lies in the proposal of an occlusion-aware architecture for facial action units (AUs) extraction, which employs attention mechanism and adaptive feature learning. The AUs can be used later to classify facial expressions in classroom settings.\nThis research paper's findings provide valuable insights into handling occlusion in analyzing facial images for emotional engagement analysis. The proposed experiments demonstrate the significance of considering occlusion and enhancing the reliability of facial analysis models in classroom environments. These findings can also be extended to other settings where occlusions are prevalent.\n    ",
        "primary_category": "cs.CV",
        "categories": [],
        "submitted_date": "18 Jul 2023",
        "last_revised_date": " "
    },
    "2307.09950": {
        "title": "Prompting for Automatic Log Template Extraction",
        "authors": [
            "Junjielong Xu",
            "Ruichun Yang",
            "Yintong Huo",
            "Chengyu Zhang",
            "Pinjia He"
        ],
        "comments": "Accepted by ICSE'24",
        "subjects": "Software Engineering (cs.SE)",
        "abstract": "Log parsing, which involves log template extraction from semi-structured logs to produce structured logs, is the first and the most critical step in automated log analysis. However, current log parsers suffer from limited effectiveness for two reasons. First, traditional data-driven log parsers solely rely on heuristics or handcrafted features designed by domain experts, which may not consistently perform well on logs from diverse systems. Second, existing supervised log parsers require model tuning, which is often limited to fixed training samples and causes sub-optimal performance across the entire log source. To address this limitation, we propose DivLog, an effective log parsing framework based on the in-context learning (ICL) ability of large language models (LLMs). Specifically, before log parsing, DivLog samples a small amount of offline logs as candidates by maximizing their diversity. Then, during log parsing, DivLog selects five appropriate labeled candidates as examples for each target log and constructs them into a prompt. By mining the semantics of examples in the prompt, DivLog generates a target log template in a training-free manner. In addition, we design a straightforward yet effective prompt format to extract the output and enhance the quality of the generated log templates. We conducted experiments on 16 widely-used public datasets. The results show that DivLog achieves (1) 98.1% Parsing Accuracy, (2) 92.1% Precision Template Accuracy, and (3) 92.9% Recall Template Accuracy on average, exhibiting state-of-the-art performance.\n    ",
        "primary_category": "cs.SE",
        "categories": [],
        "submitted_date": "19 Jul 2023",
        "last_revised_date": " "
    },
    "2307.10811": {
        "title": "\"It Felt Like Having a Second Mind\": Investigating Human-AI Co-creativity in Prewriting with Large Language Models",
        "authors": [
            "Qian Wan",
            "Siying Hu",
            "Yu Zhang",
            "Piaohong Wang",
            "Bo Wen",
            "Zhicong Lu"
        ],
        "comments": "To appear at ACM CSCW 2024; Accepted to PACM HCI (CSCW); 25 pages, 2 figures",
        "subjects": "Human-Computer Interaction (cs.HC)",
        "abstract": "Prewriting is the process of discovering and developing ideas before a first draft, which requires divergent thinking and often implies unstructured strategies such as diagramming, outlining, free-writing, etc. Although large language models (LLMs) have been demonstrated to be useful for a variety of tasks including creative writing, little is known about how users would collaborate with LLMs to support prewriting. The preferred collaborative role and initiative of LLMs during such a creativity process is also unclear. To investigate human-LLM collaboration patterns and dynamics during prewriting, we conducted a three-session qualitative study with 15 participants in two creative tasks: story writing and slogan writing. The findings indicated that during collaborative prewriting, there appears to be a three-stage iterative Human-AI Co-creativity process that includes Ideation, Illumination, and Implementation stages. This collaborative process champions the human in a dominant role, in addition to mixed and shifting levels of initiative that exist between humans and LLMs. This research also reports on collaboration breakdowns that occur during this process, user perceptions of using existing LLMs during Human-AI Co-creativity, and discusses design implications to support this co-creativity process.\n    ",
        "primary_category": "cs.HC",
        "categories": [
            "cs.AI",
            "cs.CL"
        ],
        "submitted_date": "20 Jul 2023",
        "last_revised_date": " "
    },
    "2307.11025": {
        "title": "Investigating VTubing as a Reconstruction of Streamer Self-Presentation: Identity, Performance, and Gender",
        "authors": [
            "Qian Wan",
            "Zhicong Lu"
        ],
        "comments": "To appear at ACM CSCW 2024 (Accepted to PACM HCI(CSCW))",
        "subjects": "Human-Computer Interaction (cs.HC)",
        "abstract": "VTubers, or Virtual YouTubers, are live streamers who create streaming content using animated 2D or 3D virtual avatars. In recent years, there has been a significant increase in the number of VTuber creators and viewers across the globe. This practise has drawn research attention into topics such as viewers' engagement behaviors and perceptions, however, as animated avatars offer more identity and performance flexibility than traditional live streaming where one uses their own body, little research has focused on how this flexibility influences how creators present themselves. This research thus seeks to fill this gap by presenting results from a qualitative study of 16 Chinese-speaking VTubers' streaming practices. The data revealed that the virtual avatars that were used while live streaming afforded creators opportunities to present themselves using inflated presentations and resulted in inclusive interactions with viewers. The results also unveiled the inflated, and often sexualized, gender expressions of VTubers while they were situated in misogynistic environments. The socio-technical facets of VTubing were found to potentially reduce sexual harassment and sexism, whilst also raising self-objectification concerns.\n    ",
        "primary_category": "cs.HC",
        "categories": [
            "cs.CY",
            "cs.MM",
            "cs.SI"
        ],
        "submitted_date": "20 Jul 2023",
        "last_revised_date": " "
    },
    "2307.11727": {
        "title": "Extensions of K5: Proof Theory and Uniform Lyndon Interpolation",
        "authors": [
            "Iris van der Giessen",
            "Raheleh Jalali",
            "Roman Kuznets"
        ],
        "comments": "20-page conference paper + 5-page appendix with examples and proofs",
        "subjects": "Logic in Computer Science (cs.LO)",
        "abstract": "We introduce a Gentzen-style framework, called layered sequent calculi, for modal logic K5 and its extensions KD5, K45, KD45, KB5, and S5 with the goal to investigate the uniform Lyndon interpolation property (ULIP), which implies both the uniform interpolation property and the Lyndon interpolation property. We obtain complexity-optimal decision procedures for all logics and present a constructive proof of the ULIP for K5, which to the best of our knowledge, is the first such syntactic proof. To prove that the interpolant is correct, we use model-theoretic methods, especially bisimulation modulo literals.\n    ",
        "primary_category": "cs.LO",
        "categories": [
            "math.LO"
        ],
        "submitted_date": "21 Jul 2023",
        "last_revised_date": " "
    },
    "2307.13717": {
        "title": "On the Leakage of Fuzzy Matchers",
        "authors": [
            "Axel Durbet",
            "Kevin Thiry-Atighehchi",
            "Dorine Chagnon",
            "Paul-Marie Grollemund"
        ],
        "comments": "Minor corrections",
        "subjects": "Cryptography and Security (cs.CR)",
        "abstract": "In a biometric authentication or identification system, the matcher compares a stored and a fresh template to determine whether there is a match. This assessment is based on both a similarity score and a predefined threshold. For better compliance with privacy legislation, the matcher can be built upon a threshold-based obfuscated distance (i.e., Fuzzy Matcher). Beyond the binary output (\"yes\" or \"no\"), most algorithms perform more precise computations, e.g., the value of the distance. Such precise information is prone to leakage even when not returned by the matcher. This can occur due to a malware infection or the use of a weakly privacy-preserving matcher, exemplified by side channel attacks or partially obfuscated designs. This paper provides an analysis of information leakage during distance evaluation, with an emphasis on threshold-based obfuscated distance. We provide a catalog of information leakage scenarios with their impacts on data privacy. Each scenario gives rise to unique attacks with impacts quantified in terms of computational costs, thereby providing a better understanding of the security level.\n    ",
        "primary_category": "cs.CR",
        "categories": [
            "cs.CV"
        ],
        "submitted_date": "25 Jul 2023",
        "last_revised_date": " "
    },
    "2307.15852": {
        "title": "Dimensionless Policies based on the Buckingham $\u03c0$ Theorem: Is This a Good Way to Generalize Numerical Results?",
        "authors": [
            "Alexandre Girard"
        ],
        "comments": " ",
        "subjects": "Optimization and Control (math.OC)",
        "abstract": "The answer to the question posed in the title is yes if the context (the list of variables defining the motion control problem) is dimensionally similar. This article explores the use of the Buckingham $\\pi$ theorem as a tool to encode the control policies of physical systems into a more generic form of knowledge that can be reused in various situations. This approach can be interpreted as enforcing invariance to the scaling of the fundamental units in an algorithm learning a control policy. First, we show, by restating the solution to a motion control problem using dimensionless variables, that (1) the policy mapping involves a reduced number of parameters and (2) control policies generated numerically for a specific system can be transferred exactly to a subset of dimensionally similar systems by scaling the input and output variables appropriately. Those two generic theoretical results are then demonstrated, with numerically generated optimal controllers, for the classic motion control problem of swinging up a torque-limited inverted pendulum and positioning a vehicle in slippery conditions. We also discuss the concept of regime, a region in the space of context variables, that can help to relax the similarity condition. Furthermore, we discuss how applying dimensional scaling of the input and output of a context-specific black-box policy is equivalent to substituting new system parameters in an analytical equation under some conditions, using a linear quadratic regulator (LQR) and a computed torque controller as examples. It remains to be seen how practical this approach can be to generalize policies for more complex high-dimensional problems, but the early results show that it is a promising transfer learning tool for numerical approaches like dynamic programming and reinforcement learning.\n    ",
        "primary_category": "math.OC",
        "categories": [
            "cs.AI",
            "cs.RO",
            "eess.SY"
        ],
        "submitted_date": "29 Jul 2023",
        "last_revised_date": " "
    },
    "2307.16230": {
        "title": "An Unforgeable Publicly Verifiable Watermark for Large Language Models",
        "authors": [
            "Aiwei Liu",
            "Leyi Pan",
            "Xuming Hu",
            "Shu'ang Li",
            "Lijie Wen",
            "Irwin King",
            "Philip S. Yu"
        ],
        "comments": "ICLR2024, 17 pages, 5 figures, 8 tables",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "Recently, text watermarking algorithms for large language models (LLMs) have been proposed to mitigate the potential harms of text generated by LLMs, including fake news and copyright issues. However, current watermark detection algorithms require the secret key used in the watermark generation process, making them susceptible to security breaches and counterfeiting during public detection. To address this limitation, we propose an unforgeable publicly verifiable watermark algorithm that uses two different neural networks for watermark generation and detection, instead of using the same key at both stages. Meanwhile, the token embedding parameters are shared between the generation and detection networks, which makes the detection network achieve a high accuracy very efficiently. Experiments demonstrate that our algorithm attains high detection accuracy and computational efficiency through neural networks with a minimized number of parameters. Subsequent analysis confirms the high complexity involved in forging the watermark from the detection network. Our code and data are available at \\href{this https URL}{this https URL\\_watermark}.\n    ",
        "primary_category": "cs.CL",
        "categories": [],
        "submitted_date": "30 Jul 2023",
        "last_revised_date": " "
    },
    "2308.04075": {
        "title": "Boundary-preserving Lamperti-splitting schemes for some Stochastic Differential Equations",
        "authors": [
            "Johan Ulander"
        ],
        "comments": "30 pages, 6 figures",
        "subjects": "Numerical Analysis (math.NA)",
        "abstract": "We propose and analyse boundary-preserving schemes for the strong approximations of some scalar SDEs with non-globally Lipschitz drift and diffusion coefficients whose state-space is bounded. The schemes consists of a Lamperti transform followed by a Lie--Trotter splitting. We prove $L^{p}(\\Omega)$-convergence of order $1$, for every $p \\geq 1$, of the schemes and exploit the Lamperti transform to confine the numerical approximations to the state-space of the considered SDE. We provide numerical experiments that confirm the theoretical results and compare the proposed Lamperti-splitting schemes to other numerical schemes for SDEs.\n    ",
        "primary_category": "math.NA",
        "categories": [],
        "submitted_date": "8 Aug 2023",
        "last_revised_date": " "
    },
    "2308.04689": {
        "title": "Web crawler strategies for web pages under robot.txt restriction",
        "authors": [
            "Piyush Vyas",
            "Akhilesh Chauhan",
            "Tushar Mandge",
            "Surbhi Hardikar"
        ],
        "comments": " ",
        "subjects": "Artificial Intelligence (cs.AI)",
        "abstract": "In the present time, all know about World Wide Web and work over the Internet daily. In this paper, we introduce the search engines working for keywords that are entered by users to find something. The search engine uses different search algorithms for convenient results for providing to the net surfer. Net surfers go with the top search results but how did the results of web pages get higher ranks over search engines? how the search engine got that all the web pages in the database? This paper gives the answers to all these kinds of basic questions. Web crawlers working for search engines and robot exclusion protocol rules for web crawlers are also addressed in this research paper. Webmaster uses different restriction facts in robot.txt file to instruct web crawler, some basic formats of robot.txt are also mentioned in this paper.\n    ",
        "primary_category": "cs.AI",
        "categories": [
            "cs.IR"
        ],
        "submitted_date": "9 Aug 2023",
        "last_revised_date": " "
    },
    "2308.05500": {
        "title": "An Adaptive Algorithm Based on Stochastic Discontinuous Galerkin for Convection Dominated Equations with Random Data",
        "authors": [
            "Pelin \u00c7ilo\u011flu",
            "Hamdullah Y\u00fccel"
        ],
        "comments": "26 pages, 19 figures, 5 tables",
        "subjects": "Numerical Analysis (math.NA)",
        "abstract": "In this paper, we propose an adaptive approach, based on mesh refinement or parametric enrichment with polynomial degree adaption, for numerical solution of convection dominated equations with random input data. A parametric system emerged from an application of stochastic Galerkin approach is discretized by using a symmetric interior penalty Galerkin (SIPG) method with upwinding for the convection term in the spatial domain. We derive a residual-based error estimator contributed by the error due to the SIPG discretization, the (generalized) polynomial chaos discretization in the stochastic space, and data oscillations. Then, the reliability of the proposed error estimator, an upper bound for the energy error up to a multiplicative constant, is shown. Moreover, to balance the errors stemmed from spatial and stochastic spaces, the truncation error coming from Karhunen--Lo\u00e8ve expansion is also considered in the numerical simulations. Last, several benchmark examples including a random diffusivity parameter, a random velocity parameter, random diffusivity/velocity parameters, and a random (jump) discontinuous diffusivity parameter, are tested to illustrate the performance of the proposed estimator.\n    ",
        "primary_category": "math.NA",
        "categories": [],
        "submitted_date": "10 Aug 2023",
        "last_revised_date": " "
    },
    "2308.05696": {
        "title": "A Preliminary Study of the Intrinsic Relationship between Complexity and Alignment",
        "authors": [
            "Yingxiu Zhao",
            "Bowen Yu",
            "Binyuan Hui",
            "Haiyang Yu",
            "Fei Huang",
            "Yongbin Li",
            "Nevin L. Zhang"
        ],
        "comments": "LREC-Coling 2024",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "Training large language models (LLMs) with open-domain instruction data has yielded remarkable success in aligning to end tasks and human preferences. Extensive research has highlighted the importance of the quality and diversity of instruction data. However, the impact of data complexity, as a crucial metric, remains relatively unexplored from three aspects: (1)where the sustainability of performance improvements with increasing complexity is uncertain; (2)whether the improvement brought by complexity merely comes from introducing more training tokens; and (3)where the potential benefits of incorporating instructions from easy to difficult are not yet fully understood. In this paper, we propose Tree-Instruct to systematically enhance the instruction complexity in a controllable manner. By adding a specified number of nodes to instructions' semantic trees, this approach not only yields new instruction data from the modified tree but also allows us to control the difficulty level of modified instructions. Our preliminary experiments reveal the following insights: (1)Increasing complexity consistently leads to sustained performance improvements of LLMs. (2)Under the same token budget, a few complex instructions outperform diverse yet simple instructions. (3)Curriculum instruction tuning might not yield the anticipated results; focusing on increasing complexity appears to be the key.\n    ",
        "primary_category": "cs.CL",
        "categories": [],
        "submitted_date": "10 Aug 2023",
        "last_revised_date": " "
    },
    "2308.07470": {
        "title": "Symphony: Optimized DNN Model Serving using Deferred Batch Scheduling",
        "authors": [
            "Lequn Chen",
            "Weixin Deng",
            "Anirudh Canumalla",
            "Yu Xin",
            "Danyang Zhuo",
            "Matthai Philipose",
            "Arvind Krishnamurthy"
        ],
        "comments": " ",
        "subjects": "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "abstract": "Having large batch sizes is one of the most critical aspects of increasing the accelerator efficiency and the performance of DNN model inference. However, existing model serving systems cannot achieve adequate batch sizes while meeting latency objectives as these systems eagerly dispatch requests to accelerators to minimize the accelerator idle time. We propose Symphony, a DNN serving system that explores deferred batch scheduling to optimize system efficiency and throughput. Further, unlike other prior systems, Symphony's GPU usage is load-proportional: it consolidates workloads on the appropriate number of GPUs and works smoothly with cluster auto-scaling tools. Symphony consists of two core design points. First, Symphony defines a schedulable window in which a batch of inference requests can be dispatched. This window is computed in order to improve accelerator efficiency while meeting the request's SLO. Second, Symphony implements a scalable, low-latency, fine-grained coordination scheme across accelerators to dispatch and execute requests in the schedulable window. Through extensive scheduler-only benchmarks, we demonstrate that Symphony can schedule millions of requests per second and coordinate thousands of GPUs while also enabling robust autoscaling that adapts to workload changes. Symphony outperforms prior systems by achieving 5x higher goodput when given the same number of GPUs and 60% reduction in GPUs when given the same workload.\n    ",
        "primary_category": "cs.DC",
        "categories": [
            "cs.LG"
        ],
        "submitted_date": "14 Aug 2023",
        "last_revised_date": " "
    },
    "2308.08567": {
        "title": "CMISR: Circular Medical Image Super-Resolution",
        "authors": [
            "Honggui Li",
            "Nahid Md Lokman Hossain",
            "Maria Trocan",
            "Dimitri Galayko",
            "Mohamad Sawan"
        ],
        "comments": " ",
        "subjects": "Image and Video Processing (eess.IV)",
        "abstract": "Classical methods of medical image super-resolution (MISR) utilize open-loop architecture with implicit under-resolution (UR) unit and explicit super-resolution (SR) unit. The UR unit can always be given, assumed, or estimated, while the SR unit is elaborately designed according to various SR algorithms. The closed-loop feedback mechanism is widely employed in current MISR approaches and can efficiently improve their performance. The feedback mechanism may be divided into two categories: local feedback and global feedback. Therefore, this paper proposes a global feedback-based closed-cycle framework, circular MISR (CMISR), with unambiguous UR and advanced SR elements. Mathematical model and closed-loop equation of CMISR are built. Mathematical proof with Taylor-series approximation indicates that CMISR has zero recovery error in steady-state. In addition, CMISR holds plug-and-play characteristic that fuses model-based and learning-based approaches and can be established on any existing MISR algorithms. Five CMISR algorithms are respectively proposed based on the state-of-the-art open-loop MISR algorithms. Experimental results with three scale factors and on three open medical image datasets show that CMISR is superior to MISR in reconstruction performance and is particularly suited to medical images with strong edges or intense contrast.\n    ",
        "primary_category": "eess.IV",
        "categories": [
            "cs.LG"
        ],
        "submitted_date": "15 Aug 2023",
        "last_revised_date": " "
    },
    "2308.08705": {
        "title": "Partially Observable Multi-agent RL with (Quasi-)Efficiency: The Blessing of Information Sharing",
        "authors": [
            "Xiangyu Liu",
            "Kaiqing Zhang"
        ],
        "comments": "International Conference on Machine Learning (ICML) 2023",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "We study provable multi-agent reinforcement learning (MARL) in the general framework of partially observable stochastic games (POSGs). To circumvent the known hardness results and the use of computationally intractable oracles, we advocate leveraging the potential \\emph{information-sharing} among agents, a common practice in empirical MARL, and a standard model for multi-agent control systems with communications. We first establish several computation complexity results to justify the necessity of information-sharing, as well as the observability assumption that has enabled quasi-efficient single-agent RL with partial observations, for computational efficiency in solving POSGs. We then propose to further \\emph{approximate} the shared common information to construct an {approximate model} of the POSG, in which planning an approximate equilibrium (in terms of solving the original POSG) can be quasi-efficient, i.e., of quasi-polynomial-time, under the aforementioned assumptions. Furthermore, we develop a partially observable MARL algorithm that is both statistically and computationally quasi-efficient. We hope our study may open up the possibilities of leveraging and even designing different \\emph{information structures}, for developing both sample- and computation-efficient partially observable MARL.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.GT",
            "cs.MA"
        ],
        "submitted_date": "16 Aug 2023",
        "last_revised_date": " "
    },
    "2308.10562": {
        "title": "Seeing the Intangible: Survey of Image Classification into High-Level and Abstract Categories",
        "authors": [
            "Delfina Sol Martinez Pandiani",
            "Valentina Presutti"
        ],
        "comments": "Preprint",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "The field of Computer Vision (CV) is increasingly shifting towards ``high-level'' visual sensemaking tasks, yet the exact nature of these tasks remains unclear and tacit. This survey paper addresses this ambiguity by systematically reviewing research on high-level visual understanding, focusing particularly on Abstract Concepts (ACs) in automatic image classification. Our survey contributes in three main ways: Firstly, it clarifies the tacit understanding of high-level semantics in CV through a multidisciplinary analysis, and categorization into distinct clusters, including commonsense, emotional, aesthetic, and inductive interpretative semantics. Secondly, it identifies and categorizes computer vision tasks associated with high-level visual sensemaking, offering insights into the diverse research areas within this domain. Lastly, it examines how abstract concepts such as values and ideologies are handled in CV, revealing challenges and opportunities in AC-based image classification. Notably, our survey of AC image classification tasks highlights persistent challenges, such as the limited efficacy of massive datasets and the importance of integrating supplementary information and mid-level features. We emphasize the growing relevance of hybrid AI systems in addressing the multifaceted nature of AC image classification tasks. Overall, this survey enhances our understanding of high-level visual reasoning in CV and lays the groundwork for future research endeavors.\n    ",
        "primary_category": "cs.CV",
        "categories": [
            "cs.CY"
        ],
        "submitted_date": "21 Aug 2023",
        "last_revised_date": " "
    },
    "2308.10686": {
        "title": "Normative Conditional Reasoning as a Fragment of HOL",
        "authors": [
            "Xavier Parent",
            "Christoph Benzm\u00fcller"
        ],
        "comments": "30 pages, 34 figures, 3 tables",
        "subjects": "Logic in Computer Science (cs.LO)",
        "abstract": "We report on the mechanization of (preference-based) conditional normative reasoning. Our focus is on Aqvist's system E for conditional obligation, and its extensions. Our mechanization is achieved via a shallow semantical embedding in Isabelle/HOL. We consider two possible uses of the framework. The first one is as a tool for meta-reasoning about the considered logic. We employ it for the automated verification of deontic correspondences (broadly conceived) and related matters, analogous to what has been previously achieved for the modal logic cube. The equivalence is automatically verified in one direction, leading from the property to the axiom. The second use is as a tool for assessing ethical arguments. We provide a computer encoding of a well-known paradox (or impossibility theorem) in population ethics, Parfit's repugnant conclusion. While some have proposed overcoming the impossibility theorem by abandoning the presupposed transitivity of ''better than'', our formalisation unveils a less extreme approach, suggesting among other things the option of weakening transitivity suitably rather than discarding it entirely. Whether the presented encoding increases or decreases the attractiveness and persuasiveness of the repugnant conclusion is a question we would like to pass on to philosophy and ethics.\n    ",
        "primary_category": "cs.LO",
        "categories": [
            "cs.AI",
            "cs.SC"
        ],
        "submitted_date": "21 Aug 2023",
        "last_revised_date": " "
    },
    "2308.11131": {
        "title": "ReLLa: Retrieval-enhanced Large Language Models for Lifelong Sequential Behavior Comprehension in Recommendation",
        "authors": [
            "Jianghao Lin",
            "Rong Shan",
            "Chenxu Zhu",
            "Kounianhua Du",
            "Bo Chen",
            "Shigang Quan",
            "Ruiming Tang",
            "Yong Yu",
            "Weinan Zhang"
        ],
        "comments": "Accepted by WWW 2024. Full and More Readable Version",
        "subjects": "Information Retrieval (cs.IR)",
        "abstract": "With large language models (LLMs) achieving remarkable breakthroughs in natural language processing (NLP) domains, LLM-enhanced recommender systems have received much attention and have been actively explored currently. In this paper, we focus on adapting and empowering a pure large language model for zero-shot and few-shot recommendation tasks. First and foremost, we identify and formulate the lifelong sequential behavior incomprehension problem for LLMs in recommendation domains, i.e., LLMs fail to extract useful information from a textual context of long user behavior sequence, even if the length of context is far from reaching the context limitation of LLMs. To address such an issue and improve the recommendation performance of LLMs, we propose a novel framework, namely Retrieval-enhanced Large Language models (ReLLa) for recommendation tasks in both zero-shot and few-shot settings. For zero-shot recommendation, we perform semantic user behavior retrieval (SUBR) to improve the data quality of testing samples, which greatly reduces the difficulty for LLMs to extract the essential knowledge from user behavior sequences. As for few-shot recommendation, we further design retrieval-enhanced instruction tuning (ReiT) by adopting SUBR as a data augmentation technique for training samples. Specifically, we develop a mixed training dataset consisting of both the original data samples and their retrieval-enhanced counterparts. We conduct extensive experiments on three real-world public datasets to demonstrate the superiority of ReLLa compared with existing baseline models, as well as its capability for lifelong sequential behavior comprehension. To be highlighted, with only less than 10% training samples, few-shot ReLLa can outperform traditional CTR models that are trained on the entire training set (e.g., DCNv2, DIN, SIM). The code is available \\url{this https URL}.\n    ",
        "primary_category": "cs.IR",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "22 Aug 2023",
        "last_revised_date": " "
    },
    "2308.11909": {
        "title": "Edge-aware Hard Clustering Graph Pooling for Brain Imaging",
        "authors": [
            "Cheng Zhu",
            "Jiayi Zhu",
            "Xi Wu",
            "Lijuan Zhang",
            "Shuqi Yang",
            "Ping Liang",
            "Honghan Chen",
            "Ying Tan"
        ],
        "comments": " ",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Graph Convolutional Networks (GCNs) can capture non-Euclidean spatial dependence between different brain regions. The graph pooling operator, a crucial element of GCNs, enhances the representation learning capability and facilitates the acquisition of abnormal brain maps. However, most existing research designs graph pooling operators solely from the perspective of nodes while disregarding the original edge features. This confines graph pooling application scenarios and diminishes its ability to capture critical substructures. In this paper, we propose a novel edge-aware hard clustering graph pool (EHCPool), which is tailored to dominant edge features and redefines the clustering process. EHCPool initially introduced the 'Edge-to-Node' score criterion which utilized edge information to evaluate the significance of nodes. An innovative Iteration n-top strategy was then developed, guided by edge scores, to adaptively learn sparse hard clustering assignments for graphs. Additionally, a N-E Aggregation strategy is designed to aggregate node and edge features in each independent subgraph. Extensive experiments on the multi-site public datasets demonstrate the superiority and robustness of the proposed model. More notably, EHCPool has the potential to probe different types of dysfunctional brain networks from a data-driven perspective. Method code: this https URL\n",
        "primary_category": "cs.CV",
        "categories": [
            "cs.GR"
        ],
        "submitted_date": "23 Aug 2023",
        "last_revised_date": " "
    },
    "2308.13424": {
        "title": "AG codes have no list-decoding friends: Approaching the generalized Singleton bound requires exponential alphabets",
        "authors": [
            "Omar Alrabiah",
            "Venkatesan Guruswami",
            "Ray Li"
        ],
        "comments": " ",
        "subjects": "Information Theory (cs.IT)",
        "abstract": "A simple, recently observed generalization of the classical Singleton bound to list-decoding asserts that rate $R$ codes are not list-decodable using list-size $L$ beyond an error fraction $\\frac{L}{L+1} (1-R)$ (the Singleton bound being the case of $L=1$, i.e., unique decoding). We prove that in order to approach this bound for any fixed $L >1$, one needs exponential alphabets. Specifically, for every $L>1$ and $R\\in(0,1)$, if a rate $R$ code can be list-of-$L$ decoded up to error fraction $\\frac{L}{L+1} (1-R -\\varepsilon)$, then its alphabet must have size at least $\\exp(\\Omega_{L,R}(1/\\varepsilon))$. This is in sharp contrast to the situation for unique decoding where certain families of rate $R$ algebraic-geometry (AG) codes over an alphabet of size $O(1/\\varepsilon^2)$ are unique-decodable up to error fraction $(1-R-\\varepsilon)/2$. Our bounds hold even for subconstant $\\varepsilon\\ge 1/n$, implying that any code exactly achieving the $L$-th generalized Singleton bound requires alphabet size $2^{\\Omega_{L,R}(n)}$. Previously this was only known only for $L=2$ under the additional assumptions that the code is both linear and MDS.\nOur lower bound is tight up to constant factors in the exponent -- with high probability random codes (or, as shown recently, even random linear codes) over $\\exp(O_L(1/\\varepsilon))$-sized alphabets, can be list-of-$L$ decoded up to error fraction $\\frac{L}{L+1} (1-R -\\varepsilon)$.\n    ",
        "primary_category": "cs.IT",
        "categories": [
            "cs.DM",
            "math.CO"
        ],
        "submitted_date": "25 Aug 2023",
        "last_revised_date": " "
    },
    "2308.14947": {
        "title": "Improving Generalization in Reinforcement Learning Training Regimes for Social Robot Navigation",
        "authors": [
            "Adam Sigal",
            "Hsiu-Chin Lin",
            "AJung Moon"
        ],
        "comments": "NeurIPS 2023 Workshop on Generalization in Planning, 2023",
        "subjects": "Robotics (cs.RO)",
        "abstract": "In order for autonomous mobile robots to navigate in human spaces, they must abide by our social norms. Reinforcement learning (RL) has emerged as an effective method to train sequential decision-making policies that are able to respect these norms. However, a large portion of existing work in the field conducts both RL training and testing in simplistic environments. This limits the generalization potential of these models to unseen environments, and the meaningfulness of their reported results. We propose a method to improve the generalization performance of RL social navigation methods using curriculum learning. By employing multiple environment types and by modeling pedestrians using multiple dynamics models, we are able to progressively diversify and escalate difficulty in training. Our results show that the use of curriculum learning in training can be used to achieve better generalization performance than previous training methods. We also show that results presented in many existing state-of-the-art RL social navigation works do not evaluate their methods outside of their training environments, and thus do not reflect their policies' failure to adequately generalize to out-of-distribution scenarios. In response, we validate our training approach on larger and more crowded testing environments than those used in training, allowing for more meaningful measurements of model performance.\n    ",
        "primary_category": "cs.RO",
        "categories": [
            "cs.LG",
            "cs.MA"
        ],
        "submitted_date": "29 Aug 2023",
        "last_revised_date": " "
    },
    "2308.16089": {
        "title": "Application of Zone Method based Physics-Informed Neural Networks in Reheating Furnaces",
        "authors": [
            "Ujjal Kr Dutta",
            "Aldo Lipani",
            "Chuan Wang",
            "Yukun Hu"
        ],
        "comments": "Accepted in: NeurIPS 2023 - Machine Learning and the Physical Sciences Workshop",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Foundation Industries (FIs) constitute glass, metals, cement, ceramics, bulk chemicals, paper, steel, etc. and provide crucial, foundational materials for a diverse set of economically relevant industries: automobiles, machinery, construction, household appliances, chemicals, etc. Reheating furnaces within the manufacturing chain of FIs are energy-intensive. Accurate and real-time prediction of underlying temperatures in reheating furnaces has the potential to reduce the overall heating time, thereby controlling the energy consumption for achieving the Net-Zero goals in FIs. In this paper, we cast this prediction as a regression task and explore neural networks due to their inherent capability of being effective and efficient, given adequate data. However, due to the infeasibility of achieving good-quality real data in scenarios like reheating furnaces, classical Hottel's zone method based computational model has been used to generate data for model training. To further enhance the Out-Of-Distribution generalization capability of the trained model, we propose a Physics-Informed Neural Network (PINN) by incorporating prior physical knowledge using a set of novel Energy-Balance regularizers.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.AI",
            "cs.NE",
            "eess.SY"
        ],
        "submitted_date": "30 Aug 2023",
        "last_revised_date": " "
    },
    "2309.00064": {
        "title": "Ethical Framework for Harnessing the Power of AI in Healthcare and Beyond",
        "authors": [
            "Sidra Nasir",
            "Rizwan Ahmed Khan",
            "Samita Bai"
        ],
        "comments": " ",
        "subjects": "Computers and Society (cs.CY)",
        "abstract": "In the past decade, the deployment of deep learning (Artificial Intelligence (AI)) methods has become pervasive across a spectrum of real-world applications, often in safety-critical contexts. This comprehensive research article rigorously investigates the ethical dimensions intricately linked to the rapid evolution of AI technologies, with a particular focus on the healthcare domain. Delving deeply, it explores a multitude of facets including transparency, adept data management, human oversight, educational imperatives, and international collaboration within the realm of AI advancement. Central to this article is the proposition of a conscientious AI framework, meticulously crafted to accentuate values of transparency, equity, answerability, and a human-centric orientation. The second contribution of the article is the in-depth and thorough discussion of the limitations inherent to AI systems. It astutely identifies potential biases and the intricate challenges of navigating multifaceted contexts. Lastly, the article unequivocally accentuates the pressing need for globally standardized AI ethics principles and frameworks. Simultaneously, it aptly illustrates the adaptability of the ethical framework proposed herein, positioned skillfully to surmount emergent challenges.\n    ",
        "primary_category": "cs.CY",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "31 Aug 2023",
        "last_revised_date": " "
    },
    "2309.00344": {
        "title": "A Complete Dependency Pair Framework for Almost-Sure Innermost Termination of Probabilistic Term Rewriting",
        "authors": [
            "Jan-Christoph Kassing",
            "Stefan Dollase",
            "J\u00fcrgen Giesl"
        ],
        "comments": "arXiv admin note: text overlap with arXiv:2305.11741",
        "subjects": "Logic in Computer Science (cs.LO)",
        "abstract": "Recently, the well-known dependency pair (DP) framework was adapted to a dependency tuple framework in order to prove almost-sure innermost termination (iAST) of probabilistic term rewrite systems. While this approach was incomplete, in this paper, we improve it into a complete criterion for iAST by presenting a new, more elegant definition of DPs for probabilistic term rewriting. Based on this, we extend the probabilistic DP framework by new transformations. Our implementation in the tool AProVE shows that they increase its power considerably.\n    ",
        "primary_category": "cs.LO",
        "categories": [],
        "submitted_date": "1 Sep 2023",
        "last_revised_date": " "
    },
    "2309.05134": {
        "title": "Benchmarking ground truth trajectories with robotic total stations",
        "authors": [
            "Effie Daum",
            "Maxime Vaidis",
            "Fran\u00e7ois Pomerleau"
        ],
        "comments": "Accepted and presented at IROS23, Workshop on Methods for Objective Comparison of Results in Intelligent Robotics Research",
        "subjects": "Robotics (cs.RO)",
        "abstract": "Benchmarks stand as vital cornerstones in elevating SLAM algorithms within mobile robotics. Consequently, ensuring accurate and reproducible ground truth generation is vital for fair evaluation. A majority of outdoor ground truths are generated by GNSS, which can lead to discrepancies over time, especially in covered areas. However, research showed that RTS setups are more precise and can alternatively be used to generate these ground truths. In our work, we compare both RTS and GNSS systems' precision and repeatability through a set of experiments conducted weeks and months apart in the same area. We demonstrated that RTS setups give more reproducible results, with disparities having a median value of 8.6 mm compared to a median value of 10.6 cm coming from a GNSS setup. These results highlight that RTS can be considered to benchmark process for SLAM algorithms with higher precision.\n    ",
        "primary_category": "cs.RO",
        "categories": [],
        "submitted_date": "10 Sep 2023",
        "last_revised_date": " "
    },
    "2309.05605": {
        "title": "Memory Injections: Correcting Multi-Hop Reasoning Failures during Inference in Transformer-Based Language Models",
        "authors": [
            "Mansi Sakarvadia",
            "Aswathy Ajith",
            "Arham Khan",
            "Daniel Grzenda",
            "Nathaniel Hudson",
            "Andr\u00e9 Bauer",
            "Kyle Chard",
            "Ian Foster"
        ],
        "comments": "Oral Presentation at BlackboxNLP Workshop at EMNLP 2023",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "Answering multi-hop reasoning questions requires retrieving and synthesizing information from diverse sources. Large Language Models (LLMs) struggle to perform such reasoning consistently. Here we propose an approach to pinpoint and rectify multi-hop reasoning failures through targeted memory injections on LLM attention heads. First, we analyze the per-layer activations of GPT-2 models in response to single and multi-hop prompts. We then propose a mechanism that allows users to inject pertinent prompt-specific information, which we refer to as \"memories,\" at critical LLM locations during inference. By thus enabling the LLM to incorporate additional relevant information during inference, we enhance the quality of multi-hop prompt completions. We show empirically that a simple, efficient, and targeted memory injection into a key attention layer can often increase the probability of the desired next token in multi-hop tasks, by up to 424%.\n    ",
        "primary_category": "cs.CL",
        "categories": [
            "cs.AI",
            "cs.LG"
        ],
        "submitted_date": "11 Sep 2023",
        "last_revised_date": " "
    },
    "2309.05979": {
        "title": "Measure preservation and integrals for Lotka--Volterra tree-systems and their Kahan discretisation",
        "authors": [
            "Peter H. van der Kamp",
            "Robert I. McLachlan",
            "David I. McLaren",
            "G. R. W. Quispel"
        ],
        "comments": "17 pages, 3 figures",
        "subjects": "Dynamical Systems (math.DS)",
        "abstract": "We show that any Lotka--Volterra tree-system associated with an $n$-vertex tree, as introduced in Quispel et al., J. Phys. A 56 (2023) 315201, preserves a rational measure. We also prove that the Kahan discretisation of these tree-systems factorises and preserves the same measure. As a consequence, for the Kahan maps of Lotka--Volterra systems related to the subclass of tree-systems corresponding to graphs with more than one $n$-vertex subtree, we are able to construct rational integrals.\n    ",
        "primary_category": "math.DS",
        "categories": [
            "math.NA"
        ],
        "submitted_date": "12 Sep 2023",
        "last_revised_date": " "
    },
    "2309.06275": {
        "title": "Re-Reading Improves Reasoning in Large Language Models",
        "authors": [
            "Xiaohan Xu",
            "Chongyang Tao",
            "Tao Shen",
            "Can Xu",
            "Hongbo Xu",
            "Guodong Long",
            "Jian-guang Lou"
        ],
        "comments": "25 pages",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "To enhance the reasoning capabilities of off-the-shelf Large Language Models (LLMs), we introduce a simple, yet general and effective prompting method, Re2, i.e., \\textbf{Re}-\\textbf{Re}ading the question as input. Unlike most thought-eliciting prompting methods, such as Chain-of-Thought (CoT), which aim to elicit the reasoning process in the output, Re2 shifts the focus to the input by processing questions twice, thereby enhancing the understanding process. Consequently, Re2 demonstrates strong generality and compatibility with most thought-eliciting prompting methods, including CoT. Crucially, Re2 facilitates a \"bidirectional\" encoding in unidirectional decoder-only LLMs because the first pass could provide global information for the second pass. We begin with a preliminary empirical study as the foundation of Re2, illustrating its potential to enable \"bidirectional\" attention mechanisms. We then evaluate Re2 on extensive reasoning benchmarks across 14 datasets, spanning 112 experiments, to validate its effectiveness and generality. Our findings indicate that, with the exception of a few scenarios on vanilla ChatGPT, Re2 consistently enhances the reasoning performance of LLMs through a simple re-reading strategy. Further analyses reveal Re2's adaptability, showing how it can be effectively integrated with different LLMs, thought-eliciting prompting, and ensemble strategies. Our code is available at \\url{this https URL}\n    ",
        "primary_category": "cs.CL",
        "categories": [],
        "submitted_date": "12 Sep 2023",
        "last_revised_date": " "
    },
    "2309.08315": {
        "title": "i-Octree: A Fast, Lightweight, and Dynamic Octree for Proximity Search",
        "authors": [
            "Jun Zhu",
            "Hongyi Li",
            "Zhepeng Wang",
            "Shengjie Wang",
            "Tao Zhang"
        ],
        "comments": "7 pages, 7 figures",
        "subjects": "Robotics (cs.RO)",
        "abstract": "Establishing the correspondences between newly acquired points and historically accumulated data (i.e., map) through nearest neighbors search is crucial in numerous robotic applications. However, static tree data structures are inadequate to handle large and dynamically growing maps in real-time. To address this issue, we present the i-Octree, a dynamic octree data structure that supports both fast nearest neighbor search and real-time dynamic updates, such as point insertion, deletion, and on-tree down-sampling. The i-Octree is built upon a leaf-based octree and has two key features: a local spatially continuous storing strategy that allows for fast access to points while minimizing memory usage, and local on-tree updates that significantly reduce computation time compared to existing static or dynamic tree structures. The experiments show that i-Octree outperforms contemporary state-of-the-art approaches by achieving, on average, a 19% reduction in runtime on realworld open datasets.\n    ",
        "primary_category": "cs.RO",
        "categories": [],
        "submitted_date": "15 Sep 2023",
        "last_revised_date": " "
    },
    "2309.09865": {
        "title": "Contrastive Learning for Enhancing Robust Scene Transfer in Vision-based Agile Flight",
        "authors": [
            "Jiaxu Xing",
            "Leonard Bauersfeld",
            "Yunlong Song",
            "Chunwei Xing",
            "Davide Scaramuzza"
        ],
        "comments": " ",
        "subjects": "Robotics (cs.RO)",
        "abstract": "Scene transfer for vision-based mobile robotics applications is a highly relevant and challenging problem. The utility of a robot greatly depends on its ability to perform a task in the real world, outside of a well-controlled lab environment. Existing scene transfer end-to-end policy learning approaches often suffer from poor sample efficiency or limited generalization capabilities, making them unsuitable for mobile robotics applications. This work proposes an adaptive multi-pair contrastive learning strategy for visual representation learning that enables zero-shot scene transfer and real-world deployment. Control policies relying on the embedding are able to operate in unseen environments without the need for finetuning in the deployment environment. We demonstrate the performance of our approach on the task of agile, vision-based quadrotor flight. Extensive simulation and real-world experiments demonstrate that our approach successfully generalizes beyond the training domain and outperforms all baselines.\n    ",
        "primary_category": "cs.RO",
        "categories": [
            "cs.CV"
        ],
        "submitted_date": "18 Sep 2023",
        "last_revised_date": " "
    },
    "2309.10834": {
        "title": "Communication-Efficient Federated Learning via Regularized Sparse Random Networks",
        "authors": [
            "Mohamad Mestoukirdi",
            "Omid Esrafilian",
            "David Gesbert",
            "Qianrui Li",
            "Nicolas Gresset"
        ],
        "comments": " ",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "This work presents a new method for enhancing communication efficiency in stochastic Federated Learning that trains over-parameterized random networks. In this setting, a binary mask is optimized instead of the model weights, which are kept fixed. The mask characterizes a sparse sub-network that is able to generalize as good as a smaller target network. Importantly, sparse binary masks are exchanged rather than the floating point weights in traditional federated learning, reducing communication cost to at most 1 bit per parameter (Bpp). We show that previous state of the art stochastic methods fail to find sparse networks that can reduce the communication and storage overhead using consistent loss objectives. To address this, we propose adding a regularization term to local objectives that acts as a proxy of the transmitted masks entropy, therefore encouraging sparser solutions by eliminating redundant features across sub-networks. Extensive empirical experiments demonstrate significant improvements in communication and memory efficiency of up to five magnitudes compared to the literature, with minimal performance degradation in validation accuracy in some instances\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.CV",
            "cs.DC",
            "cs.DS"
        ],
        "submitted_date": "19 Sep 2023",
        "last_revised_date": " "
    },
    "2309.11661": {
        "title": "Neural Image Compression Using Masked Sparse Visual Representation",
        "authors": [
            "Wei Jiang",
            "Wei Wang",
            "Yue Chen"
        ],
        "comments": " ",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "We study neural image compression based on the Sparse Visual Representation (SVR), where images are embedded into a discrete latent space spanned by learned visual codebooks. By sharing codebooks with the decoder, the encoder transfers integer codeword indices that are efficient and cross-platform robust, and the decoder retrieves the embedded latent feature using the indices for reconstruction. Previous SVR-based compression lacks effective mechanism for rate-distortion tradeoffs, where one can only pursue either high reconstruction quality or low transmission bitrate. We propose a Masked Adaptive Codebook learning (M-AdaCode) method that applies masks to the latent feature subspace to balance bitrate and reconstruction quality. A set of semantic-class-dependent basis codebooks are learned, which are weighted combined to generate a rich latent feature for high-quality reconstruction. The combining weights are adaptively derived from each input image, providing fidelity information with additional transmission costs. By masking out unimportant weights in the encoder and recovering them in the decoder, we can trade off reconstruction quality for transmission bits, and the masking rate controls the balance between bitrate and distortion. Experiments over the standard JPEG-AI dataset demonstrate the effectiveness of our M-AdaCode approach.\n    ",
        "primary_category": "cs.CV",
        "categories": [
            "eess.IV"
        ],
        "submitted_date": "20 Sep 2023",
        "last_revised_date": " "
    },
    "2309.12309": {
        "title": "Rehearsal: Simulating Conflict to Teach Conflict Resolution",
        "authors": [
            "Omar Shaikh",
            "Valentino Chai",
            "Michele J. Gelfand",
            "Diyi Yang",
            "Michael S. Bernstein"
        ],
        "comments": "CHI 2024",
        "subjects": "Human-Computer Interaction (cs.HC)",
        "abstract": "Interpersonal conflict is an uncomfortable but unavoidable fact of life. Navigating conflict successfully is a skill -- one that can be learned through deliberate practice -- but few have access to effective training or feedback. To expand this access, we introduce Rehearsal, a system that allows users to rehearse conflicts with a believable simulated interlocutor, explore counterfactual \"what if?\" scenarios to identify alternative conversational paths, and learn through feedback on how and when to apply specific conflict strategies. Users can utilize Rehearsal to practice handling a variety of predefined conflict scenarios, from office disputes to relationship issues, or they can choose to create their own setting. To enable Rehearsal, we develop IRP prompting, a method of conditioning output of a large language model on the influential Interest-Rights-Power (IRP) theory from conflict resolution. Rehearsal uses IRP to generate utterances grounded in conflict resolution theory, guiding users towards counterfactual conflict resolution strategies that help de-escalate difficult conversations. In a between-subjects evaluation, 40 participants engaged in an actual conflict with a confederate after training. Compared to a control group with lecture material covering the same IRP theory, participants with simulated training from Rehearsal significantly improved their performance in the unaided conflict: they reduced their use of escalating competitive strategies by an average of 67%, while doubling their use of cooperative strategies. Overall, Rehearsal highlights the potential effectiveness of language models as tools for learning and practicing interpersonal skills.\n    ",
        "primary_category": "cs.HC",
        "categories": [
            "cs.AI",
            "cs.CL"
        ],
        "submitted_date": "21 Sep 2023",
        "last_revised_date": " "
    },
    "2309.12444": {
        "title": "Foundation Metrics for Evaluating Effectiveness of Healthcare Conversations Powered by Generative AI",
        "authors": [
            "Mahyar Abbasian",
            "Elahe Khatibi",
            "Iman Azimi",
            "David Oniani",
            "Zahra Shakeri Hossein Abad",
            "Alexander Thieme",
            "Ram Sriram",
            "Zhongqi Yang",
            "Yanshan Wang",
            "Bryant Lin",
            "Olivier Gevaert",
            "Li-Jia Li",
            "Ramesh Jain",
            "Amir M. Rahmani"
        ],
        "comments": "14 pages, 4 figures, 2 tables, journal paper",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "Generative Artificial Intelligence is set to revolutionize healthcare delivery by transforming traditional patient care into a more personalized, efficient, and proactive process. Chatbots, serving as interactive conversational models, will probably drive this patient-centered transformation in healthcare. Through the provision of various services, including diagnosis, personalized lifestyle recommendations, and mental health support, the objective is to substantially augment patient health outcomes, all the while mitigating the workload burden on healthcare providers. The life-critical nature of healthcare applications necessitates establishing a unified and comprehensive set of evaluation metrics for conversational models. Existing evaluation metrics proposed for various generic large language models (LLMs) demonstrate a lack of comprehension regarding medical and health concepts and their significance in promoting patients' well-being. Moreover, these metrics neglect pivotal user-centered aspects, including trust-building, ethics, personalization, empathy, user comprehension, and emotional support. The purpose of this paper is to explore state-of-the-art LLM-based evaluation metrics that are specifically applicable to the assessment of interactive conversational models in healthcare. Subsequently, we present an comprehensive set of evaluation metrics designed to thoroughly assess the performance of healthcare chatbots from an end-user perspective. These metrics encompass an evaluation of language processing abilities, impact on real-world clinical tasks, and effectiveness in user-interactive conversations. Finally, we engage in a discussion concerning the challenges associated with defining and implementing these metrics, with particular emphasis on confounding factors such as the target audience, evaluation methods, and prompt techniques involved in the evaluation process.\n    ",
        "primary_category": "cs.CL",
        "categories": [],
        "submitted_date": "21 Sep 2023",
        "last_revised_date": " "
    },
    "2309.12924": {
        "title": "Automated grading workflows for providing personalized feedback to open-ended data science assignments",
        "authors": [
            "Federica Zoe Ricci",
            "Catalina Mari Medina",
            "Mine Dogucu"
        ],
        "comments": "24 pages, 3 figures",
        "subjects": "Physics Education (physics.ed-ph)",
        "abstract": "Open-ended assignments - such as lab reports and semester-long projects - provide data science and statistics students with opportunities for developing communication, critical thinking, and creativity skills. However, providing grades and formative feedback to open-ended assignments can be very time consuming and difficult to do consistently across students. In this paper, we discuss the steps of a typical grading workflow and highlight which steps can be automated in an approach that we call automated grading workflow. We illustrate how gradetools, a new R package, implements this approach within RStudio to facilitate efficient and consistent grading while providing individualized feedback. By outlining the motivations behind the development of this package and the considerations underlying its design, we hope this article will provide data science and statistics educators with ideas for improving their grading workflows, possibly developing new grading tools or considering use gradetools as their grading workflow assistant.\n    ",
        "primary_category": "physics.ed-ph",
        "categories": [
            "cs.CY",
            "stat.OT"
        ],
        "submitted_date": "18 Aug 2023",
        "last_revised_date": " "
    },
    "2309.13192": {
        "title": "Towards Green AI in Fine-tuning Large Language Models via Adaptive Backpropagation",
        "authors": [
            "Kai Huang",
            "Hanyun Yin",
            "Heng Huang",
            "Wei Gao"
        ],
        "comments": "16 pages",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Fine-tuning is the most effective way of adapting pre-trained large language models (LLMs) to downstream applications. With the fast growth of LLM-enabled AI applications and democratization of open-souced LLMs, fine-tuning has become possible for non-expert individuals, but intensively performed LLM fine-tuning worldwide could result in significantly high energy consumption and carbon footprint, which may bring large environmental impact. Mitigating such environmental impact towards Green AI directly correlates to reducing the FLOPs of fine-tuning, but existing techniques on efficient LLM fine-tuning can only achieve limited reduction of such FLOPs, due to their ignorance of the backpropagation cost in fine-tuning. To address this limitation, in this paper we present GreenTrainer, a new LLM fine-tuning technique that adaptively evaluates different tensors' backpropagation costs and contributions to the fine-tuned model accuracy, to minimize the fine-tuning cost by selecting the most appropriate set of tensors in training. Such selection in GreenTrainer is made based on a given objective of FLOPs reduction, which can flexibly adapt to the carbon footprint in energy supply and the need in Green AI. Experiment results over multiple open-sourced LLM models and abstractive summarization datasets show that, compared to fine-tuning the whole LLM model, GreenTrainer can save up to 64% FLOPs in fine-tuning without any noticeable model accuracy loss. Compared to the existing fine-tuning techniques such as LoRa, GreenTrainer can achieve up to 4% improvement on model accuracy with on-par FLOPs reduction.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "22 Sep 2023",
        "last_revised_date": " "
    },
    "2309.16598": {
        "title": "Cross-Prediction-Powered Inference",
        "authors": [
            "Tijana Zrnic",
            "Emmanuel J. Cand\u00e8s"
        ],
        "comments": " ",
        "subjects": "Machine Learning (stat.ML)",
        "abstract": "While reliable data-driven decision-making hinges on high-quality labeled data, the acquisition of quality labels often involves laborious human annotations or slow and expensive scientific measurements. Machine learning is becoming an appealing alternative as sophisticated predictive techniques are being used to quickly and cheaply produce large amounts of predicted labels; e.g., predicted protein structures are used to supplement experimentally derived structures, predictions of socioeconomic indicators from satellite imagery are used to supplement accurate survey data, and so on. Since predictions are imperfect and potentially biased, this practice brings into question the validity of downstream inferences. We introduce cross-prediction: a method for valid inference powered by machine learning. With a small labeled dataset and a large unlabeled dataset, cross-prediction imputes the missing labels via machine learning and applies a form of debiasing to remedy the prediction inaccuracies. The resulting inferences achieve the desired error probability and are more powerful than those that only leverage the labeled data. Closely related is the recent proposal of prediction-powered inference, which assumes that a good pre-trained model is already available. We show that cross-prediction is consistently more powerful than an adaptation of prediction-powered inference in which a fraction of the labeled data is split off and used to train the model. Finally, we observe that cross-prediction gives more stable conclusions than its competitors; its confidence intervals typically have significantly lower variability.\n    ",
        "primary_category": "stat.ML",
        "categories": [
            "cs.LG",
            "stat.ME"
        ],
        "submitted_date": "28 Sep 2023",
        "last_revised_date": " "
    },
    "2309.16909": {
        "title": "ASAP: Automated Sequence Planning for Complex Robotic Assembly with Physical Feasibility",
        "authors": [
            "Yunsheng Tian",
            "Karl D.D. Willis",
            "Bassel Al Omari",
            "Jieliang Luo",
            "Pingchuan Ma",
            "Yichen Li",
            "Farhad Javid",
            "Edward Gu",
            "Joshua Jacob",
            "Shinjiro Sueda",
            "Hui Li",
            "Sachin Chitta",
            "Wojciech Matusik"
        ],
        "comments": "ICRA 2024",
        "subjects": "Robotics (cs.RO)",
        "abstract": "The automated assembly of complex products requires a system that can automatically plan a physically feasible sequence of actions for assembling many parts together. In this paper, we present ASAP, a physics-based planning approach for automatically generating such a sequence for general-shaped assemblies. ASAP accounts for gravity to design a sequence where each sub-assembly is physically stable with a limited number of parts being held and a support surface. We apply efficient tree search algorithms to reduce the combinatorial complexity of determining such an assembly sequence. The search can be guided by either geometric heuristics or graph neural networks trained on data with simulation labels. Finally, we show the superior performance of ASAP at generating physically realistic assembly sequence plans on a large dataset of hundreds of complex product assemblies. We further demonstrate the applicability of ASAP on both simulation and real-world robotic setups. Project website: this http URL\n",
        "primary_category": "cs.RO",
        "categories": [
            "cs.AI",
            "cs.GR"
        ],
        "submitted_date": "29 Sep 2023",
        "last_revised_date": " "
    },
    "2309.17260": {
        "title": "PlaceNav: Topological Navigation through Place Recognition",
        "authors": [
            "Lauri Suomela",
            "Jussi Kalliola",
            "Harry Edelman",
            "Joni-Kristian K\u00e4m\u00e4r\u00e4inen"
        ],
        "comments": "ICRA2024 camera ready",
        "subjects": "Robotics (cs.RO)",
        "abstract": "Recent results suggest that splitting topological navigation into robot-independent and robot-specific components improves navigation performance by enabling the robot-independent part to be trained with data collected by robots of different types. However, the navigation methods' performance is still limited by the scarcity of suitable training data and they suffer from poor computational scaling.\nIn this work, we present PlaceNav, subdividing the robot-independent part into navigation-specific and generic computer vision components. We utilize visual place recognition for the subgoal selection of the topological navigation pipeline. This makes subgoal selection more efficient and enables leveraging large-scale datasets from non-robotics sources, increasing training data availability. Bayesian filtering, enabled by place recognition, further improves navigation performance by increasing the temporal consistency of subgoals. Our experimental results verify the design and the new method obtains a 76% higher success rate in indoor and 23% higher in outdoor navigation tasks with higher computational efficiency.\n    ",
        "primary_category": "cs.RO",
        "categories": [
            "cs.AI",
            "cs.LG"
        ],
        "submitted_date": "29 Sep 2023",
        "last_revised_date": " "
    },
    "2310.00762": {
        "title": "A note on the stabilizer formalism via noncommutative graphs",
        "authors": [
            "Roy Araiza",
            "Jihong Cai",
            "Yushan Chen",
            "Abraham Holtermann",
            "Chieh Hsu",
            "Tushar Mohan",
            "Peixue Wu",
            "Zeyuan Yu"
        ],
        "comments": "Final version. To appear in \"Quantum Information Processing''",
        "subjects": "Information Theory (cs.IT)",
        "abstract": "In this short note we formulate a stabilizer formalism in the language of noncommutative graphs. The classes of noncommutative graphs we consider are obtained via unitary representations of compact groups, and suitably chosen operators on finite-dimensional Hilbert spaces. Furthermore, in this framework, we generalize previous results in this area for determining when such noncommutative graphs have anticliques.\n    ",
        "primary_category": "cs.IT",
        "categories": [
            "math.OA",
            "quant-ph"
        ],
        "submitted_date": "1 Oct 2023",
        "last_revised_date": " "
    },
    "2310.01236": {
        "title": "Mirror Diffusion Models for Constrained and Watermarked Generation",
        "authors": [
            "Guan-Horng Liu",
            "Tianrong Chen",
            "Evangelos A. Theodorou",
            "Molei Tao"
        ],
        "comments": "submitted to NeurIPS on 5/18 but did not arxiv per NeurIPS policy, accepted on 9/22",
        "subjects": "Machine Learning (stat.ML)",
        "abstract": "Modern successes of diffusion models in learning complex, high-dimensional data distributions are attributed, in part, to their capability to construct diffusion processes with analytic transition kernels and score functions. The tractability results in a simulation-free framework with stable regression losses, from which reversed, generative processes can be learned at scale. However, when data is confined to a constrained set as opposed to a standard Euclidean space, these desirable characteristics appear to be lost based on prior attempts. In this work, we propose Mirror Diffusion Models (MDM), a new class of diffusion models that generate data on convex constrained sets without losing any tractability. This is achieved by learning diffusion processes in a dual space constructed from a mirror map, which, crucially, is a standard Euclidean space. We derive efficient computation of mirror maps for popular constrained sets, such as simplices and $\\ell_2$-balls, showing significantly improved performance of MDM over existing methods. For safety and privacy purposes, we also explore constrained sets as a new mechanism to embed invisible but quantitative information (i.e., watermarks) in generated data, for which MDM serves as a compelling approach. Our work brings new algorithmic opportunities for learning tractable diffusion on complex domains. Our code is available at this https URL\n",
        "primary_category": "stat.ML",
        "categories": [
            "cs.CV",
            "cs.LG"
        ],
        "submitted_date": "2 Oct 2023",
        "last_revised_date": " "
    },
    "2310.02195": {
        "title": "Efficient Online Scheduling and Routing for Automated Guided Vehicles In Loop-Based Graphs",
        "authors": [
            "Louis Stubbe",
            "Jens Goemaere",
            "Jan Goedgebeur"
        ],
        "comments": "15 pages, 4 figures",
        "subjects": "Computational Engineering, Finance, and Science (cs.CE)",
        "abstract": "Automated guided vehicles (AGVs) are widely used in various industries, and scheduling and routing them in a conflict-free manner is crucial to their efficient operation. We propose a loop-based algorithm that solves the online, conflict-free scheduling and routing problem for AGVs with any capacity and ordered jobs in loop-based graphs. The proposed algorithm is compared against an exact method, a greedy heuristic and a metaheuristic. We experimentally show, using theoretical and real instances on a model representing a real manufacturing plant, that this algorithm either outperforms the other algorithms or gets an equally good solution in less computing time.\n    ",
        "primary_category": "cs.CE",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "3 Oct 2023",
        "last_revised_date": " "
    },
    "2310.02592": {
        "title": "A Faster Deterministic Approximation Algorithm for TTP-2",
        "authors": [
            "Yuga Kanaya",
            "Kenjiro Takazawa"
        ],
        "comments": "27 pages, 42 figures",
        "subjects": "Data Structures and Algorithms (cs.DS)",
        "abstract": "The traveling tournament problem (TTP) is to minimize the total traveling distance of all teams in a double round-robin tournament. In this paper, we focus on TTP-2, in which each team plays at most two consecutive home games and at most two consecutive away games. For the case where the number of teams $n\\equiv2$ (mod 4), Zhao and Xiao (2022) presented a $(1+5/n)$-approximation algorithm. This is a randomized algorithm running in $O(n^3)$ time, and its derandomized version runs in $O(n^4)$ time. In this paper, we present a faster deterministic algorithm running in $O(n^3)$ time, with approximation ratio $1+9/n$. This ratio improves the previous approximation ratios of the deterministic algorithms with the same time complexity.\n    ",
        "primary_category": "cs.DS",
        "categories": [
            "math.CO"
        ],
        "submitted_date": "4 Oct 2023",
        "last_revised_date": " "
    },
    "2310.03560": {
        "title": "Redefining Digital Health Interfaces with Large Language Models",
        "authors": [
            "Fergus Imrie",
            "Paulius Rauba",
            "Mihaela van der Schaar"
        ],
        "comments": " ",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "Digital health tools have the potential to significantly improve the delivery of healthcare services. However, their adoption remains comparatively limited due, in part, to challenges surrounding usability and trust. Large Language Models (LLMs) have emerged as general-purpose models with the ability to process complex information and produce human-quality text, presenting a wealth of potential applications in healthcare. Directly applying LLMs in clinical settings is not straightforward, however, with LLMs susceptible to providing inconsistent or nonsensical answers. We demonstrate how LLM-based systems can utilize external tools and provide a novel interface between clinicians and digital technologies. This enhances the utility and practical impact of digital healthcare tools and AI models while addressing current issues with using LLMs in clinical settings such as hallucinations. We illustrate LLM-based interfaces with the example of cardiovascular disease risk prediction. We develop a new prognostic tool using automated machine learning and demonstrate how LLMs can provide a unique interface to both our model and existing risk scores, highlighting the benefit compared to traditional interfaces for digital tools.\n    ",
        "primary_category": "cs.CL",
        "categories": [],
        "submitted_date": "5 Oct 2023",
        "last_revised_date": " "
    },
    "2310.06356": {
        "title": "A Semantic Invariant Robust Watermark for Large Language Models",
        "authors": [
            "Aiwei Liu",
            "Leyi Pan",
            "Xuming Hu",
            "Shiao Meng",
            "Lijie Wen"
        ],
        "comments": "ICLR2024, 21 pages, 10 figures, 6 tables",
        "subjects": "Cryptography and Security (cs.CR)",
        "abstract": "Watermark algorithms for large language models (LLMs) have achieved extremely high accuracy in detecting text generated by LLMs. Such algorithms typically involve adding extra watermark logits to the LLM's logits at each generation step. However, prior algorithms face a trade-off between attack robustness and security robustness. This is because the watermark logits for a token are determined by a certain number of preceding tokens; a small number leads to low security robustness, while a large number results in insufficient attack robustness. In this work, we propose a semantic invariant watermarking method for LLMs that provides both attack robustness and security robustness. The watermark logits in our work are determined by the semantics of all preceding tokens. Specifically, we utilize another embedding LLM to generate semantic embeddings for all preceding tokens, and then these semantic embeddings are transformed into the watermark logits through our trained watermark model. Subsequent analyses and experiments demonstrated the attack robustness of our method in semantically invariant settings: synonym substitution and text paraphrasing settings. Finally, we also show that our watermark possesses adequate security robustness. Our code and data are available at this https URL.\n    ",
        "primary_category": "cs.CR",
        "categories": [
            "cs.CL"
        ],
        "submitted_date": "10 Oct 2023",
        "last_revised_date": " "
    },
    "2310.07333": {
        "title": "Computing approximate roots of monotone functions",
        "authors": [
            "Alexandros Hollender",
            "Chester Lawrence",
            "Erel Segal-Halevi"
        ],
        "comments": "We solved all the open cases, except the case when f has 3 or more dimensions, and satisfies all monotonicity conditions except one. Any ideas?",
        "subjects": "Computer Science and Game Theory (cs.GT)",
        "abstract": "Given a function f: [a,b] -> R, if f(a) < 0 and f(b)> 0 and f is continuous, the Intermediate Value Theorem implies that f has a root in [a,b]. Moreover, given a value-oracle for f, an approximate root of f can be computed using the bisection method, and the number of required evaluations is polynomial in the number of accuracy digits. The goal of this note is to identify conditions under which this polynomiality result extends to a multi-dimensional function that satisfies the conditions of Miranda's theorem -- the natural multi-dimensional extension of the Intermediate Value Theorem. In general, finding an approximate root might require an exponential number of evaluations even for a two-dimensional function. We show that, if f is two-dimensional and satisfies a single monotonicity condition, then the number of required evaluations is polynomial in the accuracy. For any fixed dimension d, if f is a d-dimensional function that satisfies all d^2-d ``ex-diagonal'' monotonicity conditions (that is, component i of f is monotonically decreasing with respect to variable j for all i!=j), then the number of required evaluations is polynomial in the accuracy. But if f satisfies only d^2-d-2 ex-diagonal conditions, then the number of required evaluations may be exponential in the accuracy. The case of d^2-d-1 ex-diagonal conditions remains unsolved. As an example application, we show that computing approximate roots of monotone functions can be used for approximate envy-free cake-cutting.\n    ",
        "primary_category": "cs.GT",
        "categories": [
            "math.NA"
        ],
        "submitted_date": "11 Oct 2023",
        "last_revised_date": " "
    },
    "2310.07555": {
        "title": "Does resistance to style-transfer equal Global Shape Bias? Measuring network sensitivity to global shape configuration",
        "authors": [
            "Ziqi Wen",
            "Tianqin Li",
            "Zhi Jing",
            "Tai Sing Lee"
        ],
        "comments": " ",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Deep learning models are known to exhibit a strong texture bias, while human tends to rely heavily on global shape structure for object recognition. The current benchmark for evaluating a model's global shape bias is a set of style-transferred images with the assumption that resistance to the attack of style transfer is related to the development of global structure sensitivity in the model. In this work, we show that networks trained with style-transfer images indeed learn to ignore style, but its shape bias arises primarily from local detail. We provide a \\textbf{Disrupted Structure Testbench (DiST)} as a direct measurement of global structure sensitivity. Our test includes 2400 original images from ImageNet-1K, each of which is accompanied by two images with the global shapes of the original image disrupted while preserving its texture via the texture synthesis program. We found that \\textcolor{black}{(1) models that performed well on the previous cue-conflict dataset do not fare well in the proposed DiST; (2) the supervised trained Vision Transformer (ViT) lose its global spatial information from positional embedding, leading to no significant advantages over Convolutional Neural Networks (CNNs) on DiST. While self-supervised learning methods, especially mask autoencoder significantly improves the global structure sensitivity of ViT. (3) Improving the global structure sensitivity is orthogonal to resistance to style-transfer, indicating that the relationship between global shape structure and local texture detail is not an either/or relationship. Training with DiST images and style-transferred images are complementary, and can be combined to train network together to enhance the global shape sensitivity and robustness of local features.} Our code will be hosted in github: this https URL\n",
        "primary_category": "cs.CV",
        "categories": [],
        "submitted_date": "11 Oct 2023",
        "last_revised_date": " "
    },
    "2310.07576": {
        "title": "Analyzing Trendy Twitter Hashtags in the 2022 French Election",
        "authors": [
            "Aamir Mandviwalla",
            "Lake Yin",
            "Boleslaw K. Szymanski"
        ],
        "comments": "9 pages, 1 figure, published in Complex Networks and their Applications XII",
        "subjects": "Social and Information Networks (cs.SI)",
        "abstract": "Regressions trained to predict the future activity of social media users need rich features for accurate predictions. Many advanced models exist to generate such features; however, the time complexities of their computations are often prohibitive when they run on enormous data-sets. Some studies have shown that simple semantic network features can be rich enough to use for regressions without requiring complex computations. We propose a method for using semantic networks as user-level features for machine learning tasks. We conducted an experiment using a semantic network of 1037 Twitter hashtags from a corpus of 3.7 million tweets related to the 2022 French presidential election. A bipartite graph is formed where hashtags are nodes and weighted edges connect the hashtags reflecting the number of Twitter users that interacted with both hashtags. The graph is then transformed into a maximum-spanning tree with the most popular hashtag as its root node to construct a hierarchy amongst the hashtags. We then provide a vector feature for each user based on this tree. To validate the usefulness of our semantic feature we performed a regression experiment to predict the response rate of each user with six emotions like anger, enjoyment, or disgust. Our semantic feature performs well with the regression with most emotions having $R^2$ above 0.5. These results suggest that our semantic feature could be considered for use in further experiments predicting social media response on big data-sets.\n    ",
        "primary_category": "cs.SI",
        "categories": [
            "cs.LG"
        ],
        "submitted_date": "11 Oct 2023",
        "last_revised_date": " "
    },
    "2310.07649": {
        "title": "Automated Layout Design and Control of Robust Cooperative Grasped-Load Aerial Transportation Systems",
        "authors": [
            "Carlo Bosio",
            "Jerry Tang",
            "Ting-Hao Wang",
            "Mark W. Mueller"
        ],
        "comments": "7 pages, 7 figures, conference paper",
        "subjects": "Robotics (cs.RO)",
        "abstract": "We present a novel approach to cooperative aerial transportation through a team of drones, using optimal control theory and a hierarchical control strategy. We assume the drones are connected to the payload through rigid attachments, essentially transforming the whole system into a larger flying object with \"thrust modules\" at the attachment locations of the drones. We investigate the optimal arrangement of the thrust modules around the payload, so that the resulting system is robust to disturbances. We choose the $\\mathcal{H}_2$ norm as a measure of robustness, and propose an iterative optimization routine to compute the optimal layout of the vehicles around the object. We experimentally validate our approach using four drones and comparing the disturbance rejection performances achieved by two different layouts (the optimal one and a sub-optimal one), and observe that the results match our predictions.\n    ",
        "primary_category": "cs.RO",
        "categories": [
            "eess.SY"
        ],
        "submitted_date": "11 Oct 2023",
        "last_revised_date": " "
    },
    "2310.07779": {
        "title": "Social Approval and Network Homophily as Motivators of Online Toxicity",
        "authors": [
            "Julie Jiang",
            "Luca Luceri",
            "Joseph B. Walther",
            "Emilio Ferrara"
        ],
        "comments": " ",
        "subjects": "Social and Information Networks (cs.SI)",
        "abstract": "Online hate messaging is a pervasive issue plaguing the well-being of social media users. This research empirically investigates a novel theory positing that online hate may be driven primarily by the pursuit of social approval rather than a direct desire to harm the targets. Results show that toxicity is homophilous in users' social networks and that a user's propensity for hostility can be predicted by their social networks. We also illustrate how receiving greater or fewer social engagements in the form of likes, retweets, quotes, and replies affects a user's subsequent toxicity. We establish a clear connection between receiving social approval signals and increases in subsequent toxicity. Being retweeted plays a particularly prominent role in escalating toxicity. Results also show that not receiving expected levels of social approval leads to decreased toxicity. We discuss the important implications of our research and opportunities to combat online hate.\n    ",
        "primary_category": "cs.SI",
        "categories": [],
        "submitted_date": "11 Oct 2023",
        "last_revised_date": " "
    },
    "2310.08540": {
        "title": "Revisiting the Hypothesis: Do pretrained Transformers Learn In-Context by Gradient Descent?",
        "authors": [
            "Lingfeng Shen",
            "Aayush Mishra",
            "Daniel Khashabi"
        ],
        "comments": " ",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "The emergence of In-Context Learning (ICL) in LLMs remains a significant phenomenon with little understanding. To explain ICL, recent studies try to theoretically connect it to Gradient Descent (GD). We ask, does this connection hold up in actual pre-trained models?\nWe highlight the limiting assumptions in prior works that make their context considerably different from the practical context in which language models are trained. For example, the theoretical hand-constructed weights used in these studies have properties that don't match those of real LLMs. Furthermore, their experimental verification uses ICL objective (training models explicitly for ICL), which differs from the emergent ICL in the wild.\nWe also look for evidence in real models. We observe that ICL and GD have different sensitivity to the order in which they observe demonstrations. Finally, we probe and compare the ICL vs. GD hypothesis in a natural setting. We conduct comprehensive empirical analyses on language models pre-trained on natural data (LLaMa-7B). Our comparisons of three performance metrics highlight the inconsistent behavior of ICL and GD as a function of various factors such as datasets, models, and the number of demonstrations. We observe that ICL and GD modify the output distribution of language models differently. These results indicate that the equivalence between ICL and GD remains an open hypothesis and calls for further studies.\n    ",
        "primary_category": "cs.CL",
        "categories": [
            "cs.AI",
            "cs.LG"
        ],
        "submitted_date": "12 Oct 2023",
        "last_revised_date": " "
    },
    "2310.14720": {
        "title": "Extended Deep Adaptive Input Normalization for Preprocessing Time Series Data for Neural Networks",
        "authors": [
            "Marcus A. K. September",
            "Francesco Sanna Passino",
            "Leonie Goldmann",
            "Anton Hinel"
        ],
        "comments": " ",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Data preprocessing is a crucial part of any machine learning pipeline, and it can have a significant impact on both performance and training efficiency. This is especially evident when using deep neural networks for time series prediction and classification: real-world time series data often exhibit irregularities such as multi-modality, skewness and outliers, and the model performance can degrade rapidly if these characteristics are not adequately addressed. In this work, we propose the EDAIN (Extended Deep Adaptive Input Normalization) layer, a novel adaptive neural layer that learns how to appropriately normalize irregular time series data for a given task in an end-to-end fashion, instead of using a fixed normalization scheme. This is achieved by optimizing its unknown parameters simultaneously with the deep neural network using back-propagation. Our experiments, conducted using synthetic data, a credit default prediction dataset, and a large-scale limit order book benchmark dataset, demonstrate the superior performance of the EDAIN layer when compared to conventional normalization methods and existing adaptive time series preprocessing layers.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "stat.ML"
        ],
        "submitted_date": "23 Oct 2023",
        "last_revised_date": " "
    },
    "2310.17273": {
        "title": "Looping in the Human Collaborative and Explainable Bayesian Optimization",
        "authors": [
            "Masaki Adachi",
            "Brady Planden",
            "David A. Howey",
            "Michael A. Osborne",
            "Sebastian Orbell",
            "Natalia Ares",
            "Krikamol Muandet",
            "Siu Lun Chau"
        ],
        "comments": "Accepted at AISTATS 2024, 24 pages, 11 figures",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Like many optimizers, Bayesian optimization often falls short of gaining user trust due to opacity. While attempts have been made to develop human-centric optimizers, they typically assume user knowledge is well-specified and error-free, employing users mainly as supervisors of the optimization process. We relax these assumptions and propose a more balanced human-AI partnership with our Collaborative and Explainable Bayesian Optimization (CoExBO) framework. Instead of explicitly requiring a user to provide a knowledge model, CoExBO employs preference learning to seamlessly integrate human insights into the optimization, resulting in algorithmic suggestions that resonate with user preference. CoExBO explains its candidate selection every iteration to foster trust, empowering users with a clearer grasp of the optimization. Furthermore, CoExBO offers a no-harm guarantee, allowing users to make mistakes; even with extreme adversarial interventions, the algorithm converges asymptotically to a vanilla Bayesian optimization. We validate CoExBO's efficacy through human-AI teaming experiments in lithium-ion battery design, highlighting substantial improvements over conventional methods. Code is available this https URL.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.HC",
            "stat.ML"
        ],
        "submitted_date": "26 Oct 2023",
        "last_revised_date": " "
    },
    "2310.18127": {
        "title": "Ask more, know better: Reinforce-Learned Prompt Questions for Decision Making with Large Language Models",
        "authors": [
            "Xue Yan",
            "Yan Song",
            "Xinyu Cui",
            "Filippos Christianos",
            "Haifeng Zhang",
            "David Henry Mguni",
            "Jun Wang"
        ],
        "comments": " ",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Large language models (LLMs) demonstrate their promise in tackling complicated practical challenges by combining action-based policies with chain of thought (CoT) reasoning. Having high-quality prompts on hand, however, is vital to the framework's effectiveness. Currently, these prompts are handcrafted utilising extensive human labor, resulting in CoT policies that frequently fail to generalise. Human intervention is also required to develop grounding functions that ensure low-level controllers appropriately process CoT reasoning. In this paper, we propose a comprehensive training framework for complex task-solving, incorporating human prior knowledge into the learning of action policies. To that purpose, we offer a new leader-follower bilevel framework that is capable of learning to ask relevant questions (prompts) and subsequently undertaking reasoning to guide the learning of actions. The prompt policy is employed to make introspective revisions based on historical findings, leading the CoT process to consider the anticipated goals and generate outputs that lead to decisive, high-performing actions. The action policy subsequently learns to comprehend and integrate the CoT outputs to take actions. Our empirical data reveal that our framework outperforms leading methods in $5$ decision-making tasks such as Overcooked and FourRoom.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.AI",
            "cs.CL"
        ],
        "submitted_date": "27 Oct 2023",
        "last_revised_date": " "
    },
    "2310.19673": {
        "title": "A Novel Non-Pyrotechnic Radial Deployment Mechanism for Payloads in Sounding Rockets",
        "authors": [
            "Thakur Pranav G. Singh",
            "Utkarsh Anand",
            "Tanvi Agrawal",
            "Srinivas G"
        ],
        "comments": "The results in this paper had to be verified again and hence a new paper has been written with new detailed mechanical simulations",
        "subjects": "Systems and Control (eess.SY)",
        "abstract": "This research paper introduces an innovative payload deployment mechanism tailored for sounding rockets, addressing a crucial challenge in the field. The problem statement revolves around the need to efficiently and compactly deploy multiple payloads during a single rocket launch. This mechanism, designed to be exceptionally suitable for sounding rockets, features a cylindrical carrier structure equipped with multiple independently operable deployment ports. Powered by a motor, the carrier structure rotates to enable radial ejection of payloads. In this paper, we present the mechanism's design and conduct a comprehensive performance analysis. This analysis encompasses an examination of structural stability, system dynamics, motor torque, and power requirements. Additionally, we develop a simulation model to assess payload deployment behavior under various conditions. Our findings demonstrate the viability and efficiency of this proposed mechanism for deploying multiple payloads within a single sounding rocket launch. Its adaptability to accommodate diverse payload types and sizes enhances its versatility. Moreover, the mechanism's radial deployment capability allows payloads to be released at different altitudes, thereby offering greater flexibility for scientific experiments. In summary, this innovative payload radial deployment mechanism represents a significant advancement in sounding rocket technology and holds promise for a wide array of applications in both scientific and commercial missions.\n    ",
        "primary_category": "eess.SY",
        "categories": [],
        "submitted_date": "30 Oct 2023",
        "last_revised_date": " "
    },
    "2310.20354": {
        "title": "Statistical Complexity of Heterogeneous Geometric Networks",
        "authors": [
            "Keith Malcolm Smith",
            "Jason P. Smith"
        ],
        "comments": "12 pages, 6 figures",
        "subjects": "Social and Information Networks (cs.SI)",
        "abstract": "Heterogeneity and geometry are key explanatory components underlying the structure of real-world networks. The relationship between these components and the statistical complexity of networks is not well understood. We introduce a parsimonious normalised measure of statistical complexity for networks -- normalised hierarchical complexity. The measure is trivially 0 in regular graphs and we prove that this measure tends to 0 in Erd\u00f6s-R\u00e9nyi random graphs in the thermodynamic limit. We go on to demonstrate that greater complexity arises from the combination of hierarchical and geometric components to the network structure than either on their own. Further, the levels of complexity achieved are similar to those found in many real-world networks. We also find that real world networks establish connections in a way which increases hierarchical complexity and which our null models and a range of attachment mechanisms fail to explain. This underlines the non-trivial nature of statistical complexity in real-world networks and provides foundations for the comparative analysis of network complexity within and across disciplines.\n    ",
        "primary_category": "cs.SI",
        "categories": [],
        "submitted_date": "31 Oct 2023",
        "last_revised_date": " "
    },
    "2311.01410": {
        "title": "The Blessing of Randomness: SDE Beats ODE in General Diffusion-based Image Editing",
        "authors": [
            "Shen Nie",
            "Hanzhong Allan Guo",
            "Cheng Lu",
            "Yuhao Zhou",
            "Chenyu Zheng",
            "Chongxuan Li"
        ],
        "comments": " ",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "We present a unified probabilistic formulation for diffusion-based image editing, where a latent variable is edited in a task-specific manner and generally deviates from the corresponding marginal distribution induced by the original stochastic or ordinary differential equation (SDE or ODE). Instead, it defines a corresponding SDE or ODE for editing. In the formulation, we prove that the Kullback-Leibler divergence between the marginal distributions of the two SDEs gradually decreases while that for the ODEs remains as the time approaches zero, which shows the promise of SDE in image editing. Inspired by it, we provide the SDE counterparts for widely used ODE baselines in various tasks including inpainting and image-to-image translation, where SDE shows a consistent and substantial improvement. Moreover, we propose SDE-Drag -- a simple yet effective method built upon the SDE formulation for point-based content dragging. We build a challenging benchmark (termed DragBench) with open-set natural, art, and AI-generated images for evaluation. A user study on DragBench indicates that SDE-Drag significantly outperforms our ODE baseline, existing diffusion-based methods, and the renowned DragGAN. Our results demonstrate the superiority and versatility of SDE in image editing and push the boundary of diffusion-based editing methods.\n    ",
        "primary_category": "cs.CV",
        "categories": [
            "cs.LG"
        ],
        "submitted_date": "2 Nov 2023",
        "last_revised_date": " "
    },
    "2311.01947": {
        "title": "Lengths of divisible codes -- the missing cases",
        "authors": [
            "Sascha Kurz"
        ],
        "comments": "11 pages, 1 table",
        "subjects": "Combinatorics (math.CO)",
        "abstract": "A linear code $C$ over $\\mathbb{F}_q$ is called $\\Delta$-divisible if the Hamming weights $\\operatorname{wt}(c)$ of all codewords $c \\in C$ are divisible by $\\Delta$. The possible effective lengths of $q^r$-divisible codes have been completely characterized for each prime power $q$ and each non-negative integer $r$. The study of $\\Delta$ divisible codes was initiated by Harold Ward. If $c$ divides $\\Delta$ but is coprime to $q$, then each $\\Delta$-divisible code $C$ over $\\F_q$ is the $c$-fold repetition of a $\\Delta/c$-divisible code. Here we determine the possible effective lengths of $p^r$-divisible codes over finite fields of characteristic $p$, where $p\\in\\mathbb{N}$ but $p^r$ is not a power of the field size, i.e., the missing cases.\n    ",
        "primary_category": "math.CO",
        "categories": [
            "cs.IT"
        ],
        "submitted_date": "3 Nov 2023",
        "last_revised_date": " "
    },
    "2311.02013": {
        "title": "SMORE: Score Models for Offline Goal-Conditioned Reinforcement Learning",
        "authors": [
            "Harshit Sikchi",
            "Rohan Chitnis",
            "Ahmed Touati",
            "Alborz Geramifard",
            "Amy Zhang",
            "Scott Niekum"
        ],
        "comments": "Published at International Conference of Learning Representations (ICLR) 2024. 26 pages",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Offline Goal-Conditioned Reinforcement Learning (GCRL) is tasked with learning to achieve multiple goals in an environment purely from offline datasets using sparse reward functions. Offline GCRL is pivotal for developing generalist agents capable of leveraging pre-existing datasets to learn diverse and reusable skills without hand-engineering reward functions. However, contemporary approaches to GCRL based on supervised learning and contrastive learning are often suboptimal in the offline setting. An alternative perspective on GCRL optimizes for occupancy matching, but necessitates learning a discriminator, which subsequently serves as a pseudo-reward for downstream RL. Inaccuracies in the learned discriminator can cascade, negatively influencing the resulting policy. We present a novel approach to GCRL under a new lens of mixture-distribution matching, leading to our discriminator-free method: SMORe. The key insight is combining the occupancy matching perspective of GCRL with a convex dual formulation to derive a learning objective that can better leverage suboptimal offline data. SMORe learns scores or unnormalized densities representing the importance of taking an action at a state for reaching a particular goal. SMORe is principled and our extensive experiments on the fully offline GCRL benchmark composed of robot manipulation and locomotion tasks, including high-dimensional observations, show that SMORe can outperform state-of-the-art baselines by a significant margin.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.AI",
            "cs.RO"
        ],
        "submitted_date": "3 Nov 2023",
        "last_revised_date": " "
    },
    "2311.05181": {
        "title": "Energy-efficient flocking with nonlinear navigational feedback",
        "authors": [
            "Oleksandr Dykhovychnyi",
            "Alexander Panchenko"
        ],
        "comments": " ",
        "subjects": "Dynamical Systems (math.DS)",
        "abstract": "Modeling collective motion in multi-agent systems has gained much attention in recent years. In particular, of interest are the conditions under which flocking dynamics emerges. We present a generalization of the multi-agent model of Olfati--Saber with nonlinear navigational feedback forces. As opposed to the original model, our model is, in general, not dissipative. This makes obtaining sufficient conditions for flocking challenging due to the absence of an obvious choice of a Lyapunov function. By means of an alternative argument, we show that our model possesses a global attractor when the navigational feedback forces are bounded perturbations of the linear ones. We further demonstrate that, under mild conditions, the dynamics of the group converges to a complete velocity consensus at an exponential rate. We show that the attractor of a dissipative system can contain non-equilibrium solutions. We construct explicit examples of such solutions and obtain conditions under which they cannot exist. In addition, we present a case study of the energy efficiency of our model. We show how nonlinear navigational feedback forces, which possess flexibility that linear forces lack, can be used to reduce on-board energy consumption.\n    ",
        "primary_category": "math.DS",
        "categories": [
            "cs.MA"
        ],
        "submitted_date": "9 Nov 2023",
        "last_revised_date": " "
    },
    "2311.08168": {
        "title": "Time-Uniform Confidence Spheres for Means of Random Vectors",
        "authors": [
            "Ben Chugg",
            "Hongjian Wang",
            "Aaditya Ramdas"
        ],
        "comments": "46 pages, 1 figure",
        "subjects": "Statistics Theory (math.ST)",
        "abstract": "We derive and study time-uniform confidence spheres -- confidence sphere sequences (CSSs) -- which contain the mean of random vectors with high probability simultaneously across all sample sizes. Inspired by the original work of Catoni and Giulini, we unify and extend their analysis to cover both the sequential setting and to handle a variety of distributional assumptions. Our results include an empirical-Bernstein CSS for bounded random vectors (resulting in a novel empirical-Bernstein confidence interval with asymptotic width scaling proportionally to the true unknown variance), CSSs for sub-$\\psi$ random vectors (which includes sub-gamma, sub-Poisson, and sub-exponential), and CSSs for heavy-tailed random vectors (two moments only). Finally, we provide two CSSs that are robust to contamination by Huber noise. The first is a robust version of our empirical-Bernstein CSS, and the second extends recent work in the univariate setting to heavy-tailed multivariate distributions.\n    ",
        "primary_category": "math.ST",
        "categories": [
            "cs.IT",
            "stat.ME",
            "stat.ML"
        ],
        "submitted_date": "14 Nov 2023",
        "last_revised_date": " "
    },
    "2311.08631": {
        "title": "Influence of Video Dynamics on EEG-based Single-Trial Video Target Surveillance System",
        "authors": [
            "Heon-Gyu Kwak",
            "Sung-Jin Kim",
            "Hyeon-Taek Han",
            "Ji-Hoon Jeong",
            "Seong-Whan Lee"
        ],
        "comments": "2024 International BCI winter conference accepted paper",
        "subjects": "Human-Computer Interaction (cs.HC)",
        "abstract": "Target detection models are one of the widely used deep learning-based applications for reducing human efforts on video surveillance and patrol. However, the application of conventional computer vision-based target detection models in military usage can result in limited performance, due to the lack of sample data of hostile targets. In this paper, we present the possibility of the electroencephalography-based video target detection model, which could be applied as a supportive module of the military video surveillance system. The proposed framework and detection model showed prospective performance achieving a mean macro F-beta of 0.6522 with asynchronous real-time data from five subjects, in a certain video stimulus, but not on some video stimuli. By analyzing the results of experiments using each video stimulus, we present the factors that would affect the performance of electroencephalography-based video target detection models.\n    ",
        "primary_category": "cs.HC",
        "categories": [],
        "submitted_date": "15 Nov 2023",
        "last_revised_date": " "
    },
    "2311.08675": {
        "title": "Refined Coreset Selection: Towards Minimal Coreset Size under Model Performance Constraints",
        "authors": [
            "Xiaobo Xia",
            "Jiale Liu",
            "Shaokun Zhang",
            "Qingyun Wu",
            "Hongxin Wei",
            "Tongliang Liu"
        ],
        "comments": "22 pages, 10 tables, 4 figures",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Coreset selection is powerful in reducing computational costs and accelerating data processing for deep learning algorithms. It strives to identify a small subset from large-scale data, so that training only on the subset practically performs on par with full data. Practitioners regularly desire to identify the smallest possible coreset in realistic scenes while maintaining comparable model performance, to minimize costs and maximize acceleration. Motivated by this desideratum, for the first time, we pose the problem of refined coreset selection, in which the minimal coreset size under model performance constraints is explored. Moreover, to address this problem, we propose an innovative method, which maintains optimization priority order over the model performance and coreset size, and efficiently optimizes them in the coreset selection procedure. Theoretically, we provide the convergence guarantee of the proposed method. Empirically, extensive experiments confirm its superiority compared with previous strategies, often yielding better model performance with smaller coreset sizes.\n    ",
        "primary_category": "cs.LG",
        "categories": [],
        "submitted_date": "15 Nov 2023",
        "last_revised_date": " "
    },
    "2311.09758": {
        "title": "OrchestraLLM: Efficient Orchestration of Language Models for Dialogue State Tracking",
        "authors": [
            "Chia-Hsuan Lee",
            "Hao Cheng",
            "Mari Ostendorf"
        ],
        "comments": "updated version",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "Large language models (LLMs) have revolutionized the landscape of Natural Language Processing systems, but are computationally expensive. To reduce the cost without sacrificing performance, previous studies have explored various approaches to harness the potential of Small Language Models (SLMs) as cost-effective alternatives to their larger counterparts. Driven by findings that SLMs and LLMs exhibit complementary strengths in a structured knowledge extraction task, this work presents a novel SLM/LLM routing framework designed to improve computational efficiency and enhance task performance. First, exemplar pools are created to represent the types of contexts where each LM provides a more reliable answer, leveraging a sentence embedding fine-tuned so that context similarity is close to dialogue state similarity. Then, during inference, the k-nearest exemplars to the testing instance are retrieved, and the instance is routed according to majority vote. In dialogue state tracking tasks, the proposed routing framework enhances performance substantially compared to relying solely on LLMs, while reducing the computational costs by over 50%.\n    ",
        "primary_category": "cs.CL",
        "categories": [],
        "submitted_date": "16 Nov 2023",
        "last_revised_date": " "
    },
    "2311.09827": {
        "title": "Cognitive Overload: Jailbreaking Large Language Models with Overloaded Logical Thinking",
        "authors": [
            "Nan Xu",
            "Fei Wang",
            "Ben Zhou",
            "Bang Zheng Li",
            "Chaowei Xiao",
            "Muhao Chen"
        ],
        "comments": " ",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "While large language models (LLMs) have demonstrated increasing power, they have also given rise to a wide range of harmful behaviors. As representatives, jailbreak attacks can provoke harmful or unethical responses from LLMs, even after safety alignment. In this paper, we investigate a novel category of jailbreak attacks specifically designed to target the cognitive structure and processes of LLMs. Specifically, we analyze the safety vulnerability of LLMs in the face of (1) multilingual cognitive overload, (2) veiled expression, and (3) effect-to-cause reasoning. Different from previous jailbreak attacks, our proposed cognitive overload is a black-box attack with no need for knowledge of model architecture or access to model weights. Experiments conducted on AdvBench and MasterKey reveal that various LLMs, including both popular open-source model Llama 2 and the proprietary model ChatGPT, can be compromised through cognitive overload. Motivated by cognitive psychology work on managing cognitive load, we further investigate defending cognitive overload attack from two perspectives. Empirical studies show that our cognitive overload from three perspectives can jailbreak all studied LLMs successfully, while existing defense strategies can hardly mitigate the caused malicious uses effectively.\n    ",
        "primary_category": "cs.CL",
        "categories": [],
        "submitted_date": "16 Nov 2023",
        "last_revised_date": " "
    },
    "2311.12451": {
        "title": "A frame approach for equations involving the fractional Laplacian",
        "authors": [
            "Ioannis P. A. Papadopoulos",
            "Timon S. Gutleb",
            "Jos\u00e9 A. Carrillo",
            "Sheehan Olver"
        ],
        "comments": " ",
        "subjects": "Numerical Analysis (math.NA)",
        "abstract": "Exceptionally elegant formulae exist for the fractional Laplacian operator applied to weighted classical orthogonal polynomials. We utilize these results to construct a solver, based on frame properties, for equations involving the fractional Laplacian of any power, $s \\in (0,1)$, on an unbounded domain in one or two dimensions. The numerical method represents solutions in an expansion of weighted classical orthogonal polynomials as well as their unweighted counterparts with a specific extension to $\\mathbb{R}^d$, $d \\in \\{1,2\\}$. We examine the frame properties of this family of functions for the solution expansion and, under standard frame conditions, derive an a priori estimate for the stationary equation. Moreover, we prove one achieves the expected order of convergence when considering an implicit Euler discretization in time for the fractional heat equation. We apply our solver to numerous examples including the fractional heat equation (utilizing up to a $6^\\text{th}$-order Runge--Kutta time discretization), a fractional heat equation with a time-dependent exponent $s(t)$, and a two-dimensional problem, observing spectral convergence in the spatial dimension for sufficiently smooth data.\n    ",
        "primary_category": "math.NA",
        "categories": [],
        "submitted_date": "21 Nov 2023",
        "last_revised_date": " "
    },
    "2311.13250": {
        "title": "FedHCA$^2$: Towards Hetero-Client Federated Multi-Task Learning",
        "authors": [
            "Yuxiang Lu",
            "Suizhi Huang",
            "Yuwen Yang",
            "Shalayiding Sirejiding",
            "Yue Ding",
            "Hongtao Lu"
        ],
        "comments": "Accepted by CVPR 2024",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Federated Learning (FL) enables joint training across distributed clients using their local data privately. Federated Multi-Task Learning (FMTL) builds on FL to handle multiple tasks, assuming model congruity that identical model architecture is deployed in each client. To relax this assumption and thus extend real-world applicability, we introduce a novel problem setting, Hetero-Client Federated Multi-Task Learning (HC-FMTL), to accommodate diverse task setups. The main challenge of HC-FMTL is the model incongruity issue that invalidates conventional aggregation methods. It also escalates the difficulties in accurate model aggregation to deal with data and task heterogeneity inherent in FMTL. To address these challenges, we propose the FedHCA$^2$ framework, which allows for federated training of personalized models by modeling relationships among heterogeneous clients. Drawing on our theoretical insights into the difference between multi-task and federated optimization, we propose the Hyper Conflict-Averse Aggregation scheme to mitigate conflicts during encoder updates. Additionally, inspired by task interaction in MTL, the Hyper Cross Attention Aggregation scheme uses layer-wise cross attention to enhance decoder interactions while alleviating model incongruity. Moreover, we employ learnable Hyper Aggregation Weights for each client to customize personalized parameter updates. Extensive experiments demonstrate the superior performance of FedHCA$^2$ in various HC-FMTL scenarios compared to representative methods. Our code will be made publicly available.\n    ",
        "primary_category": "cs.CV",
        "categories": [
            "cs.LG"
        ],
        "submitted_date": "22 Nov 2023",
        "last_revised_date": " "
    },
    "2311.14175": {
        "title": "Appearance-based gaze estimation enhanced with synthetic images using deep neural networks",
        "authors": [
            "Dmytro Herashchenko",
            "Igor Farka\u0161"
        ],
        "comments": "6 pages, 10 figures, accepted to 2023 IEEE Symposium Series on Computational Intelligence (SSCI). Published version copyrighted by IEEE. This work was funded by the Horizon Europe Twinning project TERAIS G.A. number 101079338, and in part by the national project APVV-21-0105. The link to the code: this https URL",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Human eye gaze estimation is an important cognitive ingredient for successful human-robot interaction, enabling the robot to read and predict human behavior. We approach this problem using artificial neural networks and build a modular system estimating gaze from separately cropped eyes, taking advantage of existing well-functioning components for face detection (RetinaFace) and head pose estimation (6DRepNet). Our proposed method does not require any special hardware or infrared filters but uses a standard notebook-builtin RGB camera, as often approached with appearance-based methods. Using the MetaHuman tool, we also generated a large synthetic dataset of more than 57,000 human faces and made it publicly available. The inclusion of this dataset (with eye gaze and head pose information) on top of the standard Columbia Gaze dataset into training the model led to better accuracy with a mean average error below two degrees in eye pitch and yaw directions, which compares favourably to related methods. We also verified the feasibility of our model by its preliminary testing in real-world setting using the builtin 4K camera in NICO semi-humanoid robot's eye.\n    ",
        "primary_category": "cs.CV",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "23 Nov 2023",
        "last_revised_date": " "
    },
    "2311.14431": {
        "title": "What you need to know about a learning robot: Identifying the enabling architecture of complex systems",
        "authors": [
            "Helen Beierling",
            "Phillip Richter",
            "Mara Brandt",
            "Lutz Terfloth",
            "Carsten Schulte",
            "Heiko Wersing",
            "Anna-Lisa Vollmer"
        ],
        "comments": "To be published in Cognitive Systems Research",
        "subjects": "Robotics (cs.RO)",
        "abstract": "Nowadays, we are dealing more and more with robots and AI in everyday life. However, their behavior is not always apparent to most lay users, especially in error situations. As a result, there can be misconceptions about the behavior of the technologies in use. This, in turn, can lead to misuse and rejection by users. Explanation, for example, through transparency, can address these misconceptions. However, it would be confusing and overwhelming for users if the entire software or hardware was explained. Therefore, this paper looks at the 'enabling' architecture. It describes those aspects of a robotic system that might need to be explained to enable someone to use the technology effectively. Furthermore, this paper is concerned with the 'explanandum', which is the corresponding misunderstanding or missing concepts of the enabling architecture that needs to be clarified. We have thus developed and present an approach for determining this 'enabling' architecture and the resulting 'explanandum' of complex technologies.\n    ",
        "primary_category": "cs.RO",
        "categories": [],
        "submitted_date": "24 Nov 2023",
        "last_revised_date": " "
    },
    "2311.14658": {
        "title": "Convergence Analysis for Learning Orthonormal Deep Linear Neural Networks",
        "authors": [
            "Zhen Qin",
            "Xuwei Tan",
            "Zhihui Zhu"
        ],
        "comments": " ",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Enforcing orthonormal or isometric property for the weight matrices has been shown to enhance the training of deep neural networks by mitigating gradient exploding/vanishing and increasing the robustness of the learned networks. However, despite its practical performance, the theoretical analysis of orthonormality in neural networks is still lacking; for example, how orthonormality affects the convergence of the training process. In this letter, we aim to bridge this gap by providing convergence analysis for training orthonormal deep linear neural networks. Specifically, we show that Riemannian gradient descent with an appropriate initialization converges at a linear rate for training orthonormal deep linear neural networks with a class of loss functions. Unlike existing works that enforce orthonormal weight matrices for all the layers, our approach excludes this requirement for one layer, which is crucial to establish the convergence guarantee. Our results shed light on how increasing the number of hidden layers can impact the convergence speed. Experimental results validate our theoretical analysis.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "math.OC"
        ],
        "submitted_date": "24 Nov 2023",
        "last_revised_date": " "
    },
    "2311.15328": {
        "title": "BS-Diff: Effective Bone Suppression Using Conditional Diffusion Models from Chest X-Ray Images",
        "authors": [
            "Zhanghao Chen",
            "Yifei Sun",
            "Wenjian Qin",
            "Ruiquan Ge",
            "Cheng Pan",
            "Wenming Deng",
            "Zhou Liu",
            "Wenwen Min",
            "Ahmed Elazab",
            "Xiang Wan",
            "Changmiao Wang"
        ],
        "comments": "5 pages, 2 figures, accepted by IEEE ISBI 2024",
        "subjects": "Image and Video Processing (eess.IV)",
        "abstract": "Chest X-rays (CXRs) are commonly utilized as a low-dose modality for lung screening. Nonetheless, the efficacy of CXRs is somewhat impeded, given that approximately 75% of the lung area overlaps with bone, which in turn hampers the detection and diagnosis of diseases. As a remedial measure, bone suppression techniques have been introduced. The current dual-energy subtraction imaging technique in the clinic requires costly equipment and subjects being exposed to high radiation. To circumvent these issues, deep learning-based image generation algorithms have been proposed. However, existing methods fall short in terms of producing high-quality images and capturing texture details, particularly with pulmonary vessels. To address these issues, this paper proposes a new bone suppression framework, termed BS-Diff, that comprises a conditional diffusion model equipped with a U-Net architecture and a simple enhancement module to incorporate an autoencoder. Our proposed network cannot only generate soft tissue images with a high bone suppression rate but also possesses the capability to capture fine image details. Additionally, we compiled the largest dataset since 2010, including data from 120 patients with high-definition, high-resolution paired CXRs and soft tissue images collected by our affiliated hospital. Extensive experiments, comparative analyses, ablation studies, and clinical evaluations indicate that the proposed BS-Diff outperforms several bone-suppression models across multiple metrics. Our code can be accessed at this https URL.\n    ",
        "primary_category": "eess.IV",
        "categories": [
            "cs.CV"
        ],
        "submitted_date": "26 Nov 2023",
        "last_revised_date": " "
    },
    "2312.00082": {
        "title": "A Compact Implicit Neural Representation for Efficient Storage of Massive 4D Functional Magnetic Resonance Imaging",
        "authors": [
            "Ruoran Li",
            "Runzhao Yang",
            "Wenxin Xiang",
            "Yuxiao Cheng",
            "Tingxiong Xiao",
            "Jinli Suo"
        ],
        "comments": " ",
        "subjects": "Image and Video Processing (eess.IV)",
        "abstract": "Functional Magnetic Resonance Imaging (fMRI) data is a widely used kind of four-dimensional biomedical data, which requires effective compression. However, fMRI compressing poses unique challenges due to its intricate temporal dynamics, low signal-to-noise ratio, and complicated underlying redundancies. This paper reports a novel compression paradigm specifically tailored for fMRI data based on Implicit Neural Representation (INR). The proposed approach focuses on removing the various redundancies among the time series by employing several methods, including (i) conducting spatial correlation modeling for intra-region dynamics, (ii) decomposing reusable neuronal activation patterns, and (iii) using proper initialization together with nonlinear fusion to describe the inter-region similarity. This scheme appropriately incorporates the unique features of fMRI data, and experimental results on publicly available datasets demonstrate the effectiveness of the proposed method, surpassing state-of-the-art algorithms in both conventional image quality evaluation metrics and fMRI downstream tasks. This work in this paper paves the way for sharing massive fMRI data at low bandwidth and high fidelity.\n    ",
        "primary_category": "eess.IV",
        "categories": [
            "cs.CV"
        ],
        "submitted_date": "30 Nov 2023",
        "last_revised_date": " "
    },
    "2312.00746": {
        "title": "Deciphering Digital Detectives: Understanding LLM Behaviors and Capabilities in Multi-Agent Mystery Games",
        "authors": [
            "Dekun Wu",
            "Haochen Shi",
            "Zhiyuan Sun",
            "Bang Liu"
        ],
        "comments": " ",
        "subjects": "Artificial Intelligence (cs.AI)",
        "abstract": "In this study, we explore the application of Large Language Models (LLMs) in \\textit{Jubensha}, a Chinese detective role-playing game and a novel area in Artificial Intelligence (AI) driven gaming. We introduce the first dataset specifically for Jubensha, including character scripts and game rules, to foster AI agent development in this complex narrative environment. Our work also presents a unique multi-agent interaction framework using LLMs, allowing AI agents to autonomously engage in this game. To evaluate the gaming performance of these AI agents, we developed novel methods measuring their mastery of case information and reasoning skills. Furthermore, we incorporated the latest advancements in in-context learning to improve the agents' performance in information gathering, murderer identification, and logical reasoning. The experimental results validate the effectiveness of our proposed methods. This work aims to offer a novel perspective on understanding LLM capabilities and establish a new benchmark for evaluating large language model-based agents.\n    ",
        "primary_category": "cs.AI",
        "categories": [],
        "submitted_date": "1 Dec 2023",
        "last_revised_date": " "
    },
    "2312.01534": {
        "title": "Skeletal Cut Loci on Convex Polyhedra",
        "authors": [
            "Joseph O'Rourke",
            "Costin Vilcu"
        ],
        "comments": "20 pages, 12 figures, 9 references. v2: Many minor improvements",
        "subjects": "Computational Geometry (cs.CG)",
        "abstract": "On a convex polyhedron P, the cut locus C(x) with respect to a point x is a tree of geodesic segments (shortest paths) on P that includes every vertex. We say that P has a skeletal cut locus if there is some x in P such that C(x) is a subset of Sk(P), where Sk(P) is the 1-skeleton of P . At a first glance, there seems to be very little relation between the cut locus and the 1-skeleton, as the first one is an intrinsic geometry notion, and the second one specifies the combinatorics of P.\nIn this paper we study skeletal cut loci, obtaining four main results. First, given any combinatorial tree T without degree-2 nodes, there exists a convex polyhedron P and a point x in P with a cut locus that lies in Sk(P), and whose combinatorics match T. Second, any (non-degenerate) polyhedron P has at most a finite number of points x for which C(x) is a subset of Sk(P). Third, we show that almost all polyhedra have no skeletal cut locus. Fourth, we provide a combinatorial restriction to the existence of skeletal cut loci.\nBecause the source unfolding of P with respect to x is always a non-overlapping net for P, and because the boundary of the source unfolding is the (unfolded) cut locus, source unfoldings of polyhedra with skeletal cut loci are edge-unfoldings, and moreover \"blooming,\" avoiding self-intersection during an unfolding process.\n    ",
        "primary_category": "cs.CG",
        "categories": [
            "math.MG"
        ],
        "submitted_date": "3 Dec 2023",
        "last_revised_date": " "
    },
    "2312.02528": {
        "title": "Towards Automatic Power Battery Detection: New Challenge, Benchmark Dataset and Baseline",
        "authors": [
            "Xiaoqi Zhao",
            "Youwei Pang",
            "Zhenyu Chen",
            "Qian Yu",
            "Lihe Zhang",
            "Hanqi Liu",
            "Jiaming Zuo",
            "Huchuan Lu"
        ],
        "comments": "Accepted at CVPR2024",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "We conduct a comprehensive study on a new task named power battery detection (PBD), which aims to localize the dense cathode and anode plates endpoints from X-ray images to evaluate the quality of power batteries. Existing manufacturers usually rely on human eye observation to complete PBD, which makes it difficult to balance the accuracy and efficiency of detection. To address this issue and drive more attention into this meaningful task, we first elaborately collect a dataset, called X-ray PBD, which has $1,500$ diverse X-ray images selected from thousands of power batteries of $5$ manufacturers, with $7$ different visual interference. Then, we propose a novel segmentation-based solution for PBD, termed multi-dimensional collaborative network (MDCNet). With the help of line and counting predictors, the representation of the point segmentation branch can be improved at both semantic and detail aspects.Besides, we design an effective distance-adaptive mask generation strategy, which can alleviate the visual challenge caused by the inconsistent distribution density of plates to provide MDCNet with stable supervision. Without any bells and whistles, our segmentation-based MDCNet consistently outperforms various other corner detection, crowd counting and general/tiny object detection-based solutions, making it a strong baseline that can help facilitate future research in PBD. Finally, we share some potential difficulties and works for future researches. The source code and datasets will be publicly available at \\href{this https URL}{X-ray PBD}.\n    ",
        "primary_category": "cs.CV",
        "categories": [],
        "submitted_date": "5 Dec 2023",
        "last_revised_date": " "
    },
    "2312.03151": {
        "title": "Multitask Learning Can Improve Worst-Group Outcomes",
        "authors": [
            "Atharva Kulkarni",
            "Lucio Dery",
            "Amrith Setlur",
            "Aditi Raghunathan",
            "Ameet Talwalkar",
            "Graham Neubig"
        ],
        "comments": "20 pages, 7 tables, 6 Figures",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "In order to create machine learning systems that serve a variety of users well, it is vital to not only achieve high average performance but also ensure equitable outcomes across diverse groups. However, most machine learning methods are designed to improve a model's average performance on a chosen end task without consideration for their impact on worst group error. Multitask learning (MTL) is one such widely used technique. In this paper, we seek not only to understand the impact of MTL on worst-group accuracy but also to explore its potential as a tool to address the challenge of group-wise fairness. We primarily consider the standard setting of fine-tuning a pre-trained model, where, following recent work \\citep{gururangan2020don, dery2023aang}, we multitask the end task with the pre-training objective constructed from the end task data itself. In settings with few or no group annotations, we find that multitasking often, but not consistently, achieves better worst-group accuracy than Just-Train-Twice (JTT; \\citet{pmlr-v139-liu21f}) -- a representative distributionally robust optimization (DRO) method. Leveraging insights from synthetic data experiments, we propose to modify standard MTL by regularizing the joint multitask representation space. We run a large number of fine-tuning experiments across computer vision and natural language processing datasets and find that our regularized MTL approach \\emph{consistently} outperforms JTT on both average and worst-group outcomes. Our official code can be found here: \\href{this https URL}{\\url{this https URL}}.\n    ",
        "primary_category": "cs.LG",
        "categories": [],
        "submitted_date": "5 Dec 2023",
        "last_revised_date": " "
    },
    "2312.04141": {
        "title": "Distributed Approximate Computing with Constant Locality",
        "authors": [
            "Deheng Yuan",
            "Tao Guo",
            "Zhongyi Huang",
            "Shi Jin"
        ],
        "comments": " ",
        "subjects": "Information Theory (cs.IT)",
        "abstract": "Consider a distributed coding for computing problem with constant decoding locality, i.e., with a vanishing error probability, any single sample of the function can be approximately recovered by probing only constant number of compressed bits. We establish an achievable rate region by designing an efficient layered coding scheme, where the coding rate is reduced by introducing auxiliary random variables and local decoding is achieved by exploiting the expander graph code. Then we show the rate region is optimal under mild regularity conditions on source distributions. The proof relies on the reverse hypercontractivity and a rounding technique to construct auxiliary random variables. The rate region is strictly smaller than that for the classical problem without the constant locality constraint in most cases, which indicates that more rate is required in order to achieve lower coding complexity. Moreover, a coding for computing problem with side information is analogously studied. We also develop graph characterizations, which simplifies the computation of the achievable rate region.\n    ",
        "primary_category": "cs.IT",
        "categories": [],
        "submitted_date": "7 Dec 2023",
        "last_revised_date": " "
    },
    "2312.05248": {
        "title": "Topology-Based Reconstruction Prevention for Decentralised Learning",
        "authors": [
            "Florine W. Dekker",
            "Zekeriya Erkin",
            "Mauro Conti"
        ],
        "comments": "13 pages, 8 figures, submitted to PETS 2024, for associated experiment source code see doi:https://doi.org/10.4121/21572601",
        "subjects": "Cryptography and Security (cs.CR)",
        "abstract": "Decentralised learning has recently gained traction as an alternative to federated learning in which both data and coordination are distributed over its users. To preserve data confidentiality, decentralised learning relies on differential privacy, multi-party computation, or a combination thereof. However, running multiple privacy-preserving summations in sequence may allow adversaries to perform reconstruction attacks. Unfortunately, current reconstruction countermeasures either cannot trivially be adapted to the distributed setting, or add excessive amounts of noise.\nIn this work, we first show that passive honest-but-curious adversaries can infer other users' private data after several privacy-preserving summations. For example, in subgraphs with 18 users, we show that only three passive honest-but-curious adversaries succeed at reconstructing private data 11.0% of the time, requiring an average of 8.8 summations per adversary. The success rate depends only on the adversaries' direct neighbourhood, independent of the size of the full network. We consider weak adversaries, who do not control the graph topology and can exploit neither the inner workings of the summation protocol nor the specifics of users' data.\nWe develop a mathematical understanding of how reconstruction relates to topology and propose the first topology-based decentralised defence against reconstruction attacks. Specifically, we show that reconstruction requires a number of adversaries linear in the length of the network's shortest cycle. Consequently, reconstructing private data from privacy-preserving summations is impossible in acyclic networks.\nOur work is a stepping stone for a formal theory of topology-based reconstruction defences. Such a theory would generalise our countermeasure beyond summation, define confidentiality in terms of entropy, and describe the effects of differential privacy.\n    ",
        "primary_category": "cs.CR",
        "categories": [
            "cs.DC",
            "cs.DM",
            "cs.LG"
        ],
        "submitted_date": "8 Dec 2023",
        "last_revised_date": " "
    },
    "2312.05760": {
        "title": "RepViT-SAM: Towards Real-Time Segmenting Anything",
        "authors": [
            "Ao Wang",
            "Hui Chen",
            "Zijia Lin",
            "Jungong Han",
            "Guiguang Ding"
        ],
        "comments": "Technical report of RepViT+SAM in our CVPR 2024 work. Project page: this https URL",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Segment Anything Model (SAM) has shown impressive zero-shot transfer performance for various computer vision tasks recently. However, its heavy computation costs remain daunting for practical applications. MobileSAM proposes to replace the heavyweight image encoder in SAM with TinyViT by employing distillation, which results in a significant reduction in computational requirements. However, its deployment on resource-constrained mobile devices still encounters challenges due to the substantial memory and computational overhead caused by self-attention mechanisms. Recently, RepViT achieves the state-of-the-art performance and latency trade-off on mobile devices by incorporating efficient architectural designs of ViTs into CNNs. Here, to achieve real-time segmenting anything on mobile devices, following MobileSAM, we replace the heavyweight image encoder in SAM with RepViT model, ending up with the RepViT-SAM model. Extensive experiments show that RepViT-SAM can enjoy significantly better zero-shot transfer capability than MobileSAM, along with nearly $10\\times$ faster inference speed. The code and models are available at \\url{this https URL}.\n    ",
        "primary_category": "cs.CV",
        "categories": [],
        "submitted_date": "10 Dec 2023",
        "last_revised_date": " "
    },
    "2312.07193": {
        "title": "$(\u03c3,\u03b4)$-polycyclic codes in Ore extensions over rings",
        "authors": [
            "Maryam Bajalan",
            "Ivan Landjev",
            "Edgar Mart\u00ednez-Moro",
            "Steve Szabo"
        ],
        "comments": "20 pages, no figure",
        "subjects": "Information Theory (cs.IT)",
        "abstract": "In this paper, we study the algebraic structure of $(\\sigma,\\delta)$-polycyclic codes, defined as submodules in the quotient module $S/Sf$, where $S=R[x,\\sigma,\\delta]$ is the Ore extension ring, $f\\in S$, and $R$ is a finite but not necessarily commutative ring. We establish that the Euclidean duals of $(\\sigma,\\delta)$-polycyclic codes are $(\\sigma,\\delta)$-sequential codes. By using $(\\sigma,\\delta)$-Pseudo Linear Transformation, we define the annihilator dual of $(\\sigma,\\delta)$-polycyclic codes. Then, we demonstrate that the annihilator duals of $(\\sigma,\\delta)$-polycyclic codes maintain their $(\\sigma,\\delta)$-polycyclic nature. Furthermore, we classify when two $(\\sigma,\\delta)$-polycyclic codes are Hamming isometrical equivalent. By employing Wedderburn polynomials, we introduce simple-root $(\\sigma,\\delta)$-polycyclic codes. Subsequently, we define the $(\\sigma, \\delta)$-Mattson-Solomon transform for this class of codes and we address the problem of decomposing these codes by using the properties of Wedderburn polynomials.\n    ",
        "primary_category": "cs.IT",
        "categories": [],
        "submitted_date": "12 Dec 2023",
        "last_revised_date": " "
    },
    "2312.07706": {
        "title": "Near-Optimal Differentially Private k-Core Decomposition",
        "authors": [
            "Laxman Dhulipala",
            "George Z. Li",
            "Quanquan C. Liu"
        ],
        "comments": "20 pages. Abstract shortened to fit requirements. In the new version, we show that our techniques can also help give better analysis of the algorithms in [DLRSSY22]",
        "subjects": "Data Structures and Algorithms (cs.DS)",
        "abstract": "Recent work by Dhulipala et al. \\cite{DLRSSY22} initiated the study of the $k$-core decomposition problem under differential privacy via a connection between low round/depth distributed/parallel graph algorithms and private algorithms with small error bounds. They showed that one can output differentially private approximate $k$-core numbers, while only incurring a multiplicative error of $(2 +\\eta)$ (for any constant $\\eta >0$) and additive error of $\\poly(\\log(n))/\\eps$. In this paper, we revisit this problem. Our main result is an $\\eps$-edge differentially private algorithm for $k$-core decomposition which outputs the core numbers with no multiplicative error and $O(\\text{log}(n)/\\eps)$ additive error. This improves upon previous work by a factor of 2 in the multiplicative error, while giving near-optimal additive error. Our result relies on a novel generalized form of the sparse vector technique, which is especially well-suited for threshold-based graph algorithms; thus, we further strengthen the connection between distributed/parallel graph algorithms and differentially private algorithms.\n    ",
        "primary_category": "cs.DS",
        "categories": [
            "cs.CR",
            "cs.SI"
        ],
        "submitted_date": "12 Dec 2023",
        "last_revised_date": " "
    },
    "2312.09468": {
        "title": "Safe Reinforcement Learning in a Simulated Robotic Arm",
        "authors": [
            "Luka Kova\u010d",
            "Igor Farka\u0161"
        ],
        "comments": "4 pages, 2 figures. Appeared in 2023 International Conference on Artificial Neural Networks (ICANN) proceedings. Published version copyrighted by Springer. This work was funded by the Horizon Europe Twinning project TERAIS, G.A. number 101079338 and in part by the national project APVV-21-0105. Link to the code: this https URL",
        "subjects": "Robotics (cs.RO)",
        "abstract": "Reinforcement learning (RL) agents need to explore their environments in order to learn optimal policies. In many environments and tasks, safety is of critical importance. The widespread use of simulators offers a number of advantages, including safe exploration which will be inevitable in cases when RL systems need to be trained directly in the physical environment (e.g. in human-robot interaction). The popular Safety Gym library offers three mobile agent types that can learn goal-directed tasks while considering various safety constraints. In this paper, we extend the applicability of safe RL algorithms by creating a customized environment with Panda robotic arm where Safety Gym algorithms can be tested. We performed pilot experiments with the popular PPO algorithm comparing the baseline with the constrained version and show that the constrained version is able to learn the equally good policy while better complying with safety constraints and taking longer training time as expected.\n    ",
        "primary_category": "cs.RO",
        "categories": [
            "cs.AI",
            "cs.LG"
        ],
        "submitted_date": "28 Nov 2023",
        "last_revised_date": " "
    },
    "2312.12183": {
        "title": "Poincar\u00e9 Differential Privacy for Hierarchy-Aware Graph Embedding",
        "authors": [
            "Yuecen Wei",
            "Haonan Yuan",
            "Xingcheng Fu",
            "Qingyun Sun",
            "Hao Peng",
            "Xianxian Li",
            "Chunming Hu"
        ],
        "comments": "Accepted by the Thirty-Eighth AAAI Conference on Artificial Intelligence (AAAI-24)",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Hierarchy is an important and commonly observed topological property in real-world graphs that indicate the relationships between supervisors and subordinates or the organizational behavior of human groups. As hierarchy is introduced as a new inductive bias into the Graph Neural Networks (GNNs) in various tasks, it implies latent topological relations for attackers to improve their inference attack performance, leading to serious privacy leakage issues. In addition, existing privacy-preserving frameworks suffer from reduced protection ability in hierarchical propagation due to the deficiency of adaptive upper-bound estimation of the hierarchical perturbation boundary. It is of great urgency to effectively leverage the hierarchical property of data while satisfying privacy guarantees. To solve the problem, we propose the Poincar\u00e9 Differential Privacy framework, named PoinDP, to protect the hierarchy-aware graph embedding based on hyperbolic geometry. Specifically, PoinDP first learns the hierarchy weights for each entity based on the Poincar\u00e9 model in hyperbolic space. Then, the Personalized Hierarchy-aware Sensitivity is designed to measure the sensitivity of the hierarchical structure and adaptively allocate the privacy protection strength. Besides, the Hyperbolic Gaussian Mechanism (HGM) is proposed to extend the Gaussian mechanism in Euclidean space to hyperbolic space to realize random perturbations that satisfy differential privacy under the hyperbolic space metric. Extensive experiment results on five real-world datasets demonstrate the proposed PoinDP's advantages of effective privacy protection while maintaining good performance on the node classification task.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.CR"
        ],
        "submitted_date": "19 Dec 2023",
        "last_revised_date": " "
    },
    "2312.12478": {
        "title": "ProS: Prompting-to-simulate Generalized knowledge for Universal Cross-Domain Retrieval",
        "authors": [
            "Kaipeng Fang",
            "Jingkuan Song",
            "Lianli Gao",
            "Pengpeng Zeng",
            "Zhi-Qi Cheng",
            "Xiyao Li",
            "Heng Tao Shen"
        ],
        "comments": " ",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "The goal of Universal Cross-Domain Retrieval (UCDR) is to achieve robust performance in generalized test scenarios, wherein data may belong to strictly unknown domains and categories during training. Recently, pre-trained models with prompt tuning have shown strong generalization capabilities and attained noteworthy achievements in various downstream tasks, such as few-shot learning and video-text retrieval. However, applying them directly to UCDR may not sufficiently to handle both domain shift (i.e., adapting to unfamiliar domains) and semantic shift (i.e., transferring to unknown categories). To this end, we propose \\textbf{Pro}mpting-to-\\textbf{S}imulate (ProS), the first method to apply prompt tuning for UCDR. ProS employs a two-step process to simulate Content-aware Dynamic Prompts (CaDP) which can impact models to produce generalized features for UCDR. Concretely, in Prompt Units Learning stage, we introduce two Prompt Units to individually capture domain and semantic knowledge in a mask-and-align way. Then, in Context-aware Simulator Learning stage, we train a Content-aware Prompt Simulator under a simulated test scenarios to produce the corresponding CaDP. Extensive experiments conducted on three benchmark datasets show that our method achieves new state-of-the-art performance without bringing excessive parameters. Our method is publicly available at this https URL.\n    ",
        "primary_category": "cs.CV",
        "categories": [],
        "submitted_date": "19 Dec 2023",
        "last_revised_date": " "
    },
    "2312.14305": {
        "title": "The Exact Spanning Ratio of the Parallelogram Delaunay Graph",
        "authors": [
            "Prosenjit Bose",
            "Jean-Lou De Carufel",
            "Sandrine Njoo"
        ],
        "comments": " ",
        "subjects": "Computational Geometry (cs.CG)",
        "abstract": "Finding the exact spanning ratio of a Delaunay graph has been one of the longstanding open problems in Computational Geometry. Currently there are only four convex shapes for which the exact spanning ratio of their Delaunay graph is known: the equilateral triangle, the square, the regular hexagon and the rectangle. In this paper, we show the exact spanning ratio of the parallelogram Delaunay graph, making the parallelogram the fifth convex shape for which an exact bound is known. The worst-case spanning ratio is exactly $$\\frac{\\sqrt{2}\\sqrt{1+A^2+2A\\cos(\\theta_0)+(A+\\cos(\\theta_0))\\sqrt{1+A^2+2A\\cos(\\theta_0)}}}{\\sin(\\theta_0)} .$$ where $A$ is the aspect ratio and $\\theta_0$ is the non-obtuse angle of the parallelogram. Moreover, we show how to construct a parallelogram Delaunay graph whose spanning ratio matches the above mentioned spanning ratio.\n    ",
        "primary_category": "cs.CG",
        "categories": [],
        "submitted_date": "21 Dec 2023",
        "last_revised_date": " "
    },
    "2312.14949": {
        "title": "LLM Interactive Optimization of Open Source Python Libraries -- Case Studies and Generalization",
        "authors": [
            "Andreas Florath"
        ],
        "comments": "20 pages, 10 figures",
        "subjects": "Software Engineering (cs.SE)",
        "abstract": "With the advent of large language models (LLMs) like GPT-3, a natural question is the extent to which these models can be utilized for source code optimization. This paper presents methodologically stringent case studies applied to well-known open source python libraries pillow and numpy. We find that contemporary LLM ChatGPT-4 (state September and October 2023) is surprisingly adept at optimizing energy and compute efficiency. However, this is only the case in interactive use, with a human expert in the loop. Aware of experimenter bias, we document our qualitative approach in detail, and provide transcript and source code. We start by providing a detailed description of our approach in conversing with the LLM to optimize the _getextrema function in the pillow library, and a quantitative evaluation of the performance improvement. To demonstrate qualitative replicability, we report further attempts on another locus in the pillow library, and one code locus in the numpy library, to demonstrate generalization within and beyond a library. In all attempts, the performance improvement is significant (factor up to 38). We have also not omitted reporting of failed attempts (there were none). We conclude that LLMs are a promising tool for code optimization in open source libraries, but that the human expert in the loop is essential for success. Nonetheless, we were surprised by how few iterations were required to achieve substantial performance improvements that were not obvious to the expert in the loop. We would like bring attention to the qualitative nature of this study, more robust quantitative studies would need to introduce a layer of selecting experts in a representative sample -- we invite the community to collaborate.\n    ",
        "primary_category": "cs.SE",
        "categories": [
            "cs.AI",
            "cs.HC",
            "cs.PF"
        ],
        "submitted_date": "8 Dec 2023",
        "last_revised_date": " "
    },
    "2312.16475": {
        "title": "Federated Continual Learning via Knowledge Fusion: A Survey",
        "authors": [
            "Xin Yang",
            "Hao Yu",
            "Xin Gao",
            "Hao Wang",
            "Junbo Zhang",
            "Tianrui Li"
        ],
        "comments": "20 pages",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Data privacy and silos are nontrivial and greatly challenging in many real-world applications. Federated learning is a decentralized approach to training models across multiple local clients without the exchange of raw data from client devices to global servers. However, existing works focus on a static data environment and ignore continual learning from streaming data with incremental tasks. Federated Continual Learning (FCL) is an emerging paradigm to address model learning in both federated and continual learning environments. The key objective of FCL is to fuse heterogeneous knowledge from different clients and retain knowledge of previous tasks while learning on new ones. In this work, we delineate federated learning and continual learning first and then discuss their integration, i.e., FCL, and particular FCL via knowledge fusion. In summary, our motivations are four-fold: we (1) raise a fundamental problem called ''spatial-temporal catastrophic forgetting'' and evaluate its impact on the performance using a well-known method called federated averaging (FedAvg), (2) integrate most of the existing FCL methods into two generic frameworks, namely synchronous FCL and asynchronous FCL, (3) categorize a large number of methods according to the mechanism involved in knowledge fusion, and finally (4) showcase an outlook on the future work of FCL.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "27 Dec 2023",
        "last_revised_date": " "
    },
    "2312.16624": {
        "title": "Dual-stage optimizer for systematic overestimation adjustment applied to multi-objective genetic algorithms for biomarker selection",
        "authors": [
            "Luca Cattelani",
            "Vittorio Fortino"
        ],
        "comments": "Added link to source code repository",
        "subjects": "Quantitative Methods (q-bio.QM)",
        "abstract": "The challenge in biomarker discovery using machine learning from omics data lies in the abundance of molecular features but scarcity of samples. Most feature selection methods in machine learning require evaluating various sets of features (models) to determine the most effective combination. This process, typically conducted using a validation dataset, involves testing different feature sets to optimize the model's performance. Evaluations have performance estimation error and when the selection involves many models the best ones are almost certainly overestimated. Biomarker identification with feature selection methods can be addressed as a multi-objective problem with trade-offs between predictive ability and parsimony in the number of features. Genetic algorithms are a popular tool for multi-objective optimization but they evolve numerous solutions thus are prone to overestimation. Methods have been proposed to reduce the overestimation after a model has already been selected in single-objective problems, but no algorithm existed capable of reducing the overestimation during the optimization, improving model selection, or applied in the more general multi-objective domain. We propose DOSA-MO, a novel multi-objective optimization wrapper algorithm that learns how the original estimation, its variance, and the feature set size of the solutions predict the overestimation. DOSA-MO adjusts the expectation of the performance during the optimization, improving the composition of the solution set. We verify that DOSA-MO improves the performance of a state-of-the-art genetic algorithm on left-out or external sample sets, when predicting cancer subtypes and/or patient overall survival, using three transcriptomics datasets for kidney and breast cancer.\n    ",
        "primary_category": "q-bio.QM",
        "categories": [
            "cs.LG"
        ],
        "submitted_date": "27 Dec 2023",
        "last_revised_date": " "
    },
    "2312.16731": {
        "title": "Infinite dSprites for Disentangled Continual Learning: Separating Memory Edits from Generalization",
        "authors": [
            "Sebastian Dziadzio",
            "\u00c7a\u011fatay Y\u0131ld\u0131z",
            "Gido M. van de Ven",
            "Tomasz Trzci\u0144ski",
            "Tinne Tuytelaars",
            "Matthias Bethge"
        ],
        "comments": "10 pages, 10 figures",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "The ability of machine learning systems to learn continually is hindered by catastrophic forgetting, the tendency of neural networks to overwrite existing knowledge when learning a new task. Continual learning methods alleviate this problem through regularization, parameter isolation, or rehearsal, but they are typically evaluated on benchmarks comprising only a handful of tasks. In contrast, humans are able to learn continually in dynamic, open-world environments, effortlessly achieving one-shot memorization of unfamiliar objects and reliably recognizing them under various transformations. To make progress towards closing this gap, we introduce Infinite dSprites, a parsimonious tool for creating continual classification and disentanglement benchmarks of arbitrary length and with full control over generative factors. We show that over a sufficiently long time horizon, the performance of all major types of continual learning methods deteriorates on this simple benchmark. Thus, Infinite dSprites highlights an important aspect of continual learning that has not received enough attention so far: given a finite modelling capacity and an arbitrarily long learning horizon, efficient learning requires memorizing class-specific information and accumulating knowledge about general mechanisms. In a simple setting with direct supervision on the generative factors, we show how learning class-agnostic transformations offers a way to circumvent catastrophic forgetting and improve classification accuracy over time. Our approach sets the stage for continual learning over hundreds of tasks with explicit control over memorization and forgetting, emphasizing open-set classification and one-shot generalization.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.CV"
        ],
        "submitted_date": "27 Dec 2023",
        "last_revised_date": " "
    },
    "2401.02982": {
        "title": "BIBench: Benchmarking Data Analysis Knowledge of Large Language Models",
        "authors": [
            "Shu Liu",
            "Shangqing Zhao",
            "Chenghao Jia",
            "Xinlin Zhuang",
            "Zhaoguang Long",
            "Qingquan Wu",
            "Chong Yang",
            "Aimin Zhou",
            "Man Lan"
        ],
        "comments": " ",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "Large Language Models (LLMs) have demonstrated impressive capabilities across a wide range of tasks. However, their proficiency and reliability in the specialized domain of Data Analysis, particularly with a focus on data-driven thinking, remain uncertain. To bridge this gap, we introduce BIBench, a comprehensive benchmark designed to evaluate the data analysis capabilities of LLMs within the context of Business Intelligence (BI). BIBench assesses LLMs across three dimensions: 1) BI foundational knowledge, evaluating the models' numerical reasoning and familiarity with financial concepts; 2) BI knowledge application, determining the models' ability to quickly comprehend textual information and generate analysis questions from multiple views; and 3) BI technical skills, examining the models' use of technical knowledge to address real-world data analysis challenges. BIBench comprises 11 sub-tasks, spanning three categories of task types: classification, extraction, and generation. Additionally, we've developed BIChat, a domain-specific dataset with over a million data points, to fine-tune LLMs. We will release BIBenchmark, BIChat, and the evaluation scripts at \\url{this https URL}. This benchmark aims to provide a measure for in-depth analysis of LLM abilities and foster the advancement of LLMs in the field of data analysis.\n    ",
        "primary_category": "cs.CL",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "1 Jan 2024",
        "last_revised_date": " "
    },
    "2401.06349": {
        "title": "ADAPT: Alzheimer Diagnosis through Adaptive Profiling Transformers",
        "authors": [
            "Yifeng Wang",
            "Ke Chen",
            "Haohan Wang"
        ],
        "comments": " ",
        "subjects": "Image and Video Processing (eess.IV)",
        "abstract": "Automated diagnosis of Alzheimer Disease(AD) from brain imaging, such as magnetic resonance imaging (MRI), has become increasingly important and has attracted the community to contribute many deep learning methods. However, many of these methods are facing a trade-off that 3D models tend to be complicated while 2D models cannot capture the full 3D intricacies from the data. In this paper, we introduce a new model structure for diagnosing AD, and it can complete with performances of 3D models while essentially is a 2D method (thus computationally efficient). While the core idea lies in new perspective of cutting the 3D images into multiple 2D slices from three dimensions, we introduce multiple components that can further benefit the model in this new perspective, including adaptively selecting the number of sclices in each dimension, and the new attention mechanism. In addition, we also introduce a morphology augmentation, which also barely introduces new computational loads, but can help improve the diagnosis performances due to its alignment to the pathology of AD. We name our method ADAPT, which stands for Alzheimer Diagnosis through Adaptive Profiling Transformers. We test our model from a practical perspective (the testing domains do not appear in the training one): the diagnosis accuracy favors our ADAPT, while ADAPT uses less parameters than most 3D models use.\n    ",
        "primary_category": "eess.IV",
        "categories": [
            "cs.CV"
        ],
        "submitted_date": "12 Jan 2024",
        "last_revised_date": " "
    },
    "2401.06788": {
        "title": "The NPU-ASLP-LiAuto System Description for Visual Speech Recognition in CNVSRC 2023",
        "authors": [
            "He Wang",
            "Pengcheng Guo",
            "Wei Chen",
            "Pan Zhou",
            "Lei Xie"
        ],
        "comments": "Included in CNVSRC Workshop 2023, NCMMSC 2023",
        "subjects": "Audio and Speech Processing (eess.AS)",
        "abstract": "This paper delineates the visual speech recognition (VSR) system introduced by the NPU-ASLP-LiAuto (Team 237) in the first Chinese Continuous Visual Speech Recognition Challenge (CNVSRC) 2023, engaging in the fixed and open tracks of Single-Speaker VSR Task, and the open track of Multi-Speaker VSR Task. In terms of data processing, we leverage the lip motion extractor from the baseline1 to produce multi-scale video data. Besides, various augmentation techniques are applied during training, encompassing speed perturbation, random rotation, horizontal flipping, and color transformation. The VSR model adopts an end-to-end architecture with joint CTC/attention loss, comprising a ResNet3D visual frontend, an E-Branchformer encoder, and a Transformer decoder. Experiments show that our system achieves 34.76% CER for the Single-Speaker Task and 41.06% CER for the Multi-Speaker Task after multi-system fusion, ranking first place in all three tracks we participate.\n    ",
        "primary_category": "eess.AS",
        "categories": [
            "cs.AI",
            "cs.SD"
        ],
        "submitted_date": "7 Jan 2024",
        "last_revised_date": " "
    },
    "2401.07408": {
        "title": "Multimodal Language and Graph Learning of Adsorption Configuration in Catalysis",
        "authors": [
            "Janghoon Ock",
            "Rishikesh Magar",
            "Akshay Antony",
            "Amir Barati Farimani"
        ],
        "comments": "28 pages, 6 figures, supplementary information added",
        "subjects": "Computational Engineering, Finance, and Science (cs.CE)",
        "abstract": "Adsorption energy, a reactivity descriptor, should be accurately assessed for efficient catalyst screening. This evaluation requires determining the lowest energy across various adsorption configurations on the catalytic surface. While graph neural networks (GNNs) have gained popularity as a machine learning approach for computing the energy of catalyst systems, they rely heavily on atomic spatial coordinates and often lack clarity in their interpretations. Recent advancements in language models have broadened their applicability to predicting catalytic properties, allowing us to bypass the complexities of graph representation. These models are adept at handling textual data, making it possible to incorporate observable features in a human-readable format. However, language models encounter challenges in accurately predicting the energy of adsorption configurations, typically showing a high mean absolute error (MAE) of about 0.71 eV. Our study addresses this limitation by introducing a self-supervised multi-modal learning approach, termed graph-assisted pretraining. This method significantly reduces the MAE to 0.35 eV through a combination of data augmentation, achieving comparable accuracy with DimeNet++ while using 0.4% of its training data size. Furthermore, the Transformer encoder at the core of the language model can provide insights into the feature focus through its attention scores. This analysis shows that our multimodal training effectively redirects the model's attention toward relevant adsorption configurations from adsorbate-related features, enhancing prediction accuracy and interpretability.\n    ",
        "primary_category": "cs.CE",
        "categories": [],
        "submitted_date": "15 Jan 2024",
        "last_revised_date": " "
    },
    "2401.09181": {
        "title": "Beyond Anti-Forgetting: Multimodal Continual Instruction Tuning with Positive Forward Transfer",
        "authors": [
            "Junhao Zheng",
            "Qianli Ma",
            "Zhen Liu",
            "Binquan Wu",
            "Huawen Feng"
        ],
        "comments": " ",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Multimodal Continual Instruction Tuning (MCIT) enables Multimodal Large Language Models (MLLMs) to meet continuously emerging requirements without expensive retraining. MCIT faces two major obstacles: catastrophic forgetting (where old knowledge is forgotten) and negative forward transfer (where the performance of future tasks is degraded). Although existing methods have greatly alleviated catastrophic forgetting, they still suffer from negative forward transfer. By performing singular value decomposition (SVD) on input embeddings, we discover a large discrepancy in different input embeddings. The discrepancy results in the model learning irrelevant information for old and pre-trained tasks, which leads to catastrophic forgetting and negative forward transfer. To address these issues, we propose Fwd-Prompt, a prompt-based method projecting prompt gradient to the residual space to minimize the interference between tasks and to the pre-trained subspace for reusing pre-trained knowledge. Our experiments demonstrate that Fwd-Prompt achieves state-of-the-art performance while updating fewer parameters and requiring no old samples. Our research sheds light on the potential of continuously adapting MLLMs to new tasks under the instruction tuning paradigm and encourages future studies to explore MCIT. The code will soon be publicly available.\n    ",
        "primary_category": "cs.LG",
        "categories": [],
        "submitted_date": "17 Jan 2024",
        "last_revised_date": " "
    },
    "2401.11627": {
        "title": "Tight Verification of Probabilistic Robustness in Bayesian Neural Networks",
        "authors": [
            "Ben Batten",
            "Mehran Hosseini",
            "Alessio Lomuscio"
        ],
        "comments": "Accepted at AISTATS 2024",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "We introduce two algorithms for computing tight guarantees on the probabilistic robustness of Bayesian Neural Networks (BNNs). Computing robustness guarantees for BNNs is a significantly more challenging task than verifying the robustness of standard Neural Networks (NNs) because it requires searching the parameters' space for safe weights. Moreover, tight and complete approaches for the verification of standard NNs, such as those based on Mixed-Integer Linear Programming (MILP), cannot be directly used for the verification of BNNs because of the polynomial terms resulting from the consecutive multiplication of variables encoding the weights. Our algorithms efficiently and effectively search the parameters' space for safe weights by using iterative expansion and the network's gradient and can be used with any verification algorithm of choice for BNNs. In addition to proving that our algorithms compute tighter bounds than the SoA, we also evaluate our algorithms against the SoA on standard benchmarks, such as MNIST and CIFAR10, showing that our algorithms compute bounds up to 40% tighter than the SoA.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.AI",
            "cs.FL",
            "cs.LO"
        ],
        "submitted_date": "21 Jan 2024",
        "last_revised_date": " "
    },
    "2401.12202": {
        "title": "OK-Robot: What Really Matters in Integrating Open-Knowledge Models for Robotics",
        "authors": [
            "Peiqi Liu",
            "Yaswanth Orru",
            "Jay Vakil",
            "Chris Paxton",
            "Nur Muhammad Mahi Shafiullah",
            "Lerrel Pinto"
        ],
        "comments": "Github repo: this https URL",
        "subjects": "Robotics (cs.RO)",
        "abstract": "Remarkable progress has been made in recent years in the fields of vision, language, and robotics. We now have vision models capable of recognizing objects based on language queries, navigation systems that can effectively control mobile systems, and grasping models that can handle a wide range of objects. Despite these advancements, general-purpose applications of robotics still lag behind, even though they rely on these fundamental capabilities of recognition, navigation, and grasping. In this paper, we adopt a systems-first approach to develop a new Open Knowledge-based robotics framework called OK-Robot. By combining Vision-Language Models (VLMs) for object detection, navigation primitives for movement, and grasping primitives for object manipulation, OK-Robot offers a integrated solution for pick-and-drop operations without requiring any training. To evaluate its performance, we run OK-Robot in 10 real-world home environments. The results demonstrate that OK-Robot achieves a 58.5% success rate in open-ended pick-and-drop tasks, representing a new state-of-the-art in Open Vocabulary Mobile Manipulation (OVMM) with nearly 1.8x the performance of prior work. On cleaner, uncluttered environments, OK-Robot's performance increases to 82%. However, the most important insight gained from OK-Robot is the critical role of nuanced details when combining Open Knowledge systems like VLMs with robotic modules. Videos of our experiments and code are available on our website: this https URL\n",
        "primary_category": "cs.RO",
        "categories": [
            "cs.AI",
            "cs.CV",
            "cs.LG"
        ],
        "submitted_date": "22 Jan 2024",
        "last_revised_date": " "
    },
    "2401.12413": {
        "title": "How Far Can 100 Samples Go? Unlocking Overall Zero-Shot Multilingual Translation via Tiny Multi-Parallel Data",
        "authors": [
            "Di Wu",
            "Shaomu Tan",
            "Yan Meng",
            "David Stap",
            "Christof Monz"
        ],
        "comments": "15 pages, 5 figures",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "Zero-shot translation aims to translate between language pairs not seen during training in Multilingual Machine Translation (MMT) and is largely considered an open problem. A common, albeit resource-consuming, solution is to add as many related translation directions as possible to the training corpus. In this paper, we show that for an English-centric model, surprisingly large zero-shot improvements can be achieved by simply fine-tuning with a very small amount of multi-parallel data. For example, on the EC30 dataset, we obtain up to +21.7 ChrF non-English overall improvements (870 directions) by using only 100 multi-parallel samples while preserving English-centric translation quality. When investigating the size effect of fine-tuning data and its transfer capabilities, we found that already a small, randomly sampled set of fine-tuning directions is sufficient to achieve comparable improvements. The resulting non-English performance is close to the complete translation upper bound. Even in a minimal setting -- fine-tuning with only one single sample -- the well-known off-target issue is almost completely resolved, explaining parts -- but not all -- of the observed improvements in translation quality.\n    ",
        "primary_category": "cs.CL",
        "categories": [
            "cs.LG"
        ],
        "submitted_date": "22 Jan 2024",
        "last_revised_date": " "
    },
    "2401.13172": {
        "title": "ADMap: Anti-disturbance framework for reconstructing online vectorized HD map",
        "authors": [
            "Haotian Hu",
            "Fanyi Wang",
            "Yaonong Wang",
            "Laifeng Hu",
            "Jingwei Xu",
            "Zhiwang Zhang"
        ],
        "comments": " ",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "In the field of autonomous driving, online high-definition (HD) map reconstruction is crucial for planning tasks. Recent research has developed several high-performance HD map reconstruction models to meet this necessity. However, the point sequences within the instance vectors may be jittery or jagged due to prediction bias, which can impact subsequent tasks. Therefore, this paper proposes the Anti-disturbance Map reconstruction framework (ADMap). To mitigate point-order jitter, the framework consists of three modules: Multi-Scale Perception Neck, Instance Interactive Attention (IIA), and Vector Direction Difference Loss (VDDL). By exploring the point-order relationships between and within instances in a cascading manner, the model can monitor the point-order prediction process more effectively. ADMap achieves state-of-the-art performance on the nuScenes and Argoverse2 datasets. Extensive results demonstrate its ability to produce stable and reliable map elements in complex and changing driving scenarios. Code and more demos are available at this https URL.\n    ",
        "primary_category": "cs.CV",
        "categories": [],
        "submitted_date": "24 Jan 2024",
        "last_revised_date": " "
    },
    "2401.13919": {
        "title": "WebVoyager: Building an End-to-End Web Agent with Large Multimodal Models",
        "authors": [
            "Hongliang He",
            "Wenlin Yao",
            "Kaixin Ma",
            "Wenhao Yu",
            "Yong Dai",
            "Hongming Zhang",
            "Zhenzhong Lan",
            "Dong Yu"
        ],
        "comments": " ",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "The rapid advancement of large language models (LLMs) has led to a new era marked by the development of autonomous applications in real-world scenarios, which drives innovation in creating advanced web agents. Existing web agents typically only handle one input modality and are evaluated only in simplified web simulators or static web snapshots, greatly limiting their applicability in real-world scenarios. To bridge this gap, we introduce WebVoyager, an innovative Large Multimodal Model (LMM) powered web agent that can complete user instructions end-to-end by interacting with real-world websites. Moreover, we establish a new benchmark by compiling real-world tasks from 15 popular websites and introduce an automatic evaluation protocol leveraging multimodal understanding abilities of GPT-4V to evaluate open-ended web agents. We show that WebVoyager achieves a 59.1% task success rate on our benchmark, significantly surpassing the performance of both GPT-4 (All Tools) and the WebVoyager (text-only) setups, underscoring the exceptional capability of WebVoyager. The proposed automatic evaluation metric achieves 85.3% agreement with human judgment, indicating its effectiveness in providing reliable and accurate assessments of web agents.\n    ",
        "primary_category": "cs.CL",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "25 Jan 2024",
        "last_revised_date": " "
    },
    "2401.14292": {
        "title": "Single and bi-layered 2-D acoustic soft tactile skin (AST2)",
        "authors": [
            "Vishnu Rajendran",
            "Simon Parsons",
            "Amir Ghalamzan E"
        ],
        "comments": "IEEE Robosoft conference 2024 (accepted)",
        "subjects": "Robotics (cs.RO)",
        "abstract": "This paper aims to present an innovative and cost-effective design for Acoustic Soft Tactile (AST) Skin, with the primary goal of significantly enhancing the accuracy of 2-D tactile feature estimation. The existing challenge lies in achieving precise tactile feature estimation, especially concerning contact geometry characteristics, using cost-effective solutions. We hypothesise that by harnessing acoustic energy through dedicated acoustic channels in 2 layers beneath the sensing surface and analysing amplitude modulation, we can effectively decode interactions on the sensory surface, thereby improving tactile feature estimation. Our approach involves the distinct separation of hardware components responsible for emitting and receiving acoustic signals, resulting in a modular and highly customizable skin design. Practical tests demonstrate the effectiveness of this novel design, achieving remarkable precision in estimating contact normal forces (MAE < 0.8 N), 2D contact localisation (MAE < 0.7 mm), and contact surface diameter (MAE < 0.3 mm). In conclusion, the AST skin, with its innovative design and modular architecture, successfully addresses the challenge of tactile feature estimation. The presented results showcase its ability to precisely estimate various tactile features, making it a practical and cost-effective solution for robotic applications.\n    ",
        "primary_category": "cs.RO",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "25 Jan 2024",
        "last_revised_date": " "
    },
    "2401.15721": {
        "title": "A Study of Acquisition Functions for Medical Imaging Deep Active Learning",
        "authors": [
            "Bonaventure F. P. Dossou"
        ],
        "comments": "Best Poster Award at Deep Learning Indaba 2023 Conference",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "The Deep Learning revolution has enabled groundbreaking achievements in recent years. From breast cancer detection to protein folding, deep learning algorithms have been at the core of very important advancements. However, these modern advancements are becoming more and more data-hungry, especially on labeled data whose availability is scarce: this is even more prevalent in the medical context. In this work, we show how active learning could be very effective in data scarcity situations, where obtaining labeled data (or annotation budget is very limited). We compare several selection criteria (BALD, MeanSTD, and MaxEntropy) on the ISIC 2016 dataset. We also explored the effect of acquired pool size on the model's performance. Our results suggest that uncertainty is useful to the Melanoma detection task, and confirms the hypotheses of the author of the paper of interest, that \\textit{bald} performs on average better than other acquisition functions. Our extended analyses however revealed that all acquisition functions perform badly on the positive (cancerous) samples, suggesting exploitation of class unbalance, which could be crucial in real-world settings. We finish by suggesting future work directions that would be useful to improve this current work. The code of our implementation is open-sourced at \\url{this https URL}\n    ",
        "primary_category": "cs.CV",
        "categories": [
            "cs.AI",
            "cs.HC",
            "cs.LG"
        ],
        "submitted_date": "28 Jan 2024",
        "last_revised_date": " "
    },
    "2401.15861": {
        "title": "BPDec: Unveiling the Potential of Masked Language Modeling Decoder in BERT pretraining",
        "authors": [
            "Wen Liang",
            "Youzhi Liang"
        ],
        "comments": " ",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "BERT (Bidirectional Encoder Representations from Transformers) has revolutionized the field of natural language processing through its exceptional performance on numerous tasks. Yet, the majority of researchers have mainly concentrated on enhancements related to the model structure, such as relative position embedding and more efficient attention mechanisms. Others have delved into pretraining tricks associated with Masked Language Modeling, including whole word masking. DeBERTa introduced an enhanced decoder adapted for BERT's encoder model for pretraining, proving to be highly effective. We argue that the design and research around enhanced masked language modeling decoders have been underappreciated. In this paper, we propose several designs of enhanced decoders and introduce BPDec (BERT Pretraining Decoder), a novel method for modeling training. Typically, a pretrained BERT model is fine-tuned for specific Natural Language Understanding (NLU) tasks. In our approach, we utilize the original BERT model as the encoder, making only changes to the decoder without altering the encoder. This approach does not necessitate extensive modifications to the model's architecture and can be seamlessly integrated into existing fine-tuning pipelines and services, offering an efficient and effective enhancement strategy. Compared to other methods, while we also incur a moderate training cost for the decoder during the pretraining process, our approach does not introduce additional training costs during the fine-tuning phase. We test multiple enhanced decoder structures after pretraining and evaluate their performance on the GLUE benchmark. Our results demonstrate that BPDec, having only undergone subtle refinements to the model structure during pretraining, significantly enhances model performance without escalating the inference time and serving budget.\n    ",
        "primary_category": "cs.CL",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "29 Jan 2024",
        "last_revised_date": " "
    },
    "2402.00128": {
        "title": "Real-time Traffic Object Detection for Autonomous Driving",
        "authors": [
            "Abdul Hannan Khan",
            "Syed Tahseen Raza Rizvi",
            "Andreas Dengel"
        ],
        "comments": "\\c{opyright} 20XX IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses, in any current or future media, including reprinting/republishing this material for advertising or promotional purposes, creating new collective works, for resale or redistribution to servers or lists, or reuse of any copyrighted component of this work in other works",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "With recent advances in computer vision, it appears that autonomous driving will be part of modern society sooner rather than later. However, there are still a significant number of concerns to address. Although modern computer vision techniques demonstrate superior performance, they tend to prioritize accuracy over efficiency, which is a crucial aspect of real-time applications. Large object detection models typically require higher computational power, which is achieved by using more sophisticated onboard hardware. For autonomous driving, these requirements translate to increased fuel costs and, ultimately, a reduction in mileage. Further, despite their computational demands, the existing object detectors are far from being real-time. In this research, we assess the robustness of our previously proposed, highly efficient pedestrian detector LSFM on well-established autonomous driving benchmarks, including diverse weather conditions and nighttime scenes. Moreover, we extend our LSFM model for general object detection to achieve real-time object detection in traffic scenes. We evaluate its performance, low latency, and generalizability on traffic object detection datasets. Furthermore, we discuss the inadequacy of the current key performance indicator employed by object detection systems in the context of autonomous driving and propose a more suitable alternative that incorporates real-time requirements.\n    ",
        "primary_category": "cs.CV",
        "categories": [],
        "submitted_date": "31 Jan 2024",
        "last_revised_date": " "
    },
    "2402.00752": {
        "title": "On the Error Analysis of 3D Gaussian Splatting and an Optimal Projection Strategy",
        "authors": [
            "Letian Huang",
            "Jiayang Bai",
            "Jie Guo",
            "Yuanqi Li",
            "Yanwen Guo"
        ],
        "comments": " ",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "3D Gaussian Splatting has garnered extensive attention and application in real-time neural rendering. Concurrently, concerns have been raised about the limitations of this technology in aspects such as point cloud storage, performance, and robustness in sparse viewpoints, leading to various improvements. However, there has been a notable lack of attention to the fundamental problem of projection errors introduced by the local affine approximation inherent in the splatting itself, and the consequential impact of these errors on the quality of photo-realistic rendering. This paper addresses the projection error function of 3D Gaussian Splatting, commencing with the residual error from the first-order Taylor expansion of the projection function. The analysis establishes a correlation between the error and the Gaussian mean position. Subsequently, leveraging function optimization theory, this paper analyzes the function's minima to provide an optimal projection strategy for Gaussian Splatting referred to Optimal Gaussian Splatting, which can accommodate a variety of camera models. Experimental validation further confirms that this projection methodology reduces artifacts, resulting in a more convincingly realistic rendering.\n    ",
        "primary_category": "cs.CV",
        "categories": [
            "cs.GR"
        ],
        "submitted_date": "1 Feb 2024",
        "last_revised_date": " "
    },
    "2402.01109": {
        "title": "Vaccine: Perturbation-aware Alignment for Large Language Model",
        "authors": [
            "Tiansheng Huang",
            "Sihao Hu",
            "Ling Liu"
        ],
        "comments": " ",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "The new paradigm of finetuning-as-a-service introduces a new attack surface for Large Language Models (LLMs): a few harmful data uploaded by users can easily trick the finetuning to produce an alignment-broken model. We conduct an empirical analysis and uncover a \\textit{harmful embedding drift} phenomenon, showing a probable cause of the alignment-broken effect. Inspired by our findings, we propose Vaccine, a perturbation-aware alignment technique to mitigate the security risk of users finetuning. The core idea of Vaccine is to produce invariant hidden embeddings by progressively adding crafted perturbation to them in the alignment phase. This enables the embeddings to withstand harmful perturbation from un-sanitized user data in the finetuning phase. Our results on open source mainstream LLMs (e.g., Llama2, Opt, Vicuna) demonstrate that Vaccine can boost the robustness of alignment against harmful prompts induced embedding drift while reserving reasoning ability towards benign prompts. Our code is available at \\url{this https URL}.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.CL"
        ],
        "submitted_date": "2 Feb 2024",
        "last_revised_date": " "
    },
    "2402.01368": {
        "title": "LIR: A Lightweight Baseline for Image Restoration",
        "authors": [
            "Dongqi Fan",
            "Ting Yue",
            "Xin Zhao",
            "Liang Chang"
        ],
        "comments": " ",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Recently, there have been significant advancements in Image Restoration based on CNN and transformer. However, the inherent characteristics of the Image Restoration task are often overlooked. Many works, instead, only focus on the basic block design and stack numerous such blocks to the model, leading to parameters redundant and computations unnecessary. Thus, the efficiency of the image restoration is hindered. In this paper, we propose a Lightweight Baseline for Image Restoration called LIR to efficiently reconstruct the image and remove degradations (blur, rain, noise, haze). First of all, LIR addresses the degradations existing in the local and global residual connections that are ignored by modern networks, through a simple structural design. Then, to achieve lightweight, a Lightweight Adaptive Attention (LAA) Block is introduced depending on the inherent characteristics of the Image Restoration, which is mainly composed of proposed Adaptive Filters and Attention Blocks. LAA is capable of adaptively sharpening contours, removing degradation, and capturing global information in various Image Restoration scenes in a computation-friendly manner. Extensive experiments demonstrate that our LIR achieves comparable performance to state-of-the-art models with fewer parameters and computations in certain tasks. In addition, it is worth noting that our LIR produces better visual results than state-of-the-art networks that are more in line with the human aesthetic.\n    ",
        "primary_category": "cs.CV",
        "categories": [],
        "submitted_date": "2 Feb 2024",
        "last_revised_date": " "
    },
    "2402.01431": {
        "title": "Approximate Control for Continuous-Time POMDPs",
        "authors": [
            "Yannick Eich",
            "Bastian Alt",
            "Heinz Koeppl"
        ],
        "comments": "To be published in AISTATS 2024",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "This work proposes a decision-making framework for partially observable systems in continuous time with discrete state and action spaces. As optimal decision-making becomes intractable for large state spaces we employ approximation methods for the filtering and the control problem that scale well with an increasing number of states. Specifically, we approximate the high-dimensional filtering distribution by projecting it onto a parametric family of distributions, and integrate it into a control heuristic based on the fully observable system to obtain a scalable policy. We demonstrate the effectiveness of our approach on several partially observed systems, including queueing systems and chemical reaction networks.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "eess.SY",
            "q-bio.QM"
        ],
        "submitted_date": "2 Feb 2024",
        "last_revised_date": " "
    },
    "2402.02694": {
        "title": "Description on IEEE ICME 2024 Grand Challenge: Semi-supervised Acoustic Scene Classification under Domain Shift",
        "authors": [
            "Jisheng Bai",
            "Mou Wang",
            "Haohe Liu",
            "Han Yin",
            "Yafei Jia",
            "Siwei Huang",
            "Yutong Du",
            "Dongzhe Zhang",
            "Dongyuan Shi",
            "Woon-Seng Gan",
            "Mark D. Plumbley",
            "Susanto Rahardja",
            "Bin Xiang",
            "Jianfeng Chen"
        ],
        "comments": " ",
        "subjects": "Audio and Speech Processing (eess.AS)",
        "abstract": "Acoustic scene classification (ASC) is a crucial research problem in computational auditory scene analysis, and it aims to recognize the unique acoustic characteristics of an environment. One of the challenges of the ASC task is the domain shift between training and testing data. Since 2018, ASC challenges have focused on the generalization of ASC models across different recording devices. Although this task, in recent years, has achieved substantial progress in device generalization, the challenge of domain shift between different geographical regions, involving discrepancies such as time, space, culture, and language, remains insufficiently explored at present. In addition, considering the abundance of unlabeled acoustic scene data in the real world, it is important to study the possible ways to utilize these unlabelled data. Therefore, we introduce the task Semi-supervised Acoustic Scene Classification under Domain Shift in the ICME 2024 Grand Challenge. We encourage participants to innovate with semi-supervised learning techniques, aiming to develop more robust ASC models under domain shift.\n    ",
        "primary_category": "eess.AS",
        "categories": [
            "cs.LG",
            "cs.SD"
        ],
        "submitted_date": "5 Feb 2024",
        "last_revised_date": " "
    },
    "2402.03279": {
        "title": "Stepping into the Right Shoes: The Effects of User-Matched Avatar Ethnicity and Gender on Sense of Embodiment in Virtual Reality",
        "authors": [
            "Tiffany D. Do",
            "Camille Isabella Protko",
            "Ryan P. McMahan"
        ],
        "comments": "To appear in IEEE Transactions on Visualization and Computer Graphics",
        "subjects": "Human-Computer Interaction (cs.HC)",
        "abstract": "In many consumer virtual reality (VR) applications, users embody predefined characters that offer minimal customization options, frequently emphasizing storytelling over user choice. We explore whether matching a user's physical characteristics, specifically ethnicity and gender, with their virtual self-avatar affects their sense of embodiment in VR. We conducted a 2 x 2 within-subjects experiment (n=32) with a diverse user population to explore the impact of matching or not matching a user's self-avatar to their ethnicity and gender on their sense of embodiment. Our results indicate that matching the ethnicity of the user and their self-avatar significantly enhances sense of embodiment regardless of gender, extending across various aspects, including appearance, response, and ownership. We also found that matching gender significantly enhanced ownership, suggesting that this aspect is influenced by matching both ethnicity and gender. Interestingly, we found that matching ethnicity specifically affects self-location while matching gender specifically affects one's body ownership.\n    ",
        "primary_category": "cs.HC",
        "categories": [],
        "submitted_date": "5 Feb 2024",
        "last_revised_date": " "
    },
    "2402.03659": {
        "title": "Learning to Generate Explainable Stock Predictions using Self-Reflective Large Language Models",
        "authors": [
            "Kelvin J.L. Koa",
            "Yunshan Ma",
            "Ritchie Ng",
            "Tat-Seng Chua"
        ],
        "comments": "WWW 2024",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Explaining stock predictions is generally a difficult task for traditional non-generative deep learning models, where explanations are limited to visualizing the attention weights on important texts. Today, Large Language Models (LLMs) present a solution to this problem, given their known capabilities to generate human-readable explanations for their decision-making process. However, the task of stock prediction remains challenging for LLMs, as it requires the ability to weigh the varying impacts of chaotic social texts on stock prices. The problem gets progressively harder with the introduction of the explanation component, which requires LLMs to explain verbally why certain factors are more important than the others. On the other hand, to fine-tune LLMs for such a task, one would need expert-annotated samples of explanation for every stock movement in the training set, which is expensive and impractical to scale. To tackle these issues, we propose our Summarize-Explain-Predict (SEP) framework, which utilizes a self-reflective agent and Proximal Policy Optimization (PPO) to let a LLM teach itself how to generate explainable stock predictions in a fully autonomous manner. The reflective agent learns how to explain past stock movements through self-reasoning, while the PPO trainer trains the model to generate the most likely explanations from input texts. The training samples for the PPO trainer are also the responses generated during the reflective process, which eliminates the need for human annotators. Using our SEP framework, we fine-tune a LLM that can outperform both traditional deep-learning and LLM methods in prediction accuracy and Matthews correlation coefficient for the stock classification task. To justify the generalization capability of our framework, we further test it on the portfolio construction task, and demonstrate its effectiveness through various portfolio metrics.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.CL",
            "q-fin.ST"
        ],
        "submitted_date": "6 Feb 2024",
        "last_revised_date": " "
    },
    "2402.03726": {
        "title": "Learning Granger Causality from Instance-wise Self-attentive Hawkes Processes",
        "authors": [
            "Dongxia Wu",
            "Tsuyoshi Id\u00e9",
            "Aur\u00e9lie Lozano",
            "Georgios Kollias",
            "Ji\u0159\u00ed Navr\u00e1til",
            "Naoki Abe",
            "Yi-An Ma",
            "Rose Yu"
        ],
        "comments": " ",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "We address the problem of learning Granger causality from asynchronous, interdependent, multi-type event sequences. In particular, we are interested in discovering instance-level causal structures in an unsupervised manner. Instance-level causality identifies causal relationships among individual events, providing more fine-grained information for decision-making. Existing work in the literature either requires strong assumptions, such as linearity in the intensity function, or heuristically defined model parameters that do not necessarily meet the requirements of Granger causality. We propose Instance-wise Self-Attentive Hawkes Processes (ISAHP), a novel deep learning framework that can directly infer the Granger causality at the event instance level. ISAHP is the first neural point process model that meets the requirements of Granger causality. It leverages the self-attention mechanism of the transformer to align with the principles of Granger causality. We empirically demonstrate that ISAHP is capable of discovering complex instance-level causal structures that cannot be handled by classical models. We also show that ISAHP achieves state-of-the-art performance in proxy tasks involving type-level causal discovery and instance-level event type prediction.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "stat.ML"
        ],
        "submitted_date": "6 Feb 2024",
        "last_revised_date": " "
    },
    "2402.04140": {
        "title": "Advancing Legal Reasoning: The Integration of AI to Navigate Complexities and Biases in Global Jurisprudence with Semi-Automated Arbitration Processes (SAAPs)",
        "authors": [
            "Michael De'Shazer"
        ],
        "comments": " ",
        "subjects": "Artificial Intelligence (cs.AI)",
        "abstract": "This study consists of a novel approach toward the analysis of court judgments spanning five countries, including the United States, the United Kingdom, Rwanda, Sweden and Hong Kong. This study also explores the intersection of the latest advancements in artificial intelligence (AI) and legal analysis, emphasizing the role of AI (specifically generative AI) in identifying human biases and facilitating automated, valid, and coherent multisided argumentation of court judgments with the goal of ensuring consistent application of laws in and across various jurisdictions. By incorporating Advanced Language Models (ALMs) and a newly introduced human-AI collaborative framework, this paper seeks to analyze Grounded Theory-based research design with Advanced Language Models (ALMs) in the practice of law. SHIRLEY is the name of the AI-based application (built on top of OpenAI's GPT technology), focusing on detecting logical inconsistencies and biases across various legal decisions. SHIRLEY analysis is aggregated and is accompanied by a comparison-oriented AI-based application called SAM (also an ALM) to identify relative deviations in SHIRLEY bias detections. Further, a CRITIC is generated within semi-autonomous arbitration process via the ALM, SARA. A novel approach is introduced in the utilization of an AI arbitrator to critically evaluate biases and qualitative-in-nature nuances identified by the aforementioned AI applications (SAM in concert with SHIRLEY), based on the Hague Rules on Business and Human Rights Arbitration. This Semi-Automated Arbitration Process (SAAP) aims to uphold the integrity and fairness of legal judgments by ensuring a nuanced debate-resultant \"understanding\" through a hybrid system of AI and human-based collaborative analysis.\n    ",
        "primary_category": "cs.AI",
        "categories": [
            "cs.CY",
            "cs.HC"
        ],
        "submitted_date": "6 Feb 2024",
        "last_revised_date": " "
    },
    "2402.05699": {
        "title": "Self-Alignment of Large Language Models via Monopolylogue-based Social Scene Simulation",
        "authors": [
            "Xianghe Pang",
            "Shuo Tang",
            "Rui Ye",
            "Yuxin Xiong",
            "Bolun Zhang",
            "Yanfeng Wang",
            "Siheng Chen"
        ],
        "comments": "36 pages, 9 figures",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "Aligning large language models (LLMs) with human values is imperative to mitigate potential adverse effects resulting from their misuse. Drawing from the sociological insight that acknowledging all parties' concerns is a key factor in shaping human values, this paper proposes a novel direction to align LLMs by themselves: social scene simulation. To achieve this, we present MATRIX, a novel social scene simulator that emulates realistic scenes around a user's input query, enabling the LLM to take social consequences into account before responding. MATRIX serves as a virtual rehearsal space, akin to a Monopolylogue, where the LLM performs diverse roles related to the query and practice by itself. To inject this alignment, we fine-tune the LLM with MATRIX-simulated data, ensuring adherence to human values without compromising inference speed. We theoretically show that the LLM with MATRIX outperforms Constitutional AI under mild assumptions. Finally, extensive experiments validate that our method outperforms over 10 baselines across 4 benchmarks. As evidenced by 875 user ratings, our tuned 13B-size LLM exceeds GPT-4 in aligning with human values. Our project page is available at this https URL.\n    ",
        "primary_category": "cs.CL",
        "categories": [
            "cs.AI",
            "cs.CY"
        ],
        "submitted_date": "8 Feb 2024",
        "last_revised_date": " "
    },
    "2402.08208": {
        "title": "Inherent Diverse Redundant Safety Mechanisms for AI-based Software Elements in Automotive Applications",
        "authors": [
            "Mandar Pitale",
            "Alireza Abbaspour",
            "Devesh Upadhyay"
        ],
        "comments": "This article is accepted for the SAE WCX 2024 conference proceedings",
        "subjects": "Artificial Intelligence (cs.AI)",
        "abstract": "This paper explores the role and challenges of Artificial Intelligence (AI) algorithms, specifically AI-based software elements, in autonomous driving systems. These AI systems are fundamental in executing real-time critical functions in complex and high-dimensional environments. They handle vital tasks like multi-modal perception, cognition, and decision-making tasks such as motion planning, lane keeping, and emergency braking. A primary concern relates to the ability (and necessity) of AI models to generalize beyond their initial training data. This generalization issue becomes evident in real-time scenarios, where models frequently encounter inputs not represented in their training or validation data. In such cases, AI systems must still function effectively despite facing distributional or domain shifts. This paper investigates the risk associated with overconfident AI models in safety-critical applications like autonomous driving. To mitigate these risks, methods for training AI models that help maintain performance without overconfidence are proposed. This involves implementing certainty reporting architectures and ensuring diverse training data. While various distribution-based methods exist to provide safety mechanisms for AI models, there is a noted lack of systematic assessment of these methods, especially in the context of safety-critical automotive applications. Many methods in the literature do not adapt well to the quick response times required in safety-critical edge applications. This paper reviews these methods, discusses their suitability for safety-critical applications, and highlights their strengths and limitations. The paper also proposes potential improvements to enhance the safety and reliability of AI algorithms in autonomous vehicles in the context of rapid and accurate decision-making processes.\n    ",
        "primary_category": "cs.AI",
        "categories": [],
        "submitted_date": "13 Feb 2024",
        "last_revised_date": " "
    },
    "2402.09164": {
        "title": "Less is More: Fewer Interpretable Region via Submodular Subset Selection",
        "authors": [
            "Ruoyu Chen",
            "Hua Zhang",
            "Siyuan Liang",
            "Jingzhi Li",
            "Xiaochun Cao"
        ],
        "comments": "Accepted to ICLR 2024 (Oral)",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Image attribution algorithms aim to identify important regions that are highly relevant to model decisions. Although existing attribution solutions can effectively assign importance to target elements, they still face the following challenges: 1) existing attribution methods generate inaccurate small regions thus misleading the direction of correct attribution, and 2) the model cannot produce good attribution results for samples with wrong predictions. To address the above challenges, this paper re-models the above image attribution problem as a submodular subset selection problem, aiming to enhance model interpretability using fewer regions. To address the lack of attention to local regions, we construct a novel submodular function to discover more accurate small interpretation regions. To enhance the attribution effect for all samples, we also impose four different constraints on the selection of sub-regions, i.e., confidence, effectiveness, consistency, and collaboration scores, to assess the importance of various subsets. Moreover, our theoretical analysis substantiates that the proposed function is in fact submodular. Extensive experiments show that the proposed method outperforms SOTA methods on two face datasets (Celeb-A and VGG-Face2) and one fine-grained dataset (CUB-200-2011). For correctly predicted samples, the proposed method improves the Deletion and Insertion scores with an average of 4.9% and 2.5% gain relative to HSIC-Attribution. For incorrectly predicted samples, our method achieves gains of 81.0% and 18.4% compared to the HSIC-Attribution algorithm in the average highest confidence and Insertion score respectively. The code is released at this https URL.\n    ",
        "primary_category": "cs.CV",
        "categories": [
            "cs.LG"
        ],
        "submitted_date": "14 Feb 2024",
        "last_revised_date": " "
    },
    "2402.10060": {
        "title": "Quantum Backtracking in Qrisp Applied to Sudoku Problems",
        "authors": [
            "Raphael Seidel",
            "Ren\u00e9 Zander",
            "Matic Petri\u010d",
            "Niklas Steinmann",
            "David Q. Liu",
            "Nikolay Tcholtchev",
            "Manfred Hauswirth"
        ],
        "comments": " ",
        "subjects": "Quantum Physics (quant-ph)",
        "abstract": "The quantum backtracking algorithm proposed by Ashley Montanaro raised considerable interest, as it provides a quantum speed-up for a large class of classical optimization algorithms. It does not suffer from Barren-Plateaus and transfers well into the fault-tolerant era, as it requires only a limited number of arbitrary angle gates. Despite its potential, the algorithm has seen limited implementation efforts, presumably due to its abstract formulation. In this work, we provide a detailed instruction on implementing the quantum step operator for arbitrary backtracking instances. For a single controlled diffuser of a binary backtracking tree with depth n, our implementation requires only $6n+14$ CX gates. We detail the process of constructing accept and reject oracles for Sudoku problems using our interface to quantum backtracking. The presented code is written using Qrisp, a high-level quantum programming language, making it executable on most current physical backends and simulators. Subsequently, we perform several simulator based experiments and demonstrate solving 4x4 Sudoku instances with up to 9 empty fields. This is, to the best of our knowledge, the first instance of a compilable implementation of this generality, marking a significant and exciting step forward in quantum software engineering.\n    ",
        "primary_category": "quant-ph",
        "categories": [
            "cs.DS",
            "cs.PL"
        ],
        "submitted_date": "15 Feb 2024",
        "last_revised_date": " "
    },
    "2402.10153": {
        "title": "Knowledge-Infused LLM-Powered Conversational Health Agent: A Case Study for Diabetes Patients",
        "authors": [
            "Mahyar Abbasian",
            "Zhongqi Yang",
            "Elahe Khatibi",
            "Pengfei Zhang",
            "Nitish Nagesh",
            "Iman Azimi",
            "Ramesh Jain",
            "Amir M. Rahmani"
        ],
        "comments": "4 pages, 3 figures, and 2 tables, conference paper",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "Effective diabetes management is crucial for maintaining health in diabetic patients. Large Language Models (LLMs) have opened new avenues for diabetes management, facilitating their efficacy. However, current LLM-based approaches are limited by their dependence on general sources and lack of integration with domain-specific knowledge, leading to inaccurate responses. In this paper, we propose a knowledge-infused LLM-powered conversational health agent (CHA) for diabetic patients. We customize and leverage the open-source openCHA framework, enhancing our CHA with external knowledge and analytical capabilities. This integration involves two key components: 1) incorporating the American Diabetes Association dietary guidelines and the Nutritionix information and 2) deploying analytical tools that enable nutritional intake calculation and comparison with the guidelines. We compare the proposed CHA with GPT4. Our evaluation includes 100 diabetes-related questions on daily meal choices and assessing the potential risks associated with the suggested diet. Our findings show that the proposed agent demonstrates superior performance in generating responses to manage essential nutrients.\n    ",
        "primary_category": "cs.CL",
        "categories": [],
        "submitted_date": "15 Feb 2024",
        "last_revised_date": " "
    },
    "2402.10192": {
        "title": "Multi-Excitation Projective Simulation with a Many-Body Physics Inspired Inductive Bias",
        "authors": [
            "Philip A. LeMaitre",
            "Marius Krumm",
            "Hans J. Briegel"
        ],
        "comments": "24 pages, 8 figures; Code repository at this https URL. Added figures and shortened computer maintenance section text for better readability",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "With the impressive progress of deep learning, applications relying on machine learning are increasingly being integrated into daily life. However, most deep learning models have an opaque, oracle-like nature making it difficult to interpret and understand their decisions. This problem led to the development of the field known as eXplainable Artificial Intelligence (XAI). One method in this field known as Projective Simulation (PS) models a chain-of-thought as a random walk of a particle on a graph with vertices that have concepts attached to them. While this description has various benefits, including the possibility of quantization, it cannot be naturally used to model thoughts that combine several concepts simultaneously. To overcome this limitation, we introduce Multi-Excitation Projective Simulation (mePS), a generalization that considers a chain-of-thought to be a random walk of several particles on a hypergraph. A definition for a dynamic hypergraph is put forward to describe the agent's training history along with applications to AI and hypergraph visualization. An inductive bias inspired by the remarkably successful few-body interaction models used in quantum many-body physics is formalized for our classical mePS framework and employed to tackle the exponential complexity associated with naive implementations of hypergraphs. We prove that our inductive bias reduces the complexity from exponential to polynomial, with the exponent representing the cutoff on how many particles can interact. We numerically apply our method to two toy environments and a more complex scenario modelling the diagnosis of a broken computer. These environments demonstrate the resource savings provided by an appropriate choice of inductive bias, as well as showcasing aspects of interpretability. A quantum model for mePS is also briefly outlined and some future directions for it are discussed.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.AI",
            "cs.DM",
            "quant-ph"
        ],
        "submitted_date": "15 Feb 2024",
        "last_revised_date": " "
    },
    "2402.10401": {
        "title": "ManiFPT: Defining and Analyzing Fingerprints of Generative Models",
        "authors": [
            "Hae Jin Song",
            "Mahyar Khayatkhoei",
            "Wael AbdAlmageed"
        ],
        "comments": "Accepted to CVPR 2024",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Recent works have shown that generative models leave traces of their underlying generative process on the generated samples, broadly referred to as fingerprints of a generative model, and have studied their utility in detecting synthetic images from real ones. However, the extend to which these fingerprints can distinguish between various types of synthetic image and help identify the underlying generative process remain under-explored. In particular, the very definition of a fingerprint remains unclear, to our knowledge. To that end, in this work, we formalize the definition of artifact and fingerprint in generative models, propose an algorithm for computing them in practice, and finally study its effectiveness in distinguishing a large array of different generative models. We find that using our proposed definition can significantly improve the performance on the task of identifying the underlying generative process from samples (model attribution) compared to existing methods. Additionally, we study the structure of the fingerprints, and observe that it is very predictive of the effect of different design choices on the generative process.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.CV"
        ],
        "submitted_date": "16 Feb 2024",
        "last_revised_date": " "
    },
    "2402.10487": {
        "title": "Random Projection Layers for Multidimensional Time Series Forecasting",
        "authors": [
            "Chin-Chia Michael Yeh",
            "Yujie Fan",
            "Xin Dai",
            "Vivian Lai",
            "Prince Osei Aboagye",
            "Junpeng Wang",
            "Huiyuan Chen",
            "Yan Zheng",
            "Zhongfang Zhuang",
            "Liang Wang",
            "Wei Zhang"
        ],
        "comments": " ",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "All-Multi-Layer Perceptron (all-MLP) mixer models have been shown to be effective for time series forecasting problems. However, when such a model is applied to high-dimensional time series (e.g., the time series in a spatial-temporal dataset), its performance is likely to degrade due to overfitting issues. In this paper, we propose an all-MLP time series forecasting architecture, referred to as RPMixer. Our method leverages the ensemble-like behavior of deep neural networks, where each individual block within the network acts like a base learner in an ensemble model, especially when identity mapping residual connections are incorporated. By integrating random projection layers into our model, we increase the diversity among the blocks' outputs, thereby enhancing the overall performance of RPMixer. Extensive experiments conducted on large-scale spatial-temporal forecasting benchmark datasets demonstrate that our proposed method outperforms alternative methods, including both spatial-temporal graph models and general forecasting models.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "16 Feb 2024",
        "last_revised_date": " "
    },
    "2402.11050": {
        "title": "Adaptive Constellation Multiple Access for Beyond 5G Wireless Systems",
        "authors": [
            "Indu L. Shakya",
            "Falah H. Ali"
        ],
        "comments": "5 pages, 6 figures, Submission to an IEEE Journal",
        "subjects": "Information Theory (cs.IT)",
        "abstract": "We propose a novel nonorthogonal multiple access (NOMA) scheme referred as adaptive constellation multiple access (ACMA) which addresses key limitations of existing NOMA schemes for beyond 5G wireless systems. Unlike the latter, that are often constrained in choices of allocation of power, modulations and phases to allow enough separation of clusters from users combined signals, ACMA is power, modulation and phase agnostic forming unified constellations instead where distances of all possible neighbouring points are optimized. It includes an algorithm at basestation (BS) calculating phase offsets for users signals such that, when combined, it gives best minimum Euclidean distance of points from all possibilities. The BS adaptively changes the phase offsets whenever system parameters change. We also propose an enhanced receiver using a modified maximum likelihood (MML) method that dynamically exploits information from the BS to blindly estimate correct phase offsets and exploit them to enhance data rate and error performances. Superiority of this scheme, which may also be referred to as AC NOMA, is verified through extensive analyses and simulations.\n    ",
        "primary_category": "cs.IT",
        "categories": [
            "eess.SP"
        ],
        "submitted_date": "16 Feb 2024",
        "last_revised_date": " "
    },
    "2402.11194": {
        "title": "Evaluating LLMs' Mathematical Reasoning in Financial Document Question Answering",
        "authors": [
            "Pragya Srivastava",
            "Manuj Malik",
            "Vivek Gupta",
            "Tanuja Ganu",
            "Dan Roth"
        ],
        "comments": "25 pages, 17 figures",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "Large Language Models (LLMs), excel in natural language understanding, but their capability for complex mathematical reasoning with an amalgamation of structured tables and unstructured text is uncertain. This study explores LLMs' mathematical reasoning on four financial tabular question-answering datasets: TATQA, FinQA, ConvFinQA, and Multihiertt. Through extensive experiments with various models and prompting techniques, we assess how LLMs adapt to complex tables and mathematical tasks. We focus on sensitivity to table complexity and performance variations with an increasing number of arithmetic reasoning steps. The results provide insights into LLMs' capabilities and limitations in handling complex mathematical scenarios for semi-structured tables. Ultimately, we introduce a novel prompting technique tailored to semi-structured documents, matching or outperforming other baselines in performance while providing a nuanced understanding of LLMs abilities for such a task.\n    ",
        "primary_category": "cs.CL",
        "categories": [],
        "submitted_date": "17 Feb 2024",
        "last_revised_date": " "
    },
    "2402.11352": {
        "title": "Unified Capacity Results for Free-Space Optical Communication Systems Over Gamma-Gamma Atmospheric Turbulence Channels",
        "authors": [
            "Himani Verma",
            "Kamal Singh"
        ],
        "comments": " ",
        "subjects": "Information Theory (cs.IT)",
        "abstract": "In terrestrial free-space optical (FSO) communication systems, adaptive power control at the optical laser transmitters is crucial not only to prolong the life span of the laser sources, but more importantly to maintain robust and spectrally efficient communication through atmospheric turbulence. However, a comprehensive study of dynamic power adaptation in existing FSO systems is lacking in the literature. In this paper, we investigate FSO communication systems capable of adaptive laser power control with heterodyne detection (HD) and direct detection (DD) based receivers operating under shot-noise-limited conditions. Under these FSO systems considerations, we derive unified exact and asymptotic formulas for the capacities of Gamma-Gamma atmospheric turbulence channels with and without pointing errors; these novel closed-form capacity expressions are much simpler and provide new insights into the impact of varying turbulence conditions and pointing errors. Finally, the numerical results highlight the intricate relations of atmospheric fading, pointing error, and large-scale channel parameters in a typical terrestrial FSO channel setting, followed up by an accurate assessment of the key parameters determining the capacity performances of the aforementioned FSO systems revealing several interesting characteristics.\n    ",
        "primary_category": "cs.IT",
        "categories": [
            "eess.SP"
        ],
        "submitted_date": "17 Feb 2024",
        "last_revised_date": " "
    },
    "2402.12374": {
        "title": "Sequoia: Scalable, Robust, and Hardware-aware Speculative Decoding",
        "authors": [
            "Zhuoming Chen",
            "Avner May",
            "Ruslan Svirschevski",
            "Yuhsun Huang",
            "Max Ryabinin",
            "Zhihao Jia",
            "Beidi Chen"
        ],
        "comments": " ",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "As the usage of large language models (LLMs) grows, performing efficient inference with these models becomes increasingly important. While speculative decoding has recently emerged as a promising direction for speeding up inference, existing methods are limited in their ability to scale to larger speculation budgets, and adapt to different hyperparameters and hardware. This paper introduces Sequoia, a scalable, robust, and hardware-aware algorithm for speculative decoding. To attain better scalability, Sequoia introduces a dynamic programming algorithm to find the optimal tree structure for the speculated tokens. To achieve robust speculative performance, Sequoia uses a novel sampling and verification method that outperforms prior work across different decoding temperatures. Finally, Sequoia introduces a hardware-aware tree optimizer that maximizes speculative performance by automatically selecting the token tree size and depth for a given hardware platform. Evaluation shows that Sequoia improves the decoding speed of Llama2-7B, Llama2-13B, and Vicuna-33B on an A100 by up to $4.04\\times$, $3.73\\times$, and $2.27\\times$. For offloading setting on L40, Sequoia achieves as low as 0.56 s/token for exact Llama2-70B inference latency, which is $9.96\\times$ on our optimized offloading system (5.6 s/token), $9.7\\times$ than DeepSpeed-Zero-Inference, $19.5\\times$ than Huggingface Accelerate.\n    ",
        "primary_category": "cs.CL",
        "categories": [],
        "submitted_date": "19 Feb 2024",
        "last_revised_date": " "
    },
    "2402.13616": {
        "title": "YOLOv9: Learning What You Want to Learn Using Programmable Gradient Information",
        "authors": [
            "Chien-Yao Wang",
            "I-Hau Yeh",
            "Hong-Yuan Mark Liao"
        ],
        "comments": " ",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Today's deep learning methods focus on how to design the most appropriate objective functions so that the prediction results of the model can be closest to the ground truth. Meanwhile, an appropriate architecture that can facilitate acquisition of enough information for prediction has to be designed. Existing methods ignore a fact that when input data undergoes layer-by-layer feature extraction and spatial transformation, large amount of information will be lost. This paper will delve into the important issues of data loss when data is transmitted through deep networks, namely information bottleneck and reversible functions. We proposed the concept of programmable gradient information (PGI) to cope with the various changes required by deep networks to achieve multiple objectives. PGI can provide complete input information for the target task to calculate objective function, so that reliable gradient information can be obtained to update network weights. In addition, a new lightweight network architecture -- Generalized Efficient Layer Aggregation Network (GELAN), based on gradient path planning is designed. GELAN's architecture confirms that PGI has gained superior results on lightweight models. We verified the proposed GELAN and PGI on MS COCO dataset based object detection. The results show that GELAN only uses conventional convolution operators to achieve better parameter utilization than the state-of-the-art methods developed based on depth-wise convolution. PGI can be used for variety of models from lightweight to large. It can be used to obtain complete information, so that train-from-scratch models can achieve better results than state-of-the-art models pre-trained using large datasets, the comparison results are shown in Figure 1. The source codes are at: this https URL.\n    ",
        "primary_category": "cs.CV",
        "categories": [],
        "submitted_date": "21 Feb 2024",
        "last_revised_date": " "
    },
    "2402.14096": {
        "title": "EyeTrans: Merging Human and Machine Attention for Neural Code Summarization",
        "authors": [
            "Yifan Zhang",
            "Jiliang Li",
            "Zachary Karas",
            "Aakash Bansal",
            "Toby Jia-Jun Li",
            "Collin McMillan",
            "Kevin Leach",
            "Yu Huang"
        ],
        "comments": " ",
        "subjects": "Software Engineering (cs.SE)",
        "abstract": "Neural code summarization leverages deep learning models to automatically generate brief natural language summaries of code snippets. The development of Transformer models has led to extensive use of attention during model design. While existing work has primarily and almost exclusively focused on static properties of source code and related structural representations like the Abstract Syntax Tree (AST), few studies have considered human attention, that is, where programmers focus while examining and comprehending code. In this paper, we develop a method for incorporating human attention into machine attention to enhance neural code summarization. To facilitate this incorporation and vindicate this hypothesis, we introduce EyeTrans, which consists of three steps: (1) we conduct an extensive eye-tracking human study to collect and pre-analyze data for model training, (2) we devise a data-centric approach to integrate human attention with machine attention in the Transformer architecture, and (3) we conduct comprehensive experiments on two code summarization tasks to demonstrate the effectiveness of incorporating human attention into Transformers. Integrating human attention leads to an improvement of up to 29.91% in Functional Summarization and up to 6.39% in General Code Summarization performance, demonstrating the substantial benefits of this combination. We further explore performance in terms of robustness and efficiency by creating challenging summarization scenarios in which EyeTrans exhibits interesting properties. We also visualize the attention map to depict the simplifying effect of machine attention in the Transformer by incorporating human attention. This work has the potential to propel AI research in software engineering by introducing more human-centered approaches and data.\n    ",
        "primary_category": "cs.SE",
        "categories": [
            "cs.AI",
            "cs.HC"
        ],
        "submitted_date": "21 Feb 2024",
        "last_revised_date": " "
    },
    "2402.14148": {
        "title": "Neural Networks and Friction: Slide, Hold, Learn",
        "authors": [
            "Joaquin Garcia-Suarez"
        ],
        "comments": "10 paged, 10 figures, 2 tables",
        "subjects": "Geophysics (physics.geo-ph)",
        "abstract": "In this study, it is demonstrated that Recurrent Neural Networks (RNNs), specifically those utilizing Gated Recurrent Unit (GRU) architecture, possess the capability to learn the complex dynamics of rate-and-state friction laws from synthetic data. The data employed for training the network is generated through the application of traditional rate-and-state friction equations coupled with the aging law for state evolution. A novel aspect of our approach is the formulation of a loss function that explicitly accounts for initial conditions, the direct effect, and the evolution of state variables during training. It is found that the RNN, with its GRU architecture, effectively learns to predict changes in the friction coefficient resulting from velocity jumps, thereby showcasing the potential of machine learning models in understanding and simulating the physics of frictional processes.\n    ",
        "primary_category": "physics.geo-ph",
        "categories": [
            "cs.LG"
        ],
        "submitted_date": "21 Feb 2024",
        "last_revised_date": " "
    },
    "2402.14198": {
        "title": "Tight Inapproximability of Nash Equilibria in Public Goods Games",
        "authors": [
            "J\u00e9r\u00e9mi Do Dinh",
            "Alexandros Hollender"
        ],
        "comments": " ",
        "subjects": "Computer Science and Game Theory (cs.GT)",
        "abstract": "We study public goods games, a type of game where every player has to decide whether or not to produce a good which is public, i.e., neighboring players can also benefit from it. Specifically, we consider a setting where the good is indivisible and where the neighborhood structure is represented by a directed graph, with the players being the nodes. Papadimitriou and Peng (2023) recently showed that in this setting computing mixed Nash equilibria is PPAD-hard, and that this remains the case even for $\\varepsilon$-well-supported approximate equilibria for some sufficiently small constant $\\varepsilon$. In this work, we strengthen this inapproximability result by showing that the problem remains PPAD-hard for any non-trivial approximation parameter $\\varepsilon$.\n    ",
        "primary_category": "cs.GT",
        "categories": [
            "cs.CC"
        ],
        "submitted_date": "22 Feb 2024",
        "last_revised_date": " "
    },
    "2402.14485": {
        "title": "Machine-Checked Categorical Diagrammatic Reasoning",
        "authors": [
            "Beno\u00eet Guillemet",
            "Assia Mahboubi",
            "Matthieu Piquerez"
        ],
        "comments": " ",
        "subjects": "Logic in Computer Science (cs.LO)",
        "abstract": "This paper describes a formal proof library, developed using the Coq proof assistant, designed to assist users in writing correct diagrammatic proofs, for 1-categories. This library proposes a deep-embedded, domain-specific formal language, which features dedicated proof commands to automate the synthesis, and the verification, of the technical parts often eluded in the literature.\n    ",
        "primary_category": "cs.LO",
        "categories": [],
        "submitted_date": "22 Feb 2024",
        "last_revised_date": " "
    },
    "2402.14614": {
        "title": "Two Counterexamples to Tokenization and the Noiseless Channel",
        "authors": [
            "Marco Cognetta",
            "Vil\u00e9m Zouhar",
            "Sangwhan Moon",
            "Naoaki Okazaki"
        ],
        "comments": "9 pages, 2 figures, to appear in LREC-COLING 2024, de-texified metadata",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "In Tokenization and the Noiseless Channel (Zouhar et al., 2023a), R\u00e9nyi efficiency is suggested as an intrinsic mechanism for evaluating a tokenizer: for NLP tasks, the tokenizer which leads to the highest R\u00e9nyi efficiency of the unigram distribution should be chosen. The R\u00e9nyi efficiency is thus treated as a predictor of downstream performance (e.g., predicting BLEU for a machine translation task), without the expensive step of training multiple models with different tokenizers. Although useful, the predictive power of this metric is not perfect, and the authors note there are additional qualities of a good tokenization scheme that R\u00e9nyi efficiency alone cannot capture.\nWe describe two variants of BPE tokenization which can arbitrarily increase R\u00e9nyi efficiency while decreasing the downstream model performance. These counterexamples expose cases where R\u00e9nyi efficiency fails as an intrinsic tokenization metric and thus give insight for building more accurate predictors.\n    ",
        "primary_category": "cs.CL",
        "categories": [],
        "submitted_date": "22 Feb 2024",
        "last_revised_date": " "
    },
    "2402.14808": {
        "title": "RelayAttention for Efficient Large Language Model Serving with Long System Prompts",
        "authors": [
            "Lei Zhu",
            "Xinjiang Wang",
            "Wayne Zhang",
            "Rynson W.H. Lau"
        ],
        "comments": "fix typos; add code link",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "Practical large language model (LLM) services may involve a long system prompt, which specifies the instructions, examples, and knowledge documents of the task and is reused across numerous requests. However, the long system prompt causes throughput/latency bottlenecks as the cost of generating the next token grows w.r.t. the sequence length. This paper aims to improve the efficiency of LLM services that involve long system prompts. Our key observation is that handling these system prompts requires heavily redundant memory accesses in existing causal attention computation algorithms. Specifically, for batched requests, the cached hidden states (i.e., key-value pairs) of system prompts are transferred from off-chip DRAM to on-chip SRAM multiple times, each corresponding to an individual request. To eliminate such a redundancy, we propose RelayAttention, an attention algorithm that allows reading these hidden states from DRAM exactly once for a batch of input tokens. RelayAttention is a free lunch: it maintains the generation quality while requiring no model retraining, as it is based on a mathematical reformulation of causal attention. Code is available at \\url{this https URL}.\n    ",
        "primary_category": "cs.CL",
        "categories": [],
        "submitted_date": "22 Feb 2024",
        "last_revised_date": " "
    },
    "2402.15813": {
        "title": "Measuring Bargaining Abilities of LLMs: A Benchmark and A Buyer-Enhancement Method",
        "authors": [
            "Tian Xia",
            "Zhiwei He",
            "Tong Ren",
            "Yibo Miao",
            "Zhuosheng Zhang",
            "Yang Yang",
            "Rui Wang"
        ],
        "comments": "The dataset AmazonHistoryPrice and our code are available at this https URL",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "Bargaining is an important and unique part of negotiation between humans. As LLM-driven agents learn to negotiate and act like real humans, how to evaluate agents' bargaining abilities remains an open problem. For the first time, we formally described the Bargaining task as an asymmetric incomplete information game, defining the gains of the Buyer and Seller in multiple bargaining processes. It allows us to quantitatively assess an agent's performance in the Bargain task. We collected a real product price dataset, AmazonHistoryPrice, and conducted evaluations of various LLM agents' bargaining abilities. We find that playing a Buyer is much harder than a Seller, and increasing model size can not effectively improve the Buyer's performance. To address the challenge, we propose a novel approach called OG-Narrator that integrates a deterministic Offer Generator to control the price range of Buyer's offers, and an LLM Narrator to create natural language sentences for generated offers. Experimental results show that OG-Narrator improves the buyer's deal rates from 26.67% to 88.88% and brings a ten times of multiplication of profits on all baselines, even a model that has not been aligned.\n    ",
        "primary_category": "cs.CL",
        "categories": [
            "cs.GT"
        ],
        "submitted_date": "24 Feb 2024",
        "last_revised_date": " "
    },
    "2402.16041": {
        "title": "Detecting Machine-Generated Texts by Multi-Population Aware Optimization for Maximum Mean Discrepancy",
        "authors": [
            "Shuhai Zhang",
            "Yiliao Song",
            "Jiahao Yang",
            "Yuanqing Li",
            "Bo Han",
            "Mingkui Tan"
        ],
        "comments": "Accepted at ICLR 2024",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "Large language models (LLMs) such as ChatGPT have exhibited remarkable performance in generating human-like texts. However, machine-generated texts (MGTs) may carry critical risks, such as plagiarism issues, misleading information, or hallucination issues. Therefore, it is very urgent and important to detect MGTs in many situations. Unfortunately, it is challenging to distinguish MGTs and human-written texts because the distributional discrepancy between them is often very subtle due to the remarkable performance of LLMs. In this paper, we seek to exploit \\textit{maximum mean discrepancy} (MMD) to address this issue in the sense that MMD can well identify distributional discrepancies. However, directly training a detector with MMD using diverse MGTs will incur a significantly increased variance of MMD since MGTs may contain \\textit{multiple text populations} due to various LLMs. This will severely impair MMD's ability to measure the difference between two samples. To tackle this, we propose a novel \\textit{multi-population} aware optimization method for MMD called MMD-MP, which can \\textit{avoid variance increases} and thus improve the stability to measure the distributional discrepancy. Relying on MMD-MP, we develop two methods for paragraph-based and sentence-based detection, respectively. Extensive experiments on various LLMs, \\eg, GPT2 and ChatGPT, show superior detection performance of our MMD-MP. The source code is available at \\url{this https URL}.\n    ",
        "primary_category": "cs.CL",
        "categories": [
            "cs.LG"
        ],
        "submitted_date": "25 Feb 2024",
        "last_revised_date": " "
    },
    "2402.16192": {
        "title": "Defending Large Language Models against Jailbreak Attacks via Semantic Smoothing",
        "authors": [
            "Jiabao Ji",
            "Bairu Hou",
            "Alexander Robey",
            "George J. Pappas",
            "Hamed Hassani",
            "Yang Zhang",
            "Eric Wong",
            "Shiyu Chang"
        ],
        "comments": "37 pages",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "Aligned large language models (LLMs) are vulnerable to jailbreaking attacks, which bypass the safeguards of targeted LLMs and fool them into generating objectionable content. While initial defenses show promise against token-based threat models, there do not exist defenses that provide robustness against semantic attacks and avoid unfavorable trade-offs between robustness and nominal performance. To meet this need, we propose SEMANTICSMOOTH, a smoothing-based defense that aggregates the predictions of multiple semantically transformed copies of a given input prompt. Experimental results demonstrate that SEMANTICSMOOTH achieves state-of-the-art robustness against GCG, PAIR, and AutoDAN attacks while maintaining strong nominal performance on instruction following benchmarks such as InstructionFollowing and AlpacaEval. The codes will be publicly available at this https URL.\n    ",
        "primary_category": "cs.CL",
        "categories": [],
        "submitted_date": "25 Feb 2024",
        "last_revised_date": " "
    },
    "2402.16221": {
        "title": "Integrating Preprocessing Methods and Convolutional Neural Networks for Effective Tumor Detection in Medical Imaging",
        "authors": [
            "Ha Anh Vu"
        ],
        "comments": "5 pages, 5 figures, utilizing convolutional neural networks and preprocessing methods for tumor detection in MRI images, featuring a detailed methodology section on image preprocessing, segmentation, and model training, with a comprehensive evaluation of model performance on the Figshare dataset using IEEE template",
        "subjects": "Image and Video Processing (eess.IV)",
        "abstract": "This research presents a machine-learning approach for tumor detection in medical images using convolutional neural networks (CNNs). The study focuses on preprocessing techniques to enhance image features relevant to tumor detection, followed by developing and training a CNN model for accurate classification. Various image processing techniques, including Gaussian smoothing, bilateral filtering, and K-means clustering, are employed to preprocess the input images and highlight tumor regions. The CNN model is trained and evaluated on a dataset of medical images, with augmentation and data generators utilized to enhance model generalization. Experimental results demonstrate the effectiveness of the proposed approach in accurately detecting tumors in medical images, paving the way for improved diagnostic tools in healthcare.\n    ",
        "primary_category": "eess.IV",
        "categories": [
            "cs.CV"
        ],
        "submitted_date": "25 Feb 2024",
        "last_revised_date": " "
    },
    "2402.16235": {
        "title": "Human-AI Co-Creation of Worked Examples for Programming Classes",
        "authors": [
            "Mohammad Hassany",
            "Peter Brusilovsky",
            "Jiaze Ke",
            "Kamil Akhuseyinoglu",
            "Arun Balajiee Lekshmi Narayanan"
        ],
        "comments": "arXiv admin note: substantial text overlap with arXiv:2312.02105",
        "subjects": "Human-Computer Interaction (cs.HC)",
        "abstract": "Worked examples (solutions to typical programming problems presented as a source code in a certain language and are used to explain the topics from a programming class) are among the most popular types of learning content in programming classes. Most approaches and tools for presenting these examples to students are based on line-by-line explanations of the example code. However, instructors rarely have time to provide line-by-line explanations for a large number of examples typically used in a programming class. In this paper, we explore and assess a human-AI collaboration approach to authoring worked examples for Java programming. We introduce an authoring system for creating Java worked examples that generates a starting version of code explanations and presents it to the instructor to edit if necessary.We also present a study that assesses the quality of explanations created with this approach\n    ",
        "primary_category": "cs.HC",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "26 Feb 2024",
        "last_revised_date": " "
    },
    "2402.16459": {
        "title": "Defending LLMs against Jailbreaking Attacks via Backtranslation",
        "authors": [
            "Yihan Wang",
            "Zhouxing Shi",
            "Andrew Bai",
            "Cho-Jui Hsieh"
        ],
        "comments": " ",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "Although many large language models (LLMs) have been trained to refuse harmful requests, they are still vulnerable to jailbreaking attacks, which rewrite the original prompt to conceal its harmful intent. In this paper, we propose a new method for defending LLMs against jailbreaking attacks by ``backtranslation''. Specifically, given an initial response generated by the target LLM from an input prompt, our backtranslation prompts a language model to infer an input prompt that can lead to the response. The inferred prompt is called the backtranslated prompt which tends to reveal the actual intent of the original prompt, since it is generated based on the LLM's response and is not directly manipulated by the attacker. We then run the target LLM again on the backtranslated prompt, and we refuse the original prompt if the model refuses the backtranslated prompt. We explain that the proposed defense provides several benefits on its effectiveness and efficiency. We empirically demonstrate that our defense significantly outperforms the baselines, in the cases that are hard for the baselines, and our defense also has little impact on the generation quality for benign input prompts.\n    ",
        "primary_category": "cs.CL",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "26 Feb 2024",
        "last_revised_date": " "
    },
    "2402.16631": {
        "title": "GenAINet: Enabling Wireless Collective Intelligence via Knowledge Transfer and Reasoning",
        "authors": [
            "Hang Zou",
            "Qiyang Zhao",
            "Lina Bariah",
            "Yu Tian",
            "Mehdi Bennis",
            "Samson Lasaulce",
            "Merouane Debbah",
            "Faouzi Bader"
        ],
        "comments": " ",
        "subjects": "Artificial Intelligence (cs.AI)",
        "abstract": "Generative artificial intelligence (GenAI) and communication networks are expected to have groundbreaking synergies in 6G. Connecting GenAI agents over a wireless network can potentially unleash the power of collective intelligence and pave the way for artificial general intelligence (AGI). However, current wireless networks are designed as a \"data pipe\" and are not suited to accommodate and leverage the power of GenAI. In this paper, we propose the GenAINet framework in which distributed GenAI agents communicate knowledge (high-level concepts or abstracts) to accomplish arbitrary tasks. We first provide a network architecture integrating GenAI capabilities to manage both network protocols and applications. Building on this, we investigate effective communication and reasoning problems by proposing a semantic-native GenAINet. Specifically, GenAI agents extract semantic concepts from multi-modal raw data, build a knowledgebase representing their semantic relations, which is retrieved by GenAI models for planning and reasoning. Under this paradigm, an agent can learn fast from other agents' experience for making better decisions with efficient communications. Furthermore, we conduct two case studies where in wireless device query, we show that extracting and transferring knowledge can improve query accuracy with reduced communication; and in wireless power control, we show that distributed agents can improve decisions via collaborative reasoning. Finally, we address that developing a hierarchical semantic level Telecom world model is a key path towards network of collective intelligence.\n    ",
        "primary_category": "cs.AI",
        "categories": [
            "cs.NI",
            "eess.SP"
        ],
        "submitted_date": "26 Feb 2024",
        "last_revised_date": " "
    },
    "2402.16853": {
        "title": "PyRQA -- Conducting Recurrence Quantification Analysis on Very Long Time Series Efficiently",
        "authors": [
            "Tobias Rawald",
            "Mike Sips",
            "Norbert Marwan"
        ],
        "comments": "15 pages, 3 figures",
        "subjects": "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "abstract": "PyRQA is a software package that efficiently conducts recurrence quantification analysis (RQA) on time series consisting of more than one million data points. RQA is a method from non-linear time series analysis that quantifies the recurrent behaviour of systems. Existing implementations to RQA are not capable of analysing such very long time series at all or require large amounts of time to calculate the quantitative measures. PyRQA overcomes their limitations by conducting the RQA computations in a highly parallel manner. Building on the OpenCL framework, PyRQA leverages the computing capabilities of a variety of parallel hardware architectures, such as GPUs. The underlying computing approach partitions the RQA computations and enables to employ multiple compute devices at the same time. The goal of this publication is to demonstrate the features and the runtime efficiency of PyRQA. For this purpose we employ a real-world example, comparing the dynamics of two climatological time series, and a synthetic example, reducing the runtime regarding the analysis of a series consisting of over one million data points from almost eight hours using state-of-the-art RQA software to roughly 69 seconds using PyRQA.\n    ",
        "primary_category": "cs.DC",
        "categories": [],
        "submitted_date": "18 Jan 2024",
        "last_revised_date": " "
    },
    "2402.16857": {
        "title": "A novel method to compute the contact surface area between an organ and cancer tissue",
        "authors": [
            "Alessandra Bulanti",
            "Alessandro Carf\u00ec",
            "Paolo Traverso",
            "Carlo Terrone",
            "Fulvio Mastrogiovanni"
        ],
        "comments": " ",
        "subjects": "Image and Video Processing (eess.IV)",
        "abstract": "With \"contact surface area\" (CSA) we refers to the area of contact between a tumor and an organ. This indicator has been identified as a predictive factor for surgical peri-operative parameters, particularly in the context of kidney cancer. However, state-of-the-art algorithms for computing the CSA rely on assumptions about the tumor shape and require manual human annotation. In this study, we introduce an innovative method that relies on 3D reconstructions of tumors and organs to provide an accurate and objective estimate of the CSA. Our approach consists of a segmentation protocol for reconstructing organs and tumors from Computed Tomography (CT) images and an algorithm leveraging the reconstructed meshes to compute the CSA. With the aim to contributing to the literature with replicable results, we provide an open-source implementation of our algorithm, along with an easy-to-use graphical user interface to support its adoption and widespread use. We evaluated the accuracy of our method using both a synthetic dataset and reconstructions of 87 real tumor-organ pairs.\n    ",
        "primary_category": "eess.IV",
        "categories": [
            "cs.CE",
            "cs.CV"
        ],
        "submitted_date": "19 Jan 2024",
        "last_revised_date": " "
    },
    "2402.16860": {
        "title": "Interactive Mars Image Content-Based Search with Interpretable Machine Learning",
        "authors": [
            "Bhavan Vasu",
            "Steven Lu",
            "Emily Dunkel",
            "Kiri L. Wagstaff",
            "Kevin Grimes",
            "Michael McAuley"
        ],
        "comments": "7 pages, 6 figures",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "The NASA Planetary Data System (PDS) hosts millions of images of planets, moons, and other bodies collected throughout many missions. The ever-expanding nature of data and user engagement demands an interpretable content classification system to support scientific discovery and individual curiosity. In this paper, we leverage a prototype-based architecture to enable users to understand and validate the evidence used by a classifier trained on images from the Mars Science Laboratory (MSL) Curiosity rover mission. In addition to providing explanations, we investigate the diversity and correctness of evidence used by the content-based classifier. The work presented in this paper will be deployed on the PDS Image Atlas, replacing its non-interpretable counterpart.\n    ",
        "primary_category": "cs.CV",
        "categories": [
            "cs.IR"
        ],
        "submitted_date": "19 Jan 2024",
        "last_revised_date": " "
    },
    "2402.16888": {
        "title": "Chaotic attractor reconstruction using small reservoirs -- the influence of topology",
        "authors": [
            "Lina Jaurigue"
        ],
        "comments": " ",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Forecasting timeseries based upon measured data is needed in a wide range of applications and has been the subject of extensive research. A particularly challenging task is the forecasting of timeseries generated by chaotic dynamics. In recent years reservoir computing has been shown to be an effective method of forecasting chaotic dynamics and reconstructing chaotic attractors from data. In this work strides are made toward smaller and lower complexity reservoirs with the goal of improved hardware implementability and more reliable production of adequate surrogate models. We show that a reservoir of uncoupled nodes more reliably produces long term timeseries predictions than complex reservoir topologies. We then link the improved attractor reconstruction of the uncoupled reservoir with smaller spectral radii of the resulting surrogate systems. These results indicate that, the node degree plays an important role in determining whether the desired dynamics will be stable in the autonomous surrogate system which is attained via closed-loop operation of the trained reservoir. In terms of hardware implementability, uncoupled nodes would allow for greater freedom in the hardware architecture because no complex coupling setups are needed and because, for uncoupled nodes, the system response is equivalent for space and time multiplexing.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.ET",
            "math-ph",
            "nlin.CD",
            "physics.comp-ph"
        ],
        "submitted_date": "23 Feb 2024",
        "last_revised_date": " "
    },
    "2402.16893": {
        "title": "The Good and The Bad: Exploring Privacy Issues in Retrieval-Augmented Generation (RAG)",
        "authors": [
            "Shenglai Zeng",
            "Jiankun Zhang",
            "Pengfei He",
            "Yue Xing",
            "Yiding Liu",
            "Han Xu",
            "Jie Ren",
            "Shuaiqiang Wang",
            "Dawei Yin",
            "Yi Chang",
            "Jiliang Tang"
        ],
        "comments": " ",
        "subjects": "Cryptography and Security (cs.CR)",
        "abstract": "Retrieval-augmented generation (RAG) is a powerful technique to facilitate language model with proprietary and private data, where data privacy is a pivotal concern. Whereas extensive research has demonstrated the privacy risks of large language models (LLMs), the RAG technique could potentially reshape the inherent behaviors of LLM generation, posing new privacy issues that are currently under-explored. In this work, we conduct extensive empirical studies with novel attack methods, which demonstrate the vulnerability of RAG systems on leaking the private retrieval database. Despite the new risk brought by RAG on the retrieval data, we further reveal that RAG can mitigate the leakage of the LLMs' training data. Overall, we provide new insights in this paper for privacy protection of retrieval-augmented LLMs, which benefit both LLMs and RAG systems builders. Our code is available at this https URL.\n    ",
        "primary_category": "cs.CR",
        "categories": [
            "cs.AI",
            "cs.CL"
        ],
        "submitted_date": "23 Feb 2024",
        "last_revised_date": " "
    },
    "2402.16904": {
        "title": "Selective Task offloading for Maximum Inference Accuracy and Energy efficient Real-Time IoT Sensing Systems",
        "authors": [
            "Abdelkarim Ben Sada",
            "Amar Khelloufi",
            "Abdenacer Naouri",
            "Huansheng Ning",
            "Sahraoui Dhelim"
        ],
        "comments": " ",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "The recent advancements in small-size inference models facilitated AI deployment on the edge. However, the limited resource nature of edge devices poses new challenges especially for real-time applications. Deploying multiple inference models (or a single tunable model) varying in size and therefore accuracy and power consumption, in addition to an edge server inference model, can offer a dynamic system in which the allocation of inference models to inference jobs is performed according to the current resource conditions. Therefore, in this work, we tackle the problem of selectively allocating inference models to jobs or offloading them to the edge server to maximize inference accuracy under time and energy constraints. This problem is shown to be an instance of the unbounded multidimensional knapsack problem which is considered a strongly NP-hard problem. We propose a lightweight hybrid genetic algorithm (LGSTO) to solve this problem. We introduce a termination condition and neighborhood exploration techniques for faster evolution of populations. We compare LGSTO with the Naive and Dynamic programming solutions. In addition to classic genetic algorithms using different reproduction methods including NSGA-II, and finally we compare to other evolutionary methods such as Particle swarm optimization (PSO) and Ant colony optimization (ACO). Experiment results show that LGSTO performed 3 times faster than the fastest comparable schemes while producing schedules with higher average accuracy.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.AI",
            "cs.NE"
        ],
        "submitted_date": "24 Feb 2024",
        "last_revised_date": " "
    },
    "2402.16912": {
        "title": "An Adversarial Robustness Benchmark for Enterprise Network Intrusion Detection",
        "authors": [
            "Jo\u00e3o Vitorino",
            "Miguel Silva",
            "Eva Maia",
            "Isabel Pra\u00e7a"
        ],
        "comments": "15 pages, 8 tables, 2 figures, FPS 2023 conference",
        "subjects": "Cryptography and Security (cs.CR)",
        "abstract": "As cyber-attacks become more sophisticated, improving the robustness of Machine Learning (ML) models must be a priority for enterprises of all sizes. To reliably compare the robustness of different ML models for cyber-attack detection in enterprise computer networks, they must be evaluated in standardized conditions. This work presents a methodical adversarial robustness benchmark of multiple decision tree ensembles with constrained adversarial examples generated from standard datasets. The robustness of regularly and adversarially trained RF, XGB, LGBM, and EBM models was evaluated on the original CICIDS2017 dataset, a corrected version of it designated as NewCICIDS, and the HIKARI dataset, which contains more recent network traffic. NewCICIDS led to models with a better performance, especially XGB and EBM, but RF and LGBM were less robust against the more recent cyber-attacks of HIKARI. Overall, the robustness of the models to adversarial cyber-attack examples was improved without their generalization to regular traffic being affected, enabling a reliable detection of suspicious activity without costly increases of false alarms.\n    ",
        "primary_category": "cs.CR",
        "categories": [
            "cs.LG",
            "cs.NI"
        ],
        "submitted_date": "25 Feb 2024",
        "last_revised_date": " "
    },
    "2402.16982": {
        "title": "Synthesizing Tight Privacy and Accuracy Bounds via Weighted Model Counting",
        "authors": [
            "Lisa Oakley",
            "Steven Holtzen",
            "Alina Oprea"
        ],
        "comments": " ",
        "subjects": "Cryptography and Security (cs.CR)",
        "abstract": "Programmatically generating tight differential privacy (DP) bounds is a hard problem. Two core challenges are (1) finding expressive, compact, and efficient encodings of the distributions of DP algorithms, and (2) state space explosion stemming from the multiple quantifiers and relational properties of the DP definition.\nWe address the first challenge by developing a method for tight privacy and accuracy bound synthesis using weighted model counting on binary decision diagrams, a state of the art technique from the artificial intelligence and automated reasoning communities for exactly computing probability distributions. We address the second challenge by developing a framework for leveraging inherent symmetries in DP algorithms. Our solution benefits from ongoing research in probabilistic programming languages, allowing us to succinctly and expressively represent different DP algorithms with approachable language syntax that can be used by non-experts.\nWe provide a detailed case study of our solution on the binary randomized response algorithm. We also evaluate an implementation of our solution using the Dice probabilistic programming language for the randomized response and truncated geometric above threshold algorithms. We compare to prior work on exact DP verification using Markov chain probabilistic model checking. Very few existing works consider mechanized analysis of accuracy guarantees for DP algorithms. We additionally provide a detailed analysis using our technique for finding tight accuracy bounds for DP algorithms.\n    ",
        "primary_category": "cs.CR",
        "categories": [
            "cs.PL"
        ],
        "submitted_date": "26 Feb 2024",
        "last_revised_date": " "
    },
    "2402.16990": {
        "title": "inGRASS: Incremental Graph Spectral Sparsification via Low-Resistance-Diameter Decomposition",
        "authors": [
            "Ali Aghdaei",
            "Zhuo Feng"
        ],
        "comments": "Accepted on DAC 2024",
        "subjects": "Data Structures and Algorithms (cs.DS)",
        "abstract": "This work presents inGRASS, a novel algorithm designed for incremental spectral sparsification of large undirected graphs. The proposed inGRASS algorithm is highly scalable and parallel-friendly, having a nearly-linear time complexity for the setup phase and the ability to update the spectral sparsifier in $O(\\log N)$ time for each incremental change made to the original graph with $N$ nodes. A key component in the setup phase of inGRASS is a multilevel resistance embedding framework introduced for efficiently identifying spectrally-critical edges and effectively detecting redundant ones, which is achieved by decomposing the initial sparsifier into many node clusters with bounded effective-resistance diameters leveraging a low-resistance-diameter decomposition (LRD) scheme. The update phase of inGRASS exploits low-dimensional node embedding vectors for efficiently estimating the importance and uniqueness of each newly added edge. As demonstrated through extensive experiments, inGRASS achieves up to over $200 \\times$ speedups while retaining comparable solution quality in incremental spectral sparsification of graphs obtained from various datasets, such as circuit simulations, finite element analysis, and social networks.\n    ",
        "primary_category": "cs.DS",
        "categories": [
            "cs.LG",
            "cs.SI"
        ],
        "submitted_date": "26 Feb 2024",
        "last_revised_date": " "
    },
    "2402.17110": {
        "title": "Sinkhorn Distance Minimization for Knowledge Distillation",
        "authors": [
            "Xiao Cui",
            "Yulei Qin",
            "Yuting Gao",
            "Enwei Zhang",
            "Zihan Xu",
            "Tong Wu",
            "Ke Li",
            "Xing Sun",
            "Wengang Zhou",
            "Houqiang Li"
        ],
        "comments": "Accepted by COLING 2024",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Knowledge distillation (KD) has been widely adopted to compress large language models (LLMs). Existing KD methods investigate various divergence measures including the Kullback-Leibler (KL), reverse Kullback-Leibler (RKL), and Jensen-Shannon (JS) divergences. However, due to limitations inherent in their assumptions and definitions, these measures fail to deliver effective supervision when few distribution overlap exists between the teacher and the student. In this paper, we show that the aforementioned KL, RKL, and JS divergences respectively suffer from issues of mode-averaging, mode-collapsing, and mode-underestimation, which deteriorates logits-based KD for diverse NLP tasks. We propose the Sinkhorn Knowledge Distillation (SinKD) that exploits the Sinkhorn distance to ensure a nuanced and precise assessment of the disparity between teacher and student distributions. Besides, profit by properties of the Sinkhorn metric, we can get rid of sample-wise KD that restricts the perception of divergence in each teacher-student sample pair. Instead, we propose a batch-wise reformulation to capture geometric intricacies of distributions across samples in the high-dimensional space. Comprehensive evaluation on GLUE and SuperGLUE, in terms of comparability, validity, and generalizability, highlights our superiority over state-of-the-art methods on all kinds of LLMs with encoder-only, encoder-decoder, and decoder-only architectures.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.CL"
        ],
        "submitted_date": "27 Feb 2024",
        "last_revised_date": " "
    },
    "2402.17229": {
        "title": "Preserving Fairness Generalization in Deepfake Detection",
        "authors": [
            "Li Lin",
            "Xinan He",
            "Yan Ju",
            "Xin Wang",
            "Feng Ding",
            "Shu Hu"
        ],
        "comments": "Accepted by The IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR 2024)",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Although effective deepfake detection models have been developed in recent years, recent studies have revealed that these models can result in unfair performance disparities among demographic groups, such as race and gender. This can lead to particular groups facing unfair targeting or exclusion from detection, potentially allowing misclassified deepfakes to manipulate public opinion and undermine trust in the model. The existing method for addressing this problem is providing a fair loss function. It shows good fairness performance for intra-domain evaluation but does not maintain fairness for cross-domain testing. This highlights the significance of fairness generalization in the fight against deepfakes. In this work, we propose the first method to address the fairness generalization problem in deepfake detection by simultaneously considering features, loss, and optimization aspects. Our method employs disentanglement learning to extract demographic and domain-agnostic forgery features, fusing them to encourage fair learning across a flattened loss landscape. Extensive experiments on prominent deepfake datasets demonstrate our method's effectiveness, surpassing state-of-the-art approaches in preserving fairness during cross-domain deepfake detection. The code is available at this https URL\n",
        "primary_category": "cs.CV",
        "categories": [
            "cs.CY",
            "cs.LG"
        ],
        "submitted_date": "27 Feb 2024",
        "last_revised_date": " "
    },
    "2402.17236": {
        "title": "A Review of Data Mining in Personalized Education: Current Trends and Future Prospects",
        "authors": [
            "Zhang Xiong",
            "Haoxuan Li",
            "Zhuang Liu",
            "Zhuofan Chen",
            "Hao Zhou",
            "Wenge Rong",
            "Yuanxin Ouyang"
        ],
        "comments": "25 pages, 5 figures",
        "subjects": "Computers and Society (cs.CY)",
        "abstract": "Personalized education, tailored to individual student needs, leverages educational technology and artificial intelligence (AI) in the digital age to enhance learning effectiveness. The integration of AI in educational platforms provides insights into academic performance, learning preferences, and behaviors, optimizing the personal learning process. Driven by data mining techniques, it not only benefits students but also provides educators and institutions with tools to craft customized learning experiences. To offer a comprehensive review of recent advancements in personalized educational data mining, this paper focuses on four primary scenarios: educational recommendation, cognitive diagnosis, knowledge tracing, and learning analysis. This paper presents a structured taxonomy for each area, compiles commonly used datasets, and identifies future research directions, emphasizing the role of data mining in enhancing personalized education and paving the way for future exploration and innovation.\n    ",
        "primary_category": "cs.CY",
        "categories": [
            "cs.LG"
        ],
        "submitted_date": "27 Feb 2024",
        "last_revised_date": " "
    },
    "2402.17242": {
        "title": "Scalable Community Search with Accuracy Guarantee on Attributed Graphs",
        "authors": [
            "Yuxiang Wang",
            "Shuzhan Ye",
            "Xiaoliang Xu",
            "Yuxia Geng",
            "Zhenghe Zhao",
            "Xiangyu Ke",
            "Tianxing Wu"
        ],
        "comments": " ",
        "subjects": "Social and Information Networks (cs.SI)",
        "abstract": "Given an attributed graph $G$ and a query node $q$, \\underline{C}ommunity \\underline{S}earch over \\underline{A}ttributed \\underline{G}raphs (CS-AG) aims to find a structure- and attribute-cohesive subgraph from $G$ that contains $q$. Although CS-AG has been widely studied, they still face three challenges. (1) Exact methods based on graph traversal are time-consuming, especially for large graphs. Some tailored indices can improve efficiency, but introduce nonnegligible storage and maintenance overhead. (2) Approximate methods with a loose approximation ratio only provide a coarse-grained evaluation of a community's quality, rather than a reliable evaluation with an accuracy guarantee in runtime. (3) Attribute cohesiveness metrics often ignores the important correlation with the query node $q$. We formally define our CS-AG problem atop a $q$-centric attribute cohesiveness metric considering both textual and numerical attributes, for $k$-core model on homogeneous graphs. We show the problem is NP-hard. To solve it, we first propose an exact baseline with three pruning strategies. Then, we propose an index-free sampling-estimation-based method to quickly return an approximate community with an accuracy guarantee, in the form of a confidence interval. Once a good result satisfying a user-desired error bound is reached, we terminate it early. We extend it to heterogeneous graphs, $k$-truss model, and size-bounded CS. Comprehensive experimental studies on ten real-world datasets show its superiority, e.g., at least 1.54$\\times$ (41.1$\\times$ on average) faster in response time and a reliable relative error (within a user-specific error bound) of attribute cohesiveness is achieved.\n    ",
        "primary_category": "cs.SI",
        "categories": [
            "cs.DB"
        ],
        "submitted_date": "27 Feb 2024",
        "last_revised_date": " "
    },
    "2402.17279": {
        "title": "DiFashion: Towards Personalized Outfit Generation and Recommendation",
        "authors": [
            "Yiyan Xu",
            "Wenjie Wang",
            "Fuli Feng",
            "Yunshan Ma",
            "Jizhi Zhang",
            "Xiangnan He"
        ],
        "comments": " ",
        "subjects": "Information Retrieval (cs.IR)",
        "abstract": "The evolution of Outfit Recommendation (OR) in the realm of fashion has progressed through two distinct phases: Pre-defined Outfit Recommendation and Personalized Outfit Composition. Despite these advancements, both phases face limitations imposed by existing fashion products, hindering their effectiveness in meeting users' diverse fashion needs. The emergence of AI-generated content has paved the way for OR to overcome these constraints, demonstrating the potential for personalized outfit generation.\nIn pursuit of this, we introduce an innovative task named Generative Outfit Recommendation (GOR), with the goal of synthesizing a set of fashion images and assembling them to form visually harmonious outfits customized to individual users. The primary objectives of GOR revolve around achieving high fidelity, compatibility, and personalization of the generated outfits. To accomplish these, we propose DiFashion, a generative outfit recommender model that harnesses exceptional diffusion models for the simultaneous generation of multiple fashion images. To ensure the fulfillment of these objectives, three types of conditions are designed to guide the parallel generation process and Classifier-Free-Guidance are employed to enhance the alignment between generated images and conditions. DiFashion is applied to both personalized Fill-In-The-Blank and GOR tasks, and extensive experiments are conducted on the iFashion and Polyvore-U datasets. The results of quantitative and human-involved qualitative evaluations highlight the superiority of DiFashion over competitive baselines.\n    ",
        "primary_category": "cs.IR",
        "categories": [],
        "submitted_date": "27 Feb 2024",
        "last_revised_date": " "
    },
    "2402.17289": {
        "title": "Active propulsion noise shaping for multi-rotor aircraft localization",
        "authors": [
            "Gabriele Serussi",
            "Tamir Shor",
            "Tom Hirshberg",
            "Chaim Baskin",
            "Alex Bronstein"
        ],
        "comments": " ",
        "subjects": "Robotics (cs.RO)",
        "abstract": "Multi-rotor aerial autonomous vehicles (MAVs) primarily rely on vision for navigation purposes. However, visual localization and odometry techniques suffer from poor performance in low or direct sunlight, a limited field of view, and vulnerability to occlusions. Acoustic sensing can serve as a complementary or even alternative modality for vision in many situations, and it also has the added benefits of lower system cost and energy footprint, which is especially important for micro aircraft. This paper proposes actively controlling and shaping the aircraft propulsion noise generated by the rotors to benefit localization tasks, rather than considering it a harmful nuisance. We present a neural network architecture for selfnoise-based localization in a known environment. We show that training it simultaneously with learning time-varying rotor phase modulation achieves accurate and robust localization. The proposed methods are evaluated using a computationally affordable simulation of MAV rotor noise in 2D acoustic environments that is fitted to real recordings of rotor pressure fields.\n    ",
        "primary_category": "cs.RO",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "27 Feb 2024",
        "last_revised_date": " "
    },
    "2402.17311": {
        "title": "SKT5SciSumm -- A Hybrid Generative Approach for Multi-Document Scientific Summarization",
        "authors": [
            "Huy Quoc To",
            "Hung-Nghiep Tran",
            "Andr'e Greiner-Petter",
            "Felix Beierle",
            "Akiko Aizawa"
        ],
        "comments": " ",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "Summarization for scientific text has shown significant benefits both for the research community and human society. Given the fact that the nature of scientific text is distinctive and the input of the multi-document summarization task is substantially long, the task requires sufficient embedding generation and text truncation without losing important information. To tackle these issues, in this paper, we propose SKT5SciSumm - a hybrid framework for multi-document scientific summarization (MDSS). We leverage the Sentence-Transformer version of Scientific Paper Embeddings using Citation-Informed Transformers (SPECTER) to encode and represent textual sentences, allowing for efficient extractive summarization using k-means clustering. We employ the T5 family of models to generate abstractive summaries using extracted sentences. SKT5SciSumm achieves state-of-the-art performance on the Multi-XScience dataset. Through extensive experiments and evaluation, we showcase the benefits of our model by using less complicated models to achieve remarkable results, thereby highlighting its potential in advancing the field of multi-document summarization for scientific text.\n    ",
        "primary_category": "cs.CL",
        "categories": [],
        "submitted_date": "27 Feb 2024",
        "last_revised_date": " "
    },
    "2402.17316": {
        "title": "Towards Robust and Efficient Cloud-Edge Elastic Model Adaptation via Selective Entropy Distillation",
        "authors": [
            "Yaofo Chen",
            "Shuaicheng Niu",
            "Shoukai Xu",
            "Hengjie Song",
            "Yaowei Wang",
            "Mingkui Tan"
        ],
        "comments": "Published in ICLR 2024",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "The conventional deep learning paradigm often involves training a deep model on a server and then deploying the model or its distilled ones to resource-limited edge devices. Usually, the models shall remain fixed once deployed (at least for some period) due to the potential high cost of model adaptation for both the server and edge sides. However, in many real-world scenarios, the test environments may change dynamically (known as distribution shifts), which often results in degraded performance. Thus, one has to adapt the edge models promptly to attain promising performance. Moreover, with the increasing data collected at the edge, this paradigm also fails to further adapt the cloud model for better performance. To address these, we encounter two primary challenges: 1) the edge model has limited computation power and may only support forward propagation; 2) the data transmission budget between cloud and edge devices is limited in latency-sensitive scenarios. In this paper, we establish a Cloud-Edge Elastic Model Adaptation (CEMA) paradigm in which the edge models only need to perform forward propagation and the edge models can be adapted online. In our CEMA, to reduce the communication burden, we devise two criteria to exclude unnecessary samples from uploading to the cloud, i.e., dynamic unreliable and low-informative sample exclusion. Based on the uploaded samples, we update and distribute the affine parameters of normalization layers by distilling from the stronger foundation model to the edge model with a sample replay strategy. Extensive experimental results on ImageNet-C and ImageNet-R verify the effectiveness of our CEMA.\n    ",
        "primary_category": "cs.CV",
        "categories": [],
        "submitted_date": "27 Feb 2024",
        "last_revised_date": " "
    },
    "2402.17389": {
        "title": "FairBelief -- Assessing Harmful Beliefs in Language Models",
        "authors": [
            "Mattia Setzu",
            "Marta Marchiori Manerba",
            "Pasquale Minervini",
            "Debora Nozza"
        ],
        "comments": " ",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "Language Models (LMs) have been shown to inherit undesired biases that might hurt minorities and underrepresented groups if such systems were integrated into real-world applications without careful fairness auditing. This paper proposes FairBelief, an analytical approach to capture and assess beliefs, i.e., propositions that an LM may embed with different degrees of confidence and that covertly influence its predictions. With FairBelief, we leverage prompting to study the behavior of several state-of-the-art LMs across different previously neglected axes, such as model scale and likelihood, assessing predictions on a fairness dataset specifically designed to quantify LMs' outputs' hurtfulness. Finally, we conclude with an in-depth qualitative assessment of the beliefs emitted by the models. We apply FairBelief to English LMs, revealing that, although these architectures enable high performances on diverse natural language processing tasks, they show hurtful beliefs about specific genders. Interestingly, training procedure and dataset, model scale, and architecture induce beliefs of different degrees of hurtfulness.\n    ",
        "primary_category": "cs.CL",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "27 Feb 2024",
        "last_revised_date": " "
    },
    "2402.17392": {
        "title": "Spot the bot: Coarse-Grained Partition of Semantic Paths for Bots and Humans",
        "authors": [
            "Vasilii A. Gromov",
            "Alexandra S. Kogan"
        ],
        "comments": " ",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "Nowadays, technology is rapidly advancing: bots are writing comments, articles, and reviews. Due to this fact, it is crucial to know if the text was written by a human or by a bot. This paper focuses on comparing structures of the coarse-grained partitions of semantic paths for human-written and bot-generated texts. We compare the clusterizations of datasets of n-grams from literary texts and texts generated by several bots. The hypothesis is that the structures and clusterizations are different. Our research supports the hypothesis. As the semantic structure may be different for different languages, we investigate Russian, English, German, and Vietnamese languages.\n    ",
        "primary_category": "cs.CL",
        "categories": [],
        "submitted_date": "27 Feb 2024",
        "last_revised_date": " "
    },
    "2402.17398": {
        "title": "A Quantum Approach to Synthetic Minority Oversampling Technique (SMOTE)",
        "authors": [
            "Nishikanta Mohanty",
            "Bikash K. Behera",
            "Christopher Ferrie",
            "Pravat Dash"
        ],
        "comments": "18 Pages, 22 Figures, 2 Tables",
        "subjects": "Quantum Physics (quant-ph)",
        "abstract": "The paper proposes the Quantum-SMOTE method, a novel solution that uses quantum computing techniques to solve the prevalent problem of class imbalance in machine learning datasets. Quantum-SMOTE, inspired by the Synthetic Minority Oversampling Technique (SMOTE), generates synthetic data points using quantum processes such as swap tests and quantum rotation. The process varies from the conventional SMOTE algorithm's usage of K-Nearest Neighbors (KNN) and Euclidean distances, enabling synthetic instances to be generated from minority class data points without relying on neighbor proximity. The algorithm asserts greater control over the synthetic data generation process by introducing hyperparameters such as rotation angle, minority percentage, and splitting factor, which allow for customization to specific dataset requirements. The approach is tested on a public dataset of TelecomChurn and evaluated alongside two prominent classification algorithms, Random Forest and Logistic Regression, to determine its impact along with varying proportions of synthetic data.\n    ",
        "primary_category": "quant-ph",
        "categories": [
            "cs.AI",
            "cs.LG"
        ],
        "submitted_date": "27 Feb 2024",
        "last_revised_date": " "
    },
    "2402.17414": {
        "title": "Neural Video Compression with Feature Modulation",
        "authors": [
            "Jiahao Li",
            "Bin Li",
            "Yan Lu"
        ],
        "comments": "CVPR 2024. Codes are at this https URL",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "The emerging conditional coding-based neural video codec (NVC) shows superiority over commonly-used residual coding-based codec and the latest NVC already claims to outperform the best traditional codec. However, there still exist critical problems blocking the practicality of NVC. In this paper, we propose a powerful conditional coding-based NVC that solves two critical problems via feature modulation. The first is how to support a wide quality range in a single model. Previous NVC with this capability only supports about 3.8 dB PSNR range on average. To tackle this limitation, we modulate the latent feature of the current frame via the learnable quantization scaler. During the training, we specially design the uniform quantization parameter sampling mechanism to improve the harmonization of encoding and quantization. This results in a better learning of the quantization scaler and helps our NVC support about 11.4 dB PSNR range. The second is how to make NVC still work under a long prediction chain. We expose that the previous SOTA NVC has an obvious quality degradation problem when using a large intra-period setting. To this end, we propose modulating the temporal feature with a periodically refreshing mechanism to boost the quality. %Besides solving the above two problems, we also design a single model that can support both RGB and YUV colorspaces. Notably, under single intra-frame setting, our codec can achieve 29.7\\% bitrate saving over previous SOTA NVC with 16\\% MACs reduction. Our codec serves as a notable landmark in the journey of NVC evolution. The codes are at this https URL.\n    ",
        "primary_category": "cs.CV",
        "categories": [
            "eess.IV"
        ],
        "submitted_date": "27 Feb 2024",
        "last_revised_date": " "
    },
    "2402.17485": {
        "title": "EMO: Emote Portrait Alive -- Generating Expressive Portrait Videos with Audio2Video Diffusion Model under Weak Conditions",
        "authors": [
            "Linrui Tian",
            "Qi Wang",
            "Bang Zhang",
            "Liefeng Bo"
        ],
        "comments": " ",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "In this work, we tackle the challenge of enhancing the realism and expressiveness in talking head video generation by focusing on the dynamic and nuanced relationship between audio cues and facial movements. We identify the limitations of traditional techniques that often fail to capture the full spectrum of human expressions and the uniqueness of individual facial styles. To address these issues, we propose EMO, a novel framework that utilizes a direct audio-to-video synthesis approach, bypassing the need for intermediate 3D models or facial landmarks. Our method ensures seamless frame transitions and consistent identity preservation throughout the video, resulting in highly expressive and lifelike animations. Experimental results demonsrate that EMO is able to produce not only convincing speaking videos but also singing videos in various styles, significantly outperforming existing state-of-the-art methodologies in terms of expressiveness and realism.\n    ",
        "primary_category": "cs.CV",
        "categories": [],
        "submitted_date": "27 Feb 2024",
        "last_revised_date": " "
    },
    "2402.17688": {
        "title": "Novel spectral methods for shock capturing and the removal of tygers in computational fluid dynamics",
        "authors": [
            "Sai Swetha Venkata Kolluru",
            "Nicolas Besse",
            "Rahul Pandit"
        ],
        "comments": " ",
        "subjects": "Numerical Analysis (math.NA)",
        "abstract": "Spectral methods yield numerical solutions of the Galerkin-truncated versions of nonlinear partial differential equations involved especially in fluid dynamics. In the presence of discontinuities, such as shocks, spectral approximations develop Gibbs oscillations near the discontinuity. This causes the numerical solution to deviate quickly from the true solution. For spectral approximations of the 1D inviscid Burgers equation, nonlinear wave resonances lead to the formation of tygers in well-resolved areas of the flow, far from the shock. Recently, Besse(to be published) has proposed novel spectral relaxation (SR) and spectral purging (SP) schemes for the removal of tygers and Gibbs oscillations in spectral approximations of nonlinear conservation laws. For the 1D inviscid Burgers equation, it is shown that the novel SR and SP approximations of the solution converge strongly in L2 norm to the entropic weak solution, under an appropriate choice of kernels and related parameters. In this work, we carry out a detailed numerical investigation of SR and SP schemes when applied to the 1D inviscid Burgers equation and report the efficiency of shock capture and the removal of tygers. We then extend our study to systems of nonlinear hyperbolic conservation laws - such as the 2x2 system of the shallow water equations and the standard 3x3 system of 1D compressible Euler equations. For the latter, we generalise the implementation of SR methods to non-periodic problems using Chebyshev polynomials. We then turn to singular flow in the 1D wall approximation of the 3D-axisymmetric wall-bounded incompressible Euler equation. Here, in order to determine the blowup time of the solution, we compare the decay of the width of the analyticity strip, obtained from the pure pseudospectral method, with the improved estimate obtained using the novel spectral relaxation scheme.\n    ",
        "primary_category": "math.NA",
        "categories": [
            "physics.comp-ph"
        ],
        "submitted_date": "27 Feb 2024",
        "last_revised_date": " "
    },
    "2402.17758": {
        "title": "ADL4D: Towards A Contextually Rich Dataset for 4D Activities of Daily Living",
        "authors": [
            "Marsil Zakour",
            "Partha Pratim Nath",
            "Ludwig Lohmer",
            "Emre Faik G\u00f6k\u00e7e",
            "Martin Piccolrovazzi",
            "Constantin Patsch",
            "Yuankai Wu",
            "Rahul Chaudhari",
            "Eckehard Steinbach"
        ],
        "comments": " ",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Hand-Object Interactions (HOIs) are conditioned on spatial and temporal contexts like surrounding objects, previous actions, and future intents (for example, grasping and handover actions vary greatly based on objects proximity and trajectory obstruction). However, existing datasets for 4D HOI (3D HOI over time) are limited to one subject interacting with one object only. This restricts the generalization of learning-based HOI methods trained on those datasets. We introduce ADL4D, a dataset of up to two subjects interacting with different sets of objects performing Activities of Daily Living (ADL) like breakfast or lunch preparation activities. The transition between multiple objects to complete a certain task over time introduces a unique context lacking in existing datasets. Our dataset consists of 75 sequences with a total of 1.1M RGB-D frames, hand and object poses, and per-hand fine-grained action annotations. We develop an automatic system for multi-view multi-hand 3D pose annotation capable of tracking hand poses over time. We integrate and test it against publicly available datasets. Finally, we evaluate our dataset on the tasks of Hand Mesh Recovery (HMR) and Hand Action Segmentation (HAS).\n    ",
        "primary_category": "cs.CV",
        "categories": [],
        "submitted_date": "27 Feb 2024",
        "last_revised_date": " "
    },
    "2402.17810": {
        "title": "BioT5+: Towards Generalized Biological Understanding with IUPAC Integration and Multi-task Tuning",
        "authors": [
            "Qizhi Pei",
            "Lijun Wu",
            "Kaiyuan Gao",
            "Xiaozhuan Liang",
            "Yin Fang",
            "Jinhua Zhu",
            "Shufang Xie",
            "Tao Qin",
            "Rui Yan"
        ],
        "comments": "24 pages",
        "subjects": "Quantitative Methods (q-bio.QM)",
        "abstract": "Recent research trends in computational biology have increasingly focused on integrating text and bio-entity modeling, especially in the context of molecules and proteins. However, previous efforts like BioT5 faced challenges in generalizing across diverse tasks and lacked a nuanced understanding of molecular structures, particularly in their textual representations (e.g., IUPAC). This paper introduces BioT5+, an extension of the BioT5 framework, tailored to enhance biological research and drug discovery. BioT5+ incorporates several novel features: integration of IUPAC names for molecular understanding, inclusion of extensive bio-text and molecule data from sources like bioRxiv and PubChem, the multi-task instruction tuning for generality across tasks, and a novel numerical tokenization technique for improved processing of numerical data. These enhancements allow BioT5+ to bridge the gap between molecular representations and their textual descriptions, providing a more holistic understanding of biological entities, and largely improving the grounded reasoning of bio-text and bio-sequences. The model is pre-trained and fine-tuned with a large number of experiments, including \\emph{3 types of problems (classification, regression, generation), 15 kinds of tasks, and 21 total benchmark datasets}, demonstrating the remarkable performance and state-of-the-art results in most cases. BioT5+ stands out for its ability to capture intricate relationships in biological data, thereby contributing significantly to bioinformatics and computational biology. Our code is available at \\url{this https URL}.\n    ",
        "primary_category": "q-bio.QM",
        "categories": [
            "cs.AI",
            "cs.CE",
            "cs.LG",
            "q-bio.BM"
        ],
        "submitted_date": "27 Feb 2024",
        "last_revised_date": " "
    },
    "2402.17886": {
        "title": "Zeroth-Order Sampling Methods for Non-Log-Concave Distributions: Alleviating Metastability by Denoising Diffusion",
        "authors": [
            "Ye He",
            "Kevin Rojas",
            "Molei Tao"
        ],
        "comments": "Figure 4 on page 13 corrected. Comments are welcome",
        "subjects": "Machine Learning (stat.ML)",
        "abstract": "This paper considers the problem of sampling from non-logconcave distribution, based on queries of its unnormalized density. It first describes a framework, Diffusion Monte Carlo (DMC), based on the simulation of a denoising diffusion process with its score function approximated by a generic Monte Carlo estimator. DMC is an oracle-based meta-algorithm, where its oracle is the assumed access to samples that generate a Monte Carlo score estimator. Then we provide an implementation of this oracle, based on rejection sampling, and this turns DMC into a true algorithm, termed Zeroth-Order Diffusion Monte Carlo (ZOD-MC). We provide convergence analyses by first constructing a general framework, i.e. a performance guarantee for DMC, without assuming the target distribution to be log-concave or satisfying any isoperimetric inequality. Then we prove that ZOD-MC admits an inverse polynomial dependence on the desired sampling accuracy, albeit still suffering from the curse of dimensionality. Consequently, for low dimensional distributions, ZOD-MC is a very efficient sampler, with performance exceeding latest samplers, including also-denoising-diffusion-based RDMC and RS-DMC. Last, we experimentally demonstrate the insensitivity of ZOD-MC to increasingly higher barriers between modes or discontinuity in non-convex potential.\n    ",
        "primary_category": "stat.ML",
        "categories": [
            "cs.LG",
            "math.PR",
            "math.ST",
            "stat.ME"
        ],
        "submitted_date": "27 Feb 2024",
        "last_revised_date": " "
    },
    "2402.17932": {
        "title": "A Heterogeneous Agent Model of Mortgage Servicing: An Income-based Relief Analysis",
        "authors": [
            "Deepeka Garg",
            "Benjamin Patrick Evans",
            "Leo Ardon",
            "Annapoorani Lakshmi Narayanan",
            "Jared Vann",
            "Udari Madhushani",
            "Makada Henry-Nickie",
            "Sumitra Ganesh"
        ],
        "comments": "AAAI 2024 - AI in Finance for Social Impact",
        "subjects": "Multiagent Systems (cs.MA)",
        "abstract": "Mortgages account for the largest portion of household debt in the United States, totaling around \\$12 trillion nationwide. In times of financial hardship, alleviating mortgage burdens is essential for supporting affected households. The mortgage servicing industry plays a vital role in offering this assistance, yet there has been limited research modelling the complex relationship between households and servicers. To bridge this gap, we developed an agent-based model that explores household behavior and the effectiveness of relief measures during financial distress. Our model represents households as adaptive learning agents with realistic financial attributes. These households experience exogenous income shocks, which may influence their ability to make mortgage payments. Mortgage servicers provide relief options to these households, who then choose the most suitable relief based on their unique financial circumstances and individual preferences. We analyze the impact of various external shocks and the success of different mortgage relief strategies on specific borrower subgroups. Through this analysis, we show that our model can not only replicate real-world mortgage studies but also act as a tool for conducting a broad range of what-if scenario analyses. Our approach offers fine-grained insights that can inform the development of more effective and inclusive mortgage relief solutions.\n    ",
        "primary_category": "cs.MA",
        "categories": [
            "q-fin.GN"
        ],
        "submitted_date": "27 Feb 2024",
        "last_revised_date": " "
    },
    "2402.17970": {
        "title": "Exploring Advanced Methodologies in Security Evaluation for LLMs",
        "authors": [
            "Jun Huang",
            "Jiawei Zhang",
            "Qi Wang",
            "Weihong Han",
            "Yanchun Zhang"
        ],
        "comments": " ",
        "subjects": "Cryptography and Security (cs.CR)",
        "abstract": "Large Language Models (LLMs) represent an advanced evolution of earlier, simpler language models. They boast enhanced abilities to handle complex language patterns and generate coherent text, images, audios, and videos. Furthermore, they can be fine-tuned for specific tasks. This versatility has led to the proliferation and extensive use of numerous commercialized large models. However, the rapid expansion of LLMs has raised security and ethical concerns within the academic community. This emphasizes the need for ongoing research into security evaluation during their development and deployment. Over the past few years, a substantial body of research has been dedicated to the security evaluation of large-scale models. This article an in-depth review of the most recent advancements in this field, providing a comprehensive analysis of commonly used evaluation metrics, advanced evaluation frameworks, and the routine evaluation processes for LLMs. Furthermore, we also discuss the future directions for advancing the security evaluation of LLMs.\n    ",
        "primary_category": "cs.CR",
        "categories": [],
        "submitted_date": "28 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18065": {
        "title": "A Probabilistic Motion Model for Skid-Steer Wheeled Mobile Robot Navigation on Off-Road Terrains",
        "authors": [
            "Ananya Trivedi",
            "Mark Zolotas",
            "Adeeb Abbas",
            "Sarvesh Prajapati",
            "Salah Bazzi",
            "Task\u0131n Pad\u0131r"
        ],
        "comments": "Accepted for publication at IEEE ICRA 2024",
        "subjects": "Robotics (cs.RO)",
        "abstract": "Skid-Steer Wheeled Mobile Robots (SSWMRs) are increasingly being used for off-road autonomy applications. When turning at high speeds, these robots tend to undergo significant skidding and slipping. In this work, using Gaussian Process Regression (GPR) and Sigma-Point Transforms, we estimate the non-linear effects of tire-terrain interaction on robot velocities in a probabilistic fashion. Using the mean estimates from GPR, we propose a data-driven dynamic motion model that is more accurate at predicting future robot poses than conventional kinematic motion models. By efficiently solving a convex optimization problem based on the history of past robot motion, the GPR augmented motion model generalizes to previously unseen terrain conditions. The output distribution from the proposed motion model can be used for local motion planning approaches, such as stochastic model predictive control, leveraging model uncertainty to make safe decisions. We validate our work on a benchmark real-world multi-terrain SSWMR dataset. Our results show that the model generalizes to three different terrains while significantly reducing errors in linear and angular motion predictions. As shown in the attached video, we perform a separate set of experiments on a physical robot to demonstrate the robustness of the proposed algorithm.\n    ",
        "primary_category": "cs.RO",
        "categories": [],
        "submitted_date": "28 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18101": {
        "title": "Assessing the Efficacy of Grammar Error Correction: A Human Evaluation Approach in the Japanese Context",
        "authors": [
            "Qiao Wang",
            "Zheng Yuan"
        ],
        "comments": "2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation (LREC-COLING 2024)",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "In this study, we evaluated the performance of the state-of-the-art sequence tagging grammar error detection and correction model (SeqTagger) using Japanese university students' writing samples. With an automatic annotation toolkit, ERRANT, we first evaluated SeqTagger's performance on error correction with human expert correction as the benchmark. Then a human-annotated approach was adopted to evaluate Seqtagger's performance in error detection using a subset of the writing dataset. Results indicated a precision of 63.66% and a recall of 20.19% for error correction in the full dataset. For the subset, after manual exclusion of irrelevant errors such as semantic and mechanical ones, the model shows an adjusted precision of 97.98% and an adjusted recall of 42.98% for error detection, indicating the model's high accuracy but also its conservativeness. Thematic analysis on errors undetected by the model revealed that determiners and articles, especially the latter, were predominant. Specifically, in terms of context-independent errors, the model occasionally overlooked basic ones and faced challenges with overly erroneous or complex structures. Meanwhile, context-dependent errors, notably those related to tense and noun number, as well as those possibly influenced by the students' first language (L1), remained particularly challenging.\n    ",
        "primary_category": "cs.CL",
        "categories": [],
        "submitted_date": "28 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18169": {
        "title": "MIKO: Multimodal Intention Knowledge Distillation from Large Language Models for Social-Media Commonsense Discovery",
        "authors": [
            "Feihong Lu",
            "Weiqi Wang",
            "Yangyifei Luo",
            "Ziqin Zhu",
            "Qingyun Sun",
            "Baixuan Xu",
            "Haochen Shi",
            "Shiqi Gao",
            "Qian Li",
            "Yangqiu Song",
            "Jianxin Li"
        ],
        "comments": "11 pages, 5 figures",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "Social media has become a ubiquitous tool for connecting with others, staying updated with news, expressing opinions, and finding entertainment. However, understanding the intention behind social media posts remains challenging due to the implicitness of intentions in social media posts, the need for cross-modality understanding of both text and images, and the presence of noisy information such as hashtags, misspelled words, and complicated abbreviations. To address these challenges, we present MIKO, a Multimodal Intention Kowledge DistillatiOn framework that collaboratively leverages a Large Language Model (LLM) and a Multimodal Large Language Model (MLLM) to uncover users' intentions. Specifically, we use an MLLM to interpret the image and an LLM to extract key information from the text and finally instruct the LLM again to generate intentions. By applying MIKO to publicly available social media datasets, we construct an intention knowledge base featuring 1,372K intentions rooted in 137,287 posts. We conduct a two-stage annotation to verify the quality of the generated knowledge and benchmark the performance of widely used LLMs for intention generation. We further apply MIKO to a sarcasm detection dataset and distill a student model to demonstrate the downstream benefits of applying intention knowledge.\n    ",
        "primary_category": "cs.CL",
        "categories": [],
        "submitted_date": "28 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18222": {
        "title": "HearHere: Mitigating Echo Chambers in News Consumption through an AI-based Web System",
        "authors": [
            "Youngseung Jeon",
            "Jaehoon Kim",
            "Sohyun Park",
            "Yunyong Ko",
            "Seongeun Ryu",
            "Sang-Wook Kim",
            "Kyungsik Han"
        ],
        "comments": "34 pages, 6 figures, 6 tables, CSCW 2024",
        "subjects": "Human-Computer Interaction (cs.HC)",
        "abstract": "Considerable efforts are currently underway to mitigate the negative impacts of echo chambers, such as increased susceptibility to fake news and resistance towards accepting scientific evidence. Prior research has presented the development of computer systems that support the consumption of news information from diverse political perspectives to mitigate the echo chamber effect. However, existing studies still lack the ability to effectively support the key processes of news information consumption and quantitatively identify a political stance towards the information. In this paper, we present HearHere, an AI-based web system designed to help users accommodate information and opinions from diverse perspectives. HearHere facilitates the key processes of news information consumption through two visualizations. Visualization 1 provides political news with quantitative political stance information, derived from our graph-based political classification model, and users can experience diverse perspectives (Hear). Visualization 2 allows users to express their opinions on specific political issues in a comment form and observe the position of their own opinions relative to pro-liberal and pro-conservative comments presented on a map interface (Here). Through a user study with 94 participants, we demonstrate the feasibility of HearHere in supporting the consumption of information from various perspectives. Our findings highlight the importance of providing political stance information and quantifying users' political status as a means to mitigate political polarization. In addition, we propose design implications for system development, including the consideration of demographics such as political interest and providing users with initiatives.\n    ",
        "primary_category": "cs.HC",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "28 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18275": {
        "title": "Investigation of Adapter for Automatic Speech Recognition in Noisy Environment",
        "authors": [
            "Hao Shi",
            "Tatsuya Kawahara"
        ],
        "comments": " ",
        "subjects": "Sound (cs.SD)",
        "abstract": "Adapting an automatic speech recognition (ASR) system to unseen noise environments is crucial. Integrating adapters into neural networks has emerged as a potent technique for transfer learning. This study thoroughly investigates adapter-based ASR adaptation in noisy environments. We conducted experiments using the CHiME--4 dataset. The results show that inserting the adapter in the shallow layer yields superior effectiveness, and there is no significant difference between adapting solely within the shallow layer and adapting across all layers. The simulated data helps the system to improve its performance under real noise conditions. Nonetheless, when the amount of data is the same, the real data is more effective than the simulated data. Multi-condition training is still useful for adapter training. Furthermore, integrating adapters into speech enhancement-based ASR systems yields substantial improvements.\n    ",
        "primary_category": "cs.SD",
        "categories": [
            "cs.CL",
            "eess.AS"
        ],
        "submitted_date": "28 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18321": {
        "title": "Privacy Policies and Consent Management Platforms: Growth and Users' Interactions over Time",
        "authors": [
            "Nikhil Jha",
            "Martino Trevisan",
            "Marco Mellia",
            "Daniel Fernandez",
            "Rodrigo Irarrazaval"
        ],
        "comments": " ",
        "subjects": "Computers and Society (cs.CY)",
        "abstract": "In response to growing concerns about user privacy, legislators have introduced new regulations and laws such as the General Data Protection Regulation (GDPR) and the California Consumer Privacy Act (CCPA) that force websites to obtain user consent before activating personal data collection, fundamental to providing targeted advertising. The cornerstone of this consent-seeking process involves the use of Privacy Banners, the technical mechanism to collect users' approval for data collection practices. Consent management platforms (CMPs) have emerged as practical solutions to make it easier for website administrators to properly manage consent, allowing them to outsource the complexities of managing user consent and activating advertising features.\nThis paper presents a detailed and longitudinal analysis of the evolution of CMPs spanning nine years. We take a twofold perspective: Firstly, thanks to the HTTP Archive dataset, we provide insights into the growth, market share, and geographical spread of CMPs. Noteworthy observations include the substantial impact of GDPR on the proliferation of CMPs in Europe. Secondly, we analyse millions of user interactions with a medium-sized CMP present in thousands of websites worldwide. We observe how even small changes in the design of Privacy Banners have a critical impact on the user's giving or denying their consent to data collection. For instance, over 60% of users do not consent when offered a simple \"one-click reject-all\" option. Conversely, when opting out requires more than one click, about 90% of users prefer to simply give their consent. The main objective is in fact to eliminate the annoying privacy banner rather the make an informed decision. Curiously, we observe iOS users exhibit a higher tendency to accept cookies compared to Android users, possibly indicating greater confidence in the privacy offered by Apple devices.\n    ",
        "primary_category": "cs.CY",
        "categories": [],
        "submitted_date": "28 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18377": {
        "title": "Out-of-Domain Generalization in Dynamical Systems Reconstruction",
        "authors": [
            "Niclas G\u00f6ring",
            "Florian Hess",
            "Manuel Brenner",
            "Zahra Monfared",
            "Daniel Durstewitz"
        ],
        "comments": " ",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "In science we are interested in finding the governing equations, the dynamical rules, underlying empirical phenomena. While traditionally scientific models are derived through cycles of human insight and experimentation, recently deep learning (DL) techniques have been advanced to reconstruct dynamical systems (DS) directly from time series data. State-of-the-art dynamical systems reconstruction (DSR) methods show promise in capturing invariant and long-term properties of observed DS, but their ability to generalize to unobserved domains remains an open challenge. Yet, this is a crucial property we would expect from any viable scientific theory. In this work, we provide a formal framework that addresses generalization in DSR. We explain why and how out-of-domain (OOD) generalization (OODG) in DSR profoundly differs from OODG considered elsewhere in machine learning. We introduce mathematical notions based on topological concepts and ergodic theory to formalize the idea of learnability of a DSR model. We formally prove that black-box DL techniques, without adequate structural priors, generally will not be able to learn a generalizing DSR model. We also show this empirically, considering major classes of DSR algorithms proposed so far, and illustrate where and why they fail to generalize across the whole phase space. Our study provides the first comprehensive mathematical treatment of OODG in DSR, and gives a deeper conceptual understanding of where the fundamental problems in OODG lie and how they could possibly be addressed in practice.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.AI",
            "math.DS",
            "nlin.CD"
        ],
        "submitted_date": "28 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18402": {
        "title": "A Modular System for Enhanced Robustness of Multimedia Understanding Networks via Deep Parametric Estimation",
        "authors": [
            "Francesco Barbato",
            "Umberto Michieli",
            "Mehmet Kerim Yucel",
            "Pietro Zanuttigh",
            "Mete Ozay"
        ],
        "comments": "Accepted at ACM MMSys'24. 10 pages, 7 figures, 8 tables",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "In multimedia understanding tasks, corrupted samples pose a critical challenge, because when fed to machine learning models they lead to performance degradation. In the past, three groups of approaches have been proposed to handle noisy data: i) enhancer and denoiser modules to improve the quality of the noisy data, ii) data augmentation approaches, and iii) domain adaptation strategies. All the aforementioned approaches come with drawbacks that limit their applicability; the first has high computational costs and requires pairs of clean-corrupted data for training, while the others only allow deployment of the same task/network they were trained on (\\ie, when upstream and downstream task/network are the same). In this paper, we propose SyMPIE to solve these shortcomings. To this end, we design a small, modular, and efficient (just 2GFLOPs to process a Full HD image) system to enhance input data for robust downstream multimedia understanding with minimal computational cost. Our SyMPIE is pre-trained on an upstream task/network that should not match the downstream ones and does not need paired clean-corrupted samples. Our key insight is that most input corruptions found in real-world tasks can be modeled through global operations on color channels of images or spatial filters with small kernels. We validate our approach on multiple datasets and tasks, such as image classification (on ImageNetC, ImageNetC-Bar, VizWiz, and a newly proposed mixed corruption benchmark named ImageNetC-mixed) and semantic segmentation (on Cityscapes, ACDC, and DarkZurich) with consistent improvements of about 5\\% relative accuracy gain across the board. The code of our approach and the new ImageNetC-mixed benchmark will be made available upon publication.\n    ",
        "primary_category": "cs.CV",
        "categories": [],
        "submitted_date": "28 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18409": {
        "title": "A Cognitive Evaluation Benchmark of Image Reasoning and Description for Large Vision Language Models",
        "authors": [
            "Xiujie Song",
            "Mengyue Wu",
            "Kenny Q. Zhu",
            "Chunhao Zhang",
            "Yanyi Chen"
        ],
        "comments": " ",
        "subjects": "Artificial Intelligence (cs.AI)",
        "abstract": "Large Vision Language Models (LVLMs), despite their recent success, are hardly comprehensively tested for their cognitive abilities. Inspired by the prevalent use of the \"Cookie Theft\" task in human cognition test, we propose a novel evaluation benchmark to evaluate high-level cognitive ability of LVLMs using images with rich semantics. It defines eight reasoning capabilities and consists of an image description task and a visual question answering task. Our evaluation on well-known LVLMs shows that there is still a large gap in cognitive ability between LVLMs and humans.\n    ",
        "primary_category": "cs.AI",
        "categories": [
            "cs.CL",
            "cs.CV"
        ],
        "submitted_date": "28 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18485": {
        "title": "A Multimodal Foundation Agent for Financial Trading: Tool-Augmented, Diversified, and Generalist",
        "authors": [
            "Wentao Zhang",
            "Lingxuan Zhao",
            "Haochong Xia",
            "Shuo Sun",
            "Jiaze Sun",
            "Molei Qin",
            "Xinyi Li",
            "Yuqing Zhao",
            "Yilei Zhao",
            "Xinyu Cai",
            "Longtao Zheng",
            "Xinrun Wang",
            "Bo An"
        ],
        "comments": " ",
        "subjects": "Trading and Market Microstructure (q-fin.TR)",
        "abstract": "Financial trading is a crucial component of the markets, informed by a multimodal information landscape encompassing news, prices, and Kline charts, and encompasses diverse tasks such as quantitative trading and high-frequency trading with various assets. While advanced AI techniques like deep learning and reinforcement learning are extensively utilized in finance, their application in financial trading tasks often faces challenges due to inadequate handling of multimodal data and limited generalizability across various tasks. To address these challenges, we present FinAgent, a multimodal foundational agent with tool augmentation for financial trading. FinAgent's market intelligence module processes a diverse range of data-numerical, textual, and visual-to accurately analyze the financial market. Its unique dual-level reflection module not only enables rapid adaptation to market dynamics but also incorporates a diversified memory retrieval system, enhancing the agent's ability to learn from historical data and improve decision-making processes. The agent's emphasis on reasoning for actions fosters trust in its financial decisions. Moreover, FinAgent integrates established trading strategies and expert insights, ensuring that its trading approaches are both data-driven and rooted in sound financial principles. With comprehensive experiments on 6 financial datasets, including stocks and Crypto, FinAgent significantly outperforms 9 state-of-the-art baselines in terms of 6 financial metrics with over 36% average improvement on profit. Specifically, a 92.27% return (a 84.39% relative improvement) is achieved on one dataset. Notably, FinAgent is the first advanced multimodal foundation agent designed for financial trading tasks.\n    ",
        "primary_category": "q-fin.TR",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "28 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18495": {
        "title": "ROG$_{PL}$: Robust Open-Set Graph Learning via Region-Based Prototype Learning",
        "authors": [
            "Qin Zhang",
            "Xiaowei Li",
            "Jiexin Lu",
            "Liping Qiu",
            "Shirui Pan",
            "Xiaojun Chen",
            "Junyang Chen"
        ],
        "comments": "9 pages, 5 figures",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Open-set graph learning is a practical task that aims to classify the known class nodes and to identify unknown class samples as unknowns. Conventional node classification methods usually perform unsatisfactorily in open-set scenarios due to the complex data they encounter, such as out-of-distribution (OOD) data and in-distribution (IND) noise. OOD data are samples that do not belong to any known classes. They are outliers if they occur in training (OOD noise), and open-set samples if they occur in testing. IND noise are training samples which are assigned incorrect labels. The existence of IND noise and OOD noise is prevalent, which usually cause the ambiguity problem, including the intra-class variety problem and the inter-class confusion problem. Thus, to explore robust open-set learning methods is necessary and difficult, and it becomes even more difficult for non-IID graph this http URL this end, we propose a unified framework named ROG$_{PL}$ to achieve robust open-set learning on complex noisy graph data, by introducing prototype learning. In specific, ROG$_{PL}$ consists of two modules, i.e., denoising via label propagation and open-set prototype learning via regions. The first module corrects noisy labels through similarity-based label propagation and removes low-confidence samples, to solve the intra-class variety problem caused by noise. The second module learns open-set prototypes for each known class via non-overlapped regions and remains both interior and border prototypes to remedy the inter-class confusion problem.The two modules are iteratively updated under the constraints of classification loss and prototype diversity loss. To the best of our knowledge, the proposed ROG$_{PL}$ is the first robust open-set node classification method for graph data with complex noise.\n    ",
        "primary_category": "cs.LG",
        "categories": [],
        "submitted_date": "28 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18496": {
        "title": "Language Models Represent Beliefs of Self and Others",
        "authors": [
            "Wentao Zhu",
            "Zhining Zhang",
            "Yizhou Wang"
        ],
        "comments": "project page: this https URL",
        "subjects": "Artificial Intelligence (cs.AI)",
        "abstract": "Understanding and attributing mental states, known as Theory of Mind (ToM), emerges as a fundamental capability for human social reasoning. While Large Language Models (LLMs) appear to possess certain ToM abilities, the mechanisms underlying these capabilities remain elusive. In this study, we discover that it is possible to linearly decode the belief status from the perspectives of various agents through neural activations of language models, indicating the existence of internal representations of self and others' beliefs. By manipulating these representations, we observe dramatic changes in the models' ToM performance, underscoring their pivotal role in the social reasoning process. Additionally, our findings extend to diverse social reasoning tasks that involve different causal inference patterns, suggesting the potential generalizability of these representations.\n    ",
        "primary_category": "cs.AI",
        "categories": [
            "cs.CL"
        ],
        "submitted_date": "28 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18510": {
        "title": "RNNs are not Transformers (Yet): The Key Bottleneck on In-context Retrieval",
        "authors": [
            "Kaiyue Wen",
            "Xingyu Dang",
            "Kaifeng Lyu"
        ],
        "comments": "42 pages, 5 figures",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "This paper investigates the gap in representation powers of Recurrent Neural Networks (RNNs) and Transformers in the context of solving algorithmic problems. We focus on understanding whether RNNs, known for their memory efficiency in handling long sequences, can match the performance of Transformers, particularly when enhanced with Chain-of-Thought (CoT) prompting. Our theoretical analysis reveals that CoT improves RNNs but is insufficient to close the gap with Transformers. A key bottleneck lies in the inability of RNNs to perfectly retrieve information from the context, even with CoT: for several tasks that explicitly or implicitly require this capability, such as associative recall and determining if a graph is a tree, we prove that RNNs are not expressive enough to solve the tasks while Transformers can solve them with ease. Conversely, we prove that adopting techniques to enhance the in-context retrieval capability of RNNs, including Retrieval-Augmented Generation (RAG) and adding a single Transformer layer, can elevate RNNs to be capable of solving all polynomial-time solvable problems with CoT, hence closing the representation gap with Transformers.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.CL",
            "stat.ML"
        ],
        "submitted_date": "28 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18575": {
        "title": "DiffuseRAW: End-to-End Generative RAW Image Processing for Low-Light Images",
        "authors": [
            "Rishit Dagli"
        ],
        "comments": " ",
        "subjects": "Image and Video Processing (eess.IV)",
        "abstract": "Imaging under extremely low-light conditions presents a significant challenge and is an ill-posed problem due to the low signal-to-noise ratio (SNR) caused by minimal photon capture. Previously, diffusion models have been used for multiple kinds of generative tasks and image-to-image tasks, however, these models work as a post-processing step. These diffusion models are trained on processed images and learn on processed images. However, such approaches are often not well-suited for extremely low-light tasks. Unlike the task of low-light image enhancement or image-to-image enhancement, we tackle the task of learning the entire image-processing pipeline, from the RAW image to a processed image. For this task, a traditional image processing pipeline often consists of multiple specialized parts that are overly reliant on the downstream tasks. Unlike these, we develop a new generative ISP that relies on fine-tuning latent diffusion models on RAW images and generating processed long-exposure images which allows for the apt use of the priors from large text-to-image generation models. We evaluate our approach on popular end-to-end low-light datasets for which we see promising results and set a new SoTA on the See-in-Dark (SID) dataset. Furthermore, with this work, we hope to pave the way for more generative and diffusion-based image processing and other problems on RAW data.\n    ",
        "primary_category": "eess.IV",
        "categories": [
            "cs.AI",
            "cs.CV",
            "cs.LG"
        ],
        "submitted_date": "13 Dec 2023",
        "last_revised_date": " "
    },
    "2402.18576": {
        "title": "Improved Forecasting Using a PSO-RDV Framework to Enhance Artificial Neural Network",
        "authors": [
            "Sales Aribe Jr"
        ],
        "comments": "9 pages, 4 figures, Published with International Journal of Engineering Trends and Technology (IJETT)",
        "subjects": "Neural and Evolutionary Computing (cs.NE)",
        "abstract": "Decision making and planning have long relied heavily on AI-driven forecasts. The government and the general public are working to minimize the risks while maximizing benefits in the face of potential future public health uncertainties. This study used an improved method of forecasting utilizing the Random Descending Velocity Inertia Weight (RDV IW) technique to improve the convergence of Particle Swarm Optimization (PSO) and the accuracy of Artificial Neural Network (ANN). The IW technique, inspired by the motions of a golf ball, modified the particles' velocities as they approached the solution point to a parabolically descending structure. Simulation results revealed that the proposed forecasting model with [0.4, 0.9] combination of alpha and alpha_dump exhibits a 6.36% improvement in position error and 11.75% improvement in computational time compared to the old model, thus, improving its convergence. It reached the optimum level at minimal steps with 12.50% improvement as against the old model since it provides better velocity averages when speed stabilization occurs at the 24th iteration. Meanwhile, the computed p-values for NRMSE (0.04889174), MAE (0.02829063), MAPE (0.02226053), WAPE (0.01701545), and R2 (0.00000021) of the proposed algorithm are less than the set 0.05 level of significance, thus the values indicated a significant result in terms of accuracy performance. Applying the modified ANN-PSO using RDV IW technique greatly improved the new HIV/AIDS forecasting model compared with the two models.\n    ",
        "primary_category": "cs.NE",
        "categories": [
            "cs.AI",
            "cs.LG"
        ],
        "submitted_date": "10 Jan 2024",
        "last_revised_date": " "
    },
    "2402.18577": {
        "title": "Motion Guided Token Compression for Efficient Masked Video Modeling",
        "authors": [
            "Yukun Feng",
            "Yangming Shi",
            "Fengze Liu",
            "Tan Yan"
        ],
        "comments": " ",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Recent developments in Transformers have achieved notable strides in enhancing video comprehension. Nonetheless, the O($N^2$) computation complexity associated with attention mechanisms presents substantial computational hurdles when dealing with the high dimensionality of videos. This challenge becomes particularly pronounced when striving to increase the frames per second (FPS) to enhance the motion capturing capabilities. Such a pursuit is likely to introduce redundancy and exacerbate the existing computational limitations. In this paper, we initiate by showcasing the enhanced performance achieved through an escalation in the FPS rate. Additionally, we present a novel approach, Motion Guided Token Compression (MGTC), to empower Transformer models to utilize a smaller yet more representative set of tokens for comprehensive video representation. Consequently, this yields substantial reductions in computational burden and remains seamlessly adaptable to increased FPS rates. Specifically, we draw inspiration from video compression algorithms and scrutinize the variance between patches in consecutive video frames across the temporal dimension. The tokens exhibiting a disparity below a predetermined threshold are then masked. Notably, this masking strategy effectively addresses video redundancy while conserving essential information. Our experiments, conducted on widely examined video recognition datasets, Kinetics-400, UCF101 and HMDB51, demonstrate that elevating the FPS rate results in a significant top-1 accuracy score improvement of over 1.6, 1.6 and 4.0. By implementing MGTC with the masking ratio of 25\\%, we further augment accuracy by 0.1 and simultaneously reduce computational costs by over 31\\% on Kinetics-400. Even within a fixed computational budget, higher FPS rates paired with MGTC sustain performance gains when compared to lower FPS settings.\n    ",
        "primary_category": "cs.CV",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "10 Jan 2024",
        "last_revised_date": " "
    },
    "2402.18579": {
        "title": "Wilcoxon Nonparametric CFAR Scheme for Ship Detection in SAR Image",
        "authors": [
            "Xiangwei Meng"
        ],
        "comments": " ",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "The parametric constant false alarm rate (CFAR) detection algorithms which are based on various statistical distributions, such as Gaussian, Gamma, Weibull, log-normal, G0 distribution, alpha-stable distribution, etc, are most widely used to detect the ship targets in SAR image at present. However, the clutter background in SAR images is complicated and variable. When the actual clutter background deviates from the assumed statistical distribution, the performance of the parametric CFAR detector will deteriorate. In addition to the parametric CFAR schemes, there is another class of nonparametric CFAR detectors which can maintain a constant false alarm rate for the target detection without the assumption of a known clutter distribution. In this work, the Wilcoxon nonparametric CFAR scheme for ship detection in SAR image is proposed and analyzed, and a closed form of the false alarm rate for the Wilcoxon nonparametric detector to determine the decision threshold is presented. By comparison with several typical parametric CFAR schemes on Radarsat-2, ICEYE-X6 and Gaofen-3 SAR images, the robustness of the Wilcoxon nonparametric detector to maintain a good false alarm performance in different detection backgrounds is revealed, and its detection performance for the weak ship in rough sea surface is improved to some extent. Moreover, the Wilcoxon nonparametric detector can suppress the false alarms resulting from the sidelobes at some degree and its detection speed is fast.\n    ",
        "primary_category": "cs.CV",
        "categories": [
            "cs.AI",
            "eess.SP",
            "stat.AP"
        ],
        "submitted_date": "11 Jan 2024",
        "last_revised_date": " "
    },
    "2402.18581": {
        "title": "Multi-objective Optimal Roadside Units Deployment in Urban Vehicular Networks",
        "authors": [
            "Weian Guo",
            "Zecheng Kang",
            "Dongyang Li",
            "Lun Zhang",
            "Li Li"
        ],
        "comments": "This manuscript has been submitted to the journal of IEEE Transactions on Vehicular Technology",
        "subjects": "Neural and Evolutionary Computing (cs.NE)",
        "abstract": "The significance of transportation efficiency, safety, and related services is increasing in urban vehicular networks. Within such networks, roadside units (RSUs) serve as intermediates in facilitating communication. Therefore, the deployment of RSUs is of utmost importance in ensuring the quality of communication services. However, the optimization objectives, such as time delay and deployment cost, are commonly developed from diverse perspectives. As a result, it is possible that conflicts may arise among the objectives. Furthermore, in urban environments, the presence of various obstacles, such as buildings, gardens, lakes, and other infrastructure, poses challenges for the deployment of RSUs. Hence, the deployment encounters significant difficulties due to the existence of multiple objectives, constraints imposed by obstacles, and the necessity to explore a large-scale optimization space. To address this issue, two versions of multi-objective optimization algorithms are proposed in this paper. By utilizing a multi-population strategy and an adaptive exploration technique, the methods efficiently explore a large-scale decision-variable space. In order to mitigate the issue of an overcrowded deployment of RSUs, a calibrating mechanism is adopted to adjust RSU density during the optimization procedures. The proposed methods also take care of data offloading between vehicles and RSUs by setting up an iterative best response sequence game (IBRSG). By comparing the proposed algorithms with several state-of-the-art algorithms, the results demonstrate that our strategies perform better in both high-density and low-density urban scenarios. The results also indicate that the proposed solutions substantially improve the efficiency of vehicular networks.\n    ",
        "primary_category": "cs.NE",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "14 Jan 2024",
        "last_revised_date": " "
    },
    "2402.18582": {
        "title": "Streamlining the Selection Phase of Systematic Literature Reviews (SLRs) Using AI-Enabled GPT-4 Assistant API",
        "authors": [
            "Seyed Mohammad Ali Jafari"
        ],
        "comments": "11 pages, 5 figures",
        "subjects": "Digital Libraries (cs.DL)",
        "abstract": "The escalating volume of academic literature presents a formidable challenge in staying updated with the newest research developments. Addressing this, this study introduces a pioneering AI-based tool, configured specifically to streamline the efficiency of the article selection phase in Systematic Literature Reviews (SLRs). Utilizing the robust capabilities of OpenAI's GPT-4 Assistant API, the tool successfully homogenizes the article selection process across a broad array of academic disciplines. Implemented through a tripartite approach consisting of data preparation, AI-mediated article assessment, and structured result presentation, this tool significantly accelerates the time-consuming task of literature reviews. Importantly, this tool could be highly beneficial in fields such as management and economics, where the SLR process involves substantial human judgment. The adoption of a standard GPT model can substantially reduce potential biases and enhance the speed and precision of the SLR selection phase. This not only amplifies researcher productivity and accuracy but also denotes a considerable stride forward in the way academic research is conducted amidst the surging body of scholarly publications.\n    ",
        "primary_category": "cs.DL",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "14 Jan 2024",
        "last_revised_date": " "
    },
    "2402.18583": {
        "title": "Binding-Adaptive Diffusion Models for Structure-Based Drug Design",
        "authors": [
            "Zhilin Huang",
            "Ling Yang",
            "Zaixi Zhang",
            "Xiangxin Zhou",
            "Yu Bao",
            "Xiawu Zheng",
            "Yuwei Yang",
            "Yu Wang",
            "Wenming Yang"
        ],
        "comments": "Accepted by AAAI 2024. Project: this https URL",
        "subjects": "Biomolecules (q-bio.BM)",
        "abstract": "Structure-based drug design (SBDD) aims to generate 3D ligand molecules that bind to specific protein targets. Existing 3D deep generative models including diffusion models have shown great promise for SBDD. However, it is complex to capture the essential protein-ligand interactions exactly in 3D space for molecular generation. To address this problem, we propose a novel framework, namely Binding-Adaptive Diffusion Models (BindDM). In BindDM, we adaptively extract subcomplex, the essential part of binding sites responsible for protein-ligand interactions. Then the selected protein-ligand subcomplex is processed with SE(3)-equivariant neural networks, and transmitted back to each atom of the complex for augmenting the target-aware 3D molecule diffusion generation with binding interaction information. We iterate this hierarchical complex-subcomplex process with cross-hierarchy interaction node for adequately fusing global binding context between the complex and its corresponding subcomplex. Empirical studies on the CrossDocked2020 dataset show BindDM can generate molecules with more realistic 3D structures and higher binding affinities towards the protein targets, with up to -5.92 Avg. Vina Score, while maintaining proper molecular properties. Our code is available at this https URL\n",
        "primary_category": "q-bio.BM",
        "categories": [
            "cs.LG"
        ],
        "submitted_date": "15 Jan 2024",
        "last_revised_date": " "
    },
    "2402.18584": {
        "title": "Adjusting Dynamics of Hopfield Neural Network via Time-variant Stimulus",
        "authors": [
            "Xuenan Peng",
            "Chengqing Li",
            "Yicheng Zeng",
            "Chun-Lai Li"
        ],
        "comments": "14 pages, 21 figures",
        "subjects": "Neural and Evolutionary Computing (cs.NE)",
        "abstract": "As a paradigmatic model for nonlinear dynamics studies, the Hopfield Neural Network (HNN) demonstrates a high susceptibility to external disturbances owing to its intricate structure. This paper delves into the challenge of modulating HNN dynamics through time-variant stimuli. The effects of adjustments using two distinct types of time-variant stimuli, namely the Weight Matrix Stimulus (WMS) and the State Variable Stimulus (SVS), along with a Constant Stimulus (CS) are reported. The findings reveal that deploying four WMSs enables the HNN to generate either a four-scroll or a coexisting two-scroll attractor. When combined with one SVS, four WMSs can lead to the formation of an eight-scroll or four-scroll attractor, while the integration of four WMSs and multiple SVSs can induce grid-multi-scroll attractors. Moreover, the introduction of a CS and an SVS can significantly disrupt the dynamic behavior of the HNN. Consequently, suitable adjustment methods are crucial for enhancing the network's dynamics, whereas inappropriate applications can lead to the loss of its chaotic characteristics. To empirically validate these enhancement effects, the study employs an FPGA hardware platform. Subsequently, an image encryption scheme is designed to demonstrate the practical application benefits of the dynamically adjusted HNN in secure multimedia communication. This exploration into the dynamic modulation of HNN via time-variant stimuli offers insightful contributions to the advancement of secure communication technologies.\n    ",
        "primary_category": "cs.NE",
        "categories": [
            "nlin.CD"
        ],
        "submitted_date": "15 Jan 2024",
        "last_revised_date": " "
    },
    "2402.18587": {
        "title": "At the Dawn of Generative AI Era: A Tutorial-cum-Survey on New Frontiers in 6G Wireless Intelligence",
        "authors": [
            "Abdulkadir Celik",
            "Ahmed M. Eltawil"
        ],
        "comments": " ",
        "subjects": "Networking and Internet Architecture (cs.NI)",
        "abstract": "The majority of data-driven wireless research leans heavily on discriminative AI (DAI) that requires vast real-world datasets. Unlike the DAI, Generative AI (GenAI) pertains to generative models (GMs) capable of discerning the underlying data distribution, patterns, and features of the input data. This makes GenAI a crucial asset in wireless domain wherein real-world data is often scarce, incomplete, costly to acquire, and hard to model or comprehend. With these appealing attributes, GenAI can replace or supplement DAI methods in various capacities. Accordingly, this combined tutorial-survey paper commences with preliminaries of 6G and wireless intelligence by outlining candidate 6G applications and services, presenting a taxonomy of state-of-the-art DAI models, exemplifying prominent DAI use cases, and elucidating the multifaceted ways through which GenAI enhances DAI. Subsequently, we present a tutorial on GMs by spotlighting seminal examples such as generative adversarial networks, variational autoencoders, flow-based GMs, diffusion-based GMs, generative transformers, large language models, to name a few. Contrary to the prevailing belief that GenAI is a nascent trend, our exhaustive review of approximately 120 technical papers demonstrates the scope of research across core wireless research areas, including physical layer design; network optimization, organization, and management; network traffic analytics; cross-layer network security; and localization & positioning. Furthermore, we outline the central role of GMs in pioneering areas of 6G network research, including semantic/THz/near-field communications, ISAC, extremely large antenna arrays, digital twins, AI-generated content services, mobile edge computing and edge AI, adversarial ML, and trustworthy AI. Lastly, we shed light on the multifarious challenges ahead, suggesting potential strategies and promising remedies.\n    ",
        "primary_category": "cs.NI",
        "categories": [
            "cs.AI",
            "cs.LG"
        ],
        "submitted_date": "2 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18591": {
        "title": "Stochastic contextual bandits with graph feedback: from independence number to MAS number",
        "authors": [
            "Yuxiao Wen",
            "Yanjun Han",
            "Zhengyuan Zhou"
        ],
        "comments": " ",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "We consider contextual bandits with graph feedback, a class of interactive learning problems with richer structures than vanilla contextual bandits, where taking an action reveals the rewards for all neighboring actions in the feedback graph under all contexts. Unlike the multi-armed bandits setting where a growing literature has painted a near-complete understanding of graph feedback, much remains unexplored in the contextual bandits counterpart. In this paper, we make inroads into this inquiry by establishing a regret lower bound $\\Omega(\\sqrt{\\beta_M(G) T})$, where $M$ is the number of contexts, $G$ is the feedback graph, and $\\beta_M(G)$ is our proposed graph-theoretical quantity that characterizes the fundamental learning limit for this class of problems. Interestingly, $\\beta_M(G)$ interpolates between $\\alpha(G)$ (the independence number of the graph) and $\\mathsf{m}(G)$ (the maximum acyclic subgraph (MAS) number of the graph) as the number of contexts $M$ varies. We also provide algorithms that achieve near-optimal regrets for important classes of context sequences and/or feedback graphs, such as transitively closed graphs that find applications in auctions and inventory control. In particular, with many contexts, our results show that the MAS number completely characterizes the statistical complexity for contextual bandits, as opposed to the independence number in multi-armed bandits.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.GT",
            "math.ST"
        ],
        "submitted_date": "12 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18592": {
        "title": "A$^3$PIM: An Automated, Analytic and Accurate Processing-in-Memory Offloader",
        "authors": [
            "Qingcai Jiang",
            "Shaojie Tan",
            "Junshi Chen",
            "Hong An"
        ],
        "comments": "6 pages, 4 figures, accepted for presentation at Design, Automation and Test in Europe Conference | The European Event for Electronic System Design & Test (DATE 2024), conference to be held in March 2024",
        "subjects": "Hardware Architecture (cs.AR)",
        "abstract": "The performance gap between memory and processor has grown rapidly. Consequently, the energy and wall-clock time costs associated with moving data between the CPU and main memory predominate the overall computational cost. The Processing-in-Memory (PIM) paradigm emerges as a promising architecture that mitigates the need for extensive data movements by strategically positioning computing units proximate to the memory. Despite the abundant efforts devoted to building a robust and highly-available PIM system, identifying PIM-friendly segments of applications poses significant challenges due to the lack of a comprehensive tool to evaluate the intrinsic memory access pattern of the segment.\nTo tackle this challenge, we propose A$^3$PIM: an Automated, Analytic and Accurate Processing-in-Memory offloader. We systematically consider the cross-segment data movement and the intrinsic memory access pattern of each code segment via static code analyzer. We evaluate A$^3$PIM across a wide range of real-world workloads including GAP and PrIM benchmarks and achieve an average speedup of 2.63x and 4.45x (up to 7.14x and 10.64x) when compared to CPU-only and PIM-only executions, respectively.\n    ",
        "primary_category": "cs.AR",
        "categories": [
            "cs.PF"
        ],
        "submitted_date": "23 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18593": {
        "title": "Sustainable Supercomputing for AI: GPU Power Capping at HPC Scale",
        "authors": [
            "Dan Zhao",
            "Siddharth Samsi",
            "Joseph McDonald",
            "Baolin Li",
            "David Bestor",
            "Michael Jones",
            "Devesh Tiwari",
            "Vijay Gadepally"
        ],
        "comments": " ",
        "subjects": "Hardware Architecture (cs.AR)",
        "abstract": "As research and deployment of AI grows, the computational burden to support and sustain its progress inevitably does too. To train or fine-tune state-of-the-art models in NLP, computer vision, etc., some form of AI hardware acceleration is virtually a requirement. Recent large language models require considerable resources to train and deploy, resulting in significant energy usage, potential carbon emissions, and massive demand for GPUs and other hardware accelerators. However, this surge carries large implications for energy sustainability at the HPC/datacenter level. In this paper, we study the aggregate effect of power-capping GPUs on GPU temperature and power draw at a research supercomputing center. With the right amount of power-capping, we show significant decreases in both temperature and power draw, reducing power consumption and potentially improving hardware life-span with minimal impact on job performance. While power-capping reduces power draw by design, the aggregate system-wide effect on overall energy consumption is less clear; for instance, if users notice job performance degradation from GPU power-caps, they may request additional GPU-jobs to compensate, negating any energy savings or even worsening energy consumption. To our knowledge, our work is the first to conduct and make available a detailed analysis of the effects of GPU power-capping at the supercomputing scale. We hope our work will inspire HPCs/datacenters to further explore, evaluate, and communicate the impact of power-capping AI hardware accelerators for more sustainable AI.\n    ",
        "primary_category": "cs.AR",
        "categories": [
            "cs.AI",
            "cs.DC"
        ],
        "submitted_date": "25 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18595": {
        "title": "EncodingNet: A Novel Encoding-based MAC Design for Efficient Neural Network Acceleration",
        "authors": [
            "Bo Liu",
            "Grace Li Zhang",
            "Xunzhao Yin",
            "Ulf Schlichtmann",
            "Bing Li"
        ],
        "comments": " ",
        "subjects": "Hardware Architecture (cs.AR)",
        "abstract": "Deep neural networks (DNNs) have achieved great breakthroughs in many fields such as image classification and natural language processing. However, the execution of DNNs needs to conduct massive numbers of multiply-accumulate (MAC) operations on hardware and thus incurs a large power consumption. To address this challenge, we propose a novel digital MAC design based on encoding. In this new design, the multipliers are replaced by simple logic gates to project the results onto a wide bit representation. These bits carry individual position weights, which can be trained for specific neural networks to enhance inference accuracy. The outputs of the new multipliers are added by bit-wise weighted accumulation and the accumulation results are compatible with existing computing platforms accelerating neural networks with either uniform or non-uniform quantization. Since the multiplication function is replaced by simple logic projection, the critical paths in the resulting circuits become much shorter. Correspondingly, pipelining stages in the MAC array can be reduced, leading to a significantly smaller area as well as a better power efficiency. The proposed design has been synthesized and verified by ResNet18-Cifar10, ResNet20-Cifar100 and ResNet50-ImageNet. The experimental results confirmed the reduction of circuit area by up to 79.63% and the reduction of power consumption of executing DNNs by up to 70.18%, while the accuracy of the neural networks can still be well maintained.\n    ",
        "primary_category": "cs.AR",
        "categories": [
            "cs.CE",
            "cs.LG"
        ],
        "submitted_date": "25 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18596": {
        "title": "Image-To-Mesh Conversion for Biomedical Simulations",
        "authors": [
            "Fotis Drakopoulos",
            "Kevin Garner",
            "Christopher Rector",
            "Nikos Chrisochoides"
        ],
        "comments": "37 pages, 26 figures",
        "subjects": "Graphics (cs.GR)",
        "abstract": "Converting a three-dimensional medical image into a 3D mesh that satisfies both the quality and fidelity constraints of predictive simulations and image-guided surgical procedures remains a critical problem. Presented is an image-to-mesh conversion method called CBC3D. It first discretizes a segmented image by generating an adaptive Body-Centered Cubic (BCC) mesh of high-quality elements. Next, the tetrahedral mesh is converted into a mixed-element mesh of tetrahedra, pentahedra, and hexahedra to decrease element count while maintaining quality. Finally, the mesh surfaces are deformed to their corresponding physical image boundaries, improving the mesh's fidelity. The deformation scheme builds upon the ITK open-source library and is based on the concept of energy minimization, relying on a multi-material point-based registration. It uses non-connectivity patterns to implicitly control the number of extracted feature points needed for the registration and, thus, adjusts the trade-off between the achieved mesh fidelity and the deformation speed. We compare CBC3D with four widely used and state-of-the-art homegrown image-to-mesh conversion methods from industry and academia. Results indicate that the CBC3D meshes (i) achieve high fidelity, (ii) keep the element count reasonably low, and (iii) exhibit good element quality.\n    ",
        "primary_category": "cs.GR",
        "categories": [
            "cs.MS",
            "math.NA"
        ],
        "submitted_date": "27 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18599": {
        "title": "Meta-Tasks: An alternative view on Meta-Learning Regularization",
        "authors": [
            "Mohammad Rostami",
            "Atik Faysal",
            "Huaxia Wang",
            "Avimanyu Sahoo",
            "Ryan Antle"
        ],
        "comments": " ",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Few-shot learning (FSL) is a challenging machine learning problem due to a scarcity of labeled data. The ability to generalize effectively on both novel and training tasks is a significant barrier to FSL. This paper proposes a novel solution that can generalize to both training and novel tasks while also utilizing unlabeled samples. The method refines the embedding model before updating the outer loop using unsupervised techniques as ``meta-tasks''. The experimental results show that our proposed method performs well on novel and training tasks, with faster and better convergence, lower generalization, and standard deviation error, indicating its potential for practical applications in FSL. The experimental results show that the proposed method outperforms prototypical networks by 3.9%.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "27 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18600": {
        "title": "Artificial Intelligence and Diabetes Mellitus: An Inside Look Through the Retina",
        "authors": [
            "Yasin Sadeghi Bazargani",
            "Majid Mirzaei",
            "Navid Sobhi",
            "Mirsaeed Abdollahi",
            "Ali Jafarizadeh",
            "Siamak Pedrammehr",
            "Roohallah Alizadehsani",
            "Ru San Tan",
            "Sheikh Mohammed Shariful Islam",
            "U. Rajendra Acharya"
        ],
        "comments": "44 Pages, 6 figures, 1 table, 166 references",
        "subjects": "Image and Video Processing (eess.IV)",
        "abstract": "Diabetes mellitus (DM) predisposes patients to vascular complications. Retinal images and vasculature reflect the body's micro- and macrovascular health. They can be used to diagnose DM complications, including diabetic retinopathy (DR), neuropathy, nephropathy, and atherosclerotic cardiovascular disease, as well as forecast the risk of cardiovascular events. Artificial intelligence (AI)-enabled systems developed for high-throughput detection of DR using digitized retinal images have become clinically adopted. Beyond DR screening, AI integration also holds immense potential to address challenges associated with the holistic care of the patient with DM. In this work, we aim to comprehensively review the literature for studies on AI applications based on retinal images related to DM diagnosis, prognostication, and management. We will describe the findings of holistic AI-assisted diabetes care, including but not limited to DR screening, and discuss barriers to implementing such systems, including issues concerning ethics, data privacy, equitable access, and explainability. With the ability to evaluate the patient's health status vis a vis DM complication as well as risk prognostication of future cardiovascular complications, AI-assisted retinal image analysis has the potential to become a central tool for modern personalized medicine in patients with DM.\n    ",
        "primary_category": "eess.IV",
        "categories": [
            "cs.AI",
            "q-bio.TO"
        ],
        "submitted_date": "28 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18605": {
        "title": "FORML: A Riemannian Hessian-free Method for Meta-learning with Orthogonality Constraint",
        "authors": [
            "Hadi Tabealhojeh",
            "Soumava Kumar Roy",
            "Peyman Adibi",
            "Hossein Karshenas"
        ],
        "comments": " ",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Meta-learning problem is usually formulated as a bi-level optimization in which the task-specific and the meta-parameters are updated in the inner and outer loops of optimization, respectively. However, performing the optimization in the Riemannian space, where the parameters and meta-parameters are located on Riemannian manifolds is computationally intensive. Unlike the Euclidean methods, the Riemannian backpropagation needs computing the second-order derivatives that include backward computations through the Riemannian operators such as retraction and orthogonal projection. This paper introduces a Hessian-free approach that uses a first-order approximation of derivatives on the Stiefel manifold. Our method significantly reduces the computational load and memory footprint. We show how using a Stiefel fully-connected layer that enforces orthogonality constraint on the parameters of the last classification layer as the head of the backbone network, strengthens the representation reuse of the gradient-based meta-learning methods. Our experimental results across various few-shot learning datasets, demonstrate the superiority of our proposed method compared to the state-of-the-art methods, especially MAML, its Euclidean counterpart.\n    ",
        "primary_category": "cs.LG",
        "categories": [],
        "submitted_date": "28 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18606": {
        "title": "Impact of network topology on the performance of Decentralized Federated Learning",
        "authors": [
            "Luigi Palmieri",
            "Chiara Boldrini",
            "Lorenzo Valerio",
            "Andrea Passarella",
            "Marco Conti"
        ],
        "comments": "Funding: H2020 HumaneAI Net (Grant N. 952026), CHIST-ERA SAI (CHIST-ERA-19-XAI010), PNRR FAIR (PE00000013), PNRR RESTART (PE00000001). arXiv admin note: text overlap with arXiv:2307.15947",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Fully decentralized learning is gaining momentum for training AI models at the Internet's edge, addressing infrastructure challenges and privacy concerns. In a decentralized machine learning system, data is distributed across multiple nodes, with each node training a local model based on its respective dataset. The local models are then shared and combined to form a global model capable of making accurate predictions on new data. Our exploration focuses on how different types of network structures influence the spreading of knowledge - the process by which nodes incorporate insights gained from learning patterns in data available on other nodes across the network. Specifically, this study investigates the intricate interplay between network structure and learning performance using three network topologies and six data distribution methods. These methods consider different vertex properties, including degree centrality, betweenness centrality, and clustering coefficient, along with whether nodes exhibit high or low values of these metrics. Our findings underscore the significance of global centrality metrics (degree, betweenness) in correlating with learning performance, while local clustering proves less predictive. We highlight the challenges in transferring knowledge from peripheral to central nodes, attributed to a dilution effect during model aggregation. Additionally, we observe that central nodes exert a pull effect, facilitating the spread of knowledge. In examining degree distribution, hubs in Barabasi-Albert networks positively impact learning for central nodes but exacerbate dilution when knowledge originates from peripheral nodes. Finally, we demonstrate the formidable challenge of knowledge circulation outside of segregated communities.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.AI",
            "cs.DC"
        ],
        "submitted_date": "28 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18610": {
        "title": "Why Attention Graphs Are All We Need: Pioneering Hierarchical Classification of Hematologic Cell Populations with LeukoGraph",
        "authors": [
            "Fatemeh Nassajian Mojarrad",
            "Lorenzo Bini",
            "Thomas Matthes",
            "St\u00e9phane Marchand-Maillet"
        ],
        "comments": " ",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "In the complex landscape of hematologic samples such as peripheral blood or bone marrow, cell classification, delineating diverse populations into a hierarchical structure, presents profound challenges. This study presents LeukoGraph, a recently developed framework designed explicitly for this purpose employing graph attention networks (GATs) to navigate hierarchical classification (HC) complexities. Notably, LeukoGraph stands as a pioneering effort, marking the application of graph neural networks (GNNs) for hierarchical inference on graphs, accommodating up to one million nodes and millions of edges, all derived from flow cytometry data. LeukoGraph intricately addresses a classification paradigm where for example four different cell populations undergo flat categorization, while a fifth diverges into two distinct child branches, exemplifying the nuanced hierarchical structure inherent in complex datasets. The technique is more general than this example. A hallmark achievement of LeukoGraph is its F-score of 98%, significantly outclassing prevailing state-of-the-art methodologies. Crucially, LeukoGraph's prowess extends beyond theoretical innovation, showcasing remarkable precision in predicting both flat and hierarchical cell types across flow cytometry datasets from 30 distinct patients. This precision is further underscored by LeukoGraph's ability to maintain a correct label ratio, despite the inherent challenges posed by hierarchical classifications.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "q-bio.CB"
        ],
        "submitted_date": "28 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18614": {
        "title": "Deep Neural Network Models Trained With A Fixed Random Classifier Transfer Better Across Domains",
        "authors": [
            "Hafiz Tiomoko Ali",
            "Umberto Michieli",
            "Ji Joong Moon",
            "Daehyun Kim",
            "Mete Ozay"
        ],
        "comments": "ICASSP 2024. Copyright 2024 IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses, in any current or future media, including reprinting/republishing this material for advertising or promotional purposes, creating new collective works, for resale or redistribution to servers or lists, or reuse of any copyrighted component of this work in other",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "The recently discovered Neural collapse (NC) phenomenon states that the last-layer weights of Deep Neural Networks (DNN), converge to the so-called Equiangular Tight Frame (ETF) simplex, at the terminal phase of their training. This ETF geometry is equivalent to vanishing within-class variability of the last layer activations. Inspired by NC properties, we explore in this paper the transferability of DNN models trained with their last layer weight fixed according to ETF. This enforces class separation by eliminating class covariance information, effectively providing implicit regularization. We show that DNN models trained with such a fixed classifier significantly improve transfer performance, particularly on out-of-domain datasets. On a broad range of fine-grained image classification datasets, our approach outperforms i) baseline methods that do not perform any covariance regularization (up to 22%), as well as ii) methods that explicitly whiten covariance of activations throughout training (up to 19%). Our findings suggest that DNNs trained with fixed ETF classifiers offer a powerful mechanism for improving transfer learning across domains.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.CV",
            "cs.NE"
        ],
        "submitted_date": "28 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18616": {
        "title": "JCLEC-MO: a Java suite for solving many-objective optimization engineering problems",
        "authors": [
            "Aurora Ram\u00edrez",
            "Jos\u00e9 Ra\u00fal Romero",
            "Carlos Garc\u00eda-Mart\u00ednez",
            "Sebasti\u00e1n Ventura"
        ],
        "comments": "41 pages, 5 figures, journal paper",
        "subjects": "Neural and Evolutionary Computing (cs.NE)",
        "abstract": "Although metaheuristics have been widely recognized as efficient techniques to solve real-world optimization problems, implementing them from scratch remains difficult for domain-specific experts without programming skills. In this scenario, metaheuristic optimization frameworks are a practical alternative as they provide a variety of algorithms composed of customized elements, as well as experimental support. Recently, many engineering problems require to optimize multiple or even many objectives, increasing the interest in appropriate metaheuristic algorithms and frameworks that might integrate new specific requirements while maintaining the generality and reusability principles they were conceived for. Based on this idea, this paper introduces JCLEC-MO, a Java framework for both multi- and many-objective optimization that enables engineers to apply, or adapt, a great number of multi-objective algorithms with little coding effort. A case study is developed and explained to show how JCLEC-MO can be used to address many-objective engineering problems, often requiring the inclusion of domain-specific elements, and to analyze experimental outcomes by means of conveniently connected R utilities.\n    ",
        "primary_category": "cs.NE",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "28 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18617": {
        "title": "ELA: Exploited Level Augmentation for Offline Learning in Zero-Sum Games",
        "authors": [
            "Shiqi Lei",
            "Kanghoon Lee",
            "Linjing Li",
            "Jinkyoo Park",
            "Jiachen Li"
        ],
        "comments": "12 pages, 8 figures",
        "subjects": "Computer Science and Game Theory (cs.GT)",
        "abstract": "Offline learning has become widely used due to its ability to derive effective policies from offline datasets gathered by expert demonstrators without interacting with the environment directly. Recent research has explored various ways to enhance offline learning efficiency by considering the characteristics (e.g., expertise level or multiple demonstrators) of the dataset. However, a different approach is necessary in the context of zero-sum games, where outcomes vary significantly based on the strategy of the opponent. In this study, we introduce a novel approach that uses unsupervised learning techniques to estimate the exploited level of each trajectory from the offline dataset of zero-sum games made by diverse demonstrators. Subsequently, we incorporate the estimated exploited level into the offline learning to maximize the influence of the dominant strategy. Our method enables interpretable exploited level estimation in multiple zero-sum games and effectively identifies dominant strategy data. Also, our exploited level augmented offline learning significantly enhances the original offline learning algorithms including imitation learning and offline reinforcement learning for zero-sum games.\n    ",
        "primary_category": "cs.GT",
        "categories": [
            "cs.AI",
            "cs.LG",
            "cs.MA"
        ],
        "submitted_date": "28 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18618": {
        "title": "Urban Green Index estimation based on data collected by remote sensing for Romanian cities",
        "authors": [
            "Marian Necula",
            "Tudorel Andrei",
            "Bogdan Oancea",
            "Mihaela P\u0103un"
        ],
        "comments": " ",
        "subjects": "Other Computer Science (cs.OH)",
        "abstract": "The modernization of offi cial statistics involves the use of new data sources, such as data collected through remote sensing. The document contains a description of how an urban green index, derived from the SDG 11.7 objective, was obtained for Romania's 41 county seat cities based on free data sets collected by remote sensing from the European and North American space agencies. The main result is represented by an estimate of the areas of surfaces covered with vegetation for the 40 county seat towns and the municipality of Bucharest, relative to the total surface. To estimate the area covered with vegetation, we used two data sets obtained by remote sensing, namely data provided by the MODIS mission, the TERRA satellite, and data provided by the Sentinel 2 mission from the Copernicus space program. Based on the results obtained, namely the surface area covered with vegetation, estimated in square kilometers, and the percentage of the total surface area or urban green index, we have created a national top of the county seat cities\n    ",
        "primary_category": "cs.OH",
        "categories": [],
        "submitted_date": "28 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18621": {
        "title": "Unveiling News Publishers Trustworthiness Through Social Interactions",
        "authors": [
            "Manuel Pratelli",
            "Fabio Saracco",
            "Marinella Petrocchi"
        ],
        "comments": "A pre-final version of the paper accepted at WebSci'24",
        "subjects": "Social and Information Networks (cs.SI)",
        "abstract": "With the primary goal of raising readers' awareness of misinformation phenomena, extensive efforts have been made by both academic institutions and independent organizations to develop methodologies for assessing the trustworthiness of online news publishers. Unfortunately, existing approaches are costly and face critical scalability challenges. This study presents a novel framework for assessing the trustworthiness of online news publishers using user interactions on social media platforms. The proposed methodology provides a versatile solution that serves the dual purpose of i) identifying verifiable online publishers and ii) automatically performing an initial estimation of the trustworthiness of previously unclassified online news outlets.\n    ",
        "primary_category": "cs.SI",
        "categories": [],
        "submitted_date": "28 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18630": {
        "title": "GNSS Positioning using Cost Function Regulated Multilateration and Graph Neural Networks",
        "authors": [
            "Amir Jalalirad",
            "Davide Belli",
            "Bence Major",
            "Songwon Jee",
            "Himanshu Shah",
            "Will Morrison"
        ],
        "comments": "Published in The Proceedings of the Institute of Navigation GNSS+ 2023",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "In urban environments, where line-of-sight signals from GNSS satellites are frequently blocked by high-rise objects, GNSS receivers are subject to large errors in measuring satellite ranges. Heuristic methods are commonly used to estimate these errors and reduce the impact of noisy measurements on localization accuracy. In our work, we replace these error estimation heuristics with a deep learning model based on Graph Neural Networks. Additionally, by analyzing the cost function of the multilateration process, we derive an optimal method to utilize the estimated errors. Our approach guarantees that the multilateration converges to the receiver's location as the error estimation accuracy increases. We evaluate our solution on a real-world dataset containing more than 100k GNSS epochs, collected from multiple cities with diverse characteristics. The empirical results show improvements from 40% to 80% in the horizontal localization error against recent deep learning baselines as well as classical localization approaches.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "eess.SP"
        ],
        "submitted_date": "28 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18649": {
        "title": "A New Era in LLM Security: Exploring Security Concerns in Real-World LLM-based Systems",
        "authors": [
            "Fangzhou Wu",
            "Ning Zhang",
            "Somesh Jha",
            "Patrick McDaniel",
            "Chaowei Xiao"
        ],
        "comments": " ",
        "subjects": "Cryptography and Security (cs.CR)",
        "abstract": "Large Language Model (LLM) systems are inherently compositional, with individual LLM serving as the core foundation with additional layers of objects such as plugins, sandbox, and so on. Along with the great potential, there are also increasing concerns over the security of such probabilistic intelligent systems. However, existing studies on LLM security often focus on individual LLM, but without examining the ecosystem through the lens of LLM systems with other objects (e.g., Frontend, Webtool, Sandbox, and so on). In this paper, we systematically analyze the security of LLM systems, instead of focusing on the individual LLMs. To do so, we build on top of the information flow and formulate the security of LLM systems as constraints on the alignment of the information flow within LLM and between LLM and other objects. Based on this construction and the unique probabilistic nature of LLM, the attack surface of the LLM system can be decomposed into three key components: (1) multi-layer security analysis, (2) analysis of the existence of constraints, and (3) analysis of the robustness of these constraints. To ground this new attack surface, we propose a multi-layer and multi-step approach and apply it to the state-of-art LLM system, OpenAI GPT4. Our investigation exposes several security issues, not just within the LLM model itself but also in its integration with other components. We found that although the OpenAI GPT4 has designed numerous safety constraints to improve its safety features, these safety constraints are still vulnerable to attackers. To further demonstrate the real-world threats of our discovered vulnerabilities, we construct an end-to-end attack where an adversary can illicitly acquire the user's chat history, all without the need to manipulate the user's input or gain direct access to OpenAI GPT4. Our demo is in the link: this https URL\n",
        "primary_category": "cs.CR",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "28 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18650": {
        "title": "The Grasp Reset Mechanism: An Automated Apparatus for Conducting Grasping Trials",
        "authors": [
            "Kyle DuFrene",
            "Keegan Nave",
            "Joshua Campbell",
            "Ravi Balasubramanian",
            "Cindy Grimm"
        ],
        "comments": "Accepted to the 2024 IEEE International Conference on Robotics and Automation (ICRA2024)",
        "subjects": "Robotics (cs.RO)",
        "abstract": "Advancing robotic grasping and manipulation requires the ability to test algorithms and/or train learning models on large numbers of grasps. Towards the goal of more advanced grasping, we present the Grasp Reset Mechanism (GRM), a fully automated apparatus for conducting large-scale grasping trials. The GRM automates the process of resetting a grasping environment, repeatably placing an object in a fixed location and controllable 1-D orientation. It also collects data and swaps between multiple objects enabling robust dataset collection with no human intervention. We also present a standardized state machine interface for control, which allows for integration of most manipulators with minimal effort. In addition to the physical design and corresponding software, we include a dataset of 1,020 grasps. The grasps were created with a Kinova Gen3 robot arm and Robotiq 2F-85 Adaptive Gripper to enable training of learning models and to demonstrate the capabilities of the GRM. The dataset includes ranges of grasps conducted across four objects and a variety of orientations. Manipulator states, object pose, video, and grasp success data are provided for every trial.\n    ",
        "primary_category": "cs.RO",
        "categories": [],
        "submitted_date": "28 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18651": {
        "title": "Quantifying Human Priors over Social and Navigation Networks",
        "authors": [
            "Gecia Bravo-Hermsdorff"
        ],
        "comments": "Published on Proceedings of the 40th International Conference on Machine Learning (ICML), PMLR 202:3063-3105, 2023",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Human knowledge is largely implicit and relational -- do we have a friend in common? can I walk from here to there? In this work, we leverage the combinatorial structure of graphs to quantify human priors over such relational data. Our experiments focus on two domains that have been continuously relevant over evolutionary timescales: social interaction and spatial navigation. We find that some features of the inferred priors are remarkably consistent, such as the tendency for sparsity as a function of graph size. Other features are domain-specific, such as the propensity for triadic closure in social interactions. More broadly, our work demonstrates how nonclassical statistical analysis of indirect behavioral experiments can be used to efficiently model latent biases in the data.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.AI",
            "cs.SI",
            "physics.soc-ph",
            "q-bio.NC",
            "stat.ME"
        ],
        "submitted_date": "28 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18652": {
        "title": "Spatial Variation-Aware Read Disturbance Defenses: Experimental Analysis of Real DRAM Chips and Implications on Future Solutions",
        "authors": [
            "Abdullah Giray Ya\u011fl\u0131k\u00e7\u0131",
            "Yahya Can Tu\u011frul",
            "Geraldo F. Oliveira",
            "\u0130smail Emir Y\u00fcksel",
            "Ataberk Olgun",
            "Haocong Luo",
            "Onur Mutlu"
        ],
        "comments": "A shorter version of this work is to appear at the 30th IEEE International Symposium on High-Performance Computer Architecture (HPCA-30), 2024",
        "subjects": "Cryptography and Security (cs.CR)",
        "abstract": "Read disturbance in modern DRAM chips is a widespread phenomenon and is reliably used for breaking memory isolation, a fundamental building block for building robust systems. RowHammer and RowPress are two examples of read disturbance in DRAM where repeatedly accessing (hammering) or keeping active (pressing) a memory location induces bitflips in other memory locations. Unfortunately, shrinking technology node size exacerbates read disturbance in DRAM chips over generations. As a result, existing defense mechanisms suffer from significant performance and energy overheads, limited effectiveness, or prohibitively high hardware complexity.\nIn this paper, we tackle these shortcomings by leveraging the spatial variation in read disturbance across different memory locations in real DRAM chips. To do so, we 1) present the first rigorous real DRAM chip characterization study of spatial variation of read disturbance and 2) propose Sv\u00e4rd, a new mechanism that dynamically adapts the aggressiveness of existing solutions based on the row-level read disturbance profile. Our experimental characterization on 144 real DDR4 DRAM chips representing 10 chip designs demonstrates a large variation in read disturbance vulnerability across different memory locations: in the part of memory with the worst read disturbance vulnerability, 1) up to 2x the number of bitflips can occur and 2) bitflips can occur at an order of magnitude fewer accesses, compared to the memory locations with the least vulnerability to read disturbance. Sv\u00e4rd leverages this variation to reduce the overheads of five state-of-the-art read disturbance solutions, and thus significantly increases system performance.\n    ",
        "primary_category": "cs.CR",
        "categories": [
            "cs.AR"
        ],
        "submitted_date": "28 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18659": {
        "title": "Large Language Models and Games: A Survey and Roadmap",
        "authors": [
            "Roberto Gallotta",
            "Graham Todd",
            "Marvin Zammit",
            "Sam Earle",
            "Antonios Liapis",
            "Julian Togelius",
            "Georgios N. Yannakakis"
        ],
        "comments": "13 pages, 4 figures",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "Recent years have seen an explosive increase in research on large language models (LLMs), and accompanying public engagement on the topic. While starting as a niche area within natural language processing, LLMs have shown remarkable potential across a broad range of applications and domains, including games. This paper surveys the current state of the art across the various applications of LLMs in and for games, and identifies the different roles LLMs can take within a game. Importantly, we discuss underexplored areas and promising directions for future uses of LLMs in games and we reconcile the potential and limitations of LLMs within the games domain. As the first comprehensive survey and roadmap at the intersection of LLMs and games, we are hopeful that this paper will serve as the basis for groundbreaking research and innovation in this exciting new field.\n    ",
        "primary_category": "cs.CL",
        "categories": [
            "cs.AI",
            "cs.HC"
        ],
        "submitted_date": "28 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18660": {
        "title": "Versatile mixed methods for compressible flows",
        "authors": [
            "Edward A. Miller",
            "David M. Williams"
        ],
        "comments": "28 pages, 4 figures, 4 tables",
        "subjects": "Numerical Analysis (math.NA)",
        "abstract": "Versatile mixed finite element methods were originally developed by Chen and Williams for isothermal incompressible flows in \"Versatile mixed methods for the incompressible Navier-Stokes equations,\" Computers & Mathematics with Applications, Volume 80, 2020. Thereafter, these methods were extended by Miller, Chen, and Williams to non-isothermal incompressible flows in \"Versatile mixed methods for non-isothermal incompressible flows,\" Computers & Mathematics with Applications, Volume 125, 2022. The main advantage of these methods lies in their flexibility. Unlike traditional mixed methods, they retain the divergence terms in the momentum and temperature equations. As a result, the favorable properties of the schemes are maintained even in the presence of non-zero divergence. This makes them an ideal candidate for an extension to compressible flows, in which the divergence does not generally vanish. In the present article, we finally construct the fully-compressible extension of the methods. In addition, we demonstrate the excellent performance of the resulting methods for weakly-compressible flows that arise near the incompressible limit, as well as more strongly-compressible flows that arise near Mach 0.5.\n    ",
        "primary_category": "math.NA",
        "categories": [],
        "submitted_date": "28 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18667": {
        "title": "FOFO: A Benchmark to Evaluate LLMs' Format-Following Capability",
        "authors": [
            "Congying Xia",
            "Chen Xing",
            "Jiangshu Du",
            "Xinyi Yang",
            "Yihao Feng",
            "Ran Xu",
            "Wenpeng Yin",
            "Caiming Xiong"
        ],
        "comments": "The first two authors contributed equally",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "This paper presents FoFo, a pioneering benchmark for evaluating large language models' (LLMs) ability to follow complex, domain-specific formats, a crucial yet underexamined capability for their application as AI agents. Despite LLMs' advancements, existing benchmarks fail to assess their format-following proficiency adequately. FoFo fills this gap with a diverse range of real-world formats and instructions, developed through an AI-Human collaborative method. Our evaluation across both open-source (e.g., Llama 2, WizardLM) and closed-source (e.g., GPT-4, PALM2, Gemini) LLMs highlights three key findings: open-source models significantly lag behind closed-source ones in format adherence; LLMs' format-following performance is independent of their content generation quality; and LLMs' format proficiency varies across different domains. These insights suggest the need for specialized tuning for format-following skills and highlight FoFo's role in guiding the selection of domain-specific AI agents. FoFo is released here at this https URL.\n    ",
        "primary_category": "cs.CL",
        "categories": [],
        "submitted_date": "28 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18668": {
        "title": "Simple linear attention language models balance the recall-throughput tradeoff",
        "authors": [
            "Simran Arora",
            "Sabri Eyuboglu",
            "Michael Zhang",
            "Aman Timalsina",
            "Silas Alberti",
            "Dylan Zinsley",
            "James Zou",
            "Atri Rudra",
            "Christopher R\u00e9"
        ],
        "comments": " ",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "Recent work has shown that attention-based language models excel at recall, the ability to ground generations in tokens previously seen in context. However, the efficiency of attention-based models is bottle-necked during inference by the KV-cache's aggressive memory consumption. In this work, we explore whether we can improve language model efficiency (e.g. by reducing memory consumption) without compromising on recall. By applying experiments and theory to a broad set of architectures, we identify a key tradeoff between a model's state size and recall ability. We show that efficient alternatives to attention (e.g. H3, Mamba, RWKV) maintain a fixed-size recurrent state, but struggle at recall. We propose BASED a simple architecture combining linear and sliding window attention. By varying BASED window size and linear attention feature dimension, we can dial the state size and traverse the pareto frontier of the recall-memory tradeoff curve, recovering the full quality of attention on one end and the small state size of attention-alternatives on the other. We train language models up to 1.3b parameters and show that BASED matches the strongest sub-quadratic models (e.g. Mamba) in perplexity and outperforms them on real-world recall-intensive tasks by 6.22 accuracy points. Implementations of linear attention are often less efficient than optimized standard attention implementations. To make BASED competitive, we develop IO-aware algorithms that enable 24x higher throughput on language generation than FlashAttention-2, when generating 1024 tokens using 1.3b parameter models. Code for this work is provided at: this https URL.\n    ",
        "primary_category": "cs.CL",
        "categories": [
            "cs.LG"
        ],
        "submitted_date": "28 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18675": {
        "title": "Robot Body Schema Learning from Full-body Extero/Proprioception Sensors",
        "authors": [
            "Shuo Jiang",
            "Jinkun Zhang",
            "Lawson Wong"
        ],
        "comments": " ",
        "subjects": "Robotics (cs.RO)",
        "abstract": "For a robot, its body structure is an a-prior knowledge when it is designed. However, when such information is not available, can a robot recognize it by itself? In this paper, we aim to grant a robot such ability to learn its body structure from exteroception and proprioception data collected from on-body sensors. By a novel machine learning method, the robot can learn a binary Heterogeneous Dependency Matrix from its sensor readings. We showed such matrix is equivalent to a Heterogeneous out-tree structure which can uniquely represent the robot body topology. We explored the properties of such matrix and the out-tree, and proposed a remedy to fix them when they are contaminated by partial observability or data noise. We ran our algorithm on 6 different robots with different body structures in simulation and 1 real robot. Our algorithm correctly recognized their body structures with only on-body sensor readings but no topology prior knowledge.\n    ",
        "primary_category": "cs.RO",
        "categories": [],
        "submitted_date": "28 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18677": {
        "title": "Fault Tolerant Neural Control Barrier Functions for Robotic Systems under Sensor Faults and Attacks",
        "authors": [
            "Hongchao Zhang",
            "Luyao Niu",
            "Andrew Clark",
            "Radha Poovendran"
        ],
        "comments": " ",
        "subjects": "Robotics (cs.RO)",
        "abstract": "Safety is a fundamental requirement of many robotic systems. Control barrier function (CBF)-based approaches have been proposed to guarantee the safety of robotic systems. However, the effectiveness of these approaches highly relies on the choice of CBFs. Inspired by the universal approximation power of neural networks, there is a growing trend toward representing CBFs using neural networks, leading to the notion of neural CBFs (NCBFs). Current NCBFs, however, are trained and deployed in benign environments, making them ineffective for scenarios where robotic systems experience sensor faults and attacks. In this paper, we study safety-critical control synthesis for robotic systems under sensor faults and attacks. Our main contribution is the development and synthesis of a new class of CBFs that we term fault tolerant neural control barrier function (FT-NCBF). We derive the necessary and sufficient conditions for FT-NCBFs to guarantee safety, and develop a data-driven method to learn FT-NCBFs by minimizing a loss function constructed using the derived conditions. Using the learned FT-NCBF, we synthesize a control input and formally prove the safety guarantee provided by our approach. We demonstrate our proposed approach using two case studies: obstacle avoidance problem for an autonomous mobile robot and spacecraft rendezvous problem, with code available via this https URL.\n    ",
        "primary_category": "cs.RO",
        "categories": [
            "cs.AI",
            "eess.SY"
        ],
        "submitted_date": "28 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18682": {
        "title": "Acoustic tactile sensing for mobile robot wheels",
        "authors": [
            "Wilfred Mason",
            "David Brenken",
            "Falcon Z. Dai",
            "Ricardo Gonzalo Cruz Castillo",
            "Olivier St-Martin Cormier",
            "Audrey Sedal"
        ],
        "comments": "12 pages, 12 figures",
        "subjects": "Robotics (cs.RO)",
        "abstract": "Tactile sensing in mobile robots remains under-explored, mainly due to challenges related to sensor integration and the complexities of distributed sensing. In this work, we present a tactile sensing architecture for mobile robots based on wheel-mounted acoustic waveguides. Our sensor architecture enables tactile sensing along the entire circumference of a wheel with a single active component: an off-the-shelf acoustic rangefinder. We present findings showing that our sensor, mounted on the wheel of a mobile robot, is capable of discriminating between different terrains, detecting and classifying obstacles with different geometries, and performing collision detection via contact localization. We also present a comparison between our sensor and sensors traditionally used in mobile robots, and point to the potential for sensor fusion approaches that leverage the unique capabilities of our tactile sensing architecture. Our findings demonstrate that autonomous mobile robots can further leverage our sensor architecture for diverse mapping tasks requiring knowledge of terrain material, surface topology, and underlying structure.\n    ",
        "primary_category": "cs.RO",
        "categories": [],
        "submitted_date": "28 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18683": {
        "title": "Integrated Sensing and Communication Meets Smart Propagation Engineering: Opportunities and Challenges",
        "authors": [
            "Kaitao Meng",
            "Christos Masouros",
            "Kai-Kit Wong",
            "Athina P. Petropulu",
            "Lajos Hanzo"
        ],
        "comments": "7 pages, 5 figures, submitted to IEEE journal for possible publication",
        "subjects": "Information Theory (cs.IT)",
        "abstract": "Both smart propagation engineering as well as integrated sensing and communication (ISAC) constitute promising candidates for next-generation (NG) mobile networks. We provide a synergistic view of these technologies, and explore their mutual benefits. First, moving beyond just intelligent surfaces, we provide a holistic view of the engineering aspects of smart propagation environments. By delving into the fundamental characteristics of intelligent surfaces, fluid antennas, and unmanned aerial vehicles, we reveal that more efficient control of the pathloss and fading can be achieved, thus facilitating intrinsic integration and mutual assistance between sensing and communication functionalities. In turn, with the exploitation of the sensing capabilities of ISAC to orchestrate the efficient configuration of radio environments, both the computational effort and signaling overheads can be reduced. We present indicative simulation results, which verify that cooperative smart propagation environment design significantly enhances the ISAC performance. Finally, some promising directions are outlined for combining ISAC with smart propagation engineering.\n    ",
        "primary_category": "cs.IT",
        "categories": [
            "eess.SP"
        ],
        "submitted_date": "28 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18684": {
        "title": "Quantum State Compression with Polar Codes",
        "authors": [
            "Jack Weinberg",
            "Avijit Mandal",
            "Henry D. Pfister"
        ],
        "comments": "Extended Version of ISIT 2024 Submission",
        "subjects": "Quantum Physics (quant-ph)",
        "abstract": "In the quantum compression scheme proposed by Schumacher, Alice compresses a message that Bob decompresses. In that approach, there is some probability of failure and, even when successful, some distortion of the state. For sufficiently large blocklengths, both of these imperfections can be made arbitrarily small while achieving a compression rate that asymptotically approaches the source coding bound. However, direct implementation of Schumacher compression suffers from poor circuit complexity. In this paper, we consider a slightly different approach based on classical syndrome source coding. The idea is to use a linear error-correcting code and treat the message to be compressed as an error pattern. If the message is a correctable error (i.e., a coset leader) then Alice can use the error-correcting code to convert her message to a corresponding quantum syndrome. An implementation of this based on polar codes is described and simulated. As in classical source coding based on polar codes, Alice maps the information into the ``frozen\" qubits that constitute the syndrome. To decompress, Bob utilizes a quantum version of successive cancellation coding.\n    ",
        "primary_category": "quant-ph",
        "categories": [
            "cs.IT"
        ],
        "submitted_date": "28 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18688": {
        "title": "Exploring AI Problem Formulation with Children via Teachable Machines",
        "authors": [
            "Utkarsh Dwivedi",
            "Salma Elsayed-Ali",
            "Elizabeth Bonsignore",
            "Hernisa Kacorri"
        ],
        "comments": " ",
        "subjects": "Human-Computer Interaction (cs.HC)",
        "abstract": "Emphasizing problem formulation in AI literacy activities with children is vital, yet we lack empirical studies on their structure and affordances. We propose that participatory design involving teachable machines facilitates problem formulation activities. To test this, we integrated problem reduction heuristics into storyboarding and invited a university-based intergenerational design team of 10 children (ages 8-13) and 9 adults to co-design a teachable machine. We find that children draw from personal experiences when formulating AI problems; they assume voice and video capabilities, explore diverse machine learning approaches, and plan for error handling. Their ideas promote human involvement in AI, though some are drawn to more autonomous systems. Their designs prioritize values like capability, logic, helpfulness, responsibility, and obedience, and a preference for a comfortable life, family security, inner harmony, and excitement as end-states. We conclude by discussing how these results can inform the design of future participatory AI activities.\n    ",
        "primary_category": "cs.HC",
        "categories": [],
        "submitted_date": "28 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18689": {
        "title": "The VOROS: Lifting ROC curves to 3D",
        "authors": [
            "Christopher Ratigan",
            "Lenore Cowen"
        ],
        "comments": "38 pages, 19 figures",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "The area under the ROC curve is a common measure that is often used to rank the relative performance of different binary classifiers. However, as has been also previously noted, it can be a measure that ill-captures the benefits of different classifiers when either the true class values or misclassification costs are highly unbalanced between the two classes. We introduce a third dimension to capture these costs, and lift the ROC curve to a ROC surface in a natural way. We study both this surface and introduce the VOROS, the volume over this ROC surface, as a 3D generalization of the 2D area under the ROC curve. For problems where there are only bounds on the expected costs or class imbalances, we restrict consideration to the volume of the appropriate subregion of the ROC surface. We show how the VOROS can better capture the costs of different classifiers on both a classical and a modern example dataset.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "math.MG",
            "math.ST",
            "stat.ME"
        ],
        "submitted_date": "28 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18695": {
        "title": "Grounding Language Models for Visual Entity Recognition",
        "authors": [
            "Zilin Xiao",
            "Ming Gong",
            "Paola Cascante-Bonilla",
            "Xingyao Zhang",
            "Jie Wu",
            "Vicente Ordonez"
        ],
        "comments": " ",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "We introduce AutoVER, an Autoregressive model for Visual Entity Recognition. Our model extends an autoregressive Multi-modal Large Language Model by employing retrieval augmented constrained generation. It mitigates low performance on out-of-domain entities while excelling in queries that require visually-situated reasoning. Our method learns to distinguish similar entities within a vast label space by contrastively training on hard negative pairs in parallel with a sequence-to-sequence objective without an external retriever. During inference, a list of retrieved candidate answers explicitly guides language generation by removing invalid decoding paths. The proposed method achieves significant improvements across different dataset splits in the recently proposed Oven-Wiki benchmark. Accuracy on the Entity seen split rises from 32.7% to 61.5%. It also demonstrates superior performance on the unseen and query splits by a substantial double-digit margin.\n    ",
        "primary_category": "cs.CV",
        "categories": [
            "cs.CL"
        ],
        "submitted_date": "28 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18697": {
        "title": "Inferring Dynamic Networks from Marginals with Iterative Proportional Fitting",
        "authors": [
            "Serina Chang",
            "Frederic Koehler",
            "Zhaonan Qu",
            "Jure Leskovec",
            "Johan Ugander"
        ],
        "comments": " ",
        "subjects": "Machine Learning (stat.ML)",
        "abstract": "A common network inference problem, arising from real-world data constraints, is how to infer a dynamic network from its time-aggregated adjacency matrix and time-varying marginals (i.e., row and column sums). Prior approaches to this problem have repurposed the classic iterative proportional fitting (IPF) procedure, also known as Sinkhorn's algorithm, with promising empirical results. However, the statistical foundation for using IPF has not been well understood: under what settings does IPF provide principled estimation of a dynamic network from its marginals, and how well does it estimate the network? In this work, we establish such a setting, by identifying a generative network model whose maximum likelihood estimates are recovered by IPF. Our model both reveals implicit assumptions on the use of IPF in such settings and enables new analyses, such as structure-dependent error bounds on IPF's parameter estimates. When IPF fails to converge on sparse network data, we introduce a principled algorithm that guarantees IPF converges under minimal changes to the network structure. Finally, we conduct experiments with synthetic and real-world data, which demonstrate the practical value of our theoretical and algorithmic contributions.\n    ",
        "primary_category": "stat.ML",
        "categories": [
            "cs.LG",
            "cs.SI",
            "math.OC",
            "math.ST"
        ],
        "submitted_date": "28 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18698": {
        "title": "Spatial Coherence Loss for Salient and Camouflaged Object Detection and Beyond",
        "authors": [
            "Ziyun Yang",
            "Kevin Choy",
            "Sina Farsiu"
        ],
        "comments": " ",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Generic object detection is a category-independent task that relies on accurate modeling of objectness. Most relevant CNN-based models of objectness utilize loss functions (e.g., binary cross entropy) that focus on the single-response, i.e., the loss response of a single pixel. Inspired by the human visual system, which first discerns the boundaries of ambiguous regions (i.e., hard regions) before delving into the semantic meaning, we propose a novel loss function, Spatial Coherence Loss (SCLoss), that uses the mutual response between adjacent pixels to suppress or emphasize the single-response of pixels. We demonstrate that the proposed SCLoss can gradually learn the hard regions by detecting and emphasizing their boundaries. Through comprehensive experiments, we demonstrate that replacing popular loss functions with SCLoss can improve the performance of current state-of-the-art (SOTA) salient or camouflaged object detection (SOD or COD) models. We also demonstrate that combining SCLoss with other loss functions can further improve performance and result in the SOTA outcomes for different applications. Finally, as a demonstrative example of the potential uses for other related tasks, we show an application of SCLoss for semantic segmentation.\n    ",
        "primary_category": "cs.CV",
        "categories": [],
        "submitted_date": "28 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18702": {
        "title": "Characterizing Multimedia Information Environment through Multi-modal Clustering of YouTube Videos",
        "authors": [
            "Niloofar Yousefi",
            "Mainuddin Shaik",
            "Nitin Agarwal"
        ],
        "comments": "14 pages, In the 4th International Conference on SMART MULTIMEDIA, 2024",
        "subjects": "Multimedia (cs.MM)",
        "abstract": "This study aims to investigate the comprehensive characterization of information content in multimedia (videos), particularly on YouTube. The research presents a multi-method framework for characterizing multimedia content by clustering signals from various modalities, such as audio, video, and text. With a focus on South China Sea videos as a case study, this approach aims to enhance our understanding of online content, especially on YouTube. The dataset includes 160 videos, and our findings offer insights into content themes and patterns within different modalities of a video based on clusters. Text modality analysis revealed topical themes related to geopolitical countries, strategies, and global security, while video and audio modality analysis identified distinct patterns of signals related to diverse sets of videos, including news analysis/reporting, educational content, and interviews. Furthermore, our findings uncover instances of content repurposing within video clusters, which were identified using the barcode technique and audio similarity assessments. These findings indicate potential content amplification techniques. In conclusion, this study uniquely enhances our current understanding of multimedia content information based on modality clustering techniques.\n    ",
        "primary_category": "cs.MM",
        "categories": [],
        "submitted_date": "28 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18703": {
        "title": "Zero-error communication, scrambling, and ergodicity",
        "authors": [
            "Satvik Singh",
            "Mizanur Rahaman",
            "Nilanjana Datta"
        ],
        "comments": "Preliminary version. Comments are welcome",
        "subjects": "Quantum Physics (quant-ph)",
        "abstract": "The long term behaviour of a quantum channel under iterations (i.e. under repeated applications of itself) yields a plethora of interesting properties. These include ergodicity, mixing, eventual scrambling, becoming strictly positive, and the vanishing of its one-shot zero error capacities. We derive relations between these seemingly different properties and find novel bounds on indices which quantify the minimum number of iterations needed for the onset of some of these properties. We obtain a lower bound on the one-shot zero-error classical capacity of $n$ iterations of an ergodic channel (for any positive integer $n$) in terms of the cardinality of its peripheral spectrum. We also find upper bounds on the minimum number of iterations needed for the one-shot capacities of any channel to stabilize. We consider two classes of quantum channels, satisfying certain symmetries, for which upper bounds on the above indices are optimal, since they reduce to the corresponding indices for a stochastic matrix (for which the bounds are known to be optimal). As an auxiliary result, we obtain a trade-off relation between the one-shot zero error classical and quantum capacities of a quantum channel.\n    ",
        "primary_category": "quant-ph",
        "categories": [
            "cs.IT",
            "math.OA",
            "math.PR"
        ],
        "submitted_date": "28 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18707": {
        "title": "Embodied Supervision: Haptic Display of Automation Command to Improve Supervisory Performance",
        "authors": [
            "Alia Gilbert",
            "Sachit Krishnan",
            "R. Brent Gillespie"
        ],
        "comments": "IEEE Haptics Symposium 2024",
        "subjects": "Human-Computer Interaction (cs.HC)",
        "abstract": "A human operator using a manual control interface has ready access to their own command signal, both by efference copy and proprioception. In contrast, a human supervisor typically relies on visual information alone. We propose supplying a supervisor with a copy of the operators command signal, hypothesizing improved performance, especially when that copy is provided through haptic display. We experimentally compared haptic with visual access to the command signal, quantifying the performance of N equals 10 participants attempting to determine which of three reference signals was being tracked by an operator. Results indicate an improved accuracy in identifying the tracked target when haptic display was available relative to visual display alone. We conjecture the benefit follows from the relationship of haptics to the supervisor's own experience, perhaps muscle memory, as an operator.\n    ",
        "primary_category": "cs.HC",
        "categories": [
            "cs.RO"
        ],
        "submitted_date": "28 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18708": {
        "title": "Bluebell: An Alliance of Relational Lifting and Independence For Probabilistic Reasoning",
        "authors": [
            "Jialu Bao",
            "Emanuele D'Osualdo",
            "Azadeh Farzan"
        ],
        "comments": "23 pages + 53 pages of appendix",
        "subjects": "Logic in Computer Science (cs.LO)",
        "abstract": "We present Bluebell, a program logic for reasoning about probabilistic programs where unary and relational styles of reasoning come together to create new reasoning tools. Unary-style reasoning is very expressive and is powered by foundational mechanisms to reason about probabilistic behaviour like independence and conditioning. The relational style of reasoning, on the other hand, naturally shines when the properties of interest compare the behaviour of similar programs (e.g. when proving differential privacy) managing to avoid having to characterize the output distributions of the individual programs. So far, the two styles of reasoning have largely remained separate in the many program logics designed for the deductive verification of probabilistic programs. In Bluebell, we unify these styles of reasoning through the introduction of a new modality called \"joint conditioning\" that can encode and illuminate the rich interaction between conditional independence and relational liftings; the two powerhouses from the two styles of reasoning.\n    ",
        "primary_category": "cs.LO",
        "categories": [
            "cs.PL"
        ],
        "submitted_date": "28 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18709": {
        "title": "Nonlinear identification algorithm for online and offline study of pulmonary mechanical ventilation",
        "authors": [
            "Diego A. Riva",
            "Carolina A. Evangelista",
            "Paul F. Puleston",
            "Luis Corsiglia",
            "Nahuel Dargains"
        ],
        "comments": " ",
        "subjects": "Systems and Control (eess.SY)",
        "abstract": "This work presents an algorithm for determining the parameters of a nonlinear dynamic model of the respiratory system in patients undergoing assisted ventilation. Using the pressure and flow signals measured at the mouth, the model's quadratic pressure-volume characteristic is fit to this data in each respiratory cycle by appropriate estimates of the model parameters. Parameter changes during ventilation can thus also be detected. The algorithm is first refined and assessed using data derived from simulated patients represented through a sigmoidal pressure-volume characteristic with hysteresis. As satisfactory results are achieved with the simulated data, the algorithm is evaluated with real data obtained from actual patients undergoing assisted ventilation. The proposed nonlinear dynamic model and associated parameter estimation algorithm yield closer fits than the static linear models computed by respiratory machines, with only a minor increase in computation. They also provide more information to the physician, such as the pressure-volume (P-V) curvature and the condition of the lung (whether normal, under-inflated, or over-inflated). This information can be used to provide safer ventilation for patients, for instance by ventilating them in the linear region of the respiratory system.\n    ",
        "primary_category": "eess.SY",
        "categories": [
            "physics.med-ph"
        ],
        "submitted_date": "28 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18710": {
        "title": "Hefty: A Modular Reconfigurable Robot for Advancing Robot Manipulation in Agriculture",
        "authors": [
            "Dominic Guri",
            "Moonyoung Lee",
            "Oliver Kroemer",
            "George Kantor"
        ],
        "comments": "8 pages, 11 figures",
        "subjects": "Robotics (cs.RO)",
        "abstract": "This paper presents a modular, reconfigurable robot platform for robot manipulation in agriculture. While robot manipulation promises great advancements in automating challenging, complex tasks that are currently best left to humans, it is also an expensive capital investment for researchers and users because it demands significantly varying robot configurations depending on the task. Modular robots provide a way to obtain multiple configurations and reduce costs by enabling incremental acquisition of only the necessary modules. The robot we present, Hefty, is designed to be modular and reconfigurable. It is designed for both researchers and end-users as a means to improve technology transfer from research to real-world application. This paper provides a detailed design and integration process, outlining the critical design decisions that enable modularity in the mobility of the robot as well as its sensor payload, power systems, computing, and fixture mounting. We demonstrate the utility of the robot by presenting five configurations used in multiple real-world agricultural robotics applications.\n    ",
        "primary_category": "cs.RO",
        "categories": [],
        "submitted_date": "28 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18715": {
        "title": "Commonsense Ontology Micropatterns",
        "authors": [
            "Andrew Eells",
            "Brandon Dave",
            "Pascal Hitzler",
            "Cogan Shimizu"
        ],
        "comments": " ",
        "subjects": "Artificial Intelligence (cs.AI)",
        "abstract": "The previously introduced Modular Ontology Modeling methodology (MOMo) attempts to mimic the human analogical process by using modular patterns to assemble more complex concepts. To support this, MOMo organizes organizes ontology design patterns into design libraries, which are programmatically queryable, to support accelerated ontology development, for both human and automated processes. However, a major bottleneck to large-scale deployment of MOMo is the (to-date) limited availability of ready-to-use ontology design patterns. At the same time, Large Language Models have quickly become a source of common knowledge and, in some cases, replacing search engines for questions. In this paper, we thus present a collection of 104 ontology design patterns representing often occurring nouns, curated from the common-sense knowledge available in LLMs, organized into a fully-annotated modular ontology design library ready for use with MOMo.\n    ",
        "primary_category": "cs.AI",
        "categories": [
            "cs.LO"
        ],
        "submitted_date": "28 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18718": {
        "title": "Model Pairing Using Embedding Translation for Backdoor Attack Detection on Open-Set Classification Tasks",
        "authors": [
            "Alexander Unnervik",
            "Hatef Otroshi Shahreza",
            "Anjith George",
            "S\u00e9bastien Marcel"
        ],
        "comments": "Under review",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Backdoor attacks allow an attacker to embed a specific vulnerability in a machine learning algorithm, activated when an attacker-chosen pattern is presented, causing a specific misprediction. The need to identify backdoors in biometric scenarios has led us to propose a novel technique with different trade-offs. In this paper we propose to use model pairs on open-set classification tasks for detecting backdoors. Using a simple linear operation to project embeddings from a probe model's embedding space to a reference model's embedding space, we can compare both embeddings and compute a similarity score. We show that this score, can be an indicator for the presence of a backdoor despite models being of different architectures, having been trained independently and on different datasets. Additionally, we show that backdoors can be detected even when both models are backdoored. The source code is made available for reproducibility purposes.\n    ",
        "primary_category": "cs.CV",
        "categories": [
            "cs.CR"
        ],
        "submitted_date": "28 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18719": {
        "title": "MaxCUCL: Max-Consensus with Deterministic Convergence in Networks with Unreliable Communication",
        "authors": [
            "Apostolos I. Rikos",
            "Themistoklis Charalambous",
            "Karl H. Johansson"
        ],
        "comments": " ",
        "subjects": "Systems and Control (eess.SY)",
        "abstract": "In this paper, we present a novel distributed algorithm (herein called MaxCUCL) designed to guarantee that max-consensus is reached in networks characterized by unreliable communication links (i.e., links suffering from packet drops). Our proposed algorithm is the first algorithm that achieves max-consensus in a deterministic manner (i.e., nodes always calculate the maximum of their states regardless of the nature of the probability distribution of the packet drops). Furthermore, it allows nodes to determine whether convergence has been achieved (enabling them to transition to subsequent tasks). The operation of MaxCUCL relies on the deployment of narrowband error-free feedback channels used for acknowledging whether a packet transmission between nodes was successful. We analyze the operation of our algorithm and show that it converges after a finite number of time steps. Finally, we demonstrate our algorithm's effectiveness and practical applicability by applying it to a sensor network deployed for environmental monitoring.\n    ",
        "primary_category": "eess.SY",
        "categories": [],
        "submitted_date": "28 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18721": {
        "title": "A collocation method for nonlinear tensor differential equations on low-rank manifolds",
        "authors": [
            "Alec Dektor"
        ],
        "comments": "19 pages, 4 figures",
        "subjects": "Numerical Analysis (math.NA)",
        "abstract": "We present a new method to compute the solution to a nonlinear tensor differential equation with dynamical low-rank approximation. The idea of dynamical low-rank approximation is to project the differential equation onto the tangent space of a low-rank tensor manifold at each time. Traditionally, an orthogonal projection onto the tangent space is employed, which is challenging to compute for nonlinear differential equations. We introduce a novel interpolatory projection onto the tangent space that is easily computed for many nonlinear differential equations and satisfies the differential equation at a set of carefully selected indices. To select these indices, we devise a new algorithm based on the discrete empirical interpolation method (DEIM) that parameterizes any tensor train and its tangent space with tensor cross interpolants. We demonstrate the proposed method with applications to tensor differential equations arising from the discretization of partial differential equations.\n    ",
        "primary_category": "math.NA",
        "categories": [
            "physics.comp-ph"
        ],
        "submitted_date": "28 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18724": {
        "title": "Learning Associative Memories with Gradient Descent",
        "authors": [
            "Vivien Cabannes",
            "Berfin Simsek",
            "Alberto Bietti"
        ],
        "comments": " ",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "This work focuses on the training dynamics of one associative memory module storing outer products of token embeddings. We reduce this problem to the study of a system of particles, which interact according to properties of the data distribution and correlations between embeddings. Through theory and experiments, we provide several insights. In overparameterized regimes, we obtain logarithmic growth of the ``classification margins.'' Yet, we show that imbalance in token frequencies and memory interferences due to correlated embeddings lead to oscillatory transitory regimes. The oscillations are more pronounced with large step sizes, which can create benign loss spikes, although these learning rates speed up the dynamics and accelerate the asymptotic convergence. In underparameterized regimes, we illustrate how the cross-entropy loss can lead to suboptimal memorization schemes. Finally, we assess the validity of our findings on small Transformer models.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.AI",
            "stat.ML"
        ],
        "submitted_date": "28 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18726": {
        "title": "Unveiling Privacy, Memorization, and Input Curvature Links",
        "authors": [
            "Deepak Ravikumar",
            "Efstathia Soufleri",
            "Abolfazl Hashemi",
            "Kaushik Roy"
        ],
        "comments": " ",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Deep Neural Nets (DNNs) have become a pervasive tool for solving many emerging problems. However, they tend to overfit to and memorize the training set. Memorization is of keen interest since it is closely related to several concepts such as generalization, noisy learning, and privacy. To study memorization, Feldman (2019) proposed a formal score, however its computational requirements limit its practical use. Recent research has shown empirical evidence linking input loss curvature (measured by the trace of the loss Hessian w.r.t inputs) and memorization. It was shown to be ~3 orders of magnitude more efficient than calculating the memorization score. However, there is a lack of theoretical understanding linking memorization with input loss curvature. In this paper, we not only investigate this connection but also extend our analysis to establish theoretical links between differential privacy, memorization, and input loss curvature. First, we derive an upper bound on memorization characterized by both differential privacy and input loss curvature. Second, we present a novel insight showing that input loss curvature is upper-bounded by the differential privacy parameter. Our theoretical findings are further empirically validated using deep models on CIFAR and ImageNet datasets, showing a strong correlation between our theoretical predictions and results observed in practice.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.AI",
            "cs.CR"
        ],
        "submitted_date": "28 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18728": {
        "title": "Not All the Same: Understanding and Informing Similarity Estimation in Tile-Based Video Games",
        "authors": [
            "Sebastian Berns",
            "Vanessa Volz",
            "Laurissa Tokarchuk",
            "Sam Snodgrass",
            "Christian Guckelsberger"
        ],
        "comments": "Proceedings of the CHI Conference on Human Factors in Computing Systems (CHI '24), 11-16 May 2024, Honolulu, HI, USA",
        "subjects": "Human-Computer Interaction (cs.HC)",
        "abstract": "Similarity estimation is essential for many game AI applications, from the procedural generation of distinct assets to automated exploration with game-playing agents. While similarity metrics often substitute human evaluation, their alignment with our judgement is unclear. Consequently, the result of their application can fail human expectations, leading to e.g. unappreciated content or unbelievable agent behaviour. We alleviate this gap through a multi-factorial study of two tile-based games in two representations, where participants (N=456) judged the similarity of level triplets. Based on this data, we construct domain-specific perceptual spaces, encoding similarity-relevant attributes. We compare 12 metrics to these spaces and evaluate their approximation quality through several quantitative lenses. Moreover, we conduct a qualitative labelling study to identify the features underlying the human similarity judgement in this popular genre. Our findings inform the selection of existing metrics and highlight requirements for the design of new similarity metrics benefiting game development and research.\n    ",
        "primary_category": "cs.HC",
        "categories": [],
        "submitted_date": "28 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18729": {
        "title": "A Priori Uncertainty Quantification of Reacting Turbulence Closure Models using Bayesian Neural Networks",
        "authors": [
            "Graham Pash",
            "Malik Hassanaly",
            "Shashank Yellapantula"
        ],
        "comments": " ",
        "subjects": "Fluid Dynamics (physics.flu-dyn)",
        "abstract": "While many physics-based closure model forms have been posited for the sub-filter scale (SFS) in large eddy simulation (LES), vast amounts of data available from direct numerical simulation (DNS) create opportunities to leverage data-driven modeling techniques. Albeit flexible, data-driven models still depend on the dataset and the functional form of the model chosen. Increased adoption of such models requires reliable uncertainty estimates both in the data-informed and out-of-distribution regimes. In this work, we employ Bayesian neural networks (BNNs) to capture both epistemic and aleatoric uncertainties in a reacting flow model. In particular, we model the filtered progress variable scalar dissipation rate which plays a key role in the dynamics of turbulent premixed flames. We demonstrate that BNN models can provide unique insights about the structure of uncertainty of the data-driven closure models. We also propose a method for the incorporation of out-of-distribution information in a BNN. The efficacy of the model is demonstrated by a priori evaluation on a dataset consisting of a variety of flame conditions and fuels.\n    ",
        "primary_category": "physics.flu-dyn",
        "categories": [
            "cs.LG",
            "physics.data-an"
        ],
        "submitted_date": "28 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18732": {
        "title": "GAIA: Categorical Foundations of Generative AI",
        "authors": [
            "Sridhar Mahadevan"
        ],
        "comments": "65 pages. arXiv admin note: text overlap with arXiv:2212.08981",
        "subjects": "Artificial Intelligence (cs.AI)",
        "abstract": "In this paper, we propose GAIA, a generative AI architecture based on category theory. GAIA is based on a hierarchical model where modules are organized as a simplicial complex. Each simplicial complex updates its internal parameters biased on information it receives from its superior simplices and in turn relays updates to its subordinate sub-simplices. Parameter updates are formulated in terms of lifting diagrams over simplicial sets, where inner and outer horn extensions correspond to different types of learning problems. Backpropagation is modeled as an endofunctor over the category of parameters, leading to a coalgebraic formulation of deep learning.\n    ",
        "primary_category": "cs.AI",
        "categories": [
            "cs.LG"
        ],
        "submitted_date": "28 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18734": {
        "title": "Priority Sampling of Large Language Models for Compilers",
        "authors": [
            "Dejan Grubisic",
            "Chris Cummins",
            "Volker Seeker",
            "Hugh Leather"
        ],
        "comments": " ",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Large language models show great potential in generating and optimizing code. Widely used sampling methods such as Nucleus Sampling increase the diversity of generation but often produce repeated samples for low temperatures and incoherent samples for high temperatures. Furthermore, the temperature coefficient has to be tuned for each task, limiting its usability. We present Priority Sampling, a simple and deterministic sampling technique that produces unique samples ordered by the model's confidence. Each new sample expands the unexpanded token with the highest probability in the augmented search tree. Additionally, Priority Sampling supports generation based on regular expression that provides a controllable and structured exploration process. Priority Sampling outperforms Nucleus Sampling for any number of samples, boosting the performance of the original model from 2.87% to 5% improvement over -Oz. Moreover, it outperforms the autotuner used for the generation of labels for the training of the original model in just 30 samples.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.CL",
            "cs.PF"
        ],
        "submitted_date": "28 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18740": {
        "title": "Sixth-order parabolic equation on an interval: Eigenfunction expansion, Green's function, and intermediate asymptotics for a finite thin film with elastic resistance",
        "authors": [
            "Nectarios C. Papanicolaou",
            "Ivan C. Christov"
        ],
        "comments": "20 pages, 6 figures",
        "subjects": "Numerical Analysis (math.NA)",
        "abstract": "A linear sixth-order partial differential equation (PDE) of ``parabolic'' type describes the dynamics of thin liquid films beneath surfaces with elastic bending resistance when deflections from the equilibrium film height are small. On a finite domain, the associated sixth-order Sturm--Liouville eigenvalue value problem is self-adjoint for the boundary conditions corresponding to a thin film in a closed trough, and the eigenfunctions form a complete orthonormal set. Using these eigenfunctions, we derive the Green's function for the governing sixth-order PDE on a finite interval and compare it to the known infinite-line solution. Further, we propose a Galerkin spectral method based on the constructed sixth-order eigenfunctions and their derivative expansions. The system of ordinary differential equations for the time-dependent expansion coefficients is solved by standard numerical methods. The numerical approach is applied to versions of the governing PDE with a second-order derivative (in addition to the sixth-order one), which arises from gravity acting on the film. In the absence of gravity, we demonstrate the self-similar intermediate asymptotics of initially localized disturbances on the film surface, at least until the disturbances ``feel'' the finite boundaries, and show that the derived Green's function is the global attractor for such solutions. In the presence of gravity, we use the proposed spectral numerical method to demonstrate that self-similar behavior persists, albeit for shortened intervals of time, even for large values of the gravity-to-bending ratio.\n    ",
        "primary_category": "math.NA",
        "categories": [
            "physics.flu-dyn"
        ],
        "submitted_date": "28 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18742": {
        "title": "Comparing Importance Sampling Based Methods for Mitigating the Effect of Class Imbalance",
        "authors": [
            "Indu Panigrahi",
            "Richard Zhu"
        ],
        "comments": "Preprint",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Most state-of-the-art computer vision models heavily depend on data. However, many datasets exhibit extreme class imbalance which has been shown to negatively impact model performance. Among the training-time and data-generation solutions that have been explored, one subset that leverages existing data is importance sampling. A good deal of this work focuses primarily on the CIFAR-10 and CIFAR-100 datasets which fail to be representative of the scale, composition, and complexity of current state-of-the-art datasets. In this work, we explore and compare three techniques that derive from importance sampling: loss reweighting, undersampling, and oversampling. Specifically, we compare the effect of these techniques on the performance of two encoders on an impactful satellite imagery dataset, Planet's Amazon Rainforest dataset, in preparation for another work. Furthermore, we perform supplemental experimentation on a scene classification dataset, ADE20K, to test on a contrasting domain and clarify our results. Across both types of encoders, we find that up-weighting the loss for and undersampling has a negigible effect on the performance on underrepresented classes. Additionally, our results suggest oversampling generally improves performance for the same underrepresented classes. Interestingly, our findings also indicate that there may exist some redundancy in data in the Planet dataset. Our work aims to provide a foundation for further work on the Planet dataset and similar domain-specific datasets. We open-source our code at this https URL for future work on other satellite imagery datasets as well.\n    ",
        "primary_category": "cs.CV",
        "categories": [],
        "submitted_date": "28 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18743": {
        "title": "A revision on Multi-Criteria Decision Making methods for Multi-UAV Mission Planning Support",
        "authors": [
            "Cristian Ramirez-Atencia",
            "Victor Rodriguez-Fernandez",
            "David Camacho"
        ],
        "comments": "Preprint submitted and acepted in Expert Systems with Applications",
        "subjects": "Artificial Intelligence (cs.AI)",
        "abstract": "Over the last decade, Unmanned Aerial Vehicles (UAVs) have been extensively used in many commercial applications due to their manageability and risk avoidance. One of the main problems considered is the Mission Planning for multiple UAVs, where a solution plan must be found satisfying the different constraints of the problem. This problem has multiple variables that must be optimized simultaneously, such as the makespan, the cost of the mission or the risk. Therefore, the problem has a lot of possible optimal solutions, and the operator must select the final solution to be executed among them. In order to reduce the workload of the operator in this decision process, a Decision Support System (DSS) becomes necessary. In this work, a DSS consisting of ranking and filtering systems, which order and reduce the optimal solutions, has been designed. With regard to the ranking system, a wide range of Multi-Criteria Decision Making (MCDM) methods, including some fuzzy MCDM, are compared on a multi-UAV mission planning scenario, in order to study which method could fit better in a multi-UAV decision support system. Expert operators have evaluated the solutions returned, and the results show, on the one hand, that fuzzy methods generally achieve better average scores, and on the other, that all of the tested methods perform better when the preferences of the operators are biased towards a specific variable, and worse when their preferences are balanced. For the filtering system, a similarity function based on the proximity of the solutions has been designed, and on top of that, a threshold is tuned empirically to decide how to filter solutions without losing much of the hypervolume of the space of solutions.\n    ",
        "primary_category": "cs.AI",
        "categories": [
            "cs.RO"
        ],
        "submitted_date": "28 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18744": {
        "title": "Timer-Based Coverage Control for Mobile Sensors",
        "authors": [
            "Federico M. Zegers",
            "Sean Phillips",
            "Gregory P. Hicks"
        ],
        "comments": " ",
        "subjects": "Systems and Control (eess.SY)",
        "abstract": "This work studies the coverage control problem over a static, bounded, and convex workspace and develops a hybrid extension of the continuous-time Lloyd algorithm. Each agent in a multi-agent system (MAS) is equipped with a timer that generates intermittent sampling events, which may occur asynchronously between agents. At each sampling event, the corresponding agents update their controllers, which are otherwise held constant. These controllers are shown to drive the MAS into a neighborhood of the configurations corresponding to a centroidal Voronoi tessellation, that is, a local minimizer of the standard locational cost. The result is a distributed control strategy that leverages intermittent and asynchronous position measurements to disperse the agents within the workspace. The combination of continuous-time dynamics with intermittently updated control inputs is modeled as a hybrid system. The coverage control objective is posed as a set stabilization problem for hybrid systems, where an invariance based convergence analysis yields sufficient conditions that ensure all maximal solutions of the hybrid system asymptotically converge to a desired set. A brief simulation example is included to showcase the result.\n    ",
        "primary_category": "eess.SY",
        "categories": [],
        "submitted_date": "28 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18746": {
        "title": "Accelerating Computer Architecture Simulation through Machine Learning",
        "authors": [
            "Wajid Ali",
            "Ayaz Akram"
        ],
        "comments": " ",
        "subjects": "Hardware Architecture (cs.AR)",
        "abstract": "This paper presents our approach to accelerate computer architecture simulation by leveraging machine learning techniques. Traditional computer architecture simulations are time-consuming, making it challenging to explore different design choices efficiently. Our proposed model utilizes a combination of application features and micro-architectural features to predict the performance of an application. These features are derived from simulations of a small portion of the application. We demonstrate the effectiveness of our approach by building and evaluating a machine learning model that offers significant speedup in architectural exploration. This model demonstrates the ability to predict IPC values for the testing data with a root mean square error of less than 0.1.\n    ",
        "primary_category": "cs.AR",
        "categories": [
            "cs.LG"
        ],
        "submitted_date": "28 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18747": {
        "title": "Fine-Tuned Machine Translation Metrics Struggle in Unseen Domains",
        "authors": [
            "Vil\u00e9m Zouhar",
            "Shuoyang Ding",
            "Anna Currey",
            "Tatyana Badeka",
            "Jenyuan Wang",
            "Brian Thompson"
        ],
        "comments": " ",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "We introduce a new, extensive multidimensional quality metrics (MQM) annotated dataset covering 11 language pairs in the biomedical domain. We use this dataset to investigate whether machine translation (MT) metrics which are fine-tuned on human-generated MT quality judgements are robust to domain shifts between training and inference. We find that fine-tuned metrics exhibit a substantial performance drop in the unseen domain scenario relative to metrics that rely on the surface form, as well as pre-trained metrics which are not fine-tuned on MT quality judgments.\n    ",
        "primary_category": "cs.CL",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "28 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18749": {
        "title": "Weighted strategies to guide a multi-objective evolutionary algorithm for multi-UAV mission planning",
        "authors": [
            "Cristian Ramirez-Atencia",
            "Javier Del Ser",
            "David Camacho"
        ],
        "comments": "Preprint submitted and accepted in Swarm and Evolutionary Computation",
        "subjects": "Neural and Evolutionary Computing (cs.NE)",
        "abstract": "Management and mission planning over a swarm of unmanned aerial vehicle (UAV) remains to date as a challenging research trend in what regards to this particular type of aircrafts. These vehicles are controlled by a number of ground control station (GCS), from which they are commanded to cooperatively perform different tasks in specific geographic areas of interest. Mathematically the problem of coordinating and assigning tasks to a swarm of UAV can be modeled as a constraint satisfaction problem, whose complexity and multiple conflicting criteria has hitherto motivated the adoption of multi-objective solvers such as multi-objective evolutionary algorithm (MOEA). The encoding approach consists of different alleles representing the decision variables, whereas the fitness function checks that all constraints are fulfilled, minimizing the optimization criteria of the problem. In problems of high complexity involving several tasks, UAV and GCS, where the space of search is huge compared to the space of valid solutions, the convergence rate of the algorithm increases significantly. To overcome this issue, this work proposes a weighted random generator for the creation and mutation of new individuals. The main objective of this work is to reduce the convergence rate of the MOEA solver for multi-UAV mission planning using weighted random strategies that focus the search on potentially better regions of the solution space. Extensive experimental results over a diverse range of scenarios evince the benefits of the proposed approach, which notably improves this convergence rate with respect to a na\u00efve MOEA approach.\n    ",
        "primary_category": "cs.NE",
        "categories": [],
        "submitted_date": "28 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18751": {
        "title": "Multi-Sensor and Multi-temporal High-Throughput Phenotyping for Monitoring and Early Detection of Water-Limiting Stress in Soybean",
        "authors": [
            "Sarah E. Jones",
            "Timilehin Ayanlade",
            "Benjamin Fallen",
            "Talukder Z. Jubery",
            "Arti Singh",
            "Baskar Ganapathysubramanian",
            "Soumik Sarkar",
            "Asheesh K. Singh"
        ],
        "comments": "25 pages, 5 figures",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Soybean production is susceptible to biotic and abiotic stresses, exacerbated by extreme weather events. Water limiting stress, i.e. drought, emerges as a significant risk for soybean production, underscoring the need for advancements in stress monitoring for crop breeding and production. This project combines multi-modal information to identify the most effective and efficient automated methods to investigate drought response. We investigated a set of diverse soybean accessions using multiple sensors in a time series high-throughput phenotyping manner to: (1) develop a pipeline for rapid classification of soybean drought stress symptoms, and (2) investigate methods for early detection of drought stress. We utilized high-throughput time-series phenotyping using UAVs and sensors in conjunction with machine learning (ML) analytics, which offered a swift and efficient means of phenotyping. The red-edge and green bands were most effective to classify canopy wilting stress. The Red-Edge Chlorophyll Vegetation Index (RECI) successfully differentiated susceptible and tolerant soybean accessions prior to visual symptom development. We report pre-visual detection of soybean wilting using a combination of different vegetation indices. These results can contribute to early stress detection methodologies and rapid classification of drought responses in screening nurseries for breeding and production applications.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.CV"
        ],
        "submitted_date": "28 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18752": {
        "title": "Pre-training Differentially Private Models with Limited Public Data",
        "authors": [
            "Zhiqi Bu",
            "Xinwei Zhang",
            "Mingyi Hong",
            "Sheng Zha",
            "George Karypis"
        ],
        "comments": " ",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "The superior performance of large foundation models relies on the use of massive amounts of high-quality data, which often contain sensitive, private and copyrighted material that requires formal protection. While differential privacy (DP) is a prominent method to gauge the degree of security provided to the models, its application is commonly limited to the model fine-tuning stage, due to the performance degradation when applying DP during the pre-training stage. Consequently, DP is yet not capable of protecting a substantial portion of the data used during the initial pre-training process.\nIn this work, we first provide a theoretical understanding of the efficacy of DP training by analyzing the per-iteration loss improvement. We make a key observation that DP optimizers' performance degradation can be significantly mitigated by the use of limited public data, which leads to a novel DP continual pre-training strategy. Empirically, using only 10\\% of public data, our strategy can achieve DP accuracy of 41.5\\% on ImageNet-21k (with $\\epsilon=8$), as well as non-DP accuracy of 55.7\\% and and 60.0\\% on downstream tasks Places365 and iNaturalist-2021, respectively, on par with state-of-the-art standard pre-training and substantially outperforming existing DP pre-trained models.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.CR"
        ],
        "submitted_date": "28 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18753": {
        "title": "Like-minded, like-bodied: How users (18-26) trust online eating and health information",
        "authors": [
            "Rachel Xu",
            "Nhu Le",
            "Rebekah Park",
            "Laura Murray"
        ],
        "comments": "10 pages",
        "subjects": "Human-Computer Interaction (cs.HC)",
        "abstract": "This paper investigates the relationship between social media and eating practices amongst 42 internet users aged 18-26. We conducted an ethnography in the US and India to observe how they navigated eating and health information online. We found that participants portrayed themselves online through a vocabulary we have labeled \"the good life\": performing holistic health by displaying a socially-ideal body. In doing so, participants unconsciously engaged in behaviors of disordered eating while actively eschewing them. They also valued personal testimonies, and readily tested tips from content creators who shared similar beliefs and bodies to them. In doing so, they discarded probabilistic thinking and opened themselves to harm. Our study found that their social media feeds did not unidirectionally influence participants - they also reflected participants' internalized views of health, in an intertwined, non-linear journey. Reducing the online spread of disordered eating practices requires addressing it within young people's social context.\n    ",
        "primary_category": "cs.HC",
        "categories": [
            "cs.CY",
            "cs.SI"
        ],
        "submitted_date": "28 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18754": {
        "title": "Extending QGroundControl for Automated Mission Planning of UAVs",
        "authors": [
            "Cristian Ramirez-Atencia",
            "David Camacho"
        ],
        "comments": "Preprint submitted and accepted in Sensors",
        "subjects": "Robotics (cs.RO)",
        "abstract": "Unmanned Aerial Vehicle (UAVs) have become very popular in the last decade due to some advantages such as strong terrain adaptation, low cost, zero casualties, and so on. One of the most interesting advances in this field is the automation of mission planning (task allocation) and real-time replanning, which are highly useful to increase the autonomy of the vehicle and reduce the operator workload. These automated mission planning and replanning systems require a Human Computer Interface (HCI) that facilitates the visualization and selection of plans that will be executed by the vehicles. In addition, most missions should be assessed before their real-life execution. This paper extends QGroundControl, an open-source simulation environment for flight control of multiple vehicles, by adding a mission designer that permits the operator to build complex missions with tasks and other scenario items; an interface for automated mission planning and replanning, which works as a test bed for different algorithms, and a Decision Support System (DSS) that helps the operator in the selection of the plan. In this work, a complete guide of these systems and some practical use cases are provided.\n    ",
        "primary_category": "cs.RO",
        "categories": [
            "cs.HC"
        ],
        "submitted_date": "28 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18755": {
        "title": "On Defeating Graph Analysis of Anonymous Transactions",
        "authors": [
            "Christoph Egger",
            "Russell W. F. Lai",
            "Viktoria Ronge",
            "Ivy K. Y. Woo",
            "Hoover H. F. Yin"
        ],
        "comments": " ",
        "subjects": "Cryptography and Security (cs.CR)",
        "abstract": "In a ring-signature-based anonymous cryptocurrency, signers of a transaction are hidden among a set of potential signers, called a ring, whose size is much smaller than the number of all users. The ring-membership relations specified by the sets of transactions thus induce bipartite transaction graphs, whose distribution is in turn induced by the ring sampler underlying the cryptocurrency.\nSince efficient graph analysis could be performed on transaction graphs to potentially deanonymise signers, it is crucial to understand the resistance of (the transaction graphs induced by) a ring sampler against graph analysis. Of particular interest is the class of partitioning ring samplers. Although previous works showed that they provide almost optimal local anonymity, their resistance against global, e.g. graph-based, attacks were unclear.\nIn this work, we analyse transaction graphs induced by partitioning ring samplers. Specifically, we show (partly analytically and partly empirically) that, somewhat surprisingly, by setting the ring size to be at least logarithmic in the number of users, a graph-analysing adversary is no better than the one that performs random guessing in deanonymisation up to constant factor of 2.\n    ",
        "primary_category": "cs.CR",
        "categories": [],
        "submitted_date": "28 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18756": {
        "title": "How Much Annotation is Needed to Compare Summarization Models?",
        "authors": [
            "Chantal Shaib",
            "Joe Barrow",
            "Alexa F. Siu",
            "Byron C. Wallace",
            "Ani Nenkova"
        ],
        "comments": "Preprint",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "Modern instruction-tuned models have become highly capable in text generation tasks such as summarization, and are expected to be released at a steady pace. In practice one may now wish to choose confidently, but with minimal effort, the best performing summarization model when applied to a new domain or purpose. In this work, we empirically investigate the test sample size necessary to select a preferred model in the context of news summarization. Empirical results reveal that comparative evaluation converges quickly for both automatic and human evaluation, with clear preferences for a system emerging from under 100 examples. The human preference data allows us to quantify how well automatic scores can reproduce preference rankings across a variety of downstream summarization tasks. We find that, while automatic metrics are stable at smaller sample sizes, only some automatic metrics are able to moderately predict model win rates according to human preference.\n    ",
        "primary_category": "cs.CL",
        "categories": [],
        "submitted_date": "28 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18758": {
        "title": "Analog Isolated Multilevel Quantizer for Voltage Sensing while Maintaining Galvanic Isolation",
        "authors": [
            "Peter Weber",
            "Antonia Papandreou-Suppappola"
        ],
        "comments": "8 pages, 12 Figures",
        "subjects": "Signal Processing (eess.SP)",
        "abstract": "A low-power, compact device for performing measurements in electrical systems with isolated voltage domains is proposed. Isolated measurements are required in numerous applications. For instance, a measurement of the bus voltage for a system with a high supply voltage and lower isolated local voltage level may be needed for system health monitoring and control. Such a requirement may necessitate the use of isolation amplifiers to provide voltage telemetry for the local system. Isolation amplifiers require dual galvanically isolated supplies and use magnetic, capacitive, or optical barriers between primary and secondary sides. Producing this supplemental voltage requires an extra voltage converter, which consumes power and generates electromagnetic interference which must, in turn, be filtered. Complex designs incorporating feedback are needed to achieve linear response. The proposed Analog Isolated Multilevel Quantizer (AIMQ) addresses these issues by monitoring the primary-side signal and communicating the results to the secondary side using a novel scheme involving Zener diodes, optocouplers, transistors, one-hot coding, and discrete outputs. The result is a low power isolated transducer that can in principle be extended to an arbitrary bit depth.\n    ",
        "primary_category": "eess.SP",
        "categories": [
            "eess.SY"
        ],
        "submitted_date": "28 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18761": {
        "title": "Exploration of Learned Lifting-Based Transform Structures for Fully Scalable and Accessible Wavelet-Like Image Compression",
        "authors": [
            "Xinyue Li",
            "Aous Naman",
            "David Taubman"
        ],
        "comments": "This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible",
        "subjects": "Image and Video Processing (eess.IV)",
        "abstract": "This paper provides a comprehensive study on features and performance of different ways to incorporate neural networks into lifting-based wavelet-like transforms, within the context of fully scalable and accessible image compression. Specifically, we explore different arrangements of lifting steps, as well as various network architectures for learned lifting operators. Moreover, we examine the impact of the number of learned lifting steps, the number of channels, the number of layers and the support of kernels in each learned lifting operator. To facilitate the study, we investigate two generic training methodologies that are simultaneously appropriate to a wide variety of lifting structures considered. Experimental results ultimately suggest that retaining fixed lifting steps from the base wavelet transform is highly beneficial. Moreover, we demonstrate that employing more learned lifting steps and more layers in each learned lifting operator do not contribute strongly to the compression performance. However, benefits can be obtained by utilizing more channels in each learned lifting operator. Ultimately, the learned wavelet-like transform proposed in this paper achieves over 25% bit-rate savings compared to JPEG 2000 with compact spatial support.\n    ",
        "primary_category": "eess.IV",
        "categories": [
            "cs.CV",
            "cs.MM"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18762": {
        "title": "Disentangling the Causes of Plasticity Loss in Neural Networks",
        "authors": [
            "Clare Lyle",
            "Zeyu Zheng",
            "Khimya Khetarpal",
            "Hado van Hasselt",
            "Razvan Pascanu",
            "James Martens",
            "Will Dabney"
        ],
        "comments": " ",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Underpinning the past decades of work on the design, initialization, and optimization of neural networks is a seemingly innocuous assumption: that the network is trained on a \\textit{stationary} data distribution. In settings where this assumption is violated, e.g.\\ deep reinforcement learning, learning algorithms become unstable and brittle with respect to hyperparameters and even random seeds. One factor driving this instability is the loss of plasticity, meaning that updating the network's predictions in response to new information becomes more difficult as training progresses. While many recent works provide analyses and partial solutions to this phenomenon, a fundamental question remains unanswered: to what extent do known mechanisms of plasticity loss overlap, and how can mitigation strategies be combined to best maintain the trainability of a network? This paper addresses these questions, showing that loss of plasticity can be decomposed into multiple independent mechanisms and that, while intervening on any single mechanism is insufficient to avoid the loss of plasticity in all cases, intervening on multiple mechanisms in conjunction results in highly robust learning algorithms. We show that a combination of layer normalization and weight decay is highly effective at maintaining plasticity in a variety of synthetic nonstationary learning tasks, and further demonstrate its effectiveness on naturally arising nonstationarities, including reinforcement learning in the Arcade Learning Environment.\n    ",
        "primary_category": "cs.LG",
        "categories": [],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18769": {
        "title": "CoMeT: Count-Min-Sketch-based Row Tracking to Mitigate RowHammer at Low Cost",
        "authors": [
            "F. Nisa Bostanci",
            "Ismail Emir Yuksel",
            "Ataberk Olgun",
            "Konstantinos Kanellopoulos",
            "Yahya Can Tugrul",
            "A. Giray Yaglikci",
            "Mohammad Sadrosadati",
            "Onur Mutlu"
        ],
        "comments": "To appear at HPCA 2024",
        "subjects": "Cryptography and Security (cs.CR)",
        "abstract": "We propose a new RowHammer mitigation mechanism, CoMeT, that prevents RowHammer bitflips with low area, performance, and energy costs in DRAM-based systems at very low RowHammer thresholds. The key idea of CoMeT is to use low-cost and scalable hash-based counters to track DRAM row activations. CoMeT uses the Count-Min Sketch technique that maps each DRAM row to a group of counters, as uniquely as possible, using multiple hash functions. When a DRAM row is activated, CoMeT increments the counters mapped to that DRAM row. Because the mapping from DRAM rows to counters is not completely unique, activating one row can increment one or more counters mapped to another row. Thus, CoMeT may overestimate, but never underestimates, a DRAM row's activation count. This property of CoMeT allows it to securely prevent RowHammer bitflips while properly configuring its hash functions reduces overestimations. As a result, CoMeT 1) implements substantially fewer counters than the number of DRAM rows in a DRAM bank and 2) does not significantly overestimate a DRAM row's activation count.\nOur comprehensive evaluations show that CoMeT prevents RowHammer bitflips with an average performance overhead of only 4.01% across 61 benign single-core workloads for a very low RowHammer threshold of 125, normalized to a system with no RowHammer mitigation. CoMeT achieves a good trade-off between performance, energy, and area overheads. Compared to the best-performing state-of-the-art mitigation, CoMeT requires 74.2x less area overhead at the RowHammer threshold 125 and incurs a small performance overhead on average for all RowHammer thresholds. Compared to the best-performing low-area-cost mechanism, at a very low RowHammer threshold of 125, CoMeT improves performance by up to 39.1% while incurring a similar area overhead. CoMeT is openly and freely available at this https URL.\n    ",
        "primary_category": "cs.CR",
        "categories": [
            "cs.AR"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18777": {
        "title": "GDCNet: Calibrationless geometric distortion correction of echo planar imaging data using deep learning",
        "authors": [
            "Marina Manso Jimeno",
            "Keren Bachi",
            "George Gardner",
            "Yasmin L. Hurd",
            "John Thomas Vaughan Jr.",
            "Sairam Geethanath"
        ],
        "comments": "30 pages, 9 figures, 3 tables",
        "subjects": "Image and Video Processing (eess.IV)",
        "abstract": "Functional magnetic resonance imaging techniques benefit from echo-planar imaging's fast image acquisition but are susceptible to inhomogeneities in the main magnetic field, resulting in geometric distortion and signal loss artifacts in the images. Traditional methods leverage a field map or voxel displacement map for distortion correction. However, voxel displacement map estimation requires additional sequence acquisitions, and the accuracy of the estimation influences correction performance. This work implements a novel approach called GDCNet, which estimates a geometric distortion map by non-linear registration to T1-weighted anatomical images and applies it for distortion correction. GDCNet demonstrated fast distortion correction of functional images in retrospectively and prospectively acquired datasets. Among the compared models, the 2D self-supervised configuration resulted in a statistically significant improvement to normalized mutual information between distortion-corrected functional and T1-weighted images compared to the benchmark methods FUGUE and TOPUP. Furthermore, GDCNet models achieved processing speeds 14 times faster than TOPUP in the prospective dataset.\n    ",
        "primary_category": "eess.IV",
        "categories": [
            "cs.CV"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18780": {
        "title": "A Quantitative Evaluation of Score Distillation Sampling Based Text-to-3D",
        "authors": [
            "Xiaohan Fei",
            "Chethan Parameshwara",
            "Jiawei Mo",
            "Xiaolong Li",
            "Ashwin Swaminathan",
            "CJ Taylor",
            "Paolo Favaro",
            "Stefano Soatto"
        ],
        "comments": " ",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "The development of generative models that create 3D content from a text prompt has made considerable strides thanks to the use of the score distillation sampling (SDS) method on pre-trained diffusion models for image generation. However, the SDS method is also the source of several artifacts, such as the Janus problem, the misalignment between the text prompt and the generated 3D model, and 3D model inaccuracies. While existing methods heavily rely on the qualitative assessment of these artifacts through visual inspection of a limited set of samples, in this work we propose more objective quantitative evaluation metrics, which we cross-validate via human ratings, and show analysis of the failure cases of the SDS technique. We demonstrate the effectiveness of this analysis by designing a novel computationally efficient baseline model that achieves state-of-the-art performance on the proposed metrics while addressing all the above-mentioned artifacts.\n    ",
        "primary_category": "cs.CV",
        "categories": [],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18784": {
        "title": "Brain-inspired and Self-based Artificial Intelligence",
        "authors": [
            "Yi Zeng",
            "Feifei Zhao",
            "Yuxuan Zhao",
            "Dongcheng Zhao",
            "Enmeng Lu",
            "Qian Zhang",
            "Yuwei Wang",
            "Hui Feng",
            "Zhuoya Zhao",
            "Jihang Wang",
            "Qingqun Kong",
            "Yinqian Sun",
            "Yang Li",
            "Guobin Shen",
            "Bing Han",
            "Yiting Dong",
            "Wenxuan Pan",
            "Xiang He",
            "Aorigele Bao",
            "Jin Wang"
        ],
        "comments": " ",
        "subjects": "Artificial Intelligence (cs.AI)",
        "abstract": "The question \"Can machines think?\" and the Turing Test to assess whether machines could achieve human-level intelligence is one of the roots of AI. With the philosophical argument \"I think, therefore I am\", this paper challenge the idea of a \"thinking machine\" supported by current AIs since there is no sense of self in them. Current artificial intelligence is only seemingly intelligent information processing and does not truly understand or be subjectively aware of oneself and perceive the world with the self as human intelligence does. In this paper, we introduce a Brain-inspired and Self-based Artificial Intelligence (BriSe AI) paradigm. This BriSe AI paradigm is dedicated to coordinating various cognitive functions and learning strategies in a self-organized manner to build human-level AI models and robotic applications. Specifically, BriSe AI emphasizes the crucial role of the Self in shaping the future AI, rooted with a practical hierarchical Self framework, including Perception and Learning, Bodily Self, Autonomous Self, Social Self, and Conceptual Self. The hierarchical framework of the Self highlights self-based environment perception, self-bodily modeling, autonomous interaction with the environment, social interaction and collaboration with others, and even more abstract understanding of the Self. Furthermore, the positive mutual promotion and support among multiple levels of Self, as well as between Self and learning, enhance the BriSe AI's conscious understanding of information and flexible adaptation to complex environments, serving as a driving force propelling BriSe AI towards real Artificial General Intelligence.\n    ",
        "primary_category": "cs.AI",
        "categories": [
            "q-bio.NC"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18786": {
        "title": "OpticalDR: A Deep Optical Imaging Model for Privacy-Protective Depression Recognition",
        "authors": [
            "Yuchen Pan",
            "Junjun Jiang",
            "Kui Jiang",
            "Zhihao Wu",
            "Keyuan Yu",
            "Xianming Liu"
        ],
        "comments": "Accepted by CVPR 2024",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Depression Recognition (DR) poses a considerable challenge, especially in the context of the growing concerns surrounding privacy. Traditional automatic diagnosis of DR technology necessitates the use of facial images, undoubtedly expose the patient identity features and poses privacy risks. In order to mitigate the potential risks associated with the inappropriate disclosure of patient facial images, we design a new imaging system to erase the identity information of captured facial images while retain disease-relevant features. It is irreversible for identity information recovery while preserving essential disease-related characteristics necessary for accurate DR. More specifically, we try to record a de-identified facial image (erasing the identifiable features as much as possible) by a learnable lens, which is optimized in conjunction with the following DR task as well as a range of face analysis related auxiliary tasks in an end-to-end manner. These aforementioned strategies form our final Optical deep Depression Recognition network (OpticalDR). Experiments on CelebA, AVEC 2013, and AVEC 2014 datasets demonstrate that our OpticalDR has achieved state-of-the-art privacy protection performance with an average AUC of 0.51 on popular facial recognition models, and competitive results for DR with MAE/RMSE of 7.53/8.48 on AVEC 2013 and 7.89/8.82 on AVEC 2014, respectively.\n    ",
        "primary_category": "cs.CV",
        "categories": [],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18787": {
        "title": "Enhancing the \"Immunity\" of Mixture-of-Experts Networks for Adversarial Defense",
        "authors": [
            "Qiao Han",
            "yong huang",
            "xinling Guo",
            "Yiteng Zhai",
            "Yu Qin",
            "Yao Yang"
        ],
        "comments": " ",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Recent studies have revealed the vulnerability of Deep Neural Networks (DNNs) to adversarial examples, which can easily fool DNNs into making incorrect predictions. To mitigate this deficiency, we propose a novel adversarial defense method called \"Immunity\" (Innovative MoE with MUtual information \\& positioN stabilITY) based on a modified Mixture-of-Experts (MoE) architecture in this work. The key enhancements to the standard MoE are two-fold: 1) integrating of Random Switch Gates (RSGs) to obtain diverse network structures via random permutation of RSG parameters at evaluation time, despite of RSGs being determined after one-time training; 2) devising innovative Mutual Information (MI)-based and Position Stability-based loss functions by capitalizing on Grad-CAM's explanatory power to increase the diversity and the causality of expert networks. Notably, our MI-based loss operates directly on the heatmaps, thereby inducing subtler negative impacts on the classification performance when compared to other losses of the same type, theoretically. Extensive evaluation validates the efficacy of the proposed approach in improving adversarial robustness against a wide range of attacks.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.CR"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18789": {
        "title": "FlexLLM: A System for Co-Serving Large Language Model Inference and Parameter-Efficient Finetuning",
        "authors": [
            "Xupeng Miao",
            "Gabriele Oliaro",
            "Xinhao Cheng",
            "Mengdi Wu",
            "Colin Unger",
            "Zhihao Jia"
        ],
        "comments": " ",
        "subjects": "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "abstract": "Parameter-efficient finetuning (PEFT) is a widely used technique to adapt large language models for different tasks. Service providers typically create separate systems for users to perform PEFT model finetuning and inference tasks. This is because existing systems cannot handle workloads that include a mix of inference and PEFT finetuning requests. As a result, shared GPU resources are underutilized, leading to inefficiencies. To address this problem, we present FlexLLM, the first system that can serve inference and parameter-efficient finetuning requests in the same iteration. Our system leverages the complementary nature of these two tasks and utilizes shared GPU resources to run them jointly, using a method called co-serving. To achieve this, FlexLLM introduces a novel token-level finetuning mechanism, which breaks down the finetuning computation of a sequence into smaller token-level computations and uses dependent parallelization and graph pruning, two static compilation optimizations, to minimize the memory overhead and latency for co-serving. Compared to existing systems, FlexLLM's co-serving approach reduces the activation GPU memory overhead by up to 8x, and the end-to-end GPU memory requirement of finetuning by up to 36% while maintaining a low inference latency and improving finetuning throughput. For example, under a heavy inference workload, FlexLLM can still preserve more than 80% of the peak finetuning throughput, whereas existing systems cannot make any progress with finetuning. The source code of FlexLLM is publicly available at this https URL.\n    ",
        "primary_category": "cs.DC",
        "categories": [
            "cs.CL",
            "cs.LG"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18790": {
        "title": "The Power of Unentangled Quantum Proofs with Non-negative Amplitudes",
        "authors": [
            "Fernando Granha Jeronimo",
            "Pei Wu"
        ],
        "comments": "64 pages",
        "subjects": "Quantum Physics (quant-ph)",
        "abstract": "Quantum entanglement is a fundamental property of quantum mechanics and plays a crucial role in quantum computation and information. We study entanglement via the lens of computational complexity by considering quantum generalizations of the class NP with multiple unentangled quantum proofs, the so-called QMA(2) and its variants. The complexity of QMA(2) is a longstanding open problem, and only the trivial bounds QMA $\\subseteq$ QMA(2) $\\subseteq$ NEXP are known.\nIn this work, we study the power of unentangled quantum proofs with non-negative amplitudes, a class which we denote $\\text{QMA}^+(2)$. In this setting, we are able to design proof verification protocols for problems both using logarithmic size quantum proofs and having a constant probability gap in distinguishing yes from no instances. In particular, we design global protocols for small set expansion, unique games, and PCP verification. As a consequence, we obtain NP $\\subseteq \\text{QMA}^+_{\\log}(2)$ with a constant gap. By virtue of the new constant gap, we are able to ``scale up'' this result to $\\text{QMA}^+(2)$, obtaining the full characterization $\\text{QMA}^+(2)$=NEXP by establishing stronger explicitness properties of the PCP for NEXP.\nOne key novelty of these protocols is the manipulation of quantum proofs in a global and coherent way yielding constant gaps. Previous protocols (only available for general amplitudes) are either local having vanishingly small gaps or treat the quantum proofs as classical probability distributions requiring polynomially many proofs thereby not implying non-trivial bounds on QMA(2).\nFinally, we show that QMA(2) is equal to $\\text{QMA}^+(2)$ provided the gap of the latter is a sufficiently large constant. In particular, if $\\text{QMA}^+(2)$ admits gap amplification, then QMA(2)=NEXP.\n    ",
        "primary_category": "quant-ph",
        "categories": [
            "cs.CC"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18792": {
        "title": "MPAT: Building Robust Deep Neural Networks against Textual Adversarial Attacks",
        "authors": [
            "Fangyuan Zhang",
            "Huichi Zhou",
            "Shuangjiao Li",
            "Hongtao Wang"
        ],
        "comments": " ",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Deep neural networks have been proven to be vulnerable to adversarial examples and various methods have been proposed to defend against adversarial attacks for natural language processing tasks. However, previous defense methods have limitations in maintaining effective defense while ensuring the performance of the original task. In this paper, we propose a malicious perturbation based adversarial training method (MPAT) for building robust deep neural networks against textual adversarial attacks. Specifically, we construct a multi-level malicious example generation strategy to generate adversarial examples with malicious perturbations, which are used instead of original inputs for model training. Additionally, we employ a novel training objective function to ensure achieving the defense goal without compromising the performance on the original task. We conduct comprehensive experiments to evaluate our defense method by attacking five victim models on three benchmark datasets. The result demonstrates that our method is more effective against malicious adversarial attacks compared with previous defense methods while maintaining or further improving the performance on the original task.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.CL",
            "cs.CR"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18796": {
        "title": "MOSAIC: A Modular System for Assistive and Interactive Cooking",
        "authors": [
            "Huaxiaoyue Wang",
            "Kushal Kedia",
            "Juntao Ren",
            "Rahma Abdullah",
            "Atiksh Bhardwaj",
            "Angela Chao",
            "Kelly Y Chen",
            "Nathaniel Chin",
            "Prithwish Dan",
            "Xinyi Fan",
            "Gonzalo Gonzalez-Pumariega",
            "Aditya Kompella",
            "Maximus Adrian Pace",
            "Yash Sharma",
            "Xiangwan Sun",
            "Neha Sunkara",
            "Sanjiban Choudhury"
        ],
        "comments": "22 pages, 13 figures",
        "subjects": "Robotics (cs.RO)",
        "abstract": "We present MOSAIC, a modular architecture for home robots to perform complex collaborative tasks, such as cooking with everyday users. MOSAIC tightly collaborates with humans, interacts with users using natural language, coordinates multiple robots, and manages an open vocabulary of everyday objects. At its core, MOSAIC employs modularity: it leverages multiple large-scale pre-trained models for general tasks like language and image recognition, while using streamlined modules designed for task-specific control. We extensively evaluate MOSAIC on 60 end-to-end trials where two robots collaborate with a human user to cook a combination of 6 recipes. We also extensively test individual modules with 180 episodes of visuomotor picking, 60 episodes of human motion forecasting, and 46 online user evaluations of the task planner. We show that MOSAIC is able to efficiently collaborate with humans by running the overall system end-to-end with a real human user, completing 68.3% (41/60) collaborative cooking trials of 6 different recipes with a subtask completion rate of 91.6%. Finally, we discuss the limitations of the current system and exciting open challenges in this domain. The project's website is at this https URL\n",
        "primary_category": "cs.RO",
        "categories": [],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18797": {
        "title": "ARTiST: Automated Text Simplification for Task Guidance in Augmented Reality",
        "authors": [
            "Guande Wu",
            "Jing Qian",
            "Sonia Castelo",
            "Shaoyu Chen",
            "Joao Rulff",
            "Claudio Silva"
        ],
        "comments": "Conditionally accepted by CHI '24",
        "subjects": "Human-Computer Interaction (cs.HC)",
        "abstract": "Text presented in augmented reality provides in-situ, real-time information for users. However, this content can be challenging to apprehend quickly when engaging in cognitively demanding AR tasks, especially when it is presented on a head-mounted display. We propose ARTiST, an automatic text simplification system that uses a few-shot prompt and GPT-3 models to specifically optimize the text length and semantic content for augmented reality. Developed out of a formative study that included seven users and three experts, our system combines a customized error calibration model with a few-shot prompt to integrate the syntactic, lexical, elaborative, and content simplification techniques, and generate simplified AR text for head-worn displays. Results from a 16-user empirical study showed that ARTiST lightens the cognitive load and improves performance significantly over both unmodified text and text modified via traditional methods. Our work constitutes a step towards automating the optimization of batch text data for readability and performance in augmented reality.\n    ",
        "primary_category": "cs.HC",
        "categories": [
            "cs.CL"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18800": {
        "title": "BlockEcho: Retaining Long-Range Dependencies for Imputing Block-Wise Missing Data",
        "authors": [
            "Qiao Han",
            "Mingqian Li",
            "Yao Yang",
            "Yiteng Zhai"
        ],
        "comments": " ",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Block-wise missing data poses significant challenges in real-world data imputation tasks. Compared to scattered missing data, block-wise gaps exacerbate adverse effects on subsequent analytic and machine learning tasks, as the lack of local neighboring elements significantly reduces the interpolation capability and predictive power. However, this issue has not received adequate attention. Most SOTA matrix completion methods appeared less effective, primarily due to overreliance on neighboring elements for predictions. We systematically analyze the issue and propose a novel matrix completion method ``BlockEcho\" for a more comprehensive solution. This method creatively integrates Matrix Factorization (MF) within Generative Adversarial Networks (GAN) to explicitly retain long-distance inter-element relationships in the original matrix. Besides, we incorporate an additional discriminator for GAN, comparing the generator's intermediate progress with pre-trained MF results to constrain high-order feature distributions. Subsequently, we evaluate BlockEcho on public datasets across three domains. Results demonstrate superior performance over both traditional and SOTA methods when imputing block-wise missing data, especially at higher missing rates. The advantage also holds for scattered missing data at high missing rates. We also contribute on the analyses in providing theoretical justification on the optimality and convergence of fusing MF and GAN for missing block data.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "stat.ML"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18803": {
        "title": "To Pool or Not To Pool: Analyzing the Regularizing Effects of Group-Fair Training on Shared Models",
        "authors": [
            "Cyrus Cousins",
            "I. Elizabeth Kumar",
            "Suresh Venkatasubramanian"
        ],
        "comments": " ",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "In fair machine learning, one source of performance disparities between groups is over-fitting to groups with relatively few training samples. We derive group-specific bounds on the generalization error of welfare-centric fair machine learning that benefit from the larger sample size of the majority group. We do this by considering group-specific Rademacher averages over a restricted hypothesis class, which contains the family of models likely to perform well with respect to a fair learning objective (e.g., a power-mean). Our simulations demonstrate these bounds improve over a naive method, as expected by theory, with particularly significant improvement for smaller group sizes.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.CY"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18805": {
        "title": "VEC-SBM: Optimal Community Detection with Vectorial Edges Covariates",
        "authors": [
            "Guillaume Braun",
            "Masashi Sugiyama"
        ],
        "comments": " ",
        "subjects": "Social and Information Networks (cs.SI)",
        "abstract": "Social networks are often associated with rich side information, such as texts and images. While numerous methods have been developed to identify communities from pairwise interactions, they usually ignore such side information. In this work, we study an extension of the Stochastic Block Model (SBM), a widely used statistical framework for community detection, that integrates vectorial edges covariates: the Vectorial Edges Covariates Stochastic Block Model (VEC-SBM). We propose a novel algorithm based on iterative refinement techniques and show that it optimally recovers the latent communities under the VEC-SBM. Furthermore, we rigorously assess the added value of leveraging edge's side information in the community detection process. We complement our theoretical results with numerical experiments on synthetic and semi-synthetic data.\n    ",
        "primary_category": "cs.SI",
        "categories": [
            "stat.ML"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18807": {
        "title": "On the Decision-Making Abilities in Role-Playing using Large Language Models",
        "authors": [
            "Chenglei Shen",
            "Guofu Xie",
            "Xiao Zhang",
            "Jun Xu"
        ],
        "comments": " ",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "Large language models (LLMs) are now increasingly utilized for role-playing tasks, especially in impersonating domain-specific experts, primarily through role-playing prompts. When interacting in real-world scenarios, the decision-making abilities of a role significantly shape its behavioral patterns. In this paper, we concentrate on evaluating the decision-making abilities of LLMs post role-playing thereby validating the efficacy of role-playing. Our goal is to provide metrics and guidance for enhancing the decision-making abilities of LLMs in role-playing tasks. Specifically, we first use LLMs to generate virtual role descriptions corresponding to the 16 personality types of Myers-Briggs Type Indicator (abbreviated as MBTI) representing a segmentation of the population. Then we design specific quantitative operations to evaluate the decision-making abilities of LLMs post role-playing from four aspects: adaptability, exploration$\\&$exploitation trade-off ability, reasoning ability, and safety. Finally, we analyze the association between the performance of decision-making and the corresponding MBTI types through GPT-4. Extensive experiments demonstrate stable differences in the four aspects of decision-making abilities across distinct roles, signifying a robust correlation between decision-making abilities and the roles emulated by LLMs. These results underscore that LLMs can effectively impersonate varied roles while embodying their genuine sociological characteristics.\n    ",
        "primary_category": "cs.CL",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18811": {
        "title": "BFRFormer: Transformer-based generator for Real-World Blind Face Restoration",
        "authors": [
            "Guojing Ge",
            "Qi Song",
            "Guibo Zhu",
            "Yuting Zhang",
            "Jinglu Chen",
            "Miao Xin",
            "Ming Tang",
            "Jinqiao Wang"
        ],
        "comments": "Accepted by ICASSP 2024",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Blind face restoration is a challenging task due to the unknown and complex degradation. Although face prior-based methods and reference-based methods have recently demonstrated high-quality results, the restored images tend to contain over-smoothed results and lose identity-preserved details when the degradation is severe. It is observed that this is attributed to short-range dependencies, the intrinsic limitation of convolutional neural networks. To model long-range dependencies, we propose a Transformer-based blind face restoration method, named BFRFormer, to reconstruct images with more identity-preserved details in an end-to-end manner. In BFRFormer, to remove blocking artifacts, the wavelet discriminator and aggregated attention module are developed, and spectral normalization and balanced consistency regulation are adaptively applied to address the training instability and over-fitting problem, respectively. Extensive experiments show that our method outperforms state-of-the-art methods on a synthetic dataset and four real-world datasets. The source code, Casia-Test dataset, and pre-trained models are released at this https URL.\n    ",
        "primary_category": "cs.CV",
        "categories": [],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18813": {
        "title": "Protein Multimer Structure Prediction via Prompt Learning",
        "authors": [
            "Ziqi Gao",
            "Xiangguo Sun",
            "Zijing Liu",
            "Yu Li",
            "Hong Cheng",
            "Jia Li"
        ],
        "comments": "International Conference on Learning Representations (ICLR 2024)",
        "subjects": "Computational Engineering, Finance, and Science (cs.CE)",
        "abstract": "Understanding the 3D structures of protein multimers is crucial, as they play a vital role in regulating various cellular processes. It has been empirically confirmed that the multimer structure prediction~(MSP) can be well handled in a step-wise assembly fashion using provided dimer structures and predicted protein-protein interactions~(PPIs). However, due to the biological gap in the formation of dimers and larger multimers, directly applying PPI prediction techniques can often cause a \\textit{poor generalization} to the MSP task. To address this challenge, we aim to extend the PPI knowledge to multimers of different scales~(i.e., chain numbers). Specifically, we propose \\textbf{\\textsc{PromptMSP}}, a pre-training and \\textbf{Prompt} tuning framework for \\textbf{M}ultimer \\textbf{S}tructure \\textbf{P}rediction. First, we tailor the source and target tasks for effective PPI knowledge learning and efficient inference, respectively. We design PPI-inspired prompt learning to narrow the gaps of two task formats and generalize the PPI knowledge to multimers of different scales. We provide a meta-learning strategy to learn a reliable initialization of the prompt model, enabling our prompting framework to effectively adapt to limited data for large-scale multimers. Empirically, we achieve both significant accuracy (RMSD and TM-Score) and efficiency improvements compared to advanced MSP models. The code, data and checkpoints are released at \\url{this https URL}.\n    ",
        "primary_category": "cs.CE",
        "categories": [],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18814": {
        "title": "New topological subsystem codes from semi-regular tessellations",
        "authors": [
            "Eduardo Brandani da Silva",
            "Evandro Mazetto Brizola"
        ],
        "comments": " ",
        "subjects": "Information Theory (cs.IT)",
        "abstract": "In this work, we present new constructions for topological subsystem codes using semi-regular Euclidean and hyperbolic tessellations. They give us new families of codes, and we also provide a new family of codes obtained through an already existing construction, due to Sarvepalli and Brown. We also prove new results that allow us to obtain the parameters of these new codes.\n    ",
        "primary_category": "cs.IT",
        "categories": [],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18815": {
        "title": "How do Large Language Models Handle Multilingualism?",
        "authors": [
            "Yiran Zhao",
            "Wenxuan Zhang",
            "Guizhen Chen",
            "Kenji Kawaguchi",
            "Lidong Bing"
        ],
        "comments": " ",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "Large language models (LLMs) demonstrate remarkable performance across a spectrum of languages. In this work, we delve into the question: How do LLMs handle multilingualism? We introduce a framework that depicts LLMs' processing of multilingual inputs: In the first several layers, LLMs understand the question, converting multilingual inputs into English to facilitate the task-solving phase. In the intermediate layers, LLMs engage in problem-solving by thinking in English and incorporating multilingual knowledge to obtain factual content, leveraging the self-attention and feed-forward structures, respectively. In the last several layers, LLMs generate responses that align with the original language of the query. In addition, we investigate the existence of language-specific neurons when processing a certain language. To detect neurons activated by the input language, even without labels, we innovatively design a Parallel Language specific Neuron Detection ($\\texttt{PLND}$) method that effectively measures the significance of neurons when handling multilingual inputs. By comprehensive ablation analysis through deactivating neurons of different layers and structures, we verify the framework that we propose. Additionally, we demonstrate that we can utilize such a framework to effectively enhance the multilingual ability with much less training effort.\n    ",
        "primary_category": "cs.CL",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18818": {
        "title": "CEBin: A Cost-Effective Framework for Large-Scale Binary Code Similarity Detection",
        "authors": [
            "Hao Wang",
            "Zeyu Gao",
            "Chao Zhang",
            "Mingyang Sun",
            "Yuchen Zhou",
            "Han Qiu",
            "Xi Xiao"
        ],
        "comments": " ",
        "subjects": "Software Engineering (cs.SE)",
        "abstract": "Binary code similarity detection (BCSD) is a fundamental technique for various application. Many BCSD solutions have been proposed recently, which mostly are embedding-based, but have shown limited accuracy and efficiency especially when the volume of target binaries to search is large. To address this issue, we propose a cost-effective BCSD framework, CEBin, which fuses embedding-based and comparison-based approaches to significantly improve accuracy while minimizing overheads. Specifically, CEBin utilizes a refined embedding-based approach to extract features of target code, which efficiently narrows down the scope of candidate similar code and boosts performance. Then, it utilizes a comparison-based approach that performs a pairwise comparison on the candidates to capture more nuanced and complex relationships, which greatly improves the accuracy of similarity detection. By bridging the gap between embedding-based and comparison-based approaches, CEBin is able to provide an effective and efficient solution for detecting similar code (including vulnerable ones) in large-scale software ecosystems. Experimental results on three well-known datasets demonstrate the superiority of CEBin over existing state-of-the-art (SOTA) baselines. To further evaluate the usefulness of BCSD in real world, we construct a large-scale benchmark of vulnerability, offering the first precise evaluation scheme to assess BCSD methods for the 1-day vulnerability detection task. CEBin could identify the similar function from millions of candidate functions in just a few seconds and achieves an impressive recall rate of $85.46\\%$ on this more practical but challenging task, which are several order of magnitudes faster and $4.07\\times$ better than the best SOTA baseline. Our code is available at this https URL.\n    ",
        "primary_category": "cs.SE",
        "categories": [
            "cs.CR"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18819": {
        "title": "Dual Operating Modes of In-Context Learning",
        "authors": [
            "Ziqian Lin",
            "Kangwook Lee"
        ],
        "comments": "53 pages, 20 figures",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "In-context learning (ICL) exhibits dual operating modes: task learning, i.e., acquiring a new skill from in-context samples, and task retrieval, i.e., locating and activating a relevant pretrained skill. Recent theoretical work investigates various mathematical models to analyze ICL, but existing models explain only one operating mode at a time. We introduce a probabilistic model, with which one can explain the dual operating modes of ICL simultaneously. Focusing on in-context learning of linear functions, we extend existing models for pretraining data by introducing multiple task groups and task-dependent input distributions. We then analyze the behavior of the optimally pretrained model under the squared loss, i.e., the MMSE estimator of the label given in-context examples. Regarding pretraining task distribution as prior and in-context examples as the observation, we derive the closed-form expression of the task posterior distribution. With the closed-form expression, we obtain a quantitative understanding of the two operating modes of ICL. Furthermore, we shed light on an unexplained phenomenon observed in practice: under certain settings, the ICL risk initially increases and then decreases with more in-context examples. Our model offers a plausible explanation for this \"early ascent\" phenomenon: a limited number of in-context samples may lead to the retrieval of an incorrect skill, thereby increasing the risk, which will eventually diminish as task learning takes effect with more in-context samples. We also theoretically analyze ICL with biased labels, e.g., zero-shot ICL, where in-context examples are assigned random labels. Lastly, we validate our findings and predictions via experiments involving Transformers and large language models.\n    ",
        "primary_category": "cs.LG",
        "categories": [],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18821": {
        "title": "Debiased Novel Category Discovering and Localization",
        "authors": [
            "Juexiao Feng",
            "Yuhong Yang",
            "Yanchun Xie",
            "Yaqian Li",
            "Yandong Guo",
            "Yuchen Guo",
            "Yuwei He",
            "Liuyu Xiang",
            "Guiguang Ding"
        ],
        "comments": "Accepted by AAAI 2024",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "In recent years, object detection in deep learning has experienced rapid development. However, most existing object detection models perform well only on closed-set datasets, ignoring a large number of potential objects whose categories are not defined in the training set. These objects are often identified as background or incorrectly classified as pre-defined categories by the detectors. In this paper, we focus on the challenging problem of Novel Class Discovery and Localization (NCDL), aiming to train detectors that can detect the categories present in the training data, while also actively discover, localize, and cluster new categories. We analyze existing NCDL methods and identify the core issue: object detectors tend to be biased towards seen objects, and this leads to the neglect of unseen targets. To address this issue, we first propose an Debiased Region Mining (DRM) approach that combines class-agnostic Region Proposal Network (RPN) and class-aware RPN in a complementary manner. Additionally, we suggest to improve the representation network through semi-supervised contrastive learning by leveraging unlabeled data. Finally, we adopt a simple and efficient mini-batch K-means clustering method for novel class discovery. We conduct extensive experiments on the NCDL benchmark, and the results demonstrate that the proposed DRM approach significantly outperforms previous methods, establishing a new state-of-the-art.\n    ",
        "primary_category": "cs.CV",
        "categories": [],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18824": {
        "title": "Batch size invariant Adam",
        "authors": [
            "Xi Wang",
            "Laurence Aitchison"
        ],
        "comments": " ",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "We propose a batch size invariant version of Adam, for use in large-scale, distributed settings, in which the mini-batch is divided into micro-batches which are distributed among worker nodes. For the v term, standard Adam first computes the average over micro-batch gradients, then squares, while in the batch size invariant Adam proposed here, we first square the micro-batch gradients, then average. Previous work (e.g. Malladi et al. 2022) used an alternative approach that involved a square-root scaling of the learning rate, but this approach requires strong assumptions to work; in particular that the gradient variance dominates the square of the expected gradient. In contrast, the approach proposed here gives batch size invariance without this assumption. We confirm that in practice our scheme gives batch size invariance in a much larger range of scenarios than the previous approach.\n    ",
        "primary_category": "cs.LG",
        "categories": [],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18835": {
        "title": "Envisioning the Applications and Implications of Generative AI for News Media",
        "authors": [
            "Sachita Nishal",
            "Nicholas Diakopoulos"
        ],
        "comments": "Accepted to CHI 2023 Workshop on Generative AI and HCI; 8 pages",
        "subjects": "Computers and Society (cs.CY)",
        "abstract": "This article considers the increasing use of algorithmic decision-support systems and synthetic media in the newsroom, and explores how generative models can help reporters and editors across a range of tasks from the conception of a news story to its distribution. Specifically, we draw from a taxonomy of tasks associated with news production, and discuss where generative models could appropriately support reporters, the journalistic and ethical values that must be preserved within these interactions, and the resulting implications for design contributions in this area in the future. Our essay is relevant to practitioners and researchers as they consider using generative AI systems to support different tasks and workflows.\n    ",
        "primary_category": "cs.CY",
        "categories": [],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18836": {
        "title": "A Model-Based Approach for Improving Reinforcement Learning Efficiency Leveraging Expert Observations",
        "authors": [
            "Erhan Can Ozcan",
            "Vittorio Giammarino",
            "James Queeney",
            "Ioannis Ch. Paschalidis"
        ],
        "comments": " ",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "This paper investigates how to incorporate expert observations (without explicit information on expert actions) into a deep reinforcement learning setting to improve sample efficiency. First, we formulate an augmented policy loss combining a maximum entropy reinforcement learning objective with a behavioral cloning loss that leverages a forward dynamics model. Then, we propose an algorithm that automatically adjusts the weights of each component in the augmented loss function. Experiments on a variety of continuous control tasks demonstrate that the proposed algorithm outperforms various benchmarks by effectively utilizing available expert observations.\n    ",
        "primary_category": "cs.LG",
        "categories": [],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18842": {
        "title": "ViewFusion: Towards Multi-View Consistency via Interpolated Denoising",
        "authors": [
            "Xianghui Yang",
            "Yan Zuo",
            "Sameera Ramasinghe",
            "Loris Bazzani",
            "Gil Avraham",
            "Anton van den Hengel"
        ],
        "comments": "CVPR2024,homepage:this https URL",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Novel-view synthesis through diffusion models has demonstrated remarkable potential for generating diverse and high-quality images. Yet, the independent process of image generation in these prevailing methods leads to challenges in maintaining multiple-view consistency. To address this, we introduce ViewFusion, a novel, training-free algorithm that can be seamlessly integrated into existing pre-trained diffusion models. Our approach adopts an auto-regressive method that implicitly leverages previously generated views as context for the next view generation, ensuring robust multi-view consistency during the novel-view generation process. Through a diffusion process that fuses known-view information via interpolated denoising, our framework successfully extends single-view conditioned models to work in multiple-view conditional settings without any additional fine-tuning. Extensive experimental results demonstrate the effectiveness of ViewFusion in generating consistent and detailed novel views.\n    ",
        "primary_category": "cs.CV",
        "categories": [],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18844": {
        "title": "Deep Learning for 3D Human Pose Estimation and Mesh Recovery: A Survey",
        "authors": [
            "Yang Liu",
            "Changzhen Qiu",
            "Zhiyong Zhang"
        ],
        "comments": " ",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "3D human pose estimation and mesh recovery have attracted widespread research interest in many areas, such as computer vision, autonomous driving, and robotics. Deep learning on 3D human pose estimation and mesh recovery has recently thrived, with numerous methods proposed to address different problems in this area. In this paper, to stimulate future research, we present a comprehensive review of recent progress over the past five years in deep learning methods for this area by delving into over 200 references. To the best of our knowledge, this survey is arguably the first to comprehensively cover deep learning methods for 3D human pose estimation, including both single-person and multi-person approaches, as well as human mesh recovery, encompassing methods based on explicit models and implicit representations. We also present comparative results on several publicly available datasets, together with insightful observations and inspiring future research directions. A regularly updated project page can be found at this https URL.\n    ",
        "primary_category": "cs.CV",
        "categories": [
            "cs.MM"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18846": {
        "title": "Multi-Fidelity Residual Neural Processes for Scalable Surrogate Modeling",
        "authors": [
            "Ruijia Niu",
            "Dongxia Wu",
            "Kai Kim",
            "Yi-An Ma",
            "Duncan Watson-Parris",
            "Rose Yu"
        ],
        "comments": "A novel probabilistic inference approach for scalable multi-fidelity surrogate modeling",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Multi-fidelity surrogate modeling aims to learn an accurate surrogate at the highest fidelity level by combining data from multiple sources. Traditional methods relying on Gaussian processes can hardly scale to high-dimensional data. Deep learning approaches utilize neural network based encoders and decoders to improve scalability. These approaches share encoded representations across fidelities without including corresponding decoder parameters. At the highest fidelity, the representations are decoded with different parameters, making the shared information inherently inaccurate. This hinders inference performance, especially in out-of-distribution scenarios when the highest fidelity data has limited domain coverage. To address these limitations, we propose Multi-fidelity Residual Neural Processes (MFRNP), a novel multi-fidelity surrogate modeling framework. MFRNP optimizes lower fidelity decoders for accurate information sharing by aggregating lower fidelity surrogate outputs and models residual between the aggregation and ground truth on the highest fidelity. We show that MFRNP significantly outperforms current state-of-the-art in learning partial differential equations and a real-world climate modeling task.\n    ",
        "primary_category": "cs.LG",
        "categories": [],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18848": {
        "title": "SwitchLight: Co-design of Physics-driven Architecture and Pre-training Framework for Human Portrait Relighting",
        "authors": [
            "Hoon Kim",
            "Minje Jang",
            "Wonjun Yoon",
            "Jisoo Lee",
            "Donghyun Na",
            "Sanghyun Woo"
        ],
        "comments": "CVPR2024. Live demos available at this https URL",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "We introduce a co-designed approach for human portrait relighting that combines a physics-guided architecture with a pre-training framework. Drawing on the Cook-Torrance reflectance model, we have meticulously configured the architecture design to precisely simulate light-surface interactions. Furthermore, to overcome the limitation of scarce high-quality lightstage data, we have developed a self-supervised pre-training strategy. This novel combination of accurate physical modeling and expanded training dataset establishes a new benchmark in relighting realism.\n    ",
        "primary_category": "cs.CV",
        "categories": [],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18849": {
        "title": "Enhancing Steganographic Text Extraction: Evaluating the Impact of NLP Models on Accuracy and Semantic Coherence",
        "authors": [
            "Mingyang Li",
            "Maoqin Yuan",
            "Luyao Li",
            "Han Pengsihua"
        ],
        "comments": " ",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "This study discusses a new method combining image steganography technology with Natural Language Processing (NLP) large models, aimed at improving the accuracy and robustness of extracting steganographic text. Traditional Least Significant Bit (LSB) steganography techniques face challenges in accuracy and robustness of information extraction when dealing with complex character encoding, such as Chinese characters. To address this issue, this study proposes an innovative LSB-NLP hybrid framework. This framework integrates the advanced capabilities of NLP large models, such as error detection, correction, and semantic consistency analysis, as well as information reconstruction techniques, thereby significantly enhancing the robustness of steganographic text extraction. Experimental results show that the LSB-NLP hybrid framework excels in improving the extraction accuracy of steganographic text, especially in handling Chinese characters. The findings of this study not only confirm the effectiveness of combining image steganography technology and NLP large models but also propose new ideas for research and application in the field of information hiding. The successful implementation of this interdisciplinary approach demonstrates the great potential of integrating image steganography technology with natural language processing technology in solving complex information processing problems.\n    ",
        "primary_category": "cs.CV",
        "categories": [
            "cs.AI",
            "cs.CL"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18851": {
        "title": "Applications of 0-1 Neural Networks in Prescription and Prediction",
        "authors": [
            "Vrishabh Patil",
            "Kara Hoppe",
            "Yonatan Mintz"
        ],
        "comments": " ",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "A key challenge in medical decision making is learning treatment policies for patients with limited observational data. This challenge is particularly evident in personalized healthcare decision-making, where models need to take into account the intricate relationships between patient characteristics, treatment options, and health outcomes. To address this, we introduce prescriptive networks (PNNs), shallow 0-1 neural networks trained with mixed integer programming that can be used with counterfactual estimation to optimize policies in medium data settings. These models offer greater interpretability than deep neural networks and can encode more complex policies than common models such as decision trees. We show that PNNs can outperform existing methods in both synthetic data experiments and in a case study of assigning treatments for postpartum hypertension. In particular, PNNs are shown to produce policies that could reduce peak blood pressure by 5.47 mm Hg (p=0.02) over existing clinical practice, and by 2 mm Hg (p=0.01) over the next best prescriptive modeling technique. Moreover PNNs were more likely than all other models to correctly identify clinically significant features while existing models relied on potentially dangerous features such as patient insurance information and race that could lead to bias in treatment.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.AI",
            "math.OC",
            "stat.ML"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18853": {
        "title": "Rethinking Multi-domain Generalization with A General Learning Objective",
        "authors": [
            "Zhaorui Tan",
            "Xi Yang",
            "Kaizhu Huang"
        ],
        "comments": "Accepted by CVPR24",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Multi-domain generalization (mDG) is universally aimed to minimize the discrepancy between training and testing distributions to enhance marginal-to-label distribution mapping. However, existing mDG literature lacks a general learning objective paradigm and often imposes constraints on static target marginal distributions. In this paper, we propose to leverage a $Y$-mapping to relax the constraint. We rethink the learning objective for mDG and design a new \\textbf{general learning objective} to interpret and analyze most existing mDG wisdom. This general objective is bifurcated into two synergistic amis: learning domain-independent conditional features and maximizing a posterior. Explorations also extend to two effective regularization terms that incorporate prior information and suppress invalid causality, alleviating the issues that come with relaxed constraints. We theoretically contribute an upper bound for the domain alignment of domain-independent conditional features, disclosing that many previous mDG endeavors actually \\textbf{optimize partially the objective} and thus lead to limited performance. As such, our study distills a general learning objective into four practical components, providing a general, robust, and flexible mechanism to handle complex domain shifts. Extensive empirical results indicate that the proposed objective with $Y$-mapping leads to substantially better mDG performance in various downstream tasks, including regression, segmentation, and classification.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.AI",
            "cs.CV"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18856": {
        "title": "Anatomy-guided fiber trajectory distribution estimation for cranial nerves tractography",
        "authors": [
            "Lei Xie",
            "Qingrun Zeng",
            "Huajun Zhou",
            "Guoqiang Xie",
            "Mingchu Li",
            "Jiahao Huang",
            "Jianan Cui",
            "Hao Chen",
            "Yuanjing Feng"
        ],
        "comments": " ",
        "subjects": "Image and Video Processing (eess.IV)",
        "abstract": "Diffusion MRI tractography is an important tool for identifying and analyzing the intracranial course of cranial nerves (CNs). However, the complex environment of the skull base leads to ambiguous spatial correspondence between diffusion directions and fiber geometry, and existing diffusion tractography methods of CNs identification are prone to producing erroneous trajectories and missing true positive connections. To overcome the above challenge, we propose a novel CNs identification framework with anatomy-guided fiber trajectory distribution, which incorporates anatomical shape prior knowledge during the process of CNs tracing to build diffusion tensor vector fields. We introduce higher-order streamline differential equations for continuous flow field representations to directly characterize the fiber trajectory distribution of CNs from the tract-based level. The experimental results on the vivo HCP dataset and the clinical MDM dataset demonstrate that the proposed method reduces false-positive fiber production compared to competing methods and produces reconstructed CNs (i.e. CN II, CN III, CN V, and CN VII/VIII) that are judged to better correspond to the known anatomy.\n    ",
        "primary_category": "eess.IV",
        "categories": [
            "cs.CV"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18859": {
        "title": "Taking Second-life Batteries from Exhausted to Empowered using Experiments, Data Analysis, and Health Estimation",
        "authors": [
            "Xiaofan Cui",
            "Muhammad Aadil Khan",
            "Gabriele Pozzato",
            "Surinder Singh",
            "Ratnesh Sharma",
            "Simona Onori"
        ],
        "comments": "31 pages, 18 figures",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "The reuse of retired electric vehicle (EV) batteries in electric grid energy storage emerges as a promising strategy to address environmental concerns and boost economic value. This study concentrates on devising health monitoring algorithms for retired batteries (BMS$_2$) deployed in grid storage applications. Over 15 months of testing, we compile, analyze, and publicly share a dataset of second-life (SL) batteries, implementing a cycling protocol simulating grid energy storage load profiles within a 3 V-4 V voltage window. Four machine learning-based health estimation models, relying on BMS$_2$ features and initial capacity, are developed and compared, with the selected model achieving a Mean Absolute Percentage Error (MAPE) below 2.3% on test data. Additionally, an adaptive online health estimation algorithm is proposed by integrating a clustering-based method, limiting estimation errors during online deployment. These results constitute an initial proof of concept, showcasing the feasibility of repurposing retired batteries for second-life applications. Based on obtained data and representative power demand, these SL batteries exhibit the potential, under specific conditions, for over a decade of grid energy storage use.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "eess.SY"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18860": {
        "title": "Error estimation for finite element method on meshes that contain thin elements",
        "authors": [
            "Kenta Kobayashi",
            "Takuya Tsuchiya"
        ],
        "comments": " ",
        "subjects": "Numerical Analysis (math.NA)",
        "abstract": "In an error estimation of finite element solutions to the Poisson equation, we usually impose the shape regularity assumption on the meshes to be used. In this paper, we show that even if the shape regularity condition is violated, the standard error estimation can be obtained if \"bad\" elements (elements that violate the shape regularity or maximum angle condition) are covered virtually by \"good\" simplices. A numerical experiment confirms the theoretical result.\n    ",
        "primary_category": "math.NA",
        "categories": [],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18865": {
        "title": "Analyzing and Reducing Catastrophic Forgetting in Parameter Efficient Tuning",
        "authors": [
            "Weijieying Ren",
            "Xinlong Li",
            "Lei Wang",
            "Tianxiang Zhao",
            "Wei Qin"
        ],
        "comments": " ",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Existing research has shown that large language models (LLMs) exhibit remarkable performance in language understanding and generation. However, when LLMs are continuously fine-tuned on complex and diverse domain-specific downstream tasks, the inference performance on historical tasks decreases dramatically, which is known as a catastrophic forgetting problem. A trade-off needs to be kept between learning plasticity and memory stability. Plenty of existing works have explored strategies like memory replay, regularization and parameter isolation, but little is known about the geometric connection of various adjacent minima in the continual LLMs fine-tuning scenarios. In this work, we investigate the geometric connections of different minima through the lens of mode connectivity, which means different minima can be connected by a low-loss valley. Through extensive experiments, we uncover the mode connectivity phenomenon in the LLMs continual learning scenario and find that it can strike a balance between plasticity and stability. Building upon these findings, we propose a simple yet effective method called Interpolation-based LoRA (I-LoRA), which constructs a dual-memory experience replay framework based on LoRA parameter interpolations. Extensive experiments and analysis on eight domain-specific CL benchmarks demonstrate that I-LoRA consistently show significant improvement over the previous state-of-the-art approaches with up to $11\\%$ performance gains, providing a strong baseline and insights for future research on the large language model continual learning problem. Our code is available at \\url{this https URL}.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.AI",
            "cs.CL"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18866": {
        "title": "Dr. Strategy: Model-Based Generalist Agents with Strategic Dreaming",
        "authors": [
            "Hany Hamed",
            "Subin Kim",
            "Dongyeong Kim",
            "Jaesik Yoon",
            "Sungjin Ahn"
        ],
        "comments": "First two authors contributed equally",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Model-based reinforcement learning (MBRL) has been a primary approach to ameliorating the sample efficiency issue as well as to make a generalist agent. However, there has not been much effort toward enhancing the strategy of dreaming itself. Therefore, it is a question whether and how an agent can \"dream better\" in a more structured and strategic way. In this paper, inspired by the observation from cognitive science suggesting that humans use a spatial divide-and-conquer strategy in planning, we propose a new MBRL agent, called Dr. Strategy, which is equipped with a novel Dreaming Strategy. The proposed agent realizes a version of divide-and-conquer-like strategy in dreaming. This is achieved by learning a set of latent landmarks and then utilizing these to learn a landmark-conditioned highway policy. With the highway policy, the agent can first learn in the dream to move to a landmark, and from there it tackles the exploration and achievement task in a more focused way. In experiments, we show that the proposed model outperforms prior pixel-based MBRL methods in various visually complex and partially observable navigation tasks. The source code will be available at this https URL\n",
        "primary_category": "cs.LG",
        "categories": [],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18867": {
        "title": "Message-Enhanced DeGroot Model",
        "authors": [
            "Huisheng Wang",
            "Zhanjiang Chen",
            "H. Vicky Zhao"
        ],
        "comments": " ",
        "subjects": "Signal Processing (eess.SP)",
        "abstract": "Understanding the impact of messages on agents' opinions over social networks is important. However, to our best knowledge, there has been limited quantitative investigation into this phenomenon in the prior works. To address this gap, this paper proposes the Message-Enhanced DeGroot model. The Bounded Brownian Message model provides a quantitative description of the message evolution, jointly considering temporal continuity, randomness, and polarization from mass media theory. The Message-Enhanced DeGroot model, combining the Bounded Brownian Message model with the traditional DeGroot model, quantitatively describes the evolution of agents' opinions under the influence of messages. We theoretically study the probability distribution and statistics of the messages and agents' opinions and quantitatively analyze the impact of messages on opinions. We also conduct simulations to validate our analyses.\n    ",
        "primary_category": "eess.SP",
        "categories": [
            "cs.SI",
            "eess.SY"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18869": {
        "title": "Evaluating the Gilbert-Varshamov Bound for Constrained Systems",
        "authors": [
            "Keshav Goyal",
            "Han Mao Kiah"
        ],
        "comments": "27 Pages, 5 figures, submitted to Entropy",
        "subjects": "Information Theory (cs.IT)",
        "abstract": "We revisit the well-known Gilbert-Varshamov (GV) bound for constrained systems. In 1991, Kolesnik and Krachkovsky showed that GV bound can be determined via the solution of some optimization problem. Later, Marcus and Roth (1992) modified the optimization problem and improved the GV bound in many instances. In this work, we provide explicit numerical procedures to solve these two optimization problems and hence, compute the bounds. We then show the procedures can be further simplified when we plot the respective curves. In the case where the graph presentation comprise a single state, we provide explicit formulas for both bounds.\n    ",
        "primary_category": "cs.IT",
        "categories": [
            "cs.DM",
            "math.CO"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18871": {
        "title": "LoLiSRFlow: Joint Single Image Low-light Enhancement and Super-resolution via Cross-scale Transformer-based Conditional Flow",
        "authors": [
            "Ziyu Yue",
            "Jiaxin Gao",
            "Sihan Xie",
            "Yang Liu",
            "Zhixun Su"
        ],
        "comments": " ",
        "subjects": "Image and Video Processing (eess.IV)",
        "abstract": "The visibility of real-world images is often limited by both low-light and low-resolution, however, these issues are only addressed in the literature through Low-Light Enhancement (LLE) and Super- Resolution (SR) methods. Admittedly, a simple cascade of these approaches cannot work harmoniously to cope well with the highly ill-posed problem for simultaneously enhancing visibility and resolution. In this paper, we propose a normalizing flow network, dubbed LoLiSRFLow, specifically designed to consider the degradation mechanism inherent in joint LLE and SR. To break the bonds of the one-to-many mapping for low-light low-resolution images to normal-light high-resolution images, LoLiSRFLow directly learns the conditional probability distribution over a variety of feasible solutions for high-resolution well-exposed images. Specifically, a multi-resolution parallel transformer acts as a conditional encoder that extracts the Retinex-induced resolution-and-illumination invariant map as the previous one. And the invertible network maps the distribution of usually exposed high-resolution images to a latent distribution. The backward inference is equivalent to introducing an additional constrained loss for the normal training route, thus enabling the manifold of the natural exposure of the high-resolution image to be immaculately depicted. We also propose a synthetic dataset modeling the realistic low-light low-resolution degradation, named DFSR-LLE, containing 7100 low-resolution dark-light/high-resolution normal sharp pairs. Quantitative and qualitative experimental results demonstrate the effectiveness of our method on both the proposed synthetic and real datasets.\n    ",
        "primary_category": "eess.IV",
        "categories": [
            "cs.CV"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18873": {
        "title": "Reducing Hallucinations in Entity Abstract Summarization with Facts-Template Decomposition",
        "authors": [
            "Fangwei Zhu",
            "Peiyi Wang",
            "Zhifang Sui"
        ],
        "comments": " ",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "Entity abstract summarization aims to generate a coherent description of a given entity based on a set of relevant Internet documents. Pretrained language models (PLMs) have achieved significant success in this task, but they may suffer from hallucinations, i.e. generating non-factual information about the entity. To address this issue, we decompose the summary into two components: Facts that represent the factual information about the given entity, which PLMs are prone to fabricate; and Template that comprises generic content with designated slots for facts, which PLMs can generate competently. Based on the facts-template decomposition, we propose SlotSum, an explainable framework for entity abstract summarization. SlotSum first creates the template and then predicts the fact for each template slot based on the input documents. Benefiting from our facts-template decomposition, SlotSum can easily locate errors and further rectify hallucinated predictions with external knowledge. We construct a new dataset WikiFactSum to evaluate the performance of SlotSum. Experimental results demonstrate that SlotSum could generate summaries that are significantly more factual with credible external knowledge.\n    ",
        "primary_category": "cs.CL",
        "categories": [],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18875": {
        "title": "Loss-aware Curriculum Learning for Heterogeneous Graph Neural Networks",
        "authors": [
            "Zhen Hao Wong",
            "Hansi Yang",
            "Xiaoyi Fu",
            "Quanming Yao"
        ],
        "comments": " ",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Heterogeneous Graph Neural Networks (HGNNs) are a class of deep learning models designed specifically for heterogeneous graphs, which are graphs that contain different types of nodes and edges. This paper investigates the application of curriculum learning techniques to improve the performance and robustness of Heterogeneous Graph Neural Networks (GNNs). To better classify the quality of the data, we design a loss-aware training schedule, named LTS that measures the quality of every nodes of the data and incorporate the training dataset into the model in a progressive manner that increases difficulty step by step. LTS can be seamlessly integrated into various frameworks, effectively reducing bias and variance, mitigating the impact of noisy data, and enhancing overall accuracy. Our findings demonstrate the efficacy of curriculum learning in enhancing HGNNs capabilities for analyzing complex graph-structured data. The code is public at https: //github.com/LARS-research/CLGNN/.\n    ",
        "primary_category": "cs.LG",
        "categories": [],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18877": {
        "title": "Principal Component Analysis as a Sanity Check for Bayesian Phylolinguistic Reconstruction",
        "authors": [
            "Yugo Murawaki"
        ],
        "comments": "Accepted at LREC-COLING 2024",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "Bayesian approaches to reconstructing the evolutionary history of languages rely on the tree model, which assumes that these languages descended from a common ancestor and underwent modifications over time. However, this assumption can be violated to different extents due to contact and other factors. Understanding the degree to which this assumption is violated is crucial for validating the accuracy of phylolinguistic inference. In this paper, we propose a simple sanity check: projecting a reconstructed tree onto a space generated by principal component analysis. By using both synthetic and real data, we demonstrate that our method effectively visualizes anomalies, particularly in the form of jogging.\n    ",
        "primary_category": "cs.CL",
        "categories": [],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18879": {
        "title": "Dose Prediction Driven Radiotherapy Paramters Regression via Intra- and Inter-Relation Modeling",
        "authors": [
            "Jiaqi Cui",
            "Yuanyuan Xu",
            "Jianghong Xiao",
            "Yuchen Fei",
            "Jiliu Zhou",
            "Xingcheng Peng",
            "Yan Wang"
        ],
        "comments": "Accepted by ISBI 2024",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Deep learning has facilitated the automation of radiotherapy by predicting accurate dose distribution maps. However, existing methods fail to derive the desirable radiotherapy parameters that can be directly input into the treatment planning system (TPS), impeding the full automation of radiotherapy. To enable more thorough automatic radiotherapy, in this paper, we propose a novel two-stage framework to directly regress the radiotherapy parameters, including a dose map prediction stage and a radiotherapy parameters regression stage. In stage one, we combine transformer and convolutional neural network (CNN) to predict realistic dose maps with rich global and local information, providing accurate dosimetric knowledge for the subsequent parameters regression. In stage two, two elaborate modules, i.e., an intra-relation modeling (Intra-RM) module and an inter-relation modeling (Inter-RM) module, are designed to exploit the organ-specific and organ-shared features for precise parameters regression. Experimental results on a rectal cancer dataset demonstrate the effectiveness of our method.\n    ",
        "primary_category": "cs.CV",
        "categories": [],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18883": {
        "title": "Efficient Processing of Subsequent Densest Subgraph Query",
        "authors": [
            "Chia-Yang Hung",
            "Chih-Ya Shen"
        ],
        "comments": "11 pages",
        "subjects": "Data Structures and Algorithms (cs.DS)",
        "abstract": "Dense subgraph extraction is a fundamental problem in graph analysis and data mining, aimed at identifying cohesive and densely connected substructures within a given graph. It plays a crucial role in various domains, including social network analysis, biological network analysis, recommendation systems, and community detection. However, extracting a subgraph with the highest node similarity is a lack of exploration. To address this problem, we studied the Member Selection Problem and extended it with a dynamic constraint variant. By incorporating dynamic constraints, our algorithm can adapt to changing conditions or requirements, allowing for more flexible and personalized subgraph extraction. This approach enables the algorithm to provide tailored solutions that meet specific needs, even in scenarios where constraints may vary over time. We also provide the theoretical analysis to show that our algorithm is 1/3-approximation. Eventually, the experiments show that our algorithm is effective and efficient in tackling the member selection problem with dynamic constraints.\n    ",
        "primary_category": "cs.DS",
        "categories": [],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18884": {
        "title": "Supervised Contrastive Representation Learning: Landscape Analysis with Unconstrained Features",
        "authors": [
            "Tina Behnia",
            "Christos Thrampoulidis"
        ],
        "comments": "10 pages",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Recent findings reveal that over-parameterized deep neural networks, trained beyond zero training-error, exhibit a distinctive structural pattern at the final layer, termed as Neural-collapse (NC). These results indicate that the final hidden-layer outputs in such networks display minimal within-class variations over the training set. While existing research extensively investigates this phenomenon under cross-entropy loss, there are fewer studies focusing on its contrastive counterpart, supervised contrastive (SC) loss. Through the lens of NC, this paper employs an analytical approach to study the solutions derived from optimizing the SC loss. We adopt the unconstrained features model (UFM) as a representative proxy for unveiling NC-related phenomena in sufficiently over-parameterized deep networks. We show that, despite the non-convexity of SC loss minimization, all local minima are global minima. Furthermore, the minimizer is unique (up to a rotation). We prove our results by formalizing a tight convex relaxation of the UFM. Finally, through this convex formulation, we delve deeper into characterizing the properties of global solutions under label-imbalanced training data.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "stat.ML"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18886": {
        "title": "BP-DeepONet: A new method for cuffless blood pressure estimation using the physcis-informed DeepONet",
        "authors": [
            "Lingfeng Li",
            "Xue-Cheng Tai",
            "Raymond Chan"
        ],
        "comments": " ",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Cardiovascular diseases (CVDs) are the leading cause of death worldwide, with blood pressure serving as a crucial indicator. Arterial blood pressure (ABP) waveforms provide continuous pressure measurements throughout the cardiac cycle and offer valuable diagnostic insights. Consequently, there is a significant demand for non-invasive and cuff-less methods to measure ABP waveforms continuously. Accurate prediction of ABP waveforms can also improve the estimation of mean blood pressure, an essential cardiovascular health characteristic.\nThis study proposes a novel framework based on the physics-informed DeepONet approach to predict ABP waveforms. Unlike previous methods, our approach requires the predicted ABP waveforms to satisfy the Navier-Stokes equation with a time-periodic condition and a Windkessel boundary condition. Notably, our framework is the first to predict ABP waveforms continuously, both with location and time, within the part of the artery that is being simulated. Furthermore, our method only requires ground truth data at the outlet boundary and can handle periodic conditions with varying periods. Incorporating the Windkessel boundary condition in our solution allows for generating natural physical reflection waves, which closely resemble measurements observed in real-world cases. Moreover, accurately estimating the hyper-parameters in the Navier-Stokes equation for our simulations poses a significant challenge. To overcome this obstacle, we introduce the concept of meta-learning, enabling the neural networks to learn these parameters during the training process.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "physics.med-ph"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18896": {
        "title": "On the maximum size of variable-length non-overlapping codes",
        "authors": [
            "Geyang Wang",
            "Qi Wang"
        ],
        "comments": " ",
        "subjects": "Information Theory (cs.IT)",
        "abstract": "Non-overlapping codes are a set of codewords such that the prefix of each codeword is not a suffix of any codeword in the set, including itself. If the lengths of the codewords are variable, it is additionally required that every codeword is not contained in any other codeword as a subword. Let $C(n,q)$ be the maximum size of $q$-ary fixed-length non-overlapping codes of length $n$. The upper bound on $C(n,q)$ has been well studied. However, the nontrivial upper bound on the maximum size of variable-length non-overlapping codes of length at most $n$ remains open. In this paper, by establishing a link between variable-length non-overlapping codes and fixed-length ones, we are able to show that the size of a $q$-ary variable-length non-overlapping code is upper bounded by $C(n,q)$. Furthermore, we prove that the average length of the codewords in a $q$-ary variable-length non-overlapping codes is lower bounded by $\\lceil \\log_q \\tilde{C} \\rceil$, and is asymptotically no shorter than $n-2$ as $q$ approaches $\\infty$, where $\\tilde{C}$ denotes the cardinality of $q$-ary variable-length non-overlapping codes of length up to $n$.\n    ",
        "primary_category": "cs.IT",
        "categories": [
            "math.CO"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18899": {
        "title": "Aligning Language Models for Versatile Text-based Item Retrieval",
        "authors": [
            "Yuxuan Lei",
            "Jianxun Lian",
            "Jing Yao",
            "Mingqi Wu",
            "Defu Lian",
            "Xing Xie"
        ],
        "comments": "4 pages,1 figures, 4 tables",
        "subjects": "Information Retrieval (cs.IR)",
        "abstract": "This paper addresses the gap between general-purpose text embeddings and the specific demands of item retrieval tasks. We demonstrate the shortcomings of existing models in capturing the nuances necessary for zero-shot performance on item retrieval tasks. To overcome these limitations, we propose generate in-domain dataset from ten tasks tailored to unlocking models' representation ability for item retrieval. Our empirical studies demonstrate that fine-tuning embedding models on the dataset leads to remarkable improvements in a variety of retrieval tasks. We also illustrate the practical application of our refined model in a conversational setting, where it enhances the capabilities of LLM-based Recommender Agents like Chat-Rec. Our code is available at this https URL.\n    ",
        "primary_category": "cs.IR",
        "categories": [],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18905": {
        "title": "On the Convergence of Differentially-Private Fine-tuning: To Linearly Probe or to Fully Fine-tune?",
        "authors": [
            "Shuqi Ke",
            "Charlie Hou",
            "Giulia Fanti",
            "Sewoong Oh"
        ],
        "comments": " ",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Differentially private (DP) machine learning pipelines typically involve a two-phase process: non-private pre-training on a public dataset, followed by fine-tuning on private data using DP optimization techniques. In the DP setting, it has been observed that full fine-tuning may not always yield the best test accuracy, even for in-distribution data. This paper (1) analyzes the training dynamics of DP linear probing (LP) and full fine-tuning (FT), and (2) explores the phenomenon of sequential fine-tuning, starting with linear probing and transitioning to full fine-tuning (LP-FT), and its impact on test loss. We provide theoretical insights into the convergence of DP fine-tuning within an overparameterized neural network and establish a utility curve that determines the allocation of privacy budget between linear probing and full fine-tuning. The theoretical results are supported by empirical evaluations on various benchmarks and models. The findings reveal the complex nature of DP fine-tuning methods. These results contribute to a deeper understanding of DP machine learning and highlight the importance of considering the allocation of privacy budget in the fine-tuning process.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.AI",
            "cs.CR",
            "math.OC"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18908": {
        "title": "Facility Location Games with Scaling Effects",
        "authors": [
            "Yu He",
            "Alexander Lam",
            "Minming Li"
        ],
        "comments": " ",
        "subjects": "Computer Science and Game Theory (cs.GT)",
        "abstract": "We take the classic facility location problem and consider a variation, in which each agent's individual cost function is equal to their distance from the facility multiplied by a scaling factor which is determined by the facility placement. In addition to the general class of continuous scaling functions, we also provide results for piecewise linear scaling functions which can effectively approximate or model the scaling of many real world scenarios. We focus on the objectives of total and maximum cost, describing the computation of the optimal solution. We then move to the approximate mechanism design setting, observing that the agents' preferences may no longer be single-peaked. Consequently, we characterize the conditions on scaling functions which ensure that agents have single-peaked preferences. Under these conditions, we find results on the total and maximum cost approximation ratios achievable by strategyproof and anonymous mechanisms.\n    ",
        "primary_category": "cs.GT",
        "categories": [
            "cs.AI",
            "cs.MA",
            "econ.TH"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18909": {
        "title": "Updating Language Models with Unstructured Facts: Towards Practical Knowledge Editing",
        "authors": [
            "Xiaobao Wu",
            "Liangming Pan",
            "William Yang Wang",
            "Anh Tuan Luu"
        ],
        "comments": " ",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "Knowledge editing aims to inject knowledge updates into language models to keep them correct and up-to-date. However, its current evaluation strategies are notably impractical: they solely update with well-curated structured facts (triplets with subjects, relations, and objects), whereas real-world knowledge updates commonly emerge in unstructured texts like news articles. In this paper, we propose a new benchmark, Unstructured Knowledge Editing (UKE). It evaluates editing performance directly using unstructured texts as knowledge updates, termed unstructured facts. Hence UKE avoids the laborious construction of structured facts and enables efficient and responsive knowledge editing, becoming a more practical benchmark. We conduct extensive experiments on newly built datasets and demonstrate that UKE poses a significant challenge to state-of-the-art knowledge editing methods, resulting in their critical performance declines. We further show that this challenge persists even if we extract triplets as structured facts. Our analysis discloses key insights to motivate future research in UKE for more practical knowledge editing.\n    ",
        "primary_category": "cs.CL",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18910": {
        "title": "DIGIC: Domain Generalizable Imitation Learning by Causal Discovery",
        "authors": [
            "Yang Chen",
            "Yitao Liang",
            "Zhouchen Lin"
        ],
        "comments": " ",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Causality has been combined with machine learning to produce robust representations for domain generalization. Most existing methods of this type require massive data from multiple domains to identify causal features by cross-domain variations, which can be expensive or even infeasible and may lead to misidentification in some cases. In this work, we make a different attempt by leveraging the demonstration data distribution to discover the causal features for a domain generalizable policy. We design a novel framework, called DIGIC, to identify the causal features by finding the direct cause of the expert action from the demonstration data distribution via causal discovery. Our framework can achieve domain generalizable imitation learning with only single-domain data and serve as a complement for cross-domain variation-based methods under non-structural assumptions on the underlying causal models. Our empirical study in various control tasks shows that the proposed framework evidently improves the domain generalization performance and has comparable performance to the expert in the original domain simultaneously.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.AI",
            "stat.ME"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18913": {
        "title": "AdaMergeX: Cross-Lingual Transfer with Large Language Models via Adaptive Adapter Merging",
        "authors": [
            "Yiran Zhao",
            "Wenxuan Zhang",
            "Huiming Wang",
            "Kenji Kawaguchi",
            "Lidong Bing"
        ],
        "comments": " ",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "As an effective alternative to the direct fine-tuning on target tasks in specific languages, cross-lingual transfer addresses the challenges of limited training data by decoupling ''task ability'' and ''language ability'' by fine-tuning on the target task in the source language and another selected task in the target language, respectively. However, they fail to fully separate the task ability from the source language or the language ability from the chosen task. In this paper, we acknowledge the mutual reliance between task ability and language ability and direct our attention toward the gap between the target language and the source language on tasks. As the gap removes the impact of tasks, we assume that it remains consistent across tasks. Based on this assumption, we propose a new cross-lingual transfer method called $\\texttt{AdaMergeX}$ that utilizes adaptive adapter merging. By introducing a reference task, we can determine that the divergence of adapters fine-tuned on the reference task in both languages follows the same distribution as the divergence of adapters fine-tuned on the target task in both languages. Hence, we can obtain target adapters by combining the other three adapters. Furthermore, we propose a structure-adaptive adapter merging method. Our empirical results demonstrate that our approach yields new and effective cross-lingual transfer, outperforming existing methods across all settings.\n    ",
        "primary_category": "cs.CL",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18917": {
        "title": "Stop Relying on No-Choice and Do not Repeat the Moves: Optimal, Efficient and Practical Algorithms for Assortment Optimization",
        "authors": [
            "Aadirupa Saha",
            "Pierre Gaillard"
        ],
        "comments": " ",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "We address the problem of active online assortment optimization problem with preference feedback, which is a framework for modeling user choices and subsetwise utility maximization. The framework is useful in various real-world applications including ad placement, online retail, recommender systems, fine-tuning language models, amongst many. The problem, although has been studied in the past, lacks an intuitive and practical solution approach with simultaneously efficient algorithm and optimal regret guarantee. E.g., popularly used assortment selection algorithms often require the presence of a `strong reference' which is always included in the choice sets, further they are also designed to offer the same assortments repeatedly until the reference item gets selected -- all such requirements are quite unrealistic for practical applications. In this paper, we designed efficient algorithms for the problem of regret minimization in assortment selection with \\emph{Plackett Luce} (PL) based user choices. We designed a novel concentration guarantee for estimating the score parameters of the PL model using `\\emph{Pairwise Rank-Breaking}', which builds the foundation of our proposed algorithms. Moreover, our methods are practical, provably optimal, and devoid of the aforementioned limitations of the existing methods. Empirical evaluations corroborate our findings and outperform the existing baselines.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.IR"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18922": {
        "title": "A Simple yet Effective Network based on Vision Transformer for Camouflaged Object and Salient Object Detection",
        "authors": [
            "Chao Hao",
            "Zitong Yu",
            "Xin Liu",
            "Jun Xu",
            "Huanjing Yue",
            "Jingyu Yang"
        ],
        "comments": "submitted to IEEE TIP",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Camouflaged object detection (COD) and salient object detection (SOD) are two distinct yet closely-related computer vision tasks widely studied during the past decades. Though sharing the same purpose of segmenting an image into binary foreground and background regions, their distinction lies in the fact that COD focuses on concealed objects hidden in the image, while SOD concentrates on the most prominent objects in the image. Previous works achieved good performance by stacking various hand-designed modules and multi-scale features. However, these carefully-designed complex networks often performed well on one task but not on another. In this work, we propose a simple yet effective network (SENet) based on vision Transformer (ViT), by employing a simple design of an asymmetric ViT-based encoder-decoder structure, we yield competitive results on both tasks, exhibiting greater versatility than meticulously crafted ones. Furthermore, to enhance the Transformer's ability to model local information, which is important for pixel-level binary segmentation tasks, we propose a local information capture module (LICM). We also propose a dynamic weighted loss (DW loss) based on Binary Cross-Entropy (BCE) and Intersection over Union (IoU) loss, which guides the network to pay more attention to those smaller and more difficult-to-find target objects according to their size. Moreover, we explore the issue of joint training of SOD and COD, and propose a preliminary solution to the conflict in joint training, further improving the performance of SOD. Extensive experiments on multiple benchmark datasets demonstrate the effectiveness of our method. The code is available at this https URL.\n    ",
        "primary_category": "cs.CV",
        "categories": [],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18923": {
        "title": "Inappropriate Pause Detection In Dysarthric Speech Using Large-Scale Speech Recognition",
        "authors": [
            "Jeehyun Lee",
            "Yerin Choi",
            "Tae-Jin Song",
            "Myoung-Wan Koo"
        ],
        "comments": "Accepted to ICASSP 2024",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "Dysarthria, a common issue among stroke patients, severely impacts speech intelligibility. Inappropriate pauses are crucial indicators in severity assessment and speech-language therapy. We propose to extend a large-scale speech recognition model for inappropriate pause detection in dysarthric speech. To this end, we propose task design, labeling strategy, and a speech recognition model with an inappropriate pause prediction layer. First, we treat pause detection as speech recognition, using an automatic speech recognition (ASR) model to convert speech into text with pause tags. According to the newly designed task, we label pause locations at the text level and their appropriateness. We collaborate with speech-language pathologists to establish labeling criteria, ensuring high-quality annotated data. Finally, we extend the ASR model with an inappropriate pause prediction layer for end-to-end inappropriate pause detection. Moreover, we propose a task-tailored metric for evaluating inappropriate pause detection independent of ASR performance. Our experiments show that the proposed method better detects inappropriate pauses in dysarthric speech than baselines. (Inappropriate Pause Error Rate: 14.47%)\n    ",
        "primary_category": "cs.CL",
        "categories": [
            "cs.SD",
            "eess.AS"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18925": {
        "title": "PCDepth: Pattern-based Complementary Learning for Monocular Depth Estimation by Best of Both Worlds",
        "authors": [
            "Haotian Liu",
            "Sanqing Qu",
            "Fan Lu",
            "Zongtao Bu",
            "Florian Roehrbein",
            "Alois Knoll",
            "Guang Chen"
        ],
        "comments": "Under Review",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Event cameras can record scene dynamics with high temporal resolution, providing rich scene details for monocular depth estimation (MDE) even at low-level illumination. Therefore, existing complementary learning approaches for MDE fuse intensity information from images and scene details from event data for better scene understanding. However, most methods directly fuse two modalities at pixel level, ignoring that the attractive complementarity mainly impacts high-level patterns that only occupy a few pixels. For example, event data is likely to complement contours of scene objects. In this paper, we discretize the scene into a set of high-level patterns to explore the complementarity and propose a Pattern-based Complementary learning architecture for monocular Depth estimation (PCDepth). Concretely, PCDepth comprises two primary components: a complementary visual representation learning module for discretizing the scene into high-level patterns and integrating complementary patterns across modalities and a refined depth estimator aimed at scene reconstruction and depth prediction while maintaining an efficiency-accuracy balance. Through pattern-based complementary learning, PCDepth fully exploits two modalities and achieves more accurate predictions than existing methods, especially in challenging nighttime scenarios. Extensive experiments on MVSEC and DSEC datasets verify the effectiveness and superiority of our PCDepth. Remarkably, compared with state-of-the-art, PCDepth achieves a 37.9% improvement in accuracy in MVSEC nighttime scenarios.\n    ",
        "primary_category": "cs.CV",
        "categories": [],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18927": {
        "title": "Edge Computing Enabled Real-Time Video Analysis via Adaptive Spatial-Temporal Semantic Filtering",
        "authors": [
            "Xiang Chen",
            "Wenjie Zhu",
            "Jiayuan Chen",
            "Tong Zhang",
            "Changyan Yi",
            "Jun Cai"
        ],
        "comments": " ",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "This paper proposes a novel edge computing enabled real-time video analysis system for intelligent visual devices. The proposed system consists of a tracking-assisted object detection module (TAODM) and a region of interesting module (ROIM). TAODM adaptively determines the offloading decision to process each video frame locally with a tracking algorithm or to offload it to the edge server inferred by an object detection model. ROIM determines each offloading frame's resolution and detection model configuration to ensure that the analysis results can return in time. TAODM and ROIM interact jointly to filter the repetitive spatial-temporal semantic information to maximize the processing rate while ensuring high video analysis accuracy. Unlike most existing works, this paper investigates the real-time video analysis systems where the intelligent visual device connects to the edge server through a wireless network with fluctuating network conditions. We decompose the real-time video analysis problem into the offloading decision and configurations selection sub-problems. To solve these two sub-problems, we introduce a double deep Q network (DDQN) based offloading approach and a contextual multi-armed bandit (CMAB) based adaptive configurations selection approach, respectively. A DDQN-CMAB reinforcement learning (DCRL) training framework is further developed to integrate these two approaches to improve the overall video analyzing performance. Extensive simulations are conducted to evaluate the performance of the proposed solution, and demonstrate its superiority over counterparts.\n    ",
        "primary_category": "cs.CV",
        "categories": [
            "cs.MM",
            "cs.NI"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18930": {
        "title": "Variable-Rate Learned Image Compression with Multi-Objective Optimization and Quantization-Reconstruction Offsets",
        "authors": [
            "Fatih Kamisli",
            "Fabien Racape",
            "Hyomin Choi"
        ],
        "comments": "Accepted as a paper at DCC 2024",
        "subjects": "Image and Video Processing (eess.IV)",
        "abstract": "Achieving successful variable bitrate compression with computationally simple algorithms from a single end-to-end learned image or video compression model remains a challenge. Many approaches have been proposed, including conditional auto-encoders, channel-adaptive gains for the latent tensor or uniformly quantizing all elements of the latent tensor. This paper follows the traditional approach to vary a single quantization step size to perform uniform quantization of all latent tensor elements. However, three modifications are proposed to improve the variable rate compression performance. First, multi objective optimization is used for (post) training. Second, a quantization-reconstruction offset is introduced into the quantization operation. Third, variable rate quantization is used also for the hyper latent. All these modifications can be made on a pre-trained single-rate compression model by performing post training. The algorithms are implemented into three well-known image compression models and the achieved variable rate compression results indicate negligible or minimal compression performance loss compared to training multiple models. (Codes will be shared at this https URL)\n    ",
        "primary_category": "eess.IV",
        "categories": [
            "cs.CV"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18932": {
        "title": "Extending Multilingual Speech Synthesis to 100+ Languages without Transcribed Data",
        "authors": [
            "Takaaki Saeki",
            "Gary Wang",
            "Nobuyuki Morioka",
            "Isaac Elias",
            "Kyle Kastner",
            "Andrew Rosenberg",
            "Bhuvana Ramabhadran",
            "Heiga Zen",
            "Fran\u00e7oise Beaufays",
            "Hadar Shemtov"
        ],
        "comments": "To appear in ICASSP 2024",
        "subjects": "Audio and Speech Processing (eess.AS)",
        "abstract": "Collecting high-quality studio recordings of audio is challenging, which limits the language coverage of text-to-speech (TTS) systems. This paper proposes a framework for scaling a multilingual TTS model to 100+ languages using found data without supervision. The proposed framework combines speech-text encoder pretraining with unsupervised training using untranscribed speech and unspoken text data sources, thereby leveraging massively multilingual joint speech and text representation learning. Without any transcribed speech in a new language, this TTS model can generate intelligible speech in >30 unseen languages (CER difference of <10% to ground truth). With just 15 minutes of transcribed, found data, we can reduce the intelligibility difference to 1% or less from the ground-truth, and achieve naturalness scores that match the ground-truth in several languages.\n    ",
        "primary_category": "eess.AS",
        "categories": [
            "cs.SD"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18936": {
        "title": "Energy-Efficient UAV Swarm Assisted MEC with Dynamic Clustering and Scheduling",
        "authors": [
            "Jialiuyuan Li",
            "Jiayuan Chen",
            "Changyan Yi",
            "Tong Zhang",
            "Kun Zhu",
            "Jun Cai"
        ],
        "comments": " ",
        "subjects": "Networking and Internet Architecture (cs.NI)",
        "abstract": "In this paper, the energy-efficient unmanned aerial vehicle (UAV) swarm assisted mobile edge computing (MEC) with dynamic clustering and scheduling is studied. In the considered system model, UAVs are divided into multiple swarms, with each swarm consisting of a leader UAV and several follower UAVs to provide computing services to end-users. Unlike existing work, we allow UAVs to dynamically cluster into different swarms, i.e., each follower UAV can change its leader based on the time-varying spatial positions, updated application placement, etc. in a dynamic manner. Meanwhile, UAVs are required to dynamically schedule their energy replenishment, application placement, trajectory planning and task delegation. With the aim of maximizing the long-term energy efficiency of the UAV swarm assisted MEC system, a joint optimization problem of dynamic clustering and scheduling is formulated. Taking into account the underlying cooperation and competition among intelligent UAVs, we further reformulate this optimization problem as a combination of a series of strongly coupled multi-agent stochastic games, and then propose a novel reinforcement learning-based UAV swarm dynamic coordination (RLDC) algorithm for obtaining the equilibrium. Simulations are conducted to evaluate the performance of the RLDC algorithm and demonstrate its superiority over counterparts.\n    ",
        "primary_category": "cs.NI",
        "categories": [
            "eess.SP"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18937": {
        "title": "Equivalence of ADER and Lax-Wendroff in DG / FR framework for linear problems",
        "authors": [
            "Arpit Babbar",
            "Praveen Chandrashekar"
        ],
        "comments": " ",
        "subjects": "Numerical Analysis (math.NA)",
        "abstract": "ADER (Arbitrary high order by DERivatives) and Lax-Wendroff (LW) schemes are two high order single stage methods for solving time dependent partial differential equations. ADER is based on solving a locally implicit equation to obtain a space-time predictor solution while LW is based on an explicit Taylor's expansion in time. We cast the corrector step of ADER Discontinuous Galerkin (DG) scheme into an equivalent quadrature free Flux Reconstruction (FR) framework and then show that the obtained ADER-FR scheme is equivalent to the LWFR scheme with D2 dissipation numerical flux for linear problems. This also implies that the two schemes have the same Fourier stability limit for time step size. The equivalence is verified by numerical experiments.\n    ",
        "primary_category": "math.NA",
        "categories": [],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18944": {
        "title": "SemEval 2024 -- Task 10: Emotion Discovery and Reasoning its Flip in Conversation (EDiReF)",
        "authors": [
            "Shivani Kumar",
            "Md Shad Akhtar",
            "Erik Cambria",
            "Tanmoy Chakraborty"
        ],
        "comments": "11 pages, 3 figures, 7 tables",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "We present SemEval-2024 Task 10, a shared task centred on identifying emotions and finding the rationale behind their flips within monolingual English and Hindi-English code-mixed dialogues. This task comprises three distinct subtasks - emotion recognition in conversation for code-mixed dialogues, emotion flip reasoning for code-mixed dialogues, and emotion flip reasoning for English dialogues. Participating systems were tasked to automatically execute one or more of these subtasks. The datasets for these tasks comprise manually annotated conversations focusing on emotions and triggers for emotion shifts (The task data is available at this https URL). A total of 84 participants engaged in this task, with the most adept systems attaining F1-scores of 0.70, 0.79, and 0.76 for the respective subtasks. This paper summarises the results and findings from 24 teams alongside their system descriptions.\n    ",
        "primary_category": "cs.CL",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18945": {
        "title": "Syntactic Ghost: An Imperceptible General-purpose Backdoor Attacks on Pre-trained Language Models",
        "authors": [
            "Pengzhou Cheng",
            "Wei Du",
            "Zongru Wu",
            "Fengwei Zhang",
            "Libo Chen",
            "Gongshen Liu"
        ],
        "comments": "16 pages, 16 figures, 13 tables",
        "subjects": "Cryptography and Security (cs.CR)",
        "abstract": "Pre-trained language models (PLMs) have been found susceptible to backdoor attacks, which can transfer vulnerabilities to various downstream tasks. However, existing PLM backdoors are conducted with explicit triggers under the manually aligned, thus failing to satisfy expectation goals simultaneously in terms of effectiveness, stealthiness, and universality. In this paper, we propose a novel approach to achieve invisible and general backdoor implantation, called \\textbf{Syntactic Ghost} (synGhost for short). Specifically, the method hostilely manipulates poisoned samples with different predefined syntactic structures as stealth triggers and then implants the backdoor to pre-trained representation space without disturbing the primitive knowledge. The output representations of poisoned samples are distributed as uniformly as possible in the feature space via contrastive learning, forming a wide range of backdoors. Additionally, in light of the unique properties of syntactic triggers, we introduce an auxiliary module to drive the PLMs to learn this knowledge in priority, which can alleviate the interference between different syntactic structures. Experiments show that our method outperforms the previous methods and achieves the predefined objectives. Not only do severe threats to various natural language understanding (NLU) tasks on two tuning paradigms but also to multiple PLMs. Meanwhile, the synGhost is imperceptible against three countermeasures based on perplexity, fine-pruning, and the proposed maxEntropy.\n    ",
        "primary_category": "cs.CR",
        "categories": [
            "cs.AI",
            "cs.CL"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18949": {
        "title": "Improving Group Connectivity for Generalization of Federated Deep Learning",
        "authors": [
            "Zexi Li",
            "Jie Lin",
            "Zhiqi Li",
            "Didi Zhu",
            "Chao Wu"
        ],
        "comments": "Preprint",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Federated learning (FL) involves multiple heterogeneous clients collaboratively training a global model via iterative local updates and model fusion. The generalization of FL's global model has a large gap compared with centralized training, which is its bottleneck for broader applications. In this paper, we study and improve FL's generalization through a fundamental ``connectivity'' perspective, which means how the local models are connected in the parameter region and fused into a generalized global model. The term ``connectivity'' is derived from linear mode connectivity (LMC), studying the interpolated loss landscape of two different solutions (e.g., modes) of neural networks. Bridging the gap between LMC and FL, in this paper, we leverage fixed anchor models to empirically and theoretically study the transitivity property of connectivity from two models (LMC) to a group of models (model fusion in FL). Based on the findings, we propose FedGuCci and FedGuCci+, improving group connectivity for better generalization. It is shown that our methods can boost the generalization of FL under client heterogeneity across various tasks (4 CV datasets and 6 NLP datasets), models (both convolutional and transformer-based), and training paradigms (both from-scratch and pretrain-finetune).\n    ",
        "primary_category": "cs.LG",
        "categories": [],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18950": {
        "title": "PopALM: Popularity-Aligned Language Models for Social Media Trendy Response Prediction",
        "authors": [
            "Erxin Yu",
            "Jing Li",
            "Chunpu Xu"
        ],
        "comments": "Accepted by COLING 2024",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "Social media platforms are daily exhibiting millions of events. To preliminarily predict the mainstream public reaction to these events, we study trendy response prediction to automatically generate top-liked user replies to social media events. While previous works focus on generating responses without factoring in popularity, we propose Popularity-Aligned Language Models (PopALM) to distinguish responses liked by a larger audience through reinforcement learning. Recognizing the noisy labels from user \"likes\", we tailor-make curriculum learning in proximal policy optimization (PPO) to help models capture the essential samples for easy-to-hard training. In experiments, we build a large-scale Weibo dataset for trendy response prediction, and its results show that PopALM can help boost the performance of advanced language models.\n    ",
        "primary_category": "cs.CL",
        "categories": [],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18951": {
        "title": "Percept, Chat, and then Adapt: Multimodal Knowledge Transfer of Foundation Models for Open-World Video Recognition",
        "authors": [
            "Boyu Chen",
            "Siran Chen",
            "Kunchang Li",
            "Qinglin Xu",
            "Yu Qiao",
            "Yali Wang"
        ],
        "comments": "35 pages, 6 figures, 8 tables",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Open-world video recognition is challenging since traditional networks are not generalized well on complex environment variations. Alternatively, foundation models with rich knowledge have recently shown their generalization power. However, how to apply such knowledge has not been fully explored for open-world video recognition. To this end, we propose a generic knowledge transfer pipeline, which progressively exploits and integrates external multimodal knowledge from foundation models to boost open-world video recognition. We name it PCA, based on three stages of Percept, Chat, and Adapt. First, we perform Percept process to reduce the video domain gap and obtain external visual knowledge. Second, we generate rich linguistic semantics as external textual knowledge in Chat stage. Finally, we blend external multimodal knowledge in Adapt stage, by inserting multimodal knowledge adaptation modules into networks. We conduct extensive experiments on three challenging open-world video benchmarks, i.e., TinyVIRAT, ARID, and QV-Pipe. Our approach achieves state-of-the-art performance on all three datasets.\n    ",
        "primary_category": "cs.CV",
        "categories": [],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18954": {
        "title": "Getting Saturated with Induction",
        "authors": [
            "M\u00e1rton Hajdu",
            "Petra Hozzov\u00e1",
            "Laura Kov\u00e1cs",
            "Giles Reger",
            "Andrei Voronkov"
        ],
        "comments": "26 pages; this is an extended version of the published paper",
        "subjects": "Logic in Computer Science (cs.LO)",
        "abstract": "Induction in saturation-based first-order theorem proving is a new exciting direction in the automation of inductive reasoning. In this paper we survey our work on integrating induction directly into the saturation-based proof search framework of first-order theorem proving. We describe our induction inference rules proving properties with inductively defined datatypes and integers. We also present additional reasoning heuristics for strengthening inductive reasoning, as well as for using induction hypotheses and recursive function definitions for guiding induction. We present exhaustive experimental results demonstrating the practical impact of our approach as implemented within Vampire.\nThis is an extended version of a Principles of Systems Design 2022 paper with the same title and the same authors.\n    ",
        "primary_category": "cs.LO",
        "categories": [],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18958": {
        "title": "Boosting Semi-Supervised Object Detection in Remote Sensing Images With Active Teaching",
        "authors": [
            "Boxuan Zhang",
            "Zengmao Wang",
            "Bo Du"
        ],
        "comments": " ",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "The lack of object-level annotations poses a significant challenge for object detection in remote sensing images (RSIs). To address this issue, active learning (AL) and semi-supervised learning (SSL) techniques have been proposed to enhance the quality and quantity of annotations. AL focuses on selecting the most informative samples for annotation, while SSL leverages the knowledge from unlabeled samples. In this letter, we propose a novel AL method to boost semi-supervised object detection (SSOD) for remote sensing images with a teacher student network, called SSOD-AT. The proposed method incorporates an RoI comparison module (RoICM) to generate high-confidence pseudo-labels for regions of interest (RoIs). Meanwhile, the RoICM is utilized to identify the top-K uncertain images. To reduce redundancy in the top-K uncertain images for human labeling, a diversity criterion is introduced based on object-level prototypes of different categories using both labeled and pseudo-labeled images. Extensive experiments on DOTA and DIOR, two popular datasets, demonstrate that our proposed method outperforms state-of-the-art methods for object detection in RSIs. Compared with the best performance in the SOTA methods, the proposed method achieves 1 percent improvement in most cases in the whole AL.\n    ",
        "primary_category": "cs.CV",
        "categories": [],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18959": {
        "title": "MambaStock: Selective state space model for stock prediction",
        "authors": [
            "Zhuangwei Shi"
        ],
        "comments": "arXiv admin note: substantial text overlap with arXiv:2204.02623",
        "subjects": "Computational Engineering, Finance, and Science (cs.CE)",
        "abstract": "The stock market plays a pivotal role in economic development, yet its intricate volatility poses challenges for investors. Consequently, research and accurate predictions of stock price movements are crucial for mitigating risks. Traditional time series models fall short in capturing nonlinearity, leading to unsatisfactory stock predictions. This limitation has spurred the widespread adoption of neural networks for stock prediction, owing to their robust nonlinear generalization capabilities. Recently, Mamba, a structured state space sequence model with a selection mechanism and scan module (S6), has emerged as a powerful tool in sequence modeling tasks. Leveraging this framework, this paper proposes a novel Mamba-based model for stock price prediction, named MambaStock. The proposed MambaStock model effectively mines historical stock market data to predict future stock prices without handcrafted features or extensive preprocessing procedures. Empirical studies on several stocks indicate that the MambaStock model outperforms previous methods, delivering highly accurate predictions. This enhanced accuracy can assist investors and institutions in making informed decisions, aiming to maximize returns while minimizing risks. This work underscores the value of Mamba in time-series forecasting. Source code is available at this https URL.\n    ",
        "primary_category": "cs.CE",
        "categories": [
            "q-fin.ST"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18960": {
        "title": "Towards Out-of-Distribution Detection for breast cancer classification in Point-of-Care Ultrasound Imaging",
        "authors": [
            "Jennie Karlsson",
            "Marisa Wodrich",
            "Niels Christian Overgaard",
            "Freja Sahlin",
            "Kristina L\u00e5ng",
            "Anders Heyden",
            "Ida Arvidsson"
        ],
        "comments": " ",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Deep learning has shown to have great potential in medical applications. In critical domains as such, it is of high interest to have trustworthy algorithms which are able to tell when reliable assessments cannot be guaranteed. Detecting out-of-distribution (OOD) samples is a crucial step towards building a safe classifier. Following a previous study, showing that it is possible to classify breast cancer in point-of-care ultrasound images, this study investigates OOD detection using three different methods: softmax, energy score and deep ensembles. All methods are tested on three different OOD data sets. The results show that the energy score method outperforms the softmax method, performing well on two of the data sets. The ensemble method is the most robust, performing the best at detecting OOD samples for all three OOD data sets.\n    ",
        "primary_category": "cs.CV",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18962": {
        "title": "Program Synthesis in Saturation",
        "authors": [
            "Petra Hozzov\u00e1",
            "Laura Kov\u00e1cs",
            "Chase Norman",
            "Andrei Voronkov"
        ],
        "comments": "23 pages; this is an extended version of the published paper",
        "subjects": "Logic in Computer Science (cs.LO)",
        "abstract": "We present an automated reasoning framework for synthesizing recursion-free programs using saturation-based theorem proving. Given a functional specification encoded as a first-order logical formula, we use a first-order theorem prover to both establish validity of this formula and discover program fragments satisfying the specification. As a result, when deriving a proof of program correctness, we also synthesize a program that is correct with respect to the given specification. We describe properties of the calculus that a saturation-based prover capable of synthesis should employ, and extend the superposition calculus in a corresponding way. We implemented our work in the first-order prover Vampire, extending the successful applicability of first-order proving to program synthesis.\nThis is an extended version of an Automated Deduction -- CADE 29 paper with the same title and the same authors.\n    ",
        "primary_category": "cs.LO",
        "categories": [],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18968": {
        "title": "Ambisonics Networks -- The Effect Of Radial Functions Regularization",
        "authors": [
            "Bar Shaybet",
            "Anurag Kumar",
            "Vladimir Tourbabin",
            "Boaz Rafaely"
        ],
        "comments": "to be published in Icassp 2024",
        "subjects": "Audio and Speech Processing (eess.AS)",
        "abstract": "Ambisonics, a popular format of spatial audio, is the spherical harmonic (SH) representation of the plane wave density function of a sound field. Many algorithms operate in the SH domain and utilize the Ambisonics as their input signal. The process of encoding Ambisonics from a spherical microphone array involves dividing by the radial functions, which may amplify noise at low frequencies. This can be overcome by regularization, with the downside of introducing errors to the Ambisonics encoding. This paper aims to investigate the impact of different ways of regularization on Deep Neural Network (DNN) training and performance. Ideally, these networks should be robust to the way of regularization. Simulated data of a single speaker in a room and experimental data from the LOCATA challenge were used to evaluate this robustness on an example algorithm of speaker localization based on the direct-path dominance (DPD) test. Results show that performance may be sensitive to the way of regularization, and an informed approach is proposed and investigated, highlighting the importance of regularization information.\n    ",
        "primary_category": "eess.AS",
        "categories": [
            "cs.SD"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18969": {
        "title": "OHTA: One-shot Hand Avatar via Data-driven Implicit Priors",
        "authors": [
            "Xiaozheng Zheng",
            "Chao Wen",
            "Zhuo Su",
            "Zeran Xu",
            "Zhaohu Li",
            "Yang Zhao",
            "Zhou Xue"
        ],
        "comments": "Accepted to CVPR 2024. Project page: this https URL",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "In this paper, we delve into the creation of one-shot hand avatars, attaining high-fidelity and drivable hand representations swiftly from a single image. With the burgeoning domains of the digital human, the need for quick and personalized hand avatar creation has become increasingly critical. Existing techniques typically require extensive input data and may prove cumbersome or even impractical in certain scenarios. To enhance accessibility, we present a novel method OHTA (One-shot Hand avaTAr) that enables the creation of detailed hand avatars from merely one image. OHTA tackles the inherent difficulties of this data-limited problem by learning and utilizing data-driven hand priors. Specifically, we design a hand prior model initially employed for 1) learning various hand priors with available data and subsequently for 2) the inversion and fitting of the target identity with prior knowledge. OHTA demonstrates the capability to create high-fidelity hand avatars with consistent animatable quality, solely relying on a single image. Furthermore, we illustrate the versatility of OHTA through diverse applications, encompassing text-to-avatar conversion, hand editing, and identity latent space manipulation.\n    ",
        "primary_category": "cs.CV",
        "categories": [],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18970": {
        "title": "PrivatEyes: Appearance-based Gaze Estimation Using Federated Secure Multi-Party Computation",
        "authors": [
            "Mayar Elfares",
            "Pascal Reisert",
            "Zhiming Hu",
            "Wenwu Tang",
            "Ralf K\u00fcsters",
            "Andreas Bulling"
        ],
        "comments": " ",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Latest gaze estimation methods require large-scale training data but their collection and exchange pose significant privacy risks. We propose PrivatEyes - the first privacy-enhancing training approach for appearance-based gaze estimation based on federated learning (FL) and secure multi-party computation (MPC). PrivatEyes enables training gaze estimators on multiple local datasets across different users and server-based secure aggregation of the individual estimators' updates. PrivatEyes guarantees that individual gaze data remains private even if a majority of the aggregating servers is malicious. We also introduce a new data leakage attack DualView that shows that PrivatEyes limits the leakage of private training data more effectively than previous approaches. Evaluations on the MPIIGaze, MPIIFaceGaze, GazeCapture, and NVGaze datasets further show that the improved privacy does not lead to a lower gaze estimation accuracy or substantially higher computational costs - both of which are on par with its non-secure counterparts.\n    ",
        "primary_category": "cs.CV",
        "categories": [
            "cs.HC"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18973": {
        "title": "Privacy Management and Interface Design for a Smart House",
        "authors": [
            "Ana-Maria Comeaga",
            "Iuliana Marin"
        ],
        "comments": " ",
        "subjects": "Cryptography and Security (cs.CR)",
        "abstract": "In today's life, more and more people tend to opt for a smart house. In this way, the idea of including technology has become popular worldwide. Despite this concept's many benefits, managing security remains an essential problem due to the shared activities. The Internet of Things system behind a smart house is based on several sensors to measure temperature, humidity, air quality, and movement. Because of being supervised every day through sensors and controlling their house only with a simple click, many people can be afraid of this new approach in terms of their privacy, and this fact can constrain them from following their habits. The security aspects should be constantly analyzed to keep the data's confidentiality and make people feel safe in their own houses. In this context, the current paper puts light on an alternative design of a platform in which the safety of homeowners is the primary purpose, and they maintain complete control over the data generated by smart devices. The current research highlights the role of security and interface design in controlling a smart house. The study underscores the importance of providing an interface that can be used easily by any person to manage data and live activities in a modern residence in an era dominated by continuously developing technology.\n    ",
        "primary_category": "cs.CR",
        "categories": [
            "cs.SE"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18974": {
        "title": "Graph Generation via Spectral Diffusion",
        "authors": [
            "Giorgia Minello",
            "Alessandro Bicciato",
            "Luca Rossi",
            "Andrea Torsello",
            "Luca Cosmo"
        ],
        "comments": " ",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "In this paper, we present GRASP, a novel graph generative model based on 1) the spectral decomposition of the graph Laplacian matrix and 2) a diffusion process. Specifically, we propose to use a denoising model to sample eigenvectors and eigenvalues from which we can reconstruct the graph Laplacian and adjacency matrix. Our permutation invariant model can also handle node features by concatenating them to the eigenvectors of each node. Using the Laplacian spectrum allows us to naturally capture the structural characteristics of the graph and work directly in the node space while avoiding the quadratic complexity bottleneck that limits the applicability of other methods. This is achieved by truncating the spectrum, which as we show in our experiments results in a faster yet accurate generative process. An extensive set of experiments on both synthetic and real world graphs demonstrates the strengths of our model against state-of-the-art alternatives.\n    ",
        "primary_category": "cs.LG",
        "categories": [],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18980": {
        "title": "Helper Data Schemes for Coded Modulation and Shaping in Physical Unclonable Functions",
        "authors": [
            "Robert F.H. Fischer"
        ],
        "comments": " ",
        "subjects": "Information Theory (cs.IT)",
        "abstract": "In this paper, we consider the generation and utilization of helper data for physical unclonable functions (PUFs) that provide real-valued readout symbols. Compared to classical binary PUFs, more entropy can be extracted from each basic building block (PUF node), resulting in longer keys/fingerprints and/or a higher reliability. To this end, a coded modulation and signal shaping scheme that matches the (approximately) Gaussian distribution of the readout has to be employed. A new helper data scheme is proposed that works with any type of coded modulation/shaping scheme. Compared to the permutation scheme from the literature, less amount of helper data has to be generated and a higher reliability is achieved. Moreover, the recently proposed idea of a two-metric helper data scheme is generalized to coded modulation and a general S-metric scheme. It is shown how extra helper data can be generated to improve decodability. The proposed schemes are assessed by numerical simulations and by evaluation of measurement data. We compare multi-level codes using a new rate design strategy with bit-interleaved coded modulation and trellis shaping with a distribution matcher. By selecting a suitable design, the rate per PUF node that can be reliably extracted can be as high as 2~bit/node.\n    ",
        "primary_category": "cs.IT",
        "categories": [],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18982": {
        "title": "Splitting integrators for linear Vlasov equations with stochastic perturbations",
        "authors": [
            "Charles-Edouard Br\u00e9hier",
            "David Cohen"
        ],
        "comments": " ",
        "subjects": "Numerical Analysis (math.NA)",
        "abstract": "We consider a class of linear Vlasov partial differential equations driven by Wiener noise. Different types of stochastic perturbations are treated: additive noise, multiplicative It\u00f4 and Stratonovich noise, and transport noise. We propose to employ splitting integrators for the temporal discretization of these stochastic partial differential equations. These integrators are designed in order to preserve qualitative properties of the exact solutions depending on the stochastic perturbation, such as preservation of norms or positivity of the solutions. We provide numerical experiments in order to illustrate the properties of the proposed integrators and investigate mean-square rates of convergence.\n    ",
        "primary_category": "math.NA",
        "categories": [
            "math.PR"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18984": {
        "title": "Graph Burning: Bounds and Hardness",
        "authors": [
            "Dhanyamol Antony",
            "Anita Das",
            "Shirish Gosavi",
            "Dalu Jacob",
            "Shashanka Kulamarva"
        ],
        "comments": "22 pages, 6 figures",
        "subjects": "Combinatorics (math.CO)",
        "abstract": "The burning number of a graph $G$, denoted by $b(G)$, is the minimum number of steps required to burn all the vertices of a graph where in each step the existing fire spreads to all the adjacent vertices and one additional vertex can be burned as a new fire source. In this paper, we study the burning number problem both from an algorithmic and a structural point of view. The decision problem of computing the burning number of an input graph is known to be NP-Complete for trees with maximum degree at most three and interval graphs. Here, we prove that this problem is NP-Complete even when restricted to connected proper interval graphs and connected cubic graphs. The well-known burning number conjecture asserts that all the vertices of any graph of order $n$ can be burned in $\\lceil \\sqrt{n}~\\rceil$ steps. In line with this conjecture, upper and lower bounds of $b(G)$ are well-studied for various special graph classes. Here, we provide an improved upper bound for the burning number of connected $P_k$-free graphs and show that the bound is tight up to an additive constant $1$. Finally, we study two variants of the problem, namely edge burning (only edges are burned) and total burning (both vertices and edges are burned). In particular, we establish their relationship with the burning number problem and evaluate the complexity of these variants.\n    ",
        "primary_category": "math.CO",
        "categories": [
            "cs.DM"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18986": {
        "title": "Always be Pre-Training: Representation Learning for Network Intrusion Detection with GNNs",
        "authors": [
            "Zhengyao Gu",
            "Diego Troy Lopez",
            "Lilas Alrahis",
            "Ozgur Sinanoglu"
        ],
        "comments": "Will appear in the 2024 International Symposium on Quality Electronic Design (ISQED'24)",
        "subjects": "Cryptography and Security (cs.CR)",
        "abstract": "Graph neural network-based network intrusion detection systems have recently demonstrated state-of-the-art performance on benchmark datasets. Nevertheless, these methods suffer from a reliance on target encoding for data pre-processing, limiting widespread adoption due to the associated need for annotated labels--a cost-prohibitive requirement. In this work, we propose a solution involving in-context pre-training and the utilization of dense representations for categorical features to jointly overcome the label-dependency limitation. Our approach exhibits remarkable data efficiency, achieving over 98% of the performance of the supervised state-of-the-art with less than 4% labeled data on the NF-UQ-NIDS-V2 dataset.\n    ",
        "primary_category": "cs.CR",
        "categories": [],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18994": {
        "title": "Spyx: A Library for Just-In-Time Compiled Optimization of Spiking Neural Networks",
        "authors": [
            "Kade M. Heckel",
            "Thomas Nowotny"
        ],
        "comments": " ",
        "subjects": "Neural and Evolutionary Computing (cs.NE)",
        "abstract": "As the role of artificial intelligence becomes increasingly pivotal in modern society, the efficient training and deployment of deep neural networks have emerged as critical areas of focus. Recent advancements in attention-based large neural architectures have spurred the development of AI accelerators, facilitating the training of extensive, multi-billion parameter models. Despite their effectiveness, these powerful networks often incur high execution costs in production environments. Neuromorphic computing, inspired by biological neural processes, offers a promising alternative. By utilizing temporally-sparse computations, Spiking Neural Networks (SNNs) offer to enhance energy efficiency through a reduced and low-power hardware footprint. However, the training of SNNs can be challenging due to their recurrent nature which cannot as easily leverage the massive parallelism of modern AI accelerators. To facilitate the investigation of SNN architectures and dynamics researchers have sought to bridge Python-based deep learning frameworks such as PyTorch or TensorFlow with custom-implemented compute kernels. This paper introduces Spyx, a new and lightweight SNN simulation and optimization library designed in JAX. By pre-staging data in the expansive vRAM of contemporary accelerators and employing extensive JIT compilation, Spyx allows for SNN optimization to be executed as a unified, low-level program on NVIDIA GPUs or Google TPUs. This approach achieves optimal hardware utilization, surpassing the performance of many existing SNN training frameworks while maintaining considerable flexibility.\n    ",
        "primary_category": "cs.NE",
        "categories": [
            "cs.LG"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18995": {
        "title": "Negative-Binomial Randomized Gamma Markov Processes for Heterogeneous Overdispersed Count Time Series",
        "authors": [
            "Rui Huang",
            "Sikun Yang",
            "Heinz Koeppl"
        ],
        "comments": " ",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Modeling count-valued time series has been receiving increasing attention since count time series naturally arise in physical and social domains. Poisson gamma dynamical systems (PGDSs) are newly-developed methods, which can well capture the expressive latent transition structure and bursty dynamics behind count sequences. In particular, PGDSs demonstrate superior performance in terms of data imputation and prediction, compared with canonical linear dynamical system (LDS) based methods. Despite these advantages, PGDS cannot capture the heterogeneous overdispersed behaviours of the underlying dynamic processes. To mitigate this defect, we propose a negative-binomial-randomized gamma Markov process, which not only significantly improves the predictive performance of the proposed dynamical system, but also facilitates the fast convergence of the inference algorithm. Moreover, we develop methods to estimate both factor-structured and graph-structured transition dynamics, which enable us to infer more explainable latent structure, compared with PGDSs. Finally, we demonstrate the explainable latent structure learned by the proposed method, and show its superior performance in imputing missing data and forecasting future observations, compared with the related models.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.AI",
            "stat.ML"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.18998": {
        "title": "COFT-AD: COntrastive Fine-Tuning for Few-Shot Anomaly Detection",
        "authors": [
            "Jingyi Liao",
            "Xun Xu",
            "Manh Cuong Nguyen",
            "Adam Goodge",
            "Chuan Sheng Foo"
        ],
        "comments": "IEEE Transactions on Image Processing",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Existing approaches towards anomaly detection~(AD) often rely on a substantial amount of anomaly-free data to train representation and density models. However, large anomaly-free datasets may not always be available before the inference stage; in which case an anomaly detection model must be trained with only a handful of normal samples, a.k.a. few-shot anomaly detection (FSAD). In this paper, we propose a novel methodology to address the challenge of FSAD which incorporates two important techniques. Firstly, we employ a model pre-trained on a large source dataset to initialize model weights. Secondly, to ameliorate the covariate shift between source and target domains, we adopt contrastive training to fine-tune on the few-shot target domain data. To learn suitable representations for the downstream AD task, we additionally incorporate cross-instance positive pairs to encourage a tight cluster of the normal samples, and negative pairs for better separation between normal and synthesized negative samples. We evaluate few-shot anomaly detection on on 3 controlled AD tasks and 4 real-world AD tasks to demonstrate the effectiveness of the proposed method.\n    ",
        "primary_category": "cs.CV",
        "categories": [],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19002": {
        "title": "GoalNet: Goal Areas Oriented Pedestrian Trajectory Prediction",
        "authors": [
            "Ching-Lin Lee",
            "Zhi-Xuan Wang",
            "Kuan-Ting Lai",
            "Amar Fadillah"
        ],
        "comments": " ",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Predicting the future trajectories of pedestrians on the road is an important task for autonomous driving. The pedestrian trajectory prediction is affected by scene paths, pedestrian's intentions and decision-making, which is a multi-modal problem. Most recent studies use past trajectories to predict a variety of potential future trajectory distributions, which do not account for the scene context and pedestrian targets. Instead of predicting the future trajectory directly, we propose to use scene context and observed trajectory to predict the goal points first, and then reuse the goal points to predict the future trajectories. By leveraging the information from scene context and observed trajectory, the uncertainty can be limited to a few target areas, which represent the \"goals\" of the pedestrians. In this paper, we propose GoalNet, a new trajectory prediction neural network based on the goal areas of a pedestrian. Our network can predict both pedestrian's trajectories and bounding boxes. The overall model is efficient and modular, and its outputs can be changed according to the usage scenario. Experimental results show that GoalNet significantly improves the previous state-of-the-art performance by 48.7% on the JAAD and 40.8% on the PIE dataset.\n    ",
        "primary_category": "cs.CV",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19004": {
        "title": "RSAM-Seg: A SAM-based Approach with Prior Knowledge Integration for Remote Sensing Image Semantic Segmentation",
        "authors": [
            "Jie Zhang",
            "Xubing Yang",
            "Rui Jiang",
            "Wei Shao",
            "Li Zhang"
        ],
        "comments": "12 pages, 11 figures",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "The development of high-resolution remote sensing satellites has provided great convenience for research work related to remote sensing. Segmentation and extraction of specific targets are essential tasks when facing the vast and complex remote sensing images. Recently, the introduction of Segment Anything Model (SAM) provides a universal pre-training model for image segmentation tasks. While the direct application of SAM to remote sensing image segmentation tasks does not yield satisfactory results, we propose RSAM-Seg, which stands for Remote Sensing SAM with Semantic Segmentation, as a tailored modification of SAM for the remote sensing field and eliminates the need for manual intervention to provide prompts. Adapter-Scale, a set of supplementary scaling modules, are proposed in the multi-head attention blocks of the encoder part of SAM. Furthermore, Adapter-Feature are inserted between the Vision Transformer (ViT) blocks. These modules aim to incorporate high-frequency image information and image embedding features to generate image-informed prompts. Experiments are conducted on four distinct remote sensing scenarios, encompassing cloud detection, field monitoring, building detection and road mapping tasks . The experimental results not only showcase the improvement over the original SAM and U-Net across cloud, buildings, fields and roads scenarios, but also highlight the capacity of RSAM-Seg to discern absent areas within the ground truth of certain datasets, affirming its potential as an auxiliary annotation method. In addition, the performance in few-shot scenarios is commendable, underscores its potential in dealing with limited datasets.\n    ",
        "primary_category": "cs.CV",
        "categories": [
            "eess.IV"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19007": {
        "title": "DOZE: A Dataset for Open-Vocabulary Zero-Shot Object Navigation in Dynamic Environments",
        "authors": [
            "Ji Ma",
            "Hongming Dai",
            "Yao Mu",
            "Pengying Wu",
            "Hao Wang",
            "Xiaowei Chi",
            "Yang Fei",
            "Shanghang Zhang",
            "Chang Liu"
        ],
        "comments": " ",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Zero-Shot Object Navigation (ZSON) requires agents to autonomously locate and approach unseen objects in unfamiliar environments and has emerged as a particularly challenging task within the domain of Embodied AI. Existing datasets for developing ZSON algorithms lack consideration of dynamic obstacles, object attribute diversity, and scene texts, thus exhibiting noticeable discrepancy from real-world situations. To address these issues, we propose a Dataset for Open-Vocabulary Zero-Shot Object Navigation in Dynamic Environments (DOZE) that comprises ten high-fidelity 3D scenes with over 18k tasks, aiming to mimic complex, dynamic real-world scenarios. Specifically, DOZE scenes feature multiple moving humanoid obstacles, a wide array of open-vocabulary objects, diverse distinct-attribute objects, and valuable textual hints. Besides, different from existing datasets that only provide collision checking between the agent and static obstacles, we enhance DOZE by integrating capabilities for detecting collisions between the agent and moving obstacles. This novel functionality enables evaluation of the agents' collision avoidance abilities in dynamic environments. We test four representative ZSON methods on DOZE, revealing substantial room for improvement in existing approaches concerning navigation efficiency, safety, and object recognition accuracy. Our dataset could be found at this https URL.\n    ",
        "primary_category": "cs.CV",
        "categories": [
            "cs.RO"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19009": {
        "title": "Generating, Reconstructing, and Representing Discrete and Continuous Data: Generalized Diffusion with Learnable Encoding-Decoding",
        "authors": [
            "Guangyi Liu",
            "Yu Wang",
            "Zeyu Feng",
            "Qiyu Wu",
            "Liping Tang",
            "Yuan Gao",
            "Zhen Li",
            "Shuguang Cui",
            "Julian McAuley",
            "Eric P. Xing",
            "Zichao Yang",
            "Zhiting Hu"
        ],
        "comments": " ",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "The vast applications of deep generative models are anchored in three core capabilities -- generating new instances, reconstructing inputs, and learning compact representations -- across various data types, such as discrete text/protein sequences and continuous images. Existing model families, like Variational Autoencoders (VAEs), Generative Adversarial Networks (GANs), autoregressive models, and diffusion models, generally excel in specific capabilities and data types but fall short in others. We introduce generalized diffusion with learnable encoder-decoder (DiLED), that seamlessly integrates the core capabilities for broad applicability and enhanced performance. DiLED generalizes the Gaussian noising-denoising in standard diffusion by introducing parameterized encoding-decoding. Crucially, DiLED is compatible with the well-established diffusion model objective and training recipes, allowing effective learning of the encoder-decoder parameters jointly with diffusion. By choosing appropriate encoder/decoder (e.g., large language models), DiLED naturally applies to different data types. Extensive experiments on text, proteins, and images demonstrate DiLED's flexibility to handle diverse data and tasks and its strong improvement over various existing models.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19011": {
        "title": "Ruledger: Ensuring Execution Integrity in Trigger-Action IoT Platforms",
        "authors": [
            "Jingwen Fan",
            "Yi He",
            "Bo Tang",
            "Qi Li",
            "Ravi Sandhu"
        ],
        "comments": " ",
        "subjects": "Cryptography and Security (cs.CR)",
        "abstract": "Smart home IoT systems utilize trigger-action platforms, e.g., IFTTT, to manage devices from various vendors. However, they may be abused by triggering malicious rule execution with forged IoT devices or events violating the execution integrity and the intentions of the users. To address this issue, we propose a ledger based IoT platform called Ruledger, which ensures the correct execution of rules by verifying the authenticity of the corresponding information. Ruledger utilizes smart contracts to enforce verifying the information associated with rule executions, e.g., the user and configuration information from users, device events, and triggers in the trigger-action platforms. In particular, we develop three algorithms to enable ledger-wallet based applications for Ruledger and guarantee that the records used for verification are stateful and correct. Thus, the execution integrity of rules is ensured even if devices and platforms in the smart home systems are compromised. We prototype Ruledger in a real IoT platform, i.e., IFTTT, and evaluate the performance with various settings. The experimental results demonstrate Ruledger incurs an average of 12.53% delay, which is acceptable for smart home systems.\n    ",
        "primary_category": "cs.CR",
        "categories": [],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19012": {
        "title": "Algorithmically Expressive, Always-Terminating Model for Reversible Computation",
        "authors": [
            "Matteo Palazzo",
            "Luca Roversi"
        ],
        "comments": "16 pages, 4 figures, 2 listings",
        "subjects": "Programming Languages (cs.PL)",
        "abstract": "Concerning classical computational models able to express all the Primitive Recursive Functions (PRF), there are interesting results regarding limits on their algorithmic expressiveness or, equivalently, efficiency, namely the ability to express algorithms with minimal computational cost. By introducing the reversible programming model Forest, at our knowledge, we provide a first study of analogous properties, adapted to the context of reversible computational models that can represent all the functions in PRF. Firstly, we show that Forest extends Matos' linear reversible computational model MSRL, the very extension being a guaranteed terminating iteration that can be halted by means of logical predicates. The consequence is that Forest is PRF complete, because MSRL is. Secondly, we show that Forest is strictly algorithmically more expressive than MSRL: it can encode a reversible algorithm for the minimum between two integers in optimal time, while MSRL cannot.\n    ",
        "primary_category": "cs.PL",
        "categories": [
            "cs.LO"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19014": {
        "title": "Enhancing Visual Document Understanding with Contrastive Learning in Large Visual-Language Models",
        "authors": [
            "Xin Li",
            "Yunfei Wu",
            "Xinghua Jiang",
            "Zhihao Guo",
            "Mingming Gong",
            "Haoyu Cao",
            "Yinsong Liu",
            "Deqiang Jiang",
            "Xing Sun"
        ],
        "comments": " ",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Recently, the advent of Large Visual-Language Models (LVLMs) has received increasing attention across various domains, particularly in the field of visual document understanding (VDU). Different from conventional vision-language tasks, VDU is specifically concerned with text-rich scenarios containing abundant document elements. Nevertheless, the importance of fine-grained features remains largely unexplored within the community of LVLMs, leading to suboptimal performance in text-rich scenarios. In this paper, we abbreviate it as the fine-grained feature collapse issue. With the aim of filling this gap, we propose a contrastive learning framework, termed Document Object COntrastive learning (DoCo), specifically tailored for the downstream tasks of VDU. DoCo leverages an auxiliary multimodal encoder to obtain the features of document objects and align them to the visual features generated by the vision encoder of LVLM, which enhances visual representation in text-rich scenarios. It can represent that the contrastive learning between the visual holistic representations and the multimodal fine-grained features of document objects can assist the vision encoder in acquiring more effective visual cues, thereby enhancing the comprehension of text-rich documents in LVLMs. We also demonstrate that the proposed DoCo serves as a plug-and-play pre-training method, which can be employed in the pre-training of various LVLMs without inducing any increase in computational complexity during the inference process. Extensive experimental results on multiple benchmarks of VDU reveal that LVLMs equipped with our proposed DoCo can achieve superior performance and mitigate the gap between VDU and generic vision-language tasks.\n    ",
        "primary_category": "cs.CV",
        "categories": [],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19015": {
        "title": "Fractional material derivative: pointwise representation and a finite volume numerical scheme",
        "authors": [
            "\u0141ukasz P\u0142ociniczak",
            "Marek A. Teuerle"
        ],
        "comments": " ",
        "subjects": "Numerical Analysis (math.NA)",
        "abstract": "The fractional material derivative appears as the fractional operator that governs the dynamics of the scaling limits of L\u00e9vy walks - a stochastic process that originates from the famous continuous-time random walks. It is usually defined as the Fourier-Laplace multiplier, therefore, it can be thought of as a pseudo-differential operator. In this paper, we show that there exists a local representation in time and space, pointwise, of the fractional material derivative. This allows us to define it on a space of locally integrable functions which is larger than the original one in which Fourier and Laplace transform exist as functions.\nWe consider several typical differential equations involving the fractional material derivative and provide conditions for their solutions to exist. In some cases, the analytical solution can be found. For the general initial value problem, we devise a finite volume method and prove its stability, convergence, and conservation of probability. Numerical illustrations verify our analytical findings. Moreover, our numerical experiments show superiority in the computation time of the proposed numerical scheme over a Monte Carlo method applied to the problem of probability density function's derivation.\n    ",
        "primary_category": "math.NA",
        "categories": [],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19016": {
        "title": "SPriFed-OMP: A Differentially Private Federated Learning Algorithm for Sparse Basis Recovery",
        "authors": [
            "Ajinkya Kiran Mulay",
            "Xiaojun Lin"
        ],
        "comments": "Paper under review",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Sparse basis recovery is a classical and important statistical learning problem when the number of model dimensions $p$ is much larger than the number of samples $n$. However, there has been little work that studies sparse basis recovery in the Federated Learning (FL) setting, where the client data's differential privacy (DP) must also be simultaneously protected. In particular, the performance guarantees of existing DP-FL algorithms (such as DP-SGD) will degrade significantly when $p \\gg n$, and thus, they will fail to learn the true underlying sparse model accurately. In this work, we develop a new differentially private sparse basis recovery algorithm for the FL setting, called SPriFed-OMP. SPriFed-OMP converts OMP (Orthogonal Matching Pursuit) to the FL setting. Further, it combines SMPC (secure multi-party computation) and DP to ensure that only a small amount of noise needs to be added in order to achieve differential privacy. As a result, SPriFed-OMP can efficiently recover the true sparse basis for a linear model with only $n = O(\\sqrt{p})$ samples. We further present an enhanced version of our approach, SPriFed-OMP-GRAD based on gradient privatization, that improves the performance of SPriFed-OMP. Our theoretical analysis and empirical results demonstrate that both SPriFed-OMP and SPriFed-OMP-GRAD terminate in a small number of steps, and they significantly outperform the previous state-of-the-art DP-FL solutions in terms of the accuracy-privacy trade-off.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.CR"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19020": {
        "title": "Unsupervised Learning of High-resolution Light Field Imaging via Beam Splitter-based Hybrid Lenses",
        "authors": [
            "Jianxin Lei",
            "Chengcai Xu",
            "Langqing Shi",
            "Junhui Hou",
            "Ping Zhou"
        ],
        "comments": " ",
        "subjects": "Image and Video Processing (eess.IV)",
        "abstract": "In this paper, we design a beam splitter-based hybrid light field imaging prototype to record 4D light field image and high-resolution 2D image simultaneously, and make a hybrid light field dataset. The 2D image could be considered as the high-resolution ground truth corresponding to the low-resolution central sub-aperture image of 4D light field image. Subsequently, we propose an unsupervised learning-based super-resolution framework with the hybrid light field dataset, which adaptively settles the light field spatial super-resolution problem with a complex degradation model. Specifically, we design two loss functions based on pre-trained models that enable the super-resolution network to learn the detailed features and light field parallax structure with only one ground truth. Extensive experiments demonstrate the same superiority of our approach with supervised learning-based state-of-the-art ones. To our knowledge, it is the first end-to-end unsupervised learning-based spatial super-resolution approach in light field imaging research, whose input is available from our beam splitter-based hybrid light field system. The hardware and software together may help promote the application of light field super-resolution to a great extent.\n    ",
        "primary_category": "eess.IV",
        "categories": [
            "cs.CV"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19025": {
        "title": "Combination of Weak Learners eXplanations to Improve Random Forest eXplicability Robustness",
        "authors": [
            "Riccardo Pala",
            "Esteban Garc\u00eda-Cuesta"
        ],
        "comments": "8 pages, 10 figures",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "The notion of robustness in XAI refers to the observed variations in the explanation of the prediction of a learned model with respect to changes in the input leading to that prediction. Intuitively, if the input being explained is modified slightly subtly enough so as to not change the prediction of the model too much, then we would expect that the explanation provided for that new input does not change much either. We argue that a combination through discriminative averaging of ensembles weak learners explanations can improve the robustness of explanations in ensemble methods.This approach has been implemented and tested with post-hoc SHAP method and Random Forest ensemble with successful results. The improvements obtained have been measured quantitatively and some insights into the explicability robustness in ensemble methods are presented.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19026": {
        "title": "Progressive Contrastive Learning with Multi-Prototype for Unsupervised Visible-Infrared Person Re-identification",
        "authors": [
            "Jiangming Shi",
            "Xiangbo Yin",
            "Yaoxing Wang",
            "Xiaofeng Liu",
            "Yuan Xie",
            "Yanyun Qu"
        ],
        "comments": " ",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Unsupervised visible-infrared person re-identification (USVI-ReID) aims to match specified people in infrared images to visible images without annotation, and vice versa. USVI-ReID is a challenging yet under-explored task. Most existing methods address the USVI-ReID problem using cluster-based contrastive learning, which simply employs the cluster center as a representation of a person. However, the cluster center primarily focuses on shared information, overlooking disparity. To address the problem, we propose a Progressive Contrastive Learning with Multi-Prototype (PCLMP) method for USVI-ReID. In brief, we first generate the hard prototype by selecting the sample with the maximum distance from the cluster center. This hard prototype is used in the contrastive loss to emphasize disparity. Additionally, instead of rigidly aligning query images to a specific prototype, we generate the dynamic prototype by randomly picking samples within a cluster. This dynamic prototype is used to retain the natural variety of features while reducing instability in the simultaneous learning of both common and disparate information. Finally, we introduce a progressive learning strategy to gradually shift the model's attention towards hard samples, avoiding cluster deterioration. Extensive experiments conducted on the publicly available SYSU-MM01 and RegDB datasets validate the effectiveness of the proposed method. PCLMP outperforms the existing state-of-the-art method with an average mAP improvement of 3.9%. The source codes will be released.\n    ",
        "primary_category": "cs.CV",
        "categories": [],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19027": {
        "title": "How to Train your Antivirus: RL-based Hardening through the Problem-Space",
        "authors": [
            "Jacopo Cortellazzi",
            "Ilias Tsingenopoulos",
            "Branislav Bo\u0161ansk\u00fd",
            "Simone Aonzo",
            "Davy Preuveneers",
            "Wouter Joosen",
            "Fabio Pierazzi",
            "Lorenzo Cavallaro"
        ],
        "comments": "20 pages,4 figures",
        "subjects": "Cryptography and Security (cs.CR)",
        "abstract": "ML-based malware detection on dynamic analysis reports is vulnerable to both evasion and spurious correlations. In this work, we investigate a specific ML architecture employed in the pipeline of a widely-known commercial antivirus company, with the goal to harden it against adversarial malware. Adversarial training, the sole defensive technique that can confer empirical robustness, is not applicable out of the box in this domain, for the principal reason that gradient-based perturbations rarely map back to feasible problem-space programs. We introduce a novel Reinforcement Learning approach for constructing adversarial examples, a constituent part of adversarially training a model against evasion. Our approach comes with multiple advantages. It performs modifications that are feasible in the problem-space, and only those; thus it circumvents the inverse mapping problem. It also makes possible to provide theoretical guarantees on the robustness of the model against a particular set of adversarial capabilities. Our empirical exploration validates our theoretical insights, where we can consistently reach 0\\% Attack Success Rate after a few adversarial retraining iterations.\n    ",
        "primary_category": "cs.CR",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19028": {
        "title": "Invariant Checking for SMT-based Systems with Quantifiers",
        "authors": [
            "Gianluca Redondi",
            "Alessandro Cimatti",
            "Alberto Griggio",
            "Kenneth McMillan"
        ],
        "comments": " ",
        "subjects": "Logic in Computer Science (cs.LO)",
        "abstract": "This paper addresses the problem of checking invariant properties for a large class of symbolic transition systems, defined by a combination of SMT theories and quantifiers. State variables can be functions from an uninterpreted sort (finite, but unbounded) to an interpreted sort, such as the the integers under the theory of linear arithmetic. This formalism is very expressive and can be used for modeling parameterized systems, array-manipulating programs, and more. We propose two algorithms for finding universal inductive invariants for such systems. The first algorithm combines an IC3-style loop with a form of implicit predicate abstraction to construct an invariant in an incremental manner. The second algorithm constructs an under-approximation of the original problem, and searches for a formula which is an inductive invariant for this case; then, the invariant is generalized to the original case, and checked with a portfolio of techniques. We have implemented the two algorithms and conducted an extensive experimental evaluation, considering various benchmarks and different tools from the literature. As far as we know, our method is the first capable of handling in a large class of systems in a uniform way. The experiment shows that both algorithms are competitive with the state of the art.\n    ",
        "primary_category": "cs.LO",
        "categories": [],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19033": {
        "title": "High-Speed Motion Planning for Aerial Swarms in Unknown and Cluttered Environments",
        "authors": [
            "Charbel Toumieh",
            "Dario Floreano"
        ],
        "comments": " ",
        "subjects": "Robotics (cs.RO)",
        "abstract": "Coordinated flight of multiple drones allows to achieve tasks faster such as search and rescue and infrastructure inspection. Thus, pushing the state-of-the-art of aerial swarms in navigation speed and robustness is of tremendous benefit. In particular, being able to account for unexplored/unknown environments when planning trajectories allows for safer flight. In this work, we propose the first high-speed, decentralized, and synchronous motion planning framework (HDSM) for an aerial swarm that explicitly takes into account the unknown/undiscovered parts of the environment. The proposed approach generates an optimized trajectory for each planning agent that avoids obstacles and other planning agents while moving and exploring the environment. The only global information that each agent has is the target location. The generated trajectory is high-speed, safe from unexplored spaces, and brings the agent closer to its goal. The proposed method outperforms four recent state-of-the-art methods in success rate (100% success in reaching the target location), flight speed (67% faster), and flight time (42% lower). Finally, the method is validated on a set of Crazyflie nano-drones as a proof of concept.\n    ",
        "primary_category": "cs.RO",
        "categories": [],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19037": {
        "title": "A Deep-Learning Technique to Locate Cryptographic Operations in Side-Channel Traces",
        "authors": [
            "Giuseppe Chiari",
            "Davide Galli",
            "Francesco Lattari",
            "Matteo Matteucci",
            "Davide Zoni"
        ],
        "comments": "Accepted for presentation by DATE'24",
        "subjects": "Cryptography and Security (cs.CR)",
        "abstract": "Side-channel attacks allow extracting secret information from the execution of cryptographic primitives by correlating the partially known computed data and the measured side-channel signal. However, to set up a successful side-channel attack, the attacker has to perform i) the challenging task of locating the time instant in which the target cryptographic primitive is executed inside a side-channel trace and then ii)the time-alignment of the measured data on that time instant. This paper presents a novel deep-learning technique to locate the time instant in which the target computed cryptographic operations are executed in the side-channel trace. In contrast to state-of-the-art solutions, the proposed methodology works even in the presence of trace deformations obtained through random delay insertion techniques. We validated our proposal through a successful attack against a variety of unprotected and protected cryptographic primitives that have been executed on an FPGA-implemented system-on-chip featuring a RISC-V CPU.\n    ",
        "primary_category": "cs.CR",
        "categories": [
            "cs.LG"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19038": {
        "title": "Understanding Fairness in Software Engineering: Insights from Stack Exchange",
        "authors": [
            "Emeralda Sesari",
            "Federica Sarro",
            "Ayushi Rastogi"
        ],
        "comments": " ",
        "subjects": "Software Engineering (cs.SE)",
        "abstract": "Software practitioners discuss problems at work with peers, in-person and online. These discussions can be technical (e.g., how to fix a bug?) and social (e.g., how to assign work fairly?). While there is a growing body of knowledge exploring fairness problems and solutions in the human and social factors of software engineering, most focus has been on specific problems. This study provides fairness discussions by software practitioners on Stack Exchange sites. We present an exploratory study presenting the fairness experience of software practitioners and fairness expectations in software teams. We also want to identify the fairness aspects software practitioners talk about the most. For example, do they care more about fairness in income or how they are treated in the workplace?\nOur investigation of fairness discussions on eight Stack Exchange sites resulted in a list of 136 posts (28 questions and 108 answers) manually curated from 4,178 candidate posts. The study reveals that the majority of fairness discussions (24 posts) revolve around the topic of income suggesting that many software practitioners are highly interested in matters related to their pay and how it is fairly distributed. Further, we noted that while not discussed as often, discussions on fairness in recruitment tend to receive the highest number of views and scores. Interestingly, the study shows that unfairness experiences extend beyond the protected attributes. In this study, only 25 out of 136 posts mention protected attributes, with gender mainly being discussed.\n    ",
        "primary_category": "cs.SE",
        "categories": [],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19041": {
        "title": "Atmospheric Turbulence Removal with Video Sequence Deep Visual Priors",
        "authors": [
            "P. Hill",
            "N. Anantrasirichai",
            "A. Achim",
            "D.R. Bull"
        ],
        "comments": " ",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Atmospheric turbulence poses a challenge for the interpretation and visual perception of visual imagery due to its distortion effects. Model-based approaches have been used to address this, but such methods often suffer from artefacts associated with moving content. Conversely, deep learning based methods are dependent on large and diverse datasets that may not effectively represent any specific content. In this paper, we address these problems with a self-supervised learning method that does not require ground truth. The proposed method is not dependent on any dataset outside of the single data sequence being processed but is also able to improve the quality of any input raw sequences or pre-processed sequences. Specifically, our method is based on an accelerated Deep Image Prior (DIP), but integrates temporal information using pixel shuffling and a temporal sliding window. This efficiently learns spatio-temporal priors leading to a system that effectively mitigates atmospheric turbulence distortions. The experiments show that our method improves visual quality results qualitatively and quantitatively.\n    ",
        "primary_category": "cs.CV",
        "categories": [
            "cs.AI",
            "eess.IV"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19043": {
        "title": "WDM: 3D Wavelet Diffusion Models for High-Resolution Medical Image Synthesis",
        "authors": [
            "Paul Friedrich",
            "Julia Wolleb",
            "Florentin Bieder",
            "Alicia Durrer",
            "Philippe C. Cattin"
        ],
        "comments": "Code: this https URL",
        "subjects": "Image and Video Processing (eess.IV)",
        "abstract": "Due to the three-dimensional nature of CT- or MR-scans, generative modeling of medical images is a particularly challenging task. Existing approaches mostly apply patch-wise, slice-wise, or cascaded generation techniques to fit the high-dimensional data into the limited GPU memory. However, these approaches may introduce artifacts and potentially restrict the model's applicability for certain downstream tasks. This work presents WDM, a wavelet-based medical image synthesis framework that applies a diffusion model on wavelet decomposed images. The presented approach is a simple yet effective way of scaling diffusion models to high resolutions and can be trained on a single 40 GB GPU. Experimental results on BraTS and LIDC-IDRI unconditional image generation at a resolution of $128 \\times 128 \\times 128$ show state-of-the-art image fidelity (FID) and sample diversity (MS-SSIM) scores compared to GANs, Diffusion Models, and Latent Diffusion Models. Our proposed method is the only one capable of generating high-quality images at a resolution of $256 \\times 256 \\times 256$.\n    ",
        "primary_category": "eess.IV",
        "categories": [
            "cs.CV"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19044": {
        "title": "DMSA -- Dense Multi Scan Adjustment for LiDAR Inertial Odometry and Global Optimization",
        "authors": [
            "David Skuddis",
            "Norbert Haala"
        ],
        "comments": "accepted for ICRA 2024",
        "subjects": "Robotics (cs.RO)",
        "abstract": "We propose a new method for fine registering multiple point clouds simultaneously. The approach is characterized by being dense, therefore point clouds are not reduced to pre-selected features in advance. Furthermore, the approach is robust against small overlaps and dynamic objects, since no direct correspondences are assumed between point clouds. Instead, all points are merged into a global point cloud, whose scattering is then iteratively reduced. This is achieved by dividing the global point cloud into uniform grid cells whose contents are subsequently modeled by normal distributions. We show that the proposed approach can be used in a sliding window continuous trajectory optimization combined with IMU measurements to obtain a highly accurate and robust LiDAR inertial odometry estimation. Furthermore, we show that the proposed approach is also suitable for large scale keyframe optimization to increase accuracy. We provide the source code and some experimental data on this https URL.\n    ",
        "primary_category": "cs.RO",
        "categories": [],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19052": {
        "title": "Exploring the Efficacy of Large Language Models in Summarizing Mental Health Counseling Sessions: A Benchmark Study",
        "authors": [
            "Prottay Kumar Adhikary",
            "Aseem Srivastava",
            "Shivani Kumar",
            "Salam Michael Singh",
            "Puneet Manuja",
            "Jini K Gopinath",
            "Vijay Krishnan",
            "Swati Kedia",
            "Koushik Sinha Deb",
            "Tanmoy Chakraborty"
        ],
        "comments": " ",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "Comprehensive summaries of sessions enable an effective continuity in mental health counseling, facilitating informed therapy planning. Yet, manual summarization presents a significant challenge, diverting experts' attention from the core counseling process. This study evaluates the effectiveness of state-of-the-art Large Language Models (LLMs) in selectively summarizing various components of therapy sessions through aspect-based summarization, aiming to benchmark their performance. We introduce MentalCLOUDS, a counseling-component guided summarization dataset consisting of 191 counseling sessions with summaries focused on three distinct counseling components (aka counseling aspects). Additionally, we assess the capabilities of 11 state-of-the-art LLMs in addressing the task of component-guided summarization in counseling. The generated summaries are evaluated quantitatively using standard summarization metrics and verified qualitatively by mental health professionals. Our findings demonstrate the superior performance of task-specific LLMs such as MentalLlama, Mistral, and MentalBART in terms of standard quantitative metrics such as Rouge-1, Rouge-2, Rouge-L, and BERTScore across all aspects of counseling components. Further, expert evaluation reveals that Mistral supersedes both MentalLlama and MentalBART based on six parameters -- affective attitude, burden, ethicality, coherence, opportunity costs, and perceived effectiveness. However, these models share the same weakness by demonstrating a potential for improvement in the opportunity costs and perceived effectiveness metrics.\n    ",
        "primary_category": "cs.CL",
        "categories": [
            "cs.HC"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19054": {
        "title": "RobWE: Robust Watermark Embedding for Personalized Federated Learning Model Ownership Protection",
        "authors": [
            "Yang Xu",
            "Yunlin Tan",
            "Cheng Zhang",
            "Kai Chi",
            "Peng Sun",
            "Wenyuan Yang",
            "Ju Ren",
            "Hongbo Jiang",
            "Yaoxue Zhang"
        ],
        "comments": " ",
        "subjects": "Cryptography and Security (cs.CR)",
        "abstract": "Embedding watermarks into models has been widely used to protect model ownership in federated learning (FL). However, existing methods are inadequate for protecting the ownership of personalized models acquired by clients in personalized FL (PFL). This is due to the aggregation of the global model in PFL, resulting in conflicts over clients' private watermarks. Moreover, malicious clients may tamper with embedded watermarks to facilitate model leakage and evade accountability. This paper presents a robust watermark embedding scheme, named RobWE, to protect the ownership of personalized models in PFL. We first decouple the watermark embedding of personalized models into two parts: head layer embedding and representation layer embedding. The head layer belongs to clients' private part without participating in model aggregation, while the representation layer is the shared part for aggregation. For representation layer embedding, we employ a watermark slice embedding operation, which avoids watermark embedding conflicts. Furthermore, we design a malicious watermark detection scheme enabling the server to verify the correctness of watermarks before aggregating local models. We conduct an exhaustive experimental evaluation of RobWE. The results demonstrate that RobWE significantly outperforms the state-of-the-art watermark embedding schemes in FL in terms of fidelity, reliability, and robustness.\n    ",
        "primary_category": "cs.CR",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19058": {
        "title": "On the Design of Human-Robot Collaboration Gestures",
        "authors": [
            "Anas Shrinah",
            "Masoud S. Bahraini",
            "Fahad Khan",
            "Seemal Asif",
            "Niels Lohse",
            "Kerstin Eder"
        ],
        "comments": " ",
        "subjects": "Robotics (cs.RO)",
        "abstract": "Effective communication between humans and collaborative robots is essential for seamless Human-Robot Collaboration (HRC). In noisy industrial settings, nonverbal communication, such as gestures, plays a key role in conveying commands and information to robots efficiently. While existing literature has thoroughly examined gesture recognition and robots' responses to these gestures, there is a notable gap in exploring the design of these gestures. The criteria for creating efficient HRC gestures are scattered across numerous studies. This paper surveys the design principles of HRC gestures, as contained in the literature, aiming to consolidate a set of criteria for HRC gesture design. It also examines the methods used for designing and evaluating HRC gestures to highlight research gaps and present directions for future research in this area.\n    ",
        "primary_category": "cs.RO",
        "categories": [
            "cs.HC"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19061": {
        "title": "Optimal ANN-SNN Conversion with Group Neurons",
        "authors": [
            "Liuzhenghao Lv",
            "Wei Fang",
            "Li Yuan",
            "Yonghong Tian"
        ],
        "comments": "Accepted by International Conference on Acoustics, Speech, and Signal Processing (ICASSP) 2024",
        "subjects": "Neural and Evolutionary Computing (cs.NE)",
        "abstract": "Spiking Neural Networks (SNNs) have emerged as a promising third generation of neural networks, offering unique characteristics such as binary outputs, high sparsity, and biological plausibility. However, the lack of effective learning algorithms remains a challenge for SNNs. For instance, while converting artificial neural networks (ANNs) to SNNs circumvents the need for direct training of SNNs, it encounters issues related to conversion errors and high inference time delays. In order to reduce or even eliminate conversion errors while decreasing inference time-steps, we have introduced a novel type of neuron called Group Neurons (GNs). One GN is composed of multiple Integrate-and-Fire (IF) neurons as members, and its neural dynamics are meticulously designed. Based on GNs, we have optimized the traditional ANN-SNN conversion framework. Specifically, we replace the IF neurons in the SNNs obtained by the traditional conversion framework with GNs. The resulting SNNs, which utilize GNs, are capable of achieving accuracy levels comparable to ANNs even within extremely short inference time-steps. The experiments on CIFAR10, CIFAR100, and ImageNet datasets demonstrate the superiority of the proposed methods in terms of both inference accuracy and latency. Code is available at this https URL.\n    ",
        "primary_category": "cs.NE",
        "categories": [],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19064": {
        "title": "The Influence of Color Stimuli on Adolescents' Emotion Playing Mobile Games",
        "authors": [
            "Leonie Kallabis",
            "Bruno Baruque-Zan\u00f3n",
            "Heinrich Klocke",
            "Ana Mar\u00eda Lara-Palma",
            "Boris Naujoks"
        ],
        "comments": "17 pages, 12 figures, 1 table",
        "subjects": "Human-Computer Interaction (cs.HC)",
        "abstract": "Video games elicit emotions which can be influenced by color stimuli as shown by previous studies. However, little research has been conducted on whether this applies to mobile games played by adolescents. Therefore, we examined the influence of color stimuli hue and saturation on mobile game play. Adolescents (n=21) played a mobile platformer game with varying hue and saturation per level for about 25 minutes. We gathered data on emotional states after each level using the Self-Assessment Manikin questionnaire, recorded time spent in each level, and collected participant self-reports on their video game experience. We performed statistical tests, such as ANOVA, which depict no significant influence of hue and/or saturation on the emotional state of our players. We conclude that it is possible that color alone is not an effective measure for eliciting emotion in mobile games, and further research is needed to consider measures such as time spent in the game and screen size, as these are unique to mobile games. There was a noticeable variance in emotional response between male and female players, with a significant interaction of hue and saturation among male players for valence ratings. This may be an indication that color preference influences perceived pleasantness.\n    ",
        "primary_category": "cs.HC",
        "categories": [],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19071": {
        "title": "FATE in MMLA: A Student-Centred Exploration of Fairness, Accountability, Transparency, and Ethics in Multimodal Learning Analytics",
        "authors": [
            "Yueqiao Jin",
            "Vanessa Echeverria",
            "Lixiang Yan",
            "Linxuan Zhao",
            "Riordan Alfredo",
            "Yi-Shan Tsai",
            "Dragan Ga\u0161evi\u0107",
            "Roberto Martinez-Maldonado"
        ],
        "comments": "16 pages, 1 figure",
        "subjects": "Computers and Society (cs.CY)",
        "abstract": "Multimodal Learning Analytics (MMLA) integrates novel sensing technologies and artificial intelligence algorithms, providing opportunities to enhance student reflection during complex, collaborative learning experiences. Although recent advancements in MMLA have shown its capability to generate insights into diverse learning behaviours across various learning settings, little research has been conducted to evaluate these systems in authentic learning contexts, particularly regarding students' perceived fairness, accountability, transparency, and ethics (FATE). Understanding these perceptions is essential to using MMLA effectively without introducing ethical complications or negatively affecting how students learn. This study aimed to address this gap by assessing the FATE of MMLA in an authentic, collaborative learning context. We conducted semi-structured interviews with 14 undergraduate students who used MMLA visualisations for post-activity reflection. The findings highlighted the significance of accurate and comprehensive data representation to ensure visualisation fairness, the need for different levels of data access to foster accountability, the imperative of measuring and cultivating transparency with students, and the necessity of transforming informed consent from dichotomous to continuous and measurable scales. While students value the benefits of MMLA, they also emphasise the importance of ethical considerations, highlighting a pressing need for the LA and MMLA community to investigate and address FATE issues actively.\n    ",
        "primary_category": "cs.CY",
        "categories": [
            "cs.HC"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19072": {
        "title": "TimeXer: Empowering Transformers for Time Series Forecasting with Exogenous Variables",
        "authors": [
            "Yuxuan Wang",
            "Haixu Wu",
            "Jiaxiang Dong",
            "Yong Liu",
            "Yunzhong Qiu",
            "Haoran Zhang",
            "Jianmin Wang",
            "Mingsheng Long"
        ],
        "comments": " ",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Recent studies have demonstrated remarkable performance in time series forecasting. However, due to the partially-observed nature of real-world applications, solely focusing on the target of interest, so-called endogenous variables, is usually insufficient to guarantee accurate forecasting. Notably, a system is often recorded into multiple variables, where the exogenous series can provide valuable external information for endogenous variables. Thus, unlike prior well-established multivariate or univariate forecasting that either treats all the variables equally or overlooks exogenous information, this paper focuses on a practical setting, which is time series forecasting with exogenous variables. We propose a novel framework, TimeXer, to utilize external information to enhance the forecasting of endogenous variables. With a deftly designed embedding layer, TimeXer empowers the canonical Transformer architecture with the ability to reconcile endogenous and exogenous information, where patch-wise self-attention and variate-wise cross-attention are employed. Moreover, a global endogenous variate token is adopted to effectively bridge the exogenous series into endogenous temporal patches. Experimentally, TimeXer significantly improves time series forecasting with exogenous variables and achieves consistent state-of-the-art performance in twelve real-world forecasting benchmarks.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19076": {
        "title": "Pointing out the Shortcomings of Relation Extraction Models with Semantically Motivated Adversarials",
        "authors": [
            "Gennaro Nolano",
            "Moritz Blum",
            "Basil Ell",
            "Philipp Cimiano"
        ],
        "comments": " ",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "In recent years, large language models have achieved state-of-the-art performance across various NLP tasks. However, investigations have shown that these models tend to rely on shortcut features, leading to inaccurate predictions and causing the models to be unreliable at generalization to out-of-distribution (OOD) samples. For instance, in the context of relation extraction (RE), we would expect a model to identify the same relation independently of the entities involved in it. For example, consider the sentence \"Leonardo da Vinci painted the Mona Lisa\" expressing the created(Leonardo_da_Vinci, Mona_Lisa) relation. If we substiute \"Leonardo da Vinci\" with \"Barack Obama\", then the sentence still expresses the created relation. A robust model is supposed to detect the same relation in both cases. In this work, we describe several semantically-motivated strategies to generate adversarial examples by replacing entity mentions and investigate how state-of-the-art RE models perform under pressure. Our analyses show that the performance of these models significantly deteriorates on the modified datasets (avg. of -48.5% in F1), which indicates that these models rely to a great extent on shortcuts, such as surface forms (or patterns therein) of entities, without making full use of the information present in the sentences.\n    ",
        "primary_category": "cs.CL",
        "categories": [],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19082": {
        "title": "VideoMAC: Video Masked Autoencoders Meet ConvNets",
        "authors": [
            "Gensheng Pei",
            "Tao Chen",
            "Xiruo Jiang",
            "Huafeng Liu",
            "Zeren Sun",
            "Yazhou Yao"
        ],
        "comments": "accepted by IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2024",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Recently, the advancement of self-supervised learning techniques, like masked autoencoders (MAE), has greatly influenced visual representation learning for images and videos. Nevertheless, it is worth noting that the predominant approaches in existing masked image / video modeling rely excessively on resource-intensive vision transformers (ViTs) as the feature encoder. In this paper, we propose a new approach termed as \\textbf{VideoMAC}, which combines video masked autoencoders with resource-friendly ConvNets. Specifically, VideoMAC employs symmetric masking on randomly sampled pairs of video frames. To prevent the issue of mask pattern dissipation, we utilize ConvNets which are implemented with sparse convolutional operators as encoders. Simultaneously, we present a simple yet effective masked video modeling (MVM) approach, a dual encoder architecture comprising an online encoder and an exponential moving average target encoder, aimed to facilitate inter-frame reconstruction consistency in videos. Additionally, we demonstrate that VideoMAC, empowering classical (ResNet) / modern (ConvNeXt) convolutional encoders to harness the benefits of MVM, outperforms ViT-based approaches on downstream tasks, including video object segmentation (+\\textbf{5.2\\%} / \\textbf{6.4\\%} $\\mathcal{J}\\&\\mathcal{F}$), body part propagation (+\\textbf{6.3\\%} / \\textbf{3.1\\%} mIoU), and human pose tracking (+\\textbf{10.2\\%} / \\textbf{11.1\\%} PCK@0.1).\n    ",
        "primary_category": "cs.CV",
        "categories": [],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19084": {
        "title": "High multiplicity of positive solutions in a superlinear problem of Moore-Nehari type",
        "authors": [
            "Pablo Cubillos",
            "Juli\u00e1n L\u00f3pez-G\u00f3mez",
            "Andrea Tellini"
        ],
        "comments": " ",
        "subjects": "Analysis of PDEs (math.AP)",
        "abstract": "In this paper we consider a superlinear one-dimensional elliptic boundary value problem that generalizes the one studied by Moore and Nehari in [43]. Specifically, we deal with piecewise-constant weight functions in front of the nonlinearity with an arbitrary number $\\kappa\\geq 1$ of vanishing regions. We study, from an analytic and numerical point of view, the number of positive solutions, depending on the value of a parameter $\\lambda$ and on $\\kappa$.\nOur main results are twofold. On the one hand, we study analytically the behavior of the solutions, as $\\lambda\\downarrow-\\infty$, in the regions where the weight vanishes. Our result leads us to conjecture the existence of $2^{\\kappa+1}-1$ solutions for sufficiently negative $\\lambda$. On the other hand, we support such a conjecture with the results of numerical simulations which also shed light on the structure of the global bifurcation diagrams in $\\lambda$ and the profiles of positive solutions.\nFinally, we give additional numerical results suggesting that the same high multiplicity result holds true for a much larger class of weights, also arbitrarily close to situations where there is uniqueness of positive solutions.\n    ",
        "primary_category": "math.AP",
        "categories": [
            "math.CA",
            "math.NA"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19085": {
        "title": "Controllable Preference Optimization: Toward Controllable Multi-Objective Alignment",
        "authors": [
            "Yiju Guo",
            "Ganqu Cui",
            "Lifan Yuan",
            "Ning Ding",
            "Jiexin Wang",
            "Huimin Chen",
            "Bowen Sun",
            "Ruobing Xie",
            "Jie Zhou",
            "Yankai Lin",
            "Zhiyuan Liu",
            "Maosong Sun"
        ],
        "comments": " ",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "Alignment in artificial intelligence pursues the consistency between model responses and human preferences as well as values. In practice, the multifaceted nature of human preferences inadvertently introduces what is known as the \"alignment tax\" -a compromise where enhancements in alignment within one objective (e.g.,harmlessness) can diminish performance in others (e.g.,helpfulness). However, existing alignment techniques are mostly unidirectional, leading to suboptimal trade-offs and poor flexibility over various objectives. To navigate this challenge, we argue the prominence of grounding LLMs with evident preferences. We introduce controllable preference optimization (CPO), which explicitly specifies preference scores for different objectives, thereby guiding the model to generate responses that meet the requirements. Our experimental analysis reveals that the aligned models can provide responses that match various preferences among the \"3H\" (helpfulness, honesty, harmlessness) desiderata. Furthermore, by introducing diverse data and alignment goals, we surpass baseline methods in aligning with single objectives, hence mitigating the impact of the alignment tax and achieving Pareto improvements in multi-objective alignment.\n    ",
        "primary_category": "cs.CL",
        "categories": [
            "cs.AI",
            "eess.SY"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19089": {
        "title": "Around Don's conjecture for binary completely reachable automata",
        "authors": [
            "Yinfeng Zhu"
        ],
        "comments": "10 pages, 2 figures",
        "subjects": "Formal Languages and Automata Theory (cs.FL)",
        "abstract": "A word $w$ is called a reaching word of a subset $S$ of states in a deterministic finite automaton (DFA) if $S$ is the image of $Q$ under the action of $w$. A DFA is called completely reachable if every non-empty subset of the state set has a reaching word. A conjecture states that in every $n$-state completely reachable DFA, for every $k$-element subset of states, there exists a reaching word of length at most $n(n-k)$. We present infinitely many completely reachable DFAs with two letters that violate this conjecture. A subfamily of completely reachable DFAs with two letters, is called standardized DFAs, introduced by Casas and Volkov (2023). We prove that every $k$-element subset of states in an $n$-state standardized DFA has a reaching word of length $\\le n(n-k) + n - 1$. Finally, we confirm the conjecture for standardized DFAs with additional properties, thus generalizing a result of Casas and Volkov (2023).\n    ",
        "primary_category": "cs.FL",
        "categories": [],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19090": {
        "title": "Best Arm Identification with Resource Constraints",
        "authors": [
            "Zitian Li",
            "Wang Chi Cheung"
        ],
        "comments": " ",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Motivated by the cost heterogeneity in experimentation across different alternatives, we study the Best Arm Identification with Resource Constraints (BAIwRC) problem. The agent aims to identify the best arm under resource constraints, where resources are consumed for each arm pull. We make two novel contributions. We design and analyze the Successive Halving with Resource Rationing algorithm (SH-RR). The SH-RR achieves a near-optimal non-asymptotic rate of convergence in terms of the probability of successively identifying an optimal arm. Interestingly, we identify a difference in convergence rates between the cases of deterministic and stochastic resource consumption.\n    ",
        "primary_category": "cs.LG",
        "categories": [],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19091": {
        "title": "Leveraging Representations from Intermediate Encoder-blocks for Synthetic Image Detection",
        "authors": [
            "Christos Koutlis",
            "Symeon Papadopoulos"
        ],
        "comments": " ",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "The recently developed and publicly available synthetic image generation methods and services make it possible to create extremely realistic imagery on demand, raising great risks for the integrity and safety of online information. State-of-the-art Synthetic Image Detection (SID) research has led to strong evidence on the advantages of feature extraction from foundation models. However, such extracted features mostly encapsulate high-level visual semantics instead of fine-grained details, which are more important for the SID task. On the contrary, shallow layers encode low-level visual information. In this work, we leverage the image representations extracted by intermediate Transformer blocks of CLIP's image-encoder via a lightweight network that maps them to a learnable forgery-aware vector space capable of generalizing exceptionally well. We also employ a trainable module to incorporate the importance of each Transformer block to the final prediction. Our method is compared against the state-of-the-art by evaluating it on 20 test datasets and exhibits an average +10.6% absolute performance improvement. Notably, the best performing models require just a single epoch for training (~8 minutes). Code available at this https URL.\n    ",
        "primary_category": "cs.CV",
        "categories": [],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19097": {
        "title": "TEncDM: Understanding the Properties of Diffusion Model in the Space of Language Model Encodings",
        "authors": [
            "Alexander Shabalin",
            "Viacheslav Meshchaninov",
            "Tingir Badmaev",
            "Dmitry Molchanov",
            "Grigory Bartosh",
            "Sergey Markov",
            "Dmitry Vetrov"
        ],
        "comments": "14 pages, 8 figures, submitted to ACL 2024",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "Drawing inspiration from the success of diffusion models in various domains, numerous research papers proposed methods for adapting them to text data. Despite these efforts, none of them has managed to achieve the quality of the large language models. In this paper, we conduct a comprehensive analysis of key components of the text diffusion models and introduce a novel approach named Text Encoding Diffusion Model (TEncDM). Instead of the commonly used token embedding space, we train our model in the space of the language model encodings. Additionally, we propose to use a Transformer-based decoder that utilizes contextual information for text reconstruction. We also analyse self-conditioning and find that it increases the magnitude of the model outputs, allowing the reduction of the number of denoising steps at the inference stage. Evaluation of TEncDM on two downstream text generation tasks, QQP and XSum, demonstrates its superiority over existing non-autoregressive models.\n    ",
        "primary_category": "cs.CL",
        "categories": [],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19101": {
        "title": "Effective Two-Stage Knowledge Transfer for Multi-Entity Cross-Domain Recommendation",
        "authors": [
            "Jianyu Guan",
            "Zongming Yin",
            "Tianyi Zhang",
            "Leihui Chen",
            "Yin Zhang",
            "Fei Huang",
            "Jufeng Chen",
            "Shuguang Han"
        ],
        "comments": " ",
        "subjects": "Information Retrieval (cs.IR)",
        "abstract": "In recent years, the recommendation content on e-commerce platforms has become increasingly rich -- a single user feed may contain multiple entities, such as selling products, short videos, and content posts. To deal with the multi-entity recommendation problem, an intuitive solution is to adopt the shared-network-based architecture for joint training. The idea is to transfer the extracted knowledge from one type of entity (source entity) to another (target entity). However, different from the conventional same-entity cross-domain recommendation, multi-entity knowledge transfer encounters several important issues: (1) data distributions of the source entity and target entity are naturally different, making the shared-network-based joint training susceptible to the negative transfer issue, (2) more importantly, the corresponding feature schema of each entity is not exactly aligned (e.g., price is an essential feature for selling product while missing for content posts), making the existing methods no longer appropriate. Recent researchers have also experimented with the pre-training and fine-tuning paradigm. Again, they only consider the scenarios with the same entity type and feature systems, which is inappropriate in our case. To this end, we design a pre-training & fine-tuning based Multi-entity Knowledge Transfer framework called MKT. MKT utilizes a multi-entity pre-training module to extract transferable knowledge across different entities. In particular, a feature alignment module is first applied to scale and align different feature schemas. Afterward, a couple of knowledge extractors are employed to extract the common and entity-specific knowledge. In the end, the extracted common knowledge is adopted for target entity model training. Through extensive offline and online experiments, we demonstrated the superiority of MKT over multiple State-Of-The-Art methods.\n    ",
        "primary_category": "cs.IR",
        "categories": [
            "cs.LG"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19102": {
        "title": "FlatNAS: optimizing Flatness in Neural Architecture Search for Out-of-Distribution Robustness",
        "authors": [
            "Matteo Gambella",
            "Fabrizio Pittorino",
            "Manuel Roveri"
        ],
        "comments": " ",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Neural Architecture Search (NAS) paves the way for the automatic definition of Neural Network (NN) architectures, attracting increasing research attention and offering solutions in various scenarios. This study introduces a novel NAS solution, called Flat Neural Architecture Search (FlatNAS), which explores the interplay between a novel figure of merit based on robustness to weight perturbations and single NN optimization with Sharpness-Aware Minimization (SAM). FlatNAS is the first work in the literature to systematically explore flat regions in the loss landscape of NNs in a NAS procedure, while jointly optimizing their performance on in-distribution data, their out-of-distribution (OOD) robustness, and constraining the number of parameters in their architecture. Differently from current studies primarily concentrating on OOD algorithms, FlatNAS successfully evaluates the impact of NN architectures on OOD robustness, a crucial aspect in real-world applications of machine and deep learning. FlatNAS achieves a good trade-off between performance, OOD generalization, and the number of parameters, by using only in-distribution data in the NAS exploration. The OOD robustness of the NAS-designed models is evaluated by focusing on robustness to input data corruptions, using popular benchmark datasets in the literature.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.AI",
            "cs.CV"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19103": {
        "title": "Whispers that Shake Foundations: Analyzing and Mitigating False Premise Hallucinations in Large Language Models",
        "authors": [
            "Hongbang Yuan",
            "Pengfei Cao",
            "Zhuoran Jin",
            "Yubo Chen",
            "Daojian Zeng",
            "Kang Liu",
            "Jun Zhao"
        ],
        "comments": "12 pages, 5 figures, 5 tables",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "Large Language Models (LLMs) have shown impressive capabilities but still suffer from the issue of hallucinations. A significant type of this issue is the false premise hallucination, which we define as the phenomenon when LLMs generate hallucinated text when confronted with false premise questions. In this paper, we perform a comprehensive analysis of the false premise hallucination and elucidate its internal working mechanism: a small subset of attention heads (which we designate as false premise heads) disturb the knowledge extraction process, leading to the occurrence of false premise hallucination. Based on our analysis, we propose \\textbf{FAITH} (\\textbf{F}alse premise \\textbf{A}ttention head constra\\textbf{I}ining for mi\\textbf{T}igating \\textbf{H}allucinations), a novel and effective method to mitigate false premise hallucinations. It constrains the false premise attention heads during the model inference process. Impressively, extensive experiments demonstrate that constraining only approximately $1\\%$ of the attention heads in the model yields a notable increase of nearly $20\\%$ of model performance.\n    ",
        "primary_category": "cs.CL",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19105": {
        "title": "CollaFuse: Navigating Limited Resources and Privacy in Collaborative Generative AI",
        "authors": [
            "Domenique Zipperling",
            "Simeon Allmendinger",
            "Lukas Struppek",
            "Niklas K\u00fchl"
        ],
        "comments": "Thirty-Second European Conference on Information Systems (ECIS 2024)",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "In the landscape of generative artificial intelligence, diffusion-based models present challenges for socio-technical systems in data requirements and privacy. Traditional approaches like federated learning distribute the learning process but strain individual clients, especially with constrained resources (e.g., edge devices). In response to these challenges, we introduce CollaFuse, a novel framework inspired by split learning. Tailored for efficient and collaborative use of denoising diffusion probabilistic models, CollaFuse enables shared server training and inference, alleviating client computational burdens. This is achieved by retaining data and computationally inexpensive GPU processes locally at each client while outsourcing the computationally expensive processes to the shared server. Demonstrated in a healthcare context, CollaFuse enhances privacy by highly reducing the need for sensitive information sharing. These capabilities hold the potential to impact various application areas, such as the design of edge computing solutions, healthcare research, or autonomous driving. In essence, our work advances distributed machine learning, shaping the future of collaborative GenAI networks.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19106": {
        "title": "A SOUND APPROACH: Using Large Language Models to generate audio descriptions for egocentric text-audio retrieval",
        "authors": [
            "Andreea-Maria Oncescu",
            "Jo\u00e3o F. Henriques",
            "Andrew Zisserman",
            "Samuel Albanie",
            "A. Sophia Koepke"
        ],
        "comments": "9 pages, 2 figures, 9 tables, Accepted at ICASSP 2024",
        "subjects": "Audio and Speech Processing (eess.AS)",
        "abstract": "Video databases from the internet are a valuable source of text-audio retrieval datasets. However, given that sound and vision streams represent different \"views\" of the data, treating visual descriptions as audio descriptions is far from optimal. Even if audio class labels are present, they commonly are not very detailed, making them unsuited for text-audio retrieval. To exploit relevant audio information from video-text datasets, we introduce a methodology for generating audio-centric descriptions using Large Language Models (LLMs). In this work, we consider the egocentric video setting and propose three new text-audio retrieval benchmarks based on the EpicMIR and EgoMCQ tasks, and on the EpicSounds dataset. Our approach for obtaining audio-centric descriptions gives significantly higher zero-shot performance than using the original visual-centric descriptions. Furthermore, we show that using the same prompts, we can successfully employ LLMs to improve the retrieval on EpicSounds, compared to using the original audio class labels of the dataset. Finally, we confirm that LLMs can be used to determine the difficulty of identifying the action associated with a sound.\n    ",
        "primary_category": "eess.AS",
        "categories": [
            "cs.IR",
            "cs.SD"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19107": {
        "title": "Rahmani Sort: A Novel Variant of Insertion Sort Algorithm with O(nlogn) Complexity",
        "authors": [
            "Mohammad Khalid Imam Rahmani"
        ],
        "comments": "None",
        "subjects": "Cryptography and Security (cs.CR)",
        "abstract": "Various decision support systems are available that implement Data Mining and Data Warehousing techniques for diving into the sea of data for getting useful patterns of knowledge (pearls). Classification, regression, clustering, and many other algorithms are used to enhance the precision and accuracy of the decision process. So, there is scope for increasing the response time of the decision process, especially in mission-critical operations. If data are ordered with suitable and efficient sorting operation, the response time of the decision process can be minimized. Insertion sort is much more suitable for such applications due to its simple and straight logic along with its dynamic nature suitable for list implementation. But it is slower than merge sort and quick sort. The main reasons this is slow: firstly, a sequential search is used to find the actual position of the next key element into the sorted left subarray and secondly, shifting of elements is required by one position towards the right for accommodating the newly inserted element. Therefore, I propose a new algorithm by using a novel technique of binary search mechanism for finding the sorted location of the next key item into the previously sorted left subarray much quicker than the conventional insertion sort algorithm. Performance measurement in terms of the actual running time of the new algorithm has been compared with those of other conventional sorting algorithms apart from the insertion sort. The results obtained on various sample data show that the new algorithm is better in performance than the conventional insertion sort and merge sort algorithms.\n    ",
        "primary_category": "cs.CR",
        "categories": [
            "cs.DS"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19108": {
        "title": "DeepEraser: Deep Iterative Context Mining for Generic Text Eraser",
        "authors": [
            "Hao Feng",
            "Wendi Wang",
            "Shaokai Liu",
            "Jiajun Deng",
            "Wengang Zhou",
            "Houqiang Li"
        ],
        "comments": " ",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "In this work, we present DeepEraser, an effective deep network for generic text removal. DeepEraser utilizes a recurrent architecture that erases the text in an image via iterative operations. Our idea comes from the process of erasing pencil script, where the text area designated for removal is subject to continuous monitoring and the text is attenuated progressively, ensuring a thorough and clean erasure. Technically, at each iteration, an innovative erasing module is deployed, which not only explicitly aggregates the previous erasing progress but also mines additional semantic context to erase the target text. Through iterative refinements, the text regions are progressively replaced with more appropriate content and finally converge to a relatively accurate status. Furthermore, a custom mask generation strategy is introduced to improve the capability of DeepEraser for adaptive text removal, as opposed to indiscriminately removing all the text in an image. Our DeepEraser is notably compact with only 1.4M parameters and trained in an end-to-end manner. To verify its effectiveness, extensive experiments are conducted on several prevalent benchmarks, including SCUT-Syn, SCUT-EnsText, and Oxford Synthetic text dataset. The quantitative and qualitative results demonstrate the effectiveness of our DeepEraser over the state-of-the-art methods, as well as its strong generalization ability in custom mask text removal. The codes and pre-trained models are available at this https URL\n",
        "primary_category": "cs.CV",
        "categories": [],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19109": {
        "title": "Confidence and Assurance of Percentiles",
        "authors": [
            "Sanjay M. Joshi"
        ],
        "comments": "5 pages, 4 Figures",
        "subjects": "Methodology (stat.ME)",
        "abstract": "Confidence interval of mean is often used when quoting statistics. The same rigor is often missing when quoting percentiles and tolerance or percentile intervals. This article derives the expression for confidence in percentiles of a sample population. Confidence intervals of median is compared to those of mean for a few sample distributions. The concept of assurance from reliability engineering is then extended to percentiles. The assurance level of sorted samples simply matches the confidence and percentile levels. Numerical method to compute assurance using Brent's optimization method is provided as an open-source python package.\n    ",
        "primary_category": "stat.ME",
        "categories": [
            "cs.IT"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19110": {
        "title": "Temporal-Aware Deep Reinforcement Learning for Energy Storage Bidding in Energy and Contingency Reserve Markets",
        "authors": [
            "Jinhao Li",
            "Changlong Wang",
            "Yanru Zhang",
            "Hao Wang"
        ],
        "comments": "15 pages",
        "subjects": "Systems and Control (eess.SY)",
        "abstract": "The battery energy storage system (BESS) has immense potential for enhancing grid reliability and security through its participation in the electricity market. BESS often seeks various revenue streams by taking part in multiple markets to unlock its full potential, but effective algorithms for joint-market participation under price uncertainties are insufficiently explored in the existing research. To bridge this gap, we develop a novel BESS joint bidding strategy that utilizes deep reinforcement learning (DRL) to bid in the spot and contingency frequency control ancillary services (FCAS) markets. Our approach leverages a transformer-based temporal feature extractor to effectively respond to price fluctuations in seven markets simultaneously and helps DRL learn the best BESS bidding strategy in joint-market participation. Additionally, unlike conventional \"black-box\" DRL model, our approach is more interpretable and provides valuable insights into the temporal bidding behavior of BESS in the dynamic electricity market. We validate our method using realistic market prices from the Australian National Electricity Market. The results show that our strategy outperforms benchmarks, including both optimization-based and other DRL-based strategies, by substantial margins. Our findings further suggest that effective temporal-aware bidding can significantly increase profits in the spot and contingency FCAS markets compared to individual market participation.\n    ",
        "primary_category": "eess.SY",
        "categories": [
            "cs.LG",
            "math.OC"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19111": {
        "title": "Deep Network for Image Compressed Sensing Coding Using Local Structural Sampling",
        "authors": [
            "Wenxue Cui",
            "Xingtao Wang",
            "Xiaopeng Fan",
            "Shaohui Liu",
            "Xinwei Gao",
            "Debin Zhao"
        ],
        "comments": "Accepted by ACM Transactions on Multimedia Computing Communications and Applications (TOMM)",
        "subjects": "Image and Video Processing (eess.IV)",
        "abstract": "Existing image compressed sensing (CS) coding frameworks usually solve an inverse problem based on measurement coding and optimization-based image reconstruction, which still exist the following two challenges: 1) The widely used random sampling matrix, such as the Gaussian Random Matrix (GRM), usually leads to low measurement coding efficiency. 2) The optimization-based reconstruction methods generally maintain a much higher computational complexity. In this paper, we propose a new CNN based image CS coding framework using local structural sampling (dubbed CSCNet) that includes three functional modules: local structural sampling, measurement coding and Laplacian pyramid reconstruction. In the proposed framework, instead of GRM, a new local structural sampling matrix is first developed, which is able to enhance the correlation between the measurements through a local perceptual sampling strategy. Besides, the designed local structural sampling matrix can be jointly optimized with the other functional modules during training process. After sampling, the measurements with high correlations are produced, which are then coded into final bitstreams by the third-party image codec. At last, a Laplacian pyramid reconstruction network is proposed to efficiently recover the target image from the measurement domain to the image domain. Extensive experimental results demonstrate that the proposed scheme outperforms the existing state-of-the-art CS coding methods, while maintaining fast computational speed.\n    ",
        "primary_category": "eess.IV",
        "categories": [
            "cs.CV"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19118": {
        "title": "Continuous Sign Language Recognition Based on Motor attention mechanism and frame-level Self-distillation",
        "authors": [
            "Qidan Zhu",
            "Jing Li",
            "Fei Yuan",
            "Quan Gan"
        ],
        "comments": "10 pages, 7 figures",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Changes in facial expression, head movement, body movement and gesture movement are remarkable cues in sign language recognition, and most of the current continuous sign language recognition(CSLR) research methods mainly focus on static images in video sequences at the frame-level feature extraction stage, while ignoring the dynamic changes in the images. In this paper, we propose a novel motor attention mechanism to capture the distorted changes in local motion regions during sign language expression, and obtain a dynamic representation of image changes. And for the first time, we apply the self-distillation method to frame-level feature extraction for continuous sign language, which improves the feature expression without increasing the computational resources by self-distilling the features of adjacent stages and using the higher-order features as teachers to guide the lower-order features. The combination of the two constitutes our proposed holistic model of CSLR Based on motor attention mechanism and frame-level Self-Distillation (MAM-FSD), which improves the inference ability and robustness of the model. We conduct experiments on three publicly available datasets, and the experimental results show that our proposed method can effectively extract the sign language motion information in videos, improve the accuracy of CSLR and reach the state-of-the-art level.\n    ",
        "primary_category": "cs.CV",
        "categories": [],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19120": {
        "title": "A Naive Approach for Automatic Line-level Code Completion",
        "authors": [
            "Shamima Naznin",
            "Dr.Manishankar Mondal"
        ],
        "comments": "6 pages",
        "subjects": "Software Engineering (cs.SE)",
        "abstract": "Coding is an integral aspect of programming. A programmer can automatically complete a code fragment after writing a few tokens, and the process of automatic completion is known as code completion. Several research studies on code completion have previously been conducted for method body completion and method parameter completion. However, this fundamental study explores the automatic completion of any program statement that might not even be part of a method.\nThe goal is to provide suggestions to the programmer for completing code throughout the codebase by identifying and analyzing code similarities. The proposed methodology can be regarded as a fundamental framework for automated code completion. From the investigation of hundreds of revisions of four subject systems written in C and Java, it is observed that the proposed method can automatically complete around 22% of code statements with an average accuracy of 87% that a programmer writes during development, accelerating software development time. The empirical analysis further demonstrates that the approach can be used with programming language neutrality.\nThe study concludes by illustrating that taking 10 characters as prefixes before invoking completion provides maximum precision.\n    ",
        "primary_category": "cs.SE",
        "categories": [],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19125": {
        "title": "Highly efficient Gauss's law-preserving spectral algorithms for Maxwell's double-curl source and eigenvalue problems based on eigen-decomposition",
        "authors": [
            "Sen Lin",
            "Huiyuan Li",
            "Zhiguo Yang"
        ],
        "comments": " ",
        "subjects": "Numerical Analysis (math.NA)",
        "abstract": "In this paper, we present Gauss's law-preserving spectral methods and their efficient solution algorithms for curl-curl source and eigenvalue problems in two and three dimensions arising from Maxwell's equations. Arbitrary order $H(curl)$-conforming spectral basis functions in two and three dimensions are firstly proposed using compact combination of Legendre polynomials. A mixed formulation involving a Lagrange multiplier is then adopted to preserve the Gauss's law in the weak sense. To overcome the bottleneck of computational efficiency caused by the saddle-point nature of the mixed scheme, we present highly efficient solution algorithms based on reordering and decoupling of the resultant linear algebraic system and numerical eigen-decomposition of one dimensional mass matrix. The proposed solution algorithms are direct methods requiring only several matrix-matrix or matrix-tensor products of $N$-by-$N$ matrices, where $N$ is the highest polynomial order in each direction. Compared with other direct methods, the computational complexities are reduced from $O(N^6)$ and $O(N^9)$ to $O(N^3)$ and $O(N^4)$ with small and constant pre-factors for 2D and 3D cases, respectively, and can further be accelerated to $O(N^{2.807})$ and $O(N^{3.807})$, when boosted with the Strassen's matrix multiplication algorithm. Moreover, these algorithms strictly obey the Helmholtz-Hodge decomposition, thus totally eliminate the spurious eigen-modes of non-physical zero eigenvalues. Extensions of the proposed methods and algorithms to problems in complex geometries with variable coefficients and inhomogeneous boundary conditions are discussed to deal with more general situations. Ample numerical examples for solving Maxwell's source and eigenvalue problems are presented to demonstrate the accuracy and efficiency of the proposed methods.\n    ",
        "primary_category": "math.NA",
        "categories": [],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19128": {
        "title": "ARMCHAIR: integrated inverse reinforcement learning and model predictive control for human-robot collaboration",
        "authors": [
            "Angelo Caregnato-Neto",
            "Luciano Cavalcante Siebert",
            "Arkady Zgonnikov",
            "Marcos Ricardo Omena de Albuquerque Maximo",
            "Rubens Junqueira Magalh\u00e3es Afonso"
        ],
        "comments": " ",
        "subjects": "Robotics (cs.RO)",
        "abstract": "One of the key issues in human-robot collaboration is the development of computational models that allow robots to predict and adapt to human behavior. Much progress has been achieved in developing such models, as well as control techniques that address the autonomy problems of motion planning and decision-making in robotics. However, the integration of computational models of human behavior with such control techniques still poses a major challenge, resulting in a bottleneck for efficient collaborative human-robot teams. In this context, we present a novel architecture for human-robot collaboration: Adaptive Robot Motion for Collaboration with Humans using Adversarial Inverse Reinforcement learning (ARMCHAIR). Our solution leverages adversarial inverse reinforcement learning and model predictive control to compute optimal trajectories and decisions for a mobile multi-robot system that collaborates with a human in an exploration task. During the mission, ARMCHAIR operates without human intervention, autonomously identifying the necessity to support and acting accordingly. Our approach also explicitly addresses the network connectivity requirement of the human-robot team. Extensive simulation-based evaluations demonstrate that ARMCHAIR allows a group of robots to safely support a simulated human in an exploration scenario, preventing collisions and network disconnections, and improving the overall performance of the task.\n    ",
        "primary_category": "cs.RO",
        "categories": [
            "cs.HC",
            "cs.MA",
            "eess.SY"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19132": {
        "title": "Weighted least $\\ell_p$ approximation on compact Riemannian manifolds",
        "authors": [
            "Jiansong Li",
            "Yun Ling",
            "Jiaxin Geng",
            "Heping Wang"
        ],
        "comments": "23 pages",
        "subjects": "Numerical Analysis (math.NA)",
        "abstract": "Given a sequence of Marcinkiewicz-Zygmund inequalities in $L_2$ on a compact space, Gr\u00f6chenig in \\cite{G} discussed weighted least squares approximation and least squares quadrature. Inspired by this work, for all $1\\le p\\le\\infty$, we develop weighted least $\\ell_p$ approximation induced by a sequence of Marcinkiewicz-Zygmund inequalities in $L_p$ on a compact smooth Riemannian manifold $\\Bbb M$ with normalized Riemannian measure (typical examples are the torus and the sphere). In this paper we derive corresponding approximation theorems with the error measured in $L_q,\\,1\\le q\\le\\infty$, and least quadrature errors for both Sobolev spaces $H_p^r(\\Bbb M), \\, r>d/p$ generated by eigenfunctions associated with the Laplace-Beltrami operator and Besov spaces $B_{p,\\tau}^r(\\Bbb M),\\, 0<\\tau\\le \\infty, r>d/p $ defined by best polynomial approximation. Finally, we discuss the optimality of the obtained results by giving sharp estimates of sampling numbers and optimal quadrature errors for the aforementioned spaces.\n    ",
        "primary_category": "math.NA",
        "categories": [],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19133": {
        "title": "Evaluating Webcam-based Gaze Data as an Alternative for Human Rationale Annotations",
        "authors": [
            "Stephanie Brandl",
            "Oliver Eberle",
            "Tiago Ribeiro",
            "Anders S\u00f8gaard",
            "Nora Hollenstein"
        ],
        "comments": "Accepted to LREC-COLING 2024",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "Rationales in the form of manually annotated input spans usually serve as ground truth when evaluating explainability methods in NLP. They are, however, time-consuming and often biased by the annotation process. In this paper, we debate whether human gaze, in the form of webcam-based eye-tracking recordings, poses a valid alternative when evaluating importance scores. We evaluate the additional information provided by gaze data, such as total reading times, gaze entropy, and decoding accuracy with respect to human rationale annotations. We compare WebQAmGaze, a multilingual dataset for information-seeking QA, with attention and explainability-based importance scores for 4 different multilingual Transformer-based language models (mBERT, distil-mBERT, XLMR, and XLMR-L) and 3 languages (English, Spanish, and German). Our pipeline can easily be applied to other tasks and languages. Our findings suggest that gaze data offers valuable linguistic insights that could be leveraged to infer task difficulty and further show a comparable ranking of explainability methods to that of human rationales.\n    ",
        "primary_category": "cs.CL",
        "categories": [],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19135": {
        "title": "Think Fast, Think Slow, Think Critical: Designing an Automated Propaganda Detection Tool",
        "authors": [
            "Liudmila Zavolokina",
            "Kilian Sprenkamp",
            "Zoya Katashinskaya",
            "Daniel Gordon Jones",
            "Gerhard Schwabe"
        ],
        "comments": "The paper is accepted for publication in proceedings of the CHI Conference on Human Factors in Computing Systems (2024)",
        "subjects": "Human-Computer Interaction (cs.HC)",
        "abstract": "In today's digital age, characterized by rapid news consumption and increasing vulnerability to propaganda, fostering citizens' critical thinking is crucial for stable democracies. This paper introduces the design of ClarifAI, a novel automated propaganda detection tool designed to nudge readers towards more critical news consumption by activating the analytical mode of thinking, following Kahneman's dual-system theory of cognition. Using Large Language Models, ClarifAI detects propaganda in news articles and provides context-rich explanations, enhancing users' understanding and critical thinking. Our contribution is threefold: first, we propose the design of ClarifAI; second, in an online experiment, we demonstrate that this design effectively encourages news readers to engage in more critical reading; and third, we emphasize the value of explanations for fostering critical thinking. The study thus offers both a practical tool and useful design knowledge for mitigating propaganda in digital news.\n    ",
        "primary_category": "cs.HC",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19142": {
        "title": "ProtoP-OD: Explainable Object Detection with Prototypical Parts",
        "authors": [
            "Pavlos Rath-Manakidis",
            "Frederik Strothmann",
            "Tobias Glasmachers",
            "Laurenz Wiskott"
        ],
        "comments": "9 pages, 11 figures",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Interpretation and visualization of the behavior of detection transformers tends to highlight the locations in the image that the model attends to, but it provides limited insight into the \\emph{semantics} that the model is focusing on. This paper introduces an extension to detection transformers that constructs prototypical local features and uses them in object detection. These custom features, which we call prototypical parts, are designed to be mutually exclusive and align with the classifications of the model. The proposed extension consists of a bottleneck module, the prototype neck, that computes a discretized representation of prototype activations and a new loss term that matches prototypes to object classes. This setup leads to interpretable representations in the prototype neck, allowing visual inspection of the image content perceived by the model and a better understanding of the model's reliability. We show experimentally that our method incurs only a limited performance penalty, and we provide examples that demonstrate the quality of the explanations provided by our method, which we argue outweighs the performance penalty.\n    ",
        "primary_category": "cs.CV",
        "categories": [
            "cs.LG"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19144": {
        "title": "Weakly Supervised Monocular 3D Detection with a Single-View Image",
        "authors": [
            "Xueying Jiang",
            "Sheng Jin",
            "Lewei Lu",
            "Xiaoqin Zhang",
            "Shijian Lu"
        ],
        "comments": " ",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Monocular 3D detection (M3D) aims for precise 3D object localization from a single-view image which usually involves labor-intensive annotation of 3D detection boxes. Weakly supervised M3D has recently been studied to obviate the 3D annotation process by leveraging many existing 2D annotations, but it often requires extra training data such as LiDAR point clouds or multi-view images which greatly degrades its applicability and usability in various applications. We propose SKD-WM3D, a weakly supervised monocular 3D detection framework that exploits depth information to achieve M3D with a single-view image exclusively without any 3D annotations or other training data. One key design in SKD-WM3D is a self-knowledge distillation framework, which transforms image features into 3D-like representations by fusing depth information and effectively mitigates the inherent depth ambiguity in monocular scenarios with little computational overhead in inference. In addition, we design an uncertainty-aware distillation loss and a gradient-targeted transfer modulation strategy which facilitate knowledge acquisition and knowledge transfer, respectively. Extensive experiments show that SKD-WM3D surpasses the state-of-the-art clearly and is even on par with many fully supervised methods.\n    ",
        "primary_category": "cs.CV",
        "categories": [],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19145": {
        "title": "A SAM-guided Two-stream Lightweight Model for Anomaly Detection",
        "authors": [
            "Chenghao Li",
            "Lei Qi",
            "Xin Geng"
        ],
        "comments": " ",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "In industrial anomaly detection, model efficiency and mobile-friendliness become the primary concerns in real-world applications. Simultaneously, the impressive generalization capabilities of Segment Anything (SAM) have garnered broad academic attention, making it an ideal choice for localizing unseen anomalies and diverse real-world patterns. In this paper, considering these two critical factors, we propose a SAM-guided Two-stream Lightweight Model for unsupervised anomaly detection (STLM) that not only aligns with the two practical application requirements but also harnesses the robust generalization capabilities of SAM. We employ two lightweight image encoders, i.e., our two-stream lightweight module, guided by SAM's knowledge. To be specific, one stream is trained to generate discriminative and general feature representations in both normal and anomalous regions, while the other stream reconstructs the same images without anomalies, which effectively enhances the differentiation of two-stream representations when facing anomalous regions. Furthermore, we employ a shared mask decoder and a feature aggregation module to generate anomaly maps. Our experiments conducted on MVTec AD benchmark show that STLM, with about 16M parameters and achieving an inference time in 20ms, competes effectively with state-of-the-art methods in terms of performance, 98.26% on pixel-level AUC and 94.92% on PRO. We further experiment on more difficult datasets, e.g., VisA and DAGM, to demonstrate the effectiveness and generalizability of STLM.\n    ",
        "primary_category": "cs.CV",
        "categories": [],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19147": {
        "title": "Efficient quaternion CUR method for low-rank approximation to quaternion matrix",
        "authors": [
            "Peng-Ling Wu",
            "Kit Ian Kou",
            "Hongmin Cai",
            "Zhaoyuan Yu"
        ],
        "comments": " ",
        "subjects": "Numerical Analysis (math.NA)",
        "abstract": "The low-rank quaternion matrix approximation has been successfully applied in many applications involving signal processing and color image processing. However, the cost of quaternion models for generating low-rank quaternion matrix approximation is sometimes considerable due to the computation of the quaternion singular value decomposition (QSVD), which limits their application to real large-scale data. To address this deficiency, an efficient quaternion matrix CUR (QMCUR) method for low-rank approximation is suggested, which provides significant acceleration in color image processing. We first explore the QMCUR approximation method, which uses actual columns and rows of the given quaternion matrix, instead of the costly QSVD. Additionally, two different sampling strategies are used to sample the above-selected columns and rows. Then, the perturbation analysis is performed on the QMCUR approximation of noisy versions of low-rank quaternion matrices. Extensive experiments on both synthetic and real data further reveal the superiority of the proposed algorithm compared with other algorithms for getting low-rank approximation, in terms of both efficiency and accuracy.\n    ",
        "primary_category": "math.NA",
        "categories": [],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19155": {
        "title": "Beyond Language Models: Byte Models are Digital World Simulators",
        "authors": [
            "Shangda Wu",
            "Xu Tan",
            "Zili Wang",
            "Rui Wang",
            "Xiaobing Li",
            "Maosong Sun"
        ],
        "comments": "19 pages, 5 figures, 5 tables",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Traditional deep learning often overlooks bytes, the basic units of the digital world, where all forms of information and operations are encoded and manipulated in binary format. Inspired by the success of next token prediction in natural language processing, we introduce bGPT, a model with next byte prediction to simulate the digital world. bGPT matches specialized models in performance across various modalities, including text, audio, and images, and offers new possibilities for predicting, simulating, and diagnosing algorithm or hardware behaviour. It has almost flawlessly replicated the process of converting symbolic music data, achieving a low error rate of 0.0011 bits per byte in converting ABC notation to MIDI format. In addition, bGPT demonstrates exceptional capabilities in simulating CPU behaviour, with an accuracy exceeding 99.99% in executing various operations. Leveraging next byte prediction, models like bGPT can directly learn from vast binary data, effectively simulating the intricate patterns of the digital world.\n    ",
        "primary_category": "cs.LG",
        "categories": [],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19163": {
        "title": "FedStruct: Federated Decoupled Learning over Interconnected Graphs",
        "authors": [
            "Javad Aliakbari",
            "Johan \u00d6stman",
            "Alexandre Graell i Amat"
        ],
        "comments": "10 pages plus 13 pages of appendices",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "We address the challenge of federated learning on graph-structured data distributed across multiple clients. Specifically, we focus on the prevalent scenario of interconnected subgraphs, where inter-connections between different clients play a critical role. We present a novel framework for this scenario, named FedStruct, that harnesses deep structural dependencies. To uphold privacy, unlike existing methods, FedStruct eliminates the necessity of sharing or generating sensitive node features or embeddings among clients. Instead, it leverages explicit global graph structure information to capture inter-node dependencies. We validate the effectiveness of FedStruct through experimental results conducted on six datasets for semi-supervised node classification, showcasing performance close to the centralized approach across various scenarios, including different data partitioning methods, varying levels of label availability, and number of clients.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.IT"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19166": {
        "title": "Conversational Language Models for Human-in-the-Loop Multi-Robot Coordination",
        "authors": [
            "William Hunt",
            "Toby Godfrey",
            "Mohammad D. Soorati"
        ],
        "comments": " ",
        "subjects": "Robotics (cs.RO)",
        "abstract": "With the increasing prevalence and diversity of robots interacting in the real world, there is need for flexible, on-the-fly planning and cooperation. Large Language Models are starting to be explored in a multimodal setup for communication, coordination, and planning in robotics. Existing approaches generally use a single agent building a plan, or have multiple homogeneous agents coordinating for a simple task. We present a decentralised, dialogical approach in which a team of agents with different abilities plans solutions through peer-to-peer and human-robot discussion. We suggest that argument-style dialogues are an effective way to facilitate adaptive use of each agent's abilities within a cooperative team. Two robots discuss how to solve a cleaning problem set by a human, define roles, and agree on paths they each take. Each step can be interrupted by a human advisor and agents check their plans with the human. Agents then execute this plan in the real world, collecting rubbish from people in each room. Our implementation uses text at every step, maintaining transparency and effective human-multi-robot interaction.\n    ",
        "primary_category": "cs.RO",
        "categories": [],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19167": {
        "title": "Teaching Large Language Models an Unseen Language on the Fly",
        "authors": [
            "Chen Zhang",
            "Xiao Liu",
            "Jiuheng Lin",
            "Yansong Feng"
        ],
        "comments": " ",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "Existing large language models struggle to support numerous low-resource languages, particularly the extremely low-resource ones where there is minimal training data available for effective parameter updating. We thus investigate whether LLMs can learn a new language on the fly solely through prompting. To study this question, we collect a research suite for Zhuang, a language supported by no LLMs currently. We introduce \\textsc{DiPMT++}, a framework for adapting LLMs to unseen languages by in-context learning. Using a dictionary and only 5K parallel sentences, \\textsc{DiPMT++} significantly enhances the performance of GPT-4 from 0 to 16 BLEU for Chinese-to-Zhuang translation and achieves 32 BLEU for Zhuang-to-Chinese translation. Furthermore, we demonstrate the practical utility of this framework in aiding humans to translate completely unseen languages, which could contribute to the preservation of linguistic diversity.\n    ",
        "primary_category": "cs.CL",
        "categories": [],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19168": {
        "title": "Disturbance Decoupling Problem for $n$-link chain pendulum on a cart system",
        "authors": [
            "Sayar Das",
            "Deepak Patil"
        ],
        "comments": " ",
        "subjects": "Systems and Control (eess.SY)",
        "abstract": "A disturbance decoupling problem for a $n$-link chain pendulum on a cart is considered. A model of the cart developed in a coordinate-free framework and the linearized equations of this system are considered from [1]. It is shown that it is possible to design a suitable state feedback such that the angular position or velocity of the $n^{th}$-link can always be decoupled from the disturbance coming at the cart.\n    ",
        "primary_category": "eess.SY",
        "categories": [],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19171": {
        "title": "Towards Assessing Spread in Sets of Software Architecture Designs",
        "authors": [
            "Vittorio Cortellessa",
            "J. Andres Diaz-Pace",
            "Daniele Di Pompeo",
            "Michele Tucci"
        ],
        "comments": "17th European Conference on Software Architecture (ECSA 2023), 8 pages",
        "subjects": "Software Engineering (cs.SE)",
        "abstract": "Several approaches have recently used automated techniques to generate architecture design alternatives by means of optimization techniques. These approaches aim at improving an initial architecture with respect to quality aspects, such as performance, reliability, or maintainability. In this context, each optimization experiment usually produces a different set of architecture alternatives that is characterized by specific settings. As a consequence, the designer is left with the task of comparing such sets to identify the settings that lead to better solution sets for the problem. To assess the quality of solution sets, multi-objective optimization commonly relies on quality indicators. Among these, the quality indicator for the maximum spread estimates the diversity of the generated alternatives, providing a measure of how much of the solution space has been explored. However, the maximum spread indicator is computed only on the objective space and does not consider architectural information (e.g., components structure, design decisions) from the architectural space. In this paper, we propose a quality indicator for the spread that assesses the diversity of alternatives by taking into account architectural features. To compute the spread, we rely on a notion of distance between alternatives according to the way they were generated during the optimization. We demonstrate how our architectural quality indicator can be applied to a dataset from the literature.\n    ",
        "primary_category": "cs.SE",
        "categories": [
            "cs.PF"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19172": {
        "title": "Point Processes and spatial statistics in time-frequency analysis",
        "authors": [
            "Barbara Pascal",
            "R\u00e9mi Bardenet"
        ],
        "comments": "Submitted",
        "subjects": "Signal Processing (eess.SP)",
        "abstract": "A finite-energy signal is represented by a square-integrable, complex-valued function $t\\mapsto s(t)$ of a real variable $t$, interpreted as time. Similarly, a noisy signal is represented by a random process. Time-frequency analysis, a subfield of signal processing, amounts to describing the temporal evolution of the frequency content of a signal. Loosely speaking, if $s$ is the audio recording of a musical piece, time-frequency analysis somehow consists in writing the musical score of the piece. Mathematically, the operation is performed through a transform $\\mathcal{V}$, mapping $s \\in L^2(\\mathbb{R})$ onto a complex-valued function $\\mathcal{V}s \\in L^2(\\mathbb{R}^2)$ of time $t$ and angular frequency $\\omega$. The squared modulus $(t, \\omega) \\mapsto \\vert\\mathcal{V}s(t,\\omega)\\vert^2$ of the time-frequency representation is known as the spectrogram of $s$; in the musical score analogy, a peaked spectrogram at $(t_0,\\omega_0)$ corresponds to a musical note at angular frequency $\\omega_0$ localized at time $t_0$. More generally, the intuition is that upper level sets of the spectrogram contain relevant information about in the original signal. Hence, many signal processing algorithms revolve around identifying maxima of the spectrogram. In contrast, zeros of the spectrogram indicate perfect silence, that is, a time at which a particular frequency is absent. Assimilating $\\mathbb{R}^2$ to $\\mathbb{C}$ through $z = \\omega + \\mathrm{i}t$, this chapter focuses on time-frequency transforms $\\mathcal{V}$ that map signals to analytic functions. The zeros of the spectrogram of a noisy signal are then the zeros of a random analytic function, hence forming a Point Process in $\\mathbb{C}$. This chapter is devoted to the study of these Point Processes, to their links with zeros of Gaussian Analytic Functions, and to designing signal detection and denoising algorithms using spatial statistics.\n    ",
        "primary_category": "eess.SP",
        "categories": [
            "cs.SD",
            "eess.AS",
            "math.PR"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19173": {
        "title": "StarCoder 2 and The Stack v2: The Next Generation",
        "authors": [
            "Anton Lozhkov",
            "Raymond Li",
            "Loubna Ben Allal",
            "Federico Cassano",
            "Joel Lamy-Poirier",
            "Nouamane Tazi",
            "Ao Tang",
            "Dmytro Pykhtar",
            "Jiawei Liu",
            "Yuxiang Wei",
            "Tianyang Liu",
            "Max Tian",
            "Denis Kocetkov",
            "Arthur Zucker",
            "Younes Belkada",
            "Zijian Wang",
            "Qian Liu",
            "Dmitry Abulkhanov",
            "Indraneil Paul",
            "Zhuang Li",
            "Wen-Ding Li",
            "Megan Risdal",
            "Jia Li",
            "Jian Zhu",
            "Terry Yue Zhuo",
            "Evgenii Zheltonozhskii",
            "Nii Osae Osae Dade",
            "Wenhao Yu",
            "Lucas Krau\u00df",
            "Naman Jain",
            "Yixuan Su",
            "Xuanli He",
            "Manan Dey",
            "Edoardo Abati",
            "Yekun Chai",
            "Niklas Muennighoff",
            "Xiangru Tang",
            "Muhtasham Oblokulov",
            "Christopher Akiki",
            "Marc Marone",
            "Chenghao Mou",
            "Mayank Mishra",
            "Alex Gu",
            "Binyuan Hui",
            "Tri Dao",
            "Armel Zebaze",
            "Olivier Dehaene",
            "Nicolas Patry",
            "Canwen Xu",
            "Julian McAuley",
            "Han Hu",
            "Torsten Scholak",
            "Sebastien Paquet",
            "Jennifer Robinson",
            "Carolyn Jane Anderson",
            "Nicolas Chapados",
            "Mostofa Patwary",
            "Nima Tajbakhsh",
            "Yacine Jernite",
            "Carlos Mu\u00f1oz Ferrandis",
            "Lingming Zhang",
            "Sean Hughes",
            "Thomas Wolf",
            "Arjun Guha",
            "Leandro von Werra",
            "Harm de Vries"
        ],
        "comments": " ",
        "subjects": "Software Engineering (cs.SE)",
        "abstract": "The BigCode project, an open-scientific collaboration focused on the responsible development of Large Language Models for Code (Code LLMs), introduces StarCoder2. In partnership with Software Heritage (SWH), we build The Stack v2 on top of the digital commons of their source code archive. Alongside the SWH repositories spanning 619 programming languages, we carefully select other high-quality data sources, such as GitHub pull requests, Kaggle notebooks, and code documentation. This results in a training set that is 4x larger than the first StarCoder dataset. We train StarCoder2 models with 3B, 7B, and 15B parameters on 3.3 to 4.3 trillion tokens and thoroughly evaluate them on a comprehensive set of Code LLM benchmarks. We find that our small model, StarCoder2-3B, outperforms other Code LLMs of similar size on most benchmarks, and also outperforms StarCoderBase-15B. Our large model, StarCoder2- 15B, significantly outperforms other models of comparable size. In addition, it matches or outperforms CodeLlama-34B, a model more than twice its size. Although DeepSeekCoder- 33B is the best-performing model at code completion for high-resource languages, we find that StarCoder2-15B outperforms it on math and code reasoning benchmarks, as well as several low-resource languages. We make the model weights available under an OpenRAIL license and ensure full transparency regarding the training data by releasing the SoftWare Heritage persistent IDentifiers (SWHIDs) of the source code data.\n    ",
        "primary_category": "cs.SE",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19180": {
        "title": "ModZoo: A Large-Scale Study of Modded Android Apps and their Markets",
        "authors": [
            "Luis A. Saavedra",
            "Hridoy S. Dutta",
            "Alastair R. Beresford",
            "Alice Hutchings"
        ],
        "comments": " ",
        "subjects": "Other Computer Science (cs.OH)",
        "abstract": "We present the results of the first large-scale study into Android markets that offer modified or modded apps: apps whose features and functionality have been altered by a third-party. We analyse over 146k (thousand) apps obtained from 13 of the most popular modded app markets. Around 90% of apps we collect are altered in some way when compared to the official counterparts on Google Play. Modifications include games cheats, such as infinite coins or lives; mainstream apps with premium features provided for free; and apps with modified advertising identifiers or excluded ads. We find the original app developers lose significant potential revenue due to: the provision of paid for apps for free (around 5% of the apps across all markets); the free availability of premium features that require payment in the official app; and modified advertising identifiers. While some modded apps have all trackers and ads removed (3%), in general, the installation of these apps is significantly more risky for the user than the official version: modded apps are ten times more likely to be marked as malicious and often request additional permissions.\n    ",
        "primary_category": "cs.OH",
        "categories": [
            "cs.CR",
            "cs.SE"
        ],
        "submitted_date": "15 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19184": {
        "title": "Data Transfer Optimizations for Host-CPU and Accelerators in AXI4MLIR",
        "authors": [
            "Jude Haris",
            "Nicolas Bohm Agostini",
            "Antonino Tumeo",
            "David Kaeli",
            "Jos\u00e9 Cano"
        ],
        "comments": " ",
        "subjects": "Programming Languages (cs.PL)",
        "abstract": "As custom hardware accelerators become more prevalent, it becomes increasingly important to automatically generate efficient host-driver code that can fully leverage the capabilities of these accelerators. This approach saves time and reduces the likelihood of errors that can occur during manual implementation. AXI4MLIR extends the MLIR compiler framework to generate host-driver code for custom accelerators for linear algebra problems. By leveraging specific compiler optimizations, we can further increase accelerator utilization.\nIn this work we offer two key observations through a MatMul accelerator case study. First, the accelerator's compute core utilization is less than 10%, and second, the critical latency bottleneck is caused by copying data between the heap and memory-mapped DMA buffers. We identify a set of missing host code optimizations to improve the under-utilization and the latency bottleneck. Therefore, we propose three key host-code data-movement-related optimizations, extending AXI4MLIR. The optimizations provide DMA-based data allocation, coalescing of DMA transfers, and pipelining of the accelerator's load, compute, and store stages.\n    ",
        "primary_category": "cs.PL",
        "categories": [],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19186": {
        "title": "Disentangling representations of retinal images with generative models",
        "authors": [
            "Sarah M\u00fcller",
            "Lisa M. Koch",
            "Hendrik P. A. Lensch",
            "Philipp Berens"
        ],
        "comments": " ",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Retinal fundus images play a crucial role in the early detection of eye diseases and, using deep learning approaches, recent studies have even demonstrated their potential for detecting cardiovascular risk factors and neurological disorders. However, the impact of technical factors on these images can pose challenges for reliable AI applications in ophthalmology. For example, large fundus cohorts are often confounded by factors like camera type, image quality or illumination level, bearing the risk of learning shortcuts rather than the causal relationships behind the image generation process. Here, we introduce a novel population model for retinal fundus images that effectively disentangles patient attributes from camera effects, thus enabling controllable and highly realistic image generation. To achieve this, we propose a novel disentanglement loss based on distance correlation. Through qualitative and quantitative analyses, we demonstrate the effectiveness of this novel loss function in disentangling the learned subspaces. Our results show that our model provides a new perspective on the complex relationship between patient attributes and technical confounders in retinal fundus image generation.\n    ",
        "primary_category": "cs.CV",
        "categories": [
            "cs.LG"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19189": {
        "title": "Link Recommendation to Augment Influence Diffusion with Provable Guarantees",
        "authors": [
            "Xiaolong Chen",
            "Yifan Song",
            "Jing Tang"
        ],
        "comments": "TheWebConf'24; Corresponding author: Jing Tang",
        "subjects": "Social and Information Networks (cs.SI)",
        "abstract": "Link recommendation systems in online social networks (OSNs), such as Facebook's ``People You May Know'', Twitter's ``Who to Follow'', and Instagram's ``Suggested Accounts'', facilitate the formation of new connections among users. This paper addresses the challenge of link recommendation for the purpose of social influence maximization. In particular, given a graph $G$ and the seed set $S$, our objective is to select $k$ edges that connect seed nodes and ordinary nodes to optimize the influence dissemination of the seed set. This problem, referred to as influence maximization with augmentation (IMA), has been proven to be NP-hard.\nIn this paper, we propose an algorithm, namely \\textsf{AIS}, consisting of an efficient estimator for augmented influence estimation and an accelerated sampling approach. \\textsf{AIS} provides a $(1-1/\\mathrm{e}-\\varepsilon)$-approximate solution with a high probability of $1-\\delta$, and runs in $O(k^2 (m+n) \\log (n / \\delta) / \\varepsilon^2 + k \\left|E_{\\mathcal{C}}\\right|)$ time assuming that the influence of any singleton node is smaller than that of the seed set. To the best of our knowledge, this is the first algorithm that can be implemented on large graphs containing millions of nodes while preserving strong theoretical guarantees. We conduct extensive experiments to demonstrate the effectiveness and efficiency of our proposed algorithm.\n    ",
        "primary_category": "cs.SI",
        "categories": [],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19191": {
        "title": "An asymptotic-preserving method for the three-temperature radiative transfer model",
        "authors": [
            "Ruo Li",
            "Weiming Li",
            "Shengtong Liang",
            "Yuehan Shao",
            "Min Tang",
            "Yanli Wang"
        ],
        "comments": " ",
        "subjects": "Numerical Analysis (math.NA)",
        "abstract": "We present an asymptotic-preserving (AP) numerical method for solving the three-temperature radiative transfer model, which holds significant importance in inertial confinement fusion. A carefully designedsplitting method is developed that can provide a general framework of extending AP schemes for the gray radiative transport equation to the more complex three-temperature radiative transfer model. The proposed scheme captures two important limiting models: the three-temperature radiation diffusion equation (3TRDE) when opacity approaches infinity and the two-temperature limit when the ion-electron coupling coefficient goes to infinity. We have rigorously demonstrated the AP property and energy conservation characteristics of the proposed scheme and its efficiency has been validated through a series of benchmark tests in the numerical part.\n    ",
        "primary_category": "math.NA",
        "categories": [
            "math-ph"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19194": {
        "title": "High Expectations: An Observational Study of Programming and Cannabis Intoxication",
        "authors": [
            "Wenxin He",
            "Manasvi Parikh",
            "Westley Weimer",
            "Madeline Endres"
        ],
        "comments": "To appear in the proceedings of the International Conference of Software Engineering (ICSE), 2024",
        "subjects": "Software Engineering (cs.SE)",
        "abstract": "Anecdotal evidence of cannabis use by professional programmers abounds. Recent studies have found that some professionals regularly use cannabis while programming even for work-related tasks. However, accounts of the impacts of cannabis on programming vary widely and are often contradictory. For example, some programmers claim that it impairs their ability to generate correct solutions while others claim it enhances creativity and focus. There remains a need for an empirical understanding of the true impacts of cannabis on programming. This paper presents the first controlled observational study of the effects of cannabis on programming ability. Based on a within-subjects design with over 70 participants, we find that at ecologically valid dosages, cannabis significantly impairs programming performance. Programs implemented while high contain more bugs and take longer to write (p < 0.05), a small to medium effect (0.22 <= d <= 0.44). We also did not find any evidence that high programmers generate more divergent solutions. However, programmers can accurately assess differences in their programming performance (r = 0.59), even when under the influence of cannabis. We hope that this research will facilitate evidence-based policies and help developers make informed decisions regarding cannabis use while programming.\n    ",
        "primary_category": "cs.SE",
        "categories": [],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19195": {
        "title": "Negative Sampling in Knowledge Graph Representation Learning: A Review",
        "authors": [
            "Tiroshan Madushanka",
            "Ryutaro Ichise"
        ],
        "comments": " ",
        "subjects": "Artificial Intelligence (cs.AI)",
        "abstract": "Knowledge graph representation learning (KGRL) or knowledge graph embedding (KGE) plays a crucial role in AI applications for knowledge construction and information exploration. These models aim to encode entities and relations present in a knowledge graph into a lower-dimensional vector space. During the training process of KGE models, using positive and negative samples becomes essential for discrimination purposes. However, obtaining negative samples directly from existing knowledge graphs poses a challenge, emphasizing the need for effective generation techniques. The quality of these negative samples greatly impacts the accuracy of the learned embeddings, making their generation a critical aspect of KGRL. This comprehensive survey paper systematically reviews various negative sampling (NS) methods and their contributions to the success of KGRL. Their respective advantages and disadvantages are outlined by categorizing existing NS methods into five distinct categories. Moreover, this survey identifies open research questions that serve as potential directions for future investigations. By offering a generalization and alignment of fundamental NS concepts, this survey provides valuable insights for designing effective NS methods in the context of KGRL and serves as a motivating force for further advancements in the field.\n    ",
        "primary_category": "cs.AI",
        "categories": [],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19196": {
        "title": "Generative models struggle with kirigami metamaterials",
        "authors": [
            "Gerrit Felsch",
            "Viacheslav Slesarenko"
        ],
        "comments": " ",
        "subjects": "Computational Engineering, Finance, and Science (cs.CE)",
        "abstract": "Generative machine learning models have shown notable success in identifying architectures for metamaterials - materials whose behavior is determined primarily by their internal organization - that match specific target properties. By examining kirigami metamaterials, in which dependencies between cuts yield complex design restrictions, we demonstrate that this perceived success in the employment of generative models for metamaterials might be akin to survivorship bias. We assess the performance of the four most popular generative models - the Variational Autoencoder (VAE), the Generative Adversarial Network (GAN), the Wasserstein GAN (WGAN), and the Denoising Diffusion Probabilistic Model (DDPM) - in generating kirigami structures. Prohibiting cut intersections can prevent the identification of an appropriate similarity measure for kirigami metamaterials, significantly impacting the effectiveness of VAE and WGAN, which rely on the Euclidean distance - a metric shown to be unsuitable for considered geometries. This imposes significant limitations on employing modern generative models for the creation of diverse metamaterials.\n    ",
        "primary_category": "cs.CE",
        "categories": [
            "cond-mat.mtrl-sci",
            "cond-mat.soft"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19197": {
        "title": "Fine Structure-Aware Sampling: A New Sampling Training Scheme for Pixel-Aligned Implicit Models in Single-View Human Reconstruction",
        "authors": [
            "Kennard Yanting Chan",
            "Fayao Liu",
            "Guosheng Lin",
            "Chuan Sheng Foo",
            "Weisi Lin"
        ],
        "comments": "Accepted in Proceedings of the AAAI Conference on Artificial Intelligence, 2024 (AAAI 2024)",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Pixel-aligned implicit models, such as PIFu, PIFuHD, and ICON, are used for single-view clothed human reconstruction. These models need to be trained using a sampling training scheme. Existing sampling training schemes either fail to capture thin surfaces (e.g. ears, fingers) or cause noisy artefacts in reconstructed meshes. To address these problems, we introduce Fine Structured-Aware Sampling (FSS), a new sampling training scheme to train pixel-aligned implicit models for single-view human reconstruction. FSS resolves the aforementioned problems by proactively adapting to the thickness and complexity of surfaces. In addition, unlike existing sampling training schemes, FSS shows how normals of sample points can be capitalized in the training process to improve results. Lastly, to further improve the training process, FSS proposes a mesh thickness loss signal for pixel-aligned implicit models. It becomes computationally feasible to introduce this loss once a slight reworking of the pixel-aligned implicit function framework is carried out. Our results show that our methods significantly outperform SOTA methods qualitatively and quantitatively. Our code is publicly available at this https URL.\n    ",
        "primary_category": "cs.CV",
        "categories": [
            "cs.AI",
            "cs.LG"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19199": {
        "title": "Rewriting and Inductive Reasoning",
        "authors": [
            "M\u00e1rton Hajdu",
            "Laura Kov\u00e1cs",
            "Michael Rawson"
        ],
        "comments": " ",
        "subjects": "Logic in Computer Science (cs.LO)",
        "abstract": "Rewriting techniques based on reduction orderings generate \"just enough\" consequences to retain first-order completeness. This is ideal for superposition-based first-order theorem proving, but for at least one approach to inductive reasoning we show that we are missing crucial consequences. We therefore extend the superposition calculus with rewriting-based techniques to generate sufficient consequences for automating induction in saturation. When applying our work within the unit-equational fragment, our experiments with the theorem prover Vampire show significant improvements for inductive reasoning.\n    ",
        "primary_category": "cs.LO",
        "categories": [],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19200": {
        "title": "PRSA: Prompt Reverse Stealing Attacks against Large Language Models",
        "authors": [
            "Yong Yang",
            "Xuhong Zhang",
            "Yi Jiang",
            "Xi Chen",
            "Haoyu Wang",
            "Shouling Ji",
            "Zonghui Wang"
        ],
        "comments": " ",
        "subjects": "Cryptography and Security (cs.CR)",
        "abstract": "Prompt, recognized as crucial intellectual property, enables large language models (LLMs) to perform specific tasks without the need of fine-tuning, underscoring their escalating importance. With the rise of prompt-based services, such as prompt marketplaces and LLM applications, providers often display prompts' capabilities through input-output examples to attract users. However, this paradigm raises a pivotal security concern: does the exposure of input-output pairs pose the risk of potential prompt leakage, infringing on the intellectual property rights of the developers? To our knowledge, this problem still has not been comprehensively explored yet. To remedy this gap, in this paper, we perform the first in depth exploration and propose a novel attack framework for reverse-stealing prompts against commercial LLMs, namely PRSA. The main idea of PRSA is that by analyzing the critical features of the input-output pairs, we mimic and gradually infer (steal) the target prompts. In detail, PRSA mainly consists of two key phases: prompt mutation and prompt pruning. In the mutation phase, we propose a prompt attention algorithm based on differential feedback to capture these critical features for effectively inferring the target prompts. In the prompt pruning phase, we identify and mask the words dependent on specific inputs, enabling the prompts to accommodate diverse inputs for generalization. Through extensive evaluation, we verify that PRSA poses a severe threat in real world scenarios. We have reported these findings to prompt service providers and actively collaborate with them to take protective measures for prompt copyright.\n    ",
        "primary_category": "cs.CR",
        "categories": [
            "cs.CL"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19204": {
        "title": "PeLLE: Encoder-based language models for Brazilian Portuguese based on open data",
        "authors": [
            "Guilherme Lamartine de Mello",
            "Marcelo Finger",
            "and Felipe Serras",
            "Miguel de Mello Carpi",
            "Marcos Menon Jose",
            "Pedro Henrique Domingues",
            "Paulo Cavalim"
        ],
        "comments": "15 pages",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "In this paper we present PeLLE, a family of large language models based on the RoBERTa architecture, for Brazilian Portuguese, trained on curated, open data from the Carolina corpus. Aiming at reproducible results, we describe details of the pretraining of the models. We also evaluate PeLLE models against a set of existing multilingual and PT-BR refined pretrained Transformer-based LLM encoders, contrasting performance of large versus smaller-but-curated pretrained models in several downstream tasks. We conclude that several tasks perform better with larger models, but some tasks benefit from smaller-but-curated data in its pretraining.\n    ",
        "primary_category": "cs.CL",
        "categories": [],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19215": {
        "title": "Training Generative Image Super-Resolution Models by Wavelet-Domain Losses Enables Better Control of Artifacts",
        "authors": [
            "Cansu Korkmaz",
            "A. Murat Tekalp",
            "Zafer Dogan"
        ],
        "comments": "Accepted for IEEE CVPR 2024, total of 11 pages, 3 pages for references, 7 figures and 2 tables",
        "subjects": "Image and Video Processing (eess.IV)",
        "abstract": "Super-resolution (SR) is an ill-posed inverse problem, where the size of the set of feasible solutions that are consistent with a given low-resolution image is very large. Many algorithms have been proposed to find a \"good\" solution among the feasible solutions that strike a balance between fidelity and perceptual quality. Unfortunately, all known methods generate artifacts and hallucinations while trying to reconstruct high-frequency (HF) image details. A fundamental question is: Can a model learn to distinguish genuine image details from artifacts? Although some recent works focused on the differentiation of details and artifacts, this is a very challenging problem and a satisfactory solution is yet to be found. This paper shows that the characterization of genuine HF details versus artifacts can be better learned by training GAN-based SR models using wavelet-domain loss functions compared to RGB-domain or Fourier-space losses. Although wavelet-domain losses have been used in the literature before, they have not been used in the context of the SR task. More specifically, we train the discriminator only on the HF wavelet sub-bands instead of on RGB images and the generator is trained by a fidelity loss over wavelet subbands to make it sensitive to the scale and orientation of structures. Extensive experimental results demonstrate that our model achieves better perception-distortion trade-off according to multiple objective measures and visual evaluations.\n    ",
        "primary_category": "eess.IV",
        "categories": [
            "cs.CV"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19218": {
        "title": "Memory-Augmented Generative Adversarial Transformers",
        "authors": [
            "Stephan Raaijmakers",
            "Roos Bakker",
            "Anita Cremers",
            "Roy de Kleijn",
            "Tom Kouwenhoven",
            "Tessa Verhoef"
        ],
        "comments": " ",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "Conversational AI systems that rely on Large Language Models, like Transformers, have difficulty interweaving external data (like facts) with the language they generate. Vanilla Transformer architectures are not designed for answering factual questions with high accuracy. This paper investigates a possible route for addressing this problem. We propose to extend the standard Transformer architecture with an additional memory bank holding extra information (such as facts drawn from a knowledge base), and an extra attention layer for addressing this memory. We add this augmented memory to a Generative Adversarial Network-inspired Transformer architecture. This setup allows for implementing arbitrary felicity conditions on the generated language of the Transformer. We first demonstrate how this machinery can be deployed for handling factual questions in goal-oriented dialogues. Secondly, we demonstrate that our approach can be useful for applications like {\\it style adaptation} as well: the adaptation of utterances according to certain stylistic (external) constraints, like social properties of human interlocutors in dialogues.\n    ",
        "primary_category": "cs.CL",
        "categories": [],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19222": {
        "title": "Airport take-off and landing optimization through genetic algorithms",
        "authors": [
            "Fernando Guedan Pecker",
            "Cristian Ramirez Atencia"
        ],
        "comments": "Preprint submitted and accepted in Expert Systems",
        "subjects": "Neural and Evolutionary Computing (cs.NE)",
        "abstract": "This research addresses the crucial issue of pollution from aircraft operations, focusing on optimizing both gate allocation and runway scheduling simultaneously, a novel approach not previously explored. The study presents an innovative genetic algorithm-based method for minimizing pollution from fuel combustion during aircraft take-off and landing at airports. This algorithm uniquely integrates the optimization of both landing gates and take-off/landing runways, considering the correlation between engine operation time and pollutant levels. The approach employs advanced constraint handling techniques to manage the intricate time and resource limitations inherent in airport operations. Additionally, the study conducts a thorough sensitivity analysis of the model, with a particular emphasis on the mutation factor and the type of penalty function, to fine-tune the optimization process. This dual-focus optimization strategy represents a significant advancement in reducing environmental impact in the aviation sector, establishing a new standard for comprehensive and efficient airport operation management.\n    ",
        "primary_category": "cs.NE",
        "categories": [],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19223": {
        "title": "Edit and Alphabet-Ordering Sensitivity of Lex-parse",
        "authors": [
            "Yuto Nakashima",
            "Dominik K\u00f6ppl",
            "Mitsuru Funakoshi",
            "Shunsuke Inenaga",
            "Hideo Bannai"
        ],
        "comments": " ",
        "subjects": "Data Structures and Algorithms (cs.DS)",
        "abstract": "We investigate the compression sensitivity [Akagi et al., 2023] of lex-parse [Navarro et al., 2021] for two operations: (1) single character edit and (2) modification of the alphabet ordering, and give tight upper and lower bounds for both operations. For both lower bounds, we use the family of Fibonacci words. For the bounds on edit operations, our analysis makes heavy use of properties of the Lyndon factorization of Fibonacci words to characterize the structure of lex-parse.\n    ",
        "primary_category": "cs.DS",
        "categories": [],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19229": {
        "title": "CAPTURE-24: A large dataset of wrist-worn activity tracker data collected in the wild for human activity recognition",
        "authors": [
            "Shing Chan",
            "Hang Yuan",
            "Catherine Tong",
            "Aidan Acquah",
            "Abram Schonfeldt",
            "Jonathan Gershuny",
            "Aiden Doherty"
        ],
        "comments": " ",
        "subjects": "Human-Computer Interaction (cs.HC)",
        "abstract": "Existing activity tracker datasets for human activity recognition are typically obtained by having participants perform predefined activities in an enclosed environment under supervision. This results in small datasets with a limited number of activities and heterogeneity, lacking the mixed and nuanced movements normally found in free-living scenarios. As such, models trained on laboratory-style datasets may not generalise out of sample. To address this problem, we introduce a new dataset involving wrist-worn accelerometers, wearable cameras, and sleep diaries, enabling data collection for over 24 hours in a free-living setting. The result is CAPTURE-24, a large activity tracker dataset collected in the wild from 151 participants, amounting to 3883 hours of accelerometer data, of which 2562 hours are annotated. CAPTURE-24 is two to three orders of magnitude larger than existing publicly available datasets, which is critical to developing accurate human activity recognition models.\n    ",
        "primary_category": "cs.HC",
        "categories": [],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19232": {
        "title": "Trained Random Forests Completely Reveal your Dataset",
        "authors": [
            "Julien Ferry",
            "Ricardo Fukasawa",
            "Timoth\u00e9e Pascal",
            "Thibaut Vidal"
        ],
        "comments": " ",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "We introduce an optimization-based reconstruction attack capable of completely or near-completely reconstructing a dataset utilized for training a random forest. Notably, our approach relies solely on information readily available in commonly used libraries such as scikit-learn. To achieve this, we formulate the reconstruction problem as a combinatorial problem under a maximum likelihood objective. We demonstrate that this problem is NP-hard, though solvable at scale using constraint programming -- an approach rooted in constraint propagation and solution-domain reduction. Through an extensive computational investigation, we demonstrate that random forests trained without bootstrap aggregation but with feature randomization are susceptible to a complete reconstruction. This holds true even with a small number of trees. Even with bootstrap aggregation, the majority of the data can also be reconstructed. These findings underscore a critical vulnerability inherent in widely adopted ensemble methods, warranting attention and mitigation. Although the potential for such reconstruction attacks has been discussed in privacy research, our study provides clear empirical evidence of their practicability.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.CR"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19233": {
        "title": "Shared lightweight autonomous vehicles for urban food deliveries: A simulation study",
        "authors": [
            "Ainhoa Genua Cervi\u00f1o",
            "Naroa Coretti Sanchez",
            "Elaine Liu Wang",
            "Arnaud Grignard",
            "Kent Larson"
        ],
        "comments": "17 pages, 25 including abstract, 16 figures, journal paper",
        "subjects": "Computers and Society (cs.CY)",
        "abstract": "In recent years, the rapid growth of on-demand deliveries, especially in food deliveries, has spurred the exploration of innovative mobility solutions. In this context, lightweight autonomous vehicles have emerged as a potential alternative. However, their fleet-level behavior remains largely unexplored. To address this gap, we have developed an agent-based model and an environmental impact study assessing the fleet performance of lightweight autonomous food delivery vehicles. This model explores critical factors such as fleet sizing, service level, operational strategies, and environmental impacts. We have applied this model to a case study in Cambridge, MA, USA, where results indicate that there could be environmental benefits in replacing traditional car-based deliveries with shared lightweight autonomous vehicle fleets. Lastly, we introduce an interactive platform that offers a user-friendly means of comprehending the model's performance and potential trade-offs, which can help inform decision-makers in the evolving landscape of food delivery innovation.\n    ",
        "primary_category": "cs.CY",
        "categories": [],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19234": {
        "title": "Broadcast independence number of oriented circulant graphs",
        "authors": [
            "Abdelamin Laouar",
            "Isma Bouchemakh",
            "Eric Sopena"
        ],
        "comments": "arXiv admin note: text overlap with arXiv:2102.04094",
        "subjects": "Combinatorics (math.CO)",
        "abstract": "In 2001, D. Erwin \\cite{Erw01} introduced in his Ph.D. dissertation the notion of broadcast independence in unoriented graphs. Since then, some results but not many, are published on this notion, including research work on the broadcast independence number of unoriented circulant graphs \\cite{LBS23}. In this paper, we are focused in the same parameter but of the class of oriented circulant graphs. An independent broadcast on an oriented graph $\\overrightarrow{G}$ is a function $f: V\\longrightarrow \\{0,\\ldots,\\diam(\\overrightarrow{G})\\}$ such that $(i)$ $f(v)\\leq e(v)$ for every vertex $v\\in V(\\overrightarrow{G})$, where $\\diam(\\overrightarrow{G})$ denotes the diameter of $\\overrightarrow{G}$ and $e(v)$ the eccentricity of vertex $v$, and $(ii)$ $d_{\\overrightarrow{G}}(u,v) > f(u)$ for every distinct vertices $u$, $v$ with $f(u)$, $f(v)>0$, where $d_{\\overrightarrow{G}}(u,v)$ denotes the length of a shortest oriented path from $u$ to $v$. The broadcast independence number $\\beta_b(\\overrightarrow{G})$ of $\\overrightarrow{G}$ is then the maximum value of $\\sum_{v \\in V} f(v)$, taken over all independent broadcasts on $\\overrightarrow{G}$. The goal of this paper is to study the properties of independent broadcasts of oriented circulant graphs $\\overrightarrow{C}(n;1,a)$, for any integers $n$ and $a$ with $n>|a|\\geq 1$ and $a \\notin \\{1,n-1\\}$. Then, we give some bounds and some exact values for the number $\\beta_b(\\overrightarrow{C}(n;1,a))$.\n    ",
        "primary_category": "math.CO",
        "categories": [
            "cs.DM"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19237": {
        "title": "Context-based Interpretable Spatio-Temporal Graph Convolutional Network for Human Motion Forecasting",
        "authors": [
            "Edgar Medina",
            "Leyong Loh",
            "Namrata Gurung",
            "Kyung Hun Oh",
            "Niels Heller"
        ],
        "comments": "10 pages, 6 figures",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Human motion prediction is still an open problem extremely important for autonomous driving and safety applications. Due to the complex spatiotemporal relation of motion sequences, this remains a challenging problem not only for movement prediction but also to perform a preliminary interpretation of the joint connections. In this work, we present a Context-based Interpretable Spatio-Temporal Graph Convolutional Network (CIST-GCN), as an efficient 3D human pose forecasting model based on GCNs that encompasses specific layers, aiding model interpretability and providing information that might be useful when analyzing motion distribution and body behavior. Our architecture extracts meaningful information from pose sequences, aggregates displacements and accelerations into the input model, and finally predicts the output displacements. Extensive experiments on Human 3.6M, AMASS, 3DPW, and ExPI datasets demonstrate that CIST-GCN outperforms previous methods in human motion prediction and robustness. Since the idea of enhancing interpretability for motion prediction has its merits, we showcase experiments towards it and provide preliminary evaluations of such insights here. available code: this https URL\n",
        "primary_category": "cs.CV",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "21 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19242": {
        "title": "Derivative-enhanced Deep Operator Network",
        "authors": [
            "Yuan Qiu",
            "Nolan Bridges",
            "Peng Chen"
        ],
        "comments": " ",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Deep operator networks (DeepONets), a class of neural operators that learn mappings between function spaces, have recently been developed as surrogate models for parametric partial differential equations (PDEs). In this work we propose a derivative-enhanced deep operator network (DE-DeepONet), which leverages the derivative information to enhance the prediction accuracy, and provide a more accurate approximation of the derivatives, especially when the training data are limited. DE-DeepONet incorporates dimension reduction of input into DeepONet and includes two types of derivative labels in the loss function for training, that is, the directional derivatives of the output function with respect to the input function and the gradient of the output function with respect to the physical domain variables. We test DE-DeepONet on three different equations with increasing complexity to demonstrate its effectiveness compared to the vanilla DeepONet.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.CE",
            "math.NA"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19249": {
        "title": "Mirage: Cross-Embodiment Zero-Shot Policy Transfer with Cross-Painting",
        "authors": [
            "Lawrence Yunliang Chen",
            "Kush Hari",
            "Karthik Dharmarajan",
            "Chenfeng Xu",
            "Quan Vuong",
            "Ken Goldberg"
        ],
        "comments": "Project page: this https URL",
        "subjects": "Robotics (cs.RO)",
        "abstract": "The ability to reuse collected data and transfer trained policies between robots could alleviate the burden of additional data collection and training. While existing approaches such as pretraining plus finetuning and co-training show promise, they do not generalize to robots unseen in training. Focusing on common robot arms with similar workspaces and 2-jaw grippers, we investigate the feasibility of zero-shot transfer. Through simulation studies on 8 manipulation tasks, we find that state-based Cartesian control policies can successfully zero-shot transfer to a target robot after accounting for forward dynamics. To address robot visual disparities for vision-based policies, we introduce Mirage, which uses \"cross-painting\"--masking out the unseen target robot and inpainting the seen source robot--during execution in real time so that it appears to the policy as if the trained source robot were performing the task. Despite its simplicity, our extensive simulation and physical experiments provide strong evidence that Mirage can successfully zero-shot transfer between different robot arms and grippers with only minimal performance degradation on a variety of manipulation tasks such as picking, stacking, and assembly, significantly outperforming a generalist policy. Project website: this https URL\n",
        "primary_category": "cs.RO",
        "categories": [],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19250": {
        "title": "Feature boosting with efficient attention for scene parsing",
        "authors": [
            "Vivek Singh",
            "Shailza Sharma",
            "Fabio Cuzzolin"
        ],
        "comments": " ",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "The complexity of scene parsing grows with the number of object and scene classes, which is higher in unrestricted open scenes. The biggest challenge is to model the spatial relation between scene elements while succeeding in identifying objects at smaller scales. This paper presents a novel feature-boosting network that gathers spatial context from multiple levels of feature extraction and computes the attention weights for each level of representation to generate the final class labels. A novel `channel attention module' is designed to compute the attention weights, ensuring that features from the relevant extraction stages are boosted while the others are attenuated. The model also learns spatial context information at low resolution to preserve the abstract spatial relationships among scene elements and reduce computation cost. Spatial attention is subsequently concatenated into a final feature set before applying feature boosting. Low-resolution spatial attention features are trained using an auxiliary task that helps learning a coarse global scene structure. The proposed model outperforms all state-of-the-art models on both the ADE20K and the Cityscapes datasets.\n    ",
        "primary_category": "cs.CV",
        "categories": [],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19251": {
        "title": "A Cognitive-Based Trajectory Prediction Approach for Autonomous Driving",
        "authors": [
            "Haicheng Liao",
            "Yongkang Li",
            "Zhenning Li",
            "Chengyue Wang",
            "Zhiyong Cui",
            "Shengbo Eben Li",
            "Chengzhong Xu"
        ],
        "comments": " ",
        "subjects": "Artificial Intelligence (cs.AI)",
        "abstract": "In autonomous vehicle (AV) technology, the ability to accurately predict the movements of surrounding vehicles is paramount for ensuring safety and operational efficiency. Incorporating human decision-making insights enables AVs to more effectively anticipate the potential actions of other vehicles, significantly improving prediction accuracy and responsiveness in dynamic environments. This paper introduces the Human-Like Trajectory Prediction (HLTP) model, which adopts a teacher-student knowledge distillation framework inspired by human cognitive processes. The HLTP model incorporates a sophisticated teacher-student knowledge distillation framework. The \"teacher\" model, equipped with an adaptive visual sector, mimics the visual processing of the human brain, particularly the functions of the occipital and temporal lobes. The \"student\" model focuses on real-time interaction and decision-making, drawing parallels to prefrontal and parietal cortex functions. This approach allows for dynamic adaptation to changing driving scenarios, capturing essential perceptual cues for accurate prediction. Evaluated using the Macao Connected and Autonomous Driving (MoCAD) dataset, along with the NGSIM and HighD benchmarks, HLTP demonstrates superior performance compared to existing models, particularly in challenging environments with incomplete data. The project page is available at Github.\n    ",
        "primary_category": "cs.AI",
        "categories": [
            "cs.RO"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19254": {
        "title": "Machine learning for modular multiplication",
        "authors": [
            "Kristin Lauter",
            "Cathy Yuanchen Li",
            "Krystal Maughan",
            "Rachel Newton",
            "Megha Srivastava"
        ],
        "comments": "14 pages, 12 figures. Comments welcome!",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Motivated by cryptographic applications, we investigate two machine learning approaches to modular multiplication: namely circular regression and a sequence-to-sequence transformer model. The limited success of both methods demonstrated in our results gives evidence for the hardness of tasks involving modular multiplication upon which cryptosystems are based.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.CR"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19255": {
        "title": "GSM-Plus: A Comprehensive Benchmark for Evaluating the Robustness of LLMs as Mathematical Problem Solvers",
        "authors": [
            "Qintong Li",
            "Leyang Cui",
            "Xueliang Zhao",
            "Lingpeng Kong",
            "Wei Bi"
        ],
        "comments": " ",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "Large language models (LLMs) have achieved impressive performance across various mathematical reasoning benchmarks. However, there are increasing debates regarding whether these models truly understand and apply mathematical knowledge or merely rely on shortcuts for mathematical reasoning. One essential and frequently occurring evidence is that when the math questions are slightly changed, LLMs can behave incorrectly. This motivates us to evaluate the robustness of LLMs' math reasoning capability by testing a wide range of question variations. We introduce the adversarial grade school math (\\datasetname) dataset, an extension of GSM8K augmented with various mathematical perturbations. Our experiments on 25 LLMs and 4 prompting techniques show that while LLMs exhibit different levels of math reasoning abilities, their performances are far from robust. In particular, even for problems that have been solved in GSM8K, LLMs can make mistakes when new statements are added or the question targets are altered. We also explore whether more robust performance can be achieved by composing existing prompting methods, in which we try an iterative method that generates and verifies each intermediate thought based on its reasoning goal and calculation result. Code and data are available at \\url{this https URL}.\n    ",
        "primary_category": "cs.CL",
        "categories": [],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19257": {
        "title": "More algorithmic results for problems of spread of influence in edge-weighted graphs with and without incentives",
        "authors": [
            "Siavash Askari",
            "Manouchehr Zaker"
        ],
        "comments": " ",
        "subjects": "Discrete Mathematics (cs.DM)",
        "abstract": "Many phenomena in real world social networks are interpreted as spread of influence between activated and non-activated network elements. These phenomena are formulated by combinatorial graphs, where vertices represent the elements and edges represent social ties between elements. A main problem is to study important subsets of elements (target sets or dynamic monopolies) such that their activation spreads to the entire network. In edge-weighted networks the influence between two adjacent vertices depends on the weight of their edge. In models with incentives, the main problem is to minimize total amount of incentives (called optimal target vectors) which can be offered to vertices such that some vertices are activated and their activation spreads to the whole network. Algorithmic study of target sets and vectors is a hot research field. We prove an inapproximability result for optimal target sets in edge weighted networks even for complete graphs. Some other hardness and polynomial time results are presented for optimal target vectors and degenerate threshold assignments in edge-weighted networks.\n    ",
        "primary_category": "cs.DM",
        "categories": [
            "math.CO"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19258": {
        "title": "MaskFi: Unsupervised Learning of WiFi and Vision Representations for Multimodal Human Activity Recognition",
        "authors": [
            "Jianfei Yang",
            "Shijie Tang",
            "Yuecong Xu",
            "Yunjiao Zhou",
            "Lihua Xie"
        ],
        "comments": "9 pages",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Human activity recognition (HAR) has been playing an increasingly important role in various domains such as healthcare, security monitoring, and metaverse gaming. Though numerous HAR methods based on computer vision have been developed to show prominent performance, they still suffer from poor robustness in adverse visual conditions in particular low illumination, which motivates WiFi-based HAR to serve as a good complementary modality. Existing solutions using WiFi and vision modalities rely on massive labeled data that are very cumbersome to collect. In this paper, we propose a novel unsupervised multimodal HAR solution, MaskFi, that leverages only unlabeled video and WiFi activity data for model training. We propose a new algorithm, masked WiFi-vision modeling (MI2M), that enables the model to learn cross-modal and single-modal features by predicting the masked sections in representation learning. Benefiting from our unsupervised learning procedure, the network requires only a small amount of annotated data for finetuning and can adapt to the new environment with better performance. We conduct extensive experiments on two WiFi-vision datasets collected in-house, and our method achieves human activity recognition and human identification in terms of both robustness and accuracy.\n    ",
        "primary_category": "cs.CV",
        "categories": [],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19259": {
        "title": "Total Completion Time Scheduling Under Scenarios",
        "authors": [
            "Thomas Bosman",
            "Martijn van Ee",
            "Ekin Ergen",
            "Csanad Imreh",
            "Alberto Marchetti-Spaccamela",
            "Martin Skutella",
            "Leen Stougie"
        ],
        "comments": " ",
        "subjects": "Data Structures and Algorithms (cs.DS)",
        "abstract": "Scheduling jobs with given processing times on identical parallel machines so as to minimize their total completion time is one of the most basic scheduling problems. We study interesting generalizations of this classical problem involving scenarios. In our model, a scenario is defined as a subset of a predefined and fully specified set of jobs. The aim is to find an assignment of the whole set of jobs to identical parallel machines such that the schedule, obtained for the given scenarios by simply skipping the jobs not in the scenario, optimizes a function of the total completion times over all scenarios.\nWhile the underlying scheduling problem without scenarios can be solved efficiently by a simple greedy procedure (SPT rule), scenarios, in general, make the problem NP-hard. We paint an almost complete picture of the evolving complexity landscape, drawing the line between easy and hard. One of our main algorithmic contributions relies on a deep structural result on the maximum imbalance of an optimal schedule, based on a subtle connection to Hilbert bases of a related convex cone.\n    ",
        "primary_category": "cs.DS",
        "categories": [],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19262": {
        "title": "Masks, Signs, And Learning Rate Rewinding",
        "authors": [
            "Advait Gadhikar",
            "Rebekka Burkholz"
        ],
        "comments": "Accepted for publishing at ICLR 2024",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Learning Rate Rewinding (LRR) has been established as a strong variant of Iterative Magnitude Pruning (IMP) to find lottery tickets in deep overparameterized neural networks. While both iterative pruning schemes couple structure and parameter learning, understanding how LRR excels in both aspects can bring us closer to the design of more flexible deep learning algorithms that can optimize diverse sets of sparse architectures. To this end, we conduct experiments that disentangle the effect of mask learning and parameter optimization and how both benefit from overparameterization. The ability of LRR to flip parameter signs early and stay robust to sign perturbations seems to make it not only more effective in mask identification but also in optimizing diverse sets of masks, including random ones. In support of this hypothesis, we prove in a simplified single hidden neuron setting that LRR succeeds in more cases than IMP, as it can escape initially problematic sign configurations.\n    ",
        "primary_category": "cs.LG",
        "categories": [],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19263": {
        "title": "Spinal Osteophyte Detection via Robust Patch Extraction on minimally annotated X-rays",
        "authors": [
            "Soumya Snigdha Kundu",
            "Yuanhan Mo",
            "Nicharee Srikijkasemwat",
            "Bart\u0142omiej W. Papiez"
        ],
        "comments": "ISBI'24 Full Paper",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "The development and progression of arthritis is strongly associated with osteophytes, which are small and elusive bone growths. This paper presents one of the first efforts towards automated spinal osteophyte detection in spinal X-rays. A novel automated patch extraction process, called SegPatch, has been proposed based on deep learning-driven vertebrae segmentation and the enlargement of mask contours. A final patch classification accuracy of 84.5\\% is secured, surpassing a baseline tiling-based patch generation technique by 9.5%. This demonstrates that even with limited annotations, SegPatch can deliver superior performance for detection of tiny structures such as osteophytes. The proposed approach has potential to assist clinicians in expediting the process of manually identifying osteophytes in spinal X-ray.\n    ",
        "primary_category": "cs.CV",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19264": {
        "title": "T3DNet: Compressing Point Cloud Models for Lightweight 3D Recognition",
        "authors": [
            "Zhiyuan Yang",
            "Yunjiao Zhou",
            "Lihua Xie",
            "Jianfei Yang"
        ],
        "comments": "12 pages",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "3D point cloud has been widely used in many mobile application scenarios, including autonomous driving and 3D sensing on mobile devices. However, existing 3D point cloud models tend to be large and cumbersome, making them hard to deploy on edged devices due to their high memory requirements and non-real-time latency. There has been a lack of research on how to compress 3D point cloud models into lightweight models. In this paper, we propose a method called T3DNet (Tiny 3D Network with augmEntation and disTillation) to address this issue. We find that the tiny model after network augmentation is much easier for a teacher to distill. Instead of gradually reducing the parameters through techniques such as pruning or quantization, we pre-define a tiny model and improve its performance through auxiliary supervision from augmented networks and the original model. We evaluate our method on several public datasets, including ModelNet40, ShapeNet, and ScanObjectNN. Our method can achieve high compression rates without significant accuracy sacrifice, achieving state-of-the-art performances on three datasets against existing methods. Amazingly, our T3DNet is 58 times smaller and 54 times faster than the original model yet with only 1.4% accuracy descent on the ModelNet40 dataset.\n    ",
        "primary_category": "cs.CV",
        "categories": [],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19265": {
        "title": "Learning Logic Specifications for Policy Guidance in POMDPs: an Inductive Logic Programming Approach",
        "authors": [
            "Daniele Meli",
            "Alberto Castellini",
            "Alessandro Farinelli"
        ],
        "comments": " ",
        "subjects": "Artificial Intelligence (cs.AI)",
        "abstract": "Partially Observable Markov Decision Processes (POMDPs) are a powerful framework for planning under uncertainty. They allow to model state uncertainty as a belief probability distribution. Approximate solvers based on Monte Carlo sampling show great success to relax the computational demand and perform online planning. However, scaling to complex realistic domains with many actions and long planning horizons is still a major challenge, and a key point to achieve good performance is guiding the action-selection process with domain-dependent policy heuristics which are tailored for the specific application domain. We propose to learn high-quality heuristics from POMDP traces of executions generated by any solver. We convert the belief-action pairs to a logical semantics, and exploit data- and time-efficient Inductive Logic Programming (ILP) to generate interpretable belief-based policy specifications, which are then used as online heuristics. We evaluate thoroughly our methodology on two notoriously challenging POMDP problems, involving large action spaces and long planning horizons, namely, rocksample and pocman. Considering different state-of-the-art online POMDP solvers, including POMCP, DESPOT and AdaOPS, we show that learned heuristics expressed in Answer Set Programming (ASP) yield performance superior to neural networks and similar to optimal handcrafted task-specific heuristics within lower computational time. Moreover, they well generalize to more challenging scenarios not experienced in the training phase (e.g., increasing rocks and grid size in rocksample, incrementing the size of the map and the aggressivity of ghosts in pocman).\n    ",
        "primary_category": "cs.AI",
        "categories": [
            "cs.LG",
            "cs.LO"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19266": {
        "title": "Cauchy-completions and the rule of unique choice in relational doctrines",
        "authors": [
            "Francesco Dagnino",
            "Fabio Pasquali"
        ],
        "comments": " ",
        "subjects": "Category Theory (math.CT)",
        "abstract": "Lawvere's generalised the notion of complete metric space to the field of enriched categories: an enriched category is said to be Cauchy-complete if every left adjoint bimodule into it is represented by an enriched functor. Looking at this definition from a logical standpoint, regarding bimodules as an abstraction of relations and functors as an abstraction of functions, Cauchy-completeness resembles a formulation of the rule of unique choice. In this paper, we make this analogy precise, using the language of relational doctrines, a categorical tool that provides a functorial description of the calculus of relations, in the same way Lawvere's hyperdoctrines give a functorial description of predicate logic. Given a relational doctrine, we define Cauchy-complete objects as those objects of the domain category satisfying the rule of unique choice. Then, we present a universal construction that completes a relational doctrine with the rule of unique choice, that is, producing a new relational doctrine where all objects are Cauchy-complete. We also introduce relational doctrines with singleton objects and show that these have the minimal structure needed to build the reflector of the full subcategory of its domain on Cauchy-complete objects. The main result is that this reflector exists if and only if the relational doctrine has singleton objects and this happens if and only if its restriction to Cauchy-complete objects is equivalent to its completion with the rule of unique choice. We support our results with many examples, also falling outside the scope of standard doctrines, such as complete metric spaces, Banach spaces and compact Hausdorff spaces in the general context of monoidal topology, which are all shown to be Cauchy-complete objects for appropriate relational doctrines.\n    ",
        "primary_category": "math.CT",
        "categories": [
            "cs.LO",
            "math.LO"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19267": {
        "title": "Robust Guidance for Unsupervised Data Selection: Capturing Perplexing Named Entities for Domain-Specific Machine Translation",
        "authors": [
            "Seunghyun Ji",
            "Hagai Raja Sinulingga",
            "Darongsae Kwon"
        ],
        "comments": "Submitted to SIGUL 2024, a satellite workshop of LREC-COLING 2024",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "Employing extensive datasets enables the training of multilingual machine translation models; however, these models often fail to accurately translate sentences within specialized domains. Although obtaining and translating domain-specific data incurs high costs, it is inevitable for high-quality translations. Hence, finding the most 'effective' data with an unsupervised setting becomes a practical strategy for reducing labeling costs. Recent research indicates that this effective data could be found by selecting 'properly difficult data' based on its volume. This means the data should not be excessively challenging or overly simplistic, especially if the amount of data is limited. However, we found that establishing a criterion for unsupervised data selection remains challenging, as the 'proper difficulty' might vary based on the data domain being trained on. We introduce a novel unsupervised data selection method, 'Capturing Perplexing Named Entities', which adopts the maximum inference entropy in translated named entities as a selection measure. The motivation was that named entities in domain-specific data are considered the most complex portion of the data and should be predicted with high confidence. When verified with the 'Korean-English Parallel Corpus of Specialized Domains,' our method served as a robust guidance for unsupervised data selection, in contrast to existing methods.\n    ",
        "primary_category": "cs.CL",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19273": {
        "title": "PlanGPT: Enhancing Urban Planning with Tailored Language Model and Efficient Retrieval",
        "authors": [
            "He Zhu",
            "Wenjia Zhang",
            "Nuoxian Huang",
            "Boyang Li",
            "Luyao Niu",
            "Zipei Fan",
            "Tianle Lun",
            "Yicheng Tao",
            "Junyou Su",
            "Zhaoya Gong",
            "Chenyu Fang",
            "Xing Liu"
        ],
        "comments": " ",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "In the field of urban planning, general-purpose large language models often struggle to meet the specific needs of planners. Tasks like generating urban planning texts, retrieving related information, and evaluating planning documents pose unique challenges. To enhance the efficiency of urban professionals and overcome these obstacles, we introduce PlanGPT, the first specialized Large Language Model tailored for urban and spatial planning. Developed through collaborative efforts with institutions like the Chinese Academy of Urban Planning, PlanGPT leverages a customized local database retrieval framework, domain-specific fine-tuning of base models, and advanced tooling capabilities. Empirical tests demonstrate that PlanGPT has achieved advanced performance, delivering responses of superior quality precisely tailored to the intricacies of urban planning.\n    ",
        "primary_category": "cs.CL",
        "categories": [],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19275": {
        "title": "Adaptive Testing Environment Generation for Connected and Automated Vehicles with Dense Reinforcement Learning",
        "authors": [
            "Jingxuan Yang",
            "Ruoxuan Bai",
            "Haoyuan Ji",
            "Yi Zhang",
            "Jianming Hu",
            "Shuo Feng"
        ],
        "comments": " ",
        "subjects": "Systems and Control (eess.SY)",
        "abstract": "The assessment of safety performance plays a pivotal role in the development and deployment of connected and automated vehicles (CAVs). A common approach involves designing testing scenarios based on prior knowledge of CAVs (e.g., surrogate models), conducting tests in these scenarios, and subsequently evaluating CAVs' safety performances. However, substantial differences between CAVs and the prior knowledge can significantly diminish the evaluation efficiency. In response to this issue, existing studies predominantly concentrate on the adaptive design of testing scenarios during the CAV testing process. Yet, these methods have limitations in their applicability to high-dimensional scenarios. To overcome this challenge, we develop an adaptive testing environment that bolsters evaluation robustness by incorporating multiple surrogate models and optimizing the combination coefficients of these surrogate models to enhance evaluation efficiency. We formulate the optimization problem as a regression task utilizing quadratic programming. To efficiently obtain the regression target via reinforcement learning, we propose the dense reinforcement learning method and devise a new adaptive policy with high sample efficiency. Essentially, our approach centers on learning the values of critical scenes displaying substantial surrogate-to-real gaps. The effectiveness of our method is validated in high-dimensional overtaking scenarios, demonstrating that our approach achieves notable evaluation efficiency.\n    ",
        "primary_category": "eess.SY",
        "categories": [
            "cs.LG"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19279": {
        "title": "SIFT-Aided Rectified 2D-DIC for Displacement and Strain Measurements in Asphalt Concrete Testing",
        "authors": [
            "Zehui Zhu",
            "Imad L. Al-Qadi"
        ],
        "comments": "Journal of Transportation Engineering, Part B: Pavements",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Two-dimensional digital image correlation (2D-DIC) is a widely used optical technique to measure displacement and strain during asphalt concrete (AC) testing. An accurate 2-D DIC measurement can only be achieved when the camera's principal axis is perpendicular to the planar specimen surface. However, this requirement may not be met during testing due to device constraints. This paper proposes a simple and reliable method to correct errors induced by non-perpendicularity. The method is based on image feature matching and rectification. No additional equipment is needed. A theoretical error analysis was conducted to quantify the effect of a non-perpendicular camera alignment on measurement accuracy. The proposed method was validated numerically using synthetic images and experimentally in an AC fracture test. It achieved relatively high accuracy, even under considerable camera rotation angle and large deformation. As a pre-processing technique, the proposed method showed promising performance in assisting the recently developed CrackPropNet for automated crack propagation measurement under a non-perpendicular camera alignment.\n    ",
        "primary_category": "cs.CV",
        "categories": [],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19287": {
        "title": "StiefelGen: A Simple, Model Agnostic Approach for Time Series Data Augmentation over Riemannian Manifolds",
        "authors": [
            "Prasad Cheema",
            "Mahito Sugiyama"
        ],
        "comments": "61 pages, 41 figures",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Data augmentation is an area of research which has seen active development in many machine learning fields, such as in image-based learning models, reinforcement learning for self driving vehicles, and general noise injection for point cloud data. However, convincing methods for general time series data augmentation still leaves much to be desired, especially since the methods developed for these models do not readily cross-over. Three common approaches for time series data augmentation include: (i) Constructing a physics-based model and then imbuing uncertainty over the coefficient space (for example), (ii) Adding noise to the observed data set(s), and, (iii) Having access to ample amounts of time series data sets from which a robust generative neural network model can be trained. However, for many practical problems that work with time series data in the industry: (i) One usually does not have access to a robust physical model, (ii) The addition of noise can in of itself require large or difficult assumptions (for example, what probability distribution should be used? Or, how large should the noise variance be?), and, (iii) In practice, it can be difficult to source a large representative time series data base with which to train the neural network model for the underlying problem. In this paper, we propose a methodology which attempts to simultaneously tackle all three of these previous limitations to a large extent. The method relies upon the well-studied matrix differential geometry of the Stiefel manifold, as it proposes a simple way in which time series signals can placed on, and then smoothly perturbed over the manifold. We attempt to clarify how this method works by showcasing several potential use cases which in particular work to take advantage of the unique properties of this underlying manifold.\n    ",
        "primary_category": "cs.LG",
        "categories": [],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19294": {
        "title": "Degradation Modeling and Prognostic Analysis Under Unknown Failure Modes",
        "authors": [
            "Ying Fu",
            "Ye Kwon Huh",
            "Kaibo Liu"
        ],
        "comments": " ",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Operating units often experience various failure modes in complex systems, leading to distinct degradation paths. Relying on a prognostic model trained on a single failure mode may lead to poor generalization performance across multiple failure modes. Therefore, accurately identifying the failure mode is of critical importance. Current prognostic approaches either ignore failure modes during degradation or assume known failure mode labels, which can be challenging to acquire in practice. Moreover, the high dimensionality and complex relations of sensor signals make it challenging to identify the failure modes accurately. To address these issues, we propose a novel failure mode diagnosis method that leverages a dimension reduction technique called UMAP (Uniform Manifold Approximation and Projection) to project and visualize each unit's degradation trajectory into a lower dimension. Then, using these degradation trajectories, we develop a time series-based clustering method to identify the training units' failure modes. Finally, we introduce a monotonically constrained prognostic model to predict the failure mode labels and RUL of the test units simultaneously using the obtained failure modes of the training units. The proposed prognostic model provides failure mode-specific RUL predictions while preserving the monotonic property of the RUL predictions across consecutive time steps. We evaluate the proposed model using a case study with the aircraft gas turbine engine dataset.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19295": {
        "title": "Anomaly Detection in Offshore Wind Turbine Structures using Hierarchical Bayesian Modelling",
        "authors": [
            "S. M. Smith",
            "A. J. Hughes",
            "T. A. Dardeno",
            "L. A. Bull",
            "N. Dervilis",
            "K. Worden"
        ],
        "comments": "Submitted to International Workshop on Structural Health Monitoring 2023, Stanford University, California, USA",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Population-based structural health monitoring (PBSHM), aims to share information between members of a population. An offshore wind (OW) farm could be considered as a population of nominally-identical wind-turbine structures. However, benign variations exist among members, such as geometry, sea-bed conditions and temperature differences. These factors could influence structural properties and therefore the dynamic response, making it more difficult to detect structural problems via traditional SHM techniques. This paper explores the use of a hierarchical Bayesian model to infer expected soil stiffness distributions at both population and local levels, as a basis to perform anomaly detection, in the form of scour, for new and existing turbines. To do this, observations of natural frequency will be generated as though they are from a small population of wind turbines. Differences between individual observations will be introduced by postulating distributions over the soil stiffness and measurement noise, as well as reducing soil depth (to represent scour), in the case of anomaly detection.\n    ",
        "primary_category": "cs.LG",
        "categories": [],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19296": {
        "title": "An AI based Digital Score of Tumour-Immune Microenvironment Predicts Benefit to Maintenance Immunotherapy in Advanced Oesophagogastric Adenocarcinoma",
        "authors": [
            "Quoc Dang Vu",
            "Caroline Fong",
            "Anderley Gordon",
            "Tom Lund",
            "Tatiany L Silveira",
            "Daniel Rodrigues",
            "Katharina von Loga",
            "Shan E Ahmed Raza",
            "David Cunningham",
            "Nasir Rajpoot"
        ],
        "comments": " ",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Gastric and oesophageal (OG) cancers are the leading causes of cancer mortality worldwide. In OG cancers, recent studies have showed that PDL1 immune checkpoint inhibitors (ICI) in combination with chemotherapy improves patient survival. However, our understanding of the tumour immune microenvironment in OG cancers remains limited. In this study, we interrogate multiplex immunofluorescence (mIF) images taken from patients with advanced Oesophagogastric Adenocarcinoma (OGA) who received first-line fluoropyrimidine and platinum-based chemotherapy in the PLATFORM trial (NCT02678182) to predict the efficacy of the treatment and to explore the biological basis of patients responding to maintenance durvalumab (PDL1 inhibitor). Our proposed Artificial Intelligence (AI) based marker successfully identified responder from non-responder (p < 0.05) as well as those who could potentially benefit from ICI with statistical significance (p < 0.05) for both progression free and overall survival. Our findings suggest that T cells that express FOXP3 seem to heavily influence the patient treatment response and survival outcome. We also observed that higher levels of CD8+PD1+ cells are consistently linked to poor prognosis for both OS and PFS, regardless of ICI.\n    ",
        "primary_category": "cs.CV",
        "categories": [
            "cs.LG"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19299": {
        "title": "RL-GPT: Integrating Reinforcement Learning and Code-as-policy",
        "authors": [
            "Shaoteng Liu",
            "Haoqi Yuan",
            "Minda Hu",
            "Yanwei Li",
            "Yukang Chen",
            "Shu Liu",
            "Zongqing Lu",
            "Jiaya Jia"
        ],
        "comments": " ",
        "subjects": "Artificial Intelligence (cs.AI)",
        "abstract": "Large Language Models (LLMs) have demonstrated proficiency in utilizing various tools by coding, yet they face limitations in handling intricate logic and precise control. In embodied tasks, high-level planning is amenable to direct coding, while low-level actions often necessitate task-specific refinement, such as Reinforcement Learning (RL). To seamlessly integrate both modalities, we introduce a two-level hierarchical framework, RL-GPT, comprising a slow agent and a fast agent. The slow agent analyzes actions suitable for coding, while the fast agent executes coding tasks. This decomposition effectively focuses each agent on specific tasks, proving highly efficient within our pipeline. Our approach outperforms traditional RL methods and existing GPT agents, demonstrating superior efficiency. In the Minecraft game, it rapidly obtains diamonds within a single day on an RTX3090. Additionally, it achieves SOTA performance across all designated MineDojo tasks.\n    ",
        "primary_category": "cs.AI",
        "categories": [
            "cs.LG"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19302": {
        "title": "DiffAssemble: A Unified Graph-Diffusion Model for 2D and 3D Reassembly",
        "authors": [
            "Gianluca Scarpellini",
            "Stefano Fiorini",
            "Francesco Giuliari",
            "Pietro Morerio",
            "Alessio Del Bue"
        ],
        "comments": "Accepted at CVPR2024",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Reassembly tasks play a fundamental role in many fields and multiple approaches exist to solve specific reassembly problems. In this context, we posit that a general unified model can effectively address them all, irrespective of the input data type (images, 3D, etc.). We introduce DiffAssemble, a Graph Neural Network (GNN)-based architecture that learns to solve reassembly tasks using a diffusion model formulation. Our method treats the elements of a set, whether pieces of 2D patch or 3D object fragments, as nodes of a spatial graph. Training is performed by introducing noise into the position and rotation of the elements and iteratively denoising them to reconstruct the coherent initial pose. DiffAssemble achieves state-of-the-art (SOTA) results in most 2D and 3D reassembly tasks and is the first learning-based approach that solves 2D puzzles for both rotation and translation. Furthermore, we highlight its remarkable reduction in run-time, performing 11 times faster than the quickest optimization-based method for puzzle solving. Code available at this https URL\n",
        "primary_category": "cs.CV",
        "categories": [],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19303": {
        "title": "Learnability Gaps of Strategic Classification",
        "authors": [
            "Lee Cohen",
            "Yishay Mansour",
            "Shay Moran",
            "Han Shao"
        ],
        "comments": " ",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "In contrast with standard classification tasks, strategic classification involves agents strategically modifying their features in an effort to receive favorable predictions. For instance, given a classifier determining loan approval based on credit scores, applicants may open or close their credit cards to fool the classifier. The learning goal is to find a classifier robust against strategic manipulations. Various settings, based on what and when information is known, have been explored in strategic classification. In this work, we focus on addressing a fundamental question: the learnability gaps between strategic classification and standard learning.\nWe essentially show that any learnable class is also strategically learnable: we first consider a fully informative setting, where the manipulation structure (which is modeled by a manipulation graph $G^\\star$) is known and during training time the learner has access to both the pre-manipulation data and post-manipulation data. We provide nearly tight sample complexity and regret bounds, offering significant improvements over prior results. Then, we relax the fully informative setting by introducing two natural types of uncertainty. First, following Ahmadi et al. (2023), we consider the setting in which the learner only has access to the post-manipulation data. We improve the results of Ahmadi et al. (2023) and close the gap between mistake upper bound and lower bound raised by them. Our second relaxation of the fully informative setting introduces uncertainty to the manipulation structure. That is, we assume that the manipulation graph is unknown but belongs to a known class of graphs. We provide nearly tight bounds on the learning complexity in various unknown manipulation graph settings. Notably, our algorithm in this setting is of independent interest and can be applied to other problems such as multi-label learning.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.GT"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19305": {
        "title": "HyenaPixel: Global Image Context with Convolutions",
        "authors": [
            "Julian Spravil",
            "Sebastian Houben",
            "Sven Behnke"
        ],
        "comments": " ",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "In vision tasks, a larger effective receptive field (ERF) is associated with better performance. While attention natively supports global context, convolution requires multiple stacked layers and a hierarchical structure for large context. In this work, we extend Hyena, a convolution-based attention replacement, from causal sequences to the non-causal two-dimensional image space. We scale the Hyena convolution kernels beyond the feature map size up to 191$\\times$191 to maximize the ERF while maintaining sub-quadratic complexity in the number of pixels. We integrate our two-dimensional Hyena, HyenaPixel, and bidirectional Hyena into the MetaFormer framework. For image categorization, HyenaPixel and bidirectional Hyena achieve a competitive ImageNet-1k top-1 accuracy of 83.0% and 83.5%, respectively, while outperforming other large-kernel networks. Combining HyenaPixel with attention further increases accuracy to 83.6%. We attribute the success of attention to the lack of spatial bias in later stages and support this finding with bidirectional Hyena.\n    ",
        "primary_category": "cs.CV",
        "categories": [],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19308": {
        "title": "Loss-Free Machine Unlearning",
        "authors": [
            "Jack Foster",
            "Stefan Schoepf",
            "Alexandra Brintrup"
        ],
        "comments": "Accepted as a Tiny Paper at ICLR 2024",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "We present a machine unlearning approach that is both retraining- and label-free. Most existing machine unlearning approaches require a model to be fine-tuned to remove information while preserving performance. This is computationally expensive and necessitates the storage of the whole dataset for the lifetime of the model. Retraining-free approaches often utilise Fisher information, which is derived from the loss and requires labelled data which may not be available. Thus, we present an extension to the Selective Synaptic Dampening algorithm, substituting the diagonal of the Fisher information matrix for the gradient of the l2 norm of the model output to approximate sensitivity. We evaluate our method in a range of experiments using ResNet18 and Vision Transformer. Results show our label-free method is competitive with existing state-of-the-art approaches.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.CV"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19309": {
        "title": "Closed-loop training of static output feedback neural network controllers for large systems: A distillation case study",
        "authors": [
            "E. M. Turan",
            "J. J\u00e4schke"
        ],
        "comments": " ",
        "subjects": "Systems and Control (eess.SY)",
        "abstract": "The online implementation of model predictive control for constrained multivariate systems has two main disadvantages: it requires an estimate of the entire model state and an optimisation problem must be solved online. These issues have typically been treated separately. This work proposes an integrated approach for the offline training of an output feedback neural network controller in closed loop. Online this neural network controller computers the plant inputs cheaply using noisy measurements. In addition, the controller can be trained to only make use of certain predefined measurements. Further, a heuristic approach is proposed to perform the automatic selection of important measurements. The proposed method is demonstrated by extensive simulations using a non-linear distillation column model of 50 states.\n    ",
        "primary_category": "eess.SY",
        "categories": [
            "math.OC"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19318": {
        "title": "DISCERN: Designing Decision Support Interfaces to Investigate the Complexities of Workplace Social Decision-Making With Line Managers",
        "authors": [
            "Pranav Khadpe",
            "Lindy Le",
            "Kate Nowak",
            "Shamsi T. Iqbal",
            "Jina Suh"
        ],
        "comments": "CHI 2024",
        "subjects": "Human-Computer Interaction (cs.HC)",
        "abstract": "Line managers form the first level of management in organizations, and must make complex decisions, while maintaining relationships with those impacted by their decisions. Amidst growing interest in technology-supported decision-making at work, their needs remain understudied. Further, most existing design knowledge for supporting social decision-making comes from domains where decision-makers are more socially detached from those they decide for. We conducted iterative design research with line managers within a technology organization, investigating decision-making practices, and opportunities for technological support. Through formative research, development of a decision-representation tool -- DISCERN -- and user enactments, we identify their communication and analysis needs that lack adequate support. We found they preferred tools for externalizing reasoning rather than tools that replace interpersonal interactions, and they wanted tools to support a range of intuitive and calculative decision-making. We discuss how design of social decision-making supports, especially in the workplace, can more explicitly support highly interactional social decision-making.\n    ",
        "primary_category": "cs.HC",
        "categories": [],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19319": {
        "title": "Attacks Against Mobility Prediction in 5G Networks",
        "authors": [
            "Syafiq Al Atiiq",
            "Yachao Yuan",
            "Christian Gehrmann",
            "Jakob Sternby",
            "Luis Barriga"
        ],
        "comments": "This is the preprint version of a paper which appears in 22th IEEE International Conference on Trust, Security and Privacy in Computing and Communications (TrustCom 2023)",
        "subjects": "Cryptography and Security (cs.CR)",
        "abstract": "The $5^{th}$ generation of mobile networks introduces a new Network Function (NF) that was not present in previous generations, namely the Network Data Analytics Function (NWDAF). Its primary objective is to provide advanced analytics services to various entities within the network and also towards external application services in the 5G ecosystem. One of the key use cases of NWDAF is mobility trajectory prediction, which aims to accurately support efficient mobility management of User Equipment (UE) in the network by allocating ``just in time'' necessary network resources. In this paper, we show that there are potential mobility attacks that can compromise the accuracy of these predictions. In a semi-realistic scenario with 10,000 subscribers, we demonstrate that an adversary equipped with the ability to hijack cellular mobile devices and clone them can significantly reduce the prediction accuracy from 75\\% to 40\\% using just 100 adversarial UEs. While a defense mechanism largely depends on the attack and the mobility types in a particular area, we prove that a basic KMeans clustering is effective in distinguishing legitimate and adversarial UEs.\n    ",
        "primary_category": "cs.CR",
        "categories": [
            "cs.LG",
            "cs.NI"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19325": {
        "title": "Do End-to-End Neural Diarization Attractors Need to Encode Speaker Characteristic Information?",
        "authors": [
            "Lin Zhang",
            "Themos Stafylakis",
            "Federico Landini",
            "Mireia Diez",
            "Anna Silnova",
            "Luk\u00e1\u0161 Burget"
        ],
        "comments": "Submitted to Odyssey 2024",
        "subjects": "Sound (cs.SD)",
        "abstract": "In this paper, we apply the variational information bottleneck approach to end-to-end neural diarization with encoder-decoder attractors (EEND-EDA). This allows us to investigate what information is essential for the model. EEND-EDA utilizes vector representations of the speakers in a conversation - attractors. Our analysis shows that, attractors do not necessarily have to contain speaker characteristic information. On the other hand, giving the attractors more freedom allowing them to encode some extra (possibly speaker-specific) information leads to small but consistent diarization performance improvements. Despite architectural differences in EEND systems, the notion of attractors and frame embeddings is common to most of them and not specific to EEND-EDA. We believe that the main conclusions of this work can apply to other variants of EEND. Thus, we hope this paper will be a valuable contribution to guide the community to make more informed decisions when designing new systems.\n    ",
        "primary_category": "cs.SD",
        "categories": [
            "eess.AS"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19328": {
        "title": "Seeking Soulmate via Voice: Understanding Promises and Challenges of Online Synchronized Voice-Based Mobile Dating",
        "authors": [
            "Chenxinran Shen",
            "Yan Xu",
            "Ray LC",
            "Zhicong Lu"
        ],
        "comments": "14 pages, 2 figures. Accepted to ACM CHI 2024. In Proceedings of the CHI Conference on Human Factors in Computing Systems (CHI '24)",
        "subjects": "Human-Computer Interaction (cs.HC)",
        "abstract": "Online dating has become a popular way for individuals to connect with potential romantic partners. Many dating apps use personal profiles that include a headshot and self-description, allowing users to present themselves and search for compatible matches. However, this traditional model often has limitations. In this study, we explore a non-traditional voice-based dating app called \"Soul\". Unlike traditional platforms that rely heavily on profile information, Soul facilitates user interactions through voice-based communication. We conducted semi-structured interviews with 18 dedicated Soul users to investigate how they engage with the platform and perceive themselves and others in this unique dating environment. Our findings indicate that the role of voice as a moderator influences impression management and shapes perceptions between the sender and the receiver of the voice. Additionally, the synchronous voice-based and community-based dating model offers benefits to users in the Chinese cultural context. Our study contributes to understanding the affordances introduced by voice-based interactions in online dating in China.\n    ",
        "primary_category": "cs.HC",
        "categories": [
            "cs.CY",
            "cs.SI"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19333": {
        "title": "Compact Speech Translation Models via Discrete Speech Units Pretraining",
        "authors": [
            "Tsz Kin Lam",
            "Alexandra Birch",
            "Barry Haddow"
        ],
        "comments": " ",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "Using Self-Supervised Learning (SSL) as model initialization is now common to obtain strong results in Speech Translation (ST). However, they also impose a large memory footprint, hindering on-device deployment. In this paper, we leverage the SSL models by pretraining smaller models on their Discrete Speech Units (DSU). We pretrain encoder-decoder models on 1) Filterbank-to-DSU and 2) DSU-to-Translation data, and take the encoder from 1) and the decoder from 2) to initialise a new model, finetuning this on limited speech-translation data. The final model becomes compact by using the DSU pretraining to distil the knowledge of the SSL model. Our method has several benefits over using DSU as model inputs, such as shorter inference pipeline and robustness over (DSU) tokenization. In contrast to ASR pretraining, it does not require transcripts, making it applicable to low-resource settings. Evaluation on CoVoST-2 X-En shows that our method is >$0.5$ BLEU better than a ST model that directly finetune the SSL model, given only half the model size, and on a par with ASR pretraining.\n    ",
        "primary_category": "cs.CL",
        "categories": [
            "cs.SD",
            "eess.AS"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19334": {
        "title": "Here's a Free Lunch: Sanitizing Backdoored Models with Model Merge",
        "authors": [
            "Ansh Arora",
            "Xuanli He",
            "Maximilian Mozes",
            "Srinibas Swain",
            "Mark Dras",
            "Qiongkai Xu"
        ],
        "comments": "work in progress",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "The democratization of pre-trained language models through open-source initiatives has rapidly advanced innovation and expanded access to cutting-edge technologies. However, this openness also brings significant security risks, including backdoor attacks, where hidden malicious behaviors are triggered by specific inputs, compromising natural language processing (NLP) system integrity and reliability. This paper suggests that merging a backdoored model with other homogeneous models can remediate backdoor vulnerabilities even if such models are not entirely secure. In our experiments, we explore various models (BERT-Base, RoBERTa-Large, Llama2-7B, and Mistral-7B) and datasets (SST-2, OLID, AG News, and QNLI). Compared to multiple advanced defensive approaches, our method offers an effective and efficient inference-stage defense against backdoor attacks without additional resources or specific knowledge. Our approach consistently outperforms the other advanced baselines, leading to an average of 75% reduction in the attack success rate. Since model merging has been an established approach for improving model performance, the extra advantage it provides regarding defense can be seen as a cost-free bonus.\n    ",
        "primary_category": "cs.CL",
        "categories": [],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19339": {
        "title": "Stitching Gaps: Fusing Situated Perceptual Knowledge with Vision Transformers for High-Level Image Classification",
        "authors": [
            "Delfina Sol Martinez Pandiani",
            "Nicolas Lazzari",
            "Valentina Presutti"
        ],
        "comments": "Preprint",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "The increasing demand for automatic high-level image understanding, particularly in detecting abstract concepts (AC) within images, underscores the necessity for innovative and more interpretable approaches. These approaches need to harmonize traditional deep vision methods with the nuanced, context-dependent knowledge humans employ to interpret images at intricate semantic levels. In this work, we leverage situated perceptual knowledge of cultural images to enhance performance and interpretability in AC image classification. We automatically extract perceptual semantic units from images, which we then model and integrate into the ARTstract Knowledge Graph (AKG). This resource captures situated perceptual semantics gleaned from over 14,000 cultural images labeled with ACs. Additionally, we enhance the AKG with high-level linguistic frames. We compute KG embeddings and experiment with relative representations and hybrid approaches that fuse these embeddings with visual transformer embeddings. Finally, for interpretability, we conduct posthoc qualitative analyses by examining model similarities with training instances. Our results show that our hybrid KGE-ViT methods outperform existing techniques in AC image classification. The posthoc interpretability analyses reveal the visual transformer's proficiency in capturing pixel-level visual attributes, contrasting with our method's efficacy in representing more abstract and semantic scene elements. We demonstrate the synergy and complementarity between KGE embeddings' situated perceptual knowledge and deep visual model's sensory-perceptual understanding for AC image classification. This work suggests a strong potential of neuro-symbolic methods for knowledge integration and robust image representation for use in downstream intricate visual comprehension tasks. All the materials and code are available online.\n    ",
        "primary_category": "cs.CV",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19347": {
        "title": "#PoetsOfInstagram: Navigating The Practices And Challenges Of Novice Poets On Instagram",
        "authors": [
            "Ankolika De",
            "Zhicong Lu"
        ],
        "comments": "16 pages, 2 figures; Accepted to ACM CHI 2024. In Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems (CHI'24)",
        "subjects": "Human-Computer Interaction (cs.HC)",
        "abstract": "Commencing as a photo-sharing platform, Instagram has since become multifaceted, accommodating diverse art forms, with poetry emerging as a prominent one. However, the academic understanding of Instagram's poetry community is limited, yet its significance emerges from its distinctive utilization of a primarily visual social media platform guided by recommendation algorithms for disseminating poetry, further characterized by a predominantly novice creative population. We employ qualitative analysis to explore motivations, experiences, and algorithmic influence within Instagram's poetry community. We demonstrate that participants prioritize conforming to algorithmic constraints for visibility, yet maintain their community's values of integrity and originality, illustrating the tension between algorithmic growth and participant authenticity. We introduce the concept of Algorithmically Mediated Creative Labor, a phenomenon specific to non-monetizing creative users who are impacted by the prioritization of professional creators and continually adapt their creative endeavors to align with platform logic, thereby affecting their motivation and creative outputs.\n    ",
        "primary_category": "cs.HC",
        "categories": [
            "cs.CY",
            "cs.SI"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19348": {
        "title": "Deep Learning for Cross-Domain Data Fusion in Urban Computing: Taxonomy, Advances, and Outlook",
        "authors": [
            "Xingchen Zou",
            "Yibo Yan",
            "Xixuan Hao",
            "Yuehong Hu",
            "Haomin Wen",
            "Erdong Liu",
            "Junbo Zhang",
            "Yong Li",
            "Tianrui Li",
            "Yu Zheng",
            "Yuxuan Liang"
        ],
        "comments": " ",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "As cities continue to burgeon, Urban Computing emerges as a pivotal discipline for sustainable development by harnessing the power of cross-domain data fusion from diverse sources (e.g., geographical, traffic, social media, and environmental data) and modalities (e.g., spatio-temporal, visual, and textual modalities). Recently, we are witnessing a rising trend that utilizes various deep-learning methods to facilitate cross-domain data fusion in smart cities. To this end, we propose the first survey that systematically reviews the latest advancements in deep learning-based data fusion methods tailored for urban computing. Specifically, we first delve into data perspective to comprehend the role of each modality and data source. Secondly, we classify the methodology into four primary categories: feature-based, alignment-based, contrast-based, and generation-based fusion methods. Thirdly, we further categorize multi-modal urban applications into seven types: urban planning, transportation, economy, public safety, society, environment, and energy. Compared with previous surveys, we focus more on the synergy of deep learning methods with urban computing applications. Furthermore, we shed light on the interplay between Large Language Models (LLMs) and urban computing, postulating future research directions that could revolutionize the field. We firmly believe that the taxonomy, progress, and prospects delineated in our survey stand poised to significantly enrich the research community. The summary of the comprehensive and up-to-date paper list can be found at this https URL.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19351": {
        "title": "Oriented trees in $O(k \\sqrt{k})$-chromatic digraphs, a subquadratic bound for Burr's conjecture",
        "authors": [
            "St\u00e9phane Bessy",
            "Daniel Gon\u00e7alves",
            "Amadeus Reinald"
        ],
        "comments": "17 pages, 2 figures",
        "subjects": "Combinatorics (math.CO)",
        "abstract": "In 1980, Burr conjectured that every directed graph with chromatic number $2k-2$ contains any oriented tree of order $k$ as a subdigraph. Burr showed that chromatic number $(k-1)^2$ suffices, which was improved in 2013 to $\\frac{k^2}{2} - \\frac{k}{2} + 1$ by Addario-Berry et al. We give the first subquadratic bound for Burr's conjecture, by showing that every directed graph with chromatic number $8\\sqrt{\\frac{2}{15}} k \\sqrt{k} + O(k)$ contains any oriented tree of order $k$. Moreover, we provide improved bounds of $\\sqrt{\\frac{4}{3}} k \\sqrt{k}+O(k)$ for arborescences, and $(b-1)(k-3)+3$ for paths on $b$ blocks, with $b\\ge 2$.\n    ",
        "primary_category": "math.CO",
        "categories": [
            "cs.DM"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19355": {
        "title": "Unraveling Adversarial Examples against Speaker Identification -- Techniques for Attack Detection and Victim Model Classification",
        "authors": [
            "Sonal Joshi",
            "Thomas Thebaud",
            "Jes\u00fas Villalba",
            "Najim Dehak"
        ],
        "comments": " ",
        "subjects": "Sound (cs.SD)",
        "abstract": "Adversarial examples have proven to threaten speaker identification systems, and several countermeasures against them have been proposed. In this paper, we propose a method to detect the presence of adversarial examples, i.e., a binary classifier distinguishing between benign and adversarial examples. We build upon and extend previous work on attack type classification by exploring new architectures. Additionally, we introduce a method for identifying the victim model on which the adversarial attack is carried out. To achieve this, we generate a new dataset containing multiple attacks performed against various victim models. We achieve an AUC of 0.982 for attack detection, with no more than a 0.03 drop in performance for unknown attacks. Our attack classification accuracy (excluding benign) reaches 86.48% across eight attack types using our LightResNet34 architecture, while our victim model classification accuracy reaches 72.28% across four victim models.\n    ",
        "primary_category": "cs.SD",
        "categories": [
            "cs.CR",
            "cs.LG",
            "eess.AS"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19360": {
        "title": "Joint Chance Constrained Optimal Control via Linear Programming",
        "authors": [
            "Niklas Schmid",
            "Marta Fochesato",
            "Tobias Sutter",
            "John Lygeros"
        ],
        "comments": " ",
        "subjects": "Optimization and Control (math.OC)",
        "abstract": "We establish a linear programming formulation for the solution of joint chance constrained optimal control problems over finite time horizons. The joint chance constraint may represent an invariance, reachability or reach-avoid specification that the trajectory must satisfy with a predefined probability. Compared to the existing literature, the formulation is computationally tractable and the solution exact.\n    ",
        "primary_category": "math.OC",
        "categories": [
            "eess.SY"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19365": {
        "title": "On Efficient Computation of DiRe Committees",
        "authors": [
            "Kunal Relia"
        ],
        "comments": "single-column format. 33 pages. 26 Figures. 6 Tables. 4 Algorithms. 4 Theorems. 9 Lemmas/Lemmata. 2 Observations. 14 Definitions. 2 Examples. Reducing inequality is easier than expected. P=NP",
        "subjects": "Computational Complexity (cs.CC)",
        "abstract": "Consider a committee election consisting of (i) a set of candidates who are divided into arbitrary groups each of size \\emph{at most} two and a diversity constraint that stipulates the selection of \\emph{at least} one candidate from each group and (ii) a set of voters who are divided into arbitrary populations each approving \\emph{at most} two candidates and a representation constraint that stipulates the selection of \\emph{at least} one candidate from each population who has a non-null set of approved candidates.\nThe DiRe (Diverse + Representative) committee feasibility problem (a.k.a. the minimum vertex cover problem on unweighted undirected graphs) concerns the determination of the smallest size committee that satisfies the given constraints. Here, for this problem, we discover an unconditional deterministic polynomial-time algorithm that is an amalgamation of maximum matching, breadth-first search, maximal matching, and local minimization.\n    ",
        "primary_category": "cs.CC",
        "categories": [
            "cs.CY",
            "cs.GT"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19366": {
        "title": "SoK: Exploring the Potential of Large Language Models for Improving Digital Forensic Investigation Efficiency",
        "authors": [
            "Akila Wickramasekara",
            "Frank Breitinger",
            "Mark Scanlon"
        ],
        "comments": " ",
        "subjects": "Cryptography and Security (cs.CR)",
        "abstract": "The growing number of cases requiring digital forensic analysis raises concerns about law enforcement's ability to conduct investigations promptly. Consequently, this systemisation of knowledge paper delves into the potential and effectiveness of integrating Large Language Models (LLMs) into digital forensic investigation to address these challenges. A thorough literature review is undertaken, encompassing existing digital forensic models, tools, LLMs, deep learning techniques, and the utilisation of LLMs in investigations. The review identifies current challenges within existing digital forensic processes and explores both the obstacles and possibilities of incorporating LLMs. In conclusion, the study asserts that the adoption of LLMs in digital forensics, with appropriate constraints, holds the potential to enhance investigation efficiency, improve traceability, and alleviate technical and judicial barriers faced by law enforcement entities.\n    ",
        "primary_category": "cs.CR",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19369": {
        "title": "Structure Preserving Diffusion Models",
        "authors": [
            "Haoye Lu",
            "Spencer Szabados",
            "Yaoliang Yu"
        ],
        "comments": " ",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Diffusion models have become the leading distribution-learning method in recent years. Herein, we introduce structure-preserving diffusion processes, a family of diffusion processes for learning distributions that possess additional structure, such as group symmetries, by developing theoretical conditions under which the diffusion transition steps preserve said symmetry. While also enabling equivariant data sampling trajectories, we exemplify these results by developing a collection of different symmetry equivariant diffusion models capable of learning distributions that are inherently symmetric. Empirical studies, over both synthetic and real-world datasets, are used to validate the developed models adhere to the proposed theory and are capable of achieving improved performance over existing methods in terms of sample equality. We also show how the proposed models can be used to achieve theoretically guaranteed equivariant image noise reduction without prior knowledge of the image orientation.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.CV"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19371": {
        "title": "OpenMedLM: Prompt engineering can out-perform fine-tuning in medical question-answering with open-source large language models",
        "authors": [
            "Jenish Maharjan",
            "Anurag Garikipati",
            "Navan Preet Singh",
            "Leo Cyrus",
            "Mayank Sharma",
            "Madalina Ciobanu",
            "Gina Barnes",
            "Rahul Thapa",
            "Qingqing Mao",
            "Ritankar Das"
        ],
        "comments": " ",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "LLMs have become increasingly capable at accomplishing a range of specialized-tasks and can be utilized to expand equitable access to medical knowledge. Most medical LLMs have involved extensive fine-tuning, leveraging specialized medical data and significant, thus costly, amounts of computational power. Many of the top performing LLMs are proprietary and their access is limited to very few research groups. However, open-source (OS) models represent a key area of growth for medical LLMs due to significant improvements in performance and an inherent ability to provide the transparency and compliance required in healthcare. We present OpenMedLM, a prompting platform which delivers state-of-the-art (SOTA) performance for OS LLMs on medical benchmarks. We evaluated a range of OS foundation LLMs (7B-70B) on four medical benchmarks (MedQA, MedMCQA, PubMedQA, MMLU medical-subset). We employed a series of prompting strategies, including zero-shot, few-shot, chain-of-thought (random selection and kNN selection), and ensemble/self-consistency voting. We found that OpenMedLM delivers OS SOTA results on three common medical LLM benchmarks, surpassing the previous best performing OS models that leveraged computationally costly extensive fine-tuning. The model delivers a 72.6% accuracy on the MedQA benchmark, outperforming the previous SOTA by 2.4%, and achieves 81.7% accuracy on the MMLU medical-subset, establishing itself as the first OS LLM to surpass 80% accuracy on this benchmark. Our results highlight medical-specific emergent properties in OS LLMs which have not yet been documented to date elsewhere, and showcase the benefits of further leveraging prompt engineering to improve the performance of accessible LLMs for medical applications.\n    ",
        "primary_category": "cs.CL",
        "categories": [
            "cs.AI",
            "cs.IR"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19375": {
        "title": "Unveiling Internet Censorship: Analysing the Impact of Nation States' Content Control Efforts on Internet Architecture and Routing Patterns",
        "authors": [
            "Joshua Levett",
            "Vassilios Vassilakis",
            "Poonam Yadav"
        ],
        "comments": " ",
        "subjects": "Networking and Internet Architecture (cs.NI)",
        "abstract": "Heightened interest from nation states to perform content censorship make it evermore critical to identify the impact of censorship efforts on the Internet. We undertake a study of Internet architecture, capturing the state of Internet topology with greater completeness than existing state-of-the-art. We describe our methodology for this, including the tooling we create to collect and process data from a wide range of sources. We analyse this data to find key patterns in nation states with higher censorship, discovering a funnelling effect wherein higher Internet censorship effort is reflected in a constraining effect on a state's Internet routing architecture. However, there are a small number of nation states that do not follow this trend, for which we provide an analysis and explanation, demonstrating a relationship between geographical factors in addition to geopolitics. In summary, our work provides a deeper understanding of how these censorship measures impact the overall functioning and dynamics of the Internet.\n    ",
        "primary_category": "cs.NI",
        "categories": [],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19376": {
        "title": "OzMAC: An Energy-Efficient Sparsity-Exploiting Multiply-Accumulate-Unit Design for DL Inference",
        "authors": [
            "Harideep Nair",
            "Prabhu Vellaisamy",
            "Tsung-Han Lin",
            "Perry Wang",
            "Shawn Blanton",
            "John Paul Shen"
        ],
        "comments": " ",
        "subjects": "Hardware Architecture (cs.AR)",
        "abstract": "General Matrix Multiply (GEMM) hardware, employing large arrays of multiply-accumulate (MAC) units, perform bulk of the computation in deep learning (DL). Recent trends have established 8-bit integer (INT8) as the most widely used precision for DL inference. This paper proposes a novel MAC design capable of dynamically exploiting bit sparsity (i.e., number of `0' bits within a binary value) in input data to achieve significant improvements on area, power and energy. The proposed architecture, called OzMAC (Omit-zero-MAC), skips over zeros within a binary input value and performs simple shift-and-add-based compute in place of expensive multipliers. We implement OzMAC in SystemVerilog and present post-synthesis performance-power-area (PPA) results using commercial TSMC N5 (5nm) process node. Using eight pretrained INT8 deep neural networks (DNNs) as benchmarks, we demonstrate the existence of high bit sparsity in real DNN workloads and show that 8-bit OzMAC improves all three metrics of area, power, and energy significantly by 21%, 70%, and 28%, respectively. Similar improvements are achieved when scaling data precisions (4, 8, 16 bits) and clock frequencies (0.5 GHz, 1 GHz, 1.5 GHz). For the 8-bit OzMAC, scaling its frequency to normalize the throughput relative to conventional MAC, it still achieves 30% improvement on both power and energy.\n    ",
        "primary_category": "cs.AR",
        "categories": [],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19381": {
        "title": "Optimized Bayesian Framework for Inverse Heat Transfer Problems Using Reduced Order Methods",
        "authors": [
            "Kabir Bakhshaei",
            "Umberto Emil Morelli",
            "Giovanni Stabile",
            "Gianluigi Rozza"
        ],
        "comments": " ",
        "subjects": "Numerical Analysis (math.NA)",
        "abstract": "A stochastic inverse heat transfer problem is formulated to infer the transient heat flux, treated as an unknown Neumann boundary condition. Therefore, an Ensemble-based Simultaneous Input and State Filtering as a Data Assimilation technique is utilized for simultaneous temperature distribution prediction and heat flux estimation. This approach is incorporated with Radial Basis Functions not only to lessen the size of unknown inputs but also to mitigate the computational burden of this technique. The procedure applies to the specific case of a mold used in Continuous Casting machinery, and it is based on the sequential availability of temperature provided by thermocouples inside the mold. Our research represents a significant contribution to achieving probabilistic boundary condition estimation in real-time handling with noisy measurements and errors in the model. We additionally demonstrate the procedure's dependence on some hyperparameters that are not documented in the existing literature. Accurate real-time prediction of the heat flux is imperative for the smooth operation of Continuous Casting machinery at the boundary region where the Continuous Casting mold and the molten steel meet which is not also physically measurable. Thus, this paves the way for efficient real-time monitoring and control, which is critical for preventing caster shutdowns.\n    ",
        "primary_category": "math.NA",
        "categories": [],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19385": {
        "title": "Towards Safe and Reliable Autonomous Driving: Dynamic Occupancy Set Prediction",
        "authors": [
            "Wenbo Shao",
            "Jiahui Xu",
            "Wenhao Yu",
            "Jun Li",
            "Hong Wang"
        ],
        "comments": "9 pages, 5 figures",
        "subjects": "Robotics (cs.RO)",
        "abstract": "In the rapidly evolving field of autonomous driving, accurate trajectory prediction is pivotal for vehicular safety. However, trajectory predictions often deviate from actual paths, particularly in complex and challenging environments, leading to significant errors. To address this issue, our study introduces a novel method for Dynamic Occupancy Set (DOS) prediction, enhancing trajectory prediction capabilities. This method effectively combines advanced trajectory prediction networks with a DOS prediction module, overcoming the shortcomings of existing models. It provides a comprehensive and adaptable framework for predicting the potential occupancy sets of traffic participants. The main contributions of this research include: 1) A novel DOS prediction model tailored for complex scenarios, augmenting traditional trajectory prediction; 2) The development of unique DOS representations and evaluation metrics; 3) Extensive validation through experiments, demonstrating enhanced performance and adaptability. This research contributes to the advancement of safer and more efficient intelligent vehicle and transportation systems.\n    ",
        "primary_category": "cs.RO",
        "categories": [
            "cs.CV"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19387": {
        "title": "SeD: Semantic-Aware Discriminator for Image Super-Resolution",
        "authors": [
            "Bingchen Li",
            "Xin Li",
            "Hanxin Zhu",
            "Yeying Jin",
            "Ruoyu Feng",
            "Zhizheng Zhang",
            "Zhibo Chen"
        ],
        "comments": "CVPR2024",
        "subjects": "Image and Video Processing (eess.IV)",
        "abstract": "Generative Adversarial Networks (GANs) have been widely used to recover vivid textures in image super-resolution (SR) tasks. In particular, one discriminator is utilized to enable the SR network to learn the distribution of real-world high-quality images in an adversarial training manner. However, the distribution learning is overly coarse-grained, which is susceptible to virtual textures and causes counter-intuitive generation results. To mitigate this, we propose the simple and effective Semantic-aware Discriminator (denoted as SeD), which encourages the SR network to learn the fine-grained distributions by introducing the semantics of images as a condition. Concretely, we aim to excavate the semantics of images from a well-trained semantic extractor. Under different semantics, the discriminator is able to distinguish the real-fake images individually and adaptively, which guides the SR network to learn the more fine-grained semantic-aware textures. To obtain accurate and abundant semantics, we take full advantage of recently popular pretrained vision models (PVMs) with extensive datasets, and then incorporate its semantic features into the discriminator through a well-designed spatial cross-attention module. In this way, our proposed semantic-aware discriminator empowered the SR network to produce more photo-realistic and pleasing images. Extensive experiments on two typical tasks, i.e., SR and Real SR have demonstrated the effectiveness of our proposed methods.\n    ",
        "primary_category": "eess.IV",
        "categories": [
            "cs.CV"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19401": {
        "title": "Assessing Visually-Continuous Corruption Robustness of Neural Networks Relative to Human Performance",
        "authors": [
            "Huakun Shen",
            "Boyue Caroline Hu",
            "Krzysztof Czarnecki",
            "Lina Marsso",
            "Marsha Chechik"
        ],
        "comments": " ",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "While Neural Networks (NNs) have surpassed human accuracy in image classification on ImageNet, they often lack robustness against image corruption, i.e., corruption robustness. Yet such robustness is seemingly effortless for human perception. In this paper, we propose visually-continuous corruption robustness (VCR) -- an extension of corruption robustness to allow assessing it over the wide and continuous range of changes that correspond to the human perceptive quality (i.e., from the original image to the full distortion of all perceived visual information), along with two novel human-aware metrics for NN evaluation. To compare VCR of NNs with human perception, we conducted extensive experiments on 14 commonly used image corruptions with 7,718 human participants and state-of-the-art robust NN models with different training objectives (e.g., standard, adversarial, corruption robustness), different architectures (e.g., convolution NNs, vision transformers), and different amounts of training data augmentation. Our study showed that: 1) assessing robustness against continuous corruption can reveal insufficient robustness undetected by existing benchmarks; as a result, 2) the gap between NN and human robustness is larger than previously known; and finally, 3) some image corruptions have a similar impact on human perception, offering opportunities for more cost-effective robustness assessments. Our validation set with 14 image corruptions, human robustness data, and the evaluation code is provided as a toolbox and a benchmark.\n    ",
        "primary_category": "cs.CV",
        "categories": [],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19402": {
        "title": "A Scalable and Transferable Time Series Prediction Framework for Demand Forecasting",
        "authors": [
            "Young-Jin Park",
            "Donghyun Kim",
            "Fr\u00e9d\u00e9ric Odermatt",
            "Juho Lee",
            "Kyung-Min Kim"
        ],
        "comments": "Published as a full paper at ICDM 2022",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Time series forecasting is one of the most essential and ubiquitous tasks in many business problems, including demand forecasting and logistics optimization. Traditional time series forecasting methods, however, have resulted in small models with limited expressive power because they have difficulty in scaling their model size up while maintaining high accuracy. In this paper, we propose Forecasting orchestra (Forchestra), a simple but powerful framework capable of accurately predicting future demand for a diverse range of items. We empirically demonstrate that the model size is scalable to up to 0.8 billion parameters. The proposed method not only outperforms existing forecasting models with a significant margin, but it could generalize well to unseen data points when evaluated in a zero-shot fashion on downstream datasets. Last but not least, we present extensive qualitative and quantitative studies to analyze how the proposed model outperforms baseline models and differs from conventional approaches. The original paper was presented as a full paper at ICDM 2022 and is available at: this https URL.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19407": {
        "title": "MENTOR: Multi-level Self-supervised Learning for Multimodal Recommendation",
        "authors": [
            "Jinfeng Xu",
            "Zheyu Chen",
            "Shuo Yang",
            "Jinze Li",
            "Hewei Wang",
            "Edith C.-H. Ngai"
        ],
        "comments": " ",
        "subjects": "Information Retrieval (cs.IR)",
        "abstract": "With the increasing multimedia information, multimodal recommendation has received extensive attention. It utilizes multimodal information to alleviate the data sparsity problem in recommendation systems, thus improving recommendation accuracy. However, the reliance on labeled data severely limits the performance of multimodal recommendation models. Recently, self-supervised learning has been used in multimodal recommendations to mitigate the label sparsity problem. Nevertheless, the state-of-the-art methods cannot avoid the modality noise when aligning multimodal information due to the large differences in the distributions of different modalities. To this end, we propose a Multi-level sElf-supervised learNing for mulTimOdal Recommendation (MENTOR) method to address the label sparsity problem and the modality alignment problem. Specifically, MENTOR first enhances the specific features of each modality using the graph convolutional network (GCN) and fuses the visual and textual modalities. It then enhances the item representation via the item semantic graph for all modalities, including the fused modality. Then, it introduces two multilevel self-supervised tasks: the multilevel cross-modal alignment task and the general feature enhancement task. The multilevel cross-modal alignment task aligns each modality under the guidance of the ID embedding from multiple levels while maintaining the historical interaction information. The general feature enhancement task enhances the general feature from both the graph and feature perspectives to improve the robustness of our model. Extensive experiments on three publicly available datasets demonstrate the effectiveness of our method. Our code is publicly available at this https URL.\n    ",
        "primary_category": "cs.IR",
        "categories": [],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19410": {
        "title": "Genie: Smart ROS-based Caching for Connected Autonomous Robots",
        "authors": [
            "Zexin Li",
            "Soroush Bateni",
            "Cong Liu"
        ],
        "comments": "Submitted to IROS 2024",
        "subjects": "Robotics (cs.RO)",
        "abstract": "Despite the promising future of autonomous robots, several key issues currently remain that can lead to compromised performance and safety. One such issue is latency, where we find that even the latest embedded platforms from NVIDIA fail to execute intelligence tasks (e.g., object detection) of autonomous vehicles in a real-time fashion. One remedy to this problem is the promising paradigm of edge computing. Through collaboration with our industry partner, we identify key prohibitive limitations of the current edge mindset: (1) servers are not distributed enough and thus, are not close enough to vehicles, (2) current proposed edge solutions do not provide substantially better performance and extra information specific to autonomous vehicles to warrant their cost to the user, and (3) the state-of-the-art solutions are not compatible with popular frameworks used in autonomous systems, particularly the Robot Operating System (ROS).\nTo remedy these issues, we provide Genie, an encapsulation technique that can enable transparent caching in ROS in a non-intrusive way (i.e., without modifying the source code), can build the cache in a distributed manner (in contrast to traditional central caching methods), and can construct a collective three-dimensional object map to provide substantially better latency (even on low-power edge servers) and higher quality data to all vehicles in a certain locality. We fully implement our design on state-of-the-art industry-adopted embedded and edge platforms, using the prominent autonomous driving software Autoware, and find that Genie can enhance the latency of Autoware Vision Detector by 82% on average, enable object reusability 31% of the time on average and as much as 67% for the incoming requests, and boost the confidence in its object map considerably over time.\n    ",
        "primary_category": "cs.RO",
        "categories": [
            "eess.SY"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19411": {
        "title": "PaECTER: Patent-level Representation Learning using Citation-informed Transformers",
        "authors": [
            "Mainak Ghosh",
            "Sebastian Erhardt",
            "Michael E. Rose",
            "Erik Buunk",
            "Dietmar Harhoff"
        ],
        "comments": "7 pages, 3 figures",
        "subjects": "Information Retrieval (cs.IR)",
        "abstract": "PaECTER is a publicly available, open-source document-level encoder specific for patents. We fine-tune BERT for Patents with examiner-added citation information to generate numerical representations for patent documents. PaECTER performs better in similarity tasks than current state-of-the-art models used in the patent domain. More specifically, our model outperforms the next-best patent specific pre-trained language model (BERT for Patents) on our patent citation prediction test dataset on two different rank evaluation metrics. PaECTER predicts at least one most similar patent at a rank of 1.32 on average when compared against 25 irrelevant patents. Numerical representations generated by PaECTER from patent text can be used for downstream tasks such as classification, tracing knowledge flows, or semantic similarity search. Semantic similarity search is especially relevant in the context of prior art search for both inventors and patent examiners. PaECTER is available on Hugging Face.\n    ",
        "primary_category": "cs.IR",
        "categories": [
            "cs.CL",
            "cs.LG"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19420": {
        "title": "Understanding Iterative Combinatorial Auction Designs via Multi-Agent Reinforcement Learning",
        "authors": [
            "Greg d'Eon",
            "Neil Newman",
            "Kevin Leyton-Brown"
        ],
        "comments": "18 pages (body) + 10 pages (acknowledgements, references, appendices)",
        "subjects": "Computer Science and Game Theory (cs.GT)",
        "abstract": "Iterative combinatorial auctions are widely used in high stakes settings such as spectrum auctions. Such auctions can be hard to understand analytically, making it difficult for bidders to determine how to behave and for designers to optimize auction rules to ensure desirable outcomes such as high revenue or welfare. In this paper, we investigate whether multi-agent reinforcement learning (MARL) algorithms can be used to understand iterative combinatorial auctions, given that these algorithms have recently shown empirical success in several other domains. We find that MARL can indeed benefit auction analysis, but that deploying it effectively is nontrivial. We begin by describing modelling decisions that keep the resulting game tractable without sacrificing important features such as imperfect information or asymmetry between bidders. We also discuss how to navigate pitfalls of various MARL algorithms, how to overcome challenges in verifying convergence, and how to generate and interpret multiple equilibria. We illustrate the promise of our resulting approach by using it to evaluate a specific rule change to a clock auction, finding substantially different auction outcomes due to complex changes in bidders' behavior.\n    ",
        "primary_category": "cs.GT",
        "categories": [
            "cs.AI",
            "cs.MA"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19421": {
        "title": "Crafting Knowledge: Exploring the Creative Mechanisms of Chat-Based Search Engines",
        "authors": [
            "Lijia Ma",
            "Xingchen Xu",
            "Yong Tan"
        ],
        "comments": "38 pages, 2 figures, 7 tables",
        "subjects": "Information Retrieval (cs.IR)",
        "abstract": "In the domain of digital information dissemination, search engines act as pivotal conduits linking information seekers with providers. The advent of chat-based search engines utilizing Large Language Models (LLMs) and Retrieval Augmented Generation (RAG), exemplified by Bing Chat, marks an evolutionary leap in the search ecosystem. They demonstrate metacognitive abilities in interpreting web information and crafting responses with human-like understanding and creativity. Nonetheless, the intricate nature of LLMs renders their \"cognitive\" processes opaque, challenging even their designers' understanding. This research aims to dissect the mechanisms through which an LLM-powered chat-based search engine, specifically Bing Chat, selects information sources for its responses. To this end, an extensive dataset has been compiled through engagements with New Bing, documenting the websites it cites alongside those listed by the conventional search engine. Employing natural language processing (NLP) techniques, the research reveals that Bing Chat exhibits a preference for content that is not only readable and formally structured, but also demonstrates lower perplexity levels, indicating a unique inclination towards text that is predictable by the underlying LLM. Further enriching our analysis, we procure an additional dataset through interactions with the GPT-4 based knowledge retrieval API, unveiling a congruent text preference between the RAG API and Bing Chat. This consensus suggests that these text preferences intrinsically emerge from the underlying language models, rather than being explicitly crafted by Bing Chat's developers. Moreover, our investigation documents a greater similarity among websites cited by RAG technologies compared to those ranked highest by conventional search engines.\n    ",
        "primary_category": "cs.IR",
        "categories": [
            "cs.AI",
            "econ.GN"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19423": {
        "title": "Leveraging AI Predicted and Expert Revised Annotations in Interactive Segmentation: Continual Tuning or Full Training?",
        "authors": [
            "Tiezheng Zhang",
            "Xiaoxi Chen",
            "Chongyu Qu",
            "Alan Yuille",
            "Zongwei Zhou"
        ],
        "comments": "IEEE International Symposium on Biomedical Imaging (ISBI)",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Interactive segmentation, an integration of AI algorithms and human expertise, premises to improve the accuracy and efficiency of curating large-scale, detailed-annotated datasets in healthcare. Human experts revise the annotations predicted by AI, and in turn, AI improves its predictions by learning from these revised annotations. This interactive process continues to enhance the quality of annotations until no major revision is needed from experts. The key challenge is how to leverage AI predicted and expert revised annotations to iteratively improve the AI. Two problems arise: (1) The risk of catastrophic forgetting--the AI tends to forget the previously learned classes if it is only retrained using the expert revised classes. (2) Computational inefficiency when retraining the AI using both AI predicted and expert revised annotations; moreover, given the dominant AI predicted annotations in the dataset, the contribution of newly revised annotations--often account for a very small fraction--to the AI training remains marginal. This paper proposes Continual Tuning to address the problems from two perspectives: network design and data reuse. Firstly, we design a shared network for all classes followed by class-specific networks dedicated to individual classes. To mitigate forgetting, we freeze the shared network for previously learned classes and only update the class-specific network for revised classes. Secondly, we reuse a small fraction of data with previous annotations to avoid over-computing. The selection of such data relies on the importance estimate of each data. The importance score is computed by combining the uncertainty and consistency of AI predictions. Our experiments demonstrate that Continual Tuning achieves a speed 16x greater than repeatedly training AI from scratch without compromising the performance.\n    ",
        "primary_category": "cs.CV",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19427": {
        "title": "Griffin: Mixing Gated Linear Recurrences with Local Attention for Efficient Language Models",
        "authors": [
            "Soham De",
            "Samuel L. Smith",
            "Anushan Fernando",
            "Aleksandar Botev",
            "George Cristian-Muraru",
            "Albert Gu",
            "Ruba Haroun",
            "Leonard Berrada",
            "Yutian Chen",
            "Srivatsan Srinivasan",
            "Guillaume Desjardins",
            "Arnaud Doucet",
            "David Budden",
            "Yee Whye Teh",
            "Razvan Pascanu",
            "Nando De Freitas",
            "Caglar Gulcehre"
        ],
        "comments": "25 pages, 11 figures",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Recurrent neural networks (RNNs) have fast inference and scale efficiently on long sequences, but they are difficult to train and hard to scale. We propose Hawk, an RNN with gated linear recurrences, and Griffin, a hybrid model that mixes gated linear recurrences with local attention. Hawk exceeds the reported performance of Mamba on downstream tasks, while Griffin matches the performance of Llama-2 despite being trained on over 6 times fewer tokens. We also show that Griffin can extrapolate on sequences significantly longer than those seen during training. Our models match the hardware efficiency of Transformers during training, and during inference they have lower latency and significantly higher throughput. We scale Griffin up to 14B parameters, and explain how to shard our models for efficient distributed training.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.CL"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19431": {
        "title": "Compositional API Recommendation for Library-Oriented Code Generation",
        "authors": [
            "Zexiong Ma",
            "Shengnan An",
            "Bing Xie",
            "Zeqi Lin"
        ],
        "comments": " ",
        "subjects": "Software Engineering (cs.SE)",
        "abstract": "Large language models (LLMs) have achieved exceptional performance in code generation. However, the performance remains unsatisfactory in generating library-oriented code, especially for the libraries not present in the training data of LLMs. Previous work utilizes API recommendation technology to help LLMs use libraries: it retrieves APIs related to the user requirements, then leverages them as context to prompt LLMs. However, developmental requirements can be coarse-grained, requiring a combination of multiple fine-grained APIs. This granularity inconsistency makes API recommendation a challenging task. To address this, we propose CAPIR (Compositional API Recommendation), which adopts a \"divide-and-conquer\" strategy to recommend APIs for coarse-grained requirements. Specifically, CAPIR employs an LLM-based Decomposer to break down a coarse-grained task description into several detailed subtasks. Then, CAPIR applies an embedding-based Retriever to identify relevant APIs corresponding to each subtask. Moreover, CAPIR leverages an LLM-based Reranker to filter out redundant APIs and provides the final recommendation. To facilitate the evaluation of API recommendation methods on coarse-grained requirements, we present two challenging benchmarks, RAPID (Recommend APIs based on Documentation) and LOCG (Library-Oriented Code Generation). Experimental results on these benchmarks, demonstrate the effectiveness of CAPIR in comparison to existing baselines. Specifically, on RAPID's Torchdata-AR dataset, compared to the state-of-the-art API recommendation approach, CAPIR improves recall@5 from 18.7% to 43.2% and precision@5 from 15.5% to 37.1%. On LOCG's Torchdata-Code dataset, compared to code generation without API recommendation, CAPIR improves pass@100 from 16.0% to 28.0%.\n    ",
        "primary_category": "cs.SE",
        "categories": [
            "cs.AI",
            "cs.CL"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19432": {
        "title": "Pushing the Limits of Cross-Embodiment Learning for Manipulation and Navigation",
        "authors": [
            "Jonathan Yang",
            "Catherine Glossop",
            "Arjun Bhorkar",
            "Dhruv Shah",
            "Quan Vuong",
            "Chelsea Finn",
            "Dorsa Sadigh",
            "Sergey Levine"
        ],
        "comments": "16 pages, 9 figures",
        "subjects": "Robotics (cs.RO)",
        "abstract": "Recent years in robotics and imitation learning have shown remarkable progress in training large-scale foundation models by leveraging data across a multitude of embodiments. The success of such policies might lead us to wonder: just how diverse can the robots in the training set be while still facilitating positive transfer? In this work, we study this question in the context of heterogeneous embodiments, examining how even seemingly very different domains, such as robotic navigation and manipulation, can provide benefits when included in the training data for the same model. We train a single goal-conditioned policy that is capable of controlling robotic arms, quadcopters, quadrupeds, and mobile bases. We then investigate the extent to which transfer can occur across navigation and manipulation on these embodiments by framing them as a single goal-reaching task. We find that co-training with navigation data can enhance robustness and performance in goal-conditioned manipulation with a wrist-mounted camera. We then deploy our policy trained only from navigation-only and static manipulation-only data on a mobile manipulator, showing that it can control a novel embodiment in a zero-shot manner. These results provide evidence that large-scale robotic policies can benefit from data collected across various embodiments. Further information and robot videos can be found on our project website this http URL.\n    ",
        "primary_category": "cs.RO",
        "categories": [],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19437": {
        "title": "Differentially Private Worst-group Risk Minimization",
        "authors": [
            "Xinyu Zhou",
            "Raef Bassily"
        ],
        "comments": " ",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "We initiate a systematic study of worst-group risk minimization under $(\\epsilon, \\delta)$-differential privacy (DP). The goal is to privately find a model that approximately minimizes the maximal risk across $p$ sub-populations (groups) with different distributions, where each group distribution is accessed via a sample oracle. We first present a new algorithm that achieves excess worst-group population risk of $\\tilde{O}(\\frac{p\\sqrt{d}}{K\\epsilon} + \\sqrt{\\frac{p}{K}})$, where $K$ is the total number of samples drawn from all groups and $d$ is the problem dimension. Our rate is nearly optimal when each distribution is observed via a fixed-size dataset of size $K/p$. Our result is based on a new stability-based analysis for the generalization error. In particular, we show that $\\Delta$-uniform argument stability implies $\\tilde{O}(\\Delta + \\frac{1}{\\sqrt{n}})$ generalization error w.r.t. the worst-group risk, where $n$ is the number of samples drawn from each sample oracle. Next, we propose an algorithmic framework for worst-group population risk minimization using any DP online convex optimization algorithm as a subroutine. Hence, we give another excess risk bound of $\\tilde{O}\\left( \\sqrt{\\frac{d^{1/2}}{\\epsilon K}} +\\sqrt{\\frac{p}{K\\epsilon^2}} \\right)$. Assuming the typical setting of $\\epsilon=\\Theta(1)$, this bound is more favorable than our first bound in a certain range of $p$ as a function of $K$ and $d$. Finally, we study differentially private worst-group empirical risk minimization in the offline setting, where each group distribution is observed by a fixed-size dataset. We present a new algorithm with nearly optimal excess risk of $\\tilde{O}(\\frac{p\\sqrt{d}}{K\\epsilon})$.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.AI",
            "cs.CR"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19441": {
        "title": "3D Gaussian Model for Animation and Texturing",
        "authors": [
            "Xiangzhi Eric Wang",
            "Zackary P. T. Sin"
        ],
        "comments": " ",
        "subjects": "Graphics (cs.GR)",
        "abstract": "3D Gaussian Splatting has made a marked impact on neural rendering by achieving impressive fidelity and performance. Despite this achievement, however, it is not readily applicable to developing interactive applications. Real-time applications like XR apps and games require functions such as animation, UV-mapping, and model editing simultaneously manipulated through the usage of a 3D model. We propose a modeling that is analogous to typical 3D models, which we call 3D Gaussian Model (3DGM); it provides a manipulatable proxy for novel animation and texture transfer. By binding the 3D Gaussians in texture space and re-projecting them back to world space through implicit shell mapping, we show how our 3D modeling can serve as a valid rendering methodology for interactive applications. It is further noted that recently, 3D mesh reconstruction works have been able to produce high-quality mesh for rendering. Our work, on the other hand, only requires an approximated geometry for rendering an object in high fidelity. Applicationwise, we will show that our proxy-based 3DGM is capable of driving novel animation without animated training data and texture transferring via UV mapping of the 3D Gaussians. We believe the result indicates the potential of our work for enabling interactive applications for 3D Gaussian Splatting.\n    ",
        "primary_category": "cs.GR",
        "categories": [],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19442": {
        "title": "Training Dynamics of Multi-Head Softmax Attention for In-Context Learning: Emergence, Convergence, and Optimality",
        "authors": [
            "Siyu Chen",
            "Heejune Sheen",
            "Tianhao Wang",
            "Zhuoran Yang"
        ],
        "comments": "141 pages, 7 figures",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "We study the dynamics of gradient flow for training a multi-head softmax attention model for in-context learning of multi-task linear regression. We establish the global convergence of gradient flow under suitable choices of initialization. In addition, we prove that an interesting \"task allocation\" phenomenon emerges during the gradient flow dynamics, where each attention head focuses on solving a single task of the multi-task model. Specifically, we prove that the gradient flow dynamics can be split into three phases -- a warm-up phase where the loss decreases rather slowly and the attention heads gradually build up their inclination towards individual tasks, an emergence phase where each head selects a single task and the loss rapidly decreases, and a convergence phase where the attention parameters converge to a limit. Furthermore, we prove the optimality of gradient flow in the sense that the limiting model learned by gradient flow is on par with the best possible multi-head softmax attention model up to a constant factor. Our analysis also delineates a strict separation in terms of the prediction accuracy of ICL between single-head and multi-head attention models. The key technique for our convergence analysis is to map the gradient flow dynamics in the parameter space to a set of ordinary differential equations in the spectral domain, where the relative magnitudes of the semi-singular values of the attention weights determines task allocation. To our best knowledge, our work provides the first convergence result for the multi-head softmax attention model.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.AI",
            "math.OC",
            "math.ST",
            "stat.ML"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19443": {
        "title": "Probing the Information Encoded in Neural-based Acoustic Models of Automatic Speech Recognition Systems",
        "authors": [
            "Quentin Raymondaud",
            "Mickael Rouvier",
            "Richard Dufour"
        ],
        "comments": " ",
        "subjects": "Sound (cs.SD)",
        "abstract": "Deep learning architectures have made significant progress in terms of performance in many research areas. The automatic speech recognition (ASR) field has thus benefited from these scientific and technological advances, particularly for acoustic modeling, now integrating deep neural network architectures. However, these performance gains have translated into increased complexity regarding the information learned and conveyed through these black-box architectures. Following many researches in neural networks interpretability, we propose in this article a protocol that aims to determine which and where information is located in an ASR acoustic model (AM). To do so, we propose to evaluate AM performance on a determined set of tasks using intermediate representations (here, at different layer levels). Regarding the performance variation and targeted tasks, we can emit hypothesis about which information is enhanced or perturbed at different architecture steps. Experiments are performed on both speaker verification, acoustic environment classification, gender classification, tempo-distortion detection systems and speech sentiment/emotion identification. Analysis showed that neural-based AMs hold heterogeneous information that seems surprisingly uncorrelated with phoneme recognition, such as emotion, sentiment or speaker identity. The low-level hidden layers globally appears useful for the structuring of information while the upper ones would tend to delete useless information for phoneme recognition.\n    ",
        "primary_category": "cs.SD",
        "categories": [
            "cs.AI",
            "eess.AS"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19446": {
        "title": "ArCHer: Training Language Model Agents via Hierarchical Multi-Turn RL",
        "authors": [
            "Yifei Zhou",
            "Andrea Zanette",
            "Jiayi Pan",
            "Sergey Levine",
            "Aviral Kumar"
        ],
        "comments": " ",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "A broad use case of large language models (LLMs) is in goal-directed decision-making tasks (or \"agent\" tasks), where an LLM needs to not just generate completions for a given prompt, but rather make intelligent decisions over a multi-turn interaction to accomplish a task (e.g., when interacting with the web, using tools, or providing customer support). Reinforcement learning (RL) provides a general paradigm to address such agent tasks, but current RL methods for LLMs largely focus on optimizing single-turn rewards. By construction, most single-turn RL methods cannot endow LLMs with the ability to intelligently seek information over multiple turns, perform credit assignment, or reason about their past actions -- all of which are critical in agent tasks. This raises the question: how can we design effective and efficient multi-turn RL algorithms for LLMs? In this paper, we develop a framework for building multi-turn RL algorithms for fine-tuning LLMs, that preserves the flexibility of existing single-turn RL methods for LLMs (e.g., proximal policy optimization), while accommodating multiple turns, long horizons, and delayed rewards effectively. To do this, our framework adopts a hierarchical RL approach and runs two RL algorithms in parallel: a high-level off-policy value-based RL algorithm to aggregate reward over utterances, and a low-level RL algorithm that utilizes this high-level value function to train a token policy within each utterance or turn. Our hierarchical framework, Actor-Critic Framework with a Hierarchical Structure (ArCHer), can also give rise to other RL methods. Empirically, we find that ArCHer significantly improves efficiency and performance on agent tasks, attaining a sample efficiency of about 100x over existing methods, while also improving with larger model capacity (upto the 7 billion scale that we tested on).\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.AI",
            "cs.CL"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19449": {
        "title": "Heavy-Tailed Class Imbalance and Why Adam Outperforms Gradient Descent on Language Models",
        "authors": [
            "Frederik Kunstner",
            "Robin Yadav",
            "Alan Milligan",
            "Mark Schmidt",
            "Alberto Bietti"
        ],
        "comments": " ",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Adam has been shown to outperform gradient descent in optimizing large language transformers empirically, and by a larger margin than on other tasks, but it is unclear why this happens. We show that the heavy-tailed class imbalance found in language modeling tasks leads to difficulties in the optimization dynamics. When training with gradient descent, the loss associated with infrequent words decreases slower than the loss associated with frequent ones. As most samples come from relatively infrequent words, the average loss decreases slowly with gradient descent. On the other hand, Adam and sign-based methods do not suffer from this problem and improve predictions on all classes. To establish that this behavior is indeed caused by class imbalance, we show empirically that it persist through different architectures and data types, on language transformers, vision CNNs, and linear models. We further study this phenomenon on a linear classification with cross-entropy loss, showing that heavy-tailed class imbalance leads to ill-conditioning, and that the normalization used by Adam can counteract it.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.CL",
            "math.OC",
            "stat.ML"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19450": {
        "title": "Functional Benchmarks for Robust Evaluation of Reasoning Performance, and the Reasoning Gap",
        "authors": [
            "Saurabh Srivastava",
            "Annarose M B",
            "Anto P V",
            "Shashank Menon",
            "Ajay Sukumar",
            "Adwaith Samod T",
            "Alan Philipose",
            "Stevin Prince",
            "Sooraj Thomas"
        ],
        "comments": "37 pages, 10 figures",
        "subjects": "Artificial Intelligence (cs.AI)",
        "abstract": "We propose a framework for robust evaluation of reasoning capabilities of language models, using functional variants of benchmarks. Models that solve a reasoning test should exhibit no difference in performance over the static version of a problem compared to a snapshot of the functional variant. We have rewritten the relevant fragment of the MATH benchmark into its functional variant MATH(), with functionalization of other benchmarks to follow. When evaluating current state-of-the-art models over snapshots of MATH(), we find a reasoning gap -- the percentage difference between the static and functional accuracies. We find reasoning gaps from 58.35% to 80.31% among the state-of-the-art closed and open weights models that perform well on static benchmarks, with the caveat that the gaps are likely to be smaller with more sophisticated prompting strategies. Here we show that models which anecdotally have good reasoning performance over real-world tasks, have quantifiable lower gaps, motivating the open problem of building \"gap 0\" models. Code for evaluation and new evaluation datasets, three MATH() snapshots, are publicly available at this https URL.\n    ",
        "primary_category": "cs.AI",
        "categories": [
            "cs.CL"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19455": {
        "title": "Listening to the Noise: Blind Denoising with Gibbs Diffusion",
        "authors": [
            "David Heurtel-Depeiges",
            "Charles C. Margossian",
            "Ruben Ohana",
            "Bruno R\u00e9galdo-Saint Blancard"
        ],
        "comments": "12+8 pages, 7+3 figures, 1+1 tables, code: this https URL",
        "subjects": "Machine Learning (stat.ML)",
        "abstract": "In recent years, denoising problems have become intertwined with the development of deep generative models. In particular, diffusion models are trained like denoisers, and the distribution they model coincide with denoising priors in the Bayesian picture. However, denoising through diffusion-based posterior sampling requires the noise level and covariance to be known, preventing blind denoising. We overcome this limitation by introducing Gibbs Diffusion (GDiff), a general methodology addressing posterior sampling of both the signal and the noise parameters. Assuming arbitrary parametric Gaussian noise, we develop a Gibbs algorithm that alternates sampling steps from a conditional diffusion model trained to map the signal prior to the family of noise distributions, and a Monte Carlo sampler to infer the noise parameters. Our theoretical analysis highlights potential pitfalls, guides diagnostic usage, and quantifies errors in the Gibbs stationary distribution caused by the diffusion model. We showcase our method for 1) blind denoising of natural images involving colored noises with unknown amplitude and spectral index, and 2) a cosmology problem, namely the analysis of cosmic microwave background data, where Bayesian inference of \"noise\" parameters means constraining models of the evolution of the Universe.\n    ",
        "primary_category": "stat.ML",
        "categories": [
            "astro-ph.CO",
            "cs.CV",
            "cs.LG",
            "eess.SP"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19460": {
        "title": "Benchmarking Uncertainty Disentanglement: Specialized Uncertainties for Specialized Tasks",
        "authors": [
            "B\u00e1lint Mucs\u00e1nyi",
            "Michael Kirchhof",
            "Seong Joon Oh"
        ],
        "comments": "43 pages",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Uncertainty quantification, once a singular task, has evolved into a spectrum of tasks, including abstained prediction, out-of-distribution detection, and aleatoric uncertainty quantification. The latest goal is disentanglement: the construction of multiple estimators that are each tailored to one and only one task. Hence, there is a plethora of recent advances with different intentions - that often entirely deviate from practical behavior. This paper conducts a comprehensive evaluation of numerous uncertainty estimators across diverse tasks on ImageNet. We find that, despite promising theoretical endeavors, disentanglement is not yet achieved in practice. Additionally, we reveal which uncertainty estimators excel at which specific tasks, providing insights for practitioners and guiding future research toward task-centric and disentangled uncertainty estimation methods. Our code is available at this https URL.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "stat.ML"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19462": {
        "title": "Accelerating materials discovery for polymer solar cells: Data-driven insights enabled by natural language processing",
        "authors": [
            "Pranav Shetty",
            "Aishat Adeboye",
            "Sonakshi Gupta",
            "Chao Zhang",
            "Rampi Ramprasad"
        ],
        "comments": " ",
        "subjects": "Materials Science (cond-mat.mtrl-sci)",
        "abstract": "We present a natural language processing pipeline that was used to extract polymer solar cell property data from the literature and simulate various active learning strategies. While data-driven methods have been well established to discover novel materials faster than Edisonian trial-and-error approaches, their benefits have not been quantified. Our approach demonstrates a potential reduction in discovery time by approximately 75 %, equivalent to a 15 year acceleration in material innovation. Our pipeline enables us to extract data from more than 3300 papers which is ~5 times larger than similar data sets reported by others. We also trained machine learning models to predict the power conversion efficiency and used our model to identify promising donor-acceptor combinations that are as yet unreported. We thus demonstrate a workflow that goes from published literature to extracted material property data which in turn is used to obtain data-driven insights. Our insights include active learning strategies that can simultaneously optimize the material system and train strong predictive models of material properties. This work provides a valuable framework for research in material science.\n    ",
        "primary_category": "cond-mat.mtrl-sci",
        "categories": [
            "cs.CL",
            "physics.app-ph"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19464": {
        "title": "Curiosity-driven Red-teaming for Large Language Models",
        "authors": [
            "Zhang-Wei Hong",
            "Idan Shenfeld",
            "Tsun-Hsuan Wang",
            "Yung-Sung Chuang",
            "Aldo Pareja",
            "James Glass",
            "Akash Srivastava",
            "Pulkit Agrawal"
        ],
        "comments": "Published at ICLR 2024",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Large language models (LLMs) hold great potential for many natural language applications but risk generating incorrect or toxic content. To probe when an LLM generates unwanted content, the current paradigm is to recruit a \\textit{red team} of human testers to design input prompts (i.e., test cases) that elicit undesirable responses from LLMs. However, relying solely on human testers is expensive and time-consuming. Recent works automate red teaming by training a separate red team LLM with reinforcement learning (RL) to generate test cases that maximize the chance of eliciting undesirable responses from the target LLM. However, current RL methods are only able to generate a small number of effective test cases resulting in a low coverage of the span of prompts that elicit undesirable responses from the target LLM. To overcome this limitation, we draw a connection between the problem of increasing the coverage of generated test cases and the well-studied approach of curiosity-driven exploration that optimizes for novelty. Our method of curiosity-driven red teaming (CRT) achieves greater coverage of test cases while mantaining or increasing their effectiveness compared to existing methods. Our method, CRT successfully provokes toxic responses from LLaMA2 model that has been heavily fine-tuned using human preferences to avoid toxic outputs. Code is available at \\url{this https URL}\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.AI",
            "cs.CL"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19465": {
        "title": "Towards Tracing Trustworthiness Dynamics: Revisiting Pre-training Period of Large Language Models",
        "authors": [
            "Chen Qian",
            "Jie Zhang",
            "Wei Yao",
            "Dongrui Liu",
            "Zhenfei Yin",
            "Yu Qiao",
            "Yong Liu",
            "Jing Shao"
        ],
        "comments": " ",
        "subjects": "Computation and Language (cs.CL)",
        "abstract": "Ensuring the trustworthiness of large language models (LLMs) is crucial. Most studies concentrate on fully pre-trained LLMs to better understand and improve LLMs' trustworthiness. In this paper, to reveal the untapped potential of pre-training, we pioneer the exploration of LLMs' trustworthiness during this period, focusing on five key dimensions: reliability, privacy, toxicity, fairness, and robustness. To begin with, we apply linear probing to LLMs. The high probing accuracy suggests that \\textit{LLMs in early pre-training can already distinguish concepts in each trustworthiness dimension}. Therefore, to further uncover the hidden possibilities of pre-training, we extract steering vectors from a LLM's pre-training checkpoints to enhance the LLM's trustworthiness. Finally, inspired by~\\citet{choi2023understanding} that mutual information estimation is bounded by linear probing accuracy, we also probe LLMs with mutual information to investigate the dynamics of trustworthiness during pre-training. We are the first to observe a similar two-phase phenomenon: fitting and compression~\\citep{shwartz2017opening}. This research provides an initial exploration of trustworthiness modeling during LLM pre-training, seeking to unveil new insights and spur further developments in the field. We will make our code publicly accessible at \\url{this https URL}.\n    ",
        "primary_category": "cs.CL",
        "categories": [
            "cs.AI"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19469": {
        "title": "Humanoid Locomotion as Next Token Prediction",
        "authors": [
            "Ilija Radosavovic",
            "Bike Zhang",
            "Baifeng Shi",
            "Jathushan Rajasegaran",
            "Sarthak Kamat",
            "Trevor Darrell",
            "Koushil Sreenath",
            "Jitendra Malik"
        ],
        "comments": " ",
        "subjects": "Robotics (cs.RO)",
        "abstract": "We cast real-world humanoid control as a next token prediction problem, akin to predicting the next word in language. Our model is a causal transformer trained via autoregressive prediction of sensorimotor trajectories. To account for the multi-modal nature of the data, we perform prediction in a modality-aligned way, and for each input token predict the next token from the same modality. This general formulation enables us to leverage data with missing modalities, like video trajectories without actions. We train our model on a collection of simulated trajectories coming from prior neural network policies, model-based controllers, motion capture data, and YouTube videos of humans. We show that our model enables a full-sized humanoid to walk in San Francisco zero-shot. Our model can transfer to the real world even when trained on only 27 hours of walking data, and can generalize to commands not seen during training like walking backward. These findings suggest a promising path toward learning challenging real-world control tasks by generative modeling of sensorimotor trajectories.\n    ",
        "primary_category": "cs.RO",
        "categories": [
            "cs.CV",
            "cs.LG"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19472": {
        "title": "Lifelong Benchmarks: Efficient Model Evaluation in an Era of Rapid Progress",
        "authors": [
            "Ameya Prabhu",
            "Vishaal Udandarao",
            "Philip Torr",
            "Matthias Bethge",
            "Adel Bibi",
            "Samuel Albanie"
        ],
        "comments": " ",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Standardized benchmarks drive progress in machine learning. However, with repeated testing, the risk of overfitting grows as algorithms over-exploit benchmark idiosyncrasies. In our work, we seek to mitigate this challenge by compiling ever-expanding large-scale benchmarks called Lifelong Benchmarks. As exemplars of our approach, we create Lifelong-CIFAR10 and Lifelong-ImageNet, containing (for now) 1.69M and 1.98M test samples, respectively. While reducing overfitting, lifelong benchmarks introduce a key challenge: the high cost of evaluating a growing number of models across an ever-expanding sample set. To address this challenge, we also introduce an efficient evaluation framework: Sort \\& Search (S&S), which reuses previously evaluated models by leveraging dynamic programming algorithms to selectively rank and sub-select test samples, enabling cost-effective lifelong benchmarking. Extensive empirical evaluations across 31,000 models demonstrate that S&S achieves highly-efficient approximate accuracy measurement, reducing compute cost from 180 GPU days to 5 GPU hours (1000x reduction) on a single A100 GPU, with low approximation error. As such, lifelong benchmarks offer a robust, practical solution to the \"benchmark exhaustion\" problem.\n    ",
        "primary_category": "cs.LG",
        "categories": [
            "cs.CV"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19475": {
        "title": "The Counterfeit Conundrum: Can Code Language Models Grasp the Nuances of Their Incorrect Generations?",
        "authors": [
            "Alex Gu",
            "Wen-Ding Li",
            "Naman Jain",
            "Theo X. Olausson",
            "Celine Lee",
            "Koushik Sen",
            "Armando Solar-Lezama"
        ],
        "comments": "54 pages, 25 figures",
        "subjects": "Software Engineering (cs.SE)",
        "abstract": "While language models are increasingly more proficient at code generation, they still frequently generate incorrect programs. Many of these programs are obviously wrong, but others are more subtle and pass weaker correctness checks such as being able to compile. In this work, we focus on these counterfeit samples: programs sampled from a language model that 1) have a high enough log-probability to be generated at a moderate temperature and 2) pass weak correctness checks. Overall, we discover that most models have a very shallow understanding of counterfeits through three clear failure modes. First, models mistakenly classify them as correct. Second, models are worse at reasoning about the execution behaviour of counterfeits and often predict their execution results as if they were correct. Third, when asking models to fix counterfeits, the likelihood of a model successfully repairing a counterfeit is often even lower than that of sampling a correct program from scratch. Counterfeits also have very unexpected properties: first, counterfeit programs for problems that are easier for a model to solve are not necessarily easier to detect and only slightly easier to execute and repair. Second, counterfeits from a given model are just as confusing to the model itself as they are to other models. Finally, both strong and weak models are able to generate counterfeit samples that equally challenge all models. In light of our findings, we recommend that care and caution be taken when relying on models to understand their own samples, especially when no external feedback is incorporated.\n    ",
        "primary_category": "cs.SE",
        "categories": [
            "cs.AI",
            "cs.LG"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19477": {
        "title": "Learning a Generalized Physical Face Model From Data",
        "authors": [
            "Lingchen Yang",
            "Gaspard Zoss",
            "Prashanth Chandran",
            "Markus Gross",
            "Barbara Solenthaler",
            "Eftychios Sifakis",
            "Derek Bradley"
        ],
        "comments": " ",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Physically-based simulation is a powerful approach for 3D facial animation as the resulting deformations are governed by physical constraints, allowing to easily resolve self-collisions, respond to external forces and perform realistic anatomy edits. Today's methods are data-driven, where the actuations for finite elements are inferred from captured skin geometry. Unfortunately, these approaches have not been widely adopted due to the complexity of initializing the material space and learning the deformation model for each character separately, which often requires a skilled artist followed by lengthy network training. In this work, we aim to make physics-based facial animation more accessible by proposing a generalized physical face model that we learn from a large 3D face dataset in a simulation-free manner. Once trained, our model can be quickly fit to any unseen identity and produce a ready-to-animate physical face model automatically. Fitting is as easy as providing a single 3D face scan, or even a single face image. After fitting, we offer intuitive animation controls, as well as the ability to retarget animations across characters. All the while, the resulting animations allow for physical effects like collision avoidance, gravity, paralysis, bone reshaping and more.\n    ",
        "primary_category": "cs.CV",
        "categories": [
            "cs.GR"
        ],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    },
    "2402.19479": {
        "title": "Panda-70M: Captioning 70M Videos with Multiple Cross-Modality Teachers",
        "authors": [
            "Tsai-Shien Chen",
            "Aliaksandr Siarohin",
            "Willi Menapace",
            "Ekaterina Deyneka",
            "Hsiang-wei Chao",
            "Byung Eun Jeon",
            "Yuwei Fang",
            "Hsin-Ying Lee",
            "Jian Ren",
            "Ming-Hsuan Yang",
            "Sergey Tulyakov"
        ],
        "comments": "CVPR 2024. Project Page: this https URL",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "The quality of the data and annotation upper-bounds the quality of a downstream model. While there exist large text corpora and image-text pairs, high-quality video-text data is much harder to collect. First of all, manual labeling is more time-consuming, as it requires an annotator to watch an entire video. Second, videos have a temporal dimension, consisting of several scenes stacked together, and showing multiple actions. Accordingly, to establish a video dataset with high-quality captions, we propose an automatic approach leveraging multimodal inputs, such as textual video description, subtitles, and individual video frames. Specifically, we curate 3.8M high-resolution videos from the publicly available HD-VILA-100M dataset. We then split them into semantically consistent video clips, and apply multiple cross-modality teacher models to obtain captions for each video. Next, we finetune a retrieval model on a small subset where the best caption of each video is manually selected and then employ the model in the whole dataset to select the best caption as the annotation. In this way, we get 70M videos paired with high-quality text captions. We dub the dataset as Panda-70M. We show the value of the proposed dataset on three downstream tasks: video captioning, video and text retrieval, and text-driven video generation. The models trained on the proposed data score substantially better on the majority of metrics across all the tasks.\n    ",
        "primary_category": "cs.CV",
        "categories": [],
        "submitted_date": "29 Feb 2024",
        "last_revised_date": " "
    }
}