{
    "0705.1329v3": {
        "url": "http://arxiv.org/abs/0705.1329v3",
        "title": "Third Order Newton's Method for Zernike Polynomial Zeros",
        "summary": "The Zernike radial polynomials are a system of orthogonal polynomials over\nthe unit interval with weight x. They are used as basis functions in optics to\nexpand fields over the cross section of circular pupils. To calculate the roots\nof Zernike polynomials, we optimize the generic iterative numerical Newton's\nMethod that iterates on zeros of functions with third order convergence. The\ntechnique is based on rewriting the polynomials as Gauss Hypergeometric\nFunctions, reduction of second order derivatives to first order derivatives,\nand evaluation of some ratios of derivatives by terminating continued\nfractions.\n  A PARI program and a short table of zeros complete up to polynomials of 40th\norder are included.",
        "updated": "2024-04-20T22:46:09Z",
        "published": "2007-05-09T17:22:15Z",
        "authors": [
            "Richard J. Mathar"
        ],
        "comments": "Version 3 covers also the Zernike polynomials in unit balls of\n  dimension >=3",
        "categories": [
            "math.NA",
            "cs.NA",
            "26C10, 33C45, 78M34"
        ],
        "primary_category": "math.NA"
    },
    "0806.1636v1": {
        "url": "http://arxiv.org/abs/0806.1636v1",
        "title": "Data-Complexity of the Two-Variable Fragment with Counting Quantifiers",
        "summary": "The data-complexity of both satisfiability and finite satisfiability for the\ntwo-variable fragment with counting is NP-complete; the data-complexity of both\nquery-answering and finite query-answering for the two-variable guarded\nfragment with counting is co-NP-complete.",
        "updated": "2008-06-10T11:08:07Z",
        "published": "2008-06-10T11:08:07Z",
        "authors": [
            "Ian Pratt-Hartmann"
        ],
        "categories": [
            "cs.LO",
            "cs.AI",
            "cs.CC",
            "F.4.1"
        ],
        "primary_category": "cs.LO",
        "doi": "10.1016/j.ic.2009.02.004",
        "journal_ref": "Information and Computation, 207(8), 2009, pp. 867--888"
    },
    "0808.0521v1": {
        "url": "http://arxiv.org/abs/0808.0521v1",
        "title": "Logics for the Relational Syllogistic",
        "summary": "The Aristotelian syllogistic cannot account for the validity of many\ninferences involving relational facts. In this paper, we investigate the\nprospects for providing a relational syllogistic. We identify several fragments\nbased on (a) whether negation is permitted on all nouns, including those in the\nsubject of a sentence; and (b) whether the subject noun phrase may contain a\nrelative clause. The logics we present are extensions of the classical\nsyllogistic, and we pay special attention to the question of whether reductio\nad absurdum is needed. Thus our main goal is to derive results on the existence\n(or non-existence) of syllogistic proof systems for relational fragments. We\nalso determine the computational complexity of all our fragments.",
        "updated": "2008-08-04T22:26:38Z",
        "published": "2008-08-04T22:26:38Z",
        "authors": [
            "Ian Pratt-Hartmann",
            "Lawrence S. Moss"
        ],
        "categories": [
            "cs.LO",
            "cs.CC",
            "cs.CL",
            "F.4.1; I.2.3"
        ],
        "primary_category": "cs.LO",
        "doi": "10.1017/S1755020309990086",
        "journal_ref": "Review of Symbolic Logic, 2(4), 2009, pp. 647--683"
    },
    "0903.2016v4": {
        "url": "http://arxiv.org/abs/0903.2016v4",
        "title": "Proof of a Conjecture on the Sequence of Exceptional Numbers,\n  Classifying Cyclic Codes and APN Functions",
        "summary": "We prove a conjecture that classifies exceptional numbers. This conjecture\narises in two different ways, from cryptography and from coding theory. An odd\ninteger $t\\geq 3$ is said to be exceptional if $f(x)=x^t$ is APN (Almost\nPerfect Nonlinear) over $\\mathbb{F}_{2^n}$ for infinitely many values of $n$.\nEquivalently, $t$ is exceptional if the binary cyclic code of length $2^n-1$\nwith two zeros $\\omega, \\omega^t$ has minimum distance 5 for infinitely many\nvalues of $n$. The conjecture we prove states that every exceptional number has\nthe form $2^i+1$ or $4^i-2^i+1$.",
        "updated": "2009-09-18T09:25:49Z",
        "published": "2009-03-11T17:29:11Z",
        "authors": [
            "Fernando Hernando",
            "Gary McGuire"
        ],
        "categories": [
            "cs.IT",
            "math.AG",
            "math.IT"
        ],
        "primary_category": "cs.IT",
        "doi": "10.1016/j.jalgebra.2011.06.019",
        "journal_ref": "Journal of Algebra, Volume 343, Issue 1, October 2011, Pages 78-92"
    },
    "0903.4826v2": {
        "url": "http://arxiv.org/abs/0903.4826v2",
        "title": "New Linear Codes from Matrix-Product Codes with Polynomial Units",
        "summary": "A new construction of codes from old ones is considered, it is an extension\nof the matrix-product construction. Several linear codes that improve the\nparameters of the known ones are presented.",
        "updated": "2010-05-12T16:06:21Z",
        "published": "2009-03-27T15:30:58Z",
        "authors": [
            "Fernando Hernando",
            "Diego Ruano"
        ],
        "categories": [
            "cs.IT",
            "math.IT",
            "68P30"
        ],
        "primary_category": "cs.IT",
        "doi": "10.3934/amc.2012.6.259",
        "journal_ref": "Adv. Math. Commun. 4 (2010), no. 3, 363-367"
    },
    "0905.3108v1": {
        "url": "http://arxiv.org/abs/0905.3108v1",
        "title": "A Note on the Complexity of the Satisfiability Problem for Graded Modal\n  Logics",
        "summary": "Graded modal logic is the formal language obtained from ordinary\n(propositional) modal logic by endowing its modal operators with cardinality\nconstraints. Under the familiar possible-worlds semantics, these augmented\nmodal operators receive interpretations such as \"It is true at no fewer than 15\naccessible worlds that...\", or \"It is true at no more than 2 accessible worlds\nthat...\". We investigate the complexity of satisfiability for this language\nover some familiar classes of frames. This problem is more challenging than its\nordinary modal logic counterpart--especially in the case of transitive frames,\nwhere graded modal logic lacks the tree-model property. We obtain tight\ncomplexity bounds for the problem of determining the satisfiability of a given\ngraded modal logic formula over the classes of frames characterized by any\ncombination of reflexivity, seriality, symmetry, transitivity and the Euclidean\nproperty.",
        "updated": "2009-05-19T15:27:04Z",
        "published": "2009-05-19T15:27:04Z",
        "authors": [
            "Yevgeny Kazakov",
            "Ian Pratt-Hartmann"
        ],
        "comments": "Full proofs for paper presented at the IEEE Conference on Logic in\n  Computer Science, 2009",
        "categories": [
            "cs.LO",
            "cs.AI",
            "cs.CC",
            "F.4.1; F.2.2"
        ],
        "primary_category": "cs.LO",
        "doi": "10.1109/LICS.2009.17",
        "journal_ref": "Proceedings, 24th Annual IEEE Symposium on Logic in Computer\n  Science (LICS '09), IEEE Press, 2009, pp. 407--416"
    },
    "0911.0105v1": {
        "url": "http://arxiv.org/abs/0911.0105v1",
        "title": "Functions Definable by Numerical Set-Expressions",
        "summary": "A \"numerical set-expression\" is a term specifying a cascade of arithmetic and\nlogical operations to be performed on sets of non-negative integers. If these\noperations are confined to the usual Boolean operations together with the\nresult of lifting addition to the level of sets, we speak of \"additive\ncircuits\". If they are confined to the usual Boolean operations together with\nthe result of lifting addition and multiplication to the level of sets, we\nspeak of \"arithmetic circuits\". In this paper, we investigate the definability\nof sets and functions by means of additive and arithmetic circuits,\noccasionally augmented with additional operations.",
        "updated": "2009-10-31T23:17:49Z",
        "published": "2009-10-31T23:17:49Z",
        "authors": [
            "Ian Pratt-Hartmann",
            "Ivo D\u00fcntsch"
        ],
        "categories": [
            "cs.LO",
            "F.1.1"
        ],
        "primary_category": "cs.LO",
        "doi": "10.1093/logcom/exr050",
        "journal_ref": "Journal of Logic and Computation, 24(4), 2013, pp. 873-895"
    },
    "0911.5246v2": {
        "url": "http://arxiv.org/abs/0911.5246v2",
        "title": "Complex Algebras of Arithmetic",
        "summary": "An 'arithmetic circuit' is a labeled, acyclic directed graph specifying a\nsequence of arithmetic and logical operations to be performed on sets of\nnatural numbers. Arithmetic circuits can also be viewed as the elements of the\nsmallest subalgebra of the complex algebra of the semiring of natural numbers.\nIn the present paper, we investigate the algebraic structure of complex\nalgebras of natural numbers, and make some observations regarding the\ncomplexity of various theories of such algebras.",
        "updated": "2009-12-01T17:39:28Z",
        "published": "2009-11-27T11:43:04Z",
        "authors": [
            "Ivo D\u00fcntsch",
            "Ian Pratt-Hartmann"
        ],
        "categories": [
            "cs.LO",
            "F.1.1"
        ],
        "primary_category": "cs.LO",
        "journal_ref": "Fundamenta Informaticae, 97 (4), 2009, pp. 347-367"
    },
    "1004.3702v83": {
        "url": "http://arxiv.org/abs/1004.3702v83",
        "title": "A Polynomial time Algorithm for Hamilton Cycle with maximum Degree 3,\n  3SAT",
        "summary": "Based on the famous Rotation-Extension technique, by creating the new\nconcepts and methods: broad cycle, main segment, useful cut and insert,\ndestroying edges for a main segment, main goal Hamilton cycle, depth-first\nsearch tree, we develop a polynomial time algorithm for a famous NPC: the\nHamilton cycle problem. Thus we proved that NP=P. The key points of this paper\nare: 1) there are two ways to get a Hamilton cycle in exponential time: a full\npermutation of n vertices; or, chose n edges from all k edges, and check all\npossible combinations. The main problem is: how to avoid checking all\ncombinations of n edges from all edges. My algorithm can avoid this. Lemma 1\nand lemma 2 are very important. They are the foundation that we always can get\na good branch in the depth-first search tree and can get a series of destroying\nedges (all are bad edges) for this good branch in polynomial time. The\nextraordinary insights are: destroying edges, a tree contains each main segment\nat most one time at the same time, and dynamic combinations. The difficult part\nis to understand how to construct a main segment's series of destroying edges\nby dynamic combinations. The proof logic is: if there is at least on Hamilton\ncycle in the graph, we always can do useful cut and inserts until a Hamilton\ncycle is got. The times of useful cut and inserts are polynomial. So if at any\nstep we cannot have a useful cut and insert, this means that there are no\nHamilton cycles in the graph. In this version, I add a detailed polynomial time\nalgorithm and proof for 3SAT",
        "updated": "2024-04-03T09:07:27Z",
        "published": "2010-04-12T04:39:27Z",
        "authors": [
            "Lizhi Du"
        ],
        "comments": "22 pages. This time, I add a detailed polynomial time algorithm and\n  proof for 3SAT",
        "categories": [
            "cs.DS"
        ],
        "primary_category": "cs.DS"
    },
    "1005.1871v1": {
        "url": "http://arxiv.org/abs/1005.1871v1",
        "title": "Subfield-Subcodes of Generalized Toric codes",
        "summary": "We study subfield-subcodes of Generalized Toric (GT) codes over\n$\\mathbb{F}_{p^s}$. These are the multidimensional analogues of BCH codes,\nwhich may be seen as subfield-subcodes of generalized Reed-Solomon codes. We\nidentify polynomial generators for subfield-subcodes of GT codes which allows\nus to determine the dimensions and obtain bounds for the minimum distance. We\ngive several examples of binary and ternary subfield-subcodes of GT codes that\nare the best known codes of a given dimension and length.",
        "updated": "2010-05-11T15:56:31Z",
        "published": "2010-05-11T15:56:31Z",
        "authors": [
            "Fernando Hernando",
            "Michael E. O'Sullivan",
            "Emanuel Popovici",
            "Shraddha Srivastava"
        ],
        "comments": "Submitted to 2010 IEEE International Symposium on Information Theory\n  (ISIT 2010)",
        "categories": [
            "cs.IT",
            "math.IT"
        ],
        "primary_category": "cs.IT",
        "doi": "10.1109/ISIT.2010.5513688",
        "journal_ref": "2010 IEEE International Symposium on Information Theory (ISIT\n  2010), 1125 - 1129"
    },
    "2203.02853v2": {
        "url": "http://arxiv.org/abs/2203.02853v2",
        "title": "Spin-Dependent Graph Neural Network Potential for Magnetic Materials",
        "summary": "The development of machine learning interatomic potentials has immensely\ncontributed to the accuracy of simulations of molecules and crystals. However,\ncreating interatomic potentials for magnetic systems that account for both\nmagnetic moments and structural degrees of freedom remains a challenge. This\nwork introduces SpinGNN, a spin-dependent interatomic potential approach that\nemploys the graph neural network (GNN) to describe magnetic systems. SpinGNN\nconsists of two types of edge GNNs: Heisenberg edge GNN (HEGNN) and\nspin-distance edge GNN (SEGNN). HEGNN is tailored to capture Heisenberg-type\nspin-lattice interactions, while SEGNN accurately models multi-body and\nhigh-order spin-lattice coupling. The effectiveness of SpinGNN is demonstrated\nby its exceptional precision in fitting a high-order spin Hamiltonian and two\ncomplex spin-lattice Hamiltonians with great precision. Furthermore, it\nsuccessfully models the subtle spin-lattice coupling in BiFeO3 and performs\nlarge-scale spin-lattice dynamics simulations, predicting its antiferromagnetic\nground state, magnetic phase transition, and domain wall energy landscape with\nhigh accuracy. Our study broadens the scope of graph neural network potentials\nto magnetic systems, serving as a foundation for carrying out large-scale\nspin-lattice dynamic simulations of such systems.",
        "updated": "2023-04-20T06:14:18Z",
        "published": "2022-03-06T01:54:50Z",
        "authors": [
            "Hongyu Yu",
            "Yang Zhong",
            "Liangliang Hong",
            "Changsong Xu",
            "Wei Ren",
            "Xingao Gong",
            "Hongjun Xiang"
        ],
        "comments": "28 pages, 4 figures",
        "categories": [
            "physics.comp-ph",
            "cond-mat.dis-nn",
            "cs.LG"
        ],
        "primary_category": "physics.comp-ph",
        "doi": "10.1103/PhysRevB.109.144426",
        "journal_ref": "Physical Review B 2024"
    },
    "2203.03275v1": {
        "url": "http://arxiv.org/abs/2203.03275v1",
        "title": "Arbitrarily high-order energy-conserving methods for Hamiltonian\n  problems with quadratic holonomic constraints",
        "summary": "In this paper, we define arbitrarily high-order energy-conserving methods for\nHamiltonian systems with quadratic holonomic constraints. The derivation of the\nmethods is made within the so-called line integral framework. Numerical tests\nto illustrate the theoretical findings are presented.",
        "updated": "2022-03-07T10:48:08Z",
        "published": "2022-03-07T10:48:08Z",
        "authors": [
            "P. Amodio",
            "L. Brugnano",
            "G. Frasca-Caccia",
            "F. Iavernaro"
        ],
        "comments": "31 pages, 6 figures, 3 tables",
        "categories": [
            "math.NA",
            "cs.NA",
            "65P10, 65L80, 65L06"
        ],
        "primary_category": "math.NA",
        "doi": "10.4208/jcm.2301-m2022-0065",
        "journal_ref": "Journal of Computational Mathematics 42, No. 4 (2024) 1145-1171"
    },
    "2203.03744v2": {
        "url": "http://arxiv.org/abs/2203.03744v2",
        "title": "Identifying the Deviator",
        "summary": "A group of players are supposed to follow a prescribed profile of strategies.\nIf they follow this profile, they will reach a given target. We show that if\nthe target is not reached because some player deviates, then an outside\nobserver can identify the deviator. We also construct identification methods in\ntwo nontrivial cases.",
        "updated": "2024-04-02T02:50:04Z",
        "published": "2022-03-07T22:11:07Z",
        "authors": [
            "Noga Alon",
            "Benjamin Gunby",
            "Xiaoyu He",
            "Eran Shmaya",
            "Eilon Solan"
        ],
        "comments": "21 pages, accepted journal version",
        "categories": [
            "math.PR",
            "cs.GT",
            "econ.TH"
        ],
        "primary_category": "math.PR"
    },
    "2203.04381v1": {
        "url": "http://arxiv.org/abs/2203.04381v1",
        "title": "Formation Control of Nonlinear Multi-Agent Systems Using Three-Layer\n  Neural Networks",
        "summary": "This paper considers a leader-following formation control problem for\nheterogeneous, second-order, uncertain, input-affine, nonlinear multi-agent\nsystems modeled by a directed graph. A tunable, three-layer neural network (NN)\nis proposed with an input layer, two hidden layers, and an output layer to\napproximate an unknown nonlinearity. Unlike commonly used trial and error\nefforts to select the number of neurons in a conventional NN, in this case an\n\\textit{a priori} knowledge allows one to set up the number of neurons in each\nlayer. The NN weights tuning laws are derived using the Lyapunov theory. The\nleader-following and formation control problems are addressed by a robust\nintegral of the sign of the error (RISE) feedback and a NN-based control. The\nRISE feedback term compensates for unknown leader dynamics and the unknown,\nbounded disturbance in the agent error dynamics. The NN-based term compensates\nfor the unknown nonlinearity in the dynamics of multi-agent systems, and\nsemi-global asymptotic tracking results are rigorously proven using the\nLyapunov stability theory. The results of the paper are compared with two\nprevious results to evaluate the efficiency and performance of the proposed\nmethod.",
        "updated": "2022-03-08T20:27:32Z",
        "published": "2022-03-08T20:27:32Z",
        "authors": [
            "Kiarash Aryankia",
            "Rastko R. Selmic"
        ],
        "comments": "12 pages, 11 figures, submitted to IEEE Transactions on Neural\n  Networks and Learning Systems",
        "categories": [
            "eess.SY",
            "cs.SY"
        ],
        "primary_category": "eess.SY",
        "doi": "10.1109/TCYB.2024.3356810"
    },
    "2203.04443v3": {
        "url": "http://arxiv.org/abs/2203.04443v3",
        "title": "Estimating the Uncertainty in Emotion Class Labels with\n  Utterance-Specific Dirichlet Priors",
        "summary": "Emotion recognition is a key attribute for artificial intelligence systems\nthat need to naturally interact with humans. However, the task definition is\nstill an open problem due to the inherent ambiguity of emotions. In this paper,\na novel Bayesian training loss based on per-utterance Dirichlet prior\ndistributions is proposed for verbal emotion recognition, which models the\nuncertainty in one-hot labels created when human annotators assign the same\nutterance to different emotion classes. An additional metric is used to\nevaluate the performance by detection test utterances with high labelling\nuncertainty. This removes a major limitation that emotion classification\nsystems only consider utterances with labels where the majority of annotators\nagree on the emotion class. Furthermore, a frequentist approach is studied to\nleverage the continuous-valued \"soft\" labels obtained by averaging the one-hot\nlabels. We propose a two-branch model structure for emotion classification on a\nper-utterance basis, which achieves state-of-the-art classification results on\nthe widely used IEMOCAP dataset. Based on this, uncertainty estimation\nexperiments were performed. The best performance in terms of the area under the\nprecision-recall curve when detecting utterances with high uncertainty was\nachieved by interpolating the Bayesian training loss with the Kullback-Leibler\ndivergence training loss for the soft labels. The generality of the proposed\napproach was verified using the MSP-Podcast dataset which yielded the same\npattern of results.",
        "updated": "2022-11-17T18:09:58Z",
        "published": "2022-03-08T23:30:01Z",
        "authors": [
            "Wen Wu",
            "Chao Zhang",
            "Xixin Wu",
            "Philip C. Woodland"
        ],
        "categories": [
            "cs.CL"
        ],
        "primary_category": "cs.CL",
        "doi": "10.1109/TAFFC.2022.3221801",
        "journal_ref": "IEEE Transactions on Affective Computing ( Volume: 14, Issue: 4,\n  01 Oct.-Dec. 2023)"
    },
    "2203.04728v1": {
        "url": "http://arxiv.org/abs/2203.04728v1",
        "title": "Dynamic mode decomposition as an analysis tool for time-dependent\n  partial differential equations",
        "summary": "The time-dependent fields obtained by solving partial differential equations\nin two and more dimensions quickly overwhelm the analytical capabilities of the\nhuman brain. A meaningful insight into the temporal behaviour can be obtained\nby using scalar reductions, which, however, come with a loss of spatial detail.\nDynamic Mode Decomposition is a data-driven analysis method that solves this\nproblem by identifying oscillating spatial structures and their corresponding\nfrequencies. This paper presents the algorithm and provides a physical\ninterpretation of the results by applying the decomposition method to a series\nof increasingly complex examples.",
        "updated": "2022-03-09T14:07:45Z",
        "published": "2022-03-09T14:07:45Z",
        "authors": [
            "Miha Rot",
            "Martin Horvat",
            "Gregor Kosec"
        ],
        "comments": "6 pages, 8 figures",
        "categories": [
            "math.NA",
            "cs.NA",
            "math.DS",
            "physics.data-an"
        ],
        "primary_category": "math.NA",
        "doi": "10.23919/SpliTech55088.2022.9854243"
    },
    "2203.05314v2": {
        "url": "http://arxiv.org/abs/2203.05314v2",
        "title": "SoK: On the Semantic AI Security in Autonomous Driving",
        "summary": "Autonomous Driving (AD) systems rely on AI components to make safety and\ncorrect driving decisions. Unfortunately, today's AI algorithms are known to be\ngenerally vulnerable to adversarial attacks. However, for such AI\ncomponent-level vulnerabilities to be semantically impactful at the system\nlevel, it needs to address non-trivial semantic gaps both (1) from the\nsystem-level attack input spaces to those at AI component level, and (2) from\nAI component-level attack impacts to those at the system level. In this paper,\nwe define such research space as semantic AI security as opposed to generic AI\nsecurity. Over the past 5 years, increasingly more research works are performed\nto tackle such semantic AI security challenges in AD context, which has started\nto show an exponential growth trend.\n  In this paper, we perform the first systematization of knowledge of such\ngrowing semantic AD AI security research space. In total, we collect and\nanalyze 53 such papers, and systematically taxonomize them based on research\naspects critical for the security field. We summarize 6 most substantial\nscientific gaps observed based on quantitative comparisons both vertically\namong existing AD AI security works and horizontally with security works from\nclosely-related domains. With these, we are able to provide insights and\npotential future directions not only at the design level, but also at the\nresearch goal, methodology, and community levels. To address the most critical\nscientific methodology-level gap, we take the initiative to develop an\nopen-source, uniform, and extensible system-driven evaluation platform, named\nPASS, for the semantic AD AI security research community. We also use our\nimplemented platform prototype to showcase the capabilities and benefits of\nsuch a platform using representative semantic AD AI attacks.",
        "updated": "2024-04-26T04:16:18Z",
        "published": "2022-03-10T12:00:34Z",
        "authors": [
            "Junjie Shen",
            "Ningfei Wang",
            "Ziwen Wan",
            "Yunpeng Luo",
            "Takami Sato",
            "Zhisheng Hu",
            "Xinyang Zhang",
            "Shengjian Guo",
            "Zhenyu Zhong",
            "Kang Li",
            "Ziming Zhao",
            "Chunming Qiao",
            "Qi Alfred Chen"
        ],
        "comments": "Project website: https://sites.google.com/view/cav-sec/pass",
        "categories": [
            "cs.CR",
            "cs.AI",
            "cs.RO"
        ],
        "primary_category": "cs.CR"
    },
    "2203.06361v3": {
        "url": "http://arxiv.org/abs/2203.06361v3",
        "title": "Preserving Lagrangian structure in data-driven reduced-order modeling of\n  large-scale dynamical systems",
        "summary": "This work presents a nonintrusive physics-preserving method to learn\nreduced-order models (ROMs) of Lagrangian systems, which includes nonlinear\nwave equations. Existing intrusive projection-based model reduction approaches\nconstruct structure-preserving Lagrangian ROMs by projecting the Euler-Lagrange\nequations of the full-order model (FOM) onto a linear subspace. This Galerkin\nprojection step requires complete knowledge about the Lagrangian operators in\nthe FOM and full access to manipulate the computer code. In contrast, the\nproposed Lagrangian operator inference approach embeds the mechanics into the\noperator inference framework to develop a data-driven model reduction method\nthat preserves the underlying Lagrangian structure. The proposed approach\nexploits knowledge of the governing equations (but not their discretization) to\ndefine the form and parametrization of a Lagrangian ROM which can then be\nlearned from projected snapshot data. The method does not require access to FOM\noperators or computer code. The numerical results demonstrate Lagrangian\noperator inference on an Euler-Bernoulli beam model, the sine-Gordon\n(nonlinear) wave equation, and a large-scale discretization of a soft robot\nfishtail with 779,232 degrees of freedom. The learned Lagrangian ROMs\ngeneralize well, as they can accurately predict the physical solutions both far\noutside the training time interval, as well as for unseen initial conditions.",
        "updated": "2024-04-03T19:51:50Z",
        "published": "2022-03-12T06:56:24Z",
        "authors": [
            "Harsh Sharma",
            "Boris Kramer"
        ],
        "categories": [
            "math.NA",
            "cs.NA"
        ],
        "primary_category": "math.NA"
    },
    "2203.06630v2": {
        "url": "http://arxiv.org/abs/2203.06630v2",
        "title": "Maximum Cut on Interval Graphs of Interval Count Two is NP-complete",
        "summary": "An interval graph has interval count $\\ell$ if it has an interval model,\nwhere among every $\\ell+1$ intervals there are two that have the same length.\nMaximum Cut on interval graphs has been found to be NP-complete recently by\nAdhikary et al. while deciding its complexity on unit interval graphs (graphs\nwith interval count one) remains a longstanding open problem. More recently, de\nFigueiredo et al. have made an advancement by showing that the problem remains\nNP-complete on interval graphs of interval count four. In this paper, we show\nthat Maximum Cut is NP-complete even on interval graphs of interval count two.",
        "updated": "2024-04-24T09:45:19Z",
        "published": "2022-03-13T11:31:57Z",
        "authors": [
            "Alexey Barsukov",
            "Bodhayan Roy"
        ],
        "categories": [
            "cs.CC",
            "math.CO",
            "35A01, 65L10, 65L12, 65L20, 65L70"
        ],
        "primary_category": "cs.CC"
    },
    "2203.07976v5": {
        "url": "http://arxiv.org/abs/2203.07976v5",
        "title": "On the Pitfalls of Batch Normalization for End-to-End Video Learning: A\n  Study on Surgical Workflow Analysis",
        "summary": "Batch Normalization's (BN) unique property of depending on other samples in a\nbatch is known to cause problems in several tasks, including sequence modeling.\nYet, BN-related issues are hardly studied for long video understanding, despite\nthe ubiquitous use of BN in CNNs (Convolutional Neural Networks) for feature\nextraction. Especially in surgical workflow analysis, where the lack of\npretrained feature extractors has led to complex, multi-stage training\npipelines, limited awareness of BN issues may have hidden the benefits of\ntraining CNNs and temporal models end to end. In this paper, we analyze\npitfalls of BN in video learning, including issues specific to online tasks\nsuch as a 'cheating' effect in anticipation. We observe that BN's properties\ncreate major obstacles for end-to-end learning. However, using BN-free\nbackbones, even simple CNN-LSTMs beat the state of the art\n{\\color{\\colorrevtwo}on three surgical workflow benchmarks} by utilizing\nadequate end-to-end training strategies which maximize temporal context. We\nconclude that awareness of BN's pitfalls is crucial for effective end-to-end\nlearning in surgical tasks. By reproducing results on natural-video datasets,\nwe hope our insights will benefit other areas of video learning as well. Code\nis available at: \\url{https://gitlab.com/nct_tso_public/pitfalls_bn}",
        "updated": "2024-04-19T14:13:26Z",
        "published": "2022-03-15T15:05:40Z",
        "authors": [
            "Dominik Rivoir",
            "Isabel Funke",
            "Stefanie Speidel"
        ],
        "comments": "Accepted at Medical Image Analysis (MedIA). Publication link:\n  https://www.sciencedirect.com/science/article/pii/S1361841524000513",
        "categories": [
            "cs.CV"
        ],
        "primary_category": "cs.CV",
        "doi": "10.1016/j.media.2024.103126"
    },
    "2212.07078v2": {
        "url": "http://arxiv.org/abs/2212.07078v2",
        "title": "A Predictive Operation Controller for an Electro-Thermal Microgrid\n  Utilizing Variable Flow Temperatures",
        "summary": "We propose an optimal operation control strategy for an electro-thermal\nmicrogrid. Compared to existing work, our approach increases flexibility by\noperating the thermal network with variable flow temperatures and in that way\nexplicitly exploits its inherent storage capacities. To this end, the microgrid\nis represented by a multi-layer network composed of an electrical and a thermal\nlayer. We show that the system behavior can be represented by a discrete-time\nstate model derived from DC power flow approximations and 1d incompressible\nEuler equations. Both layers are interconnected via heat pumps. By combining\nthis model with desired operating objectives and constraints, we obtain a\nconstrained convex optimization problem. This is used to derive a model\npredictive control scheme for the optimal operation of electro-thermal\nmicrogrids. The performance of the proposed operation control algorithm is\ndemonstrated in a numerical case study.",
        "updated": "2024-04-02T10:02:44Z",
        "published": "2022-12-14T08:09:02Z",
        "authors": [
            "Max Rose",
            "Christian A. Hans",
            "Johannes Schiffer"
        ],
        "categories": [
            "eess.SY",
            "cs.SY"
        ],
        "primary_category": "eess.SY",
        "doi": "10.1016/j.ifacol.2023.10.195",
        "journal_ref": "IFAC-PapersOnLine, Volume 56, Issue 2, 2023, Pages 5444-5450"
    },
    "2212.07316v6": {
        "url": "http://arxiv.org/abs/2212.07316v6",
        "title": "Understanding Users' Interaction with Login Notifications",
        "summary": "Login notifications intend to inform users about sign-ins and help them\nprotect their accounts from unauthorized access. Notifications are usually sent\nif a login deviates from previous ones, potentially indicating malicious\nactivity. They contain information like the location, date, time, and device\nused to sign in. Users are challenged to verify whether they recognize the\nlogin (because it was them or someone they know) or to protect their account\nfrom unwanted access. In a user study, we explore users' comprehension,\nreactions, and expectations of login notifications. We utilize two treatments\nto measure users' behavior in response to notifications sent for a login they\ninitiated or based on a malicious actor relying on statistical sign-in\ninformation. We find that users identify legitimate logins but need more\nsupport to halt malicious sign-ins. We discuss the identified problems and give\nrecommendations for service providers to ensure usable and secure logins for\neveryone.",
        "updated": "2024-03-31T11:50:18Z",
        "published": "2022-12-14T16:23:23Z",
        "authors": [
            "Philipp Markert",
            "Leona Lassak",
            "Maximilian Golla",
            "Markus D\u00fcrmuth"
        ],
        "comments": "12+5 pages, 7 figures, 1+5 tables",
        "categories": [
            "cs.HC"
        ],
        "primary_category": "cs.HC",
        "doi": "10.1145/3613904.3642823",
        "journal_ref": "ACM Conference on Human Factors in Computing Systems 2024 (CHI\n  '24)"
    },
    "2212.07591v2": {
        "url": "http://arxiv.org/abs/2212.07591v2",
        "title": "Dissecting Distribution Inference",
        "summary": "A distribution inference attack aims to infer statistical properties of data\nused to train machine learning models. These attacks are sometimes surprisingly\npotent, but the factors that impact distribution inference risk are not well\nunderstood and demonstrated attacks often rely on strong and unrealistic\nassumptions such as full knowledge of training environments even in supposedly\nblack-box threat scenarios. To improve understanding of distribution inference\nrisks, we develop a new black-box attack that even outperforms the best known\nwhite-box attack in most settings. Using this new attack, we evaluate\ndistribution inference risk while relaxing a variety of assumptions about the\nadversary's knowledge under black-box access, like known model architectures\nand label-only access. Finally, we evaluate the effectiveness of previously\nproposed defenses and introduce new defenses. We find that although noise-based\ndefenses appear to be ineffective, a simple re-sampling defense can be highly\neffective. Code is available at\nhttps://github.com/iamgroot42/dissecting_distribution_inference",
        "updated": "2024-04-05T18:43:10Z",
        "published": "2022-12-15T02:43:51Z",
        "authors": [
            "Anshuman Suri",
            "Yifu Lu",
            "Yanjin Chen",
            "David Evans"
        ],
        "comments": "Accepted at SaTML 2023 (updated Yifu's email address)",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.CR"
        ],
        "primary_category": "cs.LG"
    },
    "2212.07737v2": {
        "url": "http://arxiv.org/abs/2212.07737v2",
        "title": "Deep learning-based reduced-order methods for fast transient dynamics",
        "summary": "In recent years, large-scale numerical simulations played an essential role\nin estimating the effects of explosion events in urban environments, for the\npurpose of ensuring the security and safety of cities. Such simulations are\ncomputationally expensive and, often, the time taken for one single computation\nis large and does not permit parametric studies. The aim of this work is\ntherefore to facilitate real-time and multi-query calculations by employing a\nnon-intrusive Reduced Order Method (ROM). We propose a deep learning-based (DL)\nROM scheme able to deal with fast transient dynamics. In the case of blast\nwaves, the parametrised PDEs are time-dependent and non-linear. For such\nproblems, the Proper Orthogonal Decomposition (POD), which relies on a linear\nsuperposition of modes, cannot approximate the solutions efficiently. The\npiecewise POD-DL scheme developed here is a local ROM based on time-domain\npartitioning and a first dimensionality reduction obtained through the POD.\nAutoencoders are used as a second and non-linear dimensionality reduction. The\nlatent space obtained is then reconstructed from the time and parameter space\nthrough deep forward neural networks. The proposed scheme is applied to an\nexample consisting of a blast wave propagating in air and impacting on the\noutside of a building. The efficiency of the deep learning-based ROM in\napproximating the time-dependent pressure field is shown.",
        "updated": "2024-04-11T10:00:16Z",
        "published": "2022-12-15T11:38:15Z",
        "authors": [
            "Martina Cracco",
            "Giovanni Stabile",
            "Andrea Lario",
            "Armin Sheidani",
            "Martin Larcher",
            "Folco Casadei",
            "Georgios Valsamos",
            "Gianluigi Rozza"
        ],
        "categories": [
            "math.NA",
            "cs.NA"
        ],
        "primary_category": "math.NA"
    },
    "2212.07880v2": {
        "url": "http://arxiv.org/abs/2212.07880v2",
        "title": "Twin-width of random graphs",
        "summary": "We investigate the twin-width of the Erd\\H{o}s-R\\'enyi random graph $G(n,p)$.\nWe unveil a surprising behavior of this parameter by showing the existence of a\nconstant $p^*\\approx 0.4$ such that with high probability, when $p^*\\le p\\le\n1-p^*$, the twin-width is asymptotically $2p(1-p)n$, whereas, when $0<p<p^*$ or\n$1>p>1-p^*$, the twin-width is significantly higher than $2p(1-p)n$. In\naddition, we show that the twin-width of $G(n,1/2)$ is concentrated around $n/2\n- \\sqrt{3n \\log n}/2$ within an interval of length $o(\\sqrt{n\\log n})$. For the\nsparse random graph, we show that with high probability, the twin-width of\n$G(n,p)$ is $\\Theta(n\\sqrt{p})$ when $(726\\ln n)/n\\leq p\\leq1/2$.",
        "updated": "2024-04-16T04:34:51Z",
        "published": "2022-12-15T15:04:40Z",
        "authors": [
            "Jungho Ahn",
            "Debsoumya Chakraborti",
            "Kevin Hendrey",
            "Donggyu Kim",
            "Sang-il Oum"
        ],
        "comments": "37 pages, 3 figures",
        "categories": [
            "math.CO",
            "cs.DM",
            "05C35"
        ],
        "primary_category": "math.CO"
    },
    "2212.07982v2": {
        "url": "http://arxiv.org/abs/2212.07982v2",
        "title": "A high-accuracy framework for phase-field fracture interface\n  reconstructions with application to Stokes fluid-filled fracture surrounded\n  by an elastic medium",
        "summary": "This work considers a Stokes flow in a deformable fracture interacting with a\nlinear elastic medium. To this end, we employ a phase-field model to\napproximate the crack dynamics. Phase-field methods belong to\ninterface-capturing approaches in which the interface is only given by a\nsmeared zone. For multi-domain problems, the accuracy of the coupling\nconditions is, however, of utmost importance. Here, interface-tracking methods\nare preferred, since the interface is resolved on mesh edges up to\ndiscretization errors, but it does not depend on the length scale parameter of\nsome smeared zone. The key objective of this work is to construct a robust\nframework that computes first a crack path via the phase-field method\n(interface-capturing) and then does an interface-tracking reconstruction. We\nthen discuss several approaches to reconstruct the Eulerian description of the\nopen crack domain. This includes unfitted approaches where a level-set of the\ncrack interface is constructed and an approach where the geometry is re-meshed.\nUsing this reconstructed domain, we can compute the fluid-structure interaction\nproblem between the fluid in the crack and the interacting solid. With the\nexplicit mesh reconstruction of the two domains, we can then use an\ninterface-tracking Arbitrary-Lagrangian-Eulerian (ALE) discretisation approach\nfor the resulting fluid-structure interaction (FSI) problem. Our algorithmic\nprocedure is realised in one final numerical algorithm and one implementation.\nWe substantiate our approach using several numerical examples based on\nSneddon's benchmark and corresponding extensions to Stokes fluid-filled\nregimes.",
        "updated": "2023-05-19T10:41:13Z",
        "published": "2022-12-15T17:26:48Z",
        "authors": [
            "Henry von Wahl",
            "Thomas Wick"
        ],
        "categories": [
            "math.NA",
            "cs.NA"
        ],
        "primary_category": "math.NA",
        "doi": "10.1016/j.cma.2023.116202",
        "journal_ref": "Computer Methods in Applied Mechanics and Engineering, 415:116202,\n  2023"
    },
    "2212.08234v1": {
        "url": "http://arxiv.org/abs/2212.08234v1",
        "title": "Innovation-Based Remote State Estimation Secrecy with no Acknowledgments",
        "summary": "Secrecy encoding for remote state estimation in the presence of adversarial\neavesdroppers is a well studied problem. Typical existing secrecy encoding\nschemes rely on the transmitter's knowledge of the remote estimator's current\nperformance. This performance measure is often shared via packet receipt\nacknowledgments. However, in practical situations the acknowledgment channel\nmay be susceptible to interference from an active adversary, resulting in the\nsecrecy encoding scheme failing. Aiming to achieve a reliable state estimate\nfor a legitimate estimator while ensuring secrecy, we propose a secrecy\nencoding scheme without the need for packet receipt acknowledgments. Our\nencoding scheme uses a pre-arranged scheduling sequence established at the\ntransmitter and legitimate receiver. We transmit a packet containing either the\nstate measurement or encoded information for the legitimate user. The encoding\nmakes the packet appear to be the state but is designed to damage an\neavesdropper's estimate. The pre-arranged scheduling sequence and encoding is\nchosen psuedo-random. We analyze the performance of our encoding scheme against\na class of eavesdropper, and show conditions to force the eavesdropper to have\nan unbounded estimation performance. Further, we provide a numerical\nillustration and apply our encoding scheme to an application in power systems.",
        "updated": "2022-12-16T01:52:02Z",
        "published": "2022-12-16T01:52:02Z",
        "authors": [
            "Justin M. Kennedy",
            "Jason J. Ford",
            "Daniel E. Quevedo",
            "Falko Dressler"
        ],
        "comments": "21 pages, 5 figures",
        "categories": [
            "eess.SY",
            "cs.IT",
            "cs.SY",
            "math.IT"
        ],
        "primary_category": "eess.SY",
        "doi": "10.1109/TAC.2024.3385315",
        "journal_ref": "IEEE Transactions on Automatic Control, 2024"
    },
    "2212.08546v3": {
        "url": "http://arxiv.org/abs/2212.08546v3",
        "title": "Estimating truncation effects of quantum bosonic systems using sampling\n  algorithms",
        "summary": "To simulate bosons on a qubit- or qudit-based quantum computer, one has to\nregularize the theory by truncating infinite-dimensional local Hilbert spaces\nto finite dimensions. In the search for practical quantum applications, it is\nimportant to know how big the truncation errors can be. In general, it is not\neasy to estimate errors unless we have a good quantum computer. In this paper,\nwe show that traditional sampling methods on classical devices, specifically\nMarkov Chain Monte Carlo, can address this issue for a rather generic class of\nbosonic systems with a reasonable amount of computational resources available\ntoday. As a demonstration, we apply this idea to the scalar field theory on a\ntwo-dimensional lattice, with a size that goes beyond what is achievable using\nexact diagonalization methods. This method can be used to estimate the\nresources needed for realistic quantum simulations of bosonic theories, and\nalso, to check the validity of the results of the corresponding quantum\nsimulations.",
        "updated": "2024-04-01T23:15:00Z",
        "published": "2022-12-16T15:55:16Z",
        "authors": [
            "Masanori Hanada",
            "Junyu Liu",
            "Enrico Rinaldi",
            "Masaki Tezuka"
        ],
        "comments": "22 pages, 4 figures",
        "categories": [
            "quant-ph",
            "cs.AI",
            "cs.LG",
            "hep-lat",
            "hep-th"
        ],
        "primary_category": "quant-ph",
        "doi": "10.1088/2632-2153/ad035c",
        "journal_ref": "Mach. Learn.: Sci. Technol. 4 045021, 2023"
    },
    "2212.08709v3": {
        "url": "http://arxiv.org/abs/2212.08709v3",
        "title": "Structural Complexities of Matching Mechanisms",
        "summary": "We study various novel complexity measures for two-sided matching mechanisms,\napplied to the two canonical strategyproof matching mechanisms, Deferred\nAcceptance (DA) and Top Trading Cycles (TTC). Our metrics are designed to\ncapture the complexity of various structural (rather than computational)\nconcerns, in particular ones of recent interest within economics. We consider a\nunified, flexible approach to formalizing our questions: Define a protocol or\ndata structure performing some task, and bound the number of bits that it\nrequires. Our main results apply this approach to four questions of general\ninterest; for mechanisms matching applicants to institutions, our questions\nare:\n  (1) How can one applicant affect the outcome matching?\n  (2) How can one applicant affect another applicant's set of options?\n  (3) How can the outcome matching be represented / communicated?\n  (4) How can the outcome matching be verified?\n  Holistically, our results show that TTC is more complex than DA, formalizing\nprevious intuitions that DA has a simpler structure than TTC. For question (2),\nour result gives a new combinatorial characterization of which institutions are\nremoved from each applicant's set of options when a new applicant is added in\nDA; this characterization may be of independent interest. For question (3), our\nresult gives new tight lower bounds proving that the relationship between the\nmatching and the priorities is more complex in TTC than in DA. We nonetheless\nshowcase that this higher complexity of TTC is nuanced: By constructing new\ntight lower-bound instances and new verification protocols, we prove that DA\nand TTC are comparable in complexity under questions (1) and (4). This more\nprecisely delineates the ways in which TTC is more complex than DA, and\nemphasizes that diverse considerations must factor into gauging the complexity\nof matching mechanisms.",
        "updated": "2024-03-30T22:17:26Z",
        "published": "2022-12-16T20:53:30Z",
        "authors": [
            "Yannai A. Gonczarowski",
            "Clayton Thomas"
        ],
        "categories": [
            "cs.GT",
            "cs.CC",
            "econ.TH"
        ],
        "primary_category": "cs.GT"
    },
    "2212.08731v3": {
        "url": "http://arxiv.org/abs/2212.08731v3",
        "title": "Multi-person 3D pose estimation from unlabelled data",
        "summary": "Its numerous applications make multi-human 3D pose estimation a remarkably\nimpactful area of research. Nevertheless, assuming a multiple-view system\ncomposed of several regular RGB cameras, 3D multi-pose estimation presents\nseveral challenges. First of all, each person must be uniquely identified in\nthe different views to separate the 2D information provided by the cameras.\nSecondly, the 3D pose estimation process from the multi-view 2D information of\neach person must be robust against noise and potential occlusions in the\nscenario. In this work, we address these two challenges with the help of deep\nlearning. Specifically, we present a model based on Graph Neural Networks\ncapable of predicting the cross-view correspondence of the people in the\nscenario along with a Multilayer Perceptron that takes the 2D points to yield\nthe 3D poses of each person. These two models are trained in a self-supervised\nmanner, thus avoiding the need for large datasets with 3D annotations.",
        "updated": "2024-04-09T17:52:49Z",
        "published": "2022-12-16T22:03:37Z",
        "authors": [
            "Daniel Rodriguez-Criado",
            "Pilar Bachiller",
            "George Vogiatzis",
            "Luis J. Manso"
        ],
        "categories": [
            "cs.CV",
            "cs.AI"
        ],
        "primary_category": "cs.CV",
        "doi": "10.1007/s00138-024-01530-6",
        "journal_ref": "Machine Vision and Applications 35, 46 (2024)"
    },
    "2304.11754v2": {
        "url": "http://arxiv.org/abs/2304.11754v2",
        "title": "Silent Abandonment in Contact Centers: Estimating Customer Patience from\n  Uncertain Data",
        "summary": "In the quest to improve services, companies offer customers the opportunity\nto interact with agents through contact centers, where the communication is\nmainly text-based. This has become one of the favorite channels of\ncommunication with companies in recent years. However, contact centers face\noperational challenges, since the measurement of common proxies for customer\nexperience, such as knowledge of whether customers have abandoned the queue and\ntheir willingness to wait for service (patience), are subject to information\nuncertainty. We focus this research on the impact of a main source of such\nuncertainty: silent abandonment by customers. These customers leave the system\nwhile waiting for a reply to their inquiry, but give no indication of doing so,\nsuch as closing the mobile app of the interaction. As a result, the system is\nunaware that they have left and waste agent time and capacity until this fact\nis realized. In this paper, we show that 30%-67% of the abandoning customers\nabandon the system silently, and that such customer behavior reduces system\nefficiency by 5%-15%. To do so, we develop methodologies to identify\nsilent-abandonment customers in two types of contact centers: chat and\nmessaging systems. We first use text analysis and an SVM model to estimate the\nactual abandonment level. We then use a parametric estimator and develop an\nexpectation-maximization algorithm to estimate customer patience accurately, as\ncustomer patience is an important parameter for fitting queueing models to the\ndata. We show how accounting for silent abandonment in a queueing model\nimproves dramatically the estimation accuracy of key measures of performance.\nFinally, we suggest strategies to operationally cope with the phenomenon of\nsilent abandonment.",
        "updated": "2024-04-07T16:02:11Z",
        "published": "2023-04-23T21:43:03Z",
        "authors": [
            "Antonio Castellanos",
            "Galit B. Yom-Tov",
            "Yair Goldberg"
        ],
        "comments": "V2",
        "categories": [
            "cs.SI",
            "stat.ML"
        ],
        "primary_category": "cs.SI"
    },
    "2304.11766v4": {
        "url": "http://arxiv.org/abs/2304.11766v4",
        "title": "NAIST-SIC-Aligned: an Aligned English-Japanese Simultaneous\n  Interpretation Corpus",
        "summary": "It remains a question that how simultaneous interpretation (SI) data affects\nsimultaneous machine translation (SiMT). Research has been limited due to the\nlack of a large-scale training corpus. In this work, we aim to fill in the gap\nby introducing NAIST-SIC-Aligned, which is an automatically-aligned parallel\nEnglish-Japanese SI dataset. Starting with a non-aligned corpus NAIST-SIC, we\npropose a two-stage alignment approach to make the corpus parallel and thus\nsuitable for model training. The first stage is coarse alignment where we\nperform a many-to-many mapping between source and target sentences, and the\nsecond stage is fine-grained alignment where we perform intra- and\ninter-sentence filtering to improve the quality of aligned pairs. To ensure the\nquality of the corpus, each step has been validated either quantitatively or\nqualitatively. This is the first open-sourced large-scale parallel SI dataset\nin the literature. We also manually curated a small test set for evaluation\npurposes. Our results show that models trained with SI data lead to significant\nimprovement in translation quality and latency over baselines. We hope our work\nadvances research on SI corpora construction and SiMT. Our data can be found at\nhttps://github.com/mingzi151/AHC-SI.",
        "updated": "2024-04-01T01:07:54Z",
        "published": "2023-04-23T23:03:58Z",
        "authors": [
            "Jinming Zhao",
            "Yuka Ko",
            "Kosuke Doi",
            "Ryo Fukuda",
            "Katsuhito Sudoh",
            "Satoshi Nakamura"
        ],
        "comments": "LREC-Coling 2024",
        "categories": [
            "cs.CL"
        ],
        "primary_category": "cs.CL"
    },
    "2304.11872v2": {
        "url": "http://arxiv.org/abs/2304.11872v2",
        "title": "Generation-driven Contrastive Self-training for Zero-shot Text\n  Classification with Instruction-following LLM",
        "summary": "The remarkable performance of large language models (LLMs) in zero-shot\nlanguage understanding has garnered significant attention. However, employing\nLLMs for large-scale inference or domain-specific fine-tuning requires immense\ncomputational resources due to their substantial model size. To overcome these\nlimitations, we introduce a novel method, namely GenCo, which leverages the\nstrong generative power of LLMs to assist in training a smaller and more\nadaptable language model. In our method, an LLM plays an important role in the\nself-training loop of a smaller model in two important ways. Firstly, the LLM\nis used to augment each input instance with a variety of possible\ncontinuations, enriching its semantic context for better understanding.\nSecondly, it helps crafting additional high-quality training pairs, by\nrewriting input texts conditioned on predicted labels. This ensures the\ngenerated texts are highly relevant to the predicted labels, alleviating the\nprediction error during pseudo-labeling, while reducing the dependency on large\nvolumes of unlabeled text. In our experiments, GenCo outperforms previous\nstate-of-the-art methods when only limited ($<5\\%$ of original) in-domain text\ndata is available. Notably, our approach surpasses the performance of Alpaca-7B\nwith human prompts, highlighting the potential of leveraging LLM for\nself-training.",
        "updated": "2024-04-15T02:40:54Z",
        "published": "2023-04-24T07:35:38Z",
        "authors": [
            "Ruohong Zhang",
            "Yau-Shian Wang",
            "Yiming Yang"
        ],
        "categories": [
            "cs.CL",
            "cs.AI"
        ],
        "primary_category": "cs.CL"
    },
    "2304.12015v2": {
        "url": "http://arxiv.org/abs/2304.12015v2",
        "title": "ITER: Iterative Neural Repair for Multi-Location Patches",
        "summary": "Automated program repair (APR) has achieved promising results, especially\nusing neural networks. Yet, the overwhelming majority of patches produced by\nAPR tools are confined to one single location. When looking at the patches\nproduced with neural repair, most of them fail to compile, while a few\nuncompilable ones go in the right direction. In both cases, the fundamental\nproblem is to ignore the potential of partial patches. In this paper, we\npropose an iterative program repair paradigm called ITER founded on the concept\nof improving partial patches until they become plausible and correct. First,\nITER iteratively improves partial single-location patches by fixing compilation\nerrors and further refining the previously generated code. Second, ITER\niteratively improves partial patches to construct multi-location patches, with\nfault localization re-execution. ITER is implemented for Java based on\nbattle-proven deep neural networks and code representation. ITER is evaluated\non 476 bugs from 10 open-source projects in Defects4J 2.0. ITER succeeds in\nrepairing 15.5% of them, including 9 uniquely repaired multi-location bugs.",
        "updated": "2024-04-23T19:49:42Z",
        "published": "2023-04-24T11:32:02Z",
        "authors": [
            "He Ye",
            "Martin Monperrus"
        ],
        "categories": [
            "cs.SE"
        ],
        "primary_category": "cs.SE",
        "journal_ref": "Proceedings of International Conference on Software Engineering,\n  2024"
    },
    "2304.12212v2": {
        "url": "http://arxiv.org/abs/2304.12212v2",
        "title": "AeonG: An Efficient Built-in Temporal Support in Graph Databases",
        "summary": "Real world graphs are often dynamic and evolve over time. It is crucial for\nstoring and querying graph evolution in graph databases. However, existing\nworks either suffer from high storage overhead or lack efficient temporal query\nsupport, or both. In this paper, we propose AeonG, a new graph database with\nbuilt-in temporal support. AeonG is based on a novel temporal graph model. To\nfit this model, we design a storage engine and a query engine. Our storage\nengine is hybrid, with one current storage to manage the most recent versions\nof graph objects, and another historical storage to manage the previous\nversions of graph objects. This separation makes the performance degradation of\nquerying the most recent graph object versions as slight as possible. To reduce\nthe historical storage overhead, we propose a novel anchor+delta strategy, in\nwhich we periodically create a complete version (namely anchor) of a graph\nobject, and maintain every change (namely delta) between two adjacent anchors\nof the same object. To boost temporal query processing, we propose an\nanchor-based version retrieval technique in the query engine to skip\nunnecessary historical version traversals. Extensive experiments are conducted\non both real and synthetic datasets. The results show that AeonG achieves up to\n5.73X lower storage consumption and 2.57X lower temporal query latency against\nstate-of-the-art approaches, while introducing only 9.74% performance\ndegradation for supporting temporal features",
        "updated": "2024-04-01T05:29:49Z",
        "published": "2023-04-24T15:51:01Z",
        "authors": [
            "Jiamin Hou",
            "Zhanhao Zhao",
            "Zhouyu Wang",
            "Wei Lu",
            "Guodong Jin",
            "Dong Wen",
            "Xiaoyong Du"
        ],
        "comments": "VLDB 2024",
        "categories": [
            "cs.DB"
        ],
        "primary_category": "cs.DB"
    },
    "2304.12306v3": {
        "url": "http://arxiv.org/abs/2304.12306v3",
        "title": "Segment Anything in Medical Images",
        "summary": "Medical image segmentation is a critical component in clinical practice,\nfacilitating accurate diagnosis, treatment planning, and disease monitoring.\nHowever, existing methods, often tailored to specific modalities or disease\ntypes, lack generalizability across the diverse spectrum of medical image\nsegmentation tasks. Here we present MedSAM, a foundation model designed for\nbridging this gap by enabling universal medical image segmentation. The model\nis developed on a large-scale medical image dataset with 1,570,263 image-mask\npairs, covering 10 imaging modalities and over 30 cancer types. We conduct a\ncomprehensive evaluation on 86 internal validation tasks and 60 external\nvalidation tasks, demonstrating better accuracy and robustness than\nmodality-wise specialist models. By delivering accurate and efficient\nsegmentation across a wide spectrum of tasks, MedSAM holds significant\npotential to expedite the evolution of diagnostic tools and the personalization\nof treatment plans.",
        "updated": "2024-04-01T16:18:16Z",
        "published": "2023-04-24T17:56:12Z",
        "authors": [
            "Jun Ma",
            "Yuting He",
            "Feifei Li",
            "Lin Han",
            "Chenyu You",
            "Bo Wang"
        ],
        "categories": [
            "eess.IV",
            "cs.CV"
        ],
        "primary_category": "eess.IV",
        "doi": "10.1038/s41467-024-44824-z",
        "journal_ref": "Nature Communications 15, 654 (2024)"
    },
    "2304.12308v5": {
        "url": "http://arxiv.org/abs/2304.12308v5",
        "title": "Segment Anything in 3D with Radiance Fields",
        "summary": "The Segment Anything Model (SAM) emerges as a powerful vision foundation\nmodel to generate high-quality 2D segmentation results. This paper aims to\ngeneralize SAM to segment 3D objects. Rather than replicating the data\nacquisition and annotation procedure which is costly in 3D, we design an\nefficient solution, leveraging the radiance field as a cheap and off-the-shelf\nprior that connects multi-view 2D images to the 3D space. We refer to the\nproposed solution as SA3D, short for Segment Anything in 3D. With SA3D, the\nuser is only required to provide a 2D segmentation prompt (e.g., rough points)\nfor the target object in a single view, which is used to generate its\ncorresponding 2D mask with SAM. Next, SA3D alternately performs mask inverse\nrendering and cross-view self-prompting across various views to iteratively\nrefine the 3D mask of the target object. For one view, mask inverse rendering\nprojects the 2D mask obtained by SAM into the 3D space with guidance of the\ndensity distribution learned by the radiance field for 3D mask refinement;\nThen, cross-view self-prompting extracts reliable prompts automatically as the\ninput to SAM from the rendered 2D mask of the inaccurate 3D mask for a new\nview. We show in experiments that SA3D adapts to various scenes and achieves 3D\nsegmentation within seconds. Our research reveals a potential methodology to\nlift the ability of a 2D segmentation model to 3D. Our code is available at\nhttps://github.com/Jumpat/SegmentAnythingin3D.",
        "updated": "2024-04-16T01:52:00Z",
        "published": "2023-04-24T17:57:15Z",
        "authors": [
            "Jiazhong Cen",
            "Jiemin Fang",
            "Zanwei Zhou",
            "Chen Yang",
            "Lingxi Xie",
            "Xiaopeng Zhang",
            "Wei Shen",
            "Qi Tian"
        ],
        "comments": "Extension version of SA3D (NeurIPS 2023). Project page:\n  https://jumpat.github.io/SA3D/",
        "categories": [
            "cs.CV"
        ],
        "primary_category": "cs.CV"
    },
    "2304.12310v3": {
        "url": "http://arxiv.org/abs/2304.12310v3",
        "title": "Fully Sparse Fusion for 3D Object Detection",
        "summary": "Currently prevalent multimodal 3D detection methods are built upon\nLiDAR-based detectors that usually use dense Bird's-Eye-View (BEV) feature\nmaps. However, the cost of such BEV feature maps is quadratic to the detection\nrange, making it not suitable for long-range detection. Fully sparse\narchitecture is gaining attention as they are highly efficient in long-range\nperception. In this paper, we study how to effectively leverage image modality\nin the emerging fully sparse architecture. Particularly, utilizing instance\nqueries, our framework integrates the well-studied 2D instance segmentation\ninto the LiDAR side, which is parallel to the 3D instance segmentation part in\nthe fully sparse detector. This design achieves a uniform query-based fusion\nframework in both the 2D and 3D sides while maintaining the fully sparse\ncharacteristic. Extensive experiments showcase state-of-the-art results on the\nwidely used nuScenes dataset and the long-range Argoverse 2 dataset. Notably,\nthe inference speed of the proposed method under the long-range LiDAR\nperception setting is 2.7 $\\times$ faster than that of other state-of-the-art\nmultimodal 3D detection methods. Code will be released at\n\\url{https://github.com/BraveGroup/FullySparseFusion}.",
        "updated": "2024-04-28T05:54:15Z",
        "published": "2023-04-24T17:57:43Z",
        "authors": [
            "Yingyan Li",
            "Lue Fan",
            "Yang Liu",
            "Zehao Huang",
            "Yuntao Chen",
            "Naiyan Wang",
            "Zhaoxiang Zhang"
        ],
        "comments": "TPMAI 2024",
        "categories": [
            "cs.CV"
        ],
        "primary_category": "cs.CV",
        "doi": "10.1109/TPAMI.2024.3392303"
    },
    "2304.12377v2": {
        "url": "http://arxiv.org/abs/2304.12377v2",
        "title": "Efficient and Scalable Path-Planning Algorithms for Curvature\n  Constrained Motion in the Hamilton-Jacobi Formulation",
        "summary": "We present a partial-differential-equation-based optimal path-planning\nframework for curvature constrained motion, with application to vehicles in 2-\nand 3-spatial-dimensions. This formulation relies on optimal control theory,\ndynamic programming, and Hamilton-Jacobi-Bellman equations. We develop\nefficient and scalable algorithms for solutions of high dimensional\nHamilton-Jacobi equations which can solve these types of path-planning problems\nefficiently, even in high dimensions, while maintaining the Hamilton-Jacobi\nformulation. Because our method is rooted in optimal control theory and has no\nblack box components, it has solid interpretability, and thus averts the\ntradeoff between interpretability and efficiency for high-dimensional\npath-planning problems. We demonstrate our method with several examples.",
        "updated": "2024-04-16T17:25:36Z",
        "published": "2023-04-24T18:13:38Z",
        "authors": [
            "Christian Parkinson",
            "Isabelle Boyle"
        ],
        "comments": "32 pages, 7 figures",
        "categories": [
            "math.NA",
            "cs.NA",
            "49L20, 49N90, 93C95"
        ],
        "primary_category": "math.NA"
    },
    "2304.12420v2": {
        "url": "http://arxiv.org/abs/2304.12420v2",
        "title": "Sample-Efficient and Surrogate-Based Design Optimization of Underwater\n  Vehicle Hulls",
        "summary": "Physics simulations like computational fluid dynamics (CFD) are a\ncomputational bottleneck in computer-aided design (CAD) optimization processes.\nTo overcome this bottleneck, one requires either an optimization framework that\nis highly sample-efficient, or a fast data-driven proxy (surrogate model) for\nlong-running simulations. Both approaches have benefits and limitations.\nBayesian optimization is often used for sample efficiency, but it solves one\nspecific problem and struggles with transferability; alternatively, surrogate\nmodels can offer fast and often more generalizable solutions for CFD problems,\nbut gathering data for and training such models can be computationally\ndemanding. In this work, we leverage recent advances in optimization and\nartificial intelligence (AI) to explore both of these potential approaches, in\nthe context of designing an optimal unmanned underwater vehicle (UUV) hull. Our\nstudy finds that the Bayesian Optimization-Lower Condition Bound (BO-LCB)\nalgorithm is the most sample-efficient optimization framework and has the best\nconvergence behavior of those considered. Subsequently, we show that our\nDNN-based surrogate model predicts drag force on test data in tight agreement\nwith CFD simulations, with a mean absolute percentage error (MAPE) of 1.85%.\nCombining these results, we demonstrate a two-orders-of-magnitude speedup (with\ncomparable accuracy) for the design optimization process when the surrogate\nmodel is used. To our knowledge, this is the first study applying Bayesian\noptimization and DNN-based surrogate modeling to the problem of UUV design\noptimization, and we share our developments as open-source software.",
        "updated": "2024-03-29T04:13:25Z",
        "published": "2023-04-24T19:52:42Z",
        "authors": [
            "Harsh Vardhan",
            "David Hyde",
            "Umesh Timalsina",
            "Peter Volgyesi",
            "Janos Sztipanovits"
        ],
        "categories": [
            "cs.LG",
            "cs.AI",
            "physics.app-ph",
            "physics.flu-dyn",
            "stat.AP",
            "stat.ML"
        ],
        "primary_category": "cs.LG"
    },
    "2307.01004v2": {
        "url": "http://arxiv.org/abs/2307.01004v2",
        "title": "Joint Coordinate Regression and Association For Multi-Person Pose\n  Estimation, A Pure Neural Network Approach",
        "summary": "We introduce a novel one-stage end-to-end multi-person 2D pose estimation\nalgorithm, known as Joint Coordinate Regression and Association (JCRA), that\nproduces human pose joints and associations without requiring any\npost-processing. The proposed algorithm is fast, accurate, effective, and\nsimple. The one-stage end-to-end network architecture significantly improves\nthe inference speed of JCRA. Meanwhile, we devised a symmetric network\nstructure for both the encoder and decoder, which ensures high accuracy in\nidentifying keypoints. It follows an architecture that directly outputs part\npositions via a transformer network, resulting in a significant improvement in\nperformance. Extensive experiments on the MS COCO and CrowdPose benchmarks\ndemonstrate that JCRA outperforms state-of-the-art approaches in both accuracy\nand efficiency. Moreover, JCRA demonstrates 69.2 mAP and is 78\\% faster at\ninference acceleration than previous state-of-the-art bottom-up algorithms. The\ncode for this algorithm will be publicly available.",
        "updated": "2024-04-19T08:59:37Z",
        "published": "2023-07-03T13:40:20Z",
        "authors": [
            "Dongyang Yu",
            "Yunshi Xie",
            "Wangpeng An",
            "Li Zhang",
            "Yufeng Yao"
        ],
        "comments": "This paper has been accepted by MMasia 2023 and is an oral\n  presentation",
        "categories": [
            "cs.CV",
            "cs.LG"
        ],
        "primary_category": "cs.CV"
    },
    "2307.01177v2": {
        "url": "http://arxiv.org/abs/2307.01177v2",
        "title": "Neural Hilbert Ladders: Multi-Layer Neural Networks in Function Space",
        "summary": "To characterize the function space explored by neural networks (NNs) is an\nimportant aspect of learning theory. In this work, noticing that a multi-layer\nNN generates implicitly a hierarchy of reproducing kernel Hilbert spaces\n(RKHSs) - named a neural Hilbert ladder (NHL) - we define the function space as\nan infinite union of RKHSs, which generalizes the existing Barron space theory\nof two-layer NNs. We then establish several theoretical properties of the new\nspace. First, we prove a correspondence between functions expressed by L-layer\nNNs and those belonging to L-level NHLs. Second, we prove generalization\nguarantees for learning an NHL with a controlled complexity measure. Third, we\nderive a non-Markovian dynamics of random fields that governs the evolution of\nthe NHL which is induced by the training of multi-layer NNs in an\ninfinite-width mean-field limit. Fourth, we show examples of depth separation\nin NHLs under the ReLU activation function. Finally, we perform numerical\nexperiments to illustrate the feature learning aspect of NN training through\nthe lens of NHLs.",
        "updated": "2024-04-11T17:23:42Z",
        "published": "2023-07-03T17:40:58Z",
        "authors": [
            "Zhengdao Chen"
        ],
        "comments": "65 pages, 3 figures. Published by the Journal of Machine Learning\n  Research and presented partially at the 40th International Conference on\n  Machine Learning (ICML 2023)",
        "categories": [
            "cs.LG",
            "math.FA",
            "math.OC",
            "math.PR",
            "stat.ML"
        ],
        "primary_category": "cs.LG",
        "journal_ref": "Journal of Machine Learning Research, 25(109):1-65, 2024"
    },
    "2307.01362v4": {
        "url": "http://arxiv.org/abs/2307.01362v4",
        "title": "A Strong Baseline for Point Cloud Registration via Direct Superpoints\n  Matching",
        "summary": "Deep neural networks endow the downsampled superpoints with highly\ndiscriminative feature representations. Previous dominant point cloud\nregistration approaches match these feature representations as the first step,\ne.g., using the Sinkhorn algorithm. A RANSAC-like method is then usually\nadopted as a post-processing refinement to filter the outliers. Other dominant\nmethod is to directly predict the superpoint matchings using learned MLP\nlayers. Both of them have drawbacks: RANSAC-based methods are computationally\nintensive and prediction-based methods suffer from outputing non-existing\npoints in the point cloud. In this paper, we propose a straightforward and\neffective baseline to find correspondences of superpoints in a global matching\nmanner. We employ the normalized matching scores as weights for each\ncorrespondence, allowing us to reject the outliers and further weigh the rest\ninliers when fitting the transformation matrix without relying on the\ncumbersome RANSAC. Moreover, the entire model can be trained in an end-to-end\nfashion, leading to better accuracy. Our simple yet effective baseline shows\ncomparable or even better results than state-of-the-art methods on three\ndatasets including ModelNet, 3DMatch, and KITTI. We do not advocate our\napproach to be \\emph{the} solution for point cloud registration but use the\nresults to emphasize the role of matching strategy for point cloud\nregistration. The code and models are available at\nhttps://github.com/neu-vi/Superpoints_Registration.",
        "updated": "2024-03-29T17:11:38Z",
        "published": "2023-07-03T21:33:40Z",
        "authors": [
            "Aniket Gupta",
            "Yiming Xie",
            "Hanumant Singh",
            "Huaizu Jiang"
        ],
        "categories": [
            "cs.CV"
        ],
        "primary_category": "cs.CV"
    },
    "2307.01449v2": {
        "url": "http://arxiv.org/abs/2307.01449v2",
        "title": "A Double Machine Learning Approach to Combining Experimental and\n  Observational Data",
        "summary": "Experimental and observational studies often lack validity due to untestable\nassumptions. We propose a double machine learning approach to combine\nexperimental and observational studies, allowing practitioners to test for\nassumption violations and estimate treatment effects consistently. Our\nframework tests for violations of external validity and ignorability under\nmilder assumptions. When only one of these assumptions is violated, we provide\nsemiparametrically efficient treatment effect estimators. However, our\nno-free-lunch theorem highlights the necessity of accurately identifying the\nviolated assumption for consistent treatment effect estimation. Through\ncomparative analyses, we show our framework's superiority over existing data\nfusion methods. The practical utility of our approach is further exemplified by\nthree real-world case studies, underscoring its potential for widespread\napplication in empirical research.",
        "updated": "2024-04-03T02:26:24Z",
        "published": "2023-07-04T02:53:11Z",
        "authors": [
            "Harsh Parikh",
            "Marco Morucci",
            "Vittorio Orlandi",
            "Sudeepa Roy",
            "Cynthia Rudin",
            "Alexander Volfovsky"
        ],
        "categories": [
            "stat.ME",
            "cs.AI",
            "cs.LG",
            "econ.EM"
        ],
        "primary_category": "stat.ME"
    },
    "2307.01522v2": {
        "url": "http://arxiv.org/abs/2307.01522v2",
        "title": "Immersive Media and Massive Twinning: Advancing Towards the Metaverse",
        "summary": "The advent of the Metaverse concept has further expedited the evolution of\nhaptic, tactile internet, and multimedia applications with their VR/AR/XR\nservices, and therefore, fully-immersive sensing is most likely to define the\nnext generation of wireless networks as a key to realize the speculative vision\nof the Metaverse. In this magazine, we articulate different types of media that\nwe envision will be communicated between the cyber and physical twins in the\nMetaverse. In particular, we explore the advantages grasped by exploiting each\nkind, and we point out critical challenges pertinent to 3D data processing,\ncoding, transporting, and rendering. We further shed light on the role of\nfuture wireless networks in delivering the anticipated quality of immersion\nthrough the reliable streaming of multimedia signals between the digital twin\nand its physical counterpart. Specifically, we explore emergent communication\nparadigms, including semantic, holographic, and goal-oriented communication,\nwhich we expect to realize energy and spectrally efficient Metaverse while\nensuring ultra-low latency.",
        "updated": "2024-04-04T06:09:09Z",
        "published": "2023-07-04T07:03:30Z",
        "authors": [
            "Wassim Hamidouche",
            "Lina Bariah",
            "Merouane Debbah"
        ],
        "categories": [
            "cs.MM"
        ],
        "primary_category": "cs.MM"
    },
    "2307.02046v6": {
        "url": "http://arxiv.org/abs/2307.02046v6",
        "title": "Recommender Systems in the Era of Large Language Models (LLMs)",
        "summary": "With the prosperity of e-commerce and web applications, Recommender Systems\n(RecSys) have become an important component of our daily life, providing\npersonalized suggestions that cater to user preferences. While Deep Neural\nNetworks (DNNs) have made significant advancements in enhancing recommender\nsystems by modeling user-item interactions and incorporating textual side\ninformation, DNN-based methods still face limitations, such as difficulties in\nunderstanding users' interests and capturing textual side information,\ninabilities in generalizing to various recommendation scenarios and reasoning\non their predictions, etc. Meanwhile, the emergence of Large Language Models\n(LLMs), such as ChatGPT and GPT4, has revolutionized the fields of Natural\nLanguage Processing (NLP) and Artificial Intelligence (AI), due to their\nremarkable abilities in fundamental responsibilities of language understanding\nand generation, as well as impressive generalization and reasoning\ncapabilities. As a result, recent studies have attempted to harness the power\nof LLMs to enhance recommender systems. Given the rapid evolution of this\nresearch direction in recommender systems, there is a pressing need for a\nsystematic overview that summarizes existing LLM-empowered recommender systems,\nto provide researchers in relevant fields with an in-depth understanding.\nTherefore, in this paper, we conduct a comprehensive review of LLM-empowered\nrecommender systems from various aspects including Pre-training, Fine-tuning,\nand Prompting. More specifically, we first introduce representative methods to\nharness the power of LLMs (as a feature encoder) for learning representations\nof users and items. Then, we review recent techniques of LLMs for enhancing\nrecommender systems from three paradigms, namely pre-training, fine-tuning, and\nprompting. Finally, we comprehensively discuss future directions in this\nemerging field.",
        "updated": "2024-04-29T09:06:51Z",
        "published": "2023-07-05T06:03:40Z",
        "authors": [
            "Zihuai Zhao",
            "Wenqi Fan",
            "Jiatong Li",
            "Yunqing Liu",
            "Xiaowei Mei",
            "Yiqi Wang",
            "Zhen Wen",
            "Fei Wang",
            "Xiangyu Zhao",
            "Jiliang Tang",
            "Qing Li"
        ],
        "comments": "Accepted by IEEE TKDE",
        "categories": [
            "cs.IR",
            "cs.AI",
            "cs.CL"
        ],
        "primary_category": "cs.IR"
    },
    "2307.02180v3": {
        "url": "http://arxiv.org/abs/2307.02180v3",
        "title": "Runtime Repeated Recursion Unfolding in CHR: A Just-In-Time Online\n  Program Optimization Strategy That Can Achieve Super-Linear Speedup",
        "summary": "We introduce a just-in-time runtime program transformation strategy based on\nrepeated recursion unfolding. Our online program optimization generates several\nversions of a recursion differentiated by the minimal number of recursive steps\ncovered. The base case of the recursion is ignored in our technique.\n  Our method is introduced here on the basis of single linear direct recursive\nrules. When a recursive call is encountered at runtime, first an unfolder\ncreates specializations of the associated recursive rule on-the-fly and then an\ninterpreter applies these rules to the call. Our approach reduces the number of\nrecursive rule applications to its logarithm at the expense of introducing a\nlogarithmic number of generic unfolded rules.\n  We prove correctness of our online optimization technique and determine its\ntime complexity. For recursions which have enough simplifyable unfoldings, a\nsuper-linear is possible, i.e. speedup by more than a constant factor.The\nnecessary simplification is problem-specific and has to be provided at\ncompile-time. In our speedup analysis, we prove a sufficient condition as well\nas a sufficient and necessary condition for super-linear speedup relating the\ncomplexity of the recursive steps of the original rule and the unfolded rules.\n  We have implemented an unfolder and meta-interpreter for runtime repeated\nrecursion unfolding with just five rules in Constraint Handling Rules (CHR)\nembedded in Prolog. We illustrate the feasibility of our approach with\nsimplifications, time complexity results and benchmarks for some basic\ntractable algorithms. The simplifications require some insight and were derived\nmanually. The runtime improvement quickly reaches several orders of magnitude,\nconsistent with the super-linear speedup predicted by our theorems.",
        "updated": "2024-04-25T07:36:07Z",
        "published": "2023-07-05T10:18:51Z",
        "authors": [
            "Thom Fruehwirth"
        ],
        "comments": "Minor Revision of major revision of submission to Journal Fundamenta\n  Informaticae",
        "categories": [
            "cs.PL",
            "cs.CC",
            "cs.PF",
            "cs.SC"
        ],
        "primary_category": "cs.PL"
    },
    "2307.02185v3": {
        "url": "http://arxiv.org/abs/2307.02185v3",
        "title": "Citation: A Key to Building Responsible and Accountable Large Language\n  Models",
        "summary": "Large Language Models (LLMs) bring transformative benefits alongside unique\nchallenges, including intellectual property (IP) and ethical concerns. This\nposition paper explores a novel angle to mitigate these risks, drawing\nparallels between LLMs and established web systems. We identify \"citation\" -\nthe acknowledgement or reference to a source or evidence - as a crucial yet\nmissing component in LLMs. Incorporating citation could enhance content\ntransparency and verifiability, thereby confronting the IP and ethical issues\nin the deployment of LLMs. We further propose that a comprehensive citation\nmechanism for LLMs should account for both non-parametric and parametric\ncontent. Despite the complexity of implementing such a citation mechanism,\nalong with the potential pitfalls, we advocate for its development. Building on\nthis foundation, we outline several research problems in this area, aiming to\nguide future explorations towards building more responsible and accountable\nLLMs.",
        "updated": "2024-03-31T19:47:47Z",
        "published": "2023-07-05T10:25:45Z",
        "authors": [
            "Jie Huang",
            "Kevin Chen-Chuan Chang"
        ],
        "comments": "NAACL 2024 Findings",
        "categories": [
            "cs.CL",
            "cs.AI",
            "cs.CR"
        ],
        "primary_category": "cs.CL"
    },
    "2307.02277v2": {
        "url": "http://arxiv.org/abs/2307.02277v2",
        "title": "Privacy-Preserving Federated Heavy Hitter Analytics for Non-IID Data",
        "summary": "Federated heavy-hitter analytics involves the identification of the most\nfrequent items within distributed data. Existing methods for this task often\nencounter challenges such as compromising privacy or sacrificing utility. To\naddress these issues, we introduce a novel privacy-preserving algorithm that\nexploits the hierarchical structure to discover local and global heavy hitters\nin non-IID data by utilizing perturbation and similarity techniques. We conduct\nextensive evaluations on both synthetic and real datasets to validate the\neffectiveness of our approach. We also present FedCampus, a demonstration\napplication to showcase the capabilities of our algorithm in analyzing\npopulation statistics.",
        "updated": "2024-04-17T07:42:56Z",
        "published": "2023-07-05T13:24:27Z",
        "authors": [
            "Jiaqi Shao",
            "Shanshan Han",
            "Chaoyang He",
            "Bing Luo"
        ],
        "comments": "technical error in Theorem 1",
        "categories": [
            "cs.DC"
        ],
        "primary_category": "cs.DC"
    },
    "2307.02432v2": {
        "url": "http://arxiv.org/abs/2307.02432v2",
        "title": "A probabilistic, data-driven closure model for RANS simulations with\n  aleatoric, model uncertainty",
        "summary": "We propose a data-driven, closure model for Reynolds-averaged Navier-Stokes\n(RANS) simulations that incorporates aleatoric, model uncertainty. The proposed\nclosure consists of two parts. A parametric one, which utilizes previously\nproposed, neural-network-based tensor basis functions dependent on the rate of\nstrain and rotation tensor invariants. This is complemented by latent, random\nvariables which account for aleatoric model errors. A fully Bayesian\nformulation is proposed, combined with a sparsity-inducing prior in order to\nidentify regions in the problem domain where the parametric closure is\ninsufficient and where stochastic corrections to the Reynolds stress tensor are\nneeded. Training is performed using sparse, indirect data, such as mean\nvelocities and pressures, in contrast to the majority of alternatives that\nrequire direct Reynolds stress data. For inference and learning, a Stochastic\nVariational Inference scheme is employed, which is based on Monte Carlo\nestimates of the pertinent objective in conjunction with the reparametrization\ntrick. This necessitates derivatives of the output of the RANS solver, for\nwhich we developed an adjoint-based formulation. In this manner, the parametric\nsensitivities from the differentiable solver can be combined with the built-in,\nautomatic differentiation capability of the neural network library in order to\nenable an end-to-end differentiable framework. We demonstrate the capability of\nthe proposed model to produce accurate, probabilistic, predictive estimates for\nall flow quantities, even in regions where model errors are present, on a\nseparated flow in the backward-facing step benchmark problem.",
        "updated": "2024-04-15T15:48:39Z",
        "published": "2023-07-05T16:53:31Z",
        "authors": [
            "Atul Agrawal",
            "Phaedon-Stelios Koutsourelakis"
        ],
        "comments": "31 pages, 10 figures",
        "categories": [
            "physics.flu-dyn",
            "cs.LG",
            "physics.comp-ph",
            "stat.ML"
        ],
        "primary_category": "physics.flu-dyn"
    },
    "2309.06462v3": {
        "url": "http://arxiv.org/abs/2309.06462v3",
        "title": "Action Segmentation Using 2D Skeleton Heatmaps and Multi-Modality Fusion",
        "summary": "This paper presents a 2D skeleton-based action segmentation method with\napplications in fine-grained human activity recognition. In contrast with\nstate-of-the-art methods which directly take sequences of 3D skeleton\ncoordinates as inputs and apply Graph Convolutional Networks (GCNs) for\nspatiotemporal feature learning, our main idea is to use sequences of 2D\nskeleton heatmaps as inputs and employ Temporal Convolutional Networks (TCNs)\nto extract spatiotemporal features. Despite lacking 3D information, our\napproach yields comparable/superior performances and better robustness against\nmissing keypoints than previous methods on action segmentation datasets.\nMoreover, we improve the performances further by using both 2D skeleton\nheatmaps and RGB videos as inputs. To our best knowledge, this is the first\nwork to utilize 2D skeleton heatmap inputs and the first work to explore 2D\nskeleton+RGB fusion for action segmentation.",
        "updated": "2024-04-26T02:53:13Z",
        "published": "2023-09-12T17:56:06Z",
        "authors": [
            "Syed Waleed Hyder",
            "Muhammad Usama",
            "Anas Zafar",
            "Muhammad Naufil",
            "Fawad Javed Fateh",
            "Andrey Konin",
            "M. Zeeshan Zia",
            "Quoc-Huy Tran"
        ],
        "comments": "Accepted to ICRA 2024",
        "categories": [
            "cs.CV"
        ],
        "primary_category": "cs.CV"
    },
    "2309.06702v2": {
        "url": "http://arxiv.org/abs/2309.06702v2",
        "title": "Functional Encryption in the Bounded Storage Models",
        "summary": "Functional encryption is a powerful paradigm for public-key encryption that\nallows for controlled access to encrypted data. Achieving the ideal simulation\nbased security for this primitive is generally impossible in the plain model,\nso we investigate possibilities in the bounded quantum storage model (BQSM) and\nthe bounded classical storage model (BCSM), where adversaries are limited with\nrespect to their quantum and classical memories, respectively. The\nimpossibility results on functional encryption do not apply to these settings\nwhich allows us to obtain positive outcomes.\n  Firstly, in the BQSM, we construct non-interactive functional encryption\nsatisfying information-theoretic simulation based security with\n${q}=O(\\sqrt{{s}/{r}})$. Here ${r}$ denotes the number of times that an\nadversary is restricted to ${s}$--qubits of quantum memory in the protocol and\n${q}$ denotes the required quantum memory to run the protocol honestly. We then\nshow that our scheme is optimal by proving that it is impossible to attain\ninformation-theoretically security with ${q} < \\sqrt{{s}/{r}}$. However, by\nassuming the existence of one-way functions, we achieve (interactive)\nfunctional encryption with ${q}=0$ and ${r}=1$.\n  Secondly, in the BCSM, we construct non-interactive functional encryption\nsatisfying information-theoretic subexponential simulation based security\nassuming the existence of subexponential grey-box obfuscation. We then\ndemonstrate that this assumption is minimal by constructing subexponential\ngrey-box obfuscation from non-interactive functional encryption. We also\nconsider the computational setting, obtaining (interactive) functional\nencryption satisfying simulation based security assuming grey-box obfuscation\nand one-way functions.",
        "updated": "2024-04-01T22:38:16Z",
        "published": "2023-09-13T03:55:36Z",
        "authors": [
            "Mohammed Barhoush",
            "Louis Salvail"
        ],
        "comments": "40 pages",
        "categories": [
            "cs.CR"
        ],
        "primary_category": "cs.CR"
    },
    "2309.06717v2": {
        "url": "http://arxiv.org/abs/2309.06717v2",
        "title": "Bias Amplification Enhances Minority Group Performance",
        "summary": "Neural networks produced by standard training are known to suffer from poor\naccuracy on rare subgroups despite achieving high accuracy on average, due to\nthe correlations between certain spurious features and labels. Previous\napproaches based on worst-group loss minimization (e.g. Group-DRO) are\neffective in improving worse-group accuracy but require expensive group\nannotations for all the training samples. In this paper, we focus on the more\nchallenging and realistic setting where group annotations are only available on\na small validation set or are not available at all. We propose BAM, a novel\ntwo-stage training algorithm: in the first stage, the model is trained using a\nbias amplification scheme via introducing a learnable auxiliary variable for\neach training sample; in the second stage, we upweight the samples that the\nbias-amplified model misclassifies, and then continue training the same model\non the reweighted dataset. Empirically, BAM achieves competitive performance\ncompared with existing methods evaluated on spurious correlation benchmarks in\ncomputer vision and natural language processing. Moreover, we find a simple\nstopping criterion based on minimum class accuracy difference that can remove\nthe need for group annotations, with little or no loss in worst-group accuracy.\nWe perform extensive analyses and ablations to verify the effectiveness and\nrobustness of our algorithm in varying class and group imbalance ratios.",
        "updated": "2024-04-09T16:05:23Z",
        "published": "2023-09-13T04:40:08Z",
        "authors": [
            "Gaotang Li",
            "Jiarui Liu",
            "Wei Hu"
        ],
        "comments": "To appear in TMLR",
        "categories": [
            "cs.LG",
            "cs.CY"
        ],
        "primary_category": "cs.LG"
    },
    "2309.06764v2": {
        "url": "http://arxiv.org/abs/2309.06764v2",
        "title": "Adding an Implication to Logics of Perfect Paradefinite Algebras",
        "summary": "Perfect paradefinite algebras are De Morgan algebras expanded with an\noperation that allows for the full behavior of classical negation to be\nrestored. They form a variety that is term-equivalent to the variety of\ninvolutive Stone algebras. Their associated multiple-conclusion (Set-Set) and\nsingle-conclusion (Set-Fmla) order-preserving logics are non-algebraizable\nself-extensional logics of formal inconsistency and undeterminedness determined\nby a six-valued matrix, studied in depth by Gomes et al. (2022) from both the\nalgebraic and the proof-theoretical perspectives. In the present paper, we\ncontinue that study by investigating directions for conservatively expanding\nthese logics with an implication connective (essentially, one that admits the\ndeduction-detachment theorem). We first consider logics given by very simple\nand manageable non-deterministic semantics whose implication (in isolation) is\nclassical. These, nevertheless, fail to be self-extensional. We then consider\nthe implication realized by the relative pseudo-complement over the six-valued\nperfect paradefinite algebra. Our strategy is to expand the language of the\nlatter algebra with this connective and study the (self-extensional) Set-Set\nand Set-Fmla order-preserving and top-assertional logics of the variety induced\nby the resulting algebra. We provide axiomatizations for such new variety and\nfor such logics, drawing parallels with the class of symmetric Heyting algebras\nand with Moisil's 'symmetric modal logic'. For the Set-Set logic, in\nparticular, the axiomatization we obtain is analytic. We close by studying\ninterpolation properties for these logics and concluding that the new variety\nhas the Maehara amalgamation property.",
        "updated": "2024-04-06T12:59:50Z",
        "published": "2023-09-13T07:20:35Z",
        "authors": [
            "Vitor Greati",
            "S\u00e9rgio Marcelino",
            "Jo\u00e3o Marcos",
            "Umberto Rivieccio"
        ],
        "comments": "New version after a round of peer reviewing, no critical changes",
        "categories": [
            "cs.LO",
            "03G10 (Primary) 03C05, 03B50, 03B70, 03B53, 03B22, 03B35, 03C40\n  (Secondary)",
            "F.4.1"
        ],
        "primary_category": "cs.LO"
    },
    "2309.06769v2": {
        "url": "http://arxiv.org/abs/2309.06769v2",
        "title": "Reliability-Latency-Rate Tradeoff in Low-Latency Communications with\n  Finite-Blocklength Coding",
        "summary": "Low-latency communication plays an increasingly important role in\ndelay-sensitive applications by ensuring the real-time exchange of information.\nHowever, due to the constraints on the maximum instantaneous power, bounded\nlatency is hard to be guaranteed. In this paper, we investigate the\nreliability-latency-rate tradeoff in low-latency communications with\nfinite-blocklength coding (FBC). More specifically, we are interested in the\nfundamental tradeoff between error probability, delay-violation probability\n(DVP), and service rate. Based on the effective capacity (EC), we present the\ngain-conservation equations to characterize the reliability-latency-rate\ntradeoffs in low-latency systems. In particular, we investigate the low-latency\ntransmissions over an additive white Gaussian noise (AWGN) channel and a\nNakagami-$m$ fading channel. By defining the service rate gain, reliability\ngain, and real-time gain respectively, we further adopt the asymptotic analysis\napproach to reveal the fundamental reliability-latency-rate tradeoff of\nultra-reliable and low-latency communications in the high signal-to-noise-ratio\n(SNR) regime. To analytically evaluate the quality-of-service-constrained\nthroughput of low-latency communications with FBC, an EC-approximation method\nis further conceived to derive the closed-form expression of\nquality-of-service-constrained throughput. Our results may provide some\ninsights into the efficient scheduling of low-latency wireless communications\nin which statistical latency and reliability metrics are adopted.",
        "updated": "2024-04-08T06:43:02Z",
        "published": "2023-09-13T07:40:18Z",
        "authors": [
            "Lintao Li",
            "Wei Chen",
            "Petar Popovski",
            "Khaled B. Letaief"
        ],
        "categories": [
            "cs.IT",
            "eess.SP",
            "math.IT"
        ],
        "primary_category": "cs.IT"
    },
    "2309.06861v2": {
        "url": "http://arxiv.org/abs/2309.06861v2",
        "title": "TTD Configurations for Near-Field Beamforming: Parallel, Serial, or\n  Hybrid?",
        "summary": "True-time delayers (TTDs) are popular components for hybrid beamforming\narchitectures to combat the spatial-wideband effect in wideband near-field\ncommunications. In this paper, a serial and a hybrid serial-parallel TTD\nconfiguration are investigated for hybrid beamforming architectures. Compared\nto the conventional parallel configuration, the serial configuration exhibits a\ncumulative time delay caused by multiple TTDs, which potentially alleviates the\nmaximum delay requirements on the individual TTDs. However, independent control\nof individual TTDs becomes impossible in the serial configuration. Therefore, a\nhybrid TTD configuration is proposed as a compromise solution. Furthermore, a\npower equalization approach is proposed to address the cumulative insertion\nloss of the serial and hybrid TTD configurations. The wideband near-field\nbeamforming design for different configurations is studied to maximize the\nspectral efficiency in both single-user and multiple-user systems. 1) For\nsingle-user systems, a closed-form solution for the beamforming design is\nderived. The preferred user locations and the required maximum time delay of\neach TTD configuration are characterized. 2) For multi-user systems, a\npenalty-based iterative algorithm is developed to obtain a stationary point of\nthe spectral efficiency maximization problem for the considered TTD\nconfigurations. In addition, a hybrid-forward-and-backward (HFB) implementation\nis proposed to enhance the performance of the serial configuration. Our\nnumerical results confirm the effectiveness of the proposed designs and unveil\nthat i) compared to the conventional parallel configuration, both the serial\nand hybrid configurations can significantly reduce the maximum time delays\nrequired for the individual TTDs and ii) the hybrid configuration excels in\nsingle-user systems, while the HFB serial configuration is preferred in\nmulti-user systems.",
        "updated": "2024-01-09T16:44:28Z",
        "published": "2023-09-13T10:16:30Z",
        "authors": [
            "Zhaolin Wang",
            "Xidong Mu",
            "Yuanwei Liu",
            "Robert Schober"
        ],
        "comments": "16 pages, 10 figures",
        "categories": [
            "cs.IT",
            "eess.SP",
            "math.IT"
        ],
        "primary_category": "cs.IT",
        "doi": "10.1109/TCOMM.2024.3370832"
    },
    "2309.06862v2": {
        "url": "http://arxiv.org/abs/2309.06862v2",
        "title": "Domain Decomposition Method for Poisson--Boltzmann Equations based on\n  Solvent Excluded Surface",
        "summary": "In this paper, we develop a domain decomposition method for the nonlinear\nPoisson-Boltzmann equation based on a solvent-excluded surface widely used in\ncomputational chemistry. The model relies on a nonlinear equation defined in\n$\\mathbb{R}^3$ with a space-dependent dielectric permittivity and an\nion-exclusion function that accounts for steric effects. Potential theory\narguments transform the nonlinear equation into two coupled equations defined\nin a bounded domain. Then, the Schwarz decomposition method is used to\nformulate local problems by decomposing the cavity into overlapping balls and\nonly solving a set of coupled sub-equations in each ball. The main novelty of\nthe proposed method is the introduction of a hybrid linear-nonlinear solver\nused to solve the equation. A series of numerical experiments are presented to\ntest the method and show the importance of the nonlinear model.",
        "updated": "2024-04-05T12:35:16Z",
        "published": "2023-09-13T10:17:43Z",
        "authors": [
            "Abhinav Jha",
            "Benjamin Stamm"
        ],
        "categories": [
            "math.NA",
            "cs.NA",
            "math.NT",
            "65N35, 65N55"
        ],
        "primary_category": "math.NA"
    },
    "2309.06978v4": {
        "url": "http://arxiv.org/abs/2309.06978v4",
        "title": "Differentiable JPEG: The Devil is in the Details",
        "summary": "JPEG remains one of the most widespread lossy image coding methods. However,\nthe non-differentiable nature of JPEG restricts the application in deep\nlearning pipelines. Several differentiable approximations of JPEG have recently\nbeen proposed to address this issue. This paper conducts a comprehensive review\nof existing diff. JPEG approaches and identifies critical details that have\nbeen missed by previous methods. To this end, we propose a novel diff. JPEG\napproach, overcoming previous limitations. Our approach is differentiable\nw.r.t. the input image, the JPEG quality, the quantization tables, and the\ncolor conversion parameters. We evaluate the forward and backward performance\nof our diff. JPEG approach against existing methods. Additionally, extensive\nablations are performed to evaluate crucial design choices. Our proposed diff.\nJPEG resembles the (non-diff.) reference implementation best, significantly\nsurpassing the recent-best diff. approach by $3.47$dB (PSNR) on average. For\nstrong compression rates, we can even improve PSNR by $9.51$dB. Strong\nadversarial attack results are yielded by our diff. JPEG, demonstrating the\neffective gradient approximation. Our code is available at\nhttps://github.com/necla-ml/Diff-JPEG.",
        "updated": "2023-12-22T14:16:59Z",
        "published": "2023-09-13T14:13:08Z",
        "authors": [
            "Christoph Reich",
            "Biplob Debnath",
            "Deep Patel",
            "Srimat Chakradhar"
        ],
        "comments": "Accepted at WACV 2024. Project page:\n  https://christophreich1996.github.io/differentiable_jpeg/ WACV paper:\n  https://openaccess.thecvf.com/content/WACV2024/html/Reich_Differentiable_JPEG_The_Devil_Is_in_the_Details_WACV_2024_paper.html",
        "categories": [
            "cs.CV",
            "cs.MM"
        ],
        "primary_category": "cs.CV",
        "doi": "10.1109/WACV57701.2024.00408"
    },
    "2309.07096v4": {
        "url": "http://arxiv.org/abs/2309.07096v4",
        "title": "Computational limits to the legibility of the imaged human brain",
        "summary": "Our knowledge of the organisation of the human brain at the population-level\nis yet to translate into power to predict functional differences at the\nindividual-level, limiting clinical applications, and casting doubt on the\ngeneralisability of inferred mechanisms. It remains unknown whether the\ndifficulty arises from the absence of individuating biological patterns within\nthe brain, or from limited power to access them with the models and compute at\nour disposal. Here we comprehensively investigate the resolvability of such\npatterns with data and compute at unprecedented scale. Across 23 810 unique\nparticipants from UK Biobank, we systematically evaluate the predictability of\n25 individual biological characteristics, from all available combinations of\nstructural and functional neuroimaging data. Over 4526 GPU hours of\ncomputation, we train, optimize, and evaluate out-of-sample 700 individual\npredictive models, including fully-connected feed-forward neural networks of\ndemographic, psychological, serological, chronic disease, and functional\nconnectivity characteristics, and both uni- and multi-modal 3D convolutional\nneural network models of macro- and micro-structural brain imaging. We find a\nmarked discrepancy between the high predictability of sex (balanced accuracy\n99.7%), age (mean absolute error 2.048 years, R2 0.859), and weight (mean\nabsolute error 2.609Kg, R2 0.625), for which we set new state-of-the-art\nperformance, and the surprisingly low predictability of other characteristics.\nNeither structural nor functional imaging predicted psychology better than the\ncoincidence of chronic disease (p<0.05). Serology predicted chronic disease\n(p<0.05) and was best predicted by it (p<0.001), followed by structural\nneuroimaging (p<0.05). Our findings suggest either more informative imaging or\nmore powerful models are needed to decipher individual level characteristics\nfrom the human brain.",
        "updated": "2024-04-02T19:12:46Z",
        "published": "2023-08-23T12:37:13Z",
        "authors": [
            "James K Ruffle",
            "Robert J Gray",
            "Samia Mohinta",
            "Guilherme Pombo",
            "Chaitanya Kaul",
            "Harpreet Hyare",
            "Geraint Rees",
            "Parashkev Nachev"
        ],
        "comments": "38 pages, 6 figures, 1 table, 2 supplementary figures, 1\n  supplementary table",
        "categories": [
            "q-bio.NC",
            "cs.CV",
            "eess.IV"
        ],
        "primary_category": "q-bio.NC",
        "doi": "10.1016/j.neuroimage.2024.120600"
    },
    "2309.07136v3": {
        "url": "http://arxiv.org/abs/2309.07136v3",
        "title": "Masked Transformer for Electrocardiogram Classification",
        "summary": "Electrocardiogram (ECG) is one of the most important diagnostic tools in\nclinical applications. With the advent of advanced algorithms, various deep\nlearning models have been adopted for ECG tasks. However, the potential of\nTransformer for ECG data has not been fully realized, despite their widespread\nsuccess in computer vision and natural language processing. In this work, we\npresent Masked Transformer for ECG classification (MTECG), a simple yet\neffective method which significantly outperforms recent state-of-the-art\nalgorithms in ECG classification. Our approach adapts the image-based masked\nautoencoders to self-supervised representation learning from ECG time series.\nWe utilize a lightweight Transformer for the encoder and a 1-layer Transformer\nfor the decoder. The ECG signal is split into a sequence of non-overlapping\nsegments along the time dimension, and learnable positional embeddings are\nadded to preserve the sequential information. We construct the Fuwai dataset\ncomprising 220,251 ECG recordings with a broad range of diagnoses, annotated by\nmedical experts, to explore the potential of Transformer. A strong pre-training\nand fine-tuning recipe is proposed from the empirical study. The experiments\ndemonstrate that the proposed method increases the macro F1 scores by\n3.4%-27.5% on the Fuwai dataset, 9.9%-32.0% on the PTB-XL dataset, and\n9.4%-39.1% on a multicenter dataset, compared to the alternative methods. We\nhope that this study could direct future research on the application of\nTransformer to more ECG tasks.",
        "updated": "2024-04-23T01:39:28Z",
        "published": "2023-08-31T09:21:23Z",
        "authors": [
            "Ya Zhou",
            "Xiaolin Diao",
            "Yanni Huo",
            "Yang Liu",
            "Xiaohan Fan",
            "Wei Zhao"
        ],
        "comments": "more experimental results; more implementation details; different\n  abstracts",
        "categories": [
            "eess.SP",
            "cs.AI",
            "cs.LG",
            "stat.AP"
        ],
        "primary_category": "eess.SP"
    },
    "2310.11804v3": {
        "url": "http://arxiv.org/abs/2310.11804v3",
        "title": "Physics-informed Neural Network for Acoustic Resonance Analysis in a\n  One-Dimensional Acoustic Tube",
        "summary": "This study devised a physics-informed neural network (PINN) framework to\nsolve the wave equation for acoustic resonance analysis. The proposed\nanalytical model, ResoNet, minimizes the loss function for periodic solutions\nand conventional PINN loss functions, thereby effectively using the function\napproximation capability of neural networks while performing resonance\nanalysis. Additionally, it can be easily applied to inverse problems. The\nresonance in a one-dimensional acoustic tube, and the effectiveness of the\nproposed method was validated through the forward and inverse analyses of the\nwave equation with energy-loss terms. In the forward analysis, the\napplicability of PINN to the resonance problem was evaluated via comparison\nwith the finite-difference method. The inverse analysis, which included\nidentifying the energy loss term in the wave equation and design optimization\nof the acoustic tube, was performed with good accuracy.",
        "updated": "2024-04-16T08:26:40Z",
        "published": "2023-10-18T08:52:10Z",
        "authors": [
            "Kazuya Yokota",
            "Takahiko Kurahashi",
            "Masajiro Abe"
        ],
        "comments": "15 pages, 18 figures. The following article has been submitted to the\n  Journal of the Acoustical Society of America. After it is published, it will\n  be found at https://pubs.aip.org/asa/jasa",
        "categories": [
            "cs.SD",
            "eess.AS"
        ],
        "primary_category": "cs.SD"
    },
    "2310.11807v3": {
        "url": "http://arxiv.org/abs/2310.11807v3",
        "title": "Learning quantum properties from short-range correlations using\n  multi-task networks",
        "summary": "Characterizing multipartite quantum systems is crucial for quantum computing\nand many-body physics. The problem, however, becomes challenging when the\nsystem size is large and the properties of interest involve correlations among\na large number of particles. Here we introduce a neural network model that can\npredict various quantum properties of many-body quantum states with constant\ncorrelation length, using only measurement data from a small number of\nneighboring sites. The model is based on the technique of multi-task learning,\nwhich we show to offer several advantages over traditional single-task\napproaches. Through numerical experiments, we show that multi-task learning can\nbe applied to sufficiently regular states to predict global properties, like\nstring order parameters, from the observation of short-range correlations, and\nto distinguish between quantum phases that cannot be distinguished by\nsingle-task networks. Remarkably, our model appears to be able to transfer\ninformation learnt from lower dimensional quantum systems to higher dimensional\nones, and to make accurate predictions for Hamiltonians that were not seen in\nthe training.",
        "updated": "2024-04-02T10:06:26Z",
        "published": "2023-10-18T08:53:23Z",
        "authors": [
            "Ya-Dong Wu",
            "Yan Zhu",
            "Yuexuan Wang",
            "Giulio Chiribella"
        ],
        "categories": [
            "quant-ph",
            "cs.AI"
        ],
        "primary_category": "quant-ph"
    },
    "2310.11865v2": {
        "url": "http://arxiv.org/abs/2310.11865v2",
        "title": "Effective and Efficient Federated Tree Learning on Hybrid Data",
        "summary": "Federated learning has emerged as a promising distributed learning paradigm\nthat facilitates collaborative learning among multiple parties without\ntransferring raw data. However, most existing federated learning studies focus\non either horizontal or vertical data settings, where the data of different\nparties are assumed to be from the same feature or sample space. In practice, a\ncommon scenario is the hybrid data setting, where data from different parties\nmay differ both in the features and samples. To address this, we propose\nHybridTree, a novel federated learning approach that enables federated tree\nlearning on hybrid data. We observe the existence of consistent split rules in\ntrees. With the help of these split rules, we theoretically show that the\nknowledge of parties can be incorporated into the lower layers of a tree. Based\non our theoretical analysis, we propose a layer-level solution that does not\nneed frequent communication traffic to train a tree. Our experiments\ndemonstrate that HybridTree can achieve comparable accuracy to the centralized\nsetting with low computational and communication overhead. HybridTree can\nachieve up to 8 times speedup compared with the other baselines.",
        "updated": "2024-04-29T21:44:18Z",
        "published": "2023-10-18T10:28:29Z",
        "authors": [
            "Qinbin Li",
            "Chulin Xie",
            "Xiaojun Xu",
            "Xiaoyuan Liu",
            "Ce Zhang",
            "Bo Li",
            "Bingsheng He",
            "Dawn Song"
        ],
        "categories": [
            "cs.LG"
        ],
        "primary_category": "cs.LG"
    },
    "2310.11890v3": {
        "url": "http://arxiv.org/abs/2310.11890v3",
        "title": "IRAD: Implicit Representation-driven Image Resampling against\n  Adversarial Attacks",
        "summary": "We introduce a novel approach to counter adversarial attacks, namely, image\nresampling. Image resampling transforms a discrete image into a new one,\nsimulating the process of scene recapturing or rerendering as specified by a\ngeometrical transformation. The underlying rationale behind our idea is that\nimage resampling can alleviate the influence of adversarial perturbations while\npreserving essential semantic information, thereby conferring an inherent\nadvantage in defending against adversarial attacks. To validate this concept,\nwe present a comprehensive study on leveraging image resampling to defend\nagainst adversarial attacks. We have developed basic resampling methods that\nemploy interpolation strategies and coordinate shifting magnitudes. Our\nanalysis reveals that these basic methods can partially mitigate adversarial\nattacks. However, they come with apparent limitations: the accuracy of clean\nimages noticeably decreases, while the improvement in accuracy on adversarial\nexamples is not substantial. We propose implicit representation-driven image\nresampling (IRAD) to overcome these limitations. First, we construct an\nimplicit continuous representation that enables us to represent any input image\nwithin a continuous coordinate space. Second, we introduce SampleNet, which\nautomatically generates pixel-wise shifts for resampling in response to\ndifferent inputs. Furthermore, we can extend our approach to the\nstate-of-the-art diffusion-based method, accelerating it with fewer time steps\nwhile preserving its defense capability. Extensive experiments demonstrate that\nour method significantly enhances the adversarial robustness of diverse deep\nmodels against various attacks while maintaining high accuracy on clean images.",
        "updated": "2024-04-13T14:57:15Z",
        "published": "2023-10-18T11:19:32Z",
        "authors": [
            "Yue Cao",
            "Tianlin Li",
            "Xiaofeng Cao",
            "Ivor Tsang",
            "Yang Liu",
            "Qing Guo"
        ],
        "categories": [
            "cs.CV"
        ],
        "primary_category": "cs.CV"
    },
    "2310.12058v2": {
        "url": "http://arxiv.org/abs/2310.12058v2",
        "title": "HIFuzz: Human Interaction Fuzzing for small Unmanned Aerial Vehicles",
        "summary": "Small Unmanned Aerial Systems (sUAS) must meet rigorous safety standards when\ndeployed in high-stress emergency response scenarios; however many reported\naccidents have involved humans in the loop. In this paper, we, therefore,\npresent the HiFuzz testing framework, which uses fuzz testing to identify\nsystem vulnerabilities associated with human interactions. HiFuzz includes\nthree distinct levels that progress from a low-cost, limited-fidelity,\nlarge-scale, no-hazard environment, using fully simulated Proxy Human Agents,\nvia an intermediate level, where proxy humans are replaced with real humans, to\na high-stakes, high-cost, real-world environment. Through applying HiFuzz to an\nautonomous multi-sUAS system-under-test, we show that each test level serves a\nunique purpose in revealing vulnerabilities and making the system more robust\nwith respect to human mistakes. While HiFuzz is designed for testing sUAS\nsystems, we further discuss its potential for use in other Cyber-Physical\nSystems.",
        "updated": "2024-04-07T05:02:07Z",
        "published": "2023-10-18T15:46:12Z",
        "authors": [
            "Theodore Chambers",
            "Michael Vierhauser",
            "Ankit Agrawal",
            "Michael Murphy",
            "Jason Matthew Brauer",
            "Salil Purandare",
            "Myra B. Cohen",
            "Jane Cleland-Huang"
        ],
        "categories": [
            "cs.HC"
        ],
        "primary_category": "cs.HC",
        "doi": "10.1145/3613904.3642958"
    },
    "2310.12079v2": {
        "url": "http://arxiv.org/abs/2310.12079v2",
        "title": "Differential Equation Scaling Limits of Shaped and Unshaped Neural\n  Networks",
        "summary": "Recent analyses of neural networks with shaped activations (i.e. the\nactivation function is scaled as the network size grows) have led to scaling\nlimits described by differential equations. However, these results do not a\npriori tell us anything about \"ordinary\" unshaped networks, where the\nactivation is unchanged as the network size grows. In this article, we find\nsimilar differential equation based asymptotic characterization for two types\nof unshaped networks.\n  Firstly, we show that the following two architectures converge to the same\ninfinite-depth-and-width limit at initialization: (i) a fully connected ResNet\nwith a $d^{-1/2}$ factor on the residual branch, where $d$ is the network\ndepth. (ii) a multilayer perceptron (MLP) with depth $d \\ll$ width $n$ and\nshaped ReLU activation at rate $d^{-1/2}$.\n  Secondly, for an unshaped MLP at initialization, we derive the first order\nasymptotic correction to the layerwise correlation. In particular, if\n$\\rho_\\ell$ is the correlation at layer $\\ell$, then $q_t = \\ell^2 (1 -\n\\rho_\\ell)$ with $t = \\frac{\\ell}{n}$ converges to an SDE with a singularity at\n$t=0$.\n  These results together provide a connection between shaped and unshaped\nnetwork architectures, and opens up the possibility of studying the effect of\nnormalization methods and how it connects with shaping activation functions.",
        "updated": "2024-04-18T19:07:49Z",
        "published": "2023-10-18T16:15:10Z",
        "authors": [
            "Mufan Bill Li",
            "Mihai Nica"
        ],
        "categories": [
            "stat.ML",
            "cs.LG"
        ],
        "primary_category": "stat.ML"
    },
    "2310.12362v2": {
        "url": "http://arxiv.org/abs/2310.12362v2",
        "title": "REMARK-LLM: A Robust and Efficient Watermarking Framework for Generative\n  Large Language Models",
        "summary": "We present REMARK-LLM, a novel efficient, and robust watermarking framework\ndesigned for texts generated by large language models (LLMs). Synthesizing\nhuman-like content using LLMs necessitates vast computational resources and\nextensive datasets, encapsulating critical intellectual property (IP). However,\nthe generated content is prone to malicious exploitation, including spamming\nand plagiarism. To address the challenges, REMARK-LLM proposes three new\ncomponents: (i) a learning-based message encoding module to infuse binary\nsignatures into LLM-generated texts; (ii) a reparameterization module to\ntransform the dense distributions from the message encoding to the sparse\ndistribution of the watermarked textual tokens; (iii) a decoding module\ndedicated for signature extraction; Furthermore, we introduce an optimized beam\nsearch algorithm to guarantee the coherence and consistency of the generated\ncontent. REMARK-LLM is rigorously trained to encourage the preservation of\nsemantic integrity in watermarked content, while ensuring effective watermark\nretrieval. Extensive evaluations on multiple unseen datasets highlight\nREMARK-LLM proficiency and transferability in inserting 2 times more signature\nbits into the same texts when compared to prior art, all while maintaining\nsemantic integrity. Furthermore, REMARK-LLM exhibits better resilience against\na spectrum of watermark detection and removal attacks.",
        "updated": "2024-04-08T00:16:46Z",
        "published": "2023-10-18T22:14:37Z",
        "authors": [
            "Ruisi Zhang",
            "Shehzeen Samarah Hussain",
            "Paarth Neekhara",
            "Farinaz Koushanfar"
        ],
        "comments": "accept to usenix security 2024",
        "categories": [
            "cs.CR",
            "cs.CL"
        ],
        "primary_category": "cs.CR"
    },
    "2310.12381v1": {
        "url": "http://arxiv.org/abs/2310.12381v1",
        "title": "VDKMS: Vehicular Decentralized Key Management System for Cellular\n  Vehicular-to-Everything Networks, A Blockchain-Based Approach",
        "summary": "The rapid development of intelligent transportation systems and connected\nvehicles has highlighted the need for secure and efficient key management\nsystems (KMS). In this paper, we introduce VDKMS (Vehicular Decentralized Key\nManagement System), a novel Decentralized Key Management System designed\nspecifically as an infrastructure for Cellular Vehicular-to-Everything (V2X)\nnetworks, utilizing a blockchain-based approach. The proposed VDKMS addresses\nthe challenges of secure communication, privacy preservation, and efficient key\nmanagement in V2X scenarios. It integrates blockchain technology,\nSelf-Sovereign Identity (SSI) principles, and Decentralized Identifiers (DIDs)\nto enable secure and trustworthy V2X applications among vehicles,\ninfrastructures, and networks. We first provide a comprehensive overview of the\nsystem architecture, components, protocols, and workflows, covering aspects\nsuch as provisioning, registration, verification, and authorization. We then\npresent a detailed performance evaluation, discussing the security properties\nand compatibility of the proposed solution, as well as a security analysis.\nFinally, we present potential applications in the vehicular ecosystem that can\nleverage the advantages of our approach.",
        "updated": "2023-10-18T23:14:34Z",
        "published": "2023-10-18T23:14:34Z",
        "authors": [
            "Wei Yao",
            "Yuhong Liu",
            "Fadi P. Deek",
            "Guiling Wang"
        ],
        "comments": "6 pages, 6 figures, accepted by IEEE Globecom 2023",
        "categories": [
            "cs.DC"
        ],
        "primary_category": "cs.DC",
        "doi": "10.1109/GLOBECOM54140.2023.10437245"
    },
    "2310.12451v1": {
        "url": "http://arxiv.org/abs/2310.12451v1",
        "title": "MTS-LOF: Medical Time-Series Representation Learning via\n  Occlusion-Invariant Features",
        "summary": "Medical time series data are indispensable in healthcare, providing critical\ninsights for disease diagnosis, treatment planning, and patient management. The\nexponential growth in data complexity, driven by advanced sensor technologies,\nhas presented challenges related to data labeling. Self-supervised learning\n(SSL) has emerged as a transformative approach to address these challenges,\neliminating the need for extensive human annotation. In this study, we\nintroduce a novel framework for Medical Time Series Representation Learning,\nknown as MTS-LOF. MTS-LOF leverages the strengths of contrastive learning and\nMasked Autoencoder (MAE) methods, offering a unique approach to representation\nlearning for medical time series data. By combining these techniques, MTS-LOF\nenhances the potential of healthcare applications by providing more\nsophisticated, context-rich representations. Additionally, MTS-LOF employs a\nmulti-masking strategy to facilitate occlusion-invariant feature learning. This\napproach allows the model to create multiple views of the data by masking\nportions of it. By minimizing the discrepancy between the representations of\nthese masked patches and the fully visible patches, MTS-LOF learns to capture\nrich contextual information within medical time series datasets. The results of\nexperiments conducted on diverse medical time series datasets demonstrate the\nsuperiority of MTS-LOF over other methods. These findings hold promise for\nsignificantly enhancing healthcare applications by improving representation\nlearning. Furthermore, our work delves into the integration of joint-embedding\nSSL and MAE techniques, shedding light on the intricate interplay between\ntemporal and structural dependencies in healthcare data. This understanding is\ncrucial, as it allows us to grasp the complexities of healthcare data analysis.",
        "updated": "2023-10-19T04:08:19Z",
        "published": "2023-10-19T04:08:19Z",
        "authors": [
            "Huayu Li",
            "Ana S. Carreon-Rascon",
            "Xiwen Chen",
            "Geng Yuan",
            "Ao Li"
        ],
        "categories": [
            "cs.LG",
            "cs.AI"
        ],
        "primary_category": "cs.LG",
        "doi": "10.1109/JBHI.2024.3373439"
    },
    "2310.12508v5": {
        "url": "http://arxiv.org/abs/2310.12508v5",
        "title": "SalUn: Empowering Machine Unlearning via Gradient-based Weight Saliency\n  in Both Image Classification and Generation",
        "summary": "With evolving data regulations, machine unlearning (MU) has become an\nimportant tool for fostering trust and safety in today's AI models. However,\nexisting MU methods focusing on data and/or weight perspectives often suffer\nlimitations in unlearning accuracy, stability, and cross-domain applicability.\nTo address these challenges, we introduce the concept of 'weight saliency' for\nMU, drawing parallels with input saliency in model explanation. This innovation\ndirects MU's attention toward specific model weights rather than the entire\nmodel, improving effectiveness and efficiency. The resultant method that we\ncall saliency unlearning (SalUn) narrows the performance gap with 'exact'\nunlearning (model retraining from scratch after removing the forgetting data\npoints). To the best of our knowledge, SalUn is the first principled MU\napproach that can effectively erase the influence of forgetting data, classes,\nor concepts in both image classification and generation tasks. As highlighted\nbelow, For example, SalUn yields a stability advantage in high-variance random\ndata forgetting, e.g., with a 0.2% gap compared to exact unlearning on the\nCIFAR-10 dataset. Moreover, in preventing conditional diffusion models from\ngenerating harmful images, SalUn achieves nearly 100% unlearning accuracy,\noutperforming current state-of-the-art baselines like Erased Stable Diffusion\nand Forget-Me-Not. Codes are available at\nhttps://github.com/OPTML-Group/Unlearn-Saliency. (WARNING: This paper contains\nmodel outputs that may be offensive in nature.)",
        "updated": "2024-04-04T07:45:38Z",
        "published": "2023-10-19T06:17:17Z",
        "authors": [
            "Chongyu Fan",
            "Jiancheng Liu",
            "Yihua Zhang",
            "Eric Wong",
            "Dennis Wei",
            "Sijia Liu"
        ],
        "comments": "Accepted by ICLR 2024 as a Spotlight paper",
        "categories": [
            "cs.LG",
            "cs.AI"
        ],
        "primary_category": "cs.LG"
    },
    "2311.12194v2": {
        "url": "http://arxiv.org/abs/2311.12194v2",
        "title": "DiffAvatar: Simulation-Ready Garment Optimization with Differentiable\n  Simulation",
        "summary": "The realism of digital avatars is crucial in enabling telepresence\napplications with self-expression and customization. While physical simulations\ncan produce realistic motions for clothed humans, they require high-quality\ngarment assets with associated physical parameters for cloth simulations.\nHowever, manually creating these assets and calibrating their parameters is\nlabor-intensive and requires specialized expertise. Current methods focus on\nreconstructing geometry, but don't generate complete assets for physics-based\napplications. To address this gap, we propose \\papername,~a novel approach that\nperforms body and garment co-optimization using differentiable simulation. By\nintegrating physical simulation into the optimization loop and accounting for\nthe complex nonlinear behavior of cloth and its intricate interaction with the\nbody, our framework recovers body and garment geometry and extracts important\nmaterial parameters in a physically plausible way. Our experiments demonstrate\nthat our approach generates realistic clothing and body shape suitable for\ndownstream applications. We provide additional insights and results on our\nwebpage: https://people.csail.mit.edu/liyifei/publication/diffavatar/",
        "updated": "2024-03-29T19:37:18Z",
        "published": "2023-11-20T21:20:37Z",
        "authors": [
            "Yifei Li",
            "Hsiao-yu Chen",
            "Egor Larionov",
            "Nikolaos Sarafianos",
            "Wojciech Matusik",
            "Tuur Stuyck"
        ],
        "comments": "CVPR 2024; Project page:\n  https://people.csail.mit.edu/liyifei/publication/diffavatar/",
        "categories": [
            "cs.CV"
        ],
        "primary_category": "cs.CV"
    },
    "2311.12198v3": {
        "url": "http://arxiv.org/abs/2311.12198v3",
        "title": "PhysGaussian: Physics-Integrated 3D Gaussians for Generative Dynamics",
        "summary": "We introduce PhysGaussian, a new method that seamlessly integrates physically\ngrounded Newtonian dynamics within 3D Gaussians to achieve high-quality novel\nmotion synthesis. Employing a custom Material Point Method (MPM), our approach\nenriches 3D Gaussian kernels with physically meaningful kinematic deformation\nand mechanical stress attributes, all evolved in line with continuum mechanics\nprinciples. A defining characteristic of our method is the seamless integration\nbetween physical simulation and visual rendering: both components utilize the\nsame 3D Gaussian kernels as their discrete representations. This negates the\nnecessity for triangle/tetrahedron meshing, marching cubes, \"cage meshes,\" or\nany other geometry embedding, highlighting the principle of \"what you see is\nwhat you simulate (WS$^2$).\" Our method demonstrates exceptional versatility\nacross a wide variety of materials--including elastic entities, metals,\nnon-Newtonian fluids, and granular materials--showcasing its strong\ncapabilities in creating diverse visual content with novel viewpoints and\nmovements. Our project page is at: https://xpandora.github.io/PhysGaussian/",
        "updated": "2024-04-15T06:04:55Z",
        "published": "2023-11-20T21:34:52Z",
        "authors": [
            "Tianyi Xie",
            "Zeshun Zong",
            "Yuxing Qiu",
            "Xuan Li",
            "Yutao Feng",
            "Yin Yang",
            "Chenfanfu Jiang"
        ],
        "comments": "Accepted by CVPR 2024",
        "categories": [
            "cs.GR",
            "cs.AI",
            "cs.CV",
            "cs.LG"
        ],
        "primary_category": "cs.GR"
    },
    "2311.12229v2": {
        "url": "http://arxiv.org/abs/2311.12229v2",
        "title": "NeuroPrompts: An Adaptive Framework to Optimize Prompts for\n  Text-to-Image Generation",
        "summary": "Despite impressive recent advances in text-to-image diffusion models,\nobtaining high-quality images often requires prompt engineering by humans who\nhave developed expertise in using them. In this work, we present NeuroPrompts,\nan adaptive framework that automatically enhances a user's prompt to improve\nthe quality of generations produced by text-to-image models. Our framework\nutilizes constrained text decoding with a pre-trained language model that has\nbeen adapted to generate prompts similar to those produced by human prompt\nengineers. This approach enables higher-quality text-to-image generations and\nprovides user control over stylistic features via constraint set specification.\nWe demonstrate the utility of our framework by creating an interactive\napplication for prompt enhancement and image generation using Stable Diffusion.\nAdditionally, we conduct experiments utilizing a large dataset of\nhuman-engineered prompts for text-to-image generation and show that our\napproach automatically produces enhanced prompts that result in superior image\nquality. We make our code and a screencast video demo of NeuroPrompts publicly\navailable.",
        "updated": "2024-04-06T00:17:01Z",
        "published": "2023-11-20T22:57:47Z",
        "authors": [
            "Shachar Rosenman",
            "Vasudev Lal",
            "Phillip Howard"
        ],
        "comments": "Accepted to EACL 2024 System Demonstration Track",
        "categories": [
            "cs.AI"
        ],
        "primary_category": "cs.AI"
    },
    "2311.12268v2": {
        "url": "http://arxiv.org/abs/2311.12268v2",
        "title": "Boosting Audio-visual Zero-shot Learning with Large Language Models",
        "summary": "Audio-visual zero-shot learning aims to recognize unseen classes based on\npaired audio-visual sequences. Recent methods mainly focus on learning\nmulti-modal features aligned with class names to enhance the generalization\nability to unseen categories. However, these approaches ignore the obscure\nevent concepts in class names and may inevitably introduce complex network\nstructures with difficult training objectives. In this paper, we introduce a\nstraightforward yet efficient framework called KnowleDge-Augmented audio-visual\nlearning (KDA), which aids the model in more effectively learning novel event\ncontent by leveraging an external knowledge base. Specifically, we first\npropose to utilize the knowledge contained in large language models (LLMs) to\ngenerate numerous descriptive sentences that include important distinguishing\naudio-visual features of event classes, which helps to better understand unseen\ncategories. Furthermore, we propose a knowledge-aware adaptive margin loss to\nhelp distinguish similar events, further improving the generalization ability\ntowards unseen classes. Extensive experimental results demonstrate that our\nproposed KDA can outperform state-of-the-art methods on three popular\naudio-visual zero-shot learning datasets.Our code will be avaliable at\n\\url{https://github.com/chenhaoxing/KDA}.",
        "updated": "2024-04-24T07:57:40Z",
        "published": "2023-11-21T01:18:23Z",
        "authors": [
            "Haoxing Chen",
            "Yaohui Li",
            "Yan Hong",
            "Zizheng Huang",
            "Zhuoer Xu",
            "Zhangxuan Gu",
            "Jun Lan",
            "Huijia Zhu",
            "Weiqiang Wang"
        ],
        "categories": [
            "cs.CV"
        ],
        "primary_category": "cs.CV"
    },
    "2311.12275v4": {
        "url": "http://arxiv.org/abs/2311.12275v4",
        "title": "Enabling On-Device Large Language Model Personalization with\n  Self-Supervised Data Selection and Synthesis",
        "summary": "After a large language model (LLM) is deployed on edge devices, it is\ndesirable for these devices to learn from user-generated conversation data to\ngenerate user-specific and personalized responses in real-time. However,\nuser-generated data usually contains sensitive and private information, and\nuploading such data to the cloud for annotation is not preferred if not\nprohibited. While it is possible to obtain annotation locally by directly\nasking users to provide preferred responses, such annotations have to be sparse\nto not affect user experience. In addition, the storage of edge devices is\nusually too limited to enable large-scale fine-tuning with full user-generated\ndata. It remains an open question how to enable on-device LLM personalization,\nconsidering sparse annotation and limited on-device storage. In this paper, we\npropose a novel framework to select and store the most representative data\nonline in a self-supervised way. Such data has a small memory footprint and\nallows infrequent requests of user annotations for further fine-tuning. To\nenhance fine-tuning quality, multiple semantically similar pairs of question\ntexts and expected responses are generated using the LLM. Our experiments show\nthat the proposed framework achieves the best user-specific content-generating\ncapability (accuracy) and fine-tuning speed (performance) compared with vanilla\nbaselines. To the best of our knowledge, this is the very first on-device LLM\npersonalization framework.",
        "updated": "2024-04-16T21:34:29Z",
        "published": "2023-11-21T01:34:02Z",
        "authors": [
            "Ruiyang Qin",
            "Jun Xia",
            "Zhenge Jia",
            "Meng Jiang",
            "Ahmed Abbasi",
            "Peipei Zhou",
            "Jingtong Hu",
            "Yiyu Shi"
        ],
        "comments": "Accepted by 2024 61th ACM/IEEE Design Automation Conference (DAC)",
        "categories": [
            "cs.CL"
        ],
        "primary_category": "cs.CL",
        "doi": "10.1145/3649329.3655665"
    },
    "2311.12304v5": {
        "url": "http://arxiv.org/abs/2311.12304v5",
        "title": "Discovering Effective Policies for Land-Use Planning with Neuroevolution",
        "summary": "How areas of land are allocated for different uses, such as forests, urban\nareas, and agriculture, has a large effect on the terrestrial carbon balance,\nand therefore climate change. Based on available historical data on land-use\nchanges and a simulation of the associated carbon emissions and removals, a\nsurrogate model can be learned that makes it possible to evaluate the different\noptions available to decision-makers efficiently. An evolutionary search\nprocess can then be used to discover effective land-use policies for specific\nlocations. Such a system was built on the Project Resilience platform and\nevaluated with the Land-Use Harmonization dataset LUH2 and the bookkeeping\nmodel BLUE. It generates Pareto fronts that trade off carbon impact and amount\nof land-use change customized to different locations, thus providing a\npotentially useful tool for land-use planning.",
        "updated": "2024-04-02T03:35:02Z",
        "published": "2023-11-21T02:46:14Z",
        "authors": [
            "Risto Miikkulainen",
            "Olivier Francon",
            "Daniel Young",
            "Elliot Meyerson",
            "Clemens Schwingshackl",
            "Jacob Bieker",
            "Hugo Cunha",
            "Babak Hodjat"
        ],
        "categories": [
            "cs.NE",
            "cs.AI",
            "cs.LG"
        ],
        "primary_category": "cs.NE"
    },
    "2311.12327v2": {
        "url": "http://arxiv.org/abs/2311.12327v2",
        "title": "Enhancing Visual Grounding and Generalization: A Multi-Task Cycle\n  Training Approach for Vision-Language Models",
        "summary": "Visual grounding (VG) occupies a pivotal position in multi-modality\nvision-language models. In this study, we propose ViLaM, a large multi-modality\nmodel, that supports multi-tasks of VG using the cycle training strategy, with\nabundant interaction instructions. The cycle training between referring\nexpression generation (REG) and referring expression comprehension (REC) is\nintroduced. It enhances the consistency between visual location and referring\nexpressions, and addresses the need for high-quality, multi-tasks VG datasets.\nMoreover, multi-tasks of VG are promoted in our model, contributed by the cycle\ntraining strategy. The multi-tasks in REC encompass a range of granularities,\nfrom region-level to pixel-level, which include referring bbox detection,\nreferring keypoints detection, and referring image segmentation. In REG,\nreferring region classification determines the fine-grained category of the\ntarget, while referring region captioning generates a comprehensive\ndescription. Meanwhile, all tasks participate in the joint training,\nsynergistically enhancing one another and collectively improving the overall\nperformance of the model. Furthermore, leveraging the capabilities of large\nlanguage models, ViLaM extends a wide range of instructions, thereby\nsignificantly enhancing its generalization and interaction potentials.\nExtensive public datasets corroborate the superior capabilities of our model in\nVG with muti-tasks. Additionally, validating its robust generalization, ViLaM\nis validated under open-set and few-shot scenarios. Especially in the medical\nfield, our model demonstrates cross-domain robust generalization capabilities.\nFurthermore, we contribute a VG dataset, especially with multi-tasks. To\nsupport and encourage the community focused on VG, we have made both the\ndataset and our code public: https://github.com/AnonymGiant/ViLaM.",
        "updated": "2024-04-26T01:50:55Z",
        "published": "2023-11-21T03:40:09Z",
        "authors": [
            "Xiaoyu Yang",
            "Lijian Xu",
            "Hao Sun",
            "Hongsheng Li",
            "Shaoting Zhang"
        ],
        "comments": "22 pages",
        "categories": [
            "cs.CV"
        ],
        "primary_category": "cs.CV"
    },
    "2311.12399v4": {
        "url": "http://arxiv.org/abs/2311.12399v4",
        "title": "A Survey of Graph Meets Large Language Model: Progress and Future\n  Directions",
        "summary": "Graph plays a significant role in representing and analyzing complex\nrelationships in real-world applications such as citation networks, social\nnetworks, and biological data. Recently, Large Language Models (LLMs), which\nhave achieved tremendous success in various domains, have also been leveraged\nin graph-related tasks to surpass traditional Graph Neural Networks (GNNs)\nbased methods and yield state-of-the-art performance. In this survey, we first\npresent a comprehensive review and analysis of existing methods that integrate\nLLMs with graphs. First of all, we propose a new taxonomy, which organizes\nexisting methods into three categories based on the role (i.e., enhancer,\npredictor, and alignment component) played by LLMs in graph-related tasks. Then\nwe systematically survey the representative methods along the three categories\nof the taxonomy. Finally, we discuss the remaining limitations of existing\nstudies and highlight promising avenues for future research. The relevant\npapers are summarized and will be consistently updated at:\nhttps://github.com/yhLeeee/Awesome-LLMs-in-Graph-tasks.",
        "updated": "2024-04-24T08:48:13Z",
        "published": "2023-11-21T07:22:48Z",
        "authors": [
            "Yuhan Li",
            "Zhixun Li",
            "Peisong Wang",
            "Jia Li",
            "Xiangguo Sun",
            "Hong Cheng",
            "Jeffrey Xu Yu"
        ],
        "comments": "IJCAI 2024 Survey Track",
        "categories": [
            "cs.LG",
            "cs.CL",
            "cs.SI"
        ],
        "primary_category": "cs.LG"
    },
    "2311.12539v2": {
        "url": "http://arxiv.org/abs/2311.12539v2",
        "title": "GMISeg: General Medical Image Segmentation without Re-Training",
        "summary": "Although deep learning models have become the main method for medical image\nsegmentation, they often cannot be extended to unknown segmentation tasks\ninvolving new anatomical structures, image shapes, or labels. For new\nsegmentation tasks, researchers often have to retrain or fine-tune the model,\nwhich is time-consuming and poses a significant obstacle to clinical\nresearchers, who often lack the resources and professional knowledge to train\nneural networks. Therefore, we proposed a general method that can solve unknown\nmedical image segmentation tasks without requiring additional training. Given\nan example set of images and prompts for defining new segmentation tasks,\nGMISeg applies a novel low-rank fine-tuning strategy based on the proposed\napproach to the SAM (Segment Anything Model) image encoder, and works with the\nprompt encoder and mask decoder to fine-tune the labeled dataset without the\nneed for additional training. To achieve generalization of new tasks, we used\nmedical image datasets with different imaging modes for different parts. We\ntrained and generalized GMISeg on a different set of anatomical and imaging\nmodes using cardiac images on other site datasets. We have demonstrated that\nGMISeg outperforms the latest methods on unknown tasks and have conducted a\ncomprehensive analysis and summary of the important performance of the proposed\nmethod.",
        "updated": "2024-04-08T22:19:23Z",
        "published": "2023-11-21T11:33:15Z",
        "authors": [
            "Jing Xu"
        ],
        "categories": [
            "eess.IV",
            "cs.CV"
        ],
        "primary_category": "eess.IV"
    },
    "2311.12554v3": {
        "url": "http://arxiv.org/abs/2311.12554v3",
        "title": "Multiscale interpolative construction of quantized tensor trains",
        "summary": "Quantized tensor trains (QTTs) have recently emerged as a framework for the\nnumerical discretization of continuous functions, with the potential for\nwidespread applications in numerical analysis. However, the theory of QTT\napproximation is not fully understood. In this work, we advance this theory\nfrom the point of view of multiscale polynomial interpolation. This perspective\nclarifies why QTT ranks decay with increasing depth, quantitatively controls\nQTT rank in terms of smoothness of the target function, and explains why\ncertain functions with sharp features and poor quantitative smoothness can\nstill be well approximated by QTTs. The perspective also motivates new\npractical and efficient algorithms for the construction of QTTs from function\nevaluations on multiresolution grids.",
        "updated": "2024-04-22T17:30:42Z",
        "published": "2023-11-21T12:07:09Z",
        "authors": [
            "Michael Lindsey"
        ],
        "categories": [
            "math.NA",
            "cs.NA"
        ],
        "primary_category": "math.NA"
    },
    "2312.11469v2": {
        "url": "http://arxiv.org/abs/2312.11469v2",
        "title": "An Algebraic Approach to the Longest Path Problem",
        "summary": "The Longest Path Problem is a question of finding the maximum length between\npairs of vertices of a graph. In the general case, the problem is NP-hard.\nHowever, there is a small collection of graph classes for which there exists an\nefficient solution. Current approaches involve either approximation or\ncomputational enumeration. For Tree-like classes of graphs, there are\napproximation and enumeration algorithms which solves the problem efficiently.\nWe propose a new method of approaching the longest path problem with algebraic\noperations and conditions that exactly identify and or approximate the solution\nin polynomial time. We next introduce a 'booleanize' mapping on the adjacency\nmatrix of a graph which we prove identifies the solution for trees, uniform\nblock graphs, block graphs, and directed acyclic graphs, with approached\nconditions. Finally, we display the algorithms to find the solution, in\naddition to algorithms that generate all the longest paths.",
        "updated": "2024-03-31T06:41:43Z",
        "published": "2023-11-14T07:03:49Z",
        "authors": [
            "Omar Al - Khazali"
        ],
        "comments": "Removed redundant algorithms. Summarized known definitions in the\n  Preliminaries section. Fixed references",
        "categories": [
            "cs.DS",
            "cs.DM",
            "math.CO"
        ],
        "primary_category": "cs.DS"
    },
    "2312.11489v3": {
        "url": "http://arxiv.org/abs/2312.11489v3",
        "title": "Agglomerative Federated Learning: Empowering Larger Model Training via\n  End-Edge-Cloud Collaboration",
        "summary": "Federated Learning (FL) enables training Artificial Intelligence (AI) models\nover end devices without compromising their privacy. As computing tasks are\nincreasingly performed by a combination of cloud, edge, and end devices, FL can\nbenefit from this End-Edge-Cloud Collaboration (EECC) paradigm to achieve\ncollaborative device-scale expansion with real-time access. Although\nHierarchical Federated Learning (HFL) supports multi-tier model aggregation\nsuitable for EECC, prior works assume the same model structure on all computing\nnodes, constraining the model scale by the weakest end devices. To address this\nissue, we propose Agglomerative Federated Learning (FedAgg), which is a novel\nEECC-empowered FL framework that allows the trained models from end, edge, to\ncloud to grow larger in size and stronger in generalization ability. FedAgg\nrecursively organizes computing nodes among all tiers based on Bridge Sample\nBased Online Distillation Protocol (BSBODP), which enables every pair of\nparent-child computing nodes to mutually transfer and distill knowledge\nextracted from generated bridge samples. This design enhances the performance\nby exploiting the potential of larger models, with privacy constraints of FL\nand flexibility requirements of EECC both satisfied. Experiments under various\nsettings demonstrate that FedAgg outperforms state-of-the-art methods by an\naverage of 4.53\\% accuracy gains and remarkable improvements in convergence\nrate.",
        "updated": "2024-04-29T05:09:37Z",
        "published": "2023-12-01T06:18:45Z",
        "authors": [
            "Zhiyuan Wu",
            "Sheng Sun",
            "Yuwei Wang",
            "Min Liu",
            "Bo Gao",
            "Quyang Pan",
            "Tianliu He",
            "Xuefeng Jiang"
        ],
        "comments": "Accepted by IEEE International Conference on Computer Communications\n  (INFOCOM), 2024",
        "categories": [
            "cs.DC",
            "cs.LG"
        ],
        "primary_category": "cs.DC"
    },
    "2312.11511v2": {
        "url": "http://arxiv.org/abs/2312.11511v2",
        "title": "ComplexityNet: Increasing LLM Inference Efficiency by Learning Task\n  Complexity",
        "summary": "We present ComplexityNet, a streamlined language model designed for assessing\ntask complexity. This model predicts the likelihood of accurate output by\nvarious language models, each with different capabilities. Our initial\napplication of ComplexityNet involves the Mostly Basic Python Problems (MBPP)\ndataset. We pioneered the creation of the first set of labels to define task\ncomplexity. ComplexityNet achieved a notable 79% accuracy in determining task\ncomplexity, a significant improvement over the 34% accuracy of the original,\nnon fine-tuned model. Furthermore, ComplexityNet effectively reduces\ncomputational resource usage by 90% compared to using the highest complexity\nmodel, while maintaining a high code generation accuracy of 86.7%. This study\ndemonstrates that fine-tuning smaller models to categorize tasks based on their\ncomplexity can lead to a more balanced trade-off between accuracy and\nefficiency in the use of Large Language Models. Our findings suggest a\npromising direction for optimizing LLM applications, especially in\nresource-constrained environments.",
        "updated": "2024-03-30T03:01:42Z",
        "published": "2023-12-12T05:38:55Z",
        "authors": [
            "Henry Bae",
            "Aghyad Deeb",
            "Alex Fleury",
            "Kehang Zhu"
        ],
        "categories": [
            "cs.CL",
            "cs.AI",
            "cs.LG"
        ],
        "primary_category": "cs.CL"
    },
    "2312.11517v3": {
        "url": "http://arxiv.org/abs/2312.11517v3",
        "title": "A Natural Language Processing-Based Classification and Mode-Based\n  Ranking of Musculoskeletal Disorder Risk Factors",
        "summary": "This research delves into Musculoskeletal Disorder (MSD) risk factors, using\na blend of Natural Language Processing (NLP) and mode-based ranking. The aim is\nto refine understanding, classification, and prioritization for focused\nprevention and treatment. Eight NLP models are evaluated, combining pre-trained\ntransformers, cosine similarity, and distance metrics to categorize factors\ninto personal, biomechanical, workplace, psychological, and organizational\nclasses. BERT with cosine similarity achieves 28% accuracy; sentence\ntransformer with Euclidean, Bray-Curtis, and Minkowski distances scores 100%.\nWith 10-fold cross-validation, statistical tests ensure robust results. Survey\ndata and mode-based ranking determine severity hierarchy, aligning with the\nliterature. \"Working posture\" is the most severe, highlighting posture's role.\nSurvey insights emphasize \"Job insecurity,\" \"Effort reward imbalance,\" and\n\"Poor employee facility\" as significant contributors. Rankings offer actionable\ninsights for MSD prevention. The study suggests targeted interventions,\nworkplace improvements, and future research directions. This integrated NLP and\nranking approach enhances MSD comprehension and informs occupational health\nstrategies.",
        "updated": "2024-03-30T21:14:37Z",
        "published": "2023-12-12T19:34:23Z",
        "authors": [
            "Md Abrar Jahin",
            "Subrata Talapatra"
        ],
        "categories": [
            "cs.CL",
            "cs.LG"
        ],
        "primary_category": "cs.CL"
    },
    "2312.11569v1": {
        "url": "http://arxiv.org/abs/2312.11569v1",
        "title": "Application of AI in Nutrition",
        "summary": "In healthcare, artificial intelligence (AI) has been changing the way doctors\nand health experts take care of people. This paper will cover how AI is making\nmajor changes in the health care system, especially with nutrition. Various\nmachine learning and deep learning algorithms have been developed to extract\nvaluable information from healthcare data which help doctors, nutritionists,\nand health experts to make better decisions and make our lifestyle healthy.\nThis paper provides an overview of the current state of AI applications in\nhealthcare with a focus on the utilization of AI-driven recommender systems in\nnutrition. It will discuss the positive outcomes and challenges that arise when\nAI is used in this field. This paper addresses the challenges to develop AI\nrecommender systems in healthcare, providing a well-rounded perspective on the\ncomplexities. Real-world examples and research findings are presented to\nunderscore the tangible and significant impact AI recommender systems have in\nthe field of healthcare, particularly in nutrition. The ongoing efforts of\napplying AI in nutrition lay the groundwork for a future where personalized\nrecommendations play a pivotal role in guiding individuals toward healthier\nlifestyles.",
        "updated": "2023-12-18T04:37:45Z",
        "published": "2023-12-18T04:37:45Z",
        "authors": [
            "Ritu Ramakrishnan",
            "Tianxiang Xing",
            "Tianfeng Chen",
            "Ming-Hao Lee",
            "Jinzhu Gao"
        ],
        "categories": [
            "cs.HC",
            "cs.IR"
        ],
        "primary_category": "cs.HC",
        "doi": "10.5281/zenodo.10500601",
        "journal_ref": "Journal of Advances in Information Science and Technology, Volume\n  1, Issue 1, 2023, Pages 7-12"
    },
    "2312.11575v2": {
        "url": "http://arxiv.org/abs/2312.11575v2",
        "title": "Blind-Touch: Homomorphic Encryption-Based Distributed Neural Network\n  Inference for Privacy-Preserving Fingerprint Authentication",
        "summary": "Fingerprint authentication is a popular security mechanism for smartphones\nand laptops. However, its adoption in web and cloud environments has been\nlimited due to privacy concerns over storing and processing biometric data on\nservers. This paper introduces Blind-Touch, a novel machine learning-based\nfingerprint authentication system leveraging homomorphic encryption to address\nthese privacy concerns. Homomorphic encryption allows computations on encrypted\ndata without decrypting. Thus, Blind-Touch can keep fingerprint data encrypted\non the server while performing machine learning operations. Blind-Touch\ncombines three strategies to efficiently utilize homomorphic encryption in\nmachine learning: (1) It optimizes the feature vector for a distributed\narchitecture, processing the first fully connected layer (FC-16) in plaintext\non the client side and the subsequent layer (FC-1) post-encryption on the\nserver, thereby minimizing encrypted computations; (2) It employs a homomorphic\nencryption compatible data compression technique capable of handling 8,192\nauthentication results concurrently; and (3) It utilizes a clustered server\narchitecture to simultaneously process authentication results, thereby\nenhancing scalability with increasing user numbers. Blind-Touch achieves high\naccuracy on two benchmark fingerprint datasets, with a 93.6% F1- score for the\nPolyU dataset and a 98.2% F1-score for the SOKOTO dataset. Moreover,\nBlind-Touch can match a fingerprint among 5,000 in about 0.65 seconds. With its\nprivacy focused design, high accuracy, and efficiency, Blind-Touch is a\npromising alternative to conventional fingerprint authentication for web and\ncloud applications.",
        "updated": "2024-04-01T13:15:29Z",
        "published": "2023-12-18T09:05:34Z",
        "authors": [
            "Hyunmin Choi",
            "Simon Woo",
            "Hyoungshick Kim"
        ],
        "comments": "The 38th Annual AAAI Conference on Artificial Intelligence (AAAI)\n  2024",
        "categories": [
            "cs.CR"
        ],
        "primary_category": "cs.CR",
        "doi": "10.1609/aaai.v38i20.30200"
    },
    "2312.11713v2": {
        "url": "http://arxiv.org/abs/2312.11713v2",
        "title": "Indoor and Outdoor 3D Scene Graph Generation via Language-Enabled\n  Spatial Ontologies",
        "summary": "This paper proposes an approach to build 3D scene graphs in arbitrary indoor\nand outdoor environments. Such extension is challenging; the hierarchy of\nconcepts that describe an outdoor environment is more complex than for indoors,\nand manually defining such hierarchy is time-consuming and does not scale.\nFurthermore, the lack of training data prevents the straightforward application\nof learning-based tools used in indoor settings. To address these challenges,\nwe propose two novel extensions. First, we develop methods to build a spatial\nontology defining concepts and relations relevant for indoor and outdoor robot\noperation. In particular, we use a Large Language Model (LLM) to build such an\nontology, thus largely reducing the amount of manual effort required. Second,\nwe leverage the spatial ontology for 3D scene graph construction using Logic\nTensor Networks (LTN) to add logical rules, or axioms (e.g., \"a beach contains\nsand\"), which provide additional supervisory signals at training time thus\nreducing the need for labelled data, providing better predictions, and even\nallowing predicting concepts unseen at training time. We test our approach in a\nvariety of datasets, including indoor, rural, and coastal environments, and\nshow that it leads to a significant increase in the quality of the 3D scene\ngraph generation with sparsely annotated data.",
        "updated": "2024-04-24T21:57:57Z",
        "published": "2023-12-18T21:20:28Z",
        "authors": [
            "Jared Strader",
            "Nathan Hughes",
            "William Chen",
            "Alberto Speranzon",
            "Luca Carlone"
        ],
        "comments": "10 pages, 6 figures, accepted to Robotics and Automation Letters",
        "categories": [
            "cs.RO",
            "cs.AI"
        ],
        "primary_category": "cs.RO"
    },
    "2312.11779v3": {
        "url": "http://arxiv.org/abs/2312.11779v3",
        "title": "Tokenization Matters: Navigating Data-Scarce Tokenization for Gender\n  Inclusive Language Technologies",
        "summary": "Gender-inclusive NLP research has documented the harmful limitations of\ngender binary-centric large language models (LLM), such as the inability to\ncorrectly use gender-diverse English neopronouns (e.g., xe, zir, fae). While\ndata scarcity is a known culprit, the precise mechanisms through which scarcity\naffects this behavior remain underexplored. We discover LLM misgendering is\nsignificantly influenced by Byte-Pair Encoding (BPE) tokenization, the\ntokenizer powering many popular LLMs. Unlike binary pronouns, BPE overfragments\nneopronouns, a direct consequence of data scarcity during tokenizer training.\nThis disparate tokenization mirrors tokenizer limitations observed in\nmultilingual and low-resource NLP, unlocking new misgendering mitigation\nstrategies. We propose two techniques: (1) pronoun tokenization parity, a\nmethod to enforce consistent tokenization across gendered pronouns, and (2)\nutilizing pre-existing LLM pronoun knowledge to improve neopronoun proficiency.\nOur proposed methods outperform finetuning with standard BPE, improving\nneopronoun accuracy from 14.1% to 58.4%. Our paper is the first to link LLM\nmisgendering to tokenization and deficient neopronoun grammar, indicating that\nLLMs unable to correctly treat neopronouns as pronouns are more prone to\nmisgender.",
        "updated": "2024-04-06T09:32:53Z",
        "published": "2023-12-19T01:28:46Z",
        "authors": [
            "Anaelia Ovalle",
            "Ninareh Mehrabi",
            "Palash Goyal",
            "Jwala Dhamala",
            "Kai-Wei Chang",
            "Richard Zemel",
            "Aram Galstyan",
            "Yuval Pinter",
            "Rahul Gupta"
        ],
        "comments": "Accepted to NAACL 2024 findings",
        "categories": [
            "cs.CL",
            "cs.AI",
            "cs.LG"
        ],
        "primary_category": "cs.CL"
    },
    "2312.11782v2": {
        "url": "http://arxiv.org/abs/2312.11782v2",
        "title": "Learning Object State Changes in Videos: An Open-World Perspective",
        "summary": "Object State Changes (OSCs) are pivotal for video understanding. While humans\ncan effortlessly generalize OSC understanding from familiar to unknown objects,\ncurrent approaches are confined to a closed vocabulary. Addressing this gap, we\nintroduce a novel open-world formulation for the video OSC problem. The goal is\nto temporally localize the three stages of an OSC -- the object's initial\nstate, its transitioning state, and its end state -- whether or not the object\nhas been observed during training. Towards this end, we develop VidOSC, a\nholistic learning approach that: (1) leverages text and vision-language models\nfor supervisory signals to obviate manually labeling OSC training data, and (2)\nabstracts fine-grained shared state representations from objects to enhance\ngeneralization. Furthermore, we present HowToChange, the first open-world\nbenchmark for video OSC localization, which offers an order of magnitude\nincrease in the label space and annotation volume compared to the best existing\nbenchmark. Experimental results demonstrate the efficacy of our approach, in\nboth traditional closed-world and open-world scenarios.",
        "updated": "2024-04-03T16:57:35Z",
        "published": "2023-12-19T01:33:46Z",
        "authors": [
            "Zihui Xue",
            "Kumar Ashutosh",
            "Kristen Grauman"
        ],
        "comments": "Accepted by CVPR 2024, Project website:\n  https://vision.cs.utexas.edu/projects/VidOSC/",
        "categories": [
            "cs.CV"
        ],
        "primary_category": "cs.CV"
    },
    "2312.11793v2": {
        "url": "http://arxiv.org/abs/2312.11793v2",
        "title": "An Effective Image Copy-Move Forgery Detection Using Entropy Information",
        "summary": "Image forensics has become increasingly crucial in our daily lives. Among\nvarious types of forgeries, copy-move forgery detection has received\nconsiderable attention within the academic community. Keypoint-based\nalgorithms, particularly those based on Scale Invariant Feature Transform, have\nachieved promising outcomes. However, most of keypoint detection algorithms\nfailed to generate sufficient matches when tampered patches were occurred in\nsmooth areas, leading to insufficient matches. Therefore, this paper introduces\nentropy images to determine the coordinates and scales of keypoints based on\nScale Invariant Feature Transform detector, which make the pre-processing more\nsuitable for solving the above problems. Furthermore, an overlapped entropy\nlevel clustering algorithm is developed to mitigate the increased matching\ncomplexity caused by the non-ideal distribution of gray values in keypoints.\nExperimental results demonstrate that our algorithm achieves a good balance\nbetween performance and time efficiency.",
        "updated": "2024-04-30T04:38:53Z",
        "published": "2023-12-19T02:09:38Z",
        "authors": [
            "Li Jiang",
            "Zhaowei Lu"
        ],
        "categories": [
            "cs.CV",
            "cs.CY",
            "cs.MM"
        ],
        "primary_category": "cs.CV"
    },
    "2401.15656v3": {
        "url": "http://arxiv.org/abs/2401.15656v3",
        "title": "LLsM: Generative Linguistic Steganography with Large Language Model",
        "summary": "Linguistic Steganography (LS) tasks aim to generate steganographic text\n(stego) based on secret information. Only authorized recipients can perceive\nthe existence of the stegos and extract secrets, thereby preserving privacy.\nHowever, existing LS methods do not consider the controllable generation of\nstegos containing specific discourses such as style, genre, and theme. And they\nare difficult to simulate high-quality natural texts. As a result, the stegos\nare easily perceived and detectable, compromising covert communication. This\npaper proposes the LLsM, the first LS work with the Large Language Model (LLM).\nRegarding open-source LLMs, we reconstruct the token generator of LLM to the\n\"stego generator\" so that it can control the generation of stego based on the\nsecret. In this \"stego generator\", the candidate pool is encoded by range\ncoding, and the adjustment factor for the interval length is also given. The\nsecret determines the interval, thereby determining the next token. This better\nsimulates the distribution of natural texts and controls the adjustment of the\nembedding rate. In addition, we preliminarily built an LLsM-c architecture for\nclosed-source LLMs. It encodes discourse to obtain high-quality prompts\ncontaining discourse based on secrets, and generates pure natural texts\ncontaining discourse. Experiments show that LLsM performs superior to prevalent\nLS and related-task baselines regarding various kinds of concealment and\nanti-steganalysis. LLsM's MAUVE surpasses baselines by 60%-80% and\nanti-steganalysis exceeds baselines by 20%-30%. Notably, LLsM can also generate\nlonger stegos with high quality, showing its advantages in understanding and\ncoherence.",
        "updated": "2024-04-08T03:50:39Z",
        "published": "2024-01-28T13:21:44Z",
        "authors": [
            "Yihao Wang",
            "Ruiqi Song",
            "Ru Zhang",
            "Jianyi Liu",
            "Lingxiao Li"
        ],
        "comments": "13 pages",
        "categories": [
            "cs.CL"
        ],
        "primary_category": "cs.CL"
    },
    "2401.15661v2": {
        "url": "http://arxiv.org/abs/2401.15661v2",
        "title": "Brain-Inspired Physics-Informed Neural Networks: Bare-Minimum Neural\n  Architectures for PDE Solvers",
        "summary": "Physics-Informed Neural Networks (PINNs) have emerged as a powerful tool for\nsolving partial differential equations~(PDEs) in various scientific and\nengineering domains. However, traditional PINN architectures typically rely on\nlarge, fully connected multilayer perceptrons~(MLPs), lacking the sparsity and\nmodularity inherent in many traditional numerical solvers. An unsolved and\ncritical question for PINN is: What is the minimum PINN complexity regarding\nnodes, layers, and connections needed to provide acceptable performance? To\naddress this question, this study investigates a novel approach by merging\nestablished PINN methodologies with brain-inspired neural network techniques.\nWe use Brain-Inspired Modular Training~(BIMT), leveraging concepts such as\nlocality, sparsity, and modularity inspired by the organization of the brain.\nWith brain-inspired PINN, we demonstrate the evolution of PINN architectures\nfrom large, fully connected structures to bare-minimum, compact MLP\narchitectures, often consisting of a few neural units!\n  Moreover, using brain-inspired PINN, we showcase the spectral bias phenomenon\noccurring on the PINN architectures: bare-minimum architectures solving\nproblems with high-frequency components require more neural units than PINN\nsolving low-frequency problems. Finally, we derive basic PINN building blocks\nthrough BIMT training on simple problems akin to convolutional and attention\nmodules in deep neural networks, enabling the construction of modular PINN\narchitectures. Our experiments show that brain-inspired PINN training leads to\nPINN architectures that minimize the computing and memory resources yet provide\naccurate results.",
        "updated": "2024-04-19T16:17:23Z",
        "published": "2024-01-28T13:48:21Z",
        "authors": [
            "Stefano Markidis"
        ],
        "comments": "Accepted at the 24th International Conference on Computational\n  Science (ICCS)",
        "categories": [
            "cs.CE"
        ],
        "primary_category": "cs.CE"
    },
    "2401.15663v2": {
        "url": "http://arxiv.org/abs/2401.15663v2",
        "title": "Low-resolution Prior Equilibrium Network for CT Reconstruction",
        "summary": "The unrolling method has been investigated for learning variational models in\nX-ray computed tomography. However, it has been observed that directly\nunrolling the regularization model through gradient descent does not produce\nsatisfactory results. In this paper, we present a novel deep learning-based CT\nreconstruction model, where the low-resolution image is introduced to obtain an\neffective regularization term for improving the network`s robustness. Our\napproach involves constructing the backbone network architecture by algorithm\nunrolling that is realized using the deep equilibrium architecture. We\ntheoretically discuss the convergence of the proposed low-resolution prior\nequilibrium model and provide the conditions to guarantee convergence.\nExperimental results on both sparse-view and limited-angle reconstruction\nproblems are provided, demonstrating that our end-to-end low-resolution prior\nequilibrium model outperforms other state-of-the-art methods in terms of noise\nreduction, contrast-to-noise ratio, and preservation of edge details.",
        "updated": "2024-04-18T10:48:15Z",
        "published": "2024-01-28T13:59:58Z",
        "authors": [
            "Yijie Yang",
            "Qifeng Gao",
            "Yuping Duan"
        ],
        "categories": [
            "eess.IV",
            "cs.CV"
        ],
        "primary_category": "eess.IV"
    },
    "2401.15741v4": {
        "url": "http://arxiv.org/abs/2401.15741v4",
        "title": "SERNet-Former: Semantic Segmentation by Efficient Residual Network with\n  Attention-Boosting Gates and Attention-Fusion Networks",
        "summary": "Improving the efficiency of state-of-the-art methods in semantic segmentation\nrequires overcoming the increasing computational cost as well as issues such as\nfusing semantic information from global and local contexts. Based on the recent\nsuccess and problems that convolutional neural networks (CNNs) encounter in\nsemantic segmentation, this research proposes an encoder-decoder architecture\nwith a unique efficient residual network, Efficient-ResNet. Attention-boosting\ngates (AbGs) and attention-boosting modules (AbMs) are deployed by aiming to\nfuse the equivariant and feature-based semantic information with the equivalent\nsizes of the output of global context of the efficient residual network in the\nencoder. Respectively, the decoder network is developed with the additional\nattention-fusion networks (AfNs) inspired by AbM. AfNs are designed to improve\nthe efficiency in the one-to-one conversion of the semantic information by\ndeploying additional convolution layers in the decoder part. Our network is\ntested on the challenging CamVid and Cityscapes datasets, and the proposed\nmethods reveal significant improvements on the residual networks. To the best\nof our knowledge, the developed network, SERNet-Former, achieves\nstate-of-the-art results (84.62 % mean IoU) on CamVid dataset and challenging\nresults (87.35 % mean IoU) on Cityscapes validation dataset.",
        "updated": "2024-03-29T17:42:21Z",
        "published": "2024-01-28T19:58:19Z",
        "authors": [
            "Serdar Erisen"
        ],
        "categories": [
            "cs.CV",
            "cs.AI"
        ],
        "primary_category": "cs.CV",
        "doi": "10.48550/arXiv.2401.15741"
    },
    "2401.15770v3": {
        "url": "http://arxiv.org/abs/2401.15770v3",
        "title": "PILOT: Legal Case Outcome Prediction with Case Law",
        "summary": "Machine learning shows promise in predicting the outcome of legal cases, but\nmost research has concentrated on civil law cases rather than case law systems.\nWe identified two unique challenges in making legal case outcome predictions\nwith case law. First, it is crucial to identify relevant precedent cases that\nserve as fundamental evidence for judges during decision-making. Second, it is\nnecessary to consider the evolution of legal principles over time, as early\ncases may adhere to different legal contexts. In this paper, we proposed a new\nframework named PILOT (PredictIng Legal case OuTcome) for case outcome\nprediction. It comprises two modules for relevant case retrieval and temporal\npattern handling, respectively. To benchmark the performance of existing legal\ncase outcome prediction models, we curated a dataset from a large-scale case\nlaw database. We demonstrate the importance of accurately identifying precedent\ncases and mitigating the temporal shift when making predictions for case law,\nas our method shows a significant improvement over the prior methods that focus\non civil law case outcome predictions.",
        "updated": "2024-04-13T01:59:17Z",
        "published": "2024-01-28T21:18:05Z",
        "authors": [
            "Lang Cao",
            "Zifeng Wang",
            "Cao Xiao",
            "Jimeng Sun"
        ],
        "categories": [
            "cs.CL"
        ],
        "primary_category": "cs.CL"
    },
    "2401.15781v3": {
        "url": "http://arxiv.org/abs/2401.15781v3",
        "title": "The Discrepancy of Shortest Paths",
        "summary": "The hereditary discrepancy of a set system is a certain quantitative measure\nof the pseudorandom properties of the system. Roughly, hereditary discrepancy\nmeasures how well one can $2$-color the elements of the system so that each set\ncontains approximately the same number of elements of each color. Hereditary\ndiscrepancy has well-studied applications e.g. in communication complexity and\nderandomization. More recently, the hereditary discrepancy of set systems of\nshortest paths has found applications in differential privacy [Chen et al.~SODA\n23].\n  The contribution of this paper is to improve the upper and lower bounds on\nthe hereditary discrepancy of set systems of unique shortest paths in graphs.\nIn particular, we show that any system of unique shortest paths in an\nundirected weighted graph has hereditary discrepancy $\\widetilde{O}(n^{1/4})$,\nand we construct lower bound examples demonstrating that this bound is tight up\nto hidden $\\text{polylog } n$ factors. Our lower bounds apply even in the\nplanar and bipartite settings, and they improve on a previous lower bound of\n$\\Omega(n^{1/6})$ obtained by applying the trace bound of Chazelle and Lvov\n[SoCG'00] to a classical point-line system of Erd\\H{o}s.\n  As applications, we improve the lower bound on the additive error for\ndifferentially-private all pairs shortest distances from $\\Omega(n^{1/6})$\n[Chen et al.~SODA 23] to $\\Omega(n^{1/4})$, and we improve the lower bound on\nadditive error for the differentially-private all sets range queries problem to\n$\\Omega(n^{1/4})$, which is tight up to hidden $\\text{polylog } n$ factors\n[Deng et al.~WADS 23].",
        "updated": "2024-04-22T15:55:02Z",
        "published": "2024-01-28T22:16:10Z",
        "authors": [
            "Greg Bodwin",
            "Chengyuan Deng",
            "Jie Gao",
            "Gary Hoppenworth",
            "Jalaj Upadhyay",
            "Chen Wang"
        ],
        "categories": [
            "cs.DS"
        ],
        "primary_category": "cs.DS"
    },
    "2401.15878v2": {
        "url": "http://arxiv.org/abs/2401.15878v2",
        "title": "Decoding the MITRE Engenuity ATT&CK Enterprise Evaluation: An Analysis\n  of EDR Performance in Real-World Environments",
        "summary": "Endpoint detection and response (EDR) systems have emerged as a critical\ncomponent of enterprise security solutions, effectively combating endpoint\nthreats like APT attacks with extended lifecycles. In light of the growing\nsignificance of endpoint detection and response (EDR) systems, many\ncybersecurity providers have developed their own proprietary EDR solutions.\nIt's crucial for users to assess the capabilities of these detection engines to\nmake informed decisions about which products to choose. This is especially\nurgent given the market's size, which is expected to reach around 3.7 billion\ndollars by 2023 and is still expanding. MITRE is a leading organization in\ncyber threat analysis. In 2018, MITRE started to conduct annual APT emulations\nthat cover major EDR vendors worldwide. Indicators include telemetry, detection\nand blocking capability, etc. Nevertheless, the evaluation results published by\nMITRE don't contain any further interpretations or suggestions.\n  In this paper, we thoroughly analyzed MITRE evaluation results to gain\nfurther insights into real-world EDR systems under test. Specifically, we\ndesigned a whole-graph analysis method, which utilizes additional control flow\nand data flow information to measure the performance of EDR systems. Besides,\nwe analyze MITRE evaluation's results over multiple years from various aspects,\nincluding detection coverage, detection confidence, detection modifier, data\nsource, compatibility, etc. Through the above studies, we have compiled a\nthorough summary of our findings and gained valuable insights from the\nevaluation results. We believe these summaries and insights can assist\nresearchers, practitioners, and vendors in better understanding the strengths\nand limitations of mainstream EDR products.",
        "updated": "2024-04-22T20:42:27Z",
        "published": "2024-01-29T04:19:56Z",
        "authors": [
            "Xiangmin Shen",
            "Zhenyuan Li",
            "Graham Burleigh",
            "Lingzhi Wang",
            "Yan Chen"
        ],
        "comments": "16 pages, 7 figures, to appear in AsiaCCS 2024",
        "categories": [
            "cs.CR"
        ],
        "primary_category": "cs.CR"
    },
    "2401.15902v2": {
        "url": "http://arxiv.org/abs/2401.15902v2",
        "title": "A Concise but High-performing Network for Image Guided Depth Completion\n  in Autonomous Driving",
        "summary": "Depth completion is a crucial task in autonomous driving, aiming to convert a\nsparse depth map into a dense depth prediction. Due to its potentially rich\nsemantic information, RGB image is commonly fused to enhance the completion\neffect. Image-guided depth completion involves three key challenges: 1) how to\neffectively fuse the two modalities; 2) how to better recover depth\ninformation; and 3) how to achieve real-time prediction for practical\nautonomous driving. To solve the above problems, we propose a concise but\neffective network, named CENet, to achieve high-performance depth completion\nwith a simple and elegant structure. Firstly, we use a fast guidance module to\nfuse the two sensor features, utilizing abundant auxiliary features extracted\nfrom the color space. Unlike other commonly used complicated guidance modules,\nour approach is intuitive and low-cost. In addition, we find and analyze the\noptimization inconsistency problem for observed and unobserved positions, and a\ndecoupled depth prediction head is proposed to alleviate the issue. The\nproposed decoupled head can better output the depth of valid and invalid\npositions with very few extra inference time. Based on the simple structure of\ndual-encoder and single-decoder, our CENet can achieve superior balance between\naccuracy and efficiency. In the KITTI depth completion benchmark, our CENet\nattains competitive performance and inference speed compared with the\nstate-of-the-art methods. To validate the generalization of our method, we also\nevaluate on indoor NYUv2 dataset, and our CENet still achieve impressive\nresults. The code of this work will be available at\nhttps://github.com/lmomoy/CHNet.",
        "updated": "2024-04-22T05:10:57Z",
        "published": "2024-01-29T06:06:45Z",
        "authors": [
            "Moyun Liu",
            "Bing Chen",
            "Youping Chen",
            "Jingming Xie",
            "Lei Yao",
            "Yang Zhang",
            "Joey Tianyi Zhou"
        ],
        "categories": [
            "cs.CV"
        ],
        "primary_category": "cs.CV"
    },
    "2401.15906v7": {
        "url": "http://arxiv.org/abs/2401.15906v7",
        "title": "Mean Estimation with User-Level Privacy for Spatio-Temporal IoT Datasets",
        "summary": "This paper considers the problem of the private release of sample means of\nspeed values from traffic datasets. Our key contribution is the development of\nuser-level differentially private algorithms that incorporate carefully chosen\nparameter values to ensure low estimation errors on real-world datasets, while\nensuring privacy. We test our algorithms on ITMS (Intelligent Traffic\nManagement System) data from an Indian city, where the speeds of different\nbuses are drawn in a potentially non-i.i.d. manner from an unknown\ndistribution, and where the number of speed samples contributed by different\nbuses is potentially different. We then apply our algorithms to large synthetic\ndatasets, generated based on the ITMS data. Here, we provide theoretical\njustification for the observed performance trends, and also provide\nrecommendations for the choices of algorithm subroutines that result in low\nestimation errors. Finally, we characterize the best performance of pseudo-user\ncreation-based algorithms on worst-case datasets via a minimax approach; this\nthen gives rise to a novel procedure for the creation of pseudo-users, which\noptimizes the worst-case total estimation error. The algorithms discussed in\nthe paper are readily applicable to general spatio-temporal IoT datasets for\nreleasing a differentially private mean of a desired value.",
        "updated": "2024-04-25T05:39:37Z",
        "published": "2024-01-29T06:21:29Z",
        "authors": [
            "V. Arvind Rameshwar",
            "Anshoo Tandon",
            "Prajjwal Gupta",
            "Aditya Vikram Singh",
            "Novoneel Chakraborty",
            "Abhay Sharma"
        ],
        "comments": "14 pages, 5 figures, submitted to the ACM for possible publication",
        "categories": [
            "cs.CR",
            "cs.IT",
            "math.IT",
            "stat.AP"
        ],
        "primary_category": "cs.CR"
    },
    "2401.15914v2": {
        "url": "http://arxiv.org/abs/2401.15914v2",
        "title": "Overcoming the Pitfalls of Vision-Language Model Finetuning for OOD\n  Generalization",
        "summary": "Existing vision-language models exhibit strong generalization on a variety of\nvisual domains and tasks. However, such models mainly perform zero-shot\nrecognition in a closed-set manner, and thus struggle to handle open-domain\nvisual concepts by design. There are recent finetuning methods, such as prompt\nlearning, that not only study the discrimination between in-distribution (ID)\nand out-of-distribution (OOD) samples, but also show some improvements in both\nID and OOD accuracies. In this paper, we first demonstrate that vision-language\nmodels, after long enough finetuning but without proper regularization, tend to\noverfit the known classes in the given dataset, with degraded performance on\nunknown classes. Then we propose a novel approach OGEN to address this pitfall,\nwith the main focus on improving the OOD GENeralization of finetuned models.\nSpecifically, a class-conditional feature generator is introduced to synthesize\nOOD features using just the class name of any unknown class. Such synthesized\nfeatures will provide useful knowledge about unknowns and help regularize the\ndecision boundary between ID and OOD data when optimized jointly. Equally\nimportant is our adaptive self-distillation mechanism to regularize our feature\ngeneration model during joint optimization, i.e., adaptively transferring\nknowledge between model states to further prevent overfitting. Experiments\nvalidate that our method yields convincing gains in OOD generalization\nperformance in different settings. Code: https://github.com/apple/ml-ogen.",
        "updated": "2024-04-16T03:25:25Z",
        "published": "2024-01-29T06:57:48Z",
        "authors": [
            "Yuhang Zang",
            "Hanlin Goh",
            "Josh Susskind",
            "Chen Huang"
        ],
        "comments": "ICLR 2024",
        "categories": [
            "cs.CV",
            "cs.AI"
        ],
        "primary_category": "cs.CV"
    },
    "2402.14891v5": {
        "url": "http://arxiv.org/abs/2402.14891v5",
        "title": "LLMBind: A Unified Modality-Task Integration Framework",
        "summary": "In the multi-modal domain, the dependence of various models on specific input\nformats leads to user confusion and hinders progress. To address this\nchallenge, we introduce \\textbf{LLMBind}, a novel framework designed to unify a\ndiverse array of multi-modal tasks. By harnessing a Mixture-of-Experts (MoE)\nLarge Language Model (LLM), LLMBind processes multi-modal inputs and generates\ntask-specific tokens, enabling the invocation of corresponding models to\naccomplish tasks. This unique approach empowers LLMBind to interpret inputs and\ngenerate outputs across various modalities, including image, text, video, and\naudio. Furthermore, we have constructed an interaction dataset comprising 400k\ninstructions, which unlocks the ability of LLMBind for interactive visual\ngeneration and editing tasks. Extensive experimentation demonstrates that\nLLMBind achieves very superior performance across diverse tasks and outperforms\nexisting models in user evaluations conducted in real-world scenarios.\nMoreover, the adaptability of LLMBind allows for seamless integration with the\nlatest models and extension to new modality tasks, highlighting its potential\nto serve as a unified AI agent for modeling universal modalities.",
        "updated": "2024-04-19T03:07:59Z",
        "published": "2024-02-22T12:36:31Z",
        "authors": [
            "Bin Zhu",
            "Munan Ning",
            "Peng Jin",
            "Bin Lin",
            "Jinfa Huang",
            "Qi Song",
            "Junwu Zhang",
            "Zhenyu Tang",
            "Mingjun Pan",
            "Xing Zhou",
            "Li Yuan"
        ],
        "categories": [
            "cs.CL",
            "cs.AI"
        ],
        "primary_category": "cs.CL"
    },
    "2402.14936v2": {
        "url": "http://arxiv.org/abs/2402.14936v2",
        "title": "A Fast Direct Solver for Elliptic PDEs on a Hierarchy of Adaptively\n  Refined Quadtrees",
        "summary": "We describe a fast, direct solver for elliptic partial differential equations\non a two-dimensional hierarchy of adaptively refined, Cartesian meshes. Our\nsolver, inspired by the Hierarchical Poincar\\'e-Steklov (HPS) method introduced\nby Gillman and Martinsson (SIAM J. Sci. Comput., 2014) uses fast solvers on\nlocally uniform Cartesian patches stored in the leaves of a quadtree and is the\nfirst such solver that works directly with the adaptive quadtree mesh managed\nusing the grid management library \\pforest (C. Burstedde, L. Wilcox, O.\nGhattas, SIAM J. Sci. Comput. 2011). Within each Cartesian patch, stored in\nleaves of the quadtree, we use a second order finite volume discretization on\ncell-centered meshes. Key contributions of our algorithm include 4-to-1 merge\nand split implementations for the HPS build stage and solve stage,\nrespectively. We demonstrate our solver on Poisson and Helmholtz problems with\na mesh adapted to the high local curvature of the right-hand side.",
        "updated": "2024-04-05T22:43:49Z",
        "published": "2024-02-22T19:42:08Z",
        "authors": [
            "Damyn Chipman",
            "Donna Calhoun",
            "Carsten Burstedde"
        ],
        "categories": [
            "math.NA",
            "cs.NA"
        ],
        "primary_category": "math.NA"
    },
    "2402.14961v2": {
        "url": "http://arxiv.org/abs/2402.14961v2",
        "title": "Reinforcement Learning with Elastic Time Steps",
        "summary": "Traditional Reinforcement Learning (RL) algorithms are usually applied in\nrobotics to learn controllers that act with a fixed control rate. Given the\ndiscrete nature of RL algorithms, they are oblivious to the effects of the\nchoice of control rate: finding the correct control rate can be difficult and\nmistakes often result in excessive use of computing resources or even lack of\nconvergence. We propose Soft Elastic Actor-Critic (SEAC), a novel off-policy\nactor-critic algorithm to address this issue. SEAC implements elastic time\nsteps, time steps with a known, variable duration, which allow the agent to\nchange its control frequency to adapt to the situation. In practice, SEAC\napplies control only when necessary, minimizing computational resources and\ndata usage. We evaluate SEAC's capabilities in simulation in a Newtonian\nkinematics maze navigation task and on a 3D racing video game, Trackmania. SEAC\noutperforms the SAC baseline in terms of energy efficiency and overall time\nmanagement, and most importantly without the need to identify a control\nfrequency for the learned controller. SEAC demonstrated faster and more stable\ntraining speeds than SAC, especially at control rates where SAC struggled to\nconverge. We also compared SEAC with a similar approach, the Continuous-Time\nContinuous-Options (CTCO) model, and SEAC resulted in better task performance.\nThese findings highlight the potential of SEAC for practical, real-world RL\napplications in robotics.",
        "updated": "2024-04-02T14:02:07Z",
        "published": "2024-02-22T20:49:04Z",
        "authors": [
            "Dong Wang",
            "Giovanni Beltrame"
        ],
        "categories": [
            "cs.RO",
            "cs.LG"
        ],
        "primary_category": "cs.RO"
    },
    "2402.15010v1": {
        "url": "http://arxiv.org/abs/2402.15010v1",
        "title": "How Important Is Tokenization in French Medical Masked Language Models?",
        "summary": "Subword tokenization has become the prevailing standard in the field of\nnatural language processing (NLP) over recent years, primarily due to the\nwidespread utilization of pre-trained language models. This shift began with\nByte-Pair Encoding (BPE) and was later followed by the adoption of\nSentencePiece and WordPiece. While subword tokenization consistently\noutperforms character and word-level tokenization, the precise factors\ncontributing to its success remain unclear. Key aspects such as the optimal\nsegmentation granularity for diverse tasks and languages, the influence of data\nsources on tokenizers, and the role of morphological information in\nIndo-European languages remain insufficiently explored. This is particularly\npertinent for biomedical terminology, characterized by specific rules governing\nmorpheme combinations. Despite the agglutinative nature of biomedical\nterminology, existing language models do not explicitly incorporate this\nknowledge, leading to inconsistent tokenization strategies for common terms. In\nthis paper, we seek to delve into the complexities of subword tokenization in\nFrench biomedical domain across a variety of NLP tasks and pinpoint areas where\nfurther enhancements can be made. We analyze classical tokenization algorithms,\nincluding BPE and SentencePiece, and introduce an original tokenization\nstrategy that integrates morpheme-enriched word segmentation into existing\ntokenization methods.",
        "updated": "2024-02-22T23:11:08Z",
        "published": "2024-02-22T23:11:08Z",
        "authors": [
            "Yanis Labrak",
            "Adrien Bazoge",
            "Beatrice Daille",
            "Mickael Rouvier",
            "Richard Dufour"
        ],
        "comments": "Accepted at LREC-Coling 2024",
        "categories": [
            "cs.CL",
            "cs.AI",
            "cs.LG"
        ],
        "primary_category": "cs.CL",
        "journal_ref": "The 2024 Joint International Conference on Computational\n  Linguistics, Language Resources and Evaluation (LREC-COLING 2024), May 2024,\n  Torino, Italy"
    },
    "2402.15102v2": {
        "url": "http://arxiv.org/abs/2402.15102v2",
        "title": "Trajectory-wise Iterative Reinforcement Learning Framework for\n  Auto-bidding",
        "summary": "In online advertising, advertisers participate in ad auctions to acquire ad\nopportunities, often by utilizing auto-bidding tools provided by demand-side\nplatforms (DSPs). The current auto-bidding algorithms typically employ\nreinforcement learning (RL). However, due to safety concerns, most RL-based\nauto-bidding policies are trained in simulation, leading to a performance\ndegradation when deployed in online environments. To narrow this gap, we can\ndeploy multiple auto-bidding agents in parallel to collect a large interaction\ndataset. Offline RL algorithms can then be utilized to train a new policy. The\ntrained policy can subsequently be deployed for further data collection,\nresulting in an iterative training framework, which we refer to as iterative\noffline RL. In this work, we identify the performance bottleneck of this\niterative offline RL framework, which originates from the ineffective\nexploration and exploitation caused by the inherent conservatism of offline RL\nalgorithms. To overcome this bottleneck, we propose Trajectory-wise Exploration\nand Exploitation (TEE), which introduces a novel data collecting and data\nutilization method for iterative offline RL from a trajectory perspective.\nFurthermore, to ensure the safety of online exploration while preserving the\ndataset quality for TEE, we propose Safe Exploration by Adaptive Action\nSelection (SEAS). Both offline experiments and real-world experiments on\nAlibaba display advertising platform demonstrate the effectiveness of our\nproposed method.",
        "updated": "2024-04-08T09:33:10Z",
        "published": "2024-02-23T05:20:23Z",
        "authors": [
            "Haoming Li",
            "Yusen Huo",
            "Shuai Dou",
            "Zhenzhe Zheng",
            "Zhilin Zhang",
            "Chuan Yu",
            "Jian Xu",
            "Fan Wu"
        ],
        "comments": "Accepted by The Web Conference 2024 (WWW'24) as an oral paper",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.GT",
            "cs.IR"
        ],
        "primary_category": "cs.LG"
    },
    "2402.15106v2": {
        "url": "http://arxiv.org/abs/2402.15106v2",
        "title": "Sampling-based Distributed Training with Message Passing Neural Network",
        "summary": "In this study, we introduce a domain-decomposition-based distributed training\nand inference approach for message-passing neural networks (MPNN). Our\nobjective is to address the challenge of scaling edge-based graph neural\nnetworks as the number of nodes increases. Through our distributed training\napproach, coupled with Nystr\\\"om-approximation sampling techniques, we present\na scalable graph neural network, referred to as DS-MPNN (D and S standing for\ndistributed and sampled, respectively), capable of scaling up to $O(10^5)$\nnodes. We validate our sampling and distributed training approach on two cases:\n(a) a Darcy flow dataset and (b) steady RANS simulations of 2-D airfoils,\nproviding comparisons with both single-GPU implementation and node-based graph\nconvolution networks (GCNs). The DS-MPNN model demonstrates comparable accuracy\nto single-GPU implementation, can accommodate a significantly larger number of\nnodes compared to the single-GPU variant (S-MPNN), and significantly\noutperforms the node-based GCN.",
        "updated": "2024-04-15T00:10:25Z",
        "published": "2024-02-23T05:33:43Z",
        "authors": [
            "Priyesh Kakka",
            "Sheel Nidhan",
            "Rishikesh Ranade",
            "Jonathan F. MacArt"
        ],
        "categories": [
            "cs.LG",
            "cs.DC",
            "physics.flu-dyn"
        ],
        "primary_category": "cs.LG"
    },
    "2402.15163v2": {
        "url": "http://arxiv.org/abs/2402.15163v2",
        "title": "Studying the Impact of Stochasticity on the Evaluation of Deep Neural\n  Networks for Forest-Fire Prediction",
        "summary": "This paper presents the first systematic study of Deep Neural Network (DNN)\nevaluation under stochastic assumptions, focusing on wildfire prediction. We\nnote that current evaluation strategies emphasize a DNN's replication of\nobserved ground truths rather than its ability to learn the underlying\nstochastic processes, crucial for capturing wildfire evolution's complexity. To\nbridge this gap, we propose a novel evaluation criterion: Has the DNN learned\nthe stochastic process? Using a synthetic dataset, we introduce a framework to\ncharacterize the stochastic process (generated by randomness in fire evolution\nrules). Through this framework, we assess an evaluation metric's capability to\ntest if the DNN has learned the stochastic process. Our findings show that\nconventional metrics, including classification-based metrics and proper scoring\nrules, are inadequate. We identify the Expected Calibration Error (ECE) as a\nrobust metric that tests the proposed evaluation criteria, offering asymptotic\nguarantees of proper scoring rules and improved interpretability through\ncalibration curves. We extend our analysis to real-world wildfire data,\nhighlighting the limitations of traditional evaluation methods and\ndemonstrating the utility of ECE as a stochasticity-compatible metric alongside\nexisting ones.",
        "updated": "2024-04-19T19:26:32Z",
        "published": "2024-02-23T07:54:20Z",
        "authors": [
            "Harshit Kumar",
            "Biswadeep Chakraborty",
            "Beomseok Kang",
            "Saibal Mukhopadhyay"
        ],
        "comments": "Under peer review",
        "categories": [
            "cs.LG",
            "cs.AI"
        ],
        "primary_category": "cs.LG"
    },
    "2402.15164v2": {
        "url": "http://arxiv.org/abs/2402.15164v2",
        "title": "EasyRL4Rec: An Easy-to-use Library for Reinforcement Learning Based\n  Recommender Systems",
        "summary": "Reinforcement Learning (RL)-Based Recommender Systems (RSs) have gained\nrising attention for their potential to enhance long-term user engagement.\nHowever, research in this field faces challenges, including the lack of\nuser-friendly frameworks, inconsistent evaluation metrics, and difficulties in\nreproducing existing studies. To tackle these issues, we introduce EasyRL4Rec,\nan easy-to-use code library designed specifically for RL-based RSs. This\nlibrary provides lightweight and diverse RL environments based on five public\ndatasets and includes core modules with rich options, simplifying model\ndevelopment. It provides unified evaluation standards focusing on long-term\noutcomes and offers tailored designs for state modeling and action\nrepresentation for recommendation scenarios. Furthermore, we share our findings\nfrom insightful experiments with current methods. EasyRL4Rec seeks to\nfacilitate the model development and experimental process in the domain of\nRL-based RSs. The library is available for public use.",
        "updated": "2024-04-27T10:11:31Z",
        "published": "2024-02-23T07:54:26Z",
        "authors": [
            "Yuanqing Yu",
            "Chongming Gao",
            "Jiawei Chen",
            "Heng Tang",
            "Yuefeng Sun",
            "Qian Chen",
            "Weizhi Ma",
            "Min Zhang"
        ],
        "comments": "Accepted by SIGIR2024",
        "categories": [
            "cs.IR",
            "cs.LG"
        ],
        "primary_category": "cs.IR"
    },
    "2402.15264v3": {
        "url": "http://arxiv.org/abs/2402.15264v3",
        "title": "DEEM: Dynamic Experienced Expert Modeling for Stance Detection",
        "summary": "Recent work has made a preliminary attempt to use large language models\n(LLMs) to solve the stance detection task, showing promising results. However,\nconsidering that stance detection usually requires detailed background\nknowledge, the vanilla reasoning method may neglect the domain knowledge to\nmake a professional and accurate analysis. Thus, there is still room for\nimprovement of LLMs reasoning, especially in leveraging the generation\ncapability of LLMs to simulate specific experts (i.e., multi-agents) to detect\nthe stance. In this paper, different from existing multi-agent works that\nrequire detailed descriptions and use fixed experts, we propose a Dynamic\nExperienced Expert Modeling (DEEM) method which can leverage the generated\nexperienced experts and let LLMs reason in a semi-parametric way, making the\nexperts more generalizable and reliable. Experimental results demonstrate that\nDEEM consistently achieves the best results on three standard benchmarks,\noutperforms methods with self-consistency reasoning, and reduces the bias of\nLLMs.",
        "updated": "2024-04-26T01:06:31Z",
        "published": "2024-02-23T11:24:00Z",
        "authors": [
            "Xiaolong Wang",
            "Yile Wang",
            "Sijie Cheng",
            "Peng Li",
            "Yang Liu"
        ],
        "comments": "Accepted by LREC-COLING 2024, Oral presentation",
        "categories": [
            "cs.CL"
        ],
        "primary_category": "cs.CL"
    },
    "2402.15267v2": {
        "url": "http://arxiv.org/abs/2402.15267v2",
        "title": "A Robust Defense against Adversarial Attacks on Deep Learning-based\n  Malware Detectors via (De)Randomized Smoothing",
        "summary": "Deep learning-based malware detectors have been shown to be susceptible to\nadversarial malware examples, i.e. malware examples that have been deliberately\nmanipulated in order to avoid detection. In light of the vulnerability of deep\nlearning detectors to subtle input file modifications, we propose a practical\ndefense against adversarial malware examples inspired by (de)randomized\nsmoothing. In this work, we reduce the chances of sampling adversarial content\ninjected by malware authors by selecting correlated subsets of bytes, rather\nthan using Gaussian noise to randomize inputs like in the Computer Vision (CV)\ndomain. During training, our ablation-based smoothing scheme trains a base\nclassifier to make classifications on a subset of contiguous bytes or chunk of\nbytes. At test time, a large number of chunks are then classified by a base\nclassifier and the consensus among these classifications is then reported as\nthe final prediction. We propose two strategies to determine the location of\nthe chunks used for classification: (1) randomly selecting the locations of the\nchunks and (2) selecting contiguous adjacent chunks. To showcase the\neffectiveness of our approach, we have trained two classifiers with our\nchunk-based ablation schemes on the BODMAS dataset. Our findings reveal that\nthe chunk-based smoothing classifiers exhibit greater resilience against\nadversarial malware examples generated with state-of-the-are evasion attacks,\noutperforming a non-smoothed classifier and a randomized smoothing-based\nclassifier by a great margin.",
        "updated": "2024-02-26T21:30:45Z",
        "published": "2024-02-23T11:30:12Z",
        "authors": [
            "Daniel Gibert",
            "Giulio Zizzo",
            "Quan Le",
            "Jordi Planes"
        ],
        "comments": "arXiv admin note: text overlap with arXiv:2308.08906",
        "categories": [
            "cs.CR",
            "cs.AI"
        ],
        "primary_category": "cs.CR",
        "doi": "10.1109/ACCESS.2024.3392391"
    },
    "2403.10853v2": {
        "url": "http://arxiv.org/abs/2403.10853v2",
        "title": "Just Say the Name: Online Continual Learning with Category Names Only\n  via Data Generation",
        "summary": "In real-world scenarios, extensive manual annotation for continual learning\nis impractical due to prohibitive costs. Although prior arts, influenced by\nlarge-scale webly supervised training, suggest leveraging web-scraped data in\ncontinual learning, this poses challenges such as data imbalance, usage\nrestrictions, and privacy concerns. Addressing the risks of continual webly\nsupervised training, we present an online continual learning framework -\nGenerative Name only Continual Learning (G-NoCL). The proposed G-NoCL uses a\nset of generators G along with the learner. When encountering new concepts\n(i.e., classes), G-NoCL employs the novel sample complexity-guided data\nensembling technique DIverSity and COmplexity enhancing ensemBlER (DISCOBER) to\noptimally sample training data from generated data. Through extensive\nexperimentation, we demonstrate superior performance of DISCOBER in G-NoCL\nonline CL benchmarks, covering both In-Distribution (ID) and\nOut-of-Distribution (OOD) generalization evaluations, compared to naive\ngenerator-ensembling, web-supervised, and manually annotated data.",
        "updated": "2024-04-30T15:20:54Z",
        "published": "2024-03-16T08:28:42Z",
        "authors": [
            "Minhyuk Seo",
            "Diganta Misra",
            "Seongwon Cho",
            "Minjae Lee",
            "Jonghyun Choi"
        ],
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.CV"
        ],
        "primary_category": "cs.LG"
    },
    "2403.10897v2": {
        "url": "http://arxiv.org/abs/2403.10897v2",
        "title": "Rethinking Multi-view Representation Learning via Distilled\n  Disentangling",
        "summary": "Multi-view representation learning aims to derive robust representations that\nare both view-consistent and view-specific from diverse data sources. This\npaper presents an in-depth analysis of existing approaches in this domain,\nhighlighting a commonly overlooked aspect: the redundancy between\nview-consistent and view-specific representations. To this end, we propose an\ninnovative framework for multi-view representation learning, which incorporates\na technique we term 'distilled disentangling'. Our method introduces the\nconcept of masked cross-view prediction, enabling the extraction of compact,\nhigh-quality view-consistent representations from various sources without\nincurring extra computational overhead. Additionally, we develop a distilled\ndisentangling module that efficiently filters out consistency-related\ninformation from multi-view representations, resulting in purer view-specific\nrepresentations. This approach significantly reduces redundancy between\nview-consistent and view-specific representations, enhancing the overall\nefficiency of the learning process. Our empirical evaluations reveal that\nhigher mask ratios substantially improve the quality of view-consistent\nrepresentations. Moreover, we find that reducing the dimensionality of\nview-consistent representations relative to that of view-specific\nrepresentations further refines the quality of the combined representations.\nOur code is accessible at: https://github.com/Guanzhou-Ke/MRDD.",
        "updated": "2024-03-29T14:49:11Z",
        "published": "2024-03-16T11:21:24Z",
        "authors": [
            "Guanzhou Ke",
            "Bo Wang",
            "Xiaoli Wang",
            "Shengfeng He"
        ],
        "comments": "Accepted by CVPR 2024",
        "categories": [
            "cs.CV",
            "cs.MM"
        ],
        "primary_category": "cs.CV"
    },
    "2403.10921v3": {
        "url": "http://arxiv.org/abs/2403.10921v3",
        "title": "Simultaneously Transmitting and Reflecting Reconfigurable Intelligent\n  Surfaces Empowered Cooperative Rate Splitting with User Relaying",
        "summary": "In this work, we unveil the advantages of synergizing cooperative rate\nsplitting (CRS) with user relaying and simultaneously transmitting and\nreflecting reconfigurable intelligent surface (STAR RIS). Specifically, we\npropose a novel STAR RIS-assisted CRS transmission framework, featuring six\nunique transmission modes that leverage various combination of the relaying\nprotocols (including full duplex-FD and half duplex-HD) and the STAR RIS\nconfiguration protocols (including energy splitting-ES, mode switching-MS, and\ntime splitting-TS). With the objective of maximizing the minimum user rate, we\nthen propose a unified successive convex approximation (SCA)-based alternative\noptimization (AO) algorithm to jointly optimize the transmit active\nbeamforming, common rate allocation, STAR RIS passive beamforming, as well as\ntime allocation (for HD or TS protocols) subject to the transmit power\nconstraint at the base station (BS) and the law of energy conservation at the\nSTAR RIS. To alleviate the computational burden, we further propose a\nlow-complexity algorithm that incorporates a closed-form passive beamforming\ndesign. Numerical results show that our proposed framework significantly\nenhances user fairness compared with conventional CRS schemes without STAR RIS\nor other STAR RIS empowered multiple access schemes. Moreover, the proposed\nlow-complexity algorithm dramatically reduces the computational complexity\nwhile achieving very close performance to the AO method.",
        "updated": "2024-04-13T06:11:33Z",
        "published": "2024-03-16T13:32:40Z",
        "authors": [
            "Kangchun Zhao",
            "Yijie Mao",
            "Yuanming Shi"
        ],
        "categories": [
            "cs.IT",
            "math.IT"
        ],
        "primary_category": "cs.IT"
    },
    "2403.10962v2": {
        "url": "http://arxiv.org/abs/2403.10962v2",
        "title": "Exploiting Topological Priors for Boosting Point Cloud Generation",
        "summary": "This paper presents an innovative enhancement to the Sphere as Prior\nGenerative Adversarial Network (SP-GAN) model, a state-of-the-art GAN designed\nfor point cloud generation. A novel method is introduced for point cloud\ngeneration that elevates the structural integrity and overall quality of the\ngenerated point clouds by incorporating topological priors into the training\nprocess of the generator. Specifically, this work utilizes the K-means\nalgorithm to segment a point cloud from the repository into clusters and\nextract centroids, which are then used as priors in the generation process of\nthe SP-GAN. Furthermore, the discriminator component of the SP-GAN utilizes the\nidentical point cloud that contributed the centroids, ensuring a coherent and\nconsistent learning environment. This strategic use of centroids as intuitive\nguides not only boosts the efficiency of global feature learning but also\nsubstantially improves the structural coherence and fidelity of the generated\npoint clouds. By applying the K-means algorithm to generate centroids as the\nprior, the work intuitively and experimentally demonstrates that such a prior\nenhances the quality of generated point clouds.",
        "updated": "2024-04-26T05:48:26Z",
        "published": "2024-03-16T16:17:44Z",
        "authors": [
            "Baiyuan Chen"
        ],
        "comments": "7 pages, 3 figures",
        "categories": [
            "cs.CV",
            "eess.IV"
        ],
        "primary_category": "cs.CV"
    },
    "2403.10988v2": {
        "url": "http://arxiv.org/abs/2403.10988v2",
        "title": "Boosting Flow-based Generative Super-Resolution Models via Learned Prior",
        "summary": "Flow-based super-resolution (SR) models have demonstrated astonishing\ncapabilities in generating high-quality images. However, these methods\nencounter several challenges during image generation, such as grid artifacts,\nexploding inverses, and suboptimal results due to a fixed sampling temperature.\nTo overcome these issues, this work introduces a conditional learned prior to\nthe inference phase of a flow-based SR model. This prior is a latent code\npredicted by our proposed latent module conditioned on the low-resolution\nimage, which is then transformed by the flow model into an SR image. Our\nframework is designed to seamlessly integrate with any contemporary flow-based\nSR model without modifying its architecture or pre-trained weights. We evaluate\nthe effectiveness of our proposed framework through extensive experiments and\nablation analyses. The proposed framework successfully addresses all the\ninherent issues in flow-based SR models and enhances their performance in\nvarious SR scenarios. Our code is available at:\nhttps://github.com/liyuantsao/FlowSR-LP",
        "updated": "2024-03-30T04:56:05Z",
        "published": "2024-03-16T18:04:12Z",
        "authors": [
            "Li-Yuan Tsao",
            "Yi-Chen Lo",
            "Chia-Che Chang",
            "Hao-Wei Chen",
            "Roy Tseng",
            "Chien Feng",
            "Chun-Yi Lee"
        ],
        "comments": "Accepted to CVPR2024",
        "categories": [
            "cs.CV",
            "cs.AI"
        ],
        "primary_category": "cs.CV"
    },
    "2403.11004v2": {
        "url": "http://arxiv.org/abs/2403.11004v2",
        "title": "Forward Learning of Graph Neural Networks",
        "summary": "Graph neural networks (GNNs) have achieved remarkable success across a wide\nrange of applications, such as recommendation, drug discovery, and question\nanswering. Behind the success of GNNs lies the backpropagation (BP) algorithm,\nwhich is the de facto standard for training deep neural networks (NNs).\nHowever, despite its effectiveness, BP imposes several constraints, which are\nnot only biologically implausible, but also limit the scalability, parallelism,\nand flexibility in learning NNs. Examples of such constraints include storage\nof neural activities computed in the forward pass for use in the subsequent\nbackward pass, and the dependence of parameter updates on non-local signals. To\naddress these limitations, the forward-forward algorithm (FF) was recently\nproposed as an alternative to BP in the image classification domain, which\ntrains NNs by performing two forward passes over positive and negative data.\nInspired by this advance, we propose ForwardGNN in this work, a new forward\nlearning procedure for GNNs, which avoids the constraints imposed by BP via an\neffective layer-wise local forward training. ForwardGNN extends the original FF\nto deal with graph data and GNNs, and makes it possible to operate without\ngenerating negative inputs (hence no longer forward-forward). Further,\nForwardGNN enables each layer to learn from both the bottom-up and top-down\nsignals without relying on the backpropagation of errors. Extensive experiments\non real-world datasets show the effectiveness and generality of the proposed\nforward graph learning framework. We release our code at\nhttps://github.com/facebookresearch/forwardgnn.",
        "updated": "2024-04-13T00:10:00Z",
        "published": "2024-03-16T19:40:35Z",
        "authors": [
            "Namyong Park",
            "Xing Wang",
            "Antoine Simoulin",
            "Shuai Yang",
            "Grey Yang",
            "Ryan Rossi",
            "Puja Trivedi",
            "Nesreen Ahmed"
        ],
        "comments": "ICLR 2024",
        "categories": [
            "cs.LG",
            "cs.SI"
        ],
        "primary_category": "cs.LG"
    },
    "2403.11056v2": {
        "url": "http://arxiv.org/abs/2403.11056v2",
        "title": "Analytic-Splatting: Anti-Aliased 3D Gaussian Splatting via Analytic\n  Integration",
        "summary": "The 3D Gaussian Splatting (3DGS) gained its popularity recently by combining\nthe advantages of both primitive-based and volumetric 3D representations,\nresulting in improved quality and efficiency for 3D scene rendering. However,\n3DGS is not alias-free, and its rendering at varying resolutions could produce\nsevere blurring or jaggies. This is because 3DGS treats each pixel as an\nisolated, single point rather than as an area, causing insensitivity to changes\nin the footprints of pixels. Consequently, this discrete sampling scheme\ninevitably results in aliasing, owing to the restricted sampling bandwidth. In\nthis paper, we derive an analytical solution to address this issue. More\nspecifically, we use a conditioned logistic function as the analytic\napproximation of the cumulative distribution function (CDF) in a\none-dimensional Gaussian signal and calculate the Gaussian integral by\nsubtracting the CDFs. We then introduce this approximation in the\ntwo-dimensional pixel shading, and present Analytic-Splatting, which\nanalytically approximates the Gaussian integral within the 2D-pixel window area\nto better capture the intensity response of each pixel. Moreover, we use the\napproximated response of the pixel window integral area to participate in the\ntransmittance calculation of volume rendering, making Analytic-Splatting\nsensitive to the changes in pixel footprint at different resolutions.\nExperiments on various datasets validate that our approach has better\nanti-aliasing capability that gives more details and better fidelity.",
        "updated": "2024-04-03T04:00:53Z",
        "published": "2024-03-17T02:06:03Z",
        "authors": [
            "Zhihao Liang",
            "Qi Zhang",
            "Wenbo Hu",
            "Ying Feng",
            "Lei Zhu",
            "Kui Jia"
        ],
        "comments": "29 pages",
        "categories": [
            "cs.CV"
        ],
        "primary_category": "cs.CV"
    },
    "2403.11111v2": {
        "url": "http://arxiv.org/abs/2403.11111v2",
        "title": "3D Human Reconstruction in the Wild with Synthetic Data Using Generative\n  Models",
        "summary": "In this work, we show that synthetic data created by generative models is\ncomplementary to computer graphics (CG) rendered data for achieving remarkable\ngeneralization performance on diverse real-world scenes for 3D human pose and\nshape estimation (HPS). Specifically, we propose an effective approach based on\nrecent diffusion models, termed HumanWild, which can effortlessly generate\nhuman images and corresponding 3D mesh annotations. We first collect a\nlarge-scale human-centric dataset with comprehensive annotations, e.g., text\ncaptions and surface normal images. Then, we train a customized ControlNet\nmodel upon this dataset to generate diverse human images and initial\nground-truth labels. At the core of this step is that we can easily obtain\nnumerous surface normal images from a 3D human parametric model, e.g., SMPL-X,\nby rendering the 3D mesh onto the image plane. As there exists inevitable noise\nin the initial labels, we then apply an off-the-shelf foundation segmentation\nmodel, i.e., SAM, to filter negative data samples. Our data generation pipeline\nis flexible and customizable to facilitate different real-world tasks, e.g.,\nego-centric scenes and perspective-distortion scenes. The generated dataset\ncomprises 0.79M images with corresponding 3D annotations, covering versatile\nviewpoints, scenes, and human identities. We train various HPS regressors on\ntop of the generated data and evaluate them on a wide range of benchmarks\n(3DPW, RICH, EgoBody, AGORA, SSP-3D) to verify the effectiveness of the\ngenerated data. By exclusively employing generative models, we generate\nlarge-scale in-the-wild human images and high-quality annotations, eliminating\nthe need for real-world data collection.",
        "updated": "2024-04-11T12:01:34Z",
        "published": "2024-03-17T06:31:16Z",
        "authors": [
            "Yongtao Ge",
            "Wenjia Wang",
            "Yongfan Chen",
            "Hao Chen",
            "Chunhua Shen"
        ],
        "comments": "project page: https://yongtaoge.github.io/projects/humanwild",
        "categories": [
            "cs.CV"
        ],
        "primary_category": "cs.CV"
    },
    "2403.11120v2": {
        "url": "http://arxiv.org/abs/2403.11120v2",
        "title": "Unifying Feature and Cost Aggregation with Transformers for Semantic and\n  Visual Correspondence",
        "summary": "This paper introduces a Transformer-based integrative feature and cost\naggregation network designed for dense matching tasks. In the context of dense\nmatching, many works benefit from one of two forms of aggregation: feature\naggregation, which pertains to the alignment of similar features, or cost\naggregation, a procedure aimed at instilling coherence in the flow estimates\nacross neighboring pixels. In this work, we first show that feature aggregation\nand cost aggregation exhibit distinct characteristics and reveal the potential\nfor substantial benefits stemming from the judicious use of both aggregation\nprocesses. We then introduce a simple yet effective architecture that harnesses\nself- and cross-attention mechanisms to show that our approach unifies feature\naggregation and cost aggregation and effectively harnesses the strengths of\nboth techniques. Within the proposed attention layers, the features and cost\nvolume both complement each other, and the attention layers are interleaved\nthrough a coarse-to-fine design to further promote accurate correspondence\nestimation. Finally at inference, our network produces multi-scale predictions,\ncomputes their confidence scores, and selects the most confident flow for final\nprediction. Our framework is evaluated on standard benchmarks for semantic\nmatching, and also applied to geometric matching, where we show that our\napproach achieves significant improvements compared to existing methods.",
        "updated": "2024-04-22T09:06:54Z",
        "published": "2024-03-17T07:02:55Z",
        "authors": [
            "Sunghwan Hong",
            "Seokju Cho",
            "Seungryong Kim",
            "Stephen Lin"
        ],
        "comments": "Accepted by ICLR'24",
        "categories": [
            "cs.CV"
        ],
        "primary_category": "cs.CV"
    },
    "2403.11124v2": {
        "url": "http://arxiv.org/abs/2403.11124v2",
        "title": "Scaling Data Diversity for Fine-Tuning Language Models in Human\n  Alignment",
        "summary": "Alignment with human preference prevents large language models (LLMs) from\ngenerating misleading or toxic content while requiring high-cost human\nfeedback. Assuming resources of human annotation are limited, there are two\ndifferent ways of allocating considered: more diverse PROMPTS or more diverse\nRESPONSES to be labeled. Nonetheless, a straightforward comparison between\ntheir impact is absent. In this work, we first control the diversity of both\nsides according to the number of samples for fine-tuning, which can directly\nreflect their influence. We find that instead of numerous prompts, more\nresponses but fewer prompts better trigger LLMs for human alignment.\nAdditionally, the concept of diversity for prompts can be more complex than\nresponses that are typically quantified by single digits. Consequently, a new\nformulation of prompt diversity is proposed, further implying a linear\ncorrelation with the final performance of LLMs after fine-tuning. We also\nleverage it on data augmentation and conduct experiments to show its effect on\ndifferent algorithms.",
        "updated": "2024-03-30T16:48:16Z",
        "published": "2024-03-17T07:08:55Z",
        "authors": [
            "Feifan Song",
            "Bowen Yu",
            "Hao Lang",
            "Haiyang Yu",
            "Fei Huang",
            "Houfeng Wang",
            "Yongbin Li"
        ],
        "comments": "Accepted by LREC-COLING 2024",
        "categories": [
            "cs.CL",
            "cs.AI"
        ],
        "primary_category": "cs.CL"
    },
    "2403.19889v1": {
        "url": "http://arxiv.org/abs/2403.19889v1",
        "title": "Towards a Robust Retrieval-Based Summarization System",
        "summary": "This paper describes an investigation of the robustness of large language\nmodels (LLMs) for retrieval augmented generation (RAG)-based summarization\ntasks. While LLMs provide summarization capabilities, their performance in\ncomplex, real-world scenarios remains under-explored. Our first contribution is\nLogicSumm, an innovative evaluation framework incorporating realistic scenarios\nto assess LLM robustness during RAG-based summarization. Based on limitations\nidentified by LogiSumm, we then developed SummRAG, a comprehensive system to\ncreate training dialogues and fine-tune a model to enhance robustness within\nLogicSumm's scenarios. SummRAG is an example of our goal of defining structured\nmethods to test the capabilities of an LLM, rather than addressing issues in a\none-off fashion. Experimental results confirm the power of SummRAG, showcasing\nimproved logical coherence and summarization quality. Data, corresponding model\nweights, and Python code are available online.",
        "updated": "2024-03-29T00:14:46Z",
        "published": "2024-03-29T00:14:46Z",
        "authors": [
            "Shengjie Liu",
            "Jing Wu",
            "Jingyuan Bao",
            "Wenyi Wang",
            "Naira Hovakimyan",
            "Christopher G Healey"
        ],
        "categories": [
            "cs.CL",
            "cs.AI",
            "cs.IR",
            "cs.LG"
        ],
        "primary_category": "cs.CL"
    },
    "2403.19893v1": {
        "url": "http://arxiv.org/abs/2403.19893v1",
        "title": "PLoc: A New Evaluation Criterion Based on Physical Location for\n  Autonomous Driving Datasets",
        "summary": "Autonomous driving has garnered significant attention as a key research area\nwithin artificial intelligence. In the context of autonomous driving scenarios,\nthe varying physical locations of objects correspond to different levels of\ndanger. However, conventional evaluation criteria for automatic driving object\ndetection often overlook the crucial aspect of an object's physical location,\nleading to evaluation results that may not accurately reflect the genuine\nthreat posed by the object to the autonomous driving vehicle. To enhance the\nsafety of autonomous driving, this paper introduces a novel evaluation\ncriterion based on physical location information, termed PLoc. This criterion\ntranscends the limitations of traditional criteria by acknowledging that the\nphysical location of pedestrians in autonomous driving scenarios can provide\nvaluable safety-related information. Furthermore, this paper presents a newly\nre-annotated dataset (ApolloScape-R) derived from ApolloScape. ApolloScape-R\ninvolves the relabeling of pedestrians based on the significance of their\nphysical location. The dataset is utilized to assess the performance of various\nobject detection models under the proposed PLoc criterion. Experimental results\ndemonstrate that the average accuracy of all object detection models in\nidentifying a person situated in the travel lane of an autonomous vehicle is\nlower than that for a person on a sidewalk. The dataset is publicly available\nat https://github.com/lnyrlyed/ApolloScape-R.git",
        "updated": "2024-03-29T00:28:26Z",
        "published": "2024-03-29T00:28:26Z",
        "authors": [
            "Ruining Yang",
            "Yuqi Peng"
        ],
        "categories": [
            "cs.CV"
        ],
        "primary_category": "cs.CV"
    },
    "2403.19895v1": {
        "url": "http://arxiv.org/abs/2403.19895v1",
        "title": "An Information-Theoretic Framework for Out-of-Distribution\n  Generalization",
        "summary": "We study the Out-of-Distribution (OOD) generalization in machine learning and\npropose a general framework that provides information-theoretic generalization\nbounds. Our framework interpolates freely between Integral Probability Metric\n(IPM) and $f$-divergence, which naturally recovers some known results\n(including Wasserstein- and KL-bounds), as well as yields new generalization\nbounds. Moreover, we show that our framework admits an optimal transport\ninterpretation. When evaluated in two concrete examples, the proposed bounds\neither strictly improve upon existing bounds in some cases or recover the best\namong existing OOD generalization bounds.",
        "updated": "2024-03-29T00:29:57Z",
        "published": "2024-03-29T00:29:57Z",
        "authors": [
            "Wenliang Liu",
            "Guanding Yu",
            "Lele Wang",
            "Renjie Liao"
        ],
        "categories": [
            "cs.IT",
            "cs.LG",
            "math.IT"
        ],
        "primary_category": "cs.IT"
    },
    "2403.19896v1": {
        "url": "http://arxiv.org/abs/2403.19896v1",
        "title": "Nonlinearity Enhanced Adaptive Activation Function",
        "summary": "A simply implemented activation function with even cubic nonlinearity is\nintroduced that increases the accuracy of neural networks without substantial\nadditional computational resources. This is partially enabled through an\napparent tradeoff between convergence and accuracy. The activation function\ngeneralizes the standard RELU function by introducing additional degrees of\nfreedom through optimizable parameters that enable the degree of nonlinearity\nto be adjusted. The associated accuracy enhancement is quantified in the\ncontext of the MNIST digit data set through a comparison with standard\ntechniques.",
        "updated": "2024-03-29T00:33:37Z",
        "published": "2024-03-29T00:33:37Z",
        "authors": [
            "David Yevick"
        ],
        "categories": [
            "cs.LG",
            "cs.CV",
            "cs.NE"
        ],
        "primary_category": "cs.LG"
    },
    "2403.19897v1": {
        "url": "http://arxiv.org/abs/2403.19897v1",
        "title": "Disentangling Racial Phenotypes: Fine-Grained Control of Race-related\n  Facial Phenotype Characteristics",
        "summary": "Achieving an effective fine-grained appearance variation over 2D facial\nimages, whilst preserving facial identity, is a challenging task due to the\nhigh complexity and entanglement of common 2D facial feature encoding spaces.\nDespite these challenges, such fine-grained control, by way of disentanglement\nis a crucial enabler for data-driven racial bias mitigation strategies across\nmultiple automated facial analysis tasks, as it allows to analyse, characterise\nand synthesise human facial diversity. In this paper, we propose a novel GAN\nframework to enable fine-grained control over individual race-related phenotype\nattributes of the facial images. Our framework factors the latent (feature)\nspace into elements that correspond to race-related facial phenotype\nrepresentations, thereby separating phenotype aspects (e.g. skin, hair colour,\nnose, eye, mouth shapes), which are notoriously difficult to annotate robustly\nin real-world facial data. Concurrently, we also introduce a high quality\naugmented, diverse 2D face image dataset drawn from CelebA-HQ for GAN training.\nUnlike prior work, our framework only relies upon 2D imagery and related\nparameters to achieve state-of-the-art individual control over race-related\nphenotype attributes with improved photo-realistic output.",
        "updated": "2024-03-29T00:36:38Z",
        "published": "2024-03-29T00:36:38Z",
        "authors": [
            "Seyma Yucer",
            "Amir Atapour Abarghouei",
            "Noura Al Moubayed",
            "Toby P. Breckon"
        ],
        "categories": [
            "cs.CV",
            "cs.LG"
        ],
        "primary_category": "cs.CV"
    },
    "2403.19898v2": {
        "url": "http://arxiv.org/abs/2403.19898v2",
        "title": "Structure Matters: Tackling the Semantic Discrepancy in Diffusion Models\n  for Image Inpainting",
        "summary": "Denoising diffusion probabilistic models for image inpainting aim to add the\nnoise to the texture of image during the forward process and recover masked\nregions with unmasked ones of the texture via the reverse denoising process.\nDespite the meaningful semantics generation, the existing arts suffer from the\nsemantic discrepancy between masked and unmasked regions, since the\nsemantically dense unmasked texture fails to be completely degraded while the\nmasked regions turn to the pure noise in diffusion process, leading to the\nlarge discrepancy between them. In this paper, we aim to answer how unmasked\nsemantics guide texture denoising process;together with how to tackle the\nsemantic discrepancy, to facilitate the consistent and meaningful semantics\ngeneration. To this end, we propose a novel structure-guided diffusion model\nnamed StrDiffusion, to reformulate the conventional texture denoising process\nunder structure guidance to derive a simplified denoising objective for image\ninpainting, while revealing: 1) the semantically sparse structure is beneficial\nto tackle semantic discrepancy in early stage, while dense texture generates\nreasonable semantics in late stage; 2) the semantics from unmasked regions\nessentially offer the time-dependent structure guidance for the texture\ndenoising process, benefiting from the time-dependent sparsity of the structure\nsemantics. For the denoising process, a structure-guided neural network is\ntrained to estimate the simplified denoising objective by exploiting the\nconsistency of the denoised structure between masked and unmasked regions.\nBesides, we devise an adaptive resampling strategy as a formal criterion as\nwhether structure is competent to guide the texture denoising process, while\nregulate their semantic correlations. Extensive experiments validate the merits\nof StrDiffusion over the state-of-the-arts. Our code is available at\nhttps://github.com/htyjers/StrDiffusion.",
        "updated": "2024-04-01T01:27:14Z",
        "published": "2024-03-29T00:40:12Z",
        "authors": [
            "Haipeng Liu",
            "Yang Wang",
            "Biao Qian",
            "Meng Wang",
            "Yong Rui"
        ],
        "comments": "15 pages, 10 figures, to appear CVPR 2024",
        "categories": [
            "cs.CV"
        ],
        "primary_category": "cs.CV"
    },
    "2403.19899v1": {
        "url": "http://arxiv.org/abs/2403.19899v1",
        "title": "Inclusive Design Insights from a Preliminary Image-Based Conversational\n  Search Systems Evaluation",
        "summary": "The digital realm has witnessed the rise of various search modalities, among\nwhich the Image-Based Conversational Search System stands out. This research\ndelves into the design, implementation, and evaluation of this specific system,\njuxtaposing it against its text-based and mixed counterparts. A diverse\nparticipant cohort ensures a broad evaluation spectrum. Advanced tools\nfacilitate emotion analysis, capturing user sentiments during interactions,\nwhile structured feedback sessions offer qualitative insights. Results indicate\nthat while the text-based system minimizes user confusion, the image-based\nsystem presents challenges in direct information interpretation. However, the\nmixed system achieves the highest engagement, suggesting an optimal blend of\nvisual and textual information. Notably, the potential of these systems,\nespecially the image-based modality, to assist individuals with intellectual\ndisabilities is highlighted. The study concludes that the Image-Based\nConversational Search System, though challenging in some aspects, holds\npromise, especially when integrated into a mixed system, offering both clarity\nand engagement.",
        "updated": "2024-03-29T00:45:42Z",
        "published": "2024-03-29T00:45:42Z",
        "authors": [
            "Yue Zheng",
            "Lei Yu",
            "Junmian Chen",
            "Tianyu Xia",
            "Yuanyuan Yin",
            "Shan Wang",
            "Haiming Liu"
        ],
        "categories": [
            "cs.IR"
        ],
        "primary_category": "cs.IR"
    },
    "2403.19901v1": {
        "url": "http://arxiv.org/abs/2403.19901v1",
        "title": "Nonlinear Voltage Regulation of an Auxiliary Energy Storage of a\n  Multiport Interconnection",
        "summary": "In this article, we propose a nonlinear voltage control to ensure power\nexchange in a multiport interconnected system, which consists of a\nbidirectional DC-DC converter and generating-storing devices. The converter\ntopology under consideration is two-stage, composed of an interconnection of a\nbuck with a boost converter. The motivation for this work is the explosive\nincrease in the use of DC-DC converters due to the massification of renewable\nenergies, electric vehicles powertrains, and energy storage systems, where fuel\ncells or batteries can be used as power backup or high-power support during\ntransient phenomena. The converter's voltage step-up and step-down capabilities\nallow the use of supercapacitors with voltage limits that exceed those required\nby the load, thus enabling its use in a broader range of applications. The\ncontrol design for this system does not correspond to that in standard\napplications involving power converters. As it is known, the latter consists of\nfinding a control law such that the closed-loop system has an asymptotically\nstable equilibrium point fulfilling the voltage regulation objectives. Instead,\nin this application, the state does not tend to an equilibrium value in order\nfor the system to be regulated. The converter voltage is regulated at desired\nsome setpoint whereas the other variables are only required to be bounded. To\nachieve a dynamic response that best adapts to changes in system demand and\nensure stability over the defined wide operating range we propose a novel\ncontrol strategy that exploits the partially cascaded structure of the system.\nNumerical and experimental results validate our approach.",
        "updated": "2024-03-29T00:59:36Z",
        "published": "2024-03-29T00:59:36Z",
        "authors": [
            "Felipe Morales",
            "Rafael Cisneros",
            "Romeo Ortega",
            "Antonio Sanchez-Squella"
        ],
        "categories": [
            "eess.SY",
            "cs.SY"
        ],
        "primary_category": "eess.SY"
    },
    "2403.19903v1": {
        "url": "http://arxiv.org/abs/2403.19903v1",
        "title": "Keeping Up With the Winner! Targeted Advertisement to Communities in\n  Social Networks",
        "summary": "When a new product enters a market already dominated by an existing product,\nwill it survive along with this dominant product? Most of the existing works\nhave shown the coexistence of two competing products spreading/being adopted on\noverlaid graphs with same set of users. However, when it comes to the survival\nof a weaker product on the same graph, it has been established that the\nstronger one dominates the market and wipes out the other. This paper makes a\nstep towards narrowing this gap so that a new/weaker product can also survive\nalong with its competitor with a positive market share. Specifically, we\nidentify a locally optimal set of users to induce a community that is targeted\nwith advertisement by the product launching company under a given budget\nconstraint. To this end, we model the system as competing\nSusceptible-Infected-Susceptible (SIS) epidemics and employ perturbation\ntechniques to quantify and attain a positive market share in a cost-efficient\nmanner. Our extensive simulation results with real-world graph dataset show\nthat with our choice of target users, a new product can establish itself with\npositive market share, which otherwise would be dominated and eventually wiped\nout of the competitive market under the same budget constraint.",
        "updated": "2024-03-29T01:07:07Z",
        "published": "2024-03-29T01:07:07Z",
        "authors": [
            "Shailaja Mallick",
            "Vishwaraj Doshi",
            "Do Young Eun"
        ],
        "comments": "To appear in the Proceedings of AAAI ICWSM 2024",
        "categories": [
            "eess.SY",
            "cs.SI",
            "cs.SY"
        ],
        "primary_category": "eess.SY"
    },
    "2403.19904v1": {
        "url": "http://arxiv.org/abs/2403.19904v1",
        "title": "Fully Geometric Panoramic Localization",
        "summary": "We introduce a lightweight and accurate localization method that only\nutilizes the geometry of 2D-3D lines. Given a pre-captured 3D map, our approach\nlocalizes a panorama image, taking advantage of the holistic 360 view. The\nsystem mitigates potential privacy breaches or domain discrepancies by avoiding\ntrained or hand-crafted visual descriptors. However, as lines alone can be\nambiguous, we express distinctive yet compact spatial contexts from\nrelationships between lines, namely the dominant directions of parallel lines\nand the intersection between non-parallel lines. The resulting representations\nare efficient in processing time and memory compared to conventional visual\ndescriptor-based methods. Given the groups of dominant line directions and\ntheir intersections, we accelerate the search process to test thousands of pose\ncandidates in less than a millisecond without sacrificing accuracy. We\nempirically show that the proposed 2D-3D matching can localize panoramas for\nchallenging scenes with similar structures, dramatic domain shifts or\nillumination changes. Our fully geometric approach does not involve extensive\nparameter tuning or neural network training, making it a practical algorithm\nthat can be readily deployed in the real world. Project page including the code\nis available through this link: https://82magnolia.github.io/fgpl/.",
        "updated": "2024-03-29T01:07:20Z",
        "published": "2024-03-29T01:07:20Z",
        "authors": [
            "Junho Kim",
            "Jiwon Jeong",
            "Young Min Kim"
        ],
        "comments": "Accepted to CVPR 2024",
        "categories": [
            "cs.CV"
        ],
        "primary_category": "cs.CV"
    },
    "2404.00505v2": {
        "url": "http://arxiv.org/abs/2404.00505v2",
        "title": "Transfer Learning with Reconstruction Loss",
        "summary": "In most applications of utilizing neural networks for mathematical\noptimization, a dedicated model is trained for each specific optimization\nobjective. However, in many scenarios, several distinct yet correlated\nobjectives or tasks often need to be optimized on the same set of problem\ninputs. Instead of independently training a different neural network for each\nproblem separately, it would be more efficient to exploit the correlations\nbetween these objectives and to train multiple neural network models with\nshared model parameters and feature representations. To achieve this, this\npaper first establishes the concept of common information: the shared knowledge\nrequired for solving the correlated tasks, then proposes a novel approach for\nmodel training by adding into the model an additional reconstruction stage\nassociated with a new reconstruction loss. This loss is for reconstructing the\ncommon information starting from a selected hidden layer in the model. The\nproposed approach encourages the learned features to be general and\ntransferable, and therefore can be readily used for efficient transfer\nlearning. For numerical simulations, three applications are studied: transfer\nlearning on classifying MNIST handwritten digits, the device-to-device wireless\nnetwork power allocation, and the multiple-input-single-output network downlink\nbeamforming and localization. Simulation results suggest that the proposed\napproach is highly efficient in data and model complexity, is resilient to\nover-fitting, and has competitive performances.",
        "updated": "2024-04-12T00:16:43Z",
        "published": "2024-03-31T00:22:36Z",
        "authors": [
            "Wei Cui",
            "Wei Yu"
        ],
        "comments": "16 pages, 5 figures. To appear in IEEE Transactions on Machine\n  Learning in Communications and Networking (TMLCN)",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.NI",
            "stat.ML"
        ],
        "primary_category": "cs.LG",
        "doi": "10.1109/TMLCN.2024.3384329"
    },
    "2404.00507v1": {
        "url": "http://arxiv.org/abs/2404.00507v1",
        "title": "THEMIS: Time, Heterogeneity, and Energy Minded Scheduling for Fair\n  Multi-Tenant Use in FPGAs",
        "summary": "Using correct design metrics and understanding the limitations of the\nunderlying technology is critical to developing effective scheduling\nalgorithms. Unfortunately, existing scheduling techniques used \\emph{incorrect}\nmetrics and had \\emph{unrealistic} assumptions for fair scheduling of\nmulti-tenant FPGAs where each tenant is aimed to share approximately the same\nnumber of resources both spatially and temporally.\n  This paper introduces an enhanced fair scheduling algorithm for multi-tenant\nFPGA use, addressing previous metric and assumption issues, with three specific\nimprovements claimed First, our method ensures spatiotemporal fairness by\nconsidering both spatial and temporal aspects, addressing the limitation of\nprior work that assumed uniform task latency. Second, we incorporate energy\nconsiderations into fairness by adjusting scheduling intervals and accounting\nfor energy overhead, thereby balancing energy efficiency with fairness. Third,\nwe acknowledge overlooked aspects of FPGA multi-tenancy, including\nheterogeneous regions and the constraints on dynamically merging/splitting\npartially reconfigurable regions. We develop and evaluate our improved fair\nscheduling algorithm with these three enhancements. Inspired by the Greek\ngoddess of law and personification of justice, we name our fair scheduling\nsolution THEMIS: \\underline{T}ime, \\underline{H}eterogeneity, and\n\\underline{E}nergy \\underline{Mi}nded \\underline{S}cheduling.\n  We used the Xilinx Zedboard XC7Z020 to quantify our approach's savings.\nCompared to previous algorithms, our improved scheduling algorithm enhances\nfairness between 24.2--98.4\\% and allows a trade-off between 55.3$\\times$ in\nenergy vs. 69.3$\\times$ in fairness. The paper thus informs cloud providers\nabout future scheduling optimizations for fairness with related challenges and\nopportunities.",
        "updated": "2024-03-31T00:29:55Z",
        "published": "2024-03-31T00:29:55Z",
        "authors": [
            "Emre Karabulut",
            "Arsalan Ali Malik",
            "Amro Awad",
            "Aydin Aysu"
        ],
        "categories": [
            "cs.OS",
            "cs.DC"
        ],
        "primary_category": "cs.OS"
    },
    "2404.00509v1": {
        "url": "http://arxiv.org/abs/2404.00509v1",
        "title": "DailyMAE: Towards Pretraining Masked Autoencoders in One Day",
        "summary": "Recently, masked image modeling (MIM), an important self-supervised learning\n(SSL) method, has drawn attention for its effectiveness in learning data\nrepresentation from unlabeled data. Numerous studies underscore the advantages\nof MIM, highlighting how models pretrained on extensive datasets can enhance\nthe performance of downstream tasks. However, the high computational demands of\npretraining pose significant challenges, particularly within academic\nenvironments, thereby impeding the SSL research progress. In this study, we\npropose efficient training recipes for MIM based SSL that focuses on mitigating\ndata loading bottlenecks and employing progressive training techniques and\nother tricks to closely maintain pretraining performance. Our library enables\nthe training of a MAE-Base/16 model on the ImageNet 1K dataset for 800 epochs\nwithin just 18 hours, using a single machine equipped with 8 A100 GPUs. By\nachieving speed gains of up to 5.8 times, this work not only demonstrates the\nfeasibility of conducting high-efficiency SSL training but also paves the way\nfor broader accessibility and promotes advancement in SSL research particularly\nfor prototyping and initial testing of SSL ideas. The code is available in\nhttps://github.com/erow/FastSSL.",
        "updated": "2024-03-31T00:59:10Z",
        "published": "2024-03-31T00:59:10Z",
        "authors": [
            "Jiantao Wu",
            "Shentong Mo",
            "Sara Atito",
            "Zhenhua Feng",
            "Josef Kittler",
            "Muhammad Awais"
        ],
        "categories": [
            "cs.LG",
            "cs.CV"
        ],
        "primary_category": "cs.LG"
    },
    "2404.00510v1": {
        "url": "http://arxiv.org/abs/2404.00510v1",
        "title": "Denoising Low-dose Images Using Deep Learning of Time Series Images",
        "summary": "Digital image devices have been widely applied in many fields, including\nscientific imaging, recognition of individuals, and remote sensing. As the\napplication of these imaging technologies to autonomous driving and\nmeasurement, image noise generated when observation cannot be performed with a\nsufficient dose has become a major problem. Machine learning denoise technology\nis expected to be the solver of this problem, but there are the following\nproblems. Here we report, artifacts generated by machine learning denoise in\nultra-low dose observation using an in-situ observation video of an electron\nmicroscope as an example. And as a method to solve this problem, we propose a\nmethod to decompose a time series image into a 2D image of the spatial axis and\ntime to perform machine learning denoise. Our method opens new avenues accurate\nand stable reconstruction of continuous high-resolution images from low-dose\nimaging in science, industry, and life.",
        "updated": "2024-03-31T01:05:28Z",
        "published": "2024-03-31T01:05:28Z",
        "authors": [
            "Yang Shao",
            "Toshie Yaguchi",
            "Toshiaki Tanigaki"
        ],
        "categories": [
            "cs.CV",
            "eess.IV"
        ],
        "primary_category": "cs.CV"
    },
    "2404.00511v3": {
        "url": "http://arxiv.org/abs/2404.00511v3",
        "title": "MIPS at SemEval-2024 Task 3: Multimodal Emotion-Cause Pair Extraction in\n  Conversations with Multimodal Language Models",
        "summary": "This paper presents our winning submission to Subtask 2 of SemEval 2024 Task\n3 on multimodal emotion cause analysis in conversations. We propose a novel\nMultimodal Emotion Recognition and Multimodal Emotion Cause Extraction\n(MER-MCE) framework that integrates text, audio, and visual modalities using\nspecialized emotion encoders. Our approach sets itself apart from\ntop-performing teams by leveraging modality-specific features for enhanced\nemotion understanding and causality inference. Experimental evaluation\ndemonstrates the advantages of our multimodal approach, with our submission\nachieving a competitive weighted F1 score of 0.3435, ranking third with a\nmargin of only 0.0339 behind the 1st team and 0.0025 behind the 2nd team.\nProject: https://github.com/MIPS-COLT/MER-MCE.git",
        "updated": "2024-04-11T05:14:35Z",
        "published": "2024-03-31T01:16:02Z",
        "authors": [
            "Zebang Cheng",
            "Fuqiang Niu",
            "Yuxiang Lin",
            "Zhi-Qi Cheng",
            "Bowen Zhang",
            "Xiaojiang Peng"
        ],
        "comments": "Ranked 3rd in SemEval '24 Task 3 with F1 of 0.3435, close to 1st &\n  2nd by 0.0339 & 0.0025",
        "categories": [
            "cs.CL",
            "cs.CV",
            "cs.MM"
        ],
        "primary_category": "cs.CL"
    },
    "2404.00513v3": {
        "url": "http://arxiv.org/abs/2404.00513v3",
        "title": "Transformer based Pluralistic Image Completion with Reduced Information\n  Loss",
        "summary": "Transformer based methods have achieved great success in image inpainting\nrecently. However, we find that these solutions regard each pixel as a token,\nthus suffering from an information loss issue from two aspects: 1) They\ndownsample the input image into much lower resolutions for efficiency\nconsideration. 2) They quantize $256^3$ RGB values to a small number (such as\n512) of quantized color values. The indices of quantized pixels are used as\ntokens for the inputs and prediction targets of the transformer. To mitigate\nthese issues, we propose a new transformer based framework called \"PUT\".\nSpecifically, to avoid input downsampling while maintaining computation\nefficiency, we design a patch-based auto-encoder P-VQVAE. The encoder converts\nthe masked image into non-overlapped patch tokens and the decoder recovers the\nmasked regions from the inpainted tokens while keeping the unmasked regions\nunchanged. To eliminate the information loss caused by input quantization, an\nUn-quantized Transformer is applied. It directly takes features from the\nP-VQVAE encoder as input without any quantization and only regards the\nquantized tokens as prediction targets. Furthermore, to make the inpainting\nprocess more controllable, we introduce semantic and structural conditions as\nextra guidance. Extensive experiments show that our method greatly outperforms\nexisting transformer based methods on image fidelity and achieves much higher\ndiversity and better fidelity than state-of-the-art pluralistic inpainting\nmethods on complex large-scale datasets (e.g., ImageNet). Codes are available\nat https://github.com/liuqk3/PUT.",
        "updated": "2024-04-15T01:15:34Z",
        "published": "2024-03-31T01:20:16Z",
        "authors": [
            "Qiankun Liu",
            "Yuqi Jiang",
            "Zhentao Tan",
            "Dongdong Chen",
            "Ying Fu",
            "Qi Chu",
            "Gang Hua",
            "Nenghai Yu"
        ],
        "comments": "Accepted by TPAMI (2024). arXiv admin note: text overlap with\n  arXiv:2205.05076",
        "categories": [
            "cs.CV"
        ],
        "primary_category": "cs.CV"
    },
    "2404.00514v1": {
        "url": "http://arxiv.org/abs/2404.00514v1",
        "title": "Human-Robot Co-Transportation with Human Uncertainty-Aware MPC and Pose\n  Optimization",
        "summary": "This paper proposes a new control algorithm for human-robot co-transportation\nbased on a robot manipulator equipped with a mobile base and a robotic arm. The\nprimary focus is to adapt to human uncertainties through the robot's whole-body\ndynamics and pose optimization. We introduce an augmented Model Predictive\nControl (MPC) formulation that explicitly models human uncertainties and\ncontains extra variables than regular MPC to optimize the pose of the robotic\narm. The core of our methodology involves a two-step iterative design: At each\nplanning horizon, we select the best pose of the robotic arm (joint angle\ncombination) from a candidate set, aiming to achieve the lowest estimated\ncontrol cost. This selection is based on solving an uncertainty-aware Discrete\nAlgebraic Ricatti Equation (DARE), which also informs the optimal control\ninputs for both the mobile base and the robotic arm. To validate the\neffectiveness of the proposed approach, we provide theoretical derivation for\nthe uncertainty-aware DARE and perform simulated and proof-of-concept hardware\nexperiments using a Fetch robot under varying conditions, including different\nnominal trajectories and noise levels. The results reveal that our proposed\napproach outperforms baseline algorithms, maintaining similar execution time\nwith that do not consider human uncertainty or do not perform pose\noptimization.",
        "updated": "2024-03-31T01:21:55Z",
        "published": "2024-03-31T01:21:55Z",
        "authors": [
            "Al Jaber Mahmud",
            "Amir Hossain Raj",
            "Duc M. Nguyen",
            "Xuesu Xiao",
            "Xuan Wang"
        ],
        "comments": "8 pages, 6 figures",
        "categories": [
            "cs.RO"
        ],
        "primary_category": "cs.RO"
    },
    "2404.00520v1": {
        "url": "http://arxiv.org/abs/2404.00520v1",
        "title": "Competition-Aware Decision-Making Approach for Mobile Robots in Racing\n  Scenarios",
        "summary": "This paper presents a game-theoretic strategy for racing, where the\nautonomous ego agent seeks to block a racing opponent that aims to overtake the\nego agent. After a library of trajectory candidates and an associated reward\nmatrix are constructed, the optimal trajectory in terms of maximizing the\ncumulative reward over the planning horizon is determined based on the level-K\nreasoning framework. In particular, the level of the opponent is estimated\nonline according to its behavior over a past window and is then used to\ndetermine the trajectory for the ego agent. Taking into account that the\nopponent may change its level and strategy during the decision process of the\nego agent, we introduce a trajectory mixing strategy that blends the level-K\noptimal trajectory with a fail-safe trajectory. The overall algorithm was\ntested and evaluated in various simulated racing scenarios, which also includes\nhuman-in-the-loop experiments. Comparative analysis against the conventional\nlevel-K framework demonstrates the superiority of our proposed approach in\nterms of overtake-blocking success rates.",
        "updated": "2024-03-31T01:40:24Z",
        "published": "2024-03-31T01:40:24Z",
        "authors": [
            "Kyoungtae Ji",
            "Sangjae Bae",
            "Nan Li",
            "Kyoungseok Han"
        ],
        "comments": "7 pages, 8 figures",
        "categories": [
            "cs.RO",
            "math.OC"
        ],
        "primary_category": "cs.RO"
    },
    "2404.00521v3": {
        "url": "http://arxiv.org/abs/2404.00521v3",
        "title": "CHAIN: Enhancing Generalization in Data-Efficient GANs via lipsCHitz\n  continuity constrAIned Normalization",
        "summary": "Generative Adversarial Networks (GANs) significantly advanced image\ngeneration but their performance heavily depends on abundant training data. In\nscenarios with limited data, GANs often struggle with discriminator overfitting\nand unstable training. Batch Normalization (BN), despite being known for\nenhancing generalization and training stability, has rarely been used in the\ndiscriminator of Data-Efficient GANs. Our work addresses this gap by\nidentifying a critical flaw in BN: the tendency for gradient explosion during\nthe centering and scaling steps. To tackle this issue, we present CHAIN\n(lipsCHitz continuity constrAIned Normalization), which replaces the\nconventional centering step with zero-mean regularization and integrates a\nLipschitz continuity constraint in the scaling step. CHAIN further enhances GAN\ntraining by adaptively interpolating the normalized and unnormalized features,\neffectively avoiding discriminator overfitting. Our theoretical analyses firmly\nestablishes CHAIN's effectiveness in reducing gradients in latent features and\nweights, improving stability and generalization in GAN training. Empirical\nevidence supports our theory. CHAIN achieves state-of-the-art results in\ndata-limited scenarios on CIFAR-10/100, ImageNet, five low-shot and seven\nhigh-resolution few-shot image datasets. Code:\nhttps://github.com/MaxwellYaoNi/CHAIN",
        "updated": "2024-04-07T15:04:47Z",
        "published": "2024-03-31T01:41:36Z",
        "authors": [
            "Yao Ni",
            "Piotr Koniusz"
        ],
        "comments": "Accepted by CVPR2024. 26 pages full version. Code:\n  https://github.com/MaxwellYaoNi/CHAIN",
        "categories": [
            "cs.LG",
            "cs.CV"
        ],
        "primary_category": "cs.LG"
    },
    "2404.00522v1": {
        "url": "http://arxiv.org/abs/2404.00522v1",
        "title": "Minimum-Norm Interpolation Under Covariate Shift",
        "summary": "Transfer learning is a critical part of real-world machine learning\ndeployments and has been extensively studied in experimental works with\noverparameterized neural networks. However, even in the simplest setting of\nlinear regression a notable gap still exists in the theoretical understanding\nof transfer learning. In-distribution research on high-dimensional linear\nregression has led to the identification of a phenomenon known as\n\\textit{benign overfitting}, in which linear interpolators overfit to noisy\ntraining labels and yet still generalize well. This behavior occurs under\nspecific conditions on the source covariance matrix and input data dimension.\nTherefore, it is natural to wonder how such high-dimensional linear models\nbehave under transfer learning. We prove the first non-asymptotic excess risk\nbounds for benignly-overfit linear interpolators in the transfer learning\nsetting. From our analysis, we propose a taxonomy of \\textit{beneficial} and\n\\textit{malignant} covariate shifts based on the degree of\noverparameterization. We follow our analysis with empirical studies that show\nthese beneficial and malignant covariate shifts for linear interpolators on\nreal image data, and for fully-connected neural networks in settings where the\ninput data dimension is larger than the training sample size.",
        "updated": "2024-03-31T01:41:57Z",
        "published": "2024-03-31T01:41:57Z",
        "authors": [
            "Neil Mallinar",
            "Austin Zane",
            "Spencer Frei",
            "Bin Yu"
        ],
        "categories": [
            "cs.LG",
            "stat.ML"
        ],
        "primary_category": "cs.LG"
    },
    "2404.01445v1": {
        "url": "http://arxiv.org/abs/2404.01445v1",
        "title": "Using Dynamic Safety Margins as Control Barrier Functions",
        "summary": "This paper provides an approach to design control barrier functions (CBFs)\nusing the notion of dynamic safety margins (DSMs). In particular, it is shown\nthat DSMs are CBFs for an augmented system. The proposed approach can handle\nmultiple state and input constraints using the control-sharing property of\nCBFs. Moreover, it makes no assumption on the relative degree of the\nconstraints. Numerical simulations show that the method outperforms existing\nDSM-based approaches, while also guaranteeing safety and recursive feasibility.",
        "updated": "2024-04-01T19:32:30Z",
        "published": "2024-04-01T19:32:30Z",
        "authors": [
            "Victor Freire",
            "Marco M. Nicotra"
        ],
        "comments": "7 pages, 2 figures",
        "categories": [
            "eess.SY",
            "cs.SY"
        ],
        "primary_category": "eess.SY"
    },
    "2404.01446v2": {
        "url": "http://arxiv.org/abs/2404.01446v2",
        "title": "Finding Regions of Interest in Whole Slide Images Using Multiple\n  Instance Learning",
        "summary": "Whole Slide Images (WSI), obtained by high-resolution digital scanning of\nmicroscope slides at multiple scales, are the cornerstone of modern Digital\nPathology. However, they represent a particular challenge to\nAI-based/AI-mediated analysis because pathology labeling is typically done at\nslide-level, instead of tile-level. It is not just that medical diagnostics is\nrecorded at the specimen level, the detection of oncogene mutation is also\nexperimentally obtained, and recorded by initiatives like The Cancer Genome\nAtlas (TCGA), at the slide level. This configures a dual challenge: a)\naccurately predicting the overall cancer phenotype and b) finding out what\ncellular morphologies are associated with it at the tile level. To address\nthese challenges, a weakly supervised Multiple Instance Learning (MIL) approach\nwas explored for two prevalent cancer types, Invasive Breast Carcinoma\n(TCGA-BRCA) and Lung Squamous Cell Carcinoma (TCGA-LUSC). This approach was\nexplored for tumor detection at low magnification levels and TP53 mutations at\nvarious levels. Our results show that a novel additive implementation of MIL\nmatched the performance of reference implementation (AUC 0.96), and was only\nslightly outperformed by Attention MIL (AUC 0.97). More interestingly from the\nperspective of the molecular pathologist, these different AI architectures\nidentify distinct sensitivities to morphological features (through the\ndetection of Regions of Interest, RoI) at different amplification levels.\nTellingly, TP53 mutation was most sensitive to features at the higher\napplications where cellular morphology is resolved.",
        "updated": "2024-04-11T06:58:18Z",
        "published": "2024-04-01T19:33:41Z",
        "authors": [
            "Martim Afonso",
            "Praphulla M. S. Bhawsar",
            "Monjoy Saha",
            "Jonas S. Almeida",
            "Arlindo L. Oliveira"
        ],
        "categories": [
            "cs.CV",
            "cs.AI"
        ],
        "primary_category": "cs.CV"
    },
    "2404.01448v2": {
        "url": "http://arxiv.org/abs/2404.01448v2",
        "title": "Prior Frequency Guided Diffusion Model for Limited Angle (LA)-CBCT\n  Reconstruction",
        "summary": "Cone-beam computed tomography (CBCT) is widely used in image-guided\nradiotherapy. Reconstructing CBCTs from limited-angle acquisitions (LA-CBCT) is\nhighly desired for improved imaging efficiency, dose reduction, and better\nmechanical clearance. LA-CBCT reconstruction, however, suffers from severe\nunder-sampling artifacts, making it a highly ill-posed inverse problem.\nDiffusion models can generate data/images by reversing a data-noising process\nthrough learned data distributions; and can be incorporated as a\ndenoiser/regularizer in LA-CBCT reconstruction. In this study, we developed a\ndiffusion model-based framework, prior frequency-guided diffusion model\n(PFGDM), for robust and structure-preserving LA-CBCT reconstruction. PFGDM uses\na conditioned diffusion model as a regularizer for LA-CBCT reconstruction, and\nthe condition is based on high-frequency information extracted from\npatient-specific prior CT scans which provides a strong anatomical prior for\nLA-CBCT reconstruction. Specifically, we developed two variants of PFGDM\n(PFGDM-A and PFGDM-B) with different conditioning schemes. PFGDM-A applies the\nhigh-frequency CT information condition until a pre-optimized iteration step,\nand drops it afterwards to enable both similar and differing CT/CBCT anatomies\nto be reconstructed. PFGDM-B, on the other hand, continuously applies the prior\nCT information condition in every reconstruction step, while with a decaying\nmechanism, to gradually phase out the reconstruction guidance from the prior CT\nscans. The two variants of PFGDM were tested and compared with current\navailable LA-CBCT reconstruction solutions, via metrics including PSNR and\nSSIM. PFGDM outperformed all traditional and diffusion model-based methods.\nPFGDM reconstructs high-quality LA-CBCTs under very-limited gantry angles,\nallowing faster and more flexible CBCT scans with dose reductions.",
        "updated": "2024-04-09T03:47:27Z",
        "published": "2024-04-01T19:41:33Z",
        "authors": [
            "Jiacheng Xie",
            "Hua-Chieh Shao",
            "Yunxiang Li",
            "You Zhang"
        ],
        "comments": "20 pages, 8 figures, submitted to Physics in Medicine & Biology",
        "categories": [
            "physics.med-ph",
            "cs.LG"
        ],
        "primary_category": "physics.med-ph"
    },
    "2404.01453v1": {
        "url": "http://arxiv.org/abs/2404.01453v1",
        "title": "Unveiling Divergent Inductive Biases of LLMs on Temporal Data",
        "summary": "Unraveling the intricate details of events in natural language necessitates a\nsubtle understanding of temporal dynamics. Despite the adeptness of Large\nLanguage Models (LLMs) in discerning patterns and relationships from data,\ntheir inherent comprehension of temporal dynamics remains a formidable\nchallenge. This research meticulously explores these intrinsic challenges\nwithin LLMs, with a specific emphasis on evaluating the performance of GPT-3.5\nand GPT-4 models in the analysis of temporal data. Employing two distinct\nprompt types, namely Question Answering (QA) format and Textual Entailment (TE)\nformat, our analysis probes into both implicit and explicit events. The\nfindings underscore noteworthy trends, revealing disparities in the performance\nof GPT-3.5 and GPT-4. Notably, biases toward specific temporal relationships\ncome to light, with GPT-3.5 demonstrating a preference for \"AFTER'' in the QA\nformat for both implicit and explicit events, while GPT-4 leans towards\n\"BEFORE''. Furthermore, a consistent pattern surfaces wherein GPT-3.5 tends\ntowards \"TRUE'', and GPT-4 exhibits a preference for \"FALSE'' in the TE format\nfor both implicit and explicit events. This persistent discrepancy between\nGPT-3.5 and GPT-4 in handling temporal data highlights the intricate nature of\ninductive bias in LLMs, suggesting that the evolution of these models may not\nmerely mitigate bias but may introduce new layers of complexity.",
        "updated": "2024-04-01T19:56:41Z",
        "published": "2024-04-01T19:56:41Z",
        "authors": [
            "Sindhu Kishore",
            "Hangfeng He"
        ],
        "categories": [
            "cs.CL",
            "cs.AI"
        ],
        "primary_category": "cs.CL"
    },
    "2404.01459v1": {
        "url": "http://arxiv.org/abs/2404.01459v1",
        "title": "Game-Theoretic Deep Reinforcement Learning to Minimize Carbon Emissions\n  and Energy Costs for AI Inference Workloads in Geo-Distributed Data Centers",
        "summary": "Data centers are increasingly using more energy due to the rise in Artificial\nIntelligence (AI) workloads, which negatively impacts the environment and\nraises operational costs. Reducing operating expenses and carbon emissions\nwhile maintaining performance in data centers is a challenging problem. This\nwork introduces a unique approach combining Game Theory (GT) and Deep\nReinforcement Learning (DRL) for optimizing the distribution of AI inference\nworkloads in geo-distributed data centers to reduce carbon emissions and cloud\noperating (energy + data transfer) costs. The proposed technique integrates the\nprinciples of non-cooperative Game Theory into a DRL framework, enabling data\ncenters to make intelligent decisions regarding workload allocation while\nconsidering the heterogeneity of hardware resources, the dynamic nature of\nelectricity prices, inter-data center data transfer costs, and carbon\nfootprints. We conducted extensive experiments comparing our game-theoretic DRL\n(GT-DRL) approach with current DRL-based and other optimization techniques. The\nresults demonstrate that our strategy outperforms the state-of-the-art in\nreducing carbon emissions and minimizing cloud operating costs without\ncompromising computational performance. This work has significant implications\nfor achieving sustainability and cost-efficiency in data centers handling AI\ninference workloads across diverse geographic locations.",
        "updated": "2024-04-01T20:13:28Z",
        "published": "2024-04-01T20:13:28Z",
        "authors": [
            "Ninad Hogade",
            "Sudeep Pasricha"
        ],
        "comments": "arXiv admin note: text overlap with arXiv:2106.00066",
        "categories": [
            "cs.DC",
            "cs.AI",
            "cs.LG"
        ],
        "primary_category": "cs.DC"
    },
    "2404.01462v1": {
        "url": "http://arxiv.org/abs/2404.01462v1",
        "title": "OpenChemIE: An Information Extraction Toolkit For Chemistry Literature",
        "summary": "Information extraction from chemistry literature is vital for constructing\nup-to-date reaction databases for data-driven chemistry. Complete extraction\nrequires combining information across text, tables, and figures, whereas prior\nwork has mainly investigated extracting reactions from single modalities. In\nthis paper, we present OpenChemIE to address this complex challenge and enable\nthe extraction of reaction data at the document level. OpenChemIE approaches\nthe problem in two steps: extracting relevant information from individual\nmodalities and then integrating the results to obtain a final list of\nreactions. For the first step, we employ specialized neural models that each\naddress a specific task for chemistry information extraction, such as parsing\nmolecules or reactions from text or figures. We then integrate the information\nfrom these modules using chemistry-informed algorithms, allowing for the\nextraction of fine-grained reaction data from reaction condition and substrate\nscope investigations. Our machine learning models attain state-of-the-art\nperformance when evaluated individually, and we meticulously annotate a\nchallenging dataset of reaction schemes with R-groups to evaluate our pipeline\nas a whole, achieving an F1 score of 69.5%. Additionally, the reaction\nextraction results of \\ours attain an accuracy score of 64.3% when directly\ncompared against the Reaxys chemical database. We provide OpenChemIE freely to\nthe public as an open-source package, as well as through a web interface.",
        "updated": "2024-04-01T20:16:21Z",
        "published": "2024-04-01T20:16:21Z",
        "authors": [
            "Vincent Fan",
            "Yujie Qian",
            "Alex Wang",
            "Amber Wang",
            "Connor W. Coley",
            "Regina Barzilay"
        ],
        "comments": "To be submitted to the Journal of Chemical Information and Modeling",
        "categories": [
            "cs.LG",
            "cs.CL",
            "cs.IR"
        ],
        "primary_category": "cs.LG"
    },
    "2404.01464v1": {
        "url": "http://arxiv.org/abs/2404.01464v1",
        "title": "Data-Efficient Unsupervised Interpolation Without Any Intermediate Frame\n  for 4D Medical Images",
        "summary": "4D medical images, which represent 3D images with temporal information, are\ncrucial in clinical practice for capturing dynamic changes and monitoring\nlong-term disease progression. However, acquiring 4D medical images poses\nchallenges due to factors such as radiation exposure and imaging duration,\nnecessitating a balance between achieving high temporal resolution and\nminimizing adverse effects. Given these circumstances, not only is data\nacquisition challenging, but increasing the frame rate for each dataset also\nproves difficult. To address this challenge, this paper proposes a simple yet\neffective Unsupervised Volumetric Interpolation framework, UVI-Net. This\nframework facilitates temporal interpolation without the need for any\nintermediate frames, distinguishing it from the majority of other existing\nunsupervised methods. Experiments on benchmark datasets demonstrate significant\nimprovements across diverse evaluation metrics compared to unsupervised and\nsupervised baselines. Remarkably, our approach achieves this superior\nperformance even when trained with a dataset as small as one, highlighting its\nexceptional robustness and efficiency in scenarios with sparse supervision.\nThis positions UVI-Net as a compelling alternative for 4D medical imaging,\nparticularly in settings where data availability is limited. The source code is\navailable at https://github.com/jungeun122333/UVI-Net.",
        "updated": "2024-04-01T20:25:04Z",
        "published": "2024-04-01T20:25:04Z",
        "authors": [
            "JungEun Kim",
            "Hangyul Yoon",
            "Geondo Park",
            "Kyungsu Kim",
            "Eunho Yang"
        ],
        "comments": "CVPR 2024",
        "categories": [
            "eess.IV",
            "cs.AI",
            "cs.CV",
            "cs.LG"
        ],
        "primary_category": "eess.IV"
    },
    "2404.01466v1": {
        "url": "http://arxiv.org/abs/2404.01466v1",
        "title": "TS-CausalNN: Learning Temporal Causal Relations from Non-linear\n  Non-stationary Time Series Data",
        "summary": "The growing availability and importance of time series data across various\ndomains, including environmental science, epidemiology, and economics, has led\nto an increasing need for time-series causal discovery methods that can\nidentify the intricate relationships in the non-stationary, non-linear, and\noften noisy real world data. However, the majority of current time series\ncausal discovery methods assume stationarity and linear relations in data,\nmaking them infeasible for the task. Further, the recent deep learning-based\nmethods rely on the traditional causal structure learning approaches making\nthem computationally expensive. In this paper, we propose a Time-Series Causal\nNeural Network (TS-CausalNN) - a deep learning technique to discover\ncontemporaneous and lagged causal relations simultaneously. Our proposed\narchitecture comprises (i) convolutional blocks comprising parallel custom\ncausal layers, (ii) acyclicity constraint, and (iii) optimization techniques\nusing the augmented Lagrangian approach. In addition to the simple parallel\ndesign, an advantage of the proposed model is that it naturally handles the\nnon-stationarity and non-linearity of the data. Through experiments on multiple\nsynthetic and real world datasets, we demonstrate the empirical proficiency of\nour proposed approach as compared to several state-of-the-art methods. The\ninferred graphs for the real world dataset are in good agreement with the\ndomain understanding.",
        "updated": "2024-04-01T20:33:29Z",
        "published": "2024-04-01T20:33:29Z",
        "authors": [
            "Omar Faruque",
            "Sahara Ali",
            "Xue Zheng",
            "Jianwu Wang"
        ],
        "categories": [
            "cs.LG",
            "stat.ME"
        ],
        "primary_category": "cs.LG"
    },
    "2404.01467v1": {
        "url": "http://arxiv.org/abs/2404.01467v1",
        "title": "Transnational Network Dynamics of Problematic Information Diffusion",
        "summary": "This study maps the spread of two cases of COVID-19 conspiracy theories and\nmisinformation in Spanish and French in Latin American and French-speaking\ncommunities on Facebook, and thus contributes to understanding the dynamics,\nreach and consequences of emerging transnational misinformation networks. The\nfindings show that co-sharing behavior of public Facebook groups created\ntransnational networks by sharing videos of Medicos por la Verdad (MPV)\nconspiracy theories in Spanish and hydroxychloroquine-related misinformation\nsparked by microbiologist Didier Raoult (DR) in French, usually igniting the\nsurge of locally led interest groups across the Global South. Using inferential\nmethods, the study shows how these networks are enabled primarily by shared\ncultural and thematic attributes among Facebook groups, effectively creating\nvery large, networked audiences. The study contributes to the understanding of\nhow potentially harmful conspiracy theories and misinformation transcend\nnational borders through non-English speaking online communities, further\nhighlighting the overlooked role of transnationalism in global misinformation\ndiffusion and the potentially disproportionate harm that it causes in\nvulnerable communities across the globe.",
        "updated": "2024-04-01T20:33:29Z",
        "published": "2024-04-01T20:33:29Z",
        "authors": [
            "Esteban Villa-Turek",
            "Rod Abhari",
            "Erik C. Nisbet",
            "Yu Xu",
            "Ayse Deniz Lokmanoglu"
        ],
        "categories": [
            "cs.SI",
            "physics.soc-ph",
            "stat.AP"
        ],
        "primary_category": "cs.SI"
    },
    "2404.01468v1": {
        "url": "http://arxiv.org/abs/2404.01468v1",
        "title": "Performance triggered adaptive model reduction for soil moisture\n  estimation in precision irrigation",
        "summary": "Accurate soil moisture information is crucial for developing precise\nirrigation control strategies to enhance water use efficiency. Soil moisture\nestimation based on limited soil moisture sensors is crucial for obtaining\ncomprehensive soil moisture information when dealing with large-scale\nagricultural fields. The major challenge in soil moisture estimation lies in\nthe high dimensionality of the spatially discretized agro-hydrological models.\nIn this work, we propose a performance-triggered adaptive model reduction\napproach to address this challenge. The proposed approach employs a\ntrajectory-based unsupervised machine learning technique, and a prediction\nperformance-based triggering scheme is designed to govern model updates\nadaptively in a way such that the prediction error between the reduced model\nand the original model over a prediction horizon is maintained below a\npredetermined threshold. An adaptive extended Kalman filter (EKF) is designed\nbased on the reduced model for soil moisture estimation. The applicability and\nperformance of the proposed approach are evaluated extensively through the\napplication to a simulated large-scale agricultural field.",
        "updated": "2024-04-01T20:37:14Z",
        "published": "2024-04-01T20:37:14Z",
        "authors": [
            "Sarupa Debnath",
            "Bernard T. Agyeman",
            "Soumya R. Sahoo",
            "Xunyuan Yin",
            "Jinfeng Liu"
        ],
        "categories": [
            "eess.SY",
            "cs.SY",
            "math.DS",
            "stat.AP"
        ],
        "primary_category": "eess.SY"
    },
    "2404.02431v1": {
        "url": "http://arxiv.org/abs/2404.02431v1",
        "title": "On the Multilingual Ability of Decoder-based Pre-trained Language\n  Models: Finding and Controlling Language-Specific Neurons",
        "summary": "Current decoder-based pre-trained language models (PLMs) successfully\ndemonstrate multilingual capabilities. However, it is unclear how these models\nhandle multilingualism. We analyze the neuron-level internal behavior of\nmultilingual decoder-based PLMs, Specifically examining the existence of\nneurons that fire ``uniquely for each language'' within decoder-only\nmultilingual PLMs. We analyze six languages: English, German, French, Spanish,\nChinese, and Japanese, and show that language-specific neurons are unique, with\na slight overlap (< 5%) between languages. These neurons are mainly distributed\nin the models' first and last few layers. This trend remains consistent across\nlanguages and models. Additionally, we tamper with less than 1% of the total\nneurons in each model during inference and demonstrate that tampering with a\nfew language-specific neurons drastically changes the probability of target\nlanguage occurrence in text generation.",
        "updated": "2024-04-03T03:37:22Z",
        "published": "2024-04-03T03:37:22Z",
        "authors": [
            "Takeshi Kojima",
            "Itsuki Okimura",
            "Yusuke Iwasawa",
            "Hitomi Yanaka",
            "Yutaka Matsuo"
        ],
        "comments": "Accepted to NAACL2024. Our code is available at\n  https://github.com/kojima-takeshi188/lang_neuron",
        "categories": [
            "cs.CL"
        ],
        "primary_category": "cs.CL"
    },
    "2404.02433v1": {
        "url": "http://arxiv.org/abs/2404.02433v1",
        "title": "A fast cosine transformation accelerated method for predicting effective\n  thermal conductivity",
        "summary": "Predicting effective thermal conductivity by solving a Partial Differential\nEquation (PDE) defined on a high-resolution Representative Volume Element (RVE)\nis a computationally intensive task. In this paper, we tackle the task by\nproposing an efficient and implementation-friendly computational method that\ncan fully leverage the computing power offered by hardware accelerators,\nnamely, graphical processing units (GPUs). We first employ the Two-Point\nFlux-Approximation scheme to discretize the PDE and then utilize the\npreconditioned conjugate gradient method to solve the resulting algebraic\nlinear system. The construction of the preconditioner originates from FFT-based\nhomogenization methods, and an engineered linear programming technique is\nutilized to determine the homogeneous reference parameters. The fundamental\nobservation presented in this paper is that the preconditioner system can be\neffectively solved using multiple Fast Cosine Transformations (FCT) and\nparallel tridiagonal matrix solvers. Regarding the fact that default multiple\nFCTs are unavailable on the CUDA platform, we detail how to derive FCTs from\nFFTs with nearly optimal memory usage. Numerical experiments including the\nstability comparison with standard preconditioners are conducted for 3D RVEs.\nOur performance reports indicate that the proposed method can achieve a\n$5$-fold acceleration on the GPU platform over the pure CPU platform and solve\nthe problems with $512^3$ degrees of freedom and reasonable contrast ratios in\nless than $30$ seconds.",
        "updated": "2024-04-03T03:41:15Z",
        "published": "2024-04-03T03:41:15Z",
        "authors": [
            "Changqing Ye",
            "Shubin Fu",
            "Eric T. Chung"
        ],
        "categories": [
            "math.NA",
            "cs.NA"
        ],
        "primary_category": "math.NA"
    },
    "2404.02438v1": {
        "url": "http://arxiv.org/abs/2404.02438v1",
        "title": "From Narratives to Numbers: Valid Inference Using Language Model\n  Predictions from Verbal Autopsy Narratives",
        "summary": "In settings where most deaths occur outside the healthcare system, verbal\nautopsies (VAs) are a common tool to monitor trends in causes of death (COD).\nVAs are interviews with a surviving caregiver or relative that are used to\npredict the decedent's COD. Turning VAs into actionable insights for\nresearchers and policymakers requires two steps (i) predicting likely COD using\nthe VA interview and (ii) performing inference with predicted CODs (e.g.\nmodeling the breakdown of causes by demographic factors using a sample of\ndeaths). In this paper, we develop a method for valid inference using outcomes\n(in our case COD) predicted from free-form text using state-of-the-art NLP\ntechniques. This method, which we call multiPPI++, extends recent work in\n\"prediction-powered inference\" to multinomial classification. We leverage a\nsuite of NLP techniques for COD prediction and, through empirical analysis of\nVA data, demonstrate the effectiveness of our approach in handling\ntransportability issues. multiPPI++ recovers ground truth estimates, regardless\nof which NLP model produced predictions and regardless of whether they were\nproduced by a more accurate predictor like GPT-4-32k or a less accurate\npredictor like KNN. Our findings demonstrate the practical importance of\ninference correction for public health decision-making and suggests that if\ninference tasks are the end goal, having a small amount of contextually\nrelevant, high quality labeled data is essential regardless of the NLP\nalgorithm.",
        "updated": "2024-04-03T03:53:37Z",
        "published": "2024-04-03T03:53:37Z",
        "authors": [
            "Shuxian Fan",
            "Adam Visokay",
            "Kentaro Hoffman",
            "Stephen Salerno",
            "Li Liu",
            "Jeffrey T. Leek",
            "Tyler H. McCormick"
        ],
        "comments": "12 pages, 7 figures",
        "categories": [
            "cs.CL",
            "cs.LG",
            "stat.ML"
        ],
        "primary_category": "cs.CL"
    },
    "2404.02439v1": {
        "url": "http://arxiv.org/abs/2404.02439v1",
        "title": "A neuroergonomics model to evaluating nuclear power plants operators'\n  performance under heat stress driven by ECG time-frequency spectrums and\n  fNIRS prefrontal cortex network: a CNN-GAT fusion model",
        "summary": "Operators experience complicated physiological and psychological states when\nexposed to extreme heat stress, which can impair cognitive function and\ndecrease performance significantly, ultimately leading to severe secondary\ndisasters. Therefore, there is an urgent need for a feasible technique to\nidentify their abnormal states to enhance the reliability of human-cybernetics\nsystems. With the advancement of deep learning in physiological modeling, a\nmodel for evaluating operators' performance driven by electrocardiogram (ECG)\nand functional near-infrared spectroscopy (fNIRS) was proposed, demonstrating\nhigh ecological validity. The model fused a convolutional neural network (CNN)\nbackbone and a graph attention network (GAT) backbone to extract discriminative\nfeatures from ECG time-frequency spectrums and fNIRS prefrontal cortex (PFC)\nnetwork respectively with deeper neuroscience domain knowledge, and eventually\nachieved 0.90 AUC. Results supported that handcrafted features extracted by\nspecialized neuroscience methods can alleviate overfitting. Inspired by the\nsmall-world nature of the brain network, the fNIRS PFC network was organized as\nan undirected graph and embedded by GAT. It is proven to perform better in\ninformation aggregation and delivery compared to a simple non-linear\ntransformation. The model provides a potential neuroergonomics application for\nevaluating the human state in vital human-cybernetics systems under industry\n5.0 scenarios.",
        "updated": "2024-04-03T03:57:46Z",
        "published": "2024-04-03T03:57:46Z",
        "authors": [
            "Yan Zhang",
            "Ming Jia",
            "Meng Li",
            "JianYu Wang",
            "XiangMin Hu",
            "ZhiHui Xu",
            "Tao Chen"
        ],
        "categories": [
            "cs.HC"
        ],
        "primary_category": "cs.HC"
    },
    "2404.02440v1": {
        "url": "http://arxiv.org/abs/2404.02440v1",
        "title": "Designing a Photonic Physically Unclonable Function Having Resilience to\n  Machine Learning Attacks",
        "summary": "Physically unclonable functions (PUFs) are designed to act as device\n'fingerprints.' Given an input challenge, the PUF circuit should produce an\nunpredictable response for use in situations such as root-of-trust applications\nand other hardware-level cybersecurity applications. PUFs are typically\nsubcircuits present within integrated circuits (ICs), and while conventional IC\nPUFs are well-understood, several implementations have proven vulnerable to\nmalicious exploits, including those perpetrated by machine learning (ML)-based\nattacks. Such attacks can be difficult to prevent because they are often\ndesigned to work even when relatively few challenge-response pairs are known in\nadvance. Hence the need for both more resilient PUF designs and analysis of\nML-attack susceptibility. Previous work has developed a PUF for photonic\nintegrated circuits (PICs). A PIC PUF not only produces unpredictable responses\ngiven manufacturing-introduced tolerances, but is also less prone to\nelectromagnetic radiation eavesdropping attacks than a purely electronic IC\nPUF. In this work, we analyze the resilience of the proposed photonic PUF when\nsubjected to ML-based attacks. Specifically, we describe a computational PUF\nmodel for producing the large datasets required for training ML attacks; we\nanalyze the quality of the model; and we discuss the modeled PUF's\nsusceptibility to ML-based attacks. We find that the modeled PUF generates\ndistributions that resemble uniform white noise, explaining the exhibited\nresilience to neural-network-based attacks designed to exploit latent\nrelationships between challenges and responses. Preliminary analysis suggests\nthat the PUF exhibits similar resilience to generative adversarial networks,\nand continued development will show whether more-sophisticated ML approaches\nbetter compromise the PUF and -- if so -- how design modifications might\nimprove resilience.",
        "updated": "2024-04-03T03:58:21Z",
        "published": "2024-04-03T03:58:21Z",
        "authors": [
            "Elena R. Henderson",
            "Jessie M. Henderson",
            "Hiva Shahoei",
            "William V. Oxford",
            "Eric C. Larson",
            "Duncan L. MacFarlane",
            "Mitchell A. Thornton"
        ],
        "comments": "14 pages, 8 figures",
        "categories": [
            "cs.CR",
            "physics.optics"
        ],
        "primary_category": "cs.CR"
    },
    "2404.02444v1": {
        "url": "http://arxiv.org/abs/2404.02444v1",
        "title": "The Promises and Pitfalls of Using Language Models to Measure\n  Instruction Quality in Education",
        "summary": "Assessing instruction quality is a fundamental component of any improvement\nefforts in the education system. However, traditional manual assessments are\nexpensive, subjective, and heavily dependent on observers' expertise and\nidiosyncratic factors, preventing teachers from getting timely and frequent\nfeedback. Different from prior research that mostly focuses on low-inference\ninstructional practices on a singular basis, this paper presents the first\nstudy that leverages Natural Language Processing (NLP) techniques to assess\nmultiple high-inference instructional practices in two distinct educational\nsettings: in-person K-12 classrooms and simulated performance tasks for\npre-service teachers. This is also the first study that applies NLP to measure\na teaching practice that is widely acknowledged to be particularly effective\nfor students with special needs. We confront two challenges inherent in\nNLP-based instructional analysis, including noisy and long input data and\nhighly skewed distributions of human ratings. Our results suggest that\npretrained Language Models (PLMs) demonstrate performances comparable to the\nagreement level of human raters for variables that are more discrete and\nrequire lower inference, but their efficacy diminishes with more complex\nteaching practices. Interestingly, using only teachers' utterances as input\nyields strong results for student-centered variables, alleviating common\nconcerns over the difficulty of collecting and transcribing high-quality\nstudent speech data in in-person teaching settings. Our findings highlight both\nthe potential and the limitations of current NLP techniques in the education\ndomain, opening avenues for further exploration.",
        "updated": "2024-04-03T04:15:29Z",
        "published": "2024-04-03T04:15:29Z",
        "authors": [
            "Paiheng Xu",
            "Jing Liu",
            "Nathan Jones",
            "Julie Cohen",
            "Wei Ai"
        ],
        "comments": "NAACL 2024",
        "categories": [
            "cs.CL",
            "cs.AI"
        ],
        "primary_category": "cs.CL"
    },
    "2404.02445v1": {
        "url": "http://arxiv.org/abs/2404.02445v1",
        "title": "MOPAR: A Model Partitioning Framework for Deep Learning Inference\n  Services on Serverless Platforms",
        "summary": "With its elastic power and a pay-as-you-go cost model, the deployment of deep\nlearning inference services (DLISs) on serverless platforms is emerging as a\nprevalent trend. However, the varying resource requirements of different layers\nin DL models hinder resource utilization and increase costs, when DLISs are\ndeployed as a single function on serverless platforms. To tackle this problem,\nwe propose a model partitioning framework called MOPAR. This work is based on\nthe two resource usage patterns of DLISs: global differences and local\nsimilarity, due to the presence of resource dominant (RD) operators and layer\nstacking. Considering these patterns, MOPAR adopts a hybrid approach that\ninitially divides the DL model vertically into multiple slices composed of\nsimilar layers to improve resource efficiency. Slices containing RD operators\nare further partitioned into multiple sub-slices, enabling parallel\noptimization to reduce inference latency. Moreover, MOPAR comprehensively\nemploys data compression and share-memory techniques to offset the additional\ntime introduced by communication between slices. We implement a prototype of\nMOPAR and evaluate its efficacy using four categories of 12 DL models on\nOpenFaaS and AWS Lambda. The experiment results show that MOPAR can improve the\nresource efficiency of DLISs by 27.62\\% on average, while reducing latency by\nabout 5.52\\%. Furthermore, based on Lambda's pricing, the cost of running DLISs\nis reduced by about 2.58 $\\times$ using MOPAR.",
        "updated": "2024-04-03T04:21:27Z",
        "published": "2024-04-03T04:21:27Z",
        "authors": [
            "Jiaang Duan",
            "Shiyou Qian",
            "Dingyu Yang",
            "Hanwen Hu",
            "Jian Cao",
            "Guangtao Xue"
        ],
        "categories": [
            "cs.DC"
        ],
        "primary_category": "cs.DC"
    },
    "2404.02446v1": {
        "url": "http://arxiv.org/abs/2404.02446v1",
        "title": "Masked Completion via Structured Diffusion with White-Box Transformers",
        "summary": "Modern learning frameworks often train deep neural networks with massive\namounts of unlabeled data to learn representations by solving simple pretext\ntasks, then use the representations as foundations for downstream tasks. These\nnetworks are empirically designed; as such, they are usually not interpretable,\ntheir representations are not structured, and their designs are potentially\nredundant. White-box deep networks, in which each layer explicitly identifies\nand transforms structures in the data, present a promising alternative.\nHowever, existing white-box architectures have only been shown to work at scale\nin supervised settings with labeled data, such as classification. In this work,\nwe provide the first instantiation of the white-box design paradigm that can be\napplied to large-scale unsupervised representation learning. We do this by\nexploiting a fundamental connection between diffusion, compression, and\n(masked) completion, deriving a deep transformer-like masked autoencoder\narchitecture, called CRATE-MAE, in which the role of each layer is\nmathematically fully interpretable: they transform the data distribution to and\nfrom a structured representation. Extensive empirical evaluations confirm our\nanalytical insights. CRATE-MAE demonstrates highly promising performance on\nlarge-scale imagery datasets while using only ~30% of the parameters compared\nto the standard masked autoencoder with the same model configuration. The\nrepresentations learned by CRATE-MAE have explicit structure and also contain\nsemantic meaning. Code is available at https://github.com/Ma-Lab-Berkeley/CRATE .",
        "updated": "2024-04-03T04:23:01Z",
        "published": "2024-04-03T04:23:01Z",
        "authors": [
            "Druv Pai",
            "Ziyang Wu",
            "Sam Buchanan",
            "Yaodong Yu",
            "Yi Ma"
        ],
        "comments": "To be published at ICLR 2024; 44 pages. arXiv admin note: substantial\n  text overlap with arXiv:2311.13110",
        "categories": [
            "cs.LG",
            "stat.ML"
        ],
        "primary_category": "cs.LG"
    },
    "2404.02447v1": {
        "url": "http://arxiv.org/abs/2404.02447v1",
        "title": "A Novel Approach to Breast Cancer Histopathological Image Classification\n  Using Cross-Colour Space Feature Fusion and Quantum-Classical Stack Ensemble\n  Method",
        "summary": "Breast cancer classification stands as a pivotal pillar in ensuring timely\ndiagnosis and effective treatment. This study with histopathological images\nunderscores the profound significance of harnessing the synergistic\ncapabilities of colour space ensembling and quantum-classical stacking to\nelevate the precision of breast cancer classification. By delving into the\ndistinct colour spaces of RGB, HSV and CIE L*u*v, the authors initiated a\ncomprehensive investigation guided by advanced methodologies. Employing the\nDenseNet121 architecture for feature extraction the authors have capitalized on\nthe robustness of Random Forest, SVM, QSVC, and VQC classifiers. This research\nencompasses a unique feature fusion technique within the colour space ensemble.\nThis approach not only deepens our comprehension of breast cancer\nclassification but also marks a milestone in personalized medical assessment.\nThe amalgamation of quantum and classical classifiers through stacking emerges\nas a potent catalyst, effectively mitigating the inherent constraints of\nindividual classifiers, paving a robust path towards more dependable and\nrefined breast cancer identification. Through rigorous experimentation and\nmeticulous analysis, fusion of colour spaces like RGB with HSV and RGB with CIE\nL*u*v, presents an classification accuracy, nearing the value of unity. This\nunderscores the transformative potential of our approach, where the fusion of\ndiverse colour spaces and the synergy of quantum and classical realms converge\nto establish a new horizon in medical diagnostics. Thus the implications of\nthis research extend across medical disciplines, offering promising avenues for\nadvancing diagnostic accuracy and treatment efficacy.",
        "updated": "2024-04-03T04:26:50Z",
        "published": "2024-04-03T04:26:50Z",
        "authors": [
            "Sambit Mallick",
            "Snigdha Paul",
            "Anindya Sen"
        ],
        "categories": [
            "cs.CV",
            "cs.AI"
        ],
        "primary_category": "cs.CV"
    },
    "2404.02448v2": {
        "url": "http://arxiv.org/abs/2404.02448v2",
        "title": "Electric Vehicle Routing Problem for Emergency Power Supply: Towards\n  Telecom Base Station Relief",
        "summary": "As a telecom provider, our company has a critical mission to maintain telecom\nservices even during power outages. To accomplish the mission, it is essential\nto maintain the power of the telecom base stations. Here we consider a solution\nwhere electric vehicles (EVs) directly supply power to base stations by\ntraveling to their locations. The goal is to find EV routes that minimize both\nthe total travel distance of all EVs and the number of downed base stations. In\nthis paper, we formulate this routing problem as a new variant of the Electric\nVehicle Routing Problem (EVRP) and propose a solver that combines a rule-based\nvehicle selector and a reinforcement learning (RL)-based node selector. The\nrule of the vehicle selector ensures the exact environmental states when the\nselected EV starts to move. In addition, the node selection by the RL model\nenables fast route generation, which is critical in emergencies. We evaluate\nour solver on both synthetic datasets and real datasets. The results show that\nour solver outperforms baselines in terms of the objective value and\ncomputation time. Moreover, we analyze the generalization and scalability of\nour solver, demonstrating the capability toward unseen settings and large-scale\nproblems. Check also our project page: https://ntt-dkiku.github.io/rl-evrpeps.",
        "updated": "2024-04-08T02:46:38Z",
        "published": "2024-04-03T04:27:07Z",
        "authors": [
            "Daisuke Kikuta",
            "Hiroki Ikeuchi",
            "Kengo Tajiri",
            "Yuta Toyama",
            "Masaki Nakamura",
            "Yuusuke Nakano"
        ],
        "comments": "Accepted at AAMAS 2024 (extended abstract). 10 pages, 5 figures. Work\n  in progress",
        "categories": [
            "math.OC",
            "cs.AI",
            "cs.LG",
            "cs.MA"
        ],
        "primary_category": "math.OC"
    },
    "2404.03491v1": {
        "url": "http://arxiv.org/abs/2404.03491v1",
        "title": "A Cause-Effect Look at Alleviating Hallucination of Knowledge-grounded\n  Dialogue Generation",
        "summary": "Empowered by the large-scale pretrained language models, existing dialogue\nsystems have demonstrated impressive performance conducting fluent and\nnatural-sounding conversations. However, they are still plagued by the\nhallucination problem, causing unpredictable factual errors in the generated\nresponses. Recently, knowledge-grounded dialogue generation models, that\nintentionally invoke external knowledge resources to more informative\nresponses, are also proven to be effective in reducing hallucination. Following\nthe idea of getting high-quality knowledge, a few efforts have achieved pretty\ngood performance on this issue. As some inevitable knowledge noises may also\nlead to hallucinations, it is emergent to investigate the reason and future\ndirections for building noise-tolerant methods in KGD tasks. In this paper, we\nanalyze the causal story behind this problem with counterfactual reasoning\nmethods. Based on the causal effect analysis, we propose a possible solution\nfor alleviating the hallucination in KGD by exploiting the dialogue-knowledge\ninteraction. Experimental results of our example implementation show that this\nmethod can reduce hallucination without disrupting other dialogue performance,\nwhile keeping adaptive to different generation models. We hope our efforts can\nsupport and call for more attention to developing lightweight techniques\ntowards robust and trusty dialogue systems.",
        "updated": "2024-04-04T14:45:26Z",
        "published": "2024-04-04T14:45:26Z",
        "authors": [
            "Jifan Yu",
            "Xiaohan Zhang",
            "Yifan Xu",
            "Xuanyu Lei",
            "Zijun Yao",
            "Jing Zhang",
            "Lei Hou",
            "Juanzi Li"
        ],
        "comments": "Accepted by LREC-COLING 2024",
        "categories": [
            "cs.CL",
            "cs.AI"
        ],
        "primary_category": "cs.CL"
    },
    "2404.03493v2": {
        "url": "http://arxiv.org/abs/2404.03493v2",
        "title": "A Methodology to Study the Impact of Spiking Neural Network Parameters\n  considering Event-Based Automotive Data",
        "summary": "Autonomous Driving (AD) systems are considered as the future of human\nmobility and transportation. Solving computer vision tasks such as image\nclassification and object detection/segmentation, with high accuracy and low\npower/energy consumption, is highly needed to realize AD systems in real life.\nThese requirements can potentially be satisfied by Spiking Neural Networks\n(SNNs). However, the state-of-the-art works in SNN-based AD systems still focus\non proposing network models that can achieve high accuracy, and they have not\nsystematically studied the roles of SNN parameters when used for learning\nevent-based automotive data. Therefore, we still lack understanding of how to\neffectively develop SNN models for AD systems. Toward this, we propose a novel\nmethodology to systematically study and analyze the impact of SNN parameters\nconsidering event-based automotive data, then leverage this analysis for\nenhancing SNN developments. To do this, we first explore different settings of\nSNN parameters that directly affect the learning mechanism (i.e., batch size,\nlearning rate, neuron threshold potential, and weight decay), then analyze the\naccuracy results. Afterward, we propose techniques that jointly improve SNN\naccuracy and reduce training time. Experimental results show that our\nmethodology can improve the SNN models for AD systems than the\nstate-of-the-art, as it achieves higher accuracy (i.e., 86%) for the NCARS\ndataset, and it can also achieve iso-accuracy (i.e., ~85% with standard\ndeviation less than 0.5%) while speeding up the training time by 1.9x. In this\nmanner, our research work provides a set of guidelines for SNN parameter\nenhancements, thereby enabling the practical developments of SNN-based AD\nsystems.",
        "updated": "2024-04-05T11:42:57Z",
        "published": "2024-04-04T14:48:26Z",
        "authors": [
            "Iqra Bano",
            "Rachmad Vidya Wicaksana Putra",
            "Alberto Marchisio",
            "Muhammad Shafique"
        ],
        "comments": "7 pages, 13 figures, 1 table",
        "categories": [
            "cs.NE",
            "cs.AI",
            "cs.LG",
            "cs.RO"
        ],
        "primary_category": "cs.NE"
    },
    "2404.03494v1": {
        "url": "http://arxiv.org/abs/2404.03494v1",
        "title": "A topological reading of inductive and coinductive definitions in\n  Dependent Type Theory",
        "summary": "In the context of dependent type theory, we show that coinductive predicates\nhave an equivalent topological counterpart in terms of coinductively generated\npositivity relations, introduced by G. Sambin to represent closed subsets in\npoint-free topology. Our work is complementary to a previous one with M.E.\nMaietti, where we showed that, in dependent type theory, the well-known concept\nof wellfounded trees has a topological equivalent counterpart in terms of\nproof-relevant inductively generated formal covers used to provide a\npredicative and constructive representation of complete suplattices. All proofs\nin Martin-L\\\"of's type theory are formalised in the Agda proof assistant.",
        "updated": "2024-04-04T14:49:47Z",
        "published": "2024-04-04T14:49:47Z",
        "authors": [
            "Pietro Sabelli"
        ],
        "categories": [
            "math.LO",
            "cs.LO"
        ],
        "primary_category": "math.LO"
    },
    "2404.03495v1": {
        "url": "http://arxiv.org/abs/2404.03495v1",
        "title": "About Test-time training for outlier detection",
        "summary": "In this paper, we introduce DOUST, our method applying test-time training for\noutlier detection, significantly improving the detection performance. After\nthoroughly evaluating our algorithm on common benchmark datasets, we discuss a\ncommon problem and show that it disappears with a large enough test set. Thus,\nwe conclude that under reasonable conditions, our algorithm can reach almost\nsupervised performance even when no labeled outliers are given.",
        "updated": "2024-04-04T14:50:50Z",
        "published": "2024-04-04T14:50:50Z",
        "authors": [
            "Simon Kl\u00fcttermann",
            "Emmanuel M\u00fcller"
        ],
        "categories": [
            "cs.LG"
        ],
        "primary_category": "cs.LG"
    },
    "2404.03498v1": {
        "url": "http://arxiv.org/abs/2404.03498v1",
        "title": "Integrating Large Language Models with Multimodal Virtual Reality\n  Interfaces to Support Collaborative Human-Robot Construction Work",
        "summary": "In the construction industry, where work environments are complex,\nunstructured and often dangerous, the implementation of Human-Robot\nCollaboration (HRC) is emerging as a promising advancement. This underlines the\ncritical need for intuitive communication interfaces that enable construction\nworkers to collaborate seamlessly with robotic assistants. This study\nintroduces a conversational Virtual Reality (VR) interface integrating\nmultimodal interaction to enhance intuitive communication between construction\nworkers and robots. By integrating voice and controller inputs with the Robot\nOperating System (ROS), Building Information Modeling (BIM), and a game engine\nfeaturing a chat interface powered by a Large Language Model (LLM), the\nproposed system enables intuitive and precise interaction within a VR setting.\nEvaluated by twelve construction workers through a drywall installation case\nstudy, the proposed system demonstrated its low workload and high usability\nwith succinct command inputs. The proposed multimodal interaction system\nsuggests that such technological integration can substantially advance the\nintegration of robotic assistants in the construction industry.",
        "updated": "2024-04-04T14:56:41Z",
        "published": "2024-04-04T14:56:41Z",
        "authors": [
            "Somin Park",
            "Carol C. Menassa",
            "Vineet R. Kamat"
        ],
        "comments": "39 pages, 16 figures, 5 tables",
        "categories": [
            "cs.RO",
            "cs.HC"
        ],
        "primary_category": "cs.RO"
    },
    "2404.03499v1": {
        "url": "http://arxiv.org/abs/2404.03499v1",
        "title": "Comprehensible Artificial Intelligence on Knowledge Graphs: A survey",
        "summary": "Artificial Intelligence applications gradually move outside the safe walls of\nresearch labs and invade our daily lives. This is also true for Machine\nLearning methods on Knowledge Graphs, which has led to a steady increase in\ntheir application since the beginning of the 21st century. However, in many\napplications, users require an explanation of the Artificial Intelligences\ndecision. This led to increased demand for Comprehensible Artificial\nIntelligence. Knowledge Graphs epitomize fertile soil for Comprehensible\nArtificial Intelligence, due to their ability to display connected data, i.e.\nknowledge, in a human- as well as machine-readable way. This survey gives a\nshort history to Comprehensible Artificial Intelligence on Knowledge Graphs.\nFurthermore, we contribute by arguing that the concept Explainable Artificial\nIntelligence is overloaded and overlapping with Interpretable Machine Learning.\nBy introducing the parent concept Comprehensible Artificial Intelligence, we\nprovide a clear-cut distinction of both concepts while accounting for their\nsimilarities. Thus, we provide in this survey a case for Comprehensible\nArtificial Intelligence on Knowledge Graphs consisting of Interpretable Machine\nLearning on Knowledge Graphs and Explainable Artificial Intelligence on\nKnowledge Graphs. This leads to the introduction of a novel taxonomy for\nComprehensible Artificial Intelligence on Knowledge Graphs. In addition, a\ncomprehensive overview of the research on Comprehensible Artificial\nIntelligence on Knowledge Graphs is presented and put into the context of the\ntaxonomy. Finally, research gaps in the field of Comprehensible Artificial\nIntelligence on Knowledge Graphs are identified for future research.",
        "updated": "2024-04-04T14:57:32Z",
        "published": "2024-04-04T14:57:32Z",
        "authors": [
            "Simon Schramm",
            "Christoph Wehner",
            "Ute Schmid"
        ],
        "categories": [
            "cs.AI"
        ],
        "primary_category": "cs.AI",
        "doi": "10.1016/j.websem.2023.100806"
    },
    "2404.03502v2": {
        "url": "http://arxiv.org/abs/2404.03502v2",
        "title": "AI and the Problem of Knowledge Collapse",
        "summary": "While artificial intelligence has the potential to process vast amounts of\ndata, generate new insights, and unlock greater productivity, its widespread\nadoption may entail unforeseen consequences. We identify conditions under which\nAI, by reducing the cost of access to certain modes of knowledge, can\nparadoxically harm public understanding. While large language models are\ntrained on vast amounts of diverse data, they naturally generate output towards\nthe 'center' of the distribution. This is generally useful, but widespread\nreliance on recursive AI systems could lead to a process we define as\n\"knowledge collapse\", and argue this could harm innovation and the richness of\nhuman understanding and culture. However, unlike AI models that cannot choose\nwhat data they are trained on, humans may strategically seek out diverse forms\nof knowledge if they perceive them to be worthwhile. To investigate this, we\nprovide a simple model in which a community of learners or innovators choose to\nuse traditional methods or to rely on a discounted AI-assisted process and\nidentify conditions under which knowledge collapse occurs. In our default\nmodel, a 20% discount on AI-generated content generates public beliefs 2.3\ntimes further from the truth than when there is no discount. An empirical\napproach to measuring the distribution of LLM outputs is provided in\ntheoretical terms and illustrated through a specific example comparing the\ndiversity of outputs across different models and prompting styles. Finally,\nbased on the results, we consider further research directions to counteract\nsuch outcomes.",
        "updated": "2024-04-22T14:18:42Z",
        "published": "2024-04-04T15:06:23Z",
        "authors": [
            "Andrew J. Peterson"
        ],
        "comments": "37 pages, 9 figures",
        "categories": [
            "cs.AI",
            "cs.CY",
            "I.2.0"
        ],
        "primary_category": "cs.AI"
    },
    "2404.03506v1": {
        "url": "http://arxiv.org/abs/2404.03506v1",
        "title": "CountARFactuals -- Generating plausible model-agnostic counterfactual\n  explanations with adversarial random forests",
        "summary": "Counterfactual explanations elucidate algorithmic decisions by pointing to\nscenarios that would have led to an alternative, desired outcome. Giving\ninsight into the model's behavior, they hint users towards possible actions and\ngive grounds for contesting decisions. As a crucial factor in achieving these\ngoals, counterfactuals must be plausible, i.e., describing realistic\nalternative scenarios within the data manifold. This paper leverages a recently\ndeveloped generative modeling technique -- adversarial random forests (ARFs) --\nto efficiently generate plausible counterfactuals in a model-agnostic way. ARFs\ncan serve as a plausibility measure or directly generate counterfactual\nexplanations. Our ARF-based approach surpasses the limitations of existing\nmethods that aim to generate plausible counterfactual explanations: It is easy\nto train and computationally highly efficient, handles continuous and\ncategorical data naturally, and allows integrating additional desiderata such\nas sparsity in a straightforward manner.",
        "updated": "2024-04-04T15:10:13Z",
        "published": "2024-04-04T15:10:13Z",
        "authors": [
            "Susanne Dandl",
            "Kristin Blesch",
            "Timo Freiesleben",
            "Gunnar K\u00f6nig",
            "Jan Kapar",
            "Bernd Bischl",
            "Marvin Wright"
        ],
        "comments": "SD, KB, TB, and GK contributed equally as first authors",
        "categories": [
            "stat.ML",
            "cs.LG"
        ],
        "primary_category": "stat.ML"
    },
    "2404.03507v2": {
        "url": "http://arxiv.org/abs/2404.03507v2",
        "title": "DQ-DETR: DETR with Dynamic Query for Tiny Object Detection",
        "summary": "Despite previous DETR-like methods having performed successfully in generic\nobject detection, tiny object detection is still a challenging task for them\nsince the positional information of object queries is not customized for\ndetecting tiny objects, whose scale is extraordinarily smaller than general\nobjects. Also, DETR-like methods using a fixed number of queries make them\nunsuitable for aerial datasets, which only contain tiny objects, and the\nnumbers of instances are imbalanced between different images. Thus, we present\na simple yet effective model, named DQ-DETR, which consists of three different\ncomponents: categorical counting module, counting-guided feature enhancement,\nand dynamic query selection to solve the above-mentioned problems. DQ-DETR uses\nthe prediction and density maps from the categorical counting module to\ndynamically adjust the number of object queries and improve the positional\ninformation of queries. Our model DQ-DETR outperforms previous CNN-based and\nDETR-like methods, achieving state-of-the-art mAP 30.2% on the AI-TOD-V2\ndataset, which mostly consists of tiny objects.",
        "updated": "2024-04-11T18:54:24Z",
        "published": "2024-04-04T15:10:24Z",
        "authors": [
            "Yi-Xin Huang",
            "Hou-I Liu",
            "Hong-Han Shuai",
            "Wen-Huang Cheng"
        ],
        "categories": [
            "cs.CV"
        ],
        "primary_category": "cs.CV"
    },
    "2404.03509v1": {
        "url": "http://arxiv.org/abs/2404.03509v1",
        "title": "Privacy-Enhancing Technologies for Artificial Intelligence-Enabled\n  Systems",
        "summary": "Artificial intelligence (AI) models introduce privacy vulnerabilities to\nsystems. These vulnerabilities may impact model owners or system users; they\nexist during model development, deployment, and inference phases, and threats\ncan be internal or external to the system. In this paper, we investigate\npotential threats and propose the use of several privacy-enhancing technologies\n(PETs) to defend AI-enabled systems. We then provide a framework for PETs\nevaluation for a AI-enabled systems and discuss the impact PETs may have on\nsystem-level variables.",
        "updated": "2024-04-04T15:14:40Z",
        "published": "2024-04-04T15:14:40Z",
        "authors": [
            "Liv d'Aliberti",
            "Evan Gronberg",
            "Joseph Kovba"
        ],
        "categories": [
            "cs.CR"
        ],
        "primary_category": "cs.CR"
    },
    "2404.04550v1": {
        "url": "http://arxiv.org/abs/2404.04550v1",
        "title": "NPB-REC: A Non-parametric Bayesian Deep-learning Approach for\n  Undersampled MRI Reconstruction with Uncertainty Estimation",
        "summary": "The ability to reconstruct high-quality images from undersampled MRI data is\nvital in improving MRI temporal resolution and reducing acquisition times. Deep\nlearning methods have been proposed for this task, but the lack of verified\nmethods to quantify the uncertainty in the reconstructed images hampered\nclinical applicability. We introduce \"NPB-REC\", a non-parametric fully Bayesian\nframework, for MRI reconstruction from undersampled data with uncertainty\nestimation. We use Stochastic Gradient Langevin Dynamics during training to\ncharacterize the posterior distribution of the network parameters. This enables\nus to both improve the quality of the reconstructed images and quantify the\nuncertainty in the reconstructed images. We demonstrate the efficacy of our\napproach on a multi-coil MRI dataset from the fastMRI challenge and compare it\nto the baseline End-to-End Variational Network (E2E-VarNet). Our approach\noutperforms the baseline in terms of reconstruction accuracy by means of PSNR\nand SSIM ($34.55$, $0.908$ vs. $33.08$, $0.897$, $p<0.01$, acceleration rate\n$R=8$) and provides uncertainty measures that correlate better with the\nreconstruction error (Pearson correlation, $R=0.94$ vs. $R=0.91$).\nAdditionally, our approach exhibits better generalization capabilities against\nanatomical distribution shifts (PSNR and SSIM of $32.38$, $0.849$ vs. $31.63$,\n$0.836$, $p<0.01$, training on brain data, inference on knee data, acceleration\nrate $R=8$). NPB-REC has the potential to facilitate the safe utilization of\ndeep learning-based methods for MRI reconstruction from undersampled data. Code\nand trained models are available at \\url{https://github.com/samahkh/NPB-REC}.",
        "updated": "2024-04-06T08:25:33Z",
        "published": "2024-04-06T08:25:33Z",
        "authors": [
            "Samah Khawaled",
            "Moti Freiman"
        ],
        "comments": "Published in Artificial Intelligence in Medicine, DOI:\n  https://doi.org/10.1016/j.artmed.2024.102798 This is an extension\n  representing a more comprehensive work extending preliminary work presented\n  at arXiv:2208.03966",
        "categories": [
            "cs.CV"
        ],
        "primary_category": "cs.CV",
        "doi": "10.1016/j.artmed.2024.102798"
    },
    "2404.04552v1": {
        "url": "http://arxiv.org/abs/2404.04552v1",
        "title": "Fast and Simple Sorting Using Partial Information",
        "summary": "We consider the problem of sorting a set of items having an unknown total\norder by doing binary comparisons of the items, given the outcomes of some\npre-existing comparisons. We present a simple algorithm with a running time of\n$O(m+n+\\log T)$, where $n$, $m$, and $T$ are the number of items, the number of\npre-existing comparisons, and the number of total orders consistent with the\noutcomes of the pre-existing comparisons, respectively. The algorithm does\n$O(\\log T)$ comparisons.\n  Our running time and comparison bounds are best possible up to constant\nfactors, thus resolving a problem that has been studied intensely since 1976\n(Fredman, Theoretical Computer Science). The best previous algorithm with a\nbound of $O(\\log T)$ on the number of comparisons has a time bound of\n$O(n^{2.5})$ and is significantly more complicated. Our algorithm combines\nthree classic algorithms: topological sort, heapsort with the right kind of\nheap, and efficient insertion into a sorted list.",
        "updated": "2024-04-06T08:29:44Z",
        "published": "2024-04-06T08:29:44Z",
        "authors": [
            "Bernhard Haeupler",
            "Richard Hlad\u00edk",
            "John Iacono",
            "Vaclav Rozhon",
            "Robert Tarjan",
            "Jakub T\u011btek"
        ],
        "categories": [
            "cs.DS",
            "F.2.2; G.2.2"
        ],
        "primary_category": "cs.DS"
    },
    "2404.04554v1": {
        "url": "http://arxiv.org/abs/2404.04554v1",
        "title": "A quantum algorithm for the Kalman filter using block encoding",
        "summary": "Quantum algorithms offer significant speed-ups over their classical\ncounterparts in various applications. In this paper, we develop quantum\nalgorithms for the Kalman filter widely used in classical control engineering\nusing the block encoding method. The entire calculation process is achieved by\nperforming matrix operations on Hamiltonians based on the block encoding\nframework, including addition, multiplication, and inversion, which can be\ncompleted in a unified framework compared to previous quantum algorithms for\nsolving control problems. We demonstrate that the quantum algorithm\nexponentially accelerates the computation of the Kalman filter compared to\ntraditional methods. The time complexity can be reduced from $O(n^3)$ to\n$O(\\kappa poly\\log(n/\\epsilon)\\log(1/\\epsilon'))$, where $n$ represents the\nmatrix dimension, $\\kappa$ denotes the condition number for the matrix to be\ninverted, $\\epsilon$ indicates desired precision in block encoding, $\\epsilon'$\nsignifies desired precision in matrix inversion. This paper provides a\ncomprehensive quantum solution for implementing the Kalman filter and serves as\nan attempt to broaden the scope of quantum computation applications. Finally,\nwe present an illustrative example implemented in Qiskit (a Python-based\nopen-source toolkit) as a proof-of-concept.",
        "updated": "2024-04-06T08:44:03Z",
        "published": "2024-04-06T08:44:03Z",
        "authors": [
            "Hao Shi",
            "Guofeng Zhang",
            "Ming Zhang"
        ],
        "comments": "23 pages, 20 figures, 3 tables",
        "categories": [
            "math.QA",
            "cs.CE"
        ],
        "primary_category": "math.QA"
    },
    "2404.04556v1": {
        "url": "http://arxiv.org/abs/2404.04556v1",
        "title": "Rethinking Self-training for Semi-supervised Landmark Detection: A\n  Selection-free Approach",
        "summary": "Self-training is a simple yet effective method for semi-supervised learning,\nduring which pseudo-label selection plays an important role for handling\nconfirmation bias. Despite its popularity, applying self-training to landmark\ndetection faces three problems: 1) The selected confident pseudo-labels often\ncontain data bias, which may hurt model performance; 2) It is not easy to\ndecide a proper threshold for sample selection as the localization task can be\nsensitive to noisy pseudo-labels; 3) coordinate regression does not output\nconfidence, making selection-based self-training infeasible. To address the\nabove issues, we propose Self-Training for Landmark Detection (STLD), a method\nthat does not require explicit pseudo-label selection. Instead, STLD constructs\na task curriculum to deal with confirmation bias, which progressively\ntransitions from more confident to less confident tasks over the rounds of\nself-training. Pseudo pretraining and shrink regression are two essential\ncomponents for such a curriculum, where the former is the first task of the\ncurriculum for providing a better model initialization and the latter is\nfurther added in the later rounds to directly leverage the pseudo-labels in a\ncoarse-to-fine manner. Experiments on three facial and one medical landmark\ndetection benchmark show that STLD outperforms the existing methods\nconsistently in both semi- and omni-supervised settings.",
        "updated": "2024-04-06T08:45:07Z",
        "published": "2024-04-06T08:45:07Z",
        "authors": [
            "Haibo Jin",
            "Haoxuan Che",
            "Hao Chen"
        ],
        "comments": "Under review",
        "categories": [
            "cs.CV"
        ],
        "primary_category": "cs.CV"
    },
    "2404.04557v1": {
        "url": "http://arxiv.org/abs/2404.04557v1",
        "title": "Learning Instance-Aware Correspondences for Robust Multi-Instance Point\n  Cloud Registration in Cluttered Scenes",
        "summary": "Multi-instance point cloud registration estimates the poses of multiple\ninstances of a model point cloud in a scene point cloud. Extracting accurate\npoint correspondence is to the center of the problem. Existing approaches\nusually treat the scene point cloud as a whole, overlooking the separation of\ninstances. Therefore, point features could be easily polluted by other points\nfrom the background or different instances, leading to inaccurate\ncorrespondences oblivious to separate instances, especially in cluttered\nscenes. In this work, we propose MIRETR, Multi-Instance REgistration\nTRansformer, a coarse-to-fine approach to the extraction of instance-aware\ncorrespondences. At the coarse level, it jointly learns instance-aware\nsuperpoint features and predicts per-instance masks. With instance masks, the\ninfluence from outside of the instance being concerned is minimized, such that\nhighly reliable superpoint correspondences can be extracted. The superpoint\ncorrespondences are then extended to instance candidates at the fine level\naccording to the instance masks. At last, an efficient candidate selection and\nrefinement algorithm is devised to obtain the final registrations. Extensive\nexperiments on three public benchmarks demonstrate the efficacy of our\napproach. In particular, MIRETR outperforms the state of the arts by 16.6\npoints on F1 score on the challenging ROBI benchmark. Code and models are\navailable at https://github.com/zhiyuanYU134/MIRETR.",
        "updated": "2024-04-06T08:51:07Z",
        "published": "2024-04-06T08:51:07Z",
        "authors": [
            "Zhiyuan Yu",
            "Zheng Qin",
            "Lintao Zheng",
            "Kai Xu"
        ],
        "categories": [
            "cs.CV"
        ],
        "primary_category": "cs.CV"
    },
    "2404.04558v1": {
        "url": "http://arxiv.org/abs/2404.04558v1",
        "title": "EVT-enriched Radio Maps for URLLC",
        "summary": "This paper introduces a sophisticated and adaptable framework combining\nextreme value theory with radio maps to spatially model extreme channel\nconditions accurately. Utilising existing signal-to-noise ratio (SNR)\nmeasurements and leveraging Gaussian processes, our approach predicts the tail\nof the SNR distribution, which entails estimating the parameters of a\ngeneralised Pareto distribution, at unobserved locations. This innovative\nmethod offers a versatile solution adaptable to various resource allocation\nchallenges in ultra-reliable low-latency communications. We evaluate the\nperformance of this method in a rate maximisation problem with defined outage\nconstraints and compare it with a benchmark in the literature. Notably, the\nproposed approach meets the outage demands in a larger percentage of the\ncoverage area and reaches higher transmission rates.",
        "updated": "2024-04-06T08:52:22Z",
        "published": "2024-04-06T08:52:22Z",
        "authors": [
            "Dian Echevarr\u00eda P\u00e9rez",
            "Onel L. Alcaraz L\u00f3pez",
            "Hirley Alves"
        ],
        "comments": "8 pages, 11 figures, submitted to IEEE Transactions on Wireless\n  Communications",
        "categories": [
            "cs.NI"
        ],
        "primary_category": "cs.NI"
    },
    "2404.04559v1": {
        "url": "http://arxiv.org/abs/2404.04559v1",
        "title": "Spectral GNN via Two-dimensional (2-D) Graph Convolution",
        "summary": "Spectral Graph Neural Networks (GNNs) have achieved tremendous success in\ngraph learning. As an essential part of spectral GNNs, spectral graph\nconvolution extracts crucial frequency information in graph data, leading to\nsuperior performance of spectral GNNs in downstream tasks. However, in this\npaper, we show that existing spectral GNNs remain critical drawbacks in\nperforming the spectral graph convolution. Specifically, considering the\nspectral graph convolution as a construction operation towards target output,\nwe prove that existing popular convolution paradigms cannot construct the\ntarget output with mild conditions on input graph signals, causing spectral\nGNNs to fall into suboptimal solutions. To address the issues, we rethink the\nspectral graph convolution from a more general two-dimensional (2-D) signal\nconvolution perspective and propose a new convolution paradigm, named 2-D graph\nconvolution. We prove that 2-D graph convolution unifies existing graph\nconvolution paradigms, and is capable to construct arbitrary target output.\nBased on the proposed 2-D graph convolution, we further propose ChebNet2D, an\nefficient and effective GNN implementation of 2-D graph convolution through\napplying Chebyshev interpolation. Extensive experiments on benchmark datasets\ndemonstrate both effectiveness and efficiency of the ChebNet2D.",
        "updated": "2024-04-06T08:53:26Z",
        "published": "2024-04-06T08:53:26Z",
        "authors": [
            "Guoming Li",
            "Jian Yang",
            "Shangsong Liang",
            "Dongsheng Luo"
        ],
        "comments": "Preprint",
        "categories": [
            "cs.LG",
            "cs.NA",
            "eess.SP",
            "math.NA"
        ],
        "primary_category": "cs.LG"
    },
    "2404.04561v2": {
        "url": "http://arxiv.org/abs/2404.04561v2",
        "title": "Co-Occ: Coupling Explicit Feature Fusion with Volume Rendering\n  Regularization for Multi-Modal 3D Semantic Occupancy Prediction",
        "summary": "3D semantic occupancy prediction is a pivotal task in the field of autonomous\ndriving. Recent approaches have made great advances in 3D semantic occupancy\npredictions on a single modality. However, multi-modal semantic occupancy\nprediction approaches have encountered difficulties in dealing with the\nmodality heterogeneity, modality misalignment, and insufficient modality\ninteractions that arise during the fusion of different modalities data, which\nmay result in the loss of important geometric and semantic information. This\nletter presents a novel multi-modal, i.e., LiDAR-camera 3D semantic occupancy\nprediction framework, dubbed Co-Occ, which couples explicit LiDAR-camera\nfeature fusion with implicit volume rendering regularization. The key insight\nis that volume rendering in the feature space can proficiently bridge the gap\nbetween 3D LiDAR sweeps and 2D images while serving as a physical\nregularization to enhance LiDAR-camera fused volumetric representation.\nSpecifically, we first propose a Geometric- and Semantic-aware Fusion\n(GSFusion) module to explicitly enhance LiDAR features by incorporating\nneighboring camera features through a K-nearest neighbors (KNN) search. Then,\nwe employ volume rendering to project the fused feature back to the image\nplanes for reconstructing color and depth maps. These maps are then supervised\nby input images from the camera and depth estimations derived from LiDAR,\nrespectively. Extensive experiments on the popular nuScenes and SemanticKITTI\nbenchmarks verify the effectiveness of our Co-Occ for 3D semantic occupancy\nprediction. The project page is available at\nhttps://rorisis.github.io/Co-Occ_project-page/.",
        "updated": "2024-04-09T12:50:16Z",
        "published": "2024-04-06T09:01:19Z",
        "authors": [
            "Jingyi Pan",
            "Zipeng Wang",
            "Lin Wang"
        ],
        "categories": [
            "cs.CV"
        ],
        "primary_category": "cs.CV"
    },
    "2404.04564v1": {
        "url": "http://arxiv.org/abs/2404.04564v1",
        "title": "Enhancing Video Summarization with Context Awareness",
        "summary": "Video summarization is a crucial research area that aims to efficiently\nbrowse and retrieve relevant information from the vast amount of video content\navailable today. With the exponential growth of multimedia data, the ability to\nextract meaningful representations from videos has become essential. Video\nsummarization techniques automatically generate concise summaries by selecting\nkeyframes, shots, or segments that capture the video's essence. This process\nimproves the efficiency and accuracy of various applications, including video\nsurveillance, education, entertainment, and social media. Despite the\nimportance of video summarization, there is a lack of diverse and\nrepresentative datasets, hindering comprehensive evaluation and benchmarking of\nalgorithms. Existing evaluation metrics also fail to fully capture the\ncomplexities of video summarization, limiting accurate algorithm assessment and\nhindering the field's progress. To overcome data scarcity challenges and\nimprove evaluation, we propose an unsupervised approach that leverages video\ndata structure and information for generating informative summaries. By moving\naway from fixed annotations, our framework can produce representative summaries\neffectively. Moreover, we introduce an innovative evaluation pipeline tailored\nspecifically for video summarization. Human participants are involved in the\nevaluation, comparing our generated summaries to ground truth summaries and\nassessing their informativeness. This human-centric approach provides valuable\ninsights into the effectiveness of our proposed techniques. Experimental\nresults demonstrate that our training-free framework outperforms existing\nunsupervised approaches and achieves competitive results compared to\nstate-of-the-art supervised methods.",
        "updated": "2024-04-06T09:08:34Z",
        "published": "2024-04-06T09:08:34Z",
        "authors": [
            "Hai-Dang Huynh-Lam",
            "Ngoc-Phuong Ho-Thi",
            "Minh-Triet Tran",
            "Trung-Nghia Le"
        ],
        "comments": "115 pages, 1 supplementary paper, undergraduate thesis report at\n  US-VNUHCM",
        "categories": [
            "cs.CV",
            "cs.AI"
        ],
        "primary_category": "cs.CV"
    },
    "2404.04565v1": {
        "url": "http://arxiv.org/abs/2404.04565v1",
        "title": "SportsHHI: A Dataset for Human-Human Interaction Detection in Sports\n  Videos",
        "summary": "Video-based visual relation detection tasks, such as video scene graph\ngeneration, play important roles in fine-grained video understanding. However,\ncurrent video visual relation detection datasets have two main limitations that\nhinder the progress of research in this area. First, they do not explore\ncomplex human-human interactions in multi-person scenarios. Second, the\nrelation types of existing datasets have relatively low-level semantics and can\nbe often recognized by appearance or simple prior information, without the need\nfor detailed spatio-temporal context reasoning. Nevertheless, comprehending\nhigh-level interactions between humans is crucial for understanding complex\nmulti-person videos, such as sports and surveillance videos. To address this\nissue, we propose a new video visual relation detection task: video human-human\ninteraction detection, and build a dataset named SportsHHI for it. SportsHHI\ncontains 34 high-level interaction classes from basketball and volleyball\nsports. 118,075 human bounding boxes and 50,649 interaction instances are\nannotated on 11,398 keyframes. To benchmark this, we propose a two-stage\nbaseline method and conduct extensive experiments to reveal the key factors for\na successful human-human interaction detector. We hope that SportsHHI can\nstimulate research on human interaction understanding in videos and promote the\ndevelopment of spatio-temporal context modeling techniques in video visual\nrelation detection.",
        "updated": "2024-04-06T09:13:03Z",
        "published": "2024-04-06T09:13:03Z",
        "authors": [
            "Tao Wu",
            "Runyu He",
            "Gangshan Wu",
            "Limin Wang"
        ],
        "comments": "Accepted by CVPR 2024",
        "categories": [
            "cs.CV"
        ],
        "primary_category": "cs.CV"
    },
    "2404.05518v1": {
        "url": "http://arxiv.org/abs/2404.05518v1",
        "title": "DepthMOT: Depth Cues Lead to a Strong Multi-Object Tracker",
        "summary": "Accurately distinguishing each object is a fundamental goal of Multi-object\ntracking (MOT) algorithms. However, achieving this goal still remains\nchallenging, primarily due to: (i) For crowded scenes with occluded objects,\nthe high overlap of object bounding boxes leads to confusion among closely\nlocated objects. Nevertheless, humans naturally perceive the depth of elements\nin a scene when observing 2D videos. Inspired by this, even though the bounding\nboxes of objects are close on the camera plane, we can differentiate them in\nthe depth dimension, thereby establishing a 3D perception of the objects. (ii)\nFor videos with rapidly irregular camera motion, abrupt changes in object\npositions can result in ID switches. However, if the camera pose are known, we\ncan compensate for the errors in linear motion models. In this paper, we\npropose \\textit{DepthMOT}, which achieves: (i) detecting and estimating scene\ndepth map \\textit{end-to-end}, (ii) compensating the irregular camera motion by\ncamera pose estimation. Extensive experiments demonstrate the superior\nperformance of DepthMOT in VisDrone-MOT and UAVDT datasets. The code will be\navailable at \\url{https://github.com/JackWoo0831/DepthMOT}.",
        "updated": "2024-04-08T13:39:12Z",
        "published": "2024-04-08T13:39:12Z",
        "authors": [
            "Jiapeng Wu",
            "Yichen Liu"
        ],
        "categories": [
            "cs.CV"
        ],
        "primary_category": "cs.CV"
    },
    "2404.05519v1": {
        "url": "http://arxiv.org/abs/2404.05519v1",
        "title": "Investigating the Effectiveness of Cross-Attention to Unlock Zero-Shot\n  Editing of Text-to-Video Diffusion Models",
        "summary": "With recent advances in image and video diffusion models for content\ncreation, a plethora of techniques have been proposed for customizing their\ngenerated content. In particular, manipulating the cross-attention layers of\nText-to-Image (T2I) diffusion models has shown great promise in controlling the\nshape and location of objects in the scene. Transferring image-editing\ntechniques to the video domain, however, is extremely challenging as object\nmotion and temporal consistency are difficult to capture accurately. In this\nwork, we take a first look at the role of cross-attention in Text-to-Video\n(T2V) diffusion models for zero-shot video editing. While one-shot models have\nshown potential in controlling motion and camera movement, we demonstrate\nzero-shot control over object shape, position and movement in T2V models. We\nshow that despite the limitations of current T2V models, cross-attention\nguidance can be a promising approach for editing videos.",
        "updated": "2024-04-08T13:40:01Z",
        "published": "2024-04-08T13:40:01Z",
        "authors": [
            "Saman Motamed",
            "Wouter Van Gansbeke",
            "Luc Van Gool"
        ],
        "comments": "Generative Models for Computer Vision Generative Models for Computer\n  Vision CVPR 2024 Workshop",
        "categories": [
            "cs.CV",
            "cs.LG"
        ],
        "primary_category": "cs.CV"
    },
    "2404.05520v2": {
        "url": "http://arxiv.org/abs/2404.05520v2",
        "title": "The Fact Selection Problem in LLM-Based Program Repair",
        "summary": "Recent research has shown that incorporating bug-related facts, such as stack\ntraces and GitHub issues, into prompts enhances the bug-fixing capabilities of\nlarge language models (LLMs). Considering the ever-increasing context window of\nthese models, a critical question arises: what and how many facts should be\nincluded in prompts to maximise the chance of correctly fixing bugs? To answer\nthis question, we conducted a large-scale study, employing over 19K prompts\nfeaturing various combinations of seven diverse facts to rectify 314 bugs from\nopen-source Python projects within the BugsInPy benchmark. Our findings\nrevealed that each fact, ranging from simple syntactic details like code\ncontext to semantic information previously unexplored in the context of LLMs\nsuch as angelic values, is beneficial. Specifically, each fact aids in fixing\nsome bugs that would remain unresolved or only be fixed with a low success rate\nwithout it. Importantly, we discovered that the effectiveness of program repair\nprompts is non-monotonic over the number of used facts; using too many facts\nleads to subpar outcomes. These insights led us to define the fact selection\nproblem: determining the optimal set of facts for inclusion in a prompt to\nmaximise LLM's performance on a given task instance. We found that there is no\none-size-fits-all set of facts for bug repair. Therefore, we developed a basic\nstatistical model, named Maniple, which selects facts specific to a given bug\nto include in the prompt. This model significantly surpasses the performance of\nthe best generic fact set. To underscore the significance of the fact selection\nproblem, we benchmarked Maniple against the state-of-the-art zero-shot,\nnon-conversational LLM-based bug repair methods. On our testing dataset of 157\nbugs, Maniple repairs 88 bugs, 17% above the best configuration.",
        "updated": "2024-04-09T10:01:23Z",
        "published": "2024-04-08T13:41:32Z",
        "authors": [
            "Nikhil Parasaram",
            "Huijie Yan",
            "Boyu Yang",
            "Zineb Flahy",
            "Abriele Qudsi",
            "Damian Ziaber",
            "Earl Barr",
            "Sergey Mechtaev"
        ],
        "comments": "Code, scripts and data necessary to reproduce this work are available\n  at https://github.com/PyRepair/maniple",
        "categories": [
            "cs.SE"
        ],
        "primary_category": "cs.SE"
    },
    "2404.05522v1": {
        "url": "http://arxiv.org/abs/2404.05522v1",
        "title": "3DMambaIPF: A State Space Model for Iterative Point Cloud Filtering via\n  Differentiable Rendering",
        "summary": "Noise is an inevitable aspect of point cloud acquisition, necessitating\nfiltering as a fundamental task within the realm of 3D vision. Existing\nlearning-based filtering methods have shown promising capabilities on\nsmall-scale synthetic or real-world datasets. Nonetheless, the effectiveness of\nthese methods is constrained when dealing with a substantial quantity of point\nclouds. This limitation primarily stems from their limited denoising\ncapabilities for large-scale point clouds and their inclination to generate\nnoisy outliers after denoising. The recent introduction of State Space Models\n(SSMs) for long sequence modeling in Natural Language Processing (NLP) presents\na promising solution for handling large-scale data. Encouraged by iterative\npoint cloud filtering methods, we introduce 3DMambaIPF, firstly incorporating\nMamba (Selective SSM) architecture to sequentially handle extensive point\nclouds from large scenes, capitalizing on its strengths in selective input\nprocessing and long sequence modeling capabilities. Additionally, we integrate\na robust and fast differentiable rendering loss to constrain the noisy points\naround the surface. In contrast to previous methodologies, this differentiable\nrendering loss enhances the visual realism of denoised geometric structures and\naligns point cloud boundaries more closely with those observed in real-world\nobjects. Extensive evaluation on datasets comprising small-scale synthetic and\nreal-world models (typically with up to 50K points) demonstrate that our method\nachieves state-of-the-art results. Moreover, we showcase the superior\nscalability and efficiency of our method on large-scale models with about 500K\npoints, where the majority of the existing learning-based denoising methods are\nunable to handle.",
        "updated": "2024-04-08T13:43:19Z",
        "published": "2024-04-08T13:43:19Z",
        "authors": [
            "Qingyuan Zhou",
            "Weidong Yang",
            "Ben Fei",
            "Jingyi Xu",
            "Rui Zhang",
            "Keyi Liu",
            "Yeqi Luo",
            "Ying He"
        ],
        "categories": [
            "cs.MM"
        ],
        "primary_category": "cs.MM"
    },
    "2404.05530v1": {
        "url": "http://arxiv.org/abs/2404.05530v1",
        "title": "Best-of-Venom: Attacking RLHF by Injecting Poisoned Preference Data",
        "summary": "Reinforcement Learning from Human Feedback (RLHF) is a popular method for\naligning Language Models (LM) with human values and preferences. RLHF requires\na large number of preference pairs as training data, which are often used in\nboth the Supervised Fine-Tuning and Reward Model training, and therefore\npublicly available datasets are commonly used. In this work, we study to what\nextent a malicious actor can manipulate the LMs generations by poisoning the\npreferences, i.e., injecting poisonous preference pairs into these datasets and\nthe RLHF training process. We propose strategies to build poisonous preference\npairs and test their performance by poisoning two widely used preference\ndatasets. Our results show that preference poisoning is highly effective: by\ninjecting a small amount of poisonous data (1-5% of the original dataset), we\ncan effectively manipulate the LM to generate a target entity in a target\nsentiment (positive or negative). The findings from our experiments also shed\nlight on strategies to defend against the preference poisoning attack.",
        "updated": "2024-04-08T13:59:02Z",
        "published": "2024-04-08T13:59:02Z",
        "authors": [
            "Tim Baumg\u00e4rtner",
            "Yang Gao",
            "Dana Alon",
            "Donald Metzler"
        ],
        "categories": [
            "cs.CL",
            "cs.AI",
            "cs.CR",
            "cs.LG"
        ],
        "primary_category": "cs.CL"
    },
    "2404.05531v1": {
        "url": "http://arxiv.org/abs/2404.05531v1",
        "title": "Provably Convergent and Robust Newton-Raphson Method: A New Dawn in\n  Primitive Variable Recovery for Relativistic MHD",
        "summary": "A long-standing and formidable challenge faced by all conservative schemes\nfor relativistic magnetohydrodynamics (RMHD) is the recovery of primitive\nvariables from conservative ones. This process involves solving highly\nnonlinear equations subject to physical constraints. An ideal solver should be\n\"robust, accurate, and fast -- it is at the heart of all conservative RMHD\nschemes,\" as emphasized in [S.C. Noble et al., ApJ, 641:626-637, 2006]. Despite\nover three decades of research, seeking efficient solvers that can provably\nguarantee stability and convergence remains an open problem.\n  This paper presents the first theoretical analysis for designing a robust,\nphysical-constraint-preserving (PCP), and provably (quadratically) convergent\nNewton-Raphson (NR) method for primitive variable recovery in RMHD. Our key\ninnovation is a unified approach for the initial guess, devised based on\nsophisticated analysis. It ensures that the NR iteration consistently converges\nand adheres to physical constraints. Given the extreme nonlinearity and\ncomplexity of the iterative function, the theoretical analysis is highly\nnontrivial and technical. We discover a pivotal inequality for delineating the\nconvexity and concavity of the iterative function and establish theories to\nguarantee the PCP property and convergence. We also develop theories to\ndetermine a computable initial guess within a theoretical \"safe\" interval.\nIntriguingly, we find that the unique positive root of a cubic polynomial\nalways falls within this interval. Our PCP NR method is versatile and can be\nseamlessly integrated into any RMHD scheme that requires the recovery of\nprimitive variables, potentially leading to a broad impact in this field. As an\napplication, we incorporate it into a discontinuous Galerkin method, resulting\nin fully PCP schemes. Several numerical experiments demonstrate the efficiency\nand robustness of the PCP NR method.",
        "updated": "2024-04-08T13:59:07Z",
        "published": "2024-04-08T13:59:07Z",
        "authors": [
            "Chaoyi Cai",
            "Jianxian Qiu",
            "Kailiang Wu"
        ],
        "comments": "26 pages, 7 figures",
        "categories": [
            "math.NA",
            "astro-ph.IM",
            "cs.NA",
            "physics.comp-ph",
            "physics.plasm-ph"
        ],
        "primary_category": "math.NA"
    },
    "2404.05534v1": {
        "url": "http://arxiv.org/abs/2404.05534v1",
        "title": "Ordre public exceptions for algorithmic surveillance patents",
        "summary": "This chapter explores the role of patent protection in algorithmic\nsurveillance and whether ordre public exceptions from patentability should\napply to such patents, due to their potential to enable human rights\nviolations. It concludes that in most cases, it is undesirable to exclude\nalgorithmic surveillance patents from patentability, as the patent system is\nill-equipped to evaluate the impacts of the exploitation of such technologies.\nFurthermore, the disclosure of such patents has positive externalities from the\nsocietal perspective by opening the black box of surveillance for public\nscrutiny.",
        "updated": "2024-04-08T14:00:50Z",
        "published": "2024-04-08T14:00:50Z",
        "authors": [
            "Alina Wernick"
        ],
        "comments": "14 pages",
        "categories": [
            "cs.CY",
            "cs.AI"
        ],
        "primary_category": "cs.CY",
        "doi": "10.1007/978-3-662-68599-0_33"
    },
    "2404.05535v1": {
        "url": "http://arxiv.org/abs/2404.05535v1",
        "title": "Robust STL Control Synthesis under Maximal Disturbance Sets",
        "summary": "This work addresses maximally robust control synthesis under unknown\ndisturbances. We consider a general nonlinear system, subject to a Signal\nTemporal Logic (STL) specification, and wish to jointly synthesize the maximal\npossible disturbance bounds and the corresponding controllers that ensure the\nSTL specification is satisfied under these bounds. Many works have considered\nSTL satisfaction under given bounded disturbances. Yet, to the authors' best\nknowledge, this is the first work that aims to maximize the permissible\ndisturbance set and find the corresponding controllers that ensure satisfying\nthe STL specification with maximum disturbance robustness. We extend the notion\nof disturbance-robust semantics for STL, which is a property of a\nspecification, dynamical system, and controller, and provide an algorithm to\nget the maximal disturbance robust controllers satisfying an STL specification\nusing Hamilton-Jacobi reachability. We show its soundness and provide a\nsimulation example with an Autonomous Underwater Vehicle (AUV).",
        "updated": "2024-04-08T14:03:33Z",
        "published": "2024-04-08T14:03:33Z",
        "authors": [
            "Joris Verhagen",
            "Lars Lindemann",
            "Jana Tumova"
        ],
        "comments": "8 pages, 3 figures",
        "categories": [
            "cs.RO"
        ],
        "primary_category": "cs.RO"
    },
    "2404.05536v1": {
        "url": "http://arxiv.org/abs/2404.05536v1",
        "title": "On the Optimal MMSE Channel Estimation for One-Bit Quantized MIMO\n  Systems",
        "summary": "This paper focuses on the minimum mean squared error (MMSE) channel estimator\nfor multiple-input multiple-output (MIMO) systems with one-bit quantization at\nthe receiver side. Despite its optimality and significance in estimation\ntheory, the MMSE channel estimator has not been fully investigated in this\ncontext due to its general non-linearity and computational complexity. Instead,\nthe typically suboptimal Bussgang linear MMSE (BLMMSE) estimator has been\nwidely adopted. In this work, we develop a new framework to compute the MMSE\nchannel estimator that hinges on computation of the orthant probability of the\nmultivariate normal distribution. Based on this framework, we determine a\nnecessary and sufficient condition for the BLMMSE channel estimator to be\noptimal and equivalent to the MMSE estimator. Under the assumption of specific\nchannel correlation or pilot symbols, we further utilize the framework to\nderive analytical expressions for the MMSE channel estimator that are\nparticularly convenient for computation when certain system dimensions become\nlarge, thereby enabling a comparison between the BLMMSE and MMSE channel\nestimators in these cases.",
        "updated": "2024-04-08T14:03:37Z",
        "published": "2024-04-08T14:03:37Z",
        "authors": [
            "Minhua Ding",
            "Italo Atzeni",
            "Antti T\u00f6lli",
            "A. Lee Swindlehurst"
        ],
        "comments": "IEEE journal submission, 13 pages, 5 figures",
        "categories": [
            "cs.IT",
            "eess.SP",
            "math.IT",
            "94A12, 94A05"
        ],
        "primary_category": "cs.IT"
    },
    "2404.05538v2": {
        "url": "http://arxiv.org/abs/2404.05538v2",
        "title": "Cell-Free Multi-User MIMO Equalization via In-Context Learning",
        "summary": "Large pre-trained sequence models, such as transformers, excel as few-shot\nlearners capable of in-context learning (ICL). In ICL, a model is trained to\nadapt its operation to a new task based on limited contextual information,\ntypically in the form of a few training examples for the given task. Previous\nwork has explored the use of ICL for channel equalization in single-user\nmulti-input and multiple-output (MIMO) systems. In this work, we demonstrate\nthat ICL can be also used to tackle the problem of multi-user equalization in\ncell-free MIMO systems with limited fronthaul capacity. In this scenario, a\ntask is defined by channel statistics, signal-to-noise ratio, and modulation\nschemes. The context encompasses the users' pilot sequences, the corresponding\nquantized received signals, and the current received data signal. Different\nprompt design strategies are proposed and evaluated that encompass also\nlarge-scale fading and modulation information. Experiments demonstrate that\nICL-based equalization provides estimates with lower mean squared error as\ncompared to the linear minimum mean squared error equalizer, especially in the\npresence of limited fronthaul capacity and pilot contamination.",
        "updated": "2024-04-11T09:45:13Z",
        "published": "2024-04-08T14:06:52Z",
        "authors": [
            "Matteo Zecchin",
            "Kai Yu",
            "Osvaldo Simeone"
        ],
        "categories": [
            "cs.IT",
            "cs.LG",
            "eess.SP",
            "math.IT"
        ],
        "primary_category": "cs.IT"
    },
    "2404.06635v1": {
        "url": "http://arxiv.org/abs/2404.06635v1",
        "title": "Current Affairs: A Measurement Study of Deployment and Security Trends\n  in EV Charging Infrastructure",
        "summary": "The deployment of electric vehicle charging infrastructure is occurring at a\nrapid pace. Simultaneously, existing standards, such as ISO 15118, which\ndefines critical charging communication, are being improved and further\ndeveloped. In this paper, we conduct a measurement study of already deployed DC\ncharging stations to analyze the current state of deployment for various\nprotocols. We present the adoption of TLS, and various EV charging protocols\nwith a direct security impact, as well as observations about the Signal Level\nAttenuation Characterization (SLAC) process, and encryption keys.\n  Our results indicate that even recently installed charging stations (December\n2023) do not adhere to the latest version of the standard, leaving them\nvulnerable to attacks. We found that 84% of the surveyed charging stations do\nnot implement Transport Layer Security (TLS), and are thus unable to implement\nthe latest versions of the ISO 15118 protocol, leaving them vulnerable to\nattacks already demonstrated years ago. Finally, we observe and document\nanomalous behavior and violations of the standard.",
        "updated": "2024-04-09T22:12:39Z",
        "published": "2024-04-09T22:12:39Z",
        "authors": [
            "Marcell Szak\u00e1ly",
            "Sebastian K\u00f6hler",
            "Ivan Martinovic"
        ],
        "categories": [
            "cs.CR"
        ],
        "primary_category": "cs.CR"
    },
    "2404.06637v1": {
        "url": "http://arxiv.org/abs/2404.06637v1",
        "title": "GeoSynth: Contextually-Aware High-Resolution Satellite Image Synthesis",
        "summary": "We present GeoSynth, a model for synthesizing satellite images with global\nstyle and image-driven layout control. The global style control is via textual\nprompts or geographic location. These enable the specification of scene\nsemantics or regional appearance respectively, and can be used together. We\ntrain our model on a large dataset of paired satellite imagery, with\nautomatically generated captions, and OpenStreetMap data. We evaluate various\ncombinations of control inputs, including different types of layout controls.\nResults demonstrate that our model can generate diverse, high-quality images\nand exhibits excellent zero-shot generalization. The code and model checkpoints\nare available at https://github.com/mvrl/GeoSynth.",
        "updated": "2024-04-09T22:16:34Z",
        "published": "2024-04-09T22:16:34Z",
        "authors": [
            "Srikumar Sastry",
            "Subash Khanal",
            "Aayush Dhakal",
            "Nathan Jacobs"
        ],
        "categories": [
            "cs.CV"
        ],
        "primary_category": "cs.CV"
    },
    "2404.06641v1": {
        "url": "http://arxiv.org/abs/2404.06641v1",
        "title": "Federated learning model for predicting major postoperative\n  complications",
        "summary": "Background: The accurate prediction of postoperative complication risk using\nElectronic Health Records (EHR) and artificial intelligence shows great\npotential. Training a robust artificial intelligence model typically requires\nlarge-scale and diverse datasets. In reality, collecting medical data often\nencounters challenges surrounding privacy protection. Methods: This\nretrospective cohort study includes adult patients who were admitted to UFH\nGainesville (GNV) (n = 79,850) and Jacksonville (JAX) (n = 28,636) for any type\nof inpatient surgical procedure. Using perioperative and intraoperative\nfeatures, we developed federated learning models to predict nine major\npostoperative complications (i.e., prolonged intensive care unit stay and\nmechanical ventilation). We compared federated learning models with local\nlearning models trained on a single site and central learning models trained on\npooled dataset from two centers. Results: Our federated learning models\nachieved the area under the receiver operating characteristics curve (AUROC)\nvalues ranged from 0.81 for wound complications to 0.92 for prolonged ICU stay\nat UFH GNV center. At UFH JAX center, these values ranged from 0.73-0.74 for\nwound complications to 0.92-0.93 for hospital mortality. Federated learning\nmodels achieved comparable AUROC performance to central learning models, except\nfor prolonged ICU stay, where the performance of federated learning models was\nslightly higher than central learning models at UFH GNV center, but slightly\nlower at UFH JAX center. In addition, our federated learning model obtained\ncomparable performance to the best local learning model at each center,\ndemonstrating strong generalizability. Conclusion: Federated learning is shown\nto be a useful tool to train robust and generalizable models from large scale\ndata across multiple institutions where data protection barriers are high.",
        "updated": "2024-04-09T22:31:10Z",
        "published": "2024-04-09T22:31:10Z",
        "authors": [
            "Yonggi Park",
            "Yuanfang Ren",
            "Benjamin Shickel",
            "Ziyuan Guan",
            "Ayush Patela",
            "Yingbo Ma",
            "Zhenhong Hu",
            "Tyler J. Loftus",
            "Parisa Rashidi",
            "Tezcan Ozrazgat-Baslanti",
            "Azra Bihorac"
        ],
        "comments": "57 pages. 2 figures, 3 tables, 2 supplemental figures, 8 supplemental\n  tables",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.CY"
        ],
        "primary_category": "cs.LG"
    },
    "2404.06644v1": {
        "url": "http://arxiv.org/abs/2404.06644v1",
        "title": "Khayyam Challenge (PersianMMLU): Is Your LLM Truly Wise to The Persian\n  Language?",
        "summary": "Evaluating Large Language Models (LLMs) is challenging due to their\ngenerative nature, necessitating precise evaluation methodologies.\nAdditionally, non-English LLM evaluation lags behind English, resulting in the\nabsence or weakness of LLMs for many languages. In response to this necessity,\nwe introduce Khayyam Challenge (also known as PersianMMLU), a meticulously\ncurated collection comprising 20,192 four-choice questions sourced from 38\ndiverse tasks extracted from Persian examinations, spanning a wide spectrum of\nsubjects, complexities, and ages. The primary objective of the Khayyam\nChallenge is to facilitate the rigorous evaluation of LLMs that support the\nPersian language. Distinctive features of the Khayyam Challenge are (i) its\ncomprehensive coverage of various topics, including literary comprehension,\nmathematics, sciences, logic, intelligence testing, etc., aimed at assessing\ndifferent facets of LLMs such as language comprehension, reasoning, and\ninformation retrieval across various educational stages, from lower primary\nschool to upper secondary school (ii) its inclusion of rich metadata such as\nhuman response rates, difficulty levels, and descriptive answers (iii) its\nutilization of new data to avoid data contamination issues prevalent in\nexisting frameworks (iv) its use of original, non-translated data tailored for\nPersian speakers, ensuring the framework is free from translation challenges\nand errors while encompassing cultural nuances (v) its inherent scalability for\nfuture data updates and evaluations without requiring special human effort.\nPrevious works lacked an evaluation framework that combined all of these\nfeatures into a single comprehensive benchmark. Furthermore, we evaluate a wide\nrange of existing LLMs that support the Persian language, with statistical\nanalyses and interpretations of their outputs.",
        "updated": "2024-04-09T22:38:13Z",
        "published": "2024-04-09T22:38:13Z",
        "authors": [
            "Omid Ghahroodi",
            "Marzia Nouri",
            "Mohammad Vali Sanian",
            "Alireza Sahebi",
            "Doratossadat Dastgheib",
            "Ehsaneddin Asgari",
            "Mahdieh Soleymani Baghshah",
            "Mohammad Hossein Rohban"
        ],
        "categories": [
            "cs.CL",
            "cs.AI"
        ],
        "primary_category": "cs.CL"
    },
    "2404.06645v1": {
        "url": "http://arxiv.org/abs/2404.06645v1",
        "title": "GenCHiP: Generating Robot Policy Code for High-Precision and\n  Contact-Rich Manipulation Tasks",
        "summary": "Large Language Models (LLMs) have been successful at generating robot policy\ncode, but so far these results have been limited to high-level tasks that do\nnot require precise movement. It is an open question how well such approaches\nwork for tasks that require reasoning over contact forces and working within\ntight success tolerances. We find that, with the right action space, LLMs are\ncapable of successfully generating policies for a variety of contact-rich and\nhigh-precision manipulation tasks, even under noisy conditions, such as\nperceptual errors or grasping inaccuracies. Specifically, we reparameterize the\naction space to include compliance with constraints on the interaction forces\nand stiffnesses involved in reaching a target pose. We validate this approach\non subtasks derived from the Functional Manipulation Benchmark (FMB) and NIST\nTask Board Benchmarks. Exposing this action space alongside methods for\nestimating object poses improves policy generation with an LLM by greater than\n3x and 4x when compared to non-compliant action spaces",
        "updated": "2024-04-09T22:47:25Z",
        "published": "2024-04-09T22:47:25Z",
        "authors": [
            "Kaylee Burns",
            "Ajinkya Jain",
            "Keegan Go",
            "Fei Xia",
            "Michael Stark",
            "Stefan Schaal",
            "Karol Hausman"
        ],
        "comments": "14 pages, 12 figures",
        "categories": [
            "cs.RO",
            "cs.AI",
            "I.2.9"
        ],
        "primary_category": "cs.RO"
    },
    "2404.06646v1": {
        "url": "http://arxiv.org/abs/2404.06646v1",
        "title": "Game Semantics for Higher-Order Unitary Quantum Computation",
        "summary": "We develop a symmetric monoidal closed category of games, incorporating sums\nand products, to model quantum computation at higher types. This model is\nexpressive, capable of representing all unitary operators at base types. It is\ncompatible with base types and realizable by unitary operators.",
        "updated": "2024-04-09T22:51:39Z",
        "published": "2024-04-09T22:51:39Z",
        "authors": [
            "Samson Abramsky",
            "Radha Jagadeesan"
        ],
        "categories": [
            "cs.PL",
            "quant-ph",
            "D.3.3; F.3.2"
        ],
        "primary_category": "cs.PL"
    },
    "2404.06647v2": {
        "url": "http://arxiv.org/abs/2404.06647v2",
        "title": "From Protoscience to Epistemic Monoculture: How Benchmarking Set the\n  Stage for the Deep Learning Revolution",
        "summary": "Over the past decade, AI research has focused heavily on building ever-larger\ndeep learning models. This approach has simultaneously unlocked incredible\nachievements in science and technology, and hindered AI from overcoming\nlong-standing limitations with respect to explainability, ethical harms, and\nenvironmental efficiency. Drawing on qualitative interviews and computational\nanalyses, our three-part history of AI research traces the creation of this\n\"epistemic monoculture\" back to a radical reconceptualization of scientific\nprogress that began in the late 1980s. In the first era of AI research\n(1950s-late 1980s), researchers and patrons approached AI as a \"basic\" science\nthat would advance through autonomous exploration and organic assessments of\nprogress (e.g., peer-review, theoretical consensus). The failure of this\napproach led to a retrenchment of funding in the 1980s. Amid this \"AI Winter,\"\nan intervention by the U.S. government reoriented the field towards measurable\nprogress on tasks of military and commercial interest. A new evaluation system\ncalled \"benchmarking\" provided an objective way to quantify progress on tasks\nby focusing exclusively on increasing predictive accuracy on example datasets.\nDistilling science down to verifiable metrics clarified the roles of\nscientists, allowed the field to rapidly integrate talent, and provided clear\nsignals of significance and progress. But history has also revealed a tradeoff\nto this streamlined approach to science: the consolidation around external\ninterests and inherent conservatism of benchmarking has disincentivized\nexploration beyond scaling monoculture. In the discussion, we explain how AI's\nmonoculture offers a compelling challenge to the belief that basic,\nexploration-driven research is needed for scientific progress. Implications for\nthe spread of AI monoculture to other sciences in the era of generative AI are\nalso discussed.",
        "updated": "2024-04-11T02:09:23Z",
        "published": "2024-04-09T22:55:06Z",
        "authors": [
            "Bernard J. Koch",
            "David Peterson"
        ],
        "categories": [
            "cs.CY",
            "cs.AI",
            "cs.LG"
        ],
        "primary_category": "cs.CY"
    },
    "2404.06653v1": {
        "url": "http://arxiv.org/abs/2404.06653v1",
        "title": "FlameFinder: Illuminating Obscured Fire through Smoke with Attentive\n  Deep Metric Learning",
        "summary": "FlameFinder is a deep metric learning (DML) framework designed to accurately\ndetect flames, even when obscured by smoke, using thermal images from\nfirefighter drones during wildfire monitoring. Traditional RGB cameras struggle\nin such conditions, but thermal cameras can capture smoke-obscured flame\nfeatures. However, they lack absolute thermal reference points, leading to\nfalse positives.To address this issue, FlameFinder utilizes paired thermal-RGB\nimages for training. By learning latent flame features from smoke-free samples,\nthe model becomes less biased towards relative thermal gradients. In testing,\nit identifies flames in smoky patches by analyzing their equivalent\nthermal-domain distribution. This method improves performance using both\nsupervised and distance-based clustering metrics.The framework incorporates a\nflame segmentation method and a DML-aided detection framework. This includes\nutilizing center loss (CL), triplet center loss (TCL), and triplet cosine\ncenter loss (TCCL) to identify optimal cluster representatives for\nclassification. However, the dominance of center loss over the other losses\nleads to the model missing features sensitive to them. To address this\nlimitation, an attention mechanism is proposed. This mechanism allows for\nnon-uniform feature contribution, amplifying the critical role of cosine and\ntriplet loss in the DML framework. Additionally, it improves interpretability,\nclass discrimination, and decreases intra-class variance. As a result, the\nproposed model surpasses the baseline by 4.4% in the FLAME2 dataset and 7% in\nthe FLAME3 dataset for unobscured flame detection accuracy. Moreover, it\ndemonstrates enhanced class separation in obscured scenarios compared to VGG19,\nResNet18, and three backbone models tailored for flame detection.",
        "updated": "2024-04-09T23:24:19Z",
        "published": "2024-04-09T23:24:19Z",
        "authors": [
            "Hossein Rajoli",
            "Sahand Khoshdel",
            "Fatemeh Afghah",
            "Xiaolong Ma"
        ],
        "comments": "Submitted as a Journal Paper to IEEE Transactions on Geoscience and\n  Remote Sensing",
        "categories": [
            "cs.CV"
        ],
        "primary_category": "cs.CV"
    },
    "2404.06654v2": {
        "url": "http://arxiv.org/abs/2404.06654v2",
        "title": "RULER: What's the Real Context Size of Your Long-Context Language\n  Models?",
        "summary": "The needle-in-a-haystack (NIAH) test, which examines the ability to retrieve\na piece of information (the \"needle\") from long distractor texts (the\n\"haystack\"), has been widely adopted to evaluate long-context language models\n(LMs). However, this simple retrieval-based test is indicative of only a\nsuperficial form of long-context understanding. To provide a more comprehensive\nevaluation of long-context LMs, we create a new synthetic benchmark RULER with\nflexible configurations for customized sequence length and task complexity.\nRULER expands upon the vanilla NIAH test to encompass variations with diverse\ntypes and quantities of needles. Moreover, RULER introduces new task categories\nmulti-hop tracing and aggregation to test behaviors beyond searching from\ncontext. We evaluate ten long-context LMs with 13 representative tasks in\nRULER. Despite achieving nearly perfect accuracy in the vanilla NIAH test, all\nmodels exhibit large performance drops as the context length increases. While\nthese models all claim context sizes of 32K tokens or greater, only four models\n(GPT-4, Command-R, Yi-34B, and Mixtral) can maintain satisfactory performance\nat the length of 32K. Our analysis of Yi-34B, which supports context length of\n200K, reveals large room for improvement as we increase input length and task\ncomplexity. We open source RULER to spur comprehensive evaluation of\nlong-context LMs.",
        "updated": "2024-04-11T23:53:59Z",
        "published": "2024-04-09T23:41:27Z",
        "authors": [
            "Cheng-Ping Hsieh",
            "Simeng Sun",
            "Samuel Kriman",
            "Shantanu Acharya",
            "Dima Rekesh",
            "Fei Jia",
            "Yang Zhang",
            "Boris Ginsburg"
        ],
        "categories": [
            "cs.CL"
        ],
        "primary_category": "cs.CL"
    },
    "2404.06657v1": {
        "url": "http://arxiv.org/abs/2404.06657v1",
        "title": "Res-U2Net: Untrained Deep Learning for Phase Retrieval and Image\n  Reconstruction",
        "summary": "Conventional deep learning-based image reconstruction methods require a large\namount of training data which can be hard to obtain in practice. Untrained deep\nlearning methods overcome this limitation by training a network to invert a\nphysical model of the image formation process. Here we present a novel\nuntrained Res-U2Net model for phase retrieval. We use the extracted phase\ninformation to determine changes in an object's surface and generate a mesh\nrepresentation of its 3D structure. We compare the performance of Res-U2Net\nphase retrieval against UNet and U2Net using images from the GDXRAY dataset.",
        "updated": "2024-04-09T23:47:53Z",
        "published": "2024-04-09T23:47:53Z",
        "authors": [
            "Carlos Osorio Quero",
            "Daniel Leykam",
            "Irving Rondon Ojeda"
        ],
        "comments": "16 pages, 8 figures, 4 Tables",
        "categories": [
            "eess.IV",
            "cs.CV",
            "physics.optics"
        ],
        "primary_category": "eess.IV",
        "doi": "10.1364/JOSAA.511074",
        "journal_ref": "Journal of the Optical Society of America A, Vol. 41, Issue 5, pp.\n  766-773 (2024)"
    },
    "2404.07713v1": {
        "url": "http://arxiv.org/abs/2404.07713v1",
        "title": "Progressive Semantic-Guided Vision Transformer for Zero-Shot Learning",
        "summary": "Zero-shot learning (ZSL) recognizes the unseen classes by conducting\nvisual-semantic interactions to transfer semantic knowledge from seen classes\nto unseen ones, supported by semantic information (e.g., attributes). However,\nexisting ZSL methods simply extract visual features using a pre-trained network\nbackbone (i.e., CNN or ViT), which fail to learn matched visual-semantic\ncorrespondences for representing semantic-related visual features as lacking of\nthe guidance of semantic information, resulting in undesirable visual-semantic\ninteractions. To tackle this issue, we propose a progressive semantic-guided\nvision transformer for zero-shot learning (dubbed ZSLViT). ZSLViT mainly\nconsiders two properties in the whole network: i) discover the semantic-related\nvisual representations explicitly, and ii) discard the semantic-unrelated\nvisual information. Specifically, we first introduce semantic-embedded token\nlearning to improve the visual-semantic correspondences via semantic\nenhancement and discover the semantic-related visual tokens explicitly with\nsemantic-guided token attention. Then, we fuse low semantic-visual\ncorrespondence visual tokens to discard the semantic-unrelated visual\ninformation for visual enhancement. These two operations are integrated into\nvarious encoders to progressively learn semantic-related visual representations\nfor accurate visual-semantic interactions in ZSL. The extensive experiments\nshow that our ZSLViT achieves significant performance gains on three popular\nbenchmark datasets, i.e., CUB, SUN, and AWA2.",
        "updated": "2024-04-11T12:59:38Z",
        "published": "2024-04-11T12:59:38Z",
        "authors": [
            "Shiming Chen",
            "Wenjin Hou",
            "Salman Khan",
            "Fahad Shahbaz Khan"
        ],
        "comments": "Accepted to CVPR'24",
        "categories": [
            "cs.CV",
            "cs.LG"
        ],
        "primary_category": "cs.CV"
    },
    "2404.07717v2": {
        "url": "http://arxiv.org/abs/2404.07717v2",
        "title": "Reflectance Estimation for Proximity Sensing by Vision-Language Models:\n  Utilizing Distributional Semantics for Low-Level Cognition in Robotics",
        "summary": "Large language models (LLMs) and vision-language models (VLMs) have been\nincreasingly used in robotics for high-level cognition, but their use for\nlow-level cognition, such as interpreting sensor information, remains\nunderexplored. In robotic grasping, estimating the reflectance of objects is\ncrucial for successful grasping, as it significantly impacts the distance\nmeasured by proximity sensors. We investigate whether LLMs can estimate\nreflectance from object names alone, leveraging the embedded human knowledge in\ndistributional semantics, and if the latent structure of language in VLMs\npositively affects image-based reflectance estimation. In this paper, we verify\nthat 1) LLMs such as GPT-3.5 and GPT-4 can estimate an object's reflectance\nusing only text as input; and 2) VLMs such as CLIP can increase their\ngeneralization capabilities in reflectance estimation from images. Our\nexperiments show that GPT-4 can estimate an object's reflectance using only\ntext input with a mean error of 14.7%, lower than the image-only ResNet.\nMoreover, CLIP achieved the lowest mean error of 11.8%, while GPT-3.5 obtained\na competitive 19.9% compared to ResNet's 17.8%. These results suggest that the\ndistributional semantics in LLMs and VLMs increases their generalization\ncapabilities, and the knowledge acquired by VLMs benefits from the latent\nstructure of language.",
        "updated": "2024-04-12T06:48:52Z",
        "published": "2024-04-11T13:09:37Z",
        "authors": [
            "Masashi Osada",
            "Gustavo A. Garcia Ricardez",
            "Yosuke Suzuki",
            "Tadahiro Taniguchi"
        ],
        "comments": "16 pages, 10 figures, submitted to Advanced Robotics Special Issue on\n  Real-World Robot Applications of the Foundation Models",
        "categories": [
            "cs.RO"
        ],
        "primary_category": "cs.RO"
    },
    "2404.07719v1": {
        "url": "http://arxiv.org/abs/2404.07719v1",
        "title": "Reframing the Mind-Body Picture: Applying Formal Systems to the\n  Relationship of Mind and Matter",
        "summary": "This paper aims to show that a simple framework, utilizing basic formalisms\nfrom set theory and category theory, can clarify and inform our theories of the\nrelation between mind and matter.",
        "updated": "2024-04-11T13:11:13Z",
        "published": "2024-04-11T13:11:13Z",
        "authors": [
            "Ryan Williams"
        ],
        "categories": [
            "cs.AI",
            "q-bio.NC"
        ],
        "primary_category": "cs.AI"
    },
    "2404.07720v1": {
        "url": "http://arxiv.org/abs/2404.07720v1",
        "title": "Automatic Generation and Evaluation of Reading Comprehension Test Items\n  with Large Language Models",
        "summary": "Reading comprehension tests are used in a variety of applications, reaching\nfrom education to assessing the comprehensibility of simplified texts. However,\ncreating such tests manually and ensuring their quality is difficult and\ntime-consuming. In this paper, we explore how large language models (LLMs) can\nbe used to generate and evaluate multiple-choice reading comprehension items.\nTo this end, we compiled a dataset of German reading comprehension items and\ndeveloped a new protocol for human and automatic evaluation, including a metric\nwe call text informativity, which is based on guessability and answerability.\nWe then used this protocol and the dataset to evaluate the quality of items\ngenerated by Llama 2 and GPT-4. Our results suggest that both models are\ncapable of generating items of acceptable quality in a zero-shot setting, but\nGPT-4 clearly outperforms Llama 2. We also show that LLMs can be used for\nautomatic evaluation by eliciting item reponses from them. In this scenario,\nevaluation results with GPT-4 were the most similar to human annotators.\nOverall, zero-shot generation with LLMs is a promising approach for generating\nand evaluating reading comprehension test items, in particular for languages\nwithout large amounts of available data.",
        "updated": "2024-04-11T13:11:21Z",
        "published": "2024-04-11T13:11:21Z",
        "authors": [
            "Andreas S\u00e4uberli",
            "Simon Clematide"
        ],
        "comments": "Accepted for publication at the 3rd Workshop on Tools and Resources\n  for People with REAding DIfficulties (READI) at LREC-COLING 2024",
        "categories": [
            "cs.CL"
        ],
        "primary_category": "cs.CL"
    },
    "2404.07721v1": {
        "url": "http://arxiv.org/abs/2404.07721v1",
        "title": "Trainable Joint Channel Estimation, Detection and Decoding for MIMO\n  URLLC Systems",
        "summary": "The receiver design for multi-input multi-output (MIMO) ultra-reliable and\nlow-latency communication (URLLC) systems can be a tough task due to the use of\nshort channel codes and few pilot symbols. Consequently, error propagation can\noccur in traditional turbo receivers, leading to performance degradation.\nMoreover, the processing delay induced by information exchange between\ndifferent modules may also be undesirable for URLLC. To address the issues, we\nadvocate to perform joint channel estimation, detection, and decoding (JCDD)\nfor MIMO URLLC systems encoded by short low-density parity-check (LDPC) codes.\nSpecifically, we develop two novel JCDD problem formulations based on the\nmaximum a posteriori (MAP) criterion for Gaussian MIMO channels and sparse\nmmWave MIMO channels, respectively, which integrate the pilots, the\nbit-to-symbol mapping, the LDPC code constraints, as well as the channel\nstatistical information. Both the challenging large-scale non-convex problems\nare then solved based on the alternating direction method of multipliers (ADMM)\nalgorithms, where closed-form solutions are achieved in each ADMM iteration.\nFurthermore, two JCDD neural networks, called JCDDNet-G and JCDDNet-S, are\nbuilt by unfolding the derived ADMM algorithms and introducing trainable\nparameters. It is interesting to find via simulations that the proposed\ntrainable JCDD receivers can outperform the turbo receivers with affordable\ncomputational complexities.",
        "updated": "2024-04-11T13:11:37Z",
        "published": "2024-04-11T13:11:37Z",
        "authors": [
            "Yi Sun",
            "Hong Shen",
            "Bingqing Li",
            "Wei Xu",
            "Pengcheng Zhu",
            "Nan Hu",
            "Chunming Zhao"
        ],
        "comments": "17 pages, 12 figures, accepted by IEEE Transactions on Wireless\n  Communications",
        "categories": [
            "eess.SP",
            "cs.IT",
            "math.IT"
        ],
        "primary_category": "eess.SP"
    },
    "2404.07724v1": {
        "url": "http://arxiv.org/abs/2404.07724v1",
        "title": "Applying Guidance in a Limited Interval Improves Sample and Distribution\n  Quality in Diffusion Models",
        "summary": "Guidance is a crucial technique for extracting the best performance out of\nimage-generating diffusion models. Traditionally, a constant guidance weight\nhas been applied throughout the sampling chain of an image. We show that\nguidance is clearly harmful toward the beginning of the chain (high noise\nlevels), largely unnecessary toward the end (low noise levels), and only\nbeneficial in the middle. We thus restrict it to a specific range of noise\nlevels, improving both the inference speed and result quality. This limited\nguidance interval improves the record FID in ImageNet-512 significantly, from\n1.81 to 1.40. We show that it is quantitatively and qualitatively beneficial\nacross different sampler parameters, network architectures, and datasets,\nincluding the large-scale setting of Stable Diffusion XL. We thus suggest\nexposing the guidance interval as a hyperparameter in all diffusion models that\nuse guidance.",
        "updated": "2024-04-11T13:16:47Z",
        "published": "2024-04-11T13:16:47Z",
        "authors": [
            "Tuomas Kynk\u00e4\u00e4nniemi",
            "Miika Aittala",
            "Tero Karras",
            "Samuli Laine",
            "Timo Aila",
            "Jaakko Lehtinen"
        ],
        "categories": [
            "cs.CV",
            "cs.AI",
            "cs.LG",
            "cs.NE",
            "stat.ML"
        ],
        "primary_category": "cs.CV"
    },
    "2404.07725v1": {
        "url": "http://arxiv.org/abs/2404.07725v1",
        "title": "Unraveling the Dilemma of AI Errors: Exploring the Effectiveness of\n  Human and Machine Explanations for Large Language Models",
        "summary": "The field of eXplainable artificial intelligence (XAI) has produced a\nplethora of methods (e.g., saliency-maps) to gain insight into artificial\nintelligence (AI) models, and has exploded with the rise of deep learning (DL).\nHowever, human-participant studies question the efficacy of these methods,\nparticularly when the AI output is wrong. In this study, we collected and\nanalyzed 156 human-generated text and saliency-based explanations collected in\na question-answering task (N=40) and compared them empirically to\nstate-of-the-art XAI explanations (integrated gradients, conservative LRP, and\nChatGPT) in a human-participant study (N=136). Our findings show that\nparticipants found human saliency maps to be more helpful in explaining AI\nanswers than machine saliency maps, but performance negatively correlated with\ntrust in the AI model and explanations. This finding hints at the dilemma of AI\nerrors in explanation, where helpful explanations can lead to lower task\nperformance when they support wrong AI predictions.",
        "updated": "2024-04-11T13:16:51Z",
        "published": "2024-04-11T13:16:51Z",
        "authors": [
            "Marvin Pafla",
            "Kate Larson",
            "Mark Hancock"
        ],
        "categories": [
            "cs.HC",
            "cs.AI"
        ],
        "primary_category": "cs.HC",
        "doi": "10.1145/3613904.3642934"
    },
    "2404.07729v1": {
        "url": "http://arxiv.org/abs/2404.07729v1",
        "title": "Realistic Continual Learning Approach using Pre-trained Models",
        "summary": "Continual learning (CL) is crucial for evaluating adaptability in learning\nsolutions to retain knowledge. Our research addresses the challenge of\ncatastrophic forgetting, where models lose proficiency in previously learned\ntasks as they acquire new ones. While numerous solutions have been proposed,\nexisting experimental setups often rely on idealized class-incremental learning\nscenarios. We introduce Realistic Continual Learning (RealCL), a novel CL\nparadigm where class distributions across tasks are random, departing from\nstructured setups.\n  We also present CLARE (Continual Learning Approach with pRE-trained models\nfor RealCL scenarios), a pre-trained model-based solution designed to integrate\nnew knowledge while preserving past learning. Our contributions include\npioneering RealCL as a generalization of traditional CL setups, proposing CLARE\nas an adaptable approach for RealCL tasks, and conducting extensive experiments\ndemonstrating its effectiveness across various RealCL scenarios. Notably, CLARE\noutperforms existing models on RealCL benchmarks, highlighting its versatility\nand robustness in unpredictable learning environments.",
        "updated": "2024-04-11T13:19:46Z",
        "published": "2024-04-11T13:19:46Z",
        "authors": [
            "Nadia Nasri",
            "Carlos Guti\u00e9rrez-\u00c1lvarez",
            "Sergio Lafuente-Arroyo",
            "Saturnino Maldonado-Basc\u00f3n",
            "Roberto J. L\u00f3pez-Sastre"
        ],
        "categories": [
            "cs.LG",
            "cs.CV"
        ],
        "primary_category": "cs.LG"
    },
    "2404.07730v1": {
        "url": "http://arxiv.org/abs/2404.07730v1",
        "title": "Point cloud obstacle detection with the map filtration",
        "summary": "Obstacle detection is one of the basic tasks of a robot movement in an\nunknown environment. The use of a LiDAR (Light Detection And Ranging) sensor\nallows one to obtain a point cloud in the vicinity of the sensor. After\nprocessing this data, obstacles can be found and recorded on a map. For this\ntask, I present a pipeline capable of detecting obstacles even on a\ncomputationally limited device. The pipeline was also tested on a real robot\nand qualitatively evaluated on a dataset, which was collected in Brno\nUniversity of Technology lab. Time consumption was recorded and compared with\n3D object detectors.",
        "updated": "2024-04-11T13:24:58Z",
        "published": "2024-04-11T13:24:58Z",
        "authors": [
            "Lukas Kratochvila"
        ],
        "categories": [
            "cs.RO"
        ],
        "primary_category": "cs.RO",
        "journal_ref": "Proceedings I of the 29 th Conference STUDENT EEICT 2023 455-459;\n  ISBN 978-80-214-6153-6"
    },
    "2404.07732v1": {
        "url": "http://arxiv.org/abs/2404.07732v1",
        "title": "Monte Carlo Tree Search with Boltzmann Exploration",
        "summary": "Monte-Carlo Tree Search (MCTS) methods, such as Upper Confidence Bound\napplied to Trees (UCT), are instrumental to automated planning techniques.\nHowever, UCT can be slow to explore an optimal action when it initially appears\ninferior to other actions. Maximum ENtropy Tree-Search (MENTS) incorporates the\nmaximum entropy principle into an MCTS approach, utilising Boltzmann policies\nto sample actions, naturally encouraging more exploration. In this paper, we\nhighlight a major limitation of MENTS: optimal actions for the maximum entropy\nobjective do not necessarily correspond to optimal actions for the original\nobjective. We introduce two algorithms, Boltzmann Tree Search (BTS) and\nDecaying ENtropy Tree-Search (DENTS), that address these limitations and\npreserve the benefits of Boltzmann policies, such as allowing actions to be\nsampled faster by using the Alias method. Our empirical analysis shows that our\nalgorithms show consistent high performance across several benchmark domains,\nincluding the game of Go.",
        "updated": "2024-04-11T13:25:35Z",
        "published": "2024-04-11T13:25:35Z",
        "authors": [
            "Michael Painter",
            "Mohamed Baioumy",
            "Nick Hawes",
            "Bruno Lacerda"
        ],
        "comments": "Camera ready version of NeurIPS2023 paper",
        "categories": [
            "cs.AI",
            "cs.LG"
        ],
        "primary_category": "cs.AI",
        "journal_ref": "Advances in Neural Information Processing Systems 36 (2024)"
    },
    "2404.08717v1": {
        "url": "http://arxiv.org/abs/2404.08717v1",
        "title": "State-Space Systems as Dynamic Generative Models",
        "summary": "A probabilistic framework to study the dependence structure induced by\ndeterministic discrete-time state-space systems between input and output\nprocesses is introduced. General sufficient conditions are formulated under\nwhich output processes exist and are unique once an input process has been\nfixed, a property that in the deterministic state-space literature is known as\nthe echo state property. When those conditions are satisfied, the given\nstate-space system becomes a generative model for probabilistic dependences\nbetween two sequence spaces. Moreover, those conditions guarantee that the\noutput depends continuously on the input when using the Wasserstein metric. The\noutput processes whose existence is proved are shown to be causal in a specific\nsense and to generalize those studied in purely deterministic situations. The\nresults in this paper constitute a significant stochastic generalization of\nsufficient conditions for the deterministic echo state property to hold, in the\nsense that the stochastic echo state property can be satisfied under\ncontractivity conditions that are strictly weaker than those in deterministic\nsituations. This means that state-space systems can induce a purely\nprobabilistic dependence structure between input and output sequence spaces\neven when there is no functional relation between those two spaces.",
        "updated": "2024-04-12T07:32:57Z",
        "published": "2024-04-12T07:32:57Z",
        "authors": [
            "Juan-Pablo Ortega",
            "Florian Rossmannek"
        ],
        "categories": [
            "stat.ML",
            "cs.LG",
            "math.DS",
            "math.PR",
            "math.ST",
            "stat.TH",
            "37H05, 37N35, 62M10, 68T05"
        ],
        "primary_category": "stat.ML"
    },
    "2404.08720v1": {
        "url": "http://arxiv.org/abs/2404.08720v1",
        "title": "Exploring Contrastive Learning for Long-Tailed Multi-Label Text\n  Classification",
        "summary": "Learning an effective representation in multi-label text classification\n(MLTC) is a significant challenge in NLP. This challenge arises from the\ninherent complexity of the task, which is shaped by two key factors: the\nintricate connections between labels and the widespread long-tailed\ndistribution of the data. To overcome this issue, one potential approach\ninvolves integrating supervised contrastive learning with classical supervised\nloss functions. Although contrastive learning has shown remarkable performance\nin multi-class classification, its impact in the multi-label framework has not\nbeen thoroughly investigated. In this paper, we conduct an in-depth study of\nsupervised contrastive learning and its influence on representation in MLTC\ncontext. We emphasize the importance of considering long-tailed data\ndistributions to build a robust representation space, which effectively\naddresses two critical challenges associated with contrastive learning that we\nidentify: the \"lack of positives\" and the \"attraction-repulsion imbalance\".\nBuilding on this insight, we introduce a novel contrastive loss function for\nMLTC. It attains Micro-F1 scores that either match or surpass those obtained\nwith other frequently employed loss functions, and demonstrates a significant\nimprovement in Macro-F1 scores across three multi-label datasets.",
        "updated": "2024-04-12T11:12:16Z",
        "published": "2024-04-12T11:12:16Z",
        "authors": [
            "Alexandre Audibert",
            "Aur\u00e9lien Gauffre",
            "Massih-Reza Amini"
        ],
        "comments": "14 pages, 2 figures",
        "categories": [
            "cs.LG",
            "cs.CL",
            "cs.IR"
        ],
        "primary_category": "cs.LG"
    },
    "2404.08721v1": {
        "url": "http://arxiv.org/abs/2404.08721v1",
        "title": "Beyond One-Size-Fits-All: Adapting Counterfactual Explanations to User\n  Objectives",
        "summary": "Explainable Artificial Intelligence (XAI) has emerged as a critical area of\nresearch aimed at enhancing the transparency and interpretability of AI\nsystems. Counterfactual Explanations (CFEs) offer valuable insights into the\ndecision-making processes of machine learning algorithms by exploring\nalternative scenarios where certain factors differ. Despite the growing\npopularity of CFEs in the XAI community, existing literature often overlooks\nthe diverse needs and objectives of users across different applications and\ndomains, leading to a lack of tailored explanations that adequately address the\ndifferent use cases. In this paper, we advocate for a nuanced understanding of\nCFEs, recognizing the variability in desired properties based on user\nobjectives and target applications. We identify three primary user objectives\nand explore the desired characteristics of CFEs in each case. By addressing\nthese differences, we aim to design more effective and tailored explanations\nthat meet the specific needs of users, thereby enhancing collaboration with AI\nsystems.",
        "updated": "2024-04-12T13:11:55Z",
        "published": "2024-04-12T13:11:55Z",
        "authors": [
            "Orfeas Menis Mastromichalakis",
            "Jason Liartis",
            "Giorgos Stamou"
        ],
        "categories": [
            "cs.LG",
            "cs.AI"
        ],
        "primary_category": "cs.LG"
    },
    "2404.08722v1": {
        "url": "http://arxiv.org/abs/2404.08722v1",
        "title": "VADA: a Data-Driven Simulator for Nanopore Sequencing",
        "summary": "Nanopore sequencing offers the ability for real-time analysis of long DNA\nsequences at a low cost, enabling new applications such as early detection of\ncancer. Due to the complex nature of nanopore measurements and the high cost of\nobtaining ground truth datasets, there is a need for nanopore simulators.\nExisting simulators rely on handcrafted rules and parameters and do not learn\nan internal representation that would allow for analysing underlying biological\nfactors of interest. Instead, we propose VADA, a purely data-driven method for\nsimulating nanopores based on an autoregressive latent variable model. We embed\nsubsequences of DNA and introduce a conditional prior to address the challenge\nof a collapsing conditioning. We introduce an auxiliary regressor on the latent\nvariable to encourage our model to learn an informative latent representation.\nWe empirically demonstrate that our model achieves competitive simulation\nperformance on experimental nanopore data. Moreover, we show we have learned an\ninformative latent representation that is predictive of the DNA labels. We\nhypothesize that other biological factors of interest, beyond the DNA labels,\ncan potentially be extracted from such a learned latent representation.",
        "updated": "2024-04-12T13:24:28Z",
        "published": "2024-04-12T13:24:28Z",
        "authors": [
            "Jonas Niederle",
            "Simon Koop",
            "Marc Pag\u00e8s-Gallego",
            "Vlado Menkovski"
        ],
        "categories": [
            "q-bio.QM",
            "cs.LG"
        ],
        "primary_category": "q-bio.QM"
    },
    "2404.08723v1": {
        "url": "http://arxiv.org/abs/2404.08723v1",
        "title": "Identification of a replicable optical security element using laser\n  speckle",
        "summary": "An optical security element containing an area of random rough relief is\nproposed. It combines the low cost of mass replication inherent in traditional\nsecurity holograms with the impossibility of holographic copying, when the wave\nrestored by the hologram is rewritten as a copy of this hologram. The proposed\noptical element is also protected from contact and photographic copying.\nLaboratory samples of optical elements were obtained by taking replicas of a\nrough surface. Identification of the authenticity of optical elements was\ndemonstrated by calculating the cross-correlation of speckle patterns produced\nby coherent light scattered off different replicas. It is assumed that the\nproposed security elements can be mass-produced on standard equipment for\nembossing security holograms.",
        "updated": "2024-04-12T13:25:50Z",
        "published": "2024-04-12T13:25:50Z",
        "authors": [
            "A. M. Smolovich",
            "A. V. Frolov",
            "L. D. Klebanov",
            "I. D. Laktaev",
            "A. P. Orlov",
            "P. A. Smolovich",
            "O. V. Butov"
        ],
        "comments": "9 pages, 6 figures",
        "categories": [
            "cs.CR",
            "physics.optics"
        ],
        "primary_category": "cs.CR",
        "doi": "10.1016/j.optlastec.2024.110725",
        "journal_ref": "Optics & Laser Technology, 175, 110725 (2024)"
    },
    "2404.08726v1": {
        "url": "http://arxiv.org/abs/2404.08726v1",
        "title": "An Integrated Toolbox for Creating Neuromorphic Edge Applications",
        "summary": "Spiking Neural Networks (SNNs) and neuromorphic models are more efficient and\nhave more biological realism than the activation functions typically used in\ndeep neural networks, transformer models and generative AI. SNNs have local\nlearning rules, are able to learn on small data sets, and can adapt through\nneuromodulation. Although research has shown their advantages, there are still\nfew compelling practical applications, especially at the edge where sensors and\nactuators need to be processed in a timely fashion. One reason for this might\nbe that SNNs are much more challenging to understand, build, and operate due to\ntheir intrinsic properties. For instance, the mathematical foundation involves\ndifferential equations rather than basic activation functions. To address these\nchallenges, we have developed CARLsim++. It is an integrated toolbox that\nenables fast and easy creation of neuromorphic applications. It encapsulates\nthe mathematical intrinsics and low-level C++ programming by providing a\ngraphical user interface for users who do not have a background in software\nengineering but still want to create neuromorphic models. Developers can easily\nconfigure inputs and outputs to devices and robots. These can be accurately\nsimulated before deploying on physical devices. CARLsim++ can lead to rapid\ndevelopment of neuromorphic applications for simulation or edge processing.",
        "updated": "2024-04-12T16:34:55Z",
        "published": "2024-04-12T16:34:55Z",
        "authors": [
            "Lars Niedermeier",
            "Jeffrey L. Krichmar"
        ],
        "comments": "8 pages, 5 figures, NICE 2024",
        "categories": [
            "cs.NE",
            "cs.AI"
        ],
        "primary_category": "cs.NE"
    },
    "2404.08727v1": {
        "url": "http://arxiv.org/abs/2404.08727v1",
        "title": "Can LLMs substitute SQL? Comparing Resource Utilization of Querying LLMs\n  versus Traditional Relational Databases",
        "summary": "Large Language Models (LLMs) can automate or substitute different types of\ntasks in the software engineering process. This study evaluates the resource\nutilization and accuracy of LLM in interpreting and executing natural language\nqueries against traditional SQL within relational database management systems.\nWe empirically examine the resource utilization and accuracy of nine LLMs\nvarying from 7 to 34 Billion parameters, including Llama2 7B, Llama2 13B,\nMistral, Mixtral, Optimus-7B, SUS-chat-34B, platypus-yi-34b,\nNeuralHermes-2.5-Mistral-7B and Starling-LM-7B-alpha, using a small transaction\ndataset. Our findings indicate that using LLMs for database queries incurs\nsignificant energy overhead (even small and quantized models), making it an\nenvironmentally unfriendly approach. Therefore, we advise against replacing\nrelational databases with LLMs due to their substantial resource utilization.",
        "updated": "2024-04-12T16:44:28Z",
        "published": "2024-04-12T16:44:28Z",
        "authors": [
            "Xiang Zhang",
            "Khatoon Khedri",
            "Reza Rawassizadeh"
        ],
        "comments": "13 pages, 2 figures, 5 tables",
        "categories": [
            "cs.DB",
            "cs.AI",
            "cs.CL",
            "68-04",
            "H.2.m"
        ],
        "primary_category": "cs.DB"
    },
    "2404.08743v1": {
        "url": "http://arxiv.org/abs/2404.08743v1",
        "title": "VizGroup: An AI-Assisted Event-Driven System for Real-Time Collaborative\n  Programming Learning Analytics",
        "summary": "Programming instructors often conduct collaborative learning activities, like\nPeer Instruction, to foster a deeper understanding in students and enhance\ntheir engagement with learning. These activities, however, may not always yield\nproductive outcomes due to the diversity of student mental models and their\nineffective collaboration. In this work, we introduce VizGroup, an AI-assisted\nsystem that enables programming instructors to easily oversee students'\nreal-time collaborative learning behaviors during large programming courses.\nVizGroup leverages Large Language Models (LLMs) to recommend event\nspecifications for instructors so that they can simultaneously track and\nreceive alerts about key correlation patterns between various collaboration\nmetrics and ongoing coding tasks. We evaluated VizGroup with 12 instructors\nusing a dataset collected from a Peer Instruction activity that was conducted\nin a large programming lecture. The results showed that compared to a version\nof VizGroup without the suggested units, VizGroup with suggested units helped\ninstructors create additional monitoring units on previously undetected\npatterns on their own, covered a more diverse range of metrics, and influenced\nthe participants' following notification creation strategies.",
        "updated": "2024-04-12T18:10:40Z",
        "published": "2024-04-12T18:10:40Z",
        "authors": [
            "Xiaohang Tang",
            "Sam Wong",
            "Kevin Pu",
            "Xi Chen",
            "Yalong Yang",
            "Yan Chen"
        ],
        "categories": [
            "cs.HC"
        ],
        "primary_category": "cs.HC"
    },
    "2404.08744v1": {
        "url": "http://arxiv.org/abs/2404.08744v1",
        "title": "Routing and Spectrum Allocation in Broadband Quantum Entanglement\n  Distribution",
        "summary": "We investigate resource allocation for quantum entanglement distribution over\nan optical network. We characterize and model a network architecture that\nemploys a single quasi-deterministic time-frequency heralded\nEinstein-Podolsky-Rosen (EPR) pair source, and develop a routing scheme for\ndistributing entangled photon pairs over such a network. We focus on max-min\nfairness in entanglement distribution and compare the performance of various\nspectrum allocation schemes by examining the max-min and median number of\nEPR-pairs assigned by them, and the Jain index associated with this assignment.\nSince this presents an NP-hard problem, we identify two approximation\nalgorithms that outperform others in minimum and mean EPR-pair rate\ndistribution and are comparable to others in the Jain index. We also analyze\nhow the network size and connectivity affect these metrics using Watts-Strogatz\nrandom graphs. We find that a spectrum allocation approach that achieves high\nminimum EPR-pair rate can perform significantly worse when the median EPR-pair\nrate, Jain index, and runtimes are considered.",
        "updated": "2024-04-12T18:11:25Z",
        "published": "2024-04-12T18:11:25Z",
        "authors": [
            "Rohan Bali",
            "Ashley N. Tittelbaugh",
            "Shelbi L. Jenkins",
            "Anuj Agrawal",
            "Jerry Horgan",
            "Marco Ruffini",
            "Daniel C. Kilper",
            "Boulat A. Bash"
        ],
        "comments": "arXiv admin note: substantial text overlap with arXiv:2311.14613",
        "categories": [
            "cs.NI",
            "cs.ET",
            "quant-ph"
        ],
        "primary_category": "cs.NI"
    },
    "2404.08747v1": {
        "url": "http://arxiv.org/abs/2404.08747v1",
        "title": "Observation-specific explanations through scattered data approximation",
        "summary": "This work introduces the definition of observation-specific explanations to\nassign a score to each data point proportional to its importance in the\ndefinition of the prediction process. Such explanations involve the\nidentification of the most influential observations for the black-box model of\ninterest. The proposed method involves estimating these explanations by\nconstructing a surrogate model through scattered data approximation utilizing\nthe orthogonal matching pursuit algorithm. The proposed approach is validated\non both simulated and real-world datasets.",
        "updated": "2024-04-12T18:20:26Z",
        "published": "2024-04-12T18:20:26Z",
        "authors": [
            "Valentina Ghidini",
            "Michael Multerer",
            "Jacopo Quizi",
            "Rohan Sen"
        ],
        "categories": [
            "stat.ML",
            "cs.AI",
            "cs.LG",
            "cs.NA",
            "math.NA"
        ],
        "primary_category": "stat.ML"
    },
    "2404.09717v1": {
        "url": "http://arxiv.org/abs/2404.09717v1",
        "title": "Unveiling Imitation Learning: Exploring the Impact of Data Falsity to\n  Large Language Model",
        "summary": "Many recent studies endeavor to improve open-source language models through\nimitation learning, and re-training on the synthetic instruction data from\nstate-of-the-art proprietary models like ChatGPT and GPT-4. However, the innate\nnature of synthetic data inherently contains noisy data, giving rise to a\nsubstantial presence of low-quality data replete with erroneous responses, and\nflawed reasoning. Although we intuitively grasp the potential harm of noisy\ndata, we lack a quantitative understanding of its impact. To this end, this\npaper explores the correlation between the degree of noise and its impact on\nlanguage models through instruction tuning. We first introduce the\nFalsity-Controllable (FACO) dataset, which comprises pairs of true answers with\ncorresponding reasoning, as well as false pairs to manually control the falsity\nratio of the dataset.Through our extensive experiments, we found multiple\nintriguing findings of the correlation between the factuality of the dataset\nand instruction tuning: Specifically, we verified falsity of the instruction is\nhighly relevant to various benchmark scores. Moreover, when LLMs are trained\nwith false instructions, they learn to lie and generate fake unfaithful\nanswers, even though they know the correct answer for the user request.\nAdditionally, we noted that once the language model is trained with a dataset\ncontaminated by noise, restoring its original performance is possible, but it\nfailed to reach full performance.",
        "updated": "2024-04-15T12:20:09Z",
        "published": "2024-04-15T12:20:09Z",
        "authors": [
            "Hyunsoo Cho"
        ],
        "comments": "Under review @ *ACL",
        "categories": [
            "cs.CL",
            "cs.AI",
            "cs.LG"
        ],
        "primary_category": "cs.CL"
    },
    "2404.09722v1": {
        "url": "http://arxiv.org/abs/2404.09722v1",
        "title": "VFLGAN: Vertical Federated Learning-based Generative Adversarial Network\n  for Vertically Partitioned Data Publication",
        "summary": "In the current artificial intelligence (AI) era, the scale and quality of the\ndataset play a crucial role in training a high-quality AI model. However, good\ndata is not a free lunch and is always hard to access due to privacy\nregulations like the General Data Protection Regulation (GDPR). A potential\nsolution is to release a synthetic dataset with a similar distribution to that\nof the private dataset. Nevertheless, in some scenarios, it has been found that\nthe attributes needed to train an AI model belong to different parties, and\nthey cannot share the raw data for synthetic data publication due to privacy\nregulations. In PETS 2023, Xue et al. proposed the first generative adversary\nnetwork-based model, VertiGAN, for vertically partitioned data publication.\nHowever, after thoroughly investigating, we found that VertiGAN is less\neffective in preserving the correlation among the attributes of different\nparties. This article proposes a Vertical Federated Learning-based Generative\nAdversarial Network, VFLGAN, for vertically partitioned data publication to\naddress the above issues. Our experimental results show that compared with\nVertiGAN, VFLGAN significantly improves the quality of synthetic data. Taking\nthe MNIST dataset as an example, the quality of the synthetic dataset generated\nby VFLGAN is 3.2 times better than that generated by VertiGAN w.r.t. the\nFr\\'echet Distance. We also designed a more efficient and effective Gaussian\nmechanism for the proposed VFLGAN to provide the synthetic dataset with a\ndifferential privacy guarantee. On the other hand, differential privacy only\ngives the upper bound of the worst-case privacy guarantee. This article also\nproposes a practical auditing scheme that applies membership inference attacks\nto estimate privacy leakage through the synthetic dataset.",
        "updated": "2024-04-15T12:25:41Z",
        "published": "2024-04-15T12:25:41Z",
        "authors": [
            "Xun Yuan",
            "Yang Yang",
            "Prosanta Gope",
            "Aryan Pasikhani",
            "Biplab Sikdar"
        ],
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.CR"
        ],
        "primary_category": "cs.LG"
    },
    "2404.09724v1": {
        "url": "http://arxiv.org/abs/2404.09724v1",
        "title": "Privacy-Preserving Federated Unlearning with Certified Client Removal",
        "summary": "In recent years, Federated Unlearning (FU) has gained attention for\naddressing the removal of a client's influence from the global model in\nFederated Learning (FL) systems, thereby ensuring the ``right to be forgotten\"\n(RTBF). State-of-the-art methods for unlearning use historical data from FL\nclients, such as gradients or locally trained models. However, studies have\nrevealed significant information leakage in this setting, with the possibility\nof reconstructing a user's local data from their uploaded information.\nAddressing this, we propose Starfish, a privacy-preserving federated unlearning\nscheme using Two-Party Computation (2PC) techniques and shared historical\nclient data between two non-colluding servers. Starfish builds upon existing FU\nmethods to ensure privacy in unlearning processes. To enhance the efficiency of\nprivacy-preserving FU evaluations, we suggest 2PC-friendly alternatives for\ncertain FU algorithm operations. We also implement strategies to reduce costs\nassociated with 2PC operations and lessen cumulative approximation errors.\nMoreover, we establish a theoretical bound for the difference between the\nunlearned global model via Starfish and a global model retrained from scratch\nfor certified client removal. Our theoretical and experimental analyses\ndemonstrate that Starfish achieves effective unlearning with reasonable\nefficiency, maintaining privacy and security in FL systems.",
        "updated": "2024-04-15T12:27:07Z",
        "published": "2024-04-15T12:27:07Z",
        "authors": [
            "Ziyao Liu",
            "Huanyi Ye",
            "Yu Jiang",
            "Jiyuan Shen",
            "Jiale Guo",
            "Ivan Tjuawinata",
            "Kwok-Yan Lam"
        ],
        "categories": [
            "cs.CR"
        ],
        "primary_category": "cs.CR"
    },
    "2404.09729v1": {
        "url": "http://arxiv.org/abs/2404.09729v1",
        "title": "Amplitude-Phase Fusion for Enhanced Electrocardiogram Morphological\n  Analysis",
        "summary": "Considering the variability of amplitude and phase patterns in\nelectrocardiogram (ECG) signals due to cardiac activity and individual\ndifferences, existing entropy-based studies have not fully utilized these two\npatterns and lack integration. To address this gap, this paper proposes a novel\nfusion entropy metric, morphological ECG entropy (MEE) for the first time,\nspecifically designed for ECG morphology, to comprehensively describe the\nfusion of amplitude and phase patterns. MEE is computed based on beat-level\nsamples, enabling detailed analysis of each cardiac cycle. Experimental results\ndemonstrate that MEE achieves rapid, accurate, and label-free localization of\nabnormal ECG arrhythmia regions. Furthermore, MEE provides a method for\nassessing sample diversity, facilitating compression of imbalanced training\nsets (via representative sample selection), and outperforms random pruning.\nAdditionally, MEE exhibits the ability to describe areas of poor quality. By\ndiscussing, it proves the robustness of MEE value calculation to noise\ninterference and its low computational complexity. Finally, we integrate this\nmethod into a clinical interactive interface to provide a more convenient and\nintuitive user experience. These findings indicate that MEE serves as a\nvaluable clinical descriptor for ECG characterization. The implementation code\ncan be referenced at the following link:\nhttps://github.com/fdu-harry/ECG-MEE-metric.",
        "updated": "2024-04-15T12:29:16Z",
        "published": "2024-04-15T12:29:16Z",
        "authors": [
            "Shuaicong Hu",
            "Yanan Wang",
            "Jian Liu",
            "Jingyu Lin",
            "Shengmei Qin",
            "Zhenning Nie",
            "Zhifeng Yao",
            "Wenjie Cai",
            "Cuiwei Yang"
        ],
        "comments": "16 pages, 12 figures",
        "categories": [
            "eess.SP",
            "cs.IT",
            "cs.LG",
            "math.IT",
            "stat.ME",
            "I.5.2"
        ],
        "primary_category": "eess.SP"
    },
    "2404.09730v1": {
        "url": "http://arxiv.org/abs/2404.09730v1",
        "title": "Convergence Analysis of Probability Flow ODE for Score-based Generative\n  Models",
        "summary": "Score-based generative models have emerged as a powerful approach for\nsampling high-dimensional probability distributions. Despite their\neffectiveness, their theoretical underpinnings remain relatively\nunderdeveloped. In this work, we study the convergence properties of\ndeterministic samplers based on probability flow ODEs from both theoretical and\nnumerical perspectives. Assuming access to $L^2$-accurate estimates of the\nscore function, we prove the total variation between the target and the\ngenerated data distributions can be bounded above by\n$\\mathcal{O}(d\\sqrt{\\delta})$ in the continuous time level, where $d$ denotes\nthe data dimension and $\\delta$ represents the $L^2$-score matching error. For\npractical implementations using a $p$-th order Runge-Kutta integrator with step\nsize $h$, we establish error bounds of $\\mathcal{O}(d(\\sqrt{\\delta} + (dh)^p))$\nat the discrete level. Finally, we present numerical studies on problems up to\n$128$ dimensions to verify our theory, which indicate a better score matching\nerror and dimension dependence.",
        "updated": "2024-04-15T12:29:28Z",
        "published": "2024-04-15T12:29:28Z",
        "authors": [
            "Daniel Zhengyu Huang",
            "Jiaoyang Huang",
            "Zhengjiang Lin"
        ],
        "comments": "33 pages, 7 figures",
        "categories": [
            "cs.LG",
            "cs.NA",
            "math.CA",
            "math.NA"
        ],
        "primary_category": "cs.LG"
    },
    "2404.09732v1": {
        "url": "http://arxiv.org/abs/2404.09732v1",
        "title": "Photo-Realistic Image Restoration in the Wild with Controlled\n  Vision-Language Models",
        "summary": "Though diffusion models have been successfully applied to various image\nrestoration (IR) tasks, their performance is sensitive to the choice of\ntraining datasets. Typically, diffusion models trained in specific datasets\nfail to recover images that have out-of-distribution degradations. To address\nthis problem, this work leverages a capable vision-language model and a\nsynthetic degradation pipeline to learn image restoration in the wild (wild\nIR). More specifically, all low-quality images are simulated with a synthetic\ndegradation pipeline that contains multiple common degradations such as blur,\nresize, noise, and JPEG compression. Then we introduce robust training for a\ndegradation-aware CLIP model to extract enriched image content features to\nassist high-quality image restoration. Our base diffusion model is the image\nrestoration SDE (IR-SDE). Built upon it, we further present a posterior\nsampling strategy for fast noise-free image generation. We evaluate our model\non both synthetic and real-world degradation datasets. Moreover, experiments on\nthe unified image restoration task illustrate that the proposed posterior\nsampling improves image generation quality for various degradations.",
        "updated": "2024-04-15T12:34:21Z",
        "published": "2024-04-15T12:34:21Z",
        "authors": [
            "Ziwei Luo",
            "Fredrik K. Gustafsson",
            "Zheng Zhao",
            "Jens Sj\u00f6lund",
            "Thomas B. Sch\u00f6n"
        ],
        "comments": "CVPRW 2024; Code: https://github.com/Algolzw/daclip-uir",
        "categories": [
            "cs.CV"
        ],
        "primary_category": "cs.CV"
    },
    "2404.09734v1": {
        "url": "http://arxiv.org/abs/2404.09734v1",
        "title": "Weighted Sum-Rate Maximization for Movable Antenna-Enhanced Wireless\n  Networks",
        "summary": "This letter investigates the weighted sum rate maximization problem in\nmovable antenna (MA)-enhanced systems. To reduce the computational complexity,\nwe transform it into a more tractable weighted minimum mean square error\n(WMMSE) problem well-suited for MA. We then adopt the WMMSE algorithm and\nmajorization-minimization algorithm to optimize the beamforming and antenna\npositions, respectively. Moreover, we propose a planar movement mode, which\nconstrains each MA to a specified area, we obtain a low-complexity closed-form\nsolution. Numerical results demonstrate that the MA-enhanced system outperforms\nthe conventional system. Besides, the computation time for the planar movement\nmode is reduced by approximately 30\\% at a little performance expense.",
        "updated": "2024-04-15T12:34:51Z",
        "published": "2024-04-15T12:34:51Z",
        "authors": [
            "Biqian Feng",
            "Yongpeng Wu",
            "Xiang-Gen Xia",
            "Chengshan Xiao"
        ],
        "comments": "Accepted by IEEE Wireless Communications Letters",
        "categories": [
            "cs.IT",
            "eess.SP",
            "math.IT"
        ],
        "primary_category": "cs.IT"
    },
    "2404.09735v1": {
        "url": "http://arxiv.org/abs/2404.09735v1",
        "title": "Equipping Diffusion Models with Differentiable Spatial Entropy for\n  Low-Light Image Enhancement",
        "summary": "Image restoration, which aims to recover high-quality images from their\ncorrupted counterparts, often faces the challenge of being an ill-posed problem\nthat allows multiple solutions for a single input. However, most deep learning\nbased works simply employ l1 loss to train their network in a deterministic\nway, resulting in over-smoothed predictions with inferior perceptual quality.\nIn this work, we propose a novel method that shifts the focus from a\ndeterministic pixel-by-pixel comparison to a statistical perspective,\nemphasizing the learning of distributions rather than individual pixel values.\nThe core idea is to introduce spatial entropy into the loss function to measure\nthe distribution difference between predictions and targets. To make this\nspatial entropy differentiable, we employ kernel density estimation (KDE) to\napproximate the probabilities for specific intensity values of each pixel with\ntheir neighbor areas. Specifically, we equip the entropy with diffusion models\nand aim for superior accuracy and enhanced perceptual quality over l1 based\nnoise matching loss. In the experiments, we evaluate the proposed method for\nlow light enhancement on two datasets and the NTIRE challenge 2024. All these\nresults illustrate the effectiveness of our statistic-based entropy loss. Code\nis available at https://github.com/shermanlian/spatial-entropy-loss.",
        "updated": "2024-04-15T12:35:10Z",
        "published": "2024-04-15T12:35:10Z",
        "authors": [
            "Wenyi Lian",
            "Wenjing Lian",
            "Ziwei Luo"
        ],
        "comments": "CVPRW 2024, best LPIPS in the NTIRE low light enhancement challenge\n  2024",
        "categories": [
            "cs.CV"
        ],
        "primary_category": "cs.CV"
    },
    "2404.09736v1": {
        "url": "http://arxiv.org/abs/2404.09736v1",
        "title": "FSRT: Facial Scene Representation Transformer for Face Reenactment from\n  Factorized Appearance, Head-pose, and Facial Expression Features",
        "summary": "The task of face reenactment is to transfer the head motion and facial\nexpressions from a driving video to the appearance of a source image, which may\nbe of a different person (cross-reenactment). Most existing methods are\nCNN-based and estimate optical flow from the source image to the current\ndriving frame, which is then inpainted and refined to produce the output\nanimation. We propose a transformer-based encoder for computing a set-latent\nrepresentation of the source image(s). We then predict the output color of a\nquery pixel using a transformer-based decoder, which is conditioned with\nkeypoints and a facial expression vector extracted from the driving frame.\nLatent representations of the source person are learned in a self-supervised\nmanner that factorize their appearance, head pose, and facial expressions.\nThus, they are perfectly suited for cross-reenactment. In contrast to most\nrelated work, our method naturally extends to multiple source images and can\nthus adapt to person-specific facial dynamics. We also propose data\naugmentation and regularization schemes that are necessary to prevent\noverfitting and support generalizability of the learned representations. We\nevaluated our approach in a randomized user study. The results indicate\nsuperior performance compared to the state-of-the-art in terms of motion\ntransfer quality and temporal consistency.",
        "updated": "2024-04-15T12:37:26Z",
        "published": "2024-04-15T12:37:26Z",
        "authors": [
            "Andre Rochow",
            "Max Schwarz",
            "Sven Behnke"
        ],
        "comments": "Accepted to CVPR 2024",
        "categories": [
            "cs.CV"
        ],
        "primary_category": "cs.CV"
    },
    "2404.09737v1": {
        "url": "http://arxiv.org/abs/2404.09737v1",
        "title": "Quantization of Large Language Models with an Overdetermined Basis",
        "summary": "In this paper, we introduce an algorithm for data quantization based on the\nprinciples of Kashin representation. This approach hinges on decomposing any\ngiven vector, matrix, or tensor into two factors. The first factor maintains a\nsmall infinity norm, while the second exhibits a similarly constrained norm\nwhen multiplied by an orthogonal matrix. Surprisingly, the entries of factors\nafter decomposition are well-concentrated around several peaks, which allows us\nto efficiently replace them with corresponding centroids for quantization\npurposes. We study the theoretical properties of the proposed approach and\nrigorously evaluate our compression algorithm in the context of next-word\nprediction tasks and on a set of downstream tasks for text classification. Our\nfindings demonstrate that Kashin Quantization achieves competitive or superior\nquality in model performance while ensuring data compression, marking a\nsignificant advancement in the field of data quantization.",
        "updated": "2024-04-15T12:38:46Z",
        "published": "2024-04-15T12:38:46Z",
        "authors": [
            "Daniil Merkulov",
            "Daria Cherniuk",
            "Alexander Rudikov",
            "Ivan Oseledets",
            "Ekaterina Muravleva",
            "Aleksandr Mikhalev",
            "Boris Kashin"
        ],
        "categories": [
            "cs.LG",
            "cs.CL"
        ],
        "primary_category": "cs.LG"
    },
    "2404.10717v1": {
        "url": "http://arxiv.org/abs/2404.10717v1",
        "title": "Mixed Prototype Consistency Learning for Semi-supervised Medical Image\n  Segmentation",
        "summary": "Recently, prototype learning has emerged in semi-supervised medical image\nsegmentation and achieved remarkable performance. However, the scarcity of\nlabeled data limits the expressiveness of prototypes in previous methods,\npotentially hindering the complete representation of prototypes for class\nembedding. To address this problem, we propose the Mixed Prototype Consistency\nLearning (MPCL) framework, which includes a Mean Teacher and an auxiliary\nnetwork. The Mean Teacher generates prototypes for labeled and unlabeled data,\nwhile the auxiliary network produces additional prototypes for mixed data\nprocessed by CutMix. Through prototype fusion, mixed prototypes provide extra\nsemantic information to both labeled and unlabeled prototypes. High-quality\nglobal prototypes for each class are formed by fusing two enhanced prototypes,\noptimizing the distribution of hidden embeddings used in consistency learning.\nExtensive experiments on the left atrium and type B aortic dissection datasets\ndemonstrate MPCL's superiority over previous state-of-the-art approaches,\nconfirming the effectiveness of our framework. The code will be released soon.",
        "updated": "2024-04-16T16:51:12Z",
        "published": "2024-04-16T16:51:12Z",
        "authors": [
            "Lijian Li"
        ],
        "comments": "15 pages, 2 figures",
        "categories": [
            "cs.CV",
            "cs.AI"
        ],
        "primary_category": "cs.CV"
    },
    "2404.10718v2": {
        "url": "http://arxiv.org/abs/2404.10718v2",
        "title": "GazeHTA: End-to-end Gaze Target Detection with Head-Target Association",
        "summary": "We propose an end-to-end approach for gaze target detection: predicting a\nhead-target connection between individuals and the target image regions they\nare looking at. Most of the existing methods use independent components such as\noff-the-shelf head detectors or have problems in establishing associations\nbetween heads and gaze targets. In contrast, we investigate an end-to-end\nmulti-person Gaze target detection framework with Heads and Targets Association\n(GazeHTA), which predicts multiple head-target instances based solely on input\nscene image. GazeHTA addresses challenges in gaze target detection by (1)\nleveraging a pre-trained diffusion model to extract scene features for rich\nsemantic understanding, (2) re-injecting a head feature to enhance the head\npriors for improved head understanding, and (3) learning a connection map as\nthe explicit visual associations between heads and gaze targets. Our extensive\nexperimental results demonstrate that GazeHTA outperforms state-of-the-art gaze\ntarget detection methods and two adapted diffusion-based baselines on two\nstandard datasets.",
        "updated": "2024-04-19T01:19:25Z",
        "published": "2024-04-16T16:51:27Z",
        "authors": [
            "Zhi-Yi Lin",
            "Jouh Yeong Chew",
            "Jan van Gemert",
            "Xucong Zhang"
        ],
        "categories": [
            "cs.CV"
        ],
        "primary_category": "cs.CV"
    },
    "2404.10719v2": {
        "url": "http://arxiv.org/abs/2404.10719v2",
        "title": "Is DPO Superior to PPO for LLM Alignment? A Comprehensive Study",
        "summary": "Reinforcement Learning from Human Feedback (RLHF) is currently the most\nwidely used method to align large language models (LLMs) with human\npreferences. Existing RLHF methods can be roughly categorized as either\nreward-based or reward-free. Novel applications such as ChatGPT and Claude\nleverage reward-based methods that first learn a reward model and apply\nactor-critic algorithms, such as Proximal Policy Optimization (PPO). However,\nin academic benchmarks, state-of-the-art results are often achieved via\nreward-free methods, such as Direct Preference Optimization (DPO). Is DPO truly\nsuperior to PPO? Why does PPO perform poorly on these benchmarks? In this\npaper, we first conduct both theoretical and empirical studies on the\nalgorithmic properties of DPO and show that DPO may have fundamental\nlimitations. Moreover, we also comprehensively examine PPO and reveal the key\nfactors for the best performances of PPO in fine-tuning LLMs. Finally, we\nbenchmark DPO and PPO across a collection of RLHF testbeds, ranging from\ndialogue to code generation. Experiment results demonstrate that PPO is able to\nsurpass other alignment methods in all cases and achieve state-of-the-art\nresults in challenging code competitions.",
        "updated": "2024-04-21T11:58:54Z",
        "published": "2024-04-16T16:51:53Z",
        "authors": [
            "Shusheng Xu",
            "Wei Fu",
            "Jiaxuan Gao",
            "Wenjie Ye",
            "Weilin Liu",
            "Zhiyu Mei",
            "Guangju Wang",
            "Chao Yu",
            "Yi Wu"
        ],
        "comments": "16 pages, 2 figures, 14 tables",
        "categories": [
            "cs.CL"
        ],
        "primary_category": "cs.CL"
    },
    "2404.10726v1": {
        "url": "http://arxiv.org/abs/2404.10726v1",
        "title": "Automatic re-calibration of quantum devices by reinforcement learning",
        "summary": "During their operation, due to shifts in environmental conditions, devices\nundergo various forms of detuning from their optimal settings. Typically, this\nis addressed through control loops, which monitor variables and the device\nperformance, to maintain settings at their optimal values. Quantum devices are\nparticularly challenging since their functionality relies on precisely tuning\ntheir parameters. At the same time, the detailed modeling of the environmental\nbehavior is often computationally unaffordable, while a direct measure of the\nparameters defining the system state is costly and introduces extra noise in\nthe mechanism. In this study, we investigate the application of reinforcement\nlearning techniques to develop a model-free control loop for continuous\nrecalibration of quantum device parameters. Furthermore, we explore the\nadvantages of incorporating minimal environmental noise models. As an example,\nthe application to numerical simulations of a Kennedy receiver-based\nlong-distance quantum communication protocol is presented.",
        "updated": "2024-04-16T16:59:50Z",
        "published": "2024-04-16T16:59:50Z",
        "authors": [
            "T. Crosta",
            "L. Reb\u00f3n",
            "F. Vilari\u00f1o",
            "J. M. Matera",
            "M. Bilkis"
        ],
        "categories": [
            "quant-ph",
            "cs.LG"
        ],
        "primary_category": "quant-ph"
    },
    "2404.10728v1": {
        "url": "http://arxiv.org/abs/2404.10728v1",
        "title": "Randomized Exploration in Cooperative Multi-Agent Reinforcement Learning",
        "summary": "We present the first study on provably efficient randomized exploration in\ncooperative multi-agent reinforcement learning (MARL). We propose a unified\nalgorithm framework for randomized exploration in parallel Markov Decision\nProcesses (MDPs), and two Thompson Sampling (TS)-type algorithms, CoopTS-PHE\nand CoopTS-LMC, incorporating the perturbed-history exploration (PHE) strategy\nand the Langevin Monte Carlo exploration (LMC) strategy respectively, which are\nflexible in design and easy to implement in practice. For a special class of\nparallel MDPs where the transition is (approximately) linear, we theoretically\nprove that both CoopTS-PHE and CoopTS-LMC achieve a\n$\\widetilde{\\mathcal{O}}(d^{3/2}H^2\\sqrt{MK})$ regret bound with communication\ncomplexity $\\widetilde{\\mathcal{O}}(dHM^2)$, where $d$ is the feature\ndimension, $H$ is the horizon length, $M$ is the number of agents, and $K$ is\nthe number of episodes. This is the first theoretical result for randomized\nexploration in cooperative MARL. We evaluate our proposed method on multiple\nparallel RL environments, including a deep exploration problem (\\textit{i.e.,}\n$N$-chain), a video game, and a real-world problem in energy systems. Our\nexperimental results support that our framework can achieve better performance,\neven under conditions of misspecified transition models. Additionally, we\nestablish a connection between our unified framework and the practical\napplication of federated learning.",
        "updated": "2024-04-16T17:01:38Z",
        "published": "2024-04-16T17:01:38Z",
        "authors": [
            "Hao-Lun Hsu",
            "Weixin Wang",
            "Miroslav Pajic",
            "Pan Xu"
        ],
        "comments": "80 pages, 14 figures, 1 table. Hao-Lun Hsu and Weixin Wang\n  contributed equally to this work",
        "categories": [
            "cs.LG",
            "stat.ML"
        ],
        "primary_category": "cs.LG"
    },
    "2404.10730v1": {
        "url": "http://arxiv.org/abs/2404.10730v1",
        "title": "Insight Gained from Migrating a Machine Learning Model to Intelligence\n  Processing Units",
        "summary": "The discoveries in this paper show that Intelligence Processing Units (IPUs)\noffer a viable accelerator alternative to GPUs for machine learning (ML)\napplications within the fields of materials science and battery research. We\ninvestigate the process of migrating a model from GPU to IPU and explore\nseveral optimization techniques, including pipelining and gradient\naccumulation, aimed at enhancing the performance of IPU-based models.\nFurthermore, we have effectively migrated a specialized model to the IPU\nplatform. This model is employed for predicting effective conductivity, a\nparameter crucial in ion transport processes, which govern the performance of\nmultiple charge and discharge cycles of batteries. The model utilizes a\nConvolutional Neural Network (CNN) architecture to perform prediction tasks for\neffective conductivity. The performance of this model on the IPU is found to be\ncomparable to its execution on GPUs. We also analyze the utilization and\nperformance of Graphcore's Bow IPU. Through benchmark tests, we observe\nsignificantly improved performance with the Bow IPU when compared to its\npredecessor, the Colossus IPU.",
        "updated": "2024-04-16T17:02:52Z",
        "published": "2024-04-16T17:02:52Z",
        "authors": [
            "Hieu Le",
            "Zhenhua He",
            "Mai Le",
            "Dhruva K. Chakravorty",
            "Lisa M. Perez",
            "Akhil Chilumuru",
            "Yan Yao",
            "Jiefu Chen"
        ],
        "comments": "arXiv admin note: This version has been removed by arXiv\n  administrators as the submitter did not have the right to agree to the\n  license at the time of submission",
        "categories": [
            "cs.LG",
            "cs.AI"
        ],
        "primary_category": "cs.LG"
    },
    "2404.10731v1": {
        "url": "http://arxiv.org/abs/2404.10731v1",
        "title": "What is Meant by AGI? On the Definition of Artificial General\n  Intelligence",
        "summary": "This paper aims to establish a consensus on AGI's definition. General\nintelligence refers to the adaptation to open environments according to certain\nprinciples using limited resources. It emphasizes that adaptation or learning\nis an indispensable property of intelligence, and places the controversial part\nwithin the principles of intelligence, which can be described from different\nperspectives.",
        "updated": "2024-04-16T17:03:50Z",
        "published": "2024-04-16T17:03:50Z",
        "authors": [
            "Bowen Xu"
        ],
        "categories": [
            "cs.AI"
        ],
        "primary_category": "cs.AI"
    },
    "2404.10732v1": {
        "url": "http://arxiv.org/abs/2404.10732v1",
        "title": "Attention-Aware Visualization: Tracking and Responding to User\n  Perception Over Time",
        "summary": "We propose the notion of Attention-Aware Visualizations (AAVs) that track the\nuser's perception of a visual representation over time and feed this\ninformation back to the visualization. Such context awareness is particularly\nuseful for ubiquitous and immersive analytics where knowing which embedded\nvisualizations the user is looking at can be used to make visualizations react\nappropriately to the user's attention: for example, by highlighting data the\nuser has not yet seen. We can separate the approach into three components: (1)\nmeasuring the user's gaze on a visualization and its parts; (2) tracking the\nuser's attention over time; and (3) reactively modifying the visual\nrepresentation based on the current attention metric. In this paper, we present\ntwo separate implementations of AAV: a 2D data-agnostic method for web-based\nvisualizations that can use an embodied eyetracker to capture the user's gaze,\nand a 3D data-aware one that uses the stencil buffer to track the visibility of\neach individual mark in a visualization. Both methods provide similar\nmechanisms for accumulating attention over time and changing the appearance of\nmarks in response. We also present results from a qualitative evaluation\nstudying visual feedback and triggering mechanisms for capturing and\nrevisualizing attention.",
        "updated": "2024-04-16T17:04:32Z",
        "published": "2024-04-16T17:04:32Z",
        "authors": [
            "Arvind Srinivasan",
            "Johannes Ellemose",
            "Peter W. S. Butcher",
            "Panagiotis D. Ritsos",
            "Niklas Elmqvist"
        ],
        "categories": [
            "cs.HC"
        ],
        "primary_category": "cs.HC"
    },
    "2404.10733v1": {
        "url": "http://arxiv.org/abs/2404.10733v1",
        "title": "Bootstrapping Linear Models for Fast Online Adaptation in Human-Agent\n  Collaboration",
        "summary": "Agents that assist people need to have well-initialized policies that can\nadapt quickly to align with their partners' reward functions. Initializing\npolicies to maximize performance with unknown partners can be achieved by\nbootstrapping nonlinear models using imitation learning over large, offline\ndatasets. Such policies can require prohibitive computation to fine-tune\nin-situ and therefore may miss critical run-time information about a partner's\nreward function as expressed through their immediate behavior. In contrast,\nonline logistic regression using low-capacity models performs rapid inference\nand fine-tuning updates and thus can make effective use of immediate in-task\nbehavior for reward function alignment. However, these low-capacity models\ncannot be bootstrapped as effectively by offline datasets and thus have poor\ninitializations. We propose BLR-HAC, Bootstrapped Logistic Regression for Human\nAgent Collaboration, which bootstraps large nonlinear models to learn the\nparameters of a low-capacity model which then uses online logistic regression\nfor updates during collaboration. We test BLR-HAC in a simulated surface\nrearrangement task and demonstrate that it achieves higher zero-shot accuracy\nthan shallow methods and takes far less computation to adapt online while still\nachieving similar performance to fine-tuned, large nonlinear models. For code,\nplease see our project page https://sites.google.com/view/blr-hac.",
        "updated": "2024-04-16T17:05:43Z",
        "published": "2024-04-16T17:05:43Z",
        "authors": [
            "Benjamin A Newman",
            "Chris Paxton",
            "Kris Kitani",
            "Henny Admoni"
        ],
        "comments": "10 pages, 4 figures, Accepted to AAMAS 2024",
        "categories": [
            "cs.AI",
            "cs.HC",
            "cs.RO"
        ],
        "primary_category": "cs.AI"
    },
    "2404.10734v1": {
        "url": "http://arxiv.org/abs/2404.10734v1",
        "title": "SPONGE: Open-Source Designs of Modular Articulated Soft Robots",
        "summary": "Soft-robot designs are manifold, but only a few are publicly available.\nOften, these are only briefly described in their publications. This complicates\nreproduction, and hinders the reproducibility and comparability of research\nresults. If the designs were uniform and open source, validating researched\nmethods on real benchmark systems would be possible. To address this, we\npresent two variants of a soft pneumatic robot with antagonistic bellows as\nopen source. Starting from a semi-modular design with multiple cables and tubes\nrouted through the robot body, the transition to a fully modular robot with\nintegrated microvalves and serial communication is highlighted. Modularity in\nterms of stackability, actuation, and communication is achieved, which is the\ncrucial requirement for building soft robots with many degrees of freedom and\nhigh dexterity for real-world tasks. Both systems are compared regarding their\nrespective advantages and disadvantages. The robots' functionality is\ndemonstrated in experiments on airtightness, gravitational influence, position\ncontrol with mean tracking errors of <3 deg, and long-term operation of cast\nand printed bellows. All soft- and hardware files required for reproduction are\nprovided.",
        "updated": "2024-04-16T17:06:40Z",
        "published": "2024-04-16T17:06:40Z",
        "authors": [
            "Tim-Lukas Habich",
            "Jonas Haack",
            "Mehdi Belhadj",
            "Dustin Lehmann",
            "Thomas Seel",
            "Moritz Schappler"
        ],
        "comments": "Accepted for publication in IEEE Robotics and Automation Letters\n  (RA-L) 2024",
        "categories": [
            "cs.RO"
        ],
        "primary_category": "cs.RO",
        "doi": "10.1109/LRA.2024.3388855"
    },
    "2404.11833v1": {
        "url": "http://arxiv.org/abs/2404.11833v1",
        "title": "Planning with Language Models Through The Lens of Efficiency",
        "summary": "We analyse the cost of using LLMs for planning and highlight that recent\ntrends are profoundly uneconomical. We propose a significantly more efficient\napproach and argue for a responsible use of compute resources; urging research\ncommunity to investigate LLM-based approaches that upholds efficiency.",
        "updated": "2024-04-18T01:27:29Z",
        "published": "2024-04-18T01:27:29Z",
        "authors": [
            "Michael Katz",
            "Harsha Kokel",
            "Kavitha Srinivas",
            "Shirin Sohrabi"
        ],
        "categories": [
            "cs.AI"
        ],
        "primary_category": "cs.AI"
    },
    "2404.11834v1": {
        "url": "http://arxiv.org/abs/2404.11834v1",
        "title": "Actor-Critic Reinforcement Learning with Phased Actor",
        "summary": "Policy gradient methods in actor-critic reinforcement learning (RL) have\nbecome perhaps the most promising approaches to solving continuous optimal\ncontrol problems. However, the trial-and-error nature of RL and the inherent\nrandomness associated with solution approximations cause variations in the\nlearned optimal values and policies. This has significantly hindered their\nsuccessful deployment in real life applications where control responses need to\nmeet dynamic performance criteria deterministically. Here we propose a novel\nphased actor in actor-critic (PAAC) method, aiming at improving policy gradient\nestimation and thus the quality of the control policy. Specifically, PAAC\naccounts for both $Q$ value and TD error in its actor update. We prove\nqualitative properties of PAAC for learning convergence of the value and\npolicy, solution optimality, and stability of system dynamics. Additionally, we\nshow variance reduction in policy gradient estimation. PAAC performance is\nsystematically and quantitatively evaluated in this study using DeepMind\nControl Suite (DMC). Results show that PAAC leads to significant performance\nimprovement measured by total cost, learning variance, robustness, learning\nspeed and success rate. As PAAC can be piggybacked onto general policy gradient\nlearning frameworks, we select well-known methods such as direct heuristic\ndynamic programming (dHDP), deep deterministic policy gradient (DDPG) and their\nvariants to demonstrate the effectiveness of PAAC. Consequently we provide a\nunified view on these related policy gradient algorithms.",
        "updated": "2024-04-18T01:27:31Z",
        "published": "2024-04-18T01:27:31Z",
        "authors": [
            "Ruofan Wu",
            "Junmin Zhong",
            "Jennie Si"
        ],
        "categories": [
            "cs.LG"
        ],
        "primary_category": "cs.LG"
    },
    "2404.11841v1": {
        "url": "http://arxiv.org/abs/2404.11841v1",
        "title": "On the Unprovability of Circuit Size Bounds in Intuitionistic\n  $\\mathsf{S}^1_2$",
        "summary": "We show that there is a constant $k$ such that Buss's intuitionistic theory\n$\\mathsf{IS}^1_2$ does not prove that SAT requires co-nondeterministic circuits\nof size at least $n^k$. To our knowledge, this is the first unconditional\nunprovability result in bounded arithmetic in the context of worst-case\nfixed-polynomial size circuit lower bounds. We complement this result by\nshowing that the upper bound $\\mathsf{NP} \\subseteq \\mathsf{coNSIZE}[n^k]$ is\nunprovable in $\\mathsf{IS}^1_2$.",
        "updated": "2024-04-18T01:45:22Z",
        "published": "2024-04-18T01:45:22Z",
        "authors": [
            "Lijie Chen",
            "Jiatu Li",
            "Igor C. Oliveira"
        ],
        "categories": [
            "cs.LO",
            "cs.CC",
            "68Q99 (Primary), 03F55 03F30 (Secondary)",
            "F.4.1; F.1.3"
        ],
        "primary_category": "cs.LO"
    },
    "2404.11843v2": {
        "url": "http://arxiv.org/abs/2404.11843v2",
        "title": "Computer-Aided Diagnosis of Thoracic Diseases in Chest X-rays using\n  hybrid CNN-Transformer Architecture",
        "summary": "Medical imaging has been used for diagnosis of various conditions, making it\none of the most powerful resources for effective patient care. Due to\nwidespread availability, low cost, and low radiation, chest X-ray is one of the\nmost sought after radiology examination for the diagnosis of various thoracic\ndiseases. Due to advancements in medical imaging technologies and increasing\npatient load, current radiology workflow faces various challenges including\nincreasing backlogs, working long hours, and increase in diagnostic errors. An\nautomated computer-aided diagnosis system that can interpret chest X-rays to\naugment radiologists by providing actionable insights has potential to provide\nsecond opinion to radiologists, highlight relevant regions in the image, in\nturn expediting clinical workflow, reducing diagnostic errors, and improving\npatient care. In this study, we applied a novel architecture augmenting the\nDenseNet121 Convolutional Neural Network (CNN) with multi-head self-attention\nmechanism using transformer, namely SA-DenseNet121, that can identify multiple\nthoracic diseases in chest X-rays. We conducted experiments on four of the\nlargest chest X-ray datasets, namely, ChestX-ray14, CheXpert, MIMIC-CXR-JPG,\nand IU-CXR. Experimental results in terms of area under the receiver operating\ncharacteristics (AUC-ROC) shows that augmenting CNN with self-attention has\npotential in diagnosing different thoracic diseases from chest X-rays. The\nproposed methodology has the potential to support the reading workflow, improve\nefficiency, and reduce diagnostic errors.",
        "updated": "2024-04-19T01:45:02Z",
        "published": "2024-04-18T01:46:31Z",
        "authors": [
            "Sonit Singh"
        ],
        "comments": "24 pages, 13 Figures, 13 Tables. This article heavily draws from\n  arXiv:1904.09925 where authors originally proposed attention-augmented\n  convolutional network. arXiv admin note: text overlap with arXiv:1904.09925\n  by other authors",
        "categories": [
            "eess.IV",
            "cs.CV",
            "cs.LG"
        ],
        "primary_category": "eess.IV"
    },
    "2404.11844v1": {
        "url": "http://arxiv.org/abs/2404.11844v1",
        "title": "Finding A Taxi with Illegal Driver Substitution Activity via Behavior\n  Modelings",
        "summary": "In our urban life, Illegal Driver Substitution (IDS) activity for a taxi is a\ngrave unlawful activity in the taxi industry, possibly causing severe traffic\naccidents and painful social repercussions. Currently, the IDS activity is\nmanually supervised by law enforcers, i.e., law enforcers empirically choose a\ntaxi and inspect it. The pressing problem of this scheme is the dilemma between\nthe limited number of law-enforcers and the large volume of taxis. In this\npaper, motivated by this problem, we propose a computational method that helps\nlaw enforcers efficiently find the taxis which tend to have the IDS activity.\nFirstly, our method converts the identification of the IDS activity to a\nsupervised learning task. Secondly, two kinds of taxi driver behaviors, i.e.,\nthe Sleeping Time and Location (STL) behavior and the Pick-Up (PU) behavior are\nproposed. Thirdly, the multiple scale pooling on self-similarity is proposed to\nencode the individual behaviors into the universal features for all taxis.\nFinally, a Multiple Component- Multiple Instance Learning (MC-MIL) method is\nproposed to handle the deficiency of the behavior features and to align the\nbehavior features simultaneously. Extensive experiments on a real-world data\nset shows that the proposed behavior features have a good generalization\nability across different classifiers, and the proposed MC-MIL method suppresses\nthe baseline methods.",
        "updated": "2024-04-18T01:47:31Z",
        "published": "2024-04-18T01:47:31Z",
        "authors": [
            "Junbiao Pang",
            "Muhammad Ayub Sabir",
            "Zhuyun Wang",
            "Anjing Hu",
            "Xue Yang",
            "Haitao Yu",
            "Qingming Huang"
        ],
        "categories": [
            "cs.CY"
        ],
        "primary_category": "cs.CY"
    },
    "2404.11845v1": {
        "url": "http://arxiv.org/abs/2404.11845v1",
        "title": "Challenging Negative Gender Stereotypes: A Study on the Effectiveness of\n  Automated Counter-Stereotypes",
        "summary": "Gender stereotypes are pervasive beliefs about individuals based on their\ngender that play a significant role in shaping societal attitudes, behaviours,\nand even opportunities. Recognizing the negative implications of gender\nstereotypes, particularly in online communications, this study investigates\neleven strategies to automatically counter-act and challenge these views. We\npresent AI-generated gender-based counter-stereotypes to (self-identified) male\nand female study participants and ask them to assess their offensiveness,\nplausibility, and potential effectiveness. The strategies of counter-facts and\nbroadening universals (i.e., stating that anyone can have a trait regardless of\ngroup membership) emerged as the most robust approaches, while humour,\nperspective-taking, counter-examples, and empathy for the speaker were\nperceived as less effective. Also, the differences in ratings were more\npronounced for stereotypes about the different targets than between the genders\nof the raters. Alarmingly, many AI-generated counter-stereotypes were perceived\nas offensive and/or implausible. Our analysis and the collected dataset offer\nfoundational insight into counter-stereotype generation, guiding future efforts\nto develop strategies that effectively challenge gender stereotypes in online\ninteractions.",
        "updated": "2024-04-18T01:48:28Z",
        "published": "2024-04-18T01:48:28Z",
        "authors": [
            "Isar Nejadgholi",
            "Kathleen C. Fraser",
            "Anna Kerkhof",
            "Svetlana Kiritchenko"
        ],
        "comments": "LREC-COLING2024",
        "categories": [
            "cs.CL",
            "cs.CY"
        ],
        "primary_category": "cs.CL"
    },
    "2404.11848v1": {
        "url": "http://arxiv.org/abs/2404.11848v1",
        "title": "Partial Large Kernel CNNs for Efficient Super-Resolution",
        "summary": "Recently, in the super-resolution (SR) domain, transformers have outperformed\nCNNs with fewer FLOPs and fewer parameters since they can deal with long-range\ndependency and adaptively adjust weights based on instance. In this paper, we\ndemonstrate that CNNs, although less focused on in the current SR domain,\nsurpass Transformers in direct efficiency measures. By incorporating the\nadvantages of Transformers into CNNs, we aim to achieve both computational\nefficiency and enhanced performance. However, using a large kernel in the SR\ndomain, which mainly processes large images, incurs a large computational\noverhead. To overcome this, we propose novel approaches to employing the large\nkernel, which can reduce latency by 86\\% compared to the naive large kernel,\nand leverage an Element-wise Attention module to imitate instance-dependent\nweights. As a result, we introduce Partial Large Kernel CNNs for Efficient\nSuper-Resolution (PLKSR), which achieves state-of-the-art performance on four\ndatasets at a scale of $\\times$4, with reductions of 68.1\\% in latency and\n80.2\\% in maximum GPU memory occupancy compared to SRFormer-light.",
        "updated": "2024-04-18T01:55:44Z",
        "published": "2024-04-18T01:55:44Z",
        "authors": [
            "Dongheon Lee",
            "Seokju Yun",
            "Youngmin Ro"
        ],
        "categories": [
            "cs.CV"
        ],
        "primary_category": "cs.CV"
    },
    "2404.11852v1": {
        "url": "http://arxiv.org/abs/2404.11852v1",
        "title": "Cicero: Addressing Algorithmic and Architectural Bottlenecks in Neural\n  Rendering by Radiance Warping and Memory Optimizations",
        "summary": "Neural Radiance Field (NeRF) is widely seen as an alternative to traditional\nphysically-based rendering. However, NeRF has not yet seen its adoption in\nresource-limited mobile systems such as Virtual and Augmented Reality (VR/AR),\nbecause it is simply extremely slow. On a mobile Volta GPU, even the\nstate-of-the-art NeRF models generally execute only at 0.8 FPS. We show that\nthe main performance bottlenecks are both algorithmic and architectural. We\nintroduce, CICERO, to tame both forms of inefficiencies. We first introduce two\nalgorithms, one fundamentally reduces the amount of work any NeRF model has to\nexecute, and the other eliminates irregular DRAM accesses. We then describe an\non-chip data layout strategy that eliminates SRAM bank conflicts. A pure\nsoftware implementation of CICERO offers an 8.0x speed-up and 7.9x energy\nsaving over a mobile Volta GPU. When compared to a baseline with a dedicated\nDNN accelerator, our speed-up and energy reduction increase to 28.2x and 37.8x,\nrespectively - all with minimal quality loss (less than 1.0 dB peak\nsignal-to-noise ratio reduction).",
        "updated": "2024-04-18T02:08:57Z",
        "published": "2024-04-18T02:08:57Z",
        "authors": [
            "Yu Feng",
            "Zihan Liu",
            "Jingwen Leng",
            "Minyi Guo",
            "Yuhao Zhu"
        ],
        "categories": [
            "cs.AR",
            "cs.GR"
        ],
        "primary_category": "cs.AR"
    },
    "2404.11853v1": {
        "url": "http://arxiv.org/abs/2404.11853v1",
        "title": "Oracle-Augmented Prophet Inequalities",
        "summary": "In the classical prophet inequality settings, a gambler is given a sequence\nof $n$ random variables $X_1, \\dots, X_n$, taken from known distributions,\nobserves their values in this (potentially adversarial) order, and select one\nof them, immediately after it is being observed, so that its value is as high\nas possible. The classical \\emph{prophet inequality} shows a strategy that\nguarantees a value at least half of that an omniscience prophet that picks the\nmaximum, and this ratio is optimal.\n  Here, we generalize the prophet inequality, allowing the gambler some\nadditional information about the future that is otherwise privy only to the\nprophet. Specifically, at any point in the process, the gambler is allowed to\nquery an oracle $\\mathcal{O}$. The oracle responds with a single bit answer:\nYES if the current realization is greater than the remaining realizations, and\nNO otherwise. We show that the oracle model with $m$ oracle calls is equivalent\nto the \\textsc{Top-$1$-of-$(m+1)$} model when the objective is maximizing the\nprobability of selecting the maximum. This equivalence fails to hold when the\nobjective is maximizing the competitive ratio, but we still show that any\nalgorithm for the oracle model implies an equivalent competitive ratio for the\n\\textsc{Top-$1$-of-$(m+1)$} model.\n  We resolve the oracle model for any $m$, giving tight lower and upper bound\non the best possible competitive ratio compared to an almighty adversary. As a\nconsequence, we provide new results as well as improvements on known results\nfor the \\textsc{Top-$1$-of-$m$} model.",
        "updated": "2024-04-18T02:15:24Z",
        "published": "2024-04-18T02:15:24Z",
        "authors": [
            "Sariel Har-Peled",
            "Elfarouk Harb",
            "Vasilis Livanos"
        ],
        "categories": [
            "cs.GT"
        ],
        "primary_category": "cs.GT"
    },
    "2404.11854v1": {
        "url": "http://arxiv.org/abs/2404.11854v1",
        "title": "SGRU: A High-Performance Structured Gated Recurrent Unit for Traffic\n  Flow Prediction",
        "summary": "Traffic flow prediction is an essential task in constructing smart cities and\nis a typical Multivariate Time Series (MTS) Problem. Recent research has\nabandoned Gated Recurrent Units (GRU) and utilized dilated convolutions or\ntemporal slicing for feature extraction, and they have the following drawbacks:\n(1) Dilated convolutions fail to capture the features of adjacent time steps,\nresulting in the loss of crucial transitional data. (2) The connections within\nthe same temporal slice are strong, while the connections between different\ntemporal slices are too loose. In light of these limitations, we emphasize the\nimportance of analyzing a complete time series repeatedly and the crucial role\nof GRU in MTS. Therefore, we propose SGRU: Structured Gated Recurrent Units,\nwhich involve structured GRU layers and non-linear units, along with multiple\nlayers of time embedding to enhance the model's fitting performance. We\nevaluate our approach on four publicly available California traffic datasets:\nPeMS03, PeMS04, PeMS07, and PeMS08 for regression prediction. Experimental\nresults demonstrate that our model outperforms baseline models with average\nimprovements of 11.7%, 18.6%, 18.5%, and 12.0% respectively.",
        "updated": "2024-04-18T02:15:40Z",
        "published": "2024-04-18T02:15:40Z",
        "authors": [
            "Wenfeng Zhang",
            "Xin Li",
            "Anqi Li",
            "Xiaoting Huang",
            "Ti Wang",
            "Honglei Gao"
        ],
        "comments": "7 pages, 6 figures, conference",
        "categories": [
            "cs.AI"
        ],
        "primary_category": "cs.AI",
        "doi": "10.1109/ICPADS60453.2023"
    },
    "2404.12861v1": {
        "url": "http://arxiv.org/abs/2404.12861v1",
        "title": "Foundation Model assisted Weakly Supervised LiDAR Semantic Segmentation",
        "summary": "Current point cloud semantic segmentation has achieved great advances when\ngiven sufficient labels. However, the dense annotation of LiDAR point clouds\nremains prohibitively expensive and time-consuming, unable to keep up with the\ncontinuously growing volume of data. In this paper, we propose annotating\nimages with scattered points, followed by utilizing SAM (a Foundation model) to\ngenerate semantic segmentation labels for the images. Finally, by mapping the\nsegmentation labels of the images to the LiDAR space using the intrinsic and\nextrinsic parameters of the camera and LiDAR, we obtain labels for point cloud\nsemantic segmentation, and release Scatter-KITTI and Scatter-nuScenes, which\nare the first works to utilize image segmentation-based SAM for weakly\nsupervised point cloud semantic segmentation. Furthermore, to mitigate the\ninfluence of erroneous pseudo labels obtained from sparse annotations on point\ncloud features, we propose a multi-modal weakly supervised network for LiDAR\nsemantic segmentation, called MM-ScatterNet. This network combines features\nfrom both point cloud and image modalities, enhancing the representation\nlearning of point clouds by introducing consistency constraints between\nmulti-modal features and point cloud features. On the SemanticKITTI dataset, we\nachieve 66\\% of fully supervised performance using only 0.02% of annotated\ndata, and on the NuScenes dataset, we achieve 95% of fully supervised\nperformance using only 0.1% labeled points.",
        "updated": "2024-04-19T13:01:30Z",
        "published": "2024-04-19T13:01:30Z",
        "authors": [
            "Yilong Chen",
            "Zongyi Xu",
            "xiaoshui Huang",
            "Ruicheng Zhang",
            "Xinqi Jiang",
            "Xinbo Gao"
        ],
        "categories": [
            "cs.CV"
        ],
        "primary_category": "cs.CV"
    },
    "2404.12862v1": {
        "url": "http://arxiv.org/abs/2404.12862v1",
        "title": "A Guide to Feature Importance Methods for Scientific Inference",
        "summary": "While machine learning (ML) models are increasingly used due to their high\npredictive power, their use in understanding the data-generating process (DGP)\nis limited. Understanding the DGP requires insights into feature-target\nassociations, which many ML models cannot directly provide, due to their opaque\ninternal mechanisms. Feature importance (FI) methods provide useful insights\ninto the DGP under certain conditions. Since the results of different FI\nmethods have different interpretations, selecting the correct FI method for a\nconcrete use case is crucial and still requires expert knowledge. This paper\nserves as a comprehensive guide to help understand the different\ninterpretations of FI methods. Through an extensive review of FI methods and\nproviding new proofs regarding their interpretation, we facilitate a thorough\nunderstanding of these methods and formulate concrete recommendations for\nscientific inference. We conclude by discussing options for FI uncertainty\nestimation and point to directions for future research aiming at full\nstatistical inference from black-box ML models.",
        "updated": "2024-04-19T13:01:59Z",
        "published": "2024-04-19T13:01:59Z",
        "authors": [
            "Fiona Katharina Ewald",
            "Ludwig Bothmann",
            "Marvin N. Wright",
            "Bernd Bischl",
            "Giuseppe Casalicchio",
            "Gunnar K\u00f6nig"
        ],
        "comments": "Accepted at the 2nd World Conference on eXplainable Artificial\n  Intelligence, xAI-2024",
        "categories": [
            "stat.ML",
            "cs.LG",
            "math.ST",
            "stat.ME",
            "stat.TH"
        ],
        "primary_category": "stat.ML"
    },
    "2404.12863v1": {
        "url": "http://arxiv.org/abs/2404.12863v1",
        "title": "Grid-aware Scheduling and Control of Electric Vehicle Charging Stations\n  for Dispatching Active Distribution Networks. Part-I: Day-ahead and Numerical\n  Validation",
        "summary": "This paper proposes a grid-aware scheduling and control framework for\nElectric Vehicle Charging Stations (EVCSs) for dispatching the operation of an\nactive power distribution network. The framework consists of two stages. In the\nfirst stage, we determine an optimal day-ahead power schedule at the grid\nconnection point (GCP), referred to as the dispatch plan. Then, in the second\nstage, a real-time model predictive control is proposed to track the day-ahead\ndispatch plan using flexibility from EVCSs. The dispatch plan accounts for the\nuncertainties of vehicles connected to the EVCS along with other uncontrollable\npower injections, by day-ahead predicted scenarios. We propose using a\nGaussian-Mixture-Model (GMM) for the forecasting of EVCS demand using the\nhistorical dataset on arrival, departure times, EV battery capacity,\nState-of-Charge (SoC) targets, etc. The framework ensures that the grid is\noperated within its voltage and branches power-flow operational bounds, modeled\nby a linearized optimal power-flow model, maintaining the tractability of the\nproblem formulation. The scheme is numerically and experimentally validated on\na real-life distribution network at the EPFL connected to two EVCSs, two\nbatteries, three photovoltaic plants, and multiple heterogeneous loads. The\nday-ahead and real-time stages are described in Part-I and Part-II papers\nrespectively.",
        "updated": "2024-04-19T13:02:04Z",
        "published": "2024-04-19T13:02:04Z",
        "authors": [
            "Rahul K. Gupta",
            "Sherif Fahmy",
            "Max Chevron",
            "Riccardo Vasapollo",
            "Enea Figini",
            "Mario Paolone"
        ],
        "comments": "10 pages, 13 figures (submitted for review in IEEE Transactions)",
        "categories": [
            "eess.SY",
            "cs.SY"
        ],
        "primary_category": "eess.SY"
    },
    "2404.12864v1": {
        "url": "http://arxiv.org/abs/2404.12864v1",
        "title": "Nyon Unchained: Forensic Analysis of Bosch's eBike Board Computers",
        "summary": "Modern eBike on-board computers are basically small PCs that not only offer\nmotor control, navigation, and performance monitoring, but also store lots of\nsensitive user data. The Bosch Nyon series of board computers are cutting-edge\ndevices from one of the market leaders in the eBike business, which is why they\nare especially interesting for forensics. Therefore, we conducted an in-depth\nforensic analysis of the two available Nyon models released in 2014 and 2021.\nOn a first-generation Nyon device, Telnet access could be established by\nabusing a design flaw in the update procedure, which allowed the acquisition of\nrelevant data without risking damage to the hardware. Besides the user's\npersonal information, the data analysis revealed databases containing user\nactivities, including timestamps and GPS coordinates. Furthermore, it was\npossible to forge the data on the device and transfer it to Bosch's servers to\nbe persisted across their online service and smartphone app. On a current\nsecond-generation Nyon device, no software-based access could be obtained. For\nthis reason, more intrusive hardware-based options were considered, and the\ndata could be extracted via chip-off eventually. Despite encryption, the user\ndata could be accessed and evaluated. Besides location and user information,\nthe newer model holds even more forensically relevant data, such as nearby\nBluetooth devices.",
        "updated": "2024-04-19T13:03:14Z",
        "published": "2024-04-19T13:03:14Z",
        "authors": [
            "Marcel Stachak",
            "Julian Geus",
            "Gaston Pugliese",
            "Felix Freiling"
        ],
        "comments": "In: Proceedings of the Digital Forensics Research Conference EU\n  (DFRWS EU). 2024",
        "categories": [
            "cs.CR"
        ],
        "primary_category": "cs.CR"
    },
    "2404.12866v1": {
        "url": "http://arxiv.org/abs/2404.12866v1",
        "title": "How Does the Textual Information Affect the Retrieval of Multimodal\n  In-Context Learning?",
        "summary": "The increase in parameter size of multimodal large language models (MLLMs)\nintroduces significant capabilities, particularly in-context learning, where\nMLLMs enhance task performance without updating pre-trained parameters. This\neffectiveness, however, hinges on the appropriate selection of in-context\nexamples, a process that is currently biased towards visual data, overlooking\ntextual information. Furthermore, the area of supervised retrievers for MLLMs,\ncrucial for optimal in-context example selection, continues to be\nuninvestigated. Our study offers an in-depth evaluation of the impact of\ntextual information on the unsupervised selection of in-context examples in\nmultimodal contexts, uncovering a notable sensitivity of retriever performance\nto the employed modalities. Responding to this, we introduce a novel supervised\nMLLM-retriever MSIER that employs a neural network to select examples that\nenhance multimodal in-context learning efficiency. This approach is validated\nthrough extensive testing across three distinct tasks, demonstrating the\nmethod's effectiveness. Additionally, we investigate the influence of\nmodalities on our supervised retrieval method's training and pinpoint factors\ncontributing to our model's success. This exploration paves the way for future\nadvancements, highlighting the potential for refined in-context learning in\nMLLMs through the strategic use of multimodal data.",
        "updated": "2024-04-19T13:05:37Z",
        "published": "2024-04-19T13:05:37Z",
        "authors": [
            "Yang Luo",
            "Zangwei Zheng",
            "Zirui Zhu",
            "Yang You"
        ],
        "categories": [
            "cs.CL",
            "cs.AI",
            "cs.CV"
        ],
        "primary_category": "cs.CL"
    },
    "2404.12867v1": {
        "url": "http://arxiv.org/abs/2404.12867v1",
        "title": "FipTR: A Simple yet Effective Transformer Framework for Future Instance\n  Prediction in Autonomous Driving",
        "summary": "The future instance prediction from a Bird's Eye View(BEV) perspective is a\nvital component in autonomous driving, which involves future instance\nsegmentation and instance motion prediction. Existing methods usually rely on a\nredundant and complex pipeline which requires multiple auxiliary outputs and\npost-processing procedures. Moreover, estimated errors on each of the auxiliary\npredictions will lead to degradation of the prediction performance. In this\npaper, we propose a simple yet effective fully end-to-end framework named\nFuture Instance Prediction Transformer(FipTR), which views the task as BEV\ninstance segmentation and prediction for future frames. We propose to adopt\ninstance queries representing specific traffic participants to directly\nestimate the corresponding future occupied masks, and thus get rid of complex\npost-processing procedures. Besides, we devise a flow-aware BEV predictor for\nfuture BEV feature prediction composed of a flow-aware deformable attention\nthat takes backward flow guiding the offset sampling. A novel future instance\nmatching strategy is also proposed to further improve the temporal coherence.\nExtensive experiments demonstrate the superiority of FipTR and its\neffectiveness under different temporal BEV encoders.",
        "updated": "2024-04-19T13:08:43Z",
        "published": "2024-04-19T13:08:43Z",
        "authors": [
            "Xingtai Gui",
            "Tengteng Huang",
            "Haonan Shao",
            "Haotian Yao",
            "Chi Zhang"
        ],
        "categories": [
            "cs.CV",
            "cs.RO"
        ],
        "primary_category": "cs.CV"
    },
    "2404.12868v1": {
        "url": "http://arxiv.org/abs/2404.12868v1",
        "title": "Coding for Composite DNA to Correct Substitutions, Strand Losses, and\n  Deletions",
        "summary": "Composite DNA is a recent method to increase the base alphabet size in\nDNA-based data storage.This paper models synthesizing and sequencing of\ncomposite DNA and introduces coding techniques to correct substitutions, losses\nof entire strands, and symbol deletion errors. Non-asymptotic upper bounds on\nthe size of codes with $t$ occurrences of these error types are derived.\nExplicit constructions are presented which can achieve the bounds.",
        "updated": "2024-04-19T13:09:52Z",
        "published": "2024-04-19T13:09:52Z",
        "authors": [
            "Frederik Walter",
            "Omer Sabary",
            "Antonia Wachter-Zeh",
            "Eitan Yaakobi"
        ],
        "categories": [
            "cs.IT",
            "math.IT"
        ],
        "primary_category": "cs.IT"
    },
    "2404.12870v1": {
        "url": "http://arxiv.org/abs/2404.12870v1",
        "title": "Grid-aware Scheduling and Control of Electric Vehicle Charging Stations\n  for Dispatching Active Distribution Networks. Part-II: Intra-day and\n  Experimental Validation",
        "summary": "In Part-I, we presented an optimal day-ahead scheduling scheme for\ndispatching active distribution networks accounting for the flexibility\nprovided by electric vehicle charging stations (EVCSs) and other controllable\nresources such as battery energy storage systems (BESSs). Part-II presents the\nintra-day control layer for tracking the dispatch plan computed from the\nday-ahead scheduling stage. The control problem is formulated as model\npredictive control (MPC) with an objective to track the dispatch plan setpoint\nevery 5 minutes, while actuated every 30 seconds. MPC accounts for the\nuncertainty of the power injections from stochastic resources (such as demand\nand generation from photovoltaic - PV plants) by short-term forecasts. MPC also\naccounts for the grid's operational constraints (i.e., the limits on the nodal\nvoltages and the line power-flows) by a linearized optimal power flow (LOPF)\nmodel based on the power-flow sensitivity coefficients, and for the operational\nconstraints of the controllable resources (i.e., BESSs and EVCSs). The proposed\nframework is experimentally validated on a real-life ADN at the EPFL's\nDistributed Electrical Systems Laboratory and is composed of a medium voltage\n(MV) bus connected to three low voltage distribution networks. It hosts two\ncontrollable EVCSs (172 kWp and 32 F~kWp), multiple PV plants (aggregated\ngeneration of 42~kWp), uncontrollable demand from office buildings (20 kWp),\nand two controllable BESSs (150kW/300kWh and 25kW/25kWh).",
        "updated": "2024-04-19T13:15:18Z",
        "published": "2024-04-19T13:15:18Z",
        "authors": [
            "Rahul K. Gupta",
            "Sherif Fahmy",
            "Max Chevron",
            "Enea Figini",
            "Mario Paolone"
        ],
        "comments": "10 pages, 14 Figures, submitted for review in IEEE Transactions",
        "categories": [
            "eess.SY",
            "cs.SY"
        ],
        "primary_category": "eess.SY"
    },
    "2404.12871v1": {
        "url": "http://arxiv.org/abs/2404.12871v1",
        "title": "Expanding the Katz Index for Link Prediction: A Case Study on a Live\n  Fish Movement Network",
        "summary": "In aquaculture, disease spread models often neglect the dynamic interactions\nbetween farms, hindering accuracy. This study enhances the Katz index (KI) to\nincorporate spatial and temporal patterns of fish movement, improving the\nprediction of farms susceptible to disease via live fish transfers. We modified\nthe Katz index to create models like the Weighted Katz Index (WKI), Edge\nWeighted Katz Index (EWKI), and combined models (e.g., KIEWKI). These\nincorporate spatial distances and temporal movement patterns for a\ncomprehensive aquaculture network connection prediction framework. Model\nperformance was evaluated using precision, recall, F1-scores, AUPR, and AUROC.\nThe EWKI model significantly outperformed the traditional KI and other\nvariations. It achieved high precision (0.988), recall (0.712), F1-score\n(0.827), and AUPR (0.970). Combined models (KIEWKI, WKIEWKI) approached, but\ncouldn't surpass, EWKI performance. This study highlights the value of\nextending Katz index models to improve disease spread predictions in\naquaculture networks. The EWKI model's performance demonstrates an innovative\nand flexible approach to tackling spatial challenges within network analysis.",
        "updated": "2024-04-19T13:17:06Z",
        "published": "2024-04-19T13:17:06Z",
        "authors": [
            "Michael-Sam Vidza",
            "Marcin Budka",
            "Wei Koong Chai",
            "Mark Thrush",
            "Mickael Teixeira Alves"
        ],
        "comments": "15 pages, 3 figures, submitted to Expert Systems with Applications",
        "categories": [
            "cs.SI",
            "math.CO",
            "physics.soc-ph"
        ],
        "primary_category": "cs.SI"
    },
    "2404.12872v1": {
        "url": "http://arxiv.org/abs/2404.12872v1",
        "title": "LLM-R2: A Large Language Model Enhanced Rule-based Rewrite System for\n  Boosting Query Efficiency",
        "summary": "Query rewrite, which aims to generate more efficient queries by altering a\nSQL query's structure without changing the query result, has been an important\nresearch problem. In order to maintain equivalence between the rewritten query\nand the original one during rewriting, traditional query rewrite methods always\nrewrite the queries following certain rewrite rules. However, some problems\nstill remain. Firstly, existing methods of finding the optimal choice or\nsequence of rewrite rules are still limited and the process always costs a lot\nof resources. Methods involving discovering new rewrite rules typically require\ncomplicated proofs of structural logic or extensive user interactions.\nSecondly, current query rewrite methods usually rely highly on DBMS cost\nestimators which are often not accurate. In this paper, we address these\nproblems by proposing a novel method of query rewrite named LLM-R2, adopting a\nlarge language model (LLM) to propose possible rewrite rules for a database\nrewrite system. To further improve the inference ability of LLM in recommending\nrewrite rules, we train a contrastive model by curriculum to learn query\nrepresentations and select effective query demonstrations for the LLM.\nExperimental results have shown that our method can significantly improve the\nquery execution efficiency and outperform the baseline methods. In addition,\nour method enjoys high robustness across different datasets.",
        "updated": "2024-04-19T13:17:07Z",
        "published": "2024-04-19T13:17:07Z",
        "authors": [
            "Zhaodonghui Li",
            "Haitao Yuan",
            "Huiming Wang",
            "Gao Cong",
            "Lidong Bing"
        ],
        "comments": "12 pages",
        "categories": [
            "cs.DB",
            "cs.CL"
        ],
        "primary_category": "cs.DB"
    }
}