{"0":{"arxiv_id":"2403.16190v1","url":"http:\/\/arxiv.org\/abs\/2403.16190v1","title":"Logic-based Explanations for Linear Support Vector Classifiers with\n  Reject Option","summary":"Support Vector Classifier (SVC) is a well-known Machine Learning (ML) model\nfor linear classification problems. It can be used in conjunction with a reject\noption strategy to reject instances that are hard to correctly classify and\ndelegate them to a specialist. This further increases the confidence of the\nmodel. Given this, obtaining an explanation of the cause of rejection is\nimportant to not blindly trust the obtained results. While most of the related\nwork has developed means to give such explanations for machine learning models,\nto the best of our knowledge none have done so for when reject option is\npresent. We propose a logic-based approach with formal guarantees on the\ncorrectness and minimality of explanations for linear SVCs with reject option.\nWe evaluate our approach by comparing it to Anchors, which is a heuristic\nalgorithm for generating explanations. Obtained results show that our proposed\nmethod gives shorter explanations with reduced time cost.","updated":1711293284000,"published":1711293284000,"authors":["Francisco Mateus Rocha Filho","Thiago Alves Rocha","Reginaldo Pereira Fernandes Ribeiro","Ajalmar R\u00eago da Rocha Neto"],"comments":"16 pages, submitted to BRACIS 2023 (Brazilian Conference on\n  Intelligent Systems), accepted version published in Intelligent Systems,\n  LNCS, vol 14195","categories":["cs.AI","cs.LG","cs.LO","I.2.4; I.2.6"],"primary_category":"cs.AI","doi":"10.1007\/978-3-031-45368-7_10","journal_ref":null,"peer_reviewed":true},"1":{"arxiv_id":"2307.05300v4","url":"http:\/\/arxiv.org\/abs\/2307.05300v4","title":"Unleashing the Emergent Cognitive Synergy in Large Language Models: A\n  Task-Solving Agent through Multi-Persona Self-Collaboration","summary":"Human intelligence thrives on cognitive synergy, where collaboration among\ndifferent minds yield superior outcomes compared to isolated individuals. In\nthis work, we propose Solo Performance Prompting (SPP), which transforms a\nsingle LLM into a cognitive synergist by engaging in multi-turn\nself-collaboration with multiple personas. A cognitive synergist is an\nintelligent agent that collaboratively combines multiple minds' strengths and\nknowledge to enhance problem-solving in complex tasks. By dynamically\nidentifying and simulating different personas based on task inputs, SPP\nunleashes the potential of cognitive synergy in LLMs. Our in-depth analysis\nshows that assigning multiple fine-grained personas in LLMs improves\nproblem-solving abilities compared to using a single or fixed number of\npersonas. We evaluate SPP on three challenging tasks: Trivia Creative Writing,\nCodenames Collaborative, and Logic Grid Puzzle, encompassing both\nknowledge-intensive and reasoning-intensive types. Unlike previous works, such\nas Chain-of-Thought, that solely enhance the reasoning abilities in LLMs,\nexperimental results demonstrate that SPP effectively reduces factual\nhallucination, and maintains strong reasoning capabilities. Additionally,\ncomparative experiments show that cognitive synergy only emerges in GPT-4 and\ndoes not appear in less capable models, such as GPT-3.5-turbo and\nLlama2-13b-chat, which draws an interesting analogy to human development. Code,\ndata, and prompts can be found at:\nhttps:\/\/github.com\/MikeWangWZHL\/Solo-Performance-Prompting.git.","updated":1711463553000,"published":1689086719000,"authors":["Zhenhailong Wang","Shaoguang Mao","Wenshan Wu","Tao Ge","Furu Wei","Heng Ji"],"comments":"Accepted as a main conference paper at NAACL 2024","categories":["cs.AI","cs.CL"],"primary_category":"cs.AI","doi":null,"journal_ref":null,"peer_reviewed":true},"2":{"arxiv_id":"2403.16750v1","url":"http:\/\/arxiv.org\/abs\/2403.16750v1","title":"All Artificial, Less Intelligence: GenAI through the Lens of Formal\n  Verification","summary":"Modern hardware designs have grown increasingly efficient and complex.\nHowever, they are often susceptible to Common Weakness Enumerations (CWEs).\nThis paper is focused on the formal verification of CWEs in a dataset of\nhardware designs written in SystemVerilog from Regenerative Artificial\nIntelligence (AI) powered by Large Language Models (LLMs). We applied formal\nverification to categorize each hardware design as vulnerable or CWE-free. This\ndataset was generated by 4 different LLMs and features a unique set of designs\nfor each of the 10 CWEs we target in our paper. We have associated the\nidentified vulnerabilities with CWE numbers for a dataset of 60,000 generated\nSystemVerilog Register Transfer Level (RTL) code. It was also found that most\nLLMs are not aware of any hardware CWEs; hence they are usually not considered\nwhen generating the hardware code. Our study reveals that approximately 60% of\nthe hardware designs generated by LLMs are prone to CWEs, posing potential\nsafety and security risks. The dataset could be ideal for training LLMs and\nMachine Learning (ML) algorithms to abstain from generating CWE-prone hardware\ndesigns.","updated":1711373004000,"published":1711373004000,"authors":["Deepak Narayan Gadde","Aman Kumar","Thomas Nalapat","Evgenii Rezunov","Fabio Cappellini"],"comments":"Published in DVCon U.S. 2024","categories":["cs.AI"],"primary_category":"cs.AI","doi":null,"journal_ref":null,"peer_reviewed":true},"3":{"arxiv_id":"2311.10112v2","url":"http:\/\/arxiv.org\/abs\/2311.10112v2","title":"zrLLM: Zero-Shot Relational Learning on Temporal Knowledge Graphs with\n  Large Language Models","summary":"Modeling evolving knowledge over temporal knowledge graphs (TKGs) has become\na heated topic. Various methods have been proposed to forecast links on TKGs.\nMost of them are embedding-based, where hidden representations are learned to\nrepresent knowledge graph (KG) entities and relations based on the observed\ngraph contexts. Although these methods show strong performance on traditional\nTKG forecasting (TKGF) benchmarks, they face a strong challenge in modeling the\nunseen zero-shot relations that have no prior graph context. In this paper, we\ntry to mitigate this problem as follows. We first input the text descriptions\nof KG relations into large language models (LLMs) for generating relation\nrepresentations, and then introduce them into embedding-based TKGF methods.\nLLM-empowered representations can capture the semantic information in the\nrelation descriptions. This makes the relations, whether seen or unseen, with\nsimilar semantic meanings stay close in the embedding space, enabling TKGF\nmodels to recognize zero-shot relations even without any observed graph\ncontext. Experimental results show that our approach helps TKGF models to\nachieve much better performance in forecasting the facts with previously unseen\nrelations, while still maintaining their ability in link forecasting regarding\nseen relations.","updated":1710517087000,"published":1700083515000,"authors":["Zifeng Ding","Heling Cai","Jingpei Wu","Yunpu Ma","Ruotong Liao","Bo Xiong","Volker Tresp"],"comments":"Accepted to NAACL 2024 main conference","categories":["cs.AI","cs.CL","cs.LG"],"primary_category":"cs.AI","doi":null,"journal_ref":null,"peer_reviewed":true},"4":{"arxiv_id":"2310.08992v3","url":"http:\/\/arxiv.org\/abs\/2310.08992v3","title":"CodeChain: Towards Modular Code Generation Through Chain of\n  Self-revisions with Representative Sub-modules","summary":"Large Language Models (LLMs) have already become quite proficient at solving\nsimpler programming tasks like those in HumanEval or MBPP benchmarks. However,\nsolving more complex and competitive programming tasks is still quite\nchallenging for these models - possibly due to their tendency to generate\nsolutions as monolithic code blocks instead of decomposing them into logical\nsub-tasks and sub-modules. On the other hand, experienced programmers\ninstinctively write modularized code with abstraction for solving complex\ntasks, often reusing previously developed modules. To address this gap, we\npropose CodeChain, a novel framework for inference that elicits modularized\ncode generation through a chain of self-revisions, each being guided by some\nrepresentative sub-modules generated in previous iterations. Concretely,\nCodeChain first instructs the LLM to generate modularized codes through\nchain-of-thought prompting. Then it applies a chain of self-revisions by\niterating the two steps: 1) extracting and clustering the generated sub-modules\nand selecting the cluster representatives as the more generic and re-usable\nimplementations, and 2) augmenting the original chain-of-thought prompt with\nthese selected module-implementations and instructing the LLM to re-generate\nnew modularized solutions. We find that by naturally encouraging the LLM to\nreuse the previously developed and verified sub-modules, CodeChain can\nsignificantly boost both modularity as well as correctness of the generated\nsolutions, achieving relative pass@1 improvements of 35% on APPS and 76% on\nCodeContests. It is shown to be effective on both OpenAI LLMs as well as\nopen-sourced LLMs like WizardCoder. We also conduct comprehensive ablation\nstudies with different methods of prompting, number of clusters, model sizes,\nprogram qualities, etc., to provide useful insights that underpin CodeChain's\nsuccess.","updated":1710386949000,"published":1697192268000,"authors":["Hung Le","Hailin Chen","Amrita Saha","Akash Gokul","Doyen Sahoo","Shafiq Joty"],"comments":"Accepted to ICLR 2024","categories":["cs.AI","cs.CL","cs.PL"],"primary_category":"cs.AI","doi":null,"journal_ref":null,"peer_reviewed":true},"5":{"arxiv_id":"2402.09565v2","url":"http:\/\/arxiv.org\/abs\/2402.09565v2","title":"Graph-Skeleton: ~1% Nodes are Sufficient to Represent Billion-Scale\n  Graph","summary":"Due to the ubiquity of graph data on the web, web graph mining has become a\nhot research spot. Nonetheless, the prevalence of large-scale web graphs in\nreal applications poses significant challenges to storage, computational\ncapacity and graph model design. Despite numerous studies to enhance the\nscalability of graph models, a noticeable gap remains between academic research\nand practical web graph mining applications. One major cause is that in most\nindustrial scenarios, only a small part of nodes in a web graph are actually\nrequired to be analyzed, where we term these nodes as target nodes, while\nothers as background nodes. In this paper, we argue that properly fetching and\ncondensing the background nodes from massive web graph data might be a more\neconomical shortcut to tackle the obstacles fundamentally. To this end, we make\nthe first attempt to study the problem of massive background nodes compression\nfor target nodes classification. Through extensive experiments, we reveal two\ncritical roles played by the background nodes in target node classification:\nenhancing structural connectivity between target nodes, and feature correlation\nwith target nodes. Followingthis, we propose a novel Graph-Skeleton1 model,\nwhich properly fetches the background nodes, and further condenses the semantic\nand topological information of background nodes within similar\ntarget-background local structures. Extensive experiments on various web graph\ndatasets demonstrate the effectiveness and efficiency of the proposed method.\nIn particular, for MAG240M dataset with 0.24 billion nodes, our generated\nskeleton graph achieves highly comparable performance while only containing\n1.8% nodes of the original graph.","updated":1709763753000,"published":1707942791000,"authors":["Linfeng Cao","Haoran Deng","Yang Yang","Chunping Wang","Lei Chen"],"comments":"21 pages, 11 figures, In Proceedings of the ACM Web Conference 2024\n  (WWW'24)","categories":["cs.AI"],"primary_category":"cs.AI","doi":"10.1145\/3589334.3645452","journal_ref":null,"peer_reviewed":true},"6":{"arxiv_id":"2007.00714v4","url":"http:\/\/arxiv.org\/abs\/2007.00714v4","title":"Quantifying intrinsic causal contributions via structure preserving\n  interventions","summary":"We propose a notion of causal influence that describes the `intrinsic' part\nof the contribution of a node on a target node in a DAG. By recursively writing\neach node as a function of the upstream noise terms, we separate the intrinsic\ninformation added by each node from the one obtained from its ancestors. To\ninterpret the intrinsic information as a {\\it causal} contribution, we consider\n`structure-preserving interventions' that randomize each node in a way that\nmimics the usual dependence on the parents and does not perturb the observed\njoint distribution. To get a measure that is invariant with respect to\nrelabelling nodes we use Shapley based symmetrization and show that it reduces\nin the linear case to simple ANOVA after resolving the target node into noise\nvariables. We describe our contribution analysis for variance and entropy, but\ncontributions for other target metrics can be defined analogously. The code is\navailable in the package gcm of the open source library DoWhy.","updated":1709904783000,"published":1593632048000,"authors":["Dominik Janzing","Patrick Bl\u00f6baum","Atalanti A. Mastakouri","Philipp M. Faller","Lenon Minorics","Kailash Budhathoki"],"comments":"to appear at AISTATS 2024","categories":["cs.AI","cs.IT","math.IT","stat.ML"],"primary_category":"cs.AI","doi":null,"journal_ref":null,"peer_reviewed":true},"7":{"arxiv_id":"2311.02760v2","url":"http:\/\/arxiv.org\/abs\/2311.02760v2","title":"Causal Question Answering with Reinforcement Learning","summary":"Causal questions inquire about causal relationships between different events\nor phenomena. They are important for a variety of use cases, including virtual\nassistants and search engines. However, many current approaches to causal\nquestion answering cannot provide explanations or evidence for their answers.\nHence, in this paper, we aim to answer causal questions with a causality graph,\na large-scale dataset of causal relations between noun phrases along with the\nrelations' provenance data. Inspired by recent, successful applications of\nreinforcement learning to knowledge graph tasks, such as link prediction and\nfact-checking, we explore the application of reinforcement learning on a\ncausality graph for causal question answering. We introduce an\nActor-Critic-based agent which learns to search through the graph to answer\ncausal questions. We bootstrap the agent with a supervised learning procedure\nto deal with large action spaces and sparse rewards. Our evaluation shows that\nthe agent successfully prunes the search space to answer binary causal\nquestions by visiting less than 30 nodes per question compared to over 3,000\nnodes by a naive breadth-first search. Our ablation study indicates that our\nsupervised learning strategy provides a strong foundation upon which our\nreinforcement learning agent improves. The paths returned by our agent explain\nthe mechanisms by which a cause produces an effect. Moreover, for each edge on\na path, our causality graph provides its original source allowing for easy\nverification of paths.","updated":1711357067000,"published":1699216398000,"authors":["Lukas Bl\u00fcbaum","Stefan Heindorf"],"comments":"Accepted at WWW 2024","categories":["cs.AI","cs.LG"],"primary_category":"cs.AI","doi":"10.1145\/3589334.3645610","journal_ref":null,"peer_reviewed":true},"8":{"arxiv_id":"2403.17358v1","url":"http:\/\/arxiv.org\/abs\/2403.17358v1","title":"Addressing Myopic Constrained POMDP Planning with Recursive Dual Ascent","summary":"Lagrangian-guided Monte Carlo tree search with global dual ascent has been\napplied to solve large constrained partially observable Markov decision\nprocesses (CPOMDPs) online. In this work, we demonstrate that these global dual\nparameters can lead to myopic action selection during exploration, ultimately\nleading to suboptimal decision making. To address this, we introduce\nhistory-dependent dual variables that guide local action selection and are\noptimized with recursive dual ascent. We empirically compare the performance of\nour approach on a motivating toy example and two large CPOMDPs, demonstrating\nimproved exploration, and ultimately, safer outcomes.","updated":1711424793000,"published":1711424793000,"authors":["Paula Stocco","Suhas Chundi","Arec Jamgochian","Mykel J. Kochenderfer"],"comments":"Accepted to the 2024 International Conference on Automated Planning\n  and Scheduling (ICAPS)","categories":["cs.AI"],"primary_category":"cs.AI","doi":null,"journal_ref":null,"peer_reviewed":true},"9":{"arxiv_id":"2403.04124v1","url":"http:\/\/arxiv.org\/abs\/2403.04124v1","title":"Privacy-preserving Fine-tuning of Large Language Models through Flatness","summary":"The privacy concerns associated with the use of Large Language Models (LLMs)\nhave grown recently with the development of LLMs such as ChatGPT. Differential\nPrivacy (DP) techniques are explored in existing work to mitigate their privacy\nrisks at the cost of generalization degradation. Our paper reveals that the\nflatness of DP-trained models' loss landscape plays an essential role in the\ntrade-off between their privacy and generalization. We further propose a\nholistic framework to enforce appropriate weight flatness, which substantially\nimproves model generalization with competitive privacy preservation. It\ninnovates from three coarse-to-grained levels, including perturbation-aware\nmin-max optimization on model weights within a layer, flatness-guided sparse\nprefix-tuning on weights across layers, and weight knowledge distillation\nbetween DP \\& non-DP weights copies. Comprehensive experiments of both\nblack-box and white-box scenarios are conducted to demonstrate the\neffectiveness of our proposal in enhancing generalization and maintaining DP\ncharacteristics. For instance, on text classification dataset QNLI, DP-Flat\nachieves similar performance with non-private full fine-tuning but with DP\nguarantee under privacy budget $\\epsilon=3$, and even better performance given\nhigher privacy budgets. Codes are provided in the supplement.","updated":1709772251000,"published":1709772251000,"authors":["Tiejin Chen","Longchao Da","Huixue Zhou","Pingzhi Li","Kaixiong Zhou","Tianlong Chen","Hua Wei"],"comments":"Accepted to ICLR 2024 SeT LLM Workshop","categories":["cs.AI","I.2"],"primary_category":"cs.AI","doi":null,"journal_ref":null,"peer_reviewed":true},"10":{"arxiv_id":"2402.07398v2","url":"http:\/\/arxiv.org\/abs\/2402.07398v2","title":"VisLingInstruct: Elevating Zero-Shot Learning in Multi-Modal Language\n  Models with Autonomous Instruction Optimization","summary":"This paper presents VisLingInstruct, a novel approach to advancing\nMulti-Modal Language Models (MMLMs) in zero-shot learning. Current MMLMs show\nimpressive zero-shot abilities in multi-modal tasks, but their performance\ndepends heavily on the quality of instructions. VisLingInstruct tackles this by\nautonomously evaluating and optimizing instructional texts through In-Context\nLearning, improving the synergy between visual perception and linguistic\nexpression in MMLMs. Alongside this instructional advancement, we have also\noptimized the visual feature extraction modules in MMLMs, further augmenting\ntheir responsiveness to textual cues. Our comprehensive experiments on MMLMs,\nbased on FlanT5 and Vicuna, show that VisLingInstruct significantly improves\nzero-shot performance in visual multi-modal tasks. Notably, it achieves a 13.1%\nand 9% increase in accuracy over the prior state-of-the-art on the TextVQA and\nHatefulMemes datasets.","updated":1710426614000,"published":1707711196000,"authors":["Dongsheng Zhu","Xunzhu Tang","Weidong Han","Jinghui Lu","Yukun Zhao","Guoliang Xing","Junfeng Wang","Dawei Yin"],"comments":"Accepted to NAACL2024 main conference","categories":["cs.AI"],"primary_category":"cs.AI","doi":null,"journal_ref":null,"peer_reviewed":true},"11":{"arxiv_id":"2309.03685v2","url":"http:\/\/arxiv.org\/abs\/2309.03685v2","title":"PyGraft: Configurable Generation of Synthetic Schemas and Knowledge\n  Graphs at Your Fingertips","summary":"Knowledge graphs (KGs) have emerged as a prominent data representation and\nmanagement paradigm. Being usually underpinned by a schema (e.g., an ontology),\nKGs capture not only factual information but also contextual knowledge. In some\ntasks, a few KGs established themselves as standard benchmarks. However, recent\nworks outline that relying on a limited collection of datasets is not\nsufficient to assess the generalization capability of an approach. In some\ndata-sensitive fields such as education or medicine, access to public datasets\nis even more limited. To remedy the aforementioned issues, we release PyGraft,\na Python-based tool that generates highly customized, domain-agnostic schemas\nand KGs. The synthesized schemas encompass various RDFS and OWL constructs,\nwhile the synthesized KGs emulate the characteristics and scale of real-world\nKGs. Logical consistency of the generated resources is ultimately ensured by\nrunning a description logic (DL) reasoner. By providing a way of generating\nboth a schema and KG in a single pipeline, PyGraft's aim is to empower the\ngeneration of a more diverse array of KGs for benchmarking novel approaches in\nareas such as graph-based machine learning (ML), or more generally KG\nprocessing. In graph-based ML in particular, this should foster a more holistic\nevaluation of model performance and generalization capability, thereby going\nbeyond the limited collection of available benchmarks. PyGraft is available at:\nhttps:\/\/github.com\/nicolas-hbt\/pygraft.","updated":1709675803000,"published":1694091609000,"authors":["Nicolas Hubert","Pierre Monnin","Mathieu d'Aquin","Davy Monticolo","Armelle Brun"],"comments":"Accepted in ESWC 2024","categories":["cs.AI","cs.SE"],"primary_category":"cs.AI","doi":null,"journal_ref":null,"peer_reviewed":true},"12":{"arxiv_id":"2301.13755v3","url":"http:\/\/arxiv.org\/abs\/2301.13755v3","title":"Retrosynthetic Planning with Dual Value Networks","summary":"Retrosynthesis, which aims to find a route to synthesize a target molecule\nfrom commercially available starting materials, is a critical task in drug\ndiscovery and materials design. Recently, the combination of ML-based\nsingle-step reaction predictors with multi-step planners has led to promising\nresults. However, the single-step predictors are mostly trained offline to\noptimize the single-step accuracy, without considering complete routes. Here,\nwe leverage reinforcement learning (RL) to improve the single-step predictor,\nby using a tree-shaped MDP to optimize complete routes. Specifically, we\npropose a novel online training algorithm, called Planning with Dual Value\nNetworks (PDVN), which alternates between the planning phase and updating\nphase. In PDVN, we construct two separate value networks to predict the\nsynthesizability and cost of molecules, respectively. To maintain the\nsingle-step accuracy, we design a two-branch network structure for the\nsingle-step predictor. On the widely-used USPTO dataset, our PDVN algorithm\nimproves the search success rate of existing multi-step planners (e.g.,\nincreasing the success rate from 85.79% to 98.95% for Retro*, and reducing the\nnumber of model calls by half while solving 99.47% molecules for RetroGraph).\nAdditionally, PDVN helps find shorter synthesis routes (e.g., reducing the\naverage route length from 5.76 to 4.83 for Retro*, and from 5.63 to 4.78 for\nRetroGraph). Our code is available at \\url{https:\/\/github.com\/DiXue98\/PDVN}.","updated":1709475801000,"published":1675183433000,"authors":["Guoqing Liu","Di Xue","Shufang Xie","Yingce Xia","Austin Tripp","Krzysztof Maziarz","Marwin Segler","Tao Qin","Zongzhang Zhang","Tie-Yan Liu"],"comments":"Accepted to ICML 2023","categories":["cs.AI","cs.LG"],"primary_category":"cs.AI","doi":null,"journal_ref":null,"peer_reviewed":true},"13":{"arxiv_id":"2312.14106v2","url":"http:\/\/arxiv.org\/abs\/2312.14106v2","title":"Learning Human-like Representations to Enable Learning Human Values","summary":"How can we build AI systems that are aligned with human values to avoid\ncausing harm or violating societal standards for acceptable behavior? We argue\nthat representational alignment between humans and AI agents facilitates value\nalignment. Making AI systems learn human-like representations of the world has\nmany known benefits, including improving generalization, robustness to domain\nshifts, and few-shot learning performance. We propose that this kind of\nrepresentational alignment between machine learning (ML) models and humans can\nalso support value alignment, allowing ML systems to conform to human values\nand societal norms. We focus on ethics as one aspect of value alignment and\ntrain ML agents using a variety of methods in a multi-armed bandit setting,\nwhere rewards reflect the moral acceptability of the chosen action. We use a\nsynthetic experiment to demonstrate that agents' representational alignment\nwith the environment bounds their learning performance. We then repeat this\nprocedure in a realistic setting, using textual action descriptions and\nsimilarity judgments collected from humans and a variety of language models, to\nshow that the results generalize and are model-agnostic when grounded in an\nethically relevant context.","updated":1710293875000,"published":1703183493000,"authors":["Andrea Wynn","Ilia Sucholutsky","Thomas L. Griffiths"],"comments":"Paper accepted in Human-Centric Representation Learning workshop at\n  AAAI 2024 (https:\/\/hcrl-workshop.github.io\/2024\/)","categories":["cs.AI","cs.LG"],"primary_category":"cs.AI","doi":null,"journal_ref":null,"peer_reviewed":true},"14":{"arxiv_id":"2312.00812v4","url":"http:\/\/arxiv.org\/abs\/2312.00812v4","title":"Empowering Autonomous Driving with Large Language Models: A Safety\n  Perspective","summary":"Autonomous Driving (AD) encounters significant safety hurdles in long-tail\nunforeseen driving scenarios, largely stemming from the non-interpretability\nand poor generalization of the deep neural networks within the AD system,\nparticularly in out-of-distribution and uncertain data. To this end, this paper\nexplores the integration of Large Language Models (LLMs) into AD systems,\nleveraging their robust common-sense knowledge and reasoning abilities. The\nproposed methodologies employ LLMs as intelligent decision-makers in behavioral\nplanning, augmented with a safety verifier shield for contextual safety\nlearning, for enhancing driving performance and safety. We present two key\nstudies in a simulated environment: an adaptive LLM-conditioned Model\nPredictive Control (MPC) and an LLM-enabled interactive behavior planning\nscheme with a state machine. Demonstrating superior performance and safety\nmetrics compared to state-of-the-art approaches, our approach shows the\npromising potential for using LLMs for autonomous vehicles.","updated":1711128541000,"published":1701141189000,"authors":["Yixuan Wang","Ruochen Jiao","Sinong Simon Zhan","Chengtian Lang","Chao Huang","Zhaoran Wang","Zhuoran Yang","Qi Zhu"],"comments":"Accepted to LLMAgent workshop @ICLR2024","categories":["cs.AI","cs.LG","cs.SY","eess.SY"],"primary_category":"cs.AI","doi":null,"journal_ref":null,"peer_reviewed":true},"15":{"arxiv_id":"2403.04732v2","url":"http:\/\/arxiv.org\/abs\/2403.04732v2","title":"How Far Are We from Intelligent Visual Deductive Reasoning?","summary":"Vision-Language Models (VLMs) such as GPT-4V have recently demonstrated\nincredible strides on diverse vision language tasks. We dig into vision-based\ndeductive reasoning, a more sophisticated but less explored realm, and find\npreviously unexposed blindspots in the current SOTA VLMs. Specifically, we\nleverage Raven's Progressive Matrices (RPMs), to assess VLMs' abilities to\nperform multi-hop relational and deductive reasoning relying solely on visual\nclues. We perform comprehensive evaluations of several popular VLMs employing\nstandard strategies such as in-context learning, self-consistency, and\nChain-of-thoughts (CoT) on three diverse datasets, including the Mensa IQ test,\nIntelligenceTest, and RAVEN. The results reveal that despite the impressive\ncapabilities of LLMs in text-based reasoning, we are still far from achieving\ncomparable proficiency in visual deductive reasoning. We found that certain\nstandard strategies that are effective when applied to LLMs do not seamlessly\ntranslate to the challenges presented by visual reasoning tasks. Moreover, a\ndetailed analysis reveals that VLMs struggle to solve these tasks mainly\nbecause they are unable to perceive and comprehend multiple, confounding\nabstract patterns in RPM examples.","updated":1709880428000,"published":1709836554000,"authors":["Yizhe Zhang","He Bai","Ruixiang Zhang","Jiatao Gu","Shuangfei Zhai","Josh Susskind","Navdeep Jaitly"],"comments":"ICLR 2024 AGI workshop. https:\/\/github.com\/apple\/ml-rpm-bench","categories":["cs.AI","cs.CL","cs.CV"],"primary_category":"cs.AI","doi":null,"journal_ref":null,"peer_reviewed":true},"16":{"arxiv_id":"2307.03067v2","url":"http:\/\/arxiv.org\/abs\/2307.03067v2","title":"DeepOnto: A Python Package for Ontology Engineering with Deep Learning","summary":"Integrating deep learning techniques, particularly language models (LMs),\nwith knowledge representation techniques like ontologies has raised widespread\nattention, urging the need of a platform that supports both paradigms. Although\npackages such as OWL API and Jena offer robust support for basic ontology\nprocessing features, they lack the capability to transform various types of\ninformation within ontologies into formats suitable for downstream deep\nlearning-based applications. Moreover, widely-used ontology APIs are primarily\nJava-based while deep learning frameworks like PyTorch and Tensorflow are\nmainly for Python programming. To address the needs, we present DeepOnto, a\nPython package designed for ontology engineering with deep learning. The\npackage encompasses a core ontology processing module founded on the\nwidely-recognised and reliable OWL API, encapsulating its fundamental features\nin a more \"Pythonic\" manner and extending its capabilities to incorporate other\nessential components including reasoning, verbalisation, normalisation,\ntaxonomy, projection, and more. Building on this module, DeepOnto offers a\nsuite of tools, resources, and algorithms that support various ontology\nengineering tasks, such as ontology alignment and completion, by harnessing\ndeep learning methods, primarily pre-trained LMs. In this paper, we also\ndemonstrate the practical utility of DeepOnto through two use-cases: the\nDigital Health Coaching in Samsung Research UK and the Bio-ML track of the\nOntology Alignment Evaluation Initiative (OAEI).","updated":1709950662000,"published":1688657702000,"authors":["Yuan He","Jiaoyan Chen","Hang Dong","Ian Horrocks","Carlo Allocca","Taehun Kim","Brahmananda Sapkota"],"comments":"Accepted by the Semantic Web Journal","categories":["cs.AI","cs.CL","cs.LG","cs.LO"],"primary_category":"cs.AI","doi":null,"journal_ref":null,"peer_reviewed":true},"17":{"arxiv_id":"2403.17873v1","url":"http:\/\/arxiv.org\/abs\/2403.17873v1","title":"Addressing Social Misattributions of Large Language Models: An\n  HCXAI-based Approach","summary":"Human-centered explainable AI (HCXAI) advocates for the integration of social\naspects into AI explanations. Central to the HCXAI discourse is the Social\nTransparency (ST) framework, which aims to make the socio-organizational\ncontext of AI systems accessible to their users. In this work, we suggest\nextending the ST framework to address the risks of social misattributions in\nLarge Language Models (LLMs), particularly in sensitive areas like mental\nhealth. In fact LLMs, which are remarkably capable of simulating roles and\npersonas, may lead to mismatches between designers' intentions and users'\nperceptions of social attributes, risking to promote emotional manipulation and\ndangerous behaviors, cases of epistemic injustice, and unwarranted trust. To\naddress these issues, we propose enhancing the ST framework with a fifth\n'W-question' to clarify the specific social attributions assigned to LLMs by\nits designers and users. This addition aims to bridge the gap between LLM\ncapabilities and user perceptions, promoting the ethically responsible\ndevelopment and use of LLM-based technology.","updated":1711472562000,"published":1711472562000,"authors":["Andrea Ferrario","Alberto Termine","Alessandro Facchini"],"comments":"Extended version of the manuscript accepted for the ACM CHI Workshop\n  on Human-Centered Explainable AI 2024 (HCXAI24)","categories":["cs.AI"],"primary_category":"cs.AI","doi":null,"journal_ref":null,"peer_reviewed":true},"18":{"arxiv_id":"2403.15875v1","url":"http:\/\/arxiv.org\/abs\/2403.15875v1","title":"LAMPER: LanguAge Model and Prompt EngineeRing for zero-shot time series\n  classification","summary":"This study constructs the LanguAge Model with Prompt EngineeRing (LAMPER)\nframework, designed to systematically evaluate the adaptability of pre-trained\nlanguage models (PLMs) in accommodating diverse prompts and their integration\nin zero-shot time series (TS) classification. We deploy LAMPER in experimental\nassessments using 128 univariate TS datasets sourced from the UCR archive. Our\nfindings indicate that the feature representation capacity of LAMPER is\ninfluenced by the maximum input token threshold imposed by PLMs.","updated":1711209157000,"published":1711209157000,"authors":["Zhicheng Du","Zhaotian Xie","Yan Tong","Peiwu Qin"],"comments":"Accepted as tiny paper in ICLR 2024","categories":["cs.AI","cs.CL"],"primary_category":"cs.AI","doi":null,"journal_ref":null,"peer_reviewed":true},"19":{"arxiv_id":"2403.16508v1","url":"http:\/\/arxiv.org\/abs\/2403.16508v1","title":"Return to Tradition: Learning Reliable Heuristics with Classical Machine\n  Learning","summary":"Current approaches for learning for planning have yet to achieve competitive\nperformance against classical planners in several domains, and have poor\noverall performance. In this work, we construct novel graph representations of\nlifted planning tasks and use the WL algorithm to generate features from them.\nThese features are used with classical machine learning methods which have up\nto 2 orders of magnitude fewer parameters and train up to 3 orders of magnitude\nfaster than the state-of-the-art deep learning for planning models. Our novel\napproach, WL-GOOSE, reliably learns heuristics from scratch and outperforms the\n$h^{\\text{FF}}$ heuristic in a fair competition setting. It also outperforms or\nties with LAMA on 4 out of 10 domains on coverage and 7 out of 10 domains on\nplan quality. WL-GOOSE is the first learning for planning model which achieves\nthese feats. Furthermore, we study the connections between our novel WL feature\ngeneration method, previous theoretically flavoured learning architectures, and\nDescription Logic Features for planning.","updated":1711352872000,"published":1711352872000,"authors":["Dillon Z. Chen","Felipe Trevizan","Sylvie Thi\u00e9baux"],"comments":"Extended version of ICAPS 2024 paper","categories":["cs.AI"],"primary_category":"cs.AI","doi":null,"journal_ref":null,"peer_reviewed":true},"20":{"arxiv_id":"2403.16289v1","url":"http:\/\/arxiv.org\/abs\/2403.16289v1","title":"Engineering Safety Requirements for Autonomous Driving with Large\n  Language Models","summary":"Changes and updates in the requirement artifacts, which can be frequent in\nthe automotive domain, are a challenge for SafetyOps. Large Language Models\n(LLMs), with their impressive natural language understanding and generating\ncapabilities, can play a key role in automatically refining and decomposing\nrequirements after each update. In this study, we propose a prototype of a\npipeline of prompts and LLMs that receives an item definition and outputs\nsolutions in the form of safety requirements. This pipeline also performs a\nreview of the requirement dataset and identifies redundant or contradictory\nrequirements. We first identified the necessary characteristics for performing\nHARA and then defined tests to assess an LLM's capability in meeting these\ncriteria. We used design science with multiple iterations and let experts from\ndifferent companies evaluate each cycle quantitatively and qualitatively.\nFinally, the prototype was implemented at a case company and the responsible\nteam evaluated its efficiency.","updated":1711312851000,"published":1711312851000,"authors":["Ali Nouri","Beatriz Cabrero-Daniel","Fredrik T\u00f6rner","H\u0227kan Sivencrona","Christian Berger"],"comments":"Accepted in 32nd IEEE International Requirements Engineering 2024\n  conference, Iceland","categories":["cs.AI"],"primary_category":"cs.AI","doi":null,"journal_ref":null,"peer_reviewed":true},"21":{"arxiv_id":"2403.17419v1","url":"http:\/\/arxiv.org\/abs\/2403.17419v1","title":"AI Safety: Necessary, but insufficient and possibly problematic","summary":"This article critically examines the recent hype around AI safety. We first\nstart with noting the nature of the AI safety hype as being dominated by\ngovernments and corporations, and contrast it with other avenues within AI\nresearch on advancing social good. We consider what 'AI safety' actually means,\nand outline the dominant concepts that the digital footprint of AI safety\naligns with. We posit that AI safety has a nuanced and uneasy relationship with\ntransparency and other allied notions associated with societal good, indicating\nthat it is an insufficient notion if the goal is that of societal good in a\nbroad sense. We note that the AI safety debate has already influenced some\nregulatory efforts in AI, perhaps in not so desirable directions. We also share\nour concerns on how AI safety may normalize AI that advances structural harm\nthrough providing exploitative and harmful AI with a veneer of safety.","updated":1711433922000,"published":1711433922000,"authors":["Deepak P"],"comments":"AI & Soc (2024)","categories":["cs.AI","cs.CY"],"primary_category":"cs.AI","doi":"10.1007\/s00146-024-01899-y","journal_ref":null,"peer_reviewed":true},"22":{"arxiv_id":"2402.01786v2","url":"http:\/\/arxiv.org\/abs\/2402.01786v2","title":"COA-GPT: Generative Pre-trained Transformers for Accelerated Course of\n  Action Development in Military Operations","summary":"The development of Courses of Action (COAs) in military operations is\ntraditionally a time-consuming and intricate process. Addressing this\nchallenge, this study introduces COA-GPT, a novel algorithm employing Large\nLanguage Models (LLMs) for rapid and efficient generation of valid COAs.\nCOA-GPT incorporates military doctrine and domain expertise to LLMs through\nin-context learning, allowing commanders to input mission information - in both\ntext and image formats - and receive strategically aligned COAs for review and\napproval. Uniquely, COA-GPT not only accelerates COA development, producing\ninitial COAs within seconds, but also facilitates real-time refinement based on\ncommander feedback. This work evaluates COA-GPT in a military-relevant scenario\nwithin a militarized version of the StarCraft II game, comparing its\nperformance against state-of-the-art reinforcement learning algorithms. Our\nresults demonstrate COA-GPT's superiority in generating strategically sound\nCOAs more swiftly, with added benefits of enhanced adaptability and alignment\nwith commander intentions. COA-GPT's capability to rapidly adapt and update\nCOAs during missions presents a transformative potential for military planning,\nparticularly in addressing planning discrepancies and capitalizing on emergent\nwindows of opportunities.","updated":1711639362000,"published":1706824269000,"authors":["Vinicius G. Goecks","Nicholas Waytowich"],"comments":"Accepted at the NATO Science and Technology Organization Symposium\n  (ICMCIS) organized by the Information Systems Technology (IST) Panel,\n  IST-205-RSY - the ICMCIS, held in Koblenz, Germany, 23-24 April 2024","categories":["cs.AI","cs.CL","cs.HC","cs.LG","I.2.6; I.2.7; J.7"],"primary_category":"cs.AI","doi":null,"journal_ref":null,"peer_reviewed":true},"23":{"arxiv_id":"2403.10112v1","url":"http:\/\/arxiv.org\/abs\/2403.10112v1","title":"Single- and Multi-Agent Private Active Sensing: A Deep Neuroevolution\n  Approach","summary":"In this paper, we focus on one centralized and one decentralized problem of\nactive hypothesis testing in the presence of an eavesdropper. For the\ncentralized problem including a single legitimate agent, we present a new\nframework based on NeuroEvolution (NE), whereas, for the decentralized problem,\nwe develop a novel NE-based method for solving collaborative multi-agent tasks,\nwhich interestingly maintains all computational benefits of single-agent NE.\nThe superiority of the proposed EAHT approaches over conventional active\nhypothesis testing policies, as well as learning-based methods, is validated\nthrough numerical investigations in an example use case of anomaly detection\nover wireless sensor networks.","updated":1710492956000,"published":1710492956000,"authors":["George Stamatelis","Angelos-Nikolaos Kanatas","Ioannis Asprogerakas","George C. Alexandropoulos"],"comments":"7 pages, 5 figures, accepted at IEEE ICC 2024 (to be presented)","categories":["cs.AI","cs.CR","cs.MA","cs.NE"],"primary_category":"cs.AI","doi":null,"journal_ref":null,"peer_reviewed":true},"24":{"arxiv_id":"2403.07131v1","url":"http:\/\/arxiv.org\/abs\/2403.07131v1","title":"Bigraph Matching Weighted with Learnt Incentive Function for Multi-Robot\n  Task Allocation","summary":"Most real-world Multi-Robot Task Allocation (MRTA) problems require fast and\nefficient decision-making, which is often achieved using heuristics-aided\nmethods such as genetic algorithms, auction-based methods, and bipartite graph\nmatching methods. These methods often assume a form that lends better\nexplainability compared to an end-to-end (learnt) neural network based policy\nfor MRTA. However, deriving suitable heuristics can be tedious, risky and in\nsome cases impractical if problems are too complex. This raises the question:\ncan these heuristics be learned? To this end, this paper particularly develops\na Graph Reinforcement Learning (GRL) framework to learn the heuristics or\nincentives for a bipartite graph matching approach to MRTA. Specifically a\nCapsule Attention policy model is used to learn how to weight task\/robot\npairings (edges) in the bipartite graph that connects the set of tasks to the\nset of robots. The original capsule attention network architecture is\nfundamentally modified by adding encoding of robots' state graph, and two\nMultihead Attention based decoders whose output are used to construct a\nLogNormal distribution matrix from which positive bigraph weights can be drawn.\nThe performance of this new bigraph matching approach augmented with a\nGRL-derived incentive is found to be at par with the original bigraph matching\napproach that used expert-specified heuristics, with the former offering\nnotable robustness benefits. During training, the learned incentive policy is\nfound to get initially closer to the expert-specified incentive and then\nslightly deviate from its trend.","updated":1710186908000,"published":1710186908000,"authors":["Steve Paul","Nathan Maurer","Souma Chowdhury"],"comments":"This paper was accepted for presentation in proceedings of IEEE\n  International Conference on Robotics and Automation 2024","categories":["cs.AI","cs.MA"],"primary_category":"cs.AI","doi":null,"journal_ref":null,"peer_reviewed":true},"25":{"arxiv_id":"2403.05112v1","url":"http:\/\/arxiv.org\/abs\/2403.05112v1","title":"RLPeri: Accelerating Visual Perimetry Test with Reinforcement Learning\n  and Convolutional Feature Extraction","summary":"Visual perimetry is an important eye examination that helps detect vision\nproblems caused by ocular or neurological conditions. During the test, a\npatient's gaze is fixed at a specific location while light stimuli of varying\nintensities are presented in central and peripheral vision. Based on the\npatient's responses to the stimuli, the visual field mapping and sensitivity\nare determined. However, maintaining high levels of concentration throughout\nthe test can be challenging for patients, leading to increased examination\ntimes and decreased accuracy.\n  In this work, we present RLPeri, a reinforcement learning-based approach to\noptimize visual perimetry testing. By determining the optimal sequence of\nlocations and initial stimulus values, we aim to reduce the examination time\nwithout compromising accuracy. Additionally, we incorporate reward shaping\ntechniques to further improve the testing performance. To monitor the patient's\nresponses over time during testing, we represent the test's state as a pair of\n3D matrices. We apply two different convolutional kernels to extract spatial\nfeatures across locations as well as features across different stimulus values\nfor each location. Through experiments, we demonstrate that our approach\nresults in a 10-20% reduction in examination time while maintaining the\naccuracy as compared to state-of-the-art methods. With the presented approach,\nwe aim to make visual perimetry testing more efficient and patient-friendly,\nwhile still providing accurate results.","updated":1709882383000,"published":1709882383000,"authors":["Tanvi Verma","Linh Le Dinh","Nicholas Tan","Xinxing Xu","Chingyu Cheng","Yong Liu"],"comments":"Published at AAAI-24","categories":["cs.AI"],"primary_category":"cs.AI","doi":null,"journal_ref":"The 38th Annual AAAI Conference on Artificial Intelligence, 2024","peer_reviewed":true},"26":{"arxiv_id":"2403.00431v1","url":"http:\/\/arxiv.org\/abs\/2403.00431v1","title":"Robotic Process Automation as a Driver for Sustainable Innovation and\n  Entrepreneurship","summary":"Technological innovation plays a crucial role in driving economic growth and\ndevelopment. In this study, we investigate the extent to which technological\ninnovation contributes to a more sustainable future and fosters\nentrepreneurship. To examine this, we focus on robotic process automation (RPA)\nhighly relevant technology. We conducted a comprehensive analysis by examining\nthe usage of RPA and its impact on environmental, social, and governance (ESG)\nfactors. Our research involved gathering data from the 300 largest companies in\nterms of market capitalization. We assessed whether these companies used RPA\nand obtained their corresponding ESG ratings. To investigate the relationship\nbetween RPA and ESG, we employed a contingency table analysis, which involved\ncategorizing the data based on ESG ratings. We further used Pearson's\nChi-square Test of Independence to assess the impact of RPA on ESG. Our\nfindings revealed a statistically significant association between RPA and ESG\nratings, indicating their interconnection. The calculated value for Pearson's\nChi-square Test of Independence was 6.54, with a corresponding p-value of\n0.0381. This indicates that at a significance level of five percent, the RPA\nand ESG variables depend on each other. These results suggest that RPA,\nrepresentative of modern technologies, likely influences the achievement of a\nsustainable future and the promotion of entrepreneurship. In conclusion, our\nstudy provides empirical evidence supporting the notion that technological\ninnovations such as RPA have the potential to positively shape sustainability\nefforts and entrepreneurial endeavours.","updated":1709289168000,"published":1709289168000,"authors":["Petr Prucha"],"comments":"XB-CON International Conference 2023, Zelezna Ruda, Czechia","categories":["cs.CY"],"primary_category":"cs.CY","doi":null,"journal_ref":null,"peer_reviewed":true},"27":{"arxiv_id":"2403.17911v1","url":"http:\/\/arxiv.org\/abs\/2403.17911v1","title":"Domain-Specific Evaluation Strategies for AI in Journalism","summary":"News organizations today rely on AI tools to increase efficiency and\nproductivity across various tasks in news production and distribution. These\ntools are oriented towards stakeholders such as reporters, editors, and\nreaders. However, practitioners also express reservations around adopting AI\ntechnologies into the newsroom, due to the technical and ethical challenges\ninvolved in evaluating AI technology and its return on investments. This is to\nsome extent a result of the lack of domain-specific strategies to evaluate AI\nmodels and applications. In this paper, we consider different aspects of AI\nevaluation (model outputs, interaction, and ethics) that can benefit from\ndomain-specific tailoring, and suggest examples of how journalistic\nconsiderations can lead to specialized metrics or strategies. In doing so, we\nlay out a potential framework to guide AI evaluation in journalism, such as\nseen in other disciplines (e.g. law, healthcare). We also consider directions\nfor future work, as well as how our approach might generalize to other domains.","updated":1711475245000,"published":1711475245000,"authors":["Sachita Nishal","Charlotte Li","Nicholas Diakopoulos"],"comments":"Accepted to the Workshop on Evaluating AI at the ACM CHI conference\n  on Human Factors in Computing Systems","categories":["cs.CY","I.2.1; H.5; K.4"],"primary_category":"cs.CY","doi":null,"journal_ref":null,"peer_reviewed":true},"28":{"arxiv_id":"2403.11952v1","url":"http:\/\/arxiv.org\/abs\/2403.11952v1","title":"Exploring Estonia's Open Government Data Development as a Journey\n  towards Excellence: Unveiling the Progress of Local Governments in Open Data\n  Provision","summary":"Estonia has a global reputation of a digital state or e-country. However,\ndespite the success in digital governance, the country has faced challenges in\nthe realm of Open Government Data (OGD) area, with significant advancements in\nits OGD ecosystem, as reflected in various open data rankings from 2020 and\nonwards, in the recent years being recognized among trend-setters. This paper\naims to explore the evolution and positioning of Estonia's OGD development,\nencompassing national and local levels, through an integrated analysis of\nvarious indices, primary data from the Estonian OGD portal, and a thorough\nliterature review. The research shows that Estonia has made progress in the\nnational level open data ecosystem, primarily due to improvements in the OGD\nportal usability and legislation amendments. However, the local level is not as\ndeveloped, with local governments lagging behind in OGD provision. The\nliterature review highlights the lack of previous research focusing on Estonian\nand European local open data, emphasizing the need for future studies to\nexplore the barriers and enablers of municipal OGD. This study contributes to a\nnuanced understanding of Estonia's dynamic journey in the OGD landscape,\nshedding light on both achievements and areas warranting further attention for\nestablishing a sustainable open data ecosystem.","updated":1710780605000,"published":1710780605000,"authors":["Katrin Rajam\u00e4e-Soosaar","Anastasija Nikiforova"],"comments":"This paper has been accepted for publication in Proceedings of the\n  25th Annual International Conference on Digital Government Research and this\n  is a pre-print version of the manuscript. It is posted here for your personal\n  use. Not for redistribution","categories":["cs.CY","cs.CE","cs.DB","cs.SE","cs.SI"],"primary_category":"cs.CY","doi":null,"journal_ref":null,"peer_reviewed":true},"29":{"arxiv_id":"2403.08451v1","url":"http:\/\/arxiv.org\/abs\/2403.08451v1","title":"An Integrated Usability Framework for Evaluating Open Government Data\n  Portals: Comparative Analysis of EU and GCC Countries","summary":"This study explores the critical role of open government data (OGD) portals\nin fostering transparency and collaboration between diverse stakeholders.\nRecognizing the challenges of usability, communication with diverse\npopulations, and strategic value creation, this paper develops an integrated\nframework for evaluating OGD portal effectiveness that accommodates user\ndiversity (regardless of their data literacy and language), evaluates\ncollaboration and participation, and the ability of users to explore and\nunderstand the data provided through them. The framework is validated by\napplying it to 33 national portals across European Union and Gulf Cooperation\nCouncil (GCC) countries, as a result of which we rank OGD portals, identify\nsome good practices that lower-performing portals can learn from, and common\nshortcomings. Notably, the study unveils the competitive and innovative nature\nof GCC OGD portals, pinpointing specific improvement areas such as multilingual\nsupport and data understandability. The findings underscore the growing trend\nof exposing data quality metrics and advocate for enhanced two-way\ncommunication channels between users and portal representatives. Overall, the\nstudy contributes to accelerating the development of user-friendly,\ncollaborative, and sustainable OGD portals while addressing gaps identified in\nprevious research.","updated":1710331602000,"published":1710331602000,"authors":["Fillip Molodtsov","Anastasija Nikiforova"],"comments":"This paper has been accepted for publication in Proceedings of the\n  25th Annual International Conference on Digital Government Research and this\n  is a preprint version of the manuscript","categories":["cs.CY","cs.SE"],"primary_category":"cs.CY","doi":null,"journal_ref":null,"peer_reviewed":true},"30":{"arxiv_id":"2403.14686v1","url":"http:\/\/arxiv.org\/abs\/2403.14686v1","title":"Evaluating Pedagogical Incentives in Undergraduate Computing: A Mixed\n  Methods Approach Using Learning Analytics","summary":"In the context of higher education's evolving dynamics post-COVID-19, this\npaper assesses the impact of new pedagogical incentives implemented in a\nfirst-year undergraduate computing module at University College London. We\nemploy a mixed methods approach, combining learning analytics with qualitative\ndata, to evaluate the effectiveness of these incentives on increasing student\nengagement.\n  A longitudinal overview of resource interactions is mapped through Bayesian\nnetwork analysis of Moodle activity logs from 204 students. This analysis\nidentifies early resource engagement as a predictive indicator of continued\nengagement while also suggesting that the new incentives disproportionately\nbenefit highly engaged students. Focus group discussions complement this\nanalysis, providing insights into student perceptions of the pedagogical\nchanges and the module design. These qualitative findings underscore the\nchallenge of sustaining engagement through the new incentives and highlight the\nimportance of communication in blended learning environments.\n  Our paper introduces an interpretable and actionable model for student\nengagement, which integrates objective, data-driven analysis with students'\nperspectives. This model provides educators with a tool to evaluate and improve\ninstructional strategies. By demonstrating the effectiveness of our mixed\nmethods approach in capturing the intricacies of student behaviour in digital\nlearning environments, we underscore the model's potential to improve online\npedagogical practices across diverse educational settings.","updated":1710347978000,"published":1710347978000,"authors":["Laura J. Johnston","Takoua Jendoubi"],"comments":"5 pages, 1 figure. Accepted by IEEE Global Engineering Education\n  Conference 2024","categories":["cs.CY"],"primary_category":"cs.CY","doi":null,"journal_ref":null,"peer_reviewed":true},"31":{"arxiv_id":"2403.07082v1","url":"http:\/\/arxiv.org\/abs\/2403.07082v1","title":"Exploring the Impact of ChatGPT on Student Interactions in\n  Computer-Supported Collaborative Learning","summary":"The growing popularity of generative AI, particularly ChatGPT, has sparked\nboth enthusiasm and caution among practitioners and researchers in education.\nTo effectively harness the full potential of ChatGPT in educational contexts,\nit is crucial to analyze its impact and suitability for different educational\npurposes. This paper takes an initial step in exploring the applicability of\nChatGPT in a computer-supported collaborative learning (CSCL) environment.\nUsing statistical analysis, we validate the shifts in student interactions\nduring an asynchronous group brainstorming session by introducing ChatGPT as an\ninstantaneous question-answering agent.","updated":1710181098000,"published":1710181098000,"authors":["Han Kyul Kim","Shriniwas Nayak","Aleyeh Roknaldin","Xiaoci Zhang","Marlon Twyman","Stephen Lu"],"comments":"AAAI2024 Workshop on AI for Education (AI4ED)","categories":["cs.CY"],"primary_category":"cs.CY","doi":null,"journal_ref":null,"peer_reviewed":true},"32":{"arxiv_id":"2401.09210v2","url":"http:\/\/arxiv.org\/abs\/2401.09210v2","title":"Narratives of Collective Action in YouTube's Discourse on Veganism","summary":"Narratives can be powerful tools for inspiring action on pressing societal\nissues such as climate change. While social science theories offer frameworks\nfor understanding the narratives that arise within collective movements, these\nare rarely applied to the vast data available from social media platforms,\nwhich play a significant role in shaping public opinion and mobilizing\ncollective action. This gap in the empirical evaluation of online narratives\nlimits our understanding of their relationship with public response. In this\nstudy, we focus on plant-based diets as a form of pro-environmental action and\nemploy natural language processing to operationalize a theoretical framework of\nmoral narratives specific to the vegan movement. We apply this framework to\nnarratives found in YouTube videos promoting environmental initiatives such as\nVeganuary, Meatless March, and No Meat May. Our analysis reveals that several\nnarrative types, as defined by the theory, are empirically present in the data.\nTo identify narratives with the potential to elicit positive public engagement,\nwe used text processing to estimate the proportion of comments supporting\ncollective action across narrative types. Video narratives advocating social\nfight, whether through protest or through efforts to convert others to the\ncause, are associated with a stronger sense of collective action in the\nrespective comments. These narrative types also demonstrate increased semantic\ncoherence and alignment between the message and public response, markers\ntypically associated with successful collective action. Our work offers new\ninsights into the complex factors that influence the emergence of collective\naction, thereby informing the development of effective communication strategies\nwithin social movements.","updated":1711625999000,"published":1705499076000,"authors":["Arianna Pera","Luca Maria Aiello"],"comments":"15 pages, 7 figures, 7 tables. Accepted at ICWSM 2024","categories":["cs.CY","physics.soc-ph"],"primary_category":"cs.CY","doi":null,"journal_ref":null,"peer_reviewed":true},"33":{"arxiv_id":"2308.10148v3","url":"http:\/\/arxiv.org\/abs\/2308.10148v3","title":"Privacy Perceptions and Behaviors of Google Personal Account Holders in\n  Saudi Arabia","summary":"While privacy perceptions and behaviors have been investigated in Western\nsocieties, little is known about these issues in non-Western societies. To\nbridge this gap, we interviewed 30 Google personal account holders in Saudi\nArabia about their privacy perceptions and behaviors regarding the activity\ndata that Google saves about them. Our study focuses on Google's Activity\nControls, which enable users to control whether, and how, Google saves their\nWeb \\& App Activity, Location History, and YouTube History. Our results show\nthat although most participants have some level of awareness about Google's\ndata practices and the Activity Controls, many have only vague awareness, and\nthe majority have not used the available controls. When participants viewed\ntheir saved activity data, many were surprised by what had been saved. While\nmany participants find Google's use of their data to improve the services\nprovided to them acceptable, the majority find the use of their data for ad\npurposes unacceptable. We observe that our Saudi participants exhibit similar\ntrends and patterns in privacy awareness, attitudes, preferences, concerns, and\nbehaviors to what has been found in studies in the US. Our results emphasize\nthe need for: 1) improved techniques to inform users about privacy settings\nduring account sign-up, to remind users about their settings, and to raise\nawareness about privacy settings; 2) improved privacy setting interfaces to\nreduce the costs that deter many users from changing the settings; and 3)\nfurther research to explore privacy concerns in non-Western cultures.","updated":1710788822000,"published":1692501918000,"authors":["Eman Alashwali","Lorrie Faith Cranor"],"comments":"To appear in Proceedings of Human Computer Interaction International\n  (HCII) 2024","categories":["cs.CY","cs.CR","cs.HC"],"primary_category":"cs.CY","doi":null,"journal_ref":null,"peer_reviewed":true},"34":{"arxiv_id":"2403.02908v1","url":"http:\/\/arxiv.org\/abs\/2403.02908v1","title":"Preserving Tangible and Intangible Cultural Heritage: the Cases of\n  Volterra and Atari","summary":"At first glance, the ruins of the Roman Theatre in the Italian town of\nVolterra have little in common with cassette tapes containing Atari games. One\nis certainly considered an important historical landmark, while the consensus\non the importance of the other is partial at best. Still, both are remnants of\ntimes vastly different from the present and are at risk of oblivion. Unearthed\narchitectural structures are exposed to the elements just as the deteriorating\nsignals stored on magnetic tapes. However, the rate of deterioration is much\nfaster with the magnetic media, as their life expectancy is counted in decades,\nwhereas the Roman Theater, which is already in ruin, measures its lifespan in\ncenturies. Hence, both would benefit from some form of digital preservation and\nreconstruction. In this panel, we discuss how to sustainably preserve tangible\nand intangible cultural artifacts for future generations.","updated":1709641088000,"published":1709641088000,"authors":["Maciej Grzeszczuk","Kinga Skorupska","Pawe\u0142 Grabarczyk","W\u0142adys\u0142aw Fuchs","Paul F. Aubin","Mark E. Dietrick","Barbara Karpowicz","Rafa\u0142 Mas\u0142yk","Pavlo Zinevych","Wiktor Stawski","Stanis\u0142aw Knapi\u0144ski","Wies\u0142aw Kope\u0107"],"comments":"8 pages, including 1 page of bibliography, 9 figures. Panel summary\n  to be published in proceedings from 11th Machine Intelligence and Digital\n  Interaction MIDI Conference","categories":["cs.CY","cs.DL","cs.HC"],"primary_category":"cs.CY","doi":null,"journal_ref":null,"peer_reviewed":true},"35":{"arxiv_id":"2310.06155v3","url":"http:\/\/arxiv.org\/abs\/2310.06155v3","title":"CoQuest: Exploring Research Question Co-Creation with an LLM-based Agent","summary":"Developing novel research questions (RQs) often requires extensive literature\nreviews, especially in interdisciplinary fields. To support RQ development\nthrough human-AI co-creation, we leveraged Large Language Models (LLMs) to\nbuild an LLM-based agent system named CoQuest. We conducted an experiment with\n20 HCI researchers to examine the impact of two interaction designs:\nbreadth-first and depth-first RQ generation. The findings revealed that\nparticipants perceived the breadth-first approach as more creative and\ntrustworthy upon task completion. Conversely, during the task, participants\nconsidered the depth-first generated RQs as more creative. Additionally, we\ndiscovered that AI processing delays allowed users to reflect on multiple RQs\nsimultaneously, leading to a higher quantity of generated RQs and an enhanced\nsense of control. Our work makes both theoretical and practical contributions\nby proposing and evaluating a mental model for human-AI co-creation of RQs. We\nalso address potential ethical issues, such as biases and over-reliance on AI,\nadvocating for using the system to improve human research creativity rather\nthan automating scientific inquiry.","updated":1710967383000,"published":1696885527000,"authors":["Yiren Liu","Si Chen","Haocong Cheng","Mengxia Yu","Xiao Ran","Andrew Mo","Yiliu Tang","Yun Huang"],"comments":"Accepted to SIGCHI 2024","categories":["cs.HC","cs.CE"],"primary_category":"cs.HC","doi":null,"journal_ref":null,"peer_reviewed":true},"36":{"arxiv_id":"2403.01783v1","url":"http:\/\/arxiv.org\/abs\/2403.01783v1","title":"Towards A Diffractive Analysis of Prompt-Based Generative AI","summary":"Recent developments in prompt-based generative AI has given rise to discourse\nsurrounding the perceived ethical concerns, economic implications, and\nconsequences for the future of cultural production. As generative imagery\nbecomes pervasive in mainstream society, dominated primarily by emerging\nindustry leaders, we encourage that the role of the CHI community be one of\ninquiry; to investigate the numerous ways in which generative AI has the\npotential to, and already is, augmenting human creativity. In this paper, we\nconducted a diffractive analysis exploring the potential role of prompt-based\ninterfaces in artists' creative practice. Over a two week period, seven visual\nartists were given access to a personalised instance of Stable Diffusion,\nfine-tuned on a dataset of their work. In the following diffractive analysis,\nwe identified two dominant modes adopted by participants, AI for ideation, and\nAI for production. We furthermore present a number of ethical design\nconsiderations for the future development of generative AI interfaces.","updated":1709537029000,"published":1709537029000,"authors":["Nina Rajcic","Maria Teresa Llano","Jon McCormack"],"comments":"Preprint of paper accepted for CHI 2024","categories":["cs.HC","J.5; H.1.2; H.5"],"primary_category":"cs.HC","doi":"10.1145\/3613904.3641971","journal_ref":null,"peer_reviewed":true},"37":{"arxiv_id":"2403.08940v1","url":"http:\/\/arxiv.org\/abs\/2403.08940v1","title":"A Virtual Environment for Collaborative Inspection in Additive\n  Manufacturing","summary":"Additive manufacturing (AM) techniques have been used to enhance the design\nand fabrication of complex components for various applications in the medical,\naerospace, energy, and consumer products industries. A defining feature for\nmany AM parts is the complex internal geometry enabled by the printing process.\nHowever, inspecting these internal structures requires volumetric imaging,\ni.e., X-ray CT, leading to the well-known challenge of visualizing complex 3D\ngeometries using 2D desktop interfaces. Furthermore, existing tools are limited\nto single-user systems making it difficult to jointly discuss or share findings\nwith a larger team, i.e., the designers, manufacturing experts, and evaluation\nteam. In this work, we present a collaborative virtual reality (VR) for the\nexploration and inspection of AM parts. Geographically separated experts can\nvirtually inspect and jointly discuss data. It also supports VR and non-VR\nusers, who can be spectators in the VR environment. Various features for data\nexploration and inspection are developed and enhanced via real-time\nsynchronization. We followed usability and interface verification guidelines\nusing Nielsen's heuristics approach. Furthermore, we conducted exploratory and\nsemi-structured interviews with domain experts to collect qualitative feedback.\nResults reveal potential benefits, applicability, and current limitations. The\nproposed collaborative VR environment provides a new basis and opens new\nresearch directions for virtual inspection and team collaboration in AM\nsettings.","updated":1710360976000,"published":1710360976000,"authors":["Vuthea Chheang","Brian Thomas Weston","Robert William Cerda","Brian Au","Brian Giera","Peer-Timo Bremer","Haichao Miao"],"comments":"Conditionally Accepted - CHI LBW 2024","categories":["cs.HC","cs.DC"],"primary_category":"cs.HC","doi":null,"journal_ref":null,"peer_reviewed":true},"38":{"arxiv_id":"2403.10851v1","url":"http:\/\/arxiv.org\/abs\/2403.10851v1","title":"GustosonicSense: Towards understanding the design of playful gustosonic\n  eating experiences","summary":"The pleasure that often comes with eating can be further enhanced with\nintelligent technology, as the field of human-food interaction suggests.\nHowever, knowledge on how to design such pleasure-supporting eating systems is\nlimited. To begin filling this knowledge gap, we designed \"GustosonicSense\", a\nnovel gustosonic eating system that utilizes wireless earbuds for sensing\ndifferent eating and drinking actions with a machine learning algorithm and\ntrigger playful sounds as a way to facilitate pleasurable eating experiences.\nWe present the findings from our design and a study that revealed how we can\nsupport the \"stimulation\", \"hedonism\", and \"reflexivity\" for playful human-food\ninteractions. Ultimately, with our work, we aim to support interaction\ndesigners in facilitating playful experiences with food.","updated":1710576669000,"published":1710576669000,"authors":["Yan Wang","Humphrey O. Obie","Zhuying Li","Flora D. Salim","John Grundy","Florian 'Floyd' Mueller"],"comments":"To appear at CHI'24: The ACM Conference on Human Factors in Computing\n  Systems (CHI), Honolulu, Hawaii, 2024","categories":["cs.HC","cs.MM"],"primary_category":"cs.HC","doi":null,"journal_ref":null,"peer_reviewed":true},"39":{"arxiv_id":"2403.04760v1","url":"http:\/\/arxiv.org\/abs\/2403.04760v1","title":"iScore: Visual Analytics for Interpreting How Language Models\n  Automatically Score Summaries","summary":"The recent explosion in popularity of large language models (LLMs) has\ninspired learning engineers to incorporate them into adaptive educational tools\nthat automatically score summary writing. Understanding and evaluating LLMs is\nvital before deploying them in critical learning environments, yet their\nunprecedented size and expanding number of parameters inhibits transparency and\nimpedes trust when they underperform. Through a collaborative user-centered\ndesign process with several learning engineers building and deploying summary\nscoring LLMs, we characterized fundamental design challenges and goals around\ninterpreting their models, including aggregating large text inputs, tracking\nscore provenance, and scaling LLM interpretability methods. To address their\nconcerns, we developed iScore, an interactive visual analytics tool for\nlearning engineers to upload, score, and compare multiple summaries\nsimultaneously. Tightly integrated views allow users to iteratively revise the\nlanguage in summaries, track changes in the resulting LLM scores, and visualize\nmodel weights at multiple levels of abstraction. To validate our approach, we\ndeployed iScore with three learning engineers over the course of a month. We\npresent a case study where interacting with iScore led a learning engineer to\nimprove their LLM's score accuracy by three percentage points. Finally, we\nconducted qualitative interviews with the learning engineers that revealed how\niScore enabled them to understand, evaluate, and build trust in their LLMs\nduring deployment.","updated":1709837799000,"published":1709837799000,"authors":["Adam Coscia","Langdon Holmes","Wesley Morris","Joon Suh Choi","Scott Crossley","Alex Endert"],"comments":"Accepted to IUI 2024. 16 pages, 5 figures, 1 table. For a demo video,\n  see https:\/\/youtu.be\/EYJX-_fQPf0 . For a live demo, visit\n  https:\/\/adamcoscia.com\/papers\/iscore\/demo\/ . The source code is available at\n  https:\/\/github.com\/AdamCoscia\/iScore","categories":["cs.HC","cs.AI","cs.CY","cs.LG"],"primary_category":"cs.HC","doi":"10.1145\/3640543.3645142","journal_ref":null,"peer_reviewed":true},"40":{"arxiv_id":"2403.09308v1","url":"http:\/\/arxiv.org\/abs\/2403.09308v1","title":"Enabling Waypoint Generation for Collaborative Robots using LLMs and\n  Mixed Reality","summary":"Programming a robotic is a complex task, as it demands the user to have a\ngood command of specific programming languages and awareness of the robot's\nphysical constraints. We propose a framework that simplifies robot deployment\nby allowing direct communication using natural language. It uses large language\nmodels (LLM) for prompt processing, workspace understanding, and waypoint\ngeneration. It also employs Augmented Reality (AR) to provide visual feedback\nof the planned outcome. We showcase the effectiveness of our framework with a\nsimple pick-and-place task, which we implement on a real robot. Moreover, we\npresent an early concept of expressive robot behavior and skill generation that\ncan be used to communicate with the user and learn new skills (e.g., object\ngrasping).","updated":1710417547000,"published":1710417547000,"authors":["Cathy Mengying Fang","Krzysztof Zieli\u0144ski","Pattie Maes","Joe Paradiso","Bruce Blumberg","Mikkel Baun Kj\u00e6rgaard"],"comments":"Submitted to VLMNM 2024 - Workshop, ICRA 2024. This work has been\n  submitted to the IEEE for possible publication. Copyright may be transferred\n  without notice, after which this version may no longer be accessible","categories":["cs.HC","cs.RO"],"primary_category":"cs.HC","doi":null,"journal_ref":null,"peer_reviewed":true},"41":{"arxiv_id":"2403.02928v1","url":"http:\/\/arxiv.org\/abs\/2403.02928v1","title":"User-Driven Adaptation: Tailoring Autonomous Driving Systems with\n  Dynamic Preferences","summary":"In the realm of autonomous vehicles, dynamic user preferences are critical\nyet challenging to accommodate. Existing methods often misrepresent these\npreferences, either by overlooking their dynamism or overburdening users as\nhumans often find it challenging to express their objectives mathematically.\nThe previously introduced framework, which interprets dynamic preferences as\ninherent uncertainty and includes a ``human-on-the-loop'' mechanism enabling\nusers to give feedback when dissatisfied with system behaviors, addresses this\ngap. In this study, we further enhance the approach with a user study of 20\nparticipants, focusing on aligning system behavior with user expectations\nthrough feedback-driven adaptation. The findings affirm the approach's ability\nto effectively merge algorithm-driven adjustments with user complaints, leading\nto improved participants' subjective satisfaction in autonomous systems.","updated":1709642694000,"published":1709642694000,"authors":["Mingyue Zhang","Jialong Li","Nianyu Li","Eunsuk Kang","Kenji Tei"],"comments":"accepted by CHI LBW 2024","categories":["cs.HC","cs.SE"],"primary_category":"cs.HC","doi":null,"journal_ref":null,"peer_reviewed":true},"42":{"arxiv_id":"2403.07997v1","url":"http:\/\/arxiv.org\/abs\/2403.07997v1","title":"Fast-Forward Reality: Authoring Error-Free Context-Aware Policies with\n  Real-Time Unit Tests in Extended Reality","summary":"Advances in ubiquitous computing have enabled end-user authoring of\ncontext-aware policies (CAPs) that control smart devices based on specific\ncontexts of the user and environment. However, authoring CAPs accurately and\navoiding run-time errors is challenging for end-users as it is difficult to\nforesee CAP behaviors under complex real-world conditions. We propose\nFast-Forward Reality, an Extended Reality (XR) based authoring workflow that\nenables end-users to iteratively author and refine CAPs by validating their\nbehaviors via simulated unit test cases. We develop a computational approach to\nautomatically generate test cases based on the authored CAP and the user's\ncontext history. Our system delivers each test case with immersive\nvisualizations in XR, facilitating users to verify the CAP behavior and\nidentify necessary refinements. We evaluated Fast-Forward Reality in a user\nstudy (N=12). Our authoring and validation process improved the accuracy of\nCAPs and the users provided positive feedback on the system usability.","updated":1710266738000,"published":1710266738000,"authors":["Xun Qian","Tianyi Wang","Xuhai Xu","Tanya R Jonker","Kashyap Todi"],"comments":"17 pages, 7 figures, ACM CHI 2024 Full Paper","categories":["cs.HC","H.5.2"],"primary_category":"cs.HC","doi":"10.1145\/3613904.3642158","journal_ref":null,"peer_reviewed":true},"43":{"arxiv_id":"2403.06267v1","url":"http:\/\/arxiv.org\/abs\/2403.06267v1","title":"FARPLS: A Feature-Augmented Robot Trajectory Preference Labeling System\n  to Assist Human Labelers' Preference Elicitation","summary":"Preference-based learning aims to align robot task objectives with human\nvalues. One of the most common methods to infer human preferences is by\npairwise comparisons of robot task trajectories. Traditional comparison-based\npreference labeling systems seldom support labelers to digest and identify\ncritical differences between complex trajectories recorded in videos. Our\nformative study (N = 12) suggests that individuals may overlook non-salient\ntask features and establish biased preference criteria during their preference\nelicitation process because of partial observations. In addition, they may\nexperience mental fatigue when given many pairs to compare, causing their label\nquality to deteriorate. To mitigate these issues, we propose FARPLS, a\nFeature-Augmented Robot trajectory Preference Labeling System. FARPLS\nhighlights potential outliers in a wide variety of task features that matter to\nhumans and extracts the corresponding video keyframes for easy review and\ncomparison. It also dynamically adjusts the labeling order according to users'\nfamiliarities, difficulties of the trajectory pair, and level of disagreements.\nAt the same time, the system monitors labelers' consistency and provides\nfeedback on labeling progress to keep labelers engaged. A between-subjects\nstudy (N = 42, 105 pairs of robot pick-and-place trajectories per person) shows\nthat FARPLS can help users establish preference criteria more easily and notice\nmore relevant details in the presented trajectories than the conventional\ninterface. FARPLS also improves labeling consistency and engagement, mitigating\nchallenges in preference elicitation without raising cognitive loads\nsignificantly","updated":1710090440000,"published":1710090440000,"authors":["Hanfang Lyu","Yuanchen Bai","Xin Liang","Ujaan Das","Chuhan Shi","Leiliang Gong","Yingchi Li","Mingfei Sun","Ming Ge","Xiaojuan Ma"],"comments":"Accepted to ACM Conference on Intelligent User Interfaces (IUI) 2024,\n  March 18-21, 2024, Greenville, SC, USA","categories":["cs.HC","cs.AI"],"primary_category":"cs.HC","doi":"10.1145\/3640543.3645145","journal_ref":null,"peer_reviewed":true},"44":{"arxiv_id":"2403.06039v1","url":"http:\/\/arxiv.org\/abs\/2403.06039v1","title":"A Preliminary Exploration of YouTubers' Use of Generative-AI in Content\n  Creation","summary":"Content creators increasingly utilize generative artificial intelligence\n(Gen-AI) on platforms such as YouTube, TikTok, Instagram, and various blogging\nsites to produce imaginative images, AI-generated videos, and articles using\nLarge Language Models (LLMs). Despite its growing popularity, there remains an\nunderexplored area concerning the specific domains where AI-generated content\nis being applied, and the methodologies content creators employ with Gen-AI\ntools during the creation process. This study initially explores this emerging\narea through a qualitative analysis of 68 YouTube videos demonstrating Gen-AI\nusage. Our research focuses on identifying the content domains, the variety of\ntools used, the activities performed, and the nature of the final products\ngenerated by Gen-AI in the context of user-generated content.","updated":1710026576000,"published":1710026576000,"authors":["Yao Lyu","He Zhang","Shuo Niu","Jie Cai"],"comments":"Accepted at CHI LBW 2024","categories":["cs.HC","cs.AI"],"primary_category":"cs.HC","doi":"10.1145\/3613905.3651057","journal_ref":null,"peer_reviewed":true},"45":{"arxiv_id":"2403.06823v2","url":"http:\/\/arxiv.org\/abs\/2403.06823v2","title":"Transparent AI Disclosure Obligations: Who, What, When, Where, Why, How","summary":"Advances in Generative Artificial Intelligence (AI) are resulting in\nAI-generated media output that is (nearly) indistinguishable from human-created\ncontent. This can drastically impact users and the media sector, especially\ngiven global risks of misinformation. While the currently discussed European AI\nAct aims at addressing these risks through Article 52's AI transparency\nobligations, its interpretation and implications remain unclear. In this early\nwork, we adopt a participatory AI approach to derive key questions based on\nArticle 52's disclosure obligations. We ran two workshops with researchers,\ndesigners, and engineers across disciplines (N=16), where participants\ndeconstructed Article 52's relevant clauses using the 5W1H framework. We\ncontribute a set of 149 questions clustered into five themes and 18 sub-themes.\nWe believe these can not only help inform future legal developments and\ninterpretations of Article 52, but also provide a starting point for\nHuman-Computer Interaction research to (re-)examine disclosure transparency\nfrom a human-centered AI lens.","updated":1710319233000,"published":1710171636000,"authors":["Abdallah El Ali","Karthikeya Puttur Venkatraj","Sophie Morosoli","Laurens Naudts","Natali Helberger","Pablo Cesar"],"comments":"Accepted to CHI 2024 Late-Breaking Work","categories":["cs.HC","cs.CY","H.5.m"],"primary_category":"cs.HC","doi":"10.1145\/3613905.3650750","journal_ref":null,"peer_reviewed":true},"46":{"arxiv_id":"2402.09494v2","url":"http:\/\/arxiv.org\/abs\/2402.09494v2","title":"Can AI and humans genuinely communicate?","summary":"Can AI and humans genuinely communicate? In this article, after giving some\nbackground and motivating my proposal (sections 1 to 3), I explore a way to\nanswer this question that I call the \"mental-behavioral methodology\" (sections\n4 and 5). This methodology follows the following three steps: First, spell out\nwhat mental capacities are sufficient for human communication (as opposed to\ncommunication more generally). Second, spell out the experimental paradigms\nrequired to test whether a behavior exhibits these capacities. Third, apply or\nadapt these paradigms to test whether an AI displays the relevant behaviors. If\nthe first two steps are successfully completed, and if the AI passes the tests\nwith human-like results, this constitutes evidence that this AI and humans can\ngenuinely communicate. This mental-behavioral methodology has the advantage\nthat we don't need to understand the workings of black-box algorithms, such as\nstandard deep neural networks. This is comparable to the fact that we don't\nneed to understand how human brains work to know that humans can genuinely\ncommunicate. This methodology also has its disadvantages and I will discuss\nsome of them (section 6).","updated":1711384364000,"published":1707915640000,"authors":["Constant Bonard"],"comments":"March 2024 preprint","categories":["cs.HC","cs.AI"],"primary_category":"cs.HC","doi":null,"journal_ref":null,"peer_reviewed":true},"47":{"arxiv_id":"2403.06431v1","url":"http:\/\/arxiv.org\/abs\/2403.06431v1","title":"From Fitting Participation to Forging Relationships: The Art of\n  Participatory ML","summary":"Participatory machine learning (ML) encourages the inclusion of end users and\npeople affected by ML systems in design and development processes. We\ninterviewed 18 participation brokers -- individuals who facilitate such\ninclusion and transform the products of participants' labour into inputs for an\nML artefact or system -- across a range of organisational settings and project\nlocations. Our findings demonstrate the inherent challenges of integrating\nmessy contextual information generated through participation with the\nstructured data formats required by ML workflows and the uneven power dynamics\nin project contexts. We advocate for evolution in the role of brokers to more\nequitably balance value generated in Participatory ML projects for design and\ndevelopment teams with value created for participants. To move beyond `fitting'\nparticipation to existing processes and empower participants to envision\nalternative futures through ML, brokers must become educators and advocates for\nend users, while attending to frustration and dissent from indirect\nstakeholders.","updated":1710132274000,"published":1710132274000,"authors":["Ned Cooper","Alex Zafiroglu"],"comments":"To appear in Proceedings of the 2024 CHI Conference on Human Factors\n  in Computing Systems (CHI '24)","categories":["cs.HC","cs.CY"],"primary_category":"cs.HC","doi":null,"journal_ref":null,"peer_reviewed":true},"48":{"arxiv_id":"2403.06034v1","url":"http:\/\/arxiv.org\/abs\/2403.06034v1","title":"Content Moderation Justice and Fairness on Social Media: Comparisons\n  Across Different Contexts and Platforms","summary":"Social media users may perceive moderation decisions by the platform\ndifferently, which can lead to frustration and dropout. This study investigates\nusers' perceived justice and fairness of online moderation decisions when they\nare exposed to various illegal versus legal scenarios, retributive versus\nrestorative moderation strategies, and user-moderated versus commercially\nmoderated platforms. We conduct an online experiment on 200 American social\nmedia users of Reddit and Twitter. Results show that retributive moderation\ndelivers higher justice and fairness for commercially moderated than for\nuser-moderated platforms in illegal violations; restorative moderation delivers\nhigher fairness for legal violations than illegal ones. We discuss the\nopportunities for platform policymaking to improve moderation system design.","updated":1710024606000,"published":1710024606000,"authors":["Jie Cai","Aashka Patel","Azadeh Naderi","Donghee Yvette Wohn"],"comments":"Accepted by CHI LBW 2024","categories":["cs.HC","cs.CY"],"primary_category":"cs.HC","doi":"10.1145\/3613905.3650882","journal_ref":null,"peer_reviewed":true},"49":{"arxiv_id":"2403.06651v1","url":"http:\/\/arxiv.org\/abs\/2403.06651v1","title":"SoniWeight Shoes: Investigating Effects and Personalization of a\n  Wearable Sound Device for Altering Body Perception and Behavior","summary":"Changes in body perception influence behavior and emotion and can be induced\nthrough multisensory feedback. Auditory feedback to one's actions can trigger\nsuch alterations; however, it is unclear which individual factors modulate\nthese effects. We employ and evaluate SoniWeight Shoes, a wearable device based\non literature for altering one's weight perception through manipulated footstep\nsounds. In a healthy population sample across a spectrum of individuals (n=84)\nwith varying degrees of eating disorder symptomatology, physical activity\nlevels, body concerns, and mental imagery capacities, we explore the effects of\nthree sound conditions (low-frequency, high-frequency and control) on extensive\nbody perception measures (demographic, behavioral, physiological,\npsychological, and subjective). Analyses revealed an impact of individual\ndifferences in each of these dimensions. Besides replicating previous findings,\nwe reveal and highlight the role of individual differences in body perception,\noffering avenues for personalized sonification strategies. Datasets, technical\nrefinements, and novel body map quantification tools are provided.","updated":1710159374000,"published":1710159374000,"authors":["A. D'Adamo","M. Roel-Lesur","L. Turmo-Vidal","M. M. Dehshibi","D. De La Prida","J. R. Diaz-Duran","L. A. Azpicueta-Ruiz","A. V\u00e4ljam\u00e4e","A. Tajadura-Jim\u00e9nez"],"comments":"Conditionally Accepted in CHI '24 Conference","categories":["cs.HC"],"primary_category":"cs.HC","doi":"10.1145\/3613904.3642651","journal_ref":null,"peer_reviewed":true},"50":{"arxiv_id":"2403.08041v1","url":"http:\/\/arxiv.org\/abs\/2403.08041v1","title":"What would Plato say? Concepts and notions from Greek philosophy applied\n  to gamification mechanics for a meaningful and ethical gamification","summary":"Gamification, the integration of game mechanics in non-game settings, has\nbecome increasingly prevalent in various digital platforms; however, its\nethical and societal impacts are often overlooked. This paper delves into how\nPlatonic and Aristotelian philosophies can provide a critical framework for\nunderstanding and evaluating the ethical dimensions of gamification. Plato's\nallegory of the cave and theory of forms are used to analyse the perception of\nreality in gamified environments, questioning their authenticity and the value\nof virtual achievements, while Aristotle's virtue ethics, with its emphasis on\nmoderation, virtue, and eudaimonia (true and full happiness), can help assess\nhow gamification influences user behaviour and ethical decision-making. The\npaper critically examines various gamification elements, such as the hero's\njourney, altruistic actions, badge levels, and user autonomy, through these\nphilosophical lenses, and addresses the ethical responsibilities of\ngamification designers, advocating for a balanced approach that prioritizes\nuser well-being and ethical development over commercial interests. By bridging\nancient philosophical insights with modern digital culture, this research\ncontributes to a deeper understanding of the ethical implications of\ngamification, emphasizing the need for responsible and virtuous design in\ndigital applications.","updated":1710271513000,"published":1710271513000,"authors":["Kostas Karpouzis"],"comments":"Accepted for presentation at GamiFIN 2024","categories":["cs.HC"],"primary_category":"cs.HC","doi":null,"journal_ref":null,"peer_reviewed":true},"51":{"arxiv_id":"2403.12344v1","url":"http:\/\/arxiv.org\/abs\/2403.12344v1","title":"Human Factors in Space Exploration: Opportunities for International and\n  Interdisciplinary Collaboration","summary":"As humanity pushes the boundaries of space exploration, human factors\nresearch becomes more important. Human factors encompass a broad spectrum of\npsychological, physiological, and ergonomic factors that affect human\nperformance, well-being, and safety in the unique and challenging space\nenvironment. This panel explores the multifaceted field of human factors in\nspace exploration and highlights the opportunities that lie in fostering\ninternational and interdisciplinary cooperation. This exploration delves into\nthe current state of research on human factors in space missions, addressing\nthe physiological and psychological challenges astronauts face during long\nspace flights. It emphasizes the importance of interdisciplinary collaboration,\ncombining knowledge from fields such as psychology, medicine, engineering, and\ndesign to address the complex interaction of factors affecting human\nperformance and adaptation to the space environment","updated":1710811635000,"published":1710811635000,"authors":["Wies\u0142aw Kope\u0107","Grzegorz Pochwatko","Monika Kornacka","Wiktor Stawski","Maciej Grzeszczuk","Kinga Skorupska","Barbara Karpowicz","Rafa\u0142 Mas\u0142yk","Pavlo Zinevych","Stanis\u0142aw Knapi\u0144ski","Steven Barnes","Cezary Biele"],"comments":"13 pages including bibliography, 4 figures. To be published by\n  Springer as MIDI 2023 Conference proceedings","categories":["cs.HC"],"primary_category":"cs.HC","doi":null,"journal_ref":null,"peer_reviewed":true},"52":{"arxiv_id":"2403.19436v1","url":"http:\/\/arxiv.org\/abs\/2403.19436v1","title":"\"At the end of the day, I am accountable\": Gig Workers' Self-Tracking\n  for Multi-Dimensional Accountability Management","summary":"Tracking is inherent in and central to the gig economy. Platforms track gig\nworkers' performance through metrics such as acceptance rate and punctuality,\nwhile gig workers themselves engage in self-tracking. Although prior research\nhas extensively examined how gig platforms track workers through metrics --\nwith some studies briefly acknowledging the phenomenon of self-tracking among\nworkers -- there is a dearth of studies that explore how and why gig workers\ntrack themselves. To address this, we conducted 25 semi-structured interviews,\nrevealing how gig workers self-tracking to manage accountabilities to\nthemselves and external entities across three identities: the holistic self,\nthe entrepreneurial self, and the platformized self. We connect our findings to\nneoliberalism, through which we contextualize gig workers' self-accountability\nand the invisible labor of self-tracking. We further discuss how self-tracking\nmitigates information and power asymmetries in gig work and offer design\nimplications to support gig workers' multi-dimensional self-tracking.","updated":1711634670000,"published":1711634670000,"authors":["Rie Helene Hernandez","Qiurong Song","Yubo Kou","Xinning Gui"],"comments":"Accepted to CHI 2024","categories":["cs.HC"],"primary_category":"cs.HC","doi":null,"journal_ref":null,"peer_reviewed":true},"53":{"arxiv_id":"2401.10838v2","url":"http:\/\/arxiv.org\/abs\/2401.10838v2","title":"Rambler: Supporting Writing With Speech via LLM-Assisted Gist\n  Manipulation","summary":"Dictation enables efficient text input on mobile devices. However, writing\nwith speech can produce disfluent, wordy, and incoherent text and thus requires\nheavy post-processing. This paper presents Rambler, an LLM-powered graphical\nuser interface that supports gist-level manipulation of dictated text with two\nmain sets of functions: gist extraction and macro revision. Gist extraction\ngenerates keywords and summaries as anchors to support the review and\ninteraction with spoken text. LLM-assisted macro revisions allow users to\nrespeak, split, merge and transform dictated text without specifying precise\nediting locations. Together they pave the way for interactive dictation and\nrevision that help close gaps between spontaneous spoken words and\nwell-structured writing. In a comparative study with 12 participants performing\nverbal composition tasks, Rambler outperformed the baseline of a speech-to-text\neditor + ChatGPT, as it better facilitates iterative revisions with enhanced\nuser control over the content while supporting surprisingly diverse user\nstrategies.","updated":1709865965000,"published":1705685996000,"authors":["Susan Lin","Jeremy Warner","J. D. Zamfirescu-Pereira","Matthew G. Lee","Sauhard Jain","Michael Xuelin Huang","Piyawat Lertvittayakumjorn","Shanqing Cai","Shumin Zhai","Bj\u00f6rn Hartmann","Can Liu"],"comments":"To appear at ACM CHI 2024","categories":["cs.HC"],"primary_category":"cs.HC","doi":"10.1145\/3613904.3642217","journal_ref":null,"peer_reviewed":true},"54":{"arxiv_id":"2403.16018v1","url":"http:\/\/arxiv.org\/abs\/2403.16018v1","title":"Understanding the Impact of Referent Design on Scale Perception in\n  Immersive Data Visualization","summary":"Referents are often used to enhance scale perception in immersive\nvisualizations. Common referent designs include the considerations of referent\nlayout (side-by-side vs. in-situ) and referent size (small vs. medium vs.\nlarge). This paper introduces a controlled user study to assess how different\nreferent designs affect the efficiency and accuracy of scale perception across\ndifferent data scales, on the performance of the size-matching task in the\nvirtual environment. Our results reveal that in-situ layouts significantly\nenhance accuracy and confidence across various data scales, particularly with\nlarge referents. Linear regression analyses further confirm that in-situ\nlayouts exhibit greater resilience to changes in data scale. For tasks\nrequiring efficiency, medium-sized referents emerge as the preferred choice.\nBased on these findings, we offer design guidelines for selecting referent\nlayouts and sizes in immersive visualizations.","updated":1711258709000,"published":1711258709000,"authors":["Yihan Hou","Hao Cui","Rongrong Chen","Wei Zeng"],"comments":"7 pages, 6 figures, Accepted to Extended Abstracts of the CHI\n  Conference on Human Factors in Computing Systems (CHI EA '24)","categories":["cs.HC"],"primary_category":"cs.HC","doi":"10.1145\/3613905.3650783","journal_ref":null,"peer_reviewed":true},"55":{"arxiv_id":"2403.03822v1","url":"http:\/\/arxiv.org\/abs\/2403.03822v1","title":"HoLens: A Visual Analytics Design for Higher-order Movement Modeling and\n  Visualization","summary":"Higher-order patterns reveal sequential multistep state transitions, which\nare usually superior to origin-destination analysis, which depicts only\nfirst-order geospatial movement patterns. Conventional methods for higher-order\nmovement modeling first construct a directed acyclic graph (DAG) of movements,\nthen extract higher-order patterns from the DAG. However, DAG-based methods\nheavily rely on the identification of movement keypoints that are challenging\nfor sparse movements and fail to consider the temporal variants that are\ncritical for movements in urban environments. To overcome the limitations, we\npropose HoLens, a novel approach for modeling and visualizing higher-order\nmovement patterns in the context of an urban environment. HoLens mainly makes\ntwofold contributions: first, we design an auto-adaptive movement aggregation\nalgorithm that self-organizes movements hierarchically by considering spatial\nproximity, contextual information, and temporal variability; second, we develop\nan interactive visual analytics interface consisting of well-established\nvisualization techniques, including the H-Flow for visualizing the higher-order\npatterns on the map and the higher-order state sequence chart for representing\nthe higher-order state transitions. Two real-world case studies manifest that\nthe method can adaptively aggregate the data and exhibit the process of how to\nexplore the higher-order patterns by HoLens. We also demonstrate our approach's\nfeasibility, usability, and effectiveness through an expert interview with\nthree domain experts.","updated":1709741331000,"published":1709741331000,"authors":["Zezheng Feng","Fang Zhu","Hongjun Wang","Jianing Hao","ShuangHua Yang","Wei Zeng","Huamin Qu"],"comments":"20 pages, 18 figures, is accepted by computational visual media\n  journal","categories":["cs.HC"],"primary_category":"cs.HC","doi":null,"journal_ref":null,"peer_reviewed":true},"56":{"arxiv_id":"2403.08057v1","url":"http:\/\/arxiv.org\/abs\/2403.08057v1","title":"MineXR: Mining Personalized Extended Reality Interfaces","summary":"Extended Reality (XR) interfaces offer engaging user experiences, but their\neffective design requires a nuanced understanding of user behavior and\npreferences. This knowledge is challenging to obtain without the widespread\nadoption of XR devices. We introduce MineXR, a design mining workflow and data\nanalysis platform for collecting and analyzing personalized XR user interaction\nand experience data. MineXR enables elicitation of personalized interfaces from\nparticipants of a data collection: for any particular context, participants\ncreate interface elements using application screenshots from their own\nsmartphone, place them in the environment, and simultaneously preview the\nresulting XR layout on a headset. Using MineXR, we contribute a dataset of\npersonalized XR interfaces collected from 31 participants, consisting of 695 XR\nwidgets created from 178 unique applications. We provide insights for XR widget\nfunctionalities, categories, clusters, UI element types, and placement. Our\nopen-source tools and data support researchers and designers in developing\nfuture XR interfaces.","updated":1710273914000,"published":1710273914000,"authors":["Hyunsung Cho","Yukang Yan","Kashyap Todi","Mark Parent","Missie Smith","Tanya R. Jonker","Hrvoje Benko","David Lindlbauer"],"comments":"17 pages, 18 figures, Proceedings of the 2024 CHI Conference on Human\n  Factors in Computing Systems","categories":["cs.HC","H.5.2"],"primary_category":"cs.HC","doi":"10.1145\/3613904.3642394","journal_ref":null,"peer_reviewed":true},"57":{"arxiv_id":"2403.12730v1","url":"http:\/\/arxiv.org\/abs\/2403.12730v1","title":"What Does Evaluation of Explainable Artificial Intelligence Actually\n  Tell Us? A Case for Compositional and Contextual Validation of XAI Building\n  Blocks","summary":"Despite significant progress, evaluation of explainable artificial\nintelligence remains elusive and challenging. In this paper we propose a\nfine-grained validation framework that is not overly reliant on any one facet\nof these sociotechnical systems, and that recognises their inherent modular\nstructure: technical building blocks, user-facing explanatory artefacts and\nsocial communication protocols. While we concur that user studies are\ninvaluable in assessing the quality and effectiveness of explanation\npresentation and delivery strategies from the explainees' perspective in a\nparticular deployment context, the underlying explanation generation mechanisms\nrequire a separate, predominantly algorithmic validation strategy that accounts\nfor the technical and human-centred desiderata of their (numerical) outputs.\nSuch a comprehensive sociotechnical utility-based evaluation framework could\nallow to systematically reason about the properties and downstream influence of\ndifferent building blocks from which explainable artificial intelligence\nsystems are composed -- accounting for a diverse range of their engineering and\nsocial aspects -- in view of the anticipated use case.","updated":1710855934000,"published":1710855934000,"authors":["Kacper Sokol","Julia E. Vogt"],"comments":"Published in Extended Abstracts of the 2024 CHI Conference on Human\n  Factors in Computing Systems (CHI EA '24)","categories":["cs.HC","cs.AI"],"primary_category":"cs.HC","doi":"10.1145\/3613905.3651047","journal_ref":null,"peer_reviewed":true},"58":{"arxiv_id":"2403.18173v1","url":"http:\/\/arxiv.org\/abs\/2403.18173v1","title":"LLMs in HCI Data Work: Bridging the Gap Between Information Retrieval\n  and Responsible Research Practices","summary":"Efficient and accurate information extraction from scientific papers is\nsignificant in the rapidly developing human-computer interaction research in\nthe literature review process. Our paper introduces and analyses a new\ninformation retrieval system using state-of-the-art Large Language Models\n(LLMs) in combination with structured text analysis techniques to extract\nexperimental data from HCI literature, emphasizing key elements. Then We\nanalyze the challenges and risks of using LLMs in the world of research. We\nperformed a comprehensive analysis on our conducted dataset, which contained\nthe specified information of 300 CHI 2020-2022 papers, to evaluate the\nperformance of the two large language models, GPT-3.5 (text-davinci-003) and\nLlama-2-70b, paired with structured text analysis techniques. The GPT-3.5 model\ngains an accuracy of 58\\% and a mean absolute error of 7.00. In contrast, the\nLlama2 model indicates an accuracy of 56\\% with a mean absolute error of 7.63.\nThe ability to answer questions was also included in the system in order to\nwork with streamlined data. By evaluating the risks and opportunities presented\nby LLMs, our work contributes to the ongoing dialogue on establishing\nmethodological validity and ethical guidelines for LLM use in HCI data work.","updated":1711501269000,"published":1711501269000,"authors":["Neda Taghizadeh Serajeh","Iman Mohammadi","Vittorio Fuccella","Mattia De Rosa"],"comments":"5 pages, CHI2024 Workshop on LLMs as Research Tools: Applications and\n  Evaluations in HCI Data Work","categories":["cs.HC","cs.IR"],"primary_category":"cs.HC","doi":null,"journal_ref":null,"peer_reviewed":true},"59":{"arxiv_id":"2403.01697v1","url":"http:\/\/arxiv.org\/abs\/2403.01697v1","title":"Dismantling Gender Blindness in Online Discussion of a Crime\/Gender\n  Dichotomy","summary":"Contemporary feminists utilize social media for activism, while backlashes\ncome along. The gender-related discourses are often diminished when addressing\npublic events regarding sexism and gender inequality on social media platforms.\nThe dichotomized debate around the Tangshan beating incident in China\nepitomized how criminal interpretations of gender-related violence became a\nbacklash against feminist expressions. By analyzing posts on Weibo using mixed\nmethods, we describe the emerging discursive patterns around crime and gender,\nuncovering the inherent gender-blind sexism that refutes feminist discourses on\nthe social platform. We also highlight the critical restrictions facing\ngrassroots feminist activism in Chinese cyberspace and propose implications for\nthe design and research related to digital feminist activism.","updated":1709522274000,"published":1709522274000,"authors":["Yigang Qin","Weilun Duan","Qunfang Wu","Zhicong Lu"],"comments":"31 pages, 3 figures, Accepted for publication in Proceedings of the\n  ACM on Human-Computer Interaction (CSCW 2024)","categories":["cs.HC"],"primary_category":"cs.HC","doi":null,"journal_ref":null,"peer_reviewed":true},"60":{"arxiv_id":"2403.01055v1","url":"http:\/\/arxiv.org\/abs\/2403.01055v1","title":"Towards Full Authorship with AI: Supporting Revision with AI-Generated\n  Views","summary":"Large language models (LLMs) are shaping a new user interface (UI) paradigm\nin writing tools by enabling users to generate text through prompts. This\nparadigm shifts some creative control from the user to the system, thereby\ndiminishing the user's authorship and autonomy in the writing process. To\nrestore autonomy, we introduce Textfocals, a UI prototype designed to\ninvestigate a human-centered approach that emphasizes the user's role in\nwriting. Textfocals supports the writing process by providing LLM-generated\nsummaries, questions, and advice (i.e., LLM views) in a sidebar of a text\neditor, encouraging reflection and self-driven revision in writing without\ndirect text generation. Textfocals' UI affordances, including contextually\nadaptive views and scaffolding for prompt selection and customization, offer a\nnovel way to interact with LLMs where users maintain full authorship of their\nwriting. A formative user study with Textfocals showed promising evidence that\nthis approach might help users develop underdeveloped ideas, cater to the\nrhetorical audience, and clarify their writing. However, the study also showed\ninteraction design challenges related to document navigation and scoping,\nprompt engineering, and context management. Our work highlights the breadth of\nthe design space of writing support interfaces powered by generative AI that\nmaintain authorship integrity.","updated":1709341895000,"published":1709341895000,"authors":["Jiho Kim","Ray C. Flanagan","Noelle E. Haviland","ZeAi Sun","Souad N. Yakubu","Edom A. Maru","Kenneth C. Arnold"],"comments":"15 pages, 2 figures; Accepted to 5th Workshop on Human-AI Co-Creation\n  with Generative Models (HAI-GEN) at ACM IUI 2024","categories":["cs.HC","cs.AI","cs.CY","H.5.2; I.7.1; I.2.7"],"primary_category":"cs.HC","doi":null,"journal_ref":null,"peer_reviewed":true},"61":{"arxiv_id":"2305.11927v2","url":"http:\/\/arxiv.org\/abs\/2305.11927v2","title":"Evaluating how interactive visualizations can assist in finding samples\n  where and how computer vision models make mistakes","summary":"Creating Computer Vision (CV) models remains a complex practice, despite\ntheir ubiquity. Access to data, the requirement for ML expertise, and model\nopacity are just a few points of complexity that limit the ability of end-users\nto build, inspect, and improve these models. Interactive ML perspectives have\nhelped address some of these issues by considering a teacher in the loop where\nplanning, teaching, and evaluating tasks take place. We present and evaluate\ntwo interactive visualizations in the context of Sprite, a system for creating\nCV classification and detection models for images originating from videos. We\nstudy how these visualizations help Sprite's users identify (evaluate) and\nselect (plan) images where a model is struggling and can lead to improved\nperformance, compared to a baseline condition where users used a query\nlanguage. We found that users who had used the visualizations found more images\nacross a wider set of potential types of model errors.","updated":1710526996000,"published":1684507380000,"authors":["Hayeong Song","Gonzalo Ramos","Peter Bodik"],"comments":"Hayeong Song, Gonzalo Ramos, and Peter Bodik. \"Evaluating how\n  interactive visualizations can assist in finding samples where and how\n  computer vision models make mistakes\" 2024 IEEE Pacific Visualization\n  Symposium (PacificVis). Ieee, 2024","categories":["cs.HC","cs.CV","cs.LG"],"primary_category":"cs.HC","doi":null,"journal_ref":null,"peer_reviewed":true},"62":{"arxiv_id":"2403.00632v1","url":"http:\/\/arxiv.org\/abs\/2403.00632v1","title":"Metamorpheus: Interactive, Affective, and Creative Dream Narration\n  Through Metaphorical Visual Storytelling","summary":"Human emotions are essentially molded by lived experiences, from which we\nconstruct personalised meaning. The engagement in such meaning-making process\nhas been practiced as an intervention in various psychotherapies to promote\nwellness. Nevertheless, to support recollecting and recounting lived\nexperiences in everyday life remains under explored in HCI. It also remains\nunknown how technologies such as generative AI models can facilitate the\nmeaning making process, and ultimately support affective mindfulness. In this\npaper we present Metamorpheus, an affective interface that engages users in a\ncreative visual storytelling of emotional experiences during dreams.\nMetamorpheus arranges the storyline based on a dream's emotional arc, and\nprovokes self-reflection through the creation of metaphorical images and text\ndepictions. The system provides metaphor suggestions, and generates visual\nmetaphors and text depictions using generative AI models, while users can apply\ngenerations to recolour and re-arrange the interface to be visually affective.\nOur experience-centred evaluation manifests that, by interacting with\nMetamorpheus, users can recall their dreams in vivid detail, through which they\nrelive and reflect upon their experiences in a meaningful way.","updated":1709309372000,"published":1709309372000,"authors":["Qian Wan","Xin Feng","Yining Bei","Zhiqi Gao","Zhicong Lu"],"comments":"Accepted by CHI 2024","categories":["cs.HC","cs.AI","cs.CL","cs.CY"],"primary_category":"cs.HC","doi":null,"journal_ref":null,"peer_reviewed":true},"63":{"arxiv_id":"2309.15723v2","url":"http:\/\/arxiv.org\/abs\/2309.15723v2","title":"Where Are We So Far? Understanding Data Storytelling Tools from the\n  Perspective of Human-AI Collaboration","summary":"Data storytelling is powerful for communicating data insights, but it\nrequires diverse skills and considerable effort from human creators. Recent\nresearch has widely explored the potential for artificial intelligence (AI) to\nsupport and augment humans in data storytelling. However, there lacks a\nsystematic review to understand data storytelling tools from the perspective of\nhuman-AI collaboration, which hinders researchers from reflecting on the\nexisting collaborative tool designs that promote humans' and AI's advantages\nand mitigate their shortcomings. This paper investigated existing tools with a\nframework from two perspectives: the stages in the storytelling workflow where\na tool serves, including analysis, planning, implementation, and communication,\nand the roles of humans and AI in each stage, such as creators, assistants,\noptimizers, and reviewers. Through our analysis, we recognize the common\ncollaboration patterns in existing tools, summarize lessons learned from these\npatterns, and further illustrate research opportunities for human-AI\ncollaboration in data storytelling.","updated":1710766817000,"published":1695828650000,"authors":["Haotian Li","Yun Wang","Huamin Qu"],"comments":"Accepted by CHI 2024","categories":["cs.HC","cs.AI"],"primary_category":"cs.HC","doi":null,"journal_ref":null,"peer_reviewed":true}}