{"0":{"arxiv_id":"2403.16190v1","reader_id":"rid0","len_gpt_jargon":3,"len_human_jargon":3,"precision":0.3333333333,"recall":0.3333333333,"f1_score":0.3333333333,"f2_score":0.3333333333,"fuzzy_true_positives":1,"fuzzy_false_positives":2,"fuzzy_false_negatives":2,"url":"http:\/\/arxiv.org\/abs\/2403.16190v1","title":"Logic-based Explanations for Linear Support Vector Classifiers with\n  Reject Option","summary":"Support Vector Classifier (SVC) is a well-known Machine Learning (ML) model for linear classification problems. It can be used in conjunction with a reject option strategy to reject instances that are hard to correctly classify and delegate them to a specialist. This further increases the confidence of the model. Given this, obtaining an explanation of the cause of rejection is important to not blindly trust the obtained results. While most of the related work has developed means to give such explanations for machine learning models, to the best of our knowledge none have done so for when reject option is present. We propose a logic-based approach with formal guarantees on the correctness and minimality of explanations for linear SVCs with reject option. We evaluate our approach by comparing it to Anchors, which is a heuristic algorithm for generating explanations. Obtained results show that our proposed method gives shorter explanations with reduced time cost.","updated":1711293284000,"published":1711293284000,"authors":["Francisco Mateus Rocha Filho","Thiago Alves Rocha","Reginaldo Pereira Fernandes Ribeiro","Ajalmar R\u00eago da Rocha Neto"],"comments":"16 pages, submitted to BRACIS 2023 (Brazilian Conference on\n  Intelligent Systems), accepted version published in Intelligent Systems,\n  LNCS, vol 14195","categories":["cs.AI","cs.LG","cs.LO","I.2.4; I.2.6"],"primary_category":"cs.AI","doi":"10.1007\/978-3-031-45368-7_10","journal_ref":null,"peer_reviewed":true,"primary_category_readable":"Artificial Intelligence","gpt4_jargon_list":"reject option strategy, formal guarantees, minimality of explanations","human_jargon_list":"correctness,minimality,Anchors"},"1":{"arxiv_id":"2307.05300v4","reader_id":"rid0","len_gpt_jargon":3,"len_human_jargon":2,"precision":0.0,"recall":0.0,"f1_score":0.0,"f2_score":0.0,"fuzzy_true_positives":0,"fuzzy_false_positives":3,"fuzzy_false_negatives":2,"url":"http:\/\/arxiv.org\/abs\/2307.05300v4","title":"Unleashing the Emergent Cognitive Synergy in Large Language Models: A\n  Task-Solving Agent through Multi-Persona Self-Collaboration","summary":"Human intelligence thrives on cognitive synergy, where collaboration among different minds yield superior outcomes compared to isolated individuals. In this work, we propose Solo Performance Prompting (SPP), which transforms a single LLM into a cognitive synergist by engaging in multi-turn self-collaboration with multiple personas. A cognitive synergist is an intelligent agent that collaboratively combines multiple minds' strengths and knowledge to enhance problem-solving in complex tasks. By dynamically identifying and simulating different personas based on task inputs, SPP unleashes the potential of cognitive synergy in LLMs. Our in-depth analysis shows that assigning multiple fine-grained personas in LLMs improves problem-solving abilities compared to using a single or fixed number of personas. We evaluate SPP on three challenging tasks: Trivia Creative Writing, Codenames Collaborative, and Logic Grid Puzzle, encompassing both knowledge-intensive and reasoning-intensive types. Unlike previous works, such as Chain-of-Thought, that solely enhance the reasoning abilities in LLMs, experimental results demonstrate that SPP effectively reduces factual hallucination, and maintains strong reasoning capabilities. Additionally, comparative experiments show that cognitive synergy only emerges in GPT-4 and does not appear in less capable models, such as GPT-3.5-turbo and Llama2-13b-chat, which draws an interesting analogy to human development. Code, data, and prompts can be found at: https:\/\/github.com\/MikeWangWZHL\/Solo-Performance-Prompting.git.","updated":1711463553000,"published":1689086719000,"authors":["Zhenhailong Wang","Shaoguang Mao","Wenshan Wu","Tao Ge","Furu Wei","Heng Ji"],"comments":"Accepted as a main conference paper at NAACL 2024","categories":["cs.AI","cs.CL"],"primary_category":"cs.AI","doi":null,"journal_ref":null,"peer_reviewed":true,"primary_category_readable":"Artificial Intelligence","gpt4_jargon_list":"cognitive synergist, fine-grained personas, factual hallucination","human_jargon_list":"multi-turn,persona"},"2":{"arxiv_id":"2307.05300v4","reader_id":"rid1","len_gpt_jargon":6,"len_human_jargon":3,"precision":0.1666666667,"recall":0.3333333333,"f1_score":0.2222222222,"f2_score":0.2777777778,"fuzzy_true_positives":1,"fuzzy_false_positives":5,"fuzzy_false_negatives":2,"url":"http:\/\/arxiv.org\/abs\/2307.05300v4","title":"Unleashing the Emergent Cognitive Synergy in Large Language Models: A\n  Task-Solving Agent through Multi-Persona Self-Collaboration","summary":"Human intelligence thrives on cognitive synergy, where collaboration among different minds yield superior outcomes compared to isolated individuals. In this work, we propose Solo Performance Prompting (SPP), which transforms a single LLM into a cognitive synergist by engaging in multi-turn self-collaboration with multiple personas. A cognitive synergist is an intelligent agent that collaboratively combines multiple minds' strengths and knowledge to enhance problem-solving in complex tasks. By dynamically identifying and simulating different personas based on task inputs, SPP unleashes the potential of cognitive synergy in LLMs. Our in-depth analysis shows that assigning multiple fine-grained personas in LLMs improves problem-solving abilities compared to using a single or fixed number of personas. We evaluate SPP on three challenging tasks: Trivia Creative Writing, Codenames Collaborative, and Logic Grid Puzzle, encompassing both knowledge-intensive and reasoning-intensive types. Unlike previous works, such as Chain-of-Thought, that solely enhance the reasoning abilities in LLMs, experimental results demonstrate that SPP effectively reduces factual hallucination, and maintains strong reasoning capabilities. Additionally, comparative experiments show that cognitive synergy only emerges in GPT-4 and does not appear in less capable models, such as GPT-3.5-turbo and Llama2-13b-chat, which draws an interesting analogy to human development. Code, data, and prompts can be found at: https:\/\/github.com\/MikeWangWZHL\/Solo-Performance-Prompting.git.","updated":1711463553000,"published":1689086719000,"authors":["Zhenhailong Wang","Shaoguang Mao","Wenshan Wu","Tao Ge","Furu Wei","Heng Ji"],"comments":"Accepted as a main conference paper at NAACL 2024","categories":["cs.AI","cs.CL"],"primary_category":"cs.AI","doi":null,"journal_ref":null,"peer_reviewed":true,"primary_category_readable":"Artificial Intelligence","gpt4_jargon_list":"cognitive synergy, cognitive synergist, multi-turn self-collaboration, dynamically identifying and simulating, fine-grained personas, factual hallucination","human_jargon_list":"Solo Performance Prompting,multi-turn,Chain-of-Thought,"},"3":{"arxiv_id":"2402.09565v2","reader_id":"rid0","len_gpt_jargon":4,"len_human_jargon":4,"precision":0.25,"recall":0.25,"f1_score":0.25,"f2_score":0.25,"fuzzy_true_positives":1,"fuzzy_false_positives":3,"fuzzy_false_negatives":3,"url":"http:\/\/arxiv.org\/abs\/2402.09565v2","title":"Graph-Skeleton: ~1% Nodes are Sufficient to Represent Billion-Scale\n  Graph","summary":"Due to the ubiquity of graph data on the web, web graph mining has become a hot research spot. Nonetheless, the prevalence of large-scale web graphs in real applications poses significant challenges to storage, computational capacity and graph model design. Despite numerous studies to enhance the scalability of graph models, a noticeable gap remains between academic research and practical web graph mining applications. One major cause is that in most industrial scenarios, only a small part of nodes in a web graph are actually required to be analyzed, where we term these nodes as target nodes, while others as background nodes. In this paper, we argue that properly fetching and condensing the background nodes from massive web graph data might be a more economical shortcut to tackle the obstacles fundamentally. To this end, we make the first attempt to study the problem of massive background nodes compression for target nodes classification. Through extensive experiments, we reveal two critical roles played by the background nodes in target node classification: enhancing structural connectivity between target nodes, and feature correlation with target nodes. Followingthis, we propose a novel Graph-Skeleton1 model, which properly fetches the background nodes, and further condenses the semantic and topological information of background nodes within similar target-background local structures. Extensive experiments on various web graph datasets demonstrate the effectiveness and efficiency of the proposed method. In particular, for MAG240M dataset with 0.24 billion nodes, our generated skeleton graph achieves highly comparable performance while only containing 1.8% nodes of the original graph.","updated":1709763753000,"published":1707942791000,"authors":["Linfeng Cao","Haoran Deng","Yang Yang","Chunping Wang","Lei Chen"],"comments":"21 pages, 11 figures, In Proceedings of the ACM Web Conference 2024\n  (WWW'24)","categories":["cs.AI"],"primary_category":"cs.AI","doi":"10.1145\/3589334.3645452","journal_ref":null,"peer_reviewed":true,"primary_category_readable":"Artificial Intelligence","gpt4_jargon_list":"target nodes, background nodes, Graph-Skeleton1 model, skeleton graph","human_jargon_list":"background nodes,massive background nodes compression,structural connectivity,taget-background local structures"},"4":{"arxiv_id":"2301.13755v3","reader_id":"rid0","len_gpt_jargon":3,"len_human_jargon":5,"precision":0.3333333333,"recall":0.2,"f1_score":0.25,"f2_score":0.2173913043,"fuzzy_true_positives":1,"fuzzy_false_positives":2,"fuzzy_false_negatives":4,"url":"http:\/\/arxiv.org\/abs\/2301.13755v3","title":"Retrosynthetic Planning with Dual Value Networks","summary":"Retrosynthesis, which aims to find a route to synthesize a target molecule from commercially available starting materials, is a critical task in drug discovery and materials design. Recently, the combination of ML-based single-step reaction predictors with multi-step planners has led to promising results. However, the single-step predictors are mostly trained offline to optimize the single-step accuracy, without considering complete routes. Here, we leverage reinforcement learning (RL) to improve the single-step predictor, by using a tree-shaped MDP to optimize complete routes. Specifically, we propose a novel online training algorithm, called Planning with Dual Value Networks (PDVN), which alternates between the planning phase and updating phase. In PDVN, we construct two separate value networks to predict the synthesizability and cost of molecules, respectively. To maintain the single-step accuracy, we design a two-branch network structure for the single-step predictor. On the widely-used USPTO dataset, our PDVN algorithm improves the search success rate of existing multi-step planners (e.g., increasing the success rate from 85.79% to 98.95% for Retro*, and reducing the number of model calls by half while solving 99.47% molecules for RetroGraph). Additionally, PDVN helps find shorter synthesis routes (e.g., reducing the average route length from 5.76 to 4.83 for Retro*, and from 5.63 to 4.78 for RetroGraph). Our code is available at \\url{https:\/\/github.com\/DiXue98\/PDVN}.","updated":1709475801000,"published":1675183433000,"authors":["Guoqing Liu","Di Xue","Shufang Xie","Yingce Xia","Austin Tripp","Krzysztof Maziarz","Marwin Segler","Tao Qin","Zongzhang Zhang","Tie-Yan Liu"],"comments":"Accepted to ICML 2023","categories":["cs.AI","cs.LG"],"primary_category":"cs.AI","doi":null,"journal_ref":null,"peer_reviewed":true,"primary_category_readable":"Artificial Intelligence","gpt4_jargon_list":"tree-shaped MDP, Planning with Dual Value Networks (PDVN), value networks","human_jargon_list":"single-step reaction predictors,multi-step planners,tree-shaped MDP,synthesizability,synthesis routes"},"5":{"arxiv_id":"2403.16508v1","reader_id":"rid1","len_gpt_jargon":5,"len_human_jargon":8,"precision":0.6,"recall":0.375,"f1_score":0.4615384615,"f2_score":0.4054054054,"fuzzy_true_positives":3,"fuzzy_false_positives":2,"fuzzy_false_negatives":5,"url":"http:\/\/arxiv.org\/abs\/2403.16508v1","title":"Return to Tradition: Learning Reliable Heuristics with Classical Machine\n  Learning","summary":"Current approaches for learning for planning have yet to achieve competitive performance against classical planners in several domains, and have poor overall performance. In this work, we construct novel graph representations of lifted planning tasks and use the WL algorithm to generate features from them. These features are used with classical machine learning methods which have up to 2 orders of magnitude fewer parameters and train up to 3 orders of magnitude faster than the state-of-the-art deep learning for planning models. Our novel approach, WL-GOOSE, reliably learns heuristics from scratch and outperforms the $h^{\\text{FF}}$ heuristic in a fair competition setting. It also outperforms or ties with LAMA on 4 out of 10 domains on coverage and 7 out of 10 domains on plan quality. WL-GOOSE is the first learning for planning model which achieves these feats. Furthermore, we study the connections between our novel WL feature generation method, previous theoretically flavoured learning architectures, and Description Logic Features for planning.","updated":1711352872000,"published":1711352872000,"authors":["Dillon Z. Chen","Felipe Trevizan","Sylvie Thi\u00e9baux"],"comments":"Extended version of ICAPS 2024 paper","categories":["cs.AI"],"primary_category":"cs.AI","doi":null,"journal_ref":null,"peer_reviewed":true,"primary_category_readable":"Artificial Intelligence","gpt4_jargon_list":"lifted planning tasks, WL algorithm, $h^{\\text{FF}}$ heuristic, LAMA, Description Logic Features for planning","human_jargon_list":"classical planners,graph representations,WL algorithm,magnitude,WL-GOOSE,LAMA,flavoured learning architectures,Description Logic Features"},"6":{"arxiv_id":"2403.16289v1","reader_id":"rid0","len_gpt_jargon":3,"len_human_jargon":3,"precision":0.0,"recall":0.0,"f1_score":0.0,"f2_score":0.0,"fuzzy_true_positives":0,"fuzzy_false_positives":3,"fuzzy_false_negatives":3,"url":"http:\/\/arxiv.org\/abs\/2403.16289v1","title":"Engineering Safety Requirements for Autonomous Driving with Large\n  Language Models","summary":"Changes and updates in the requirement artifacts, which can be frequent in the automotive domain, are a challenge for SafetyOps. Large Language Models (LLMs), with their impressive natural language understanding and generating capabilities, can play a key role in automatically refining and decomposing requirements after each update. In this study, we propose a prototype of a pipeline of prompts and LLMs that receives an item definition and outputs solutions in the form of safety requirements. This pipeline also performs a review of the requirement dataset and identifies redundant or contradictory requirements. We first identified the necessary characteristics for performing HARA and then defined tests to assess an LLM's capability in meeting these criteria. We used design science with multiple iterations and let experts from different companies evaluate each cycle quantitatively and qualitatively. Finally, the prototype was implemented at a case company and the responsible team evaluated its efficiency.","updated":1711312851000,"published":1711312851000,"authors":["Ali Nouri","Beatriz Cabrero-Daniel","Fredrik T\u00f6rner","H\u0227kan Sivencrona","Christian Berger"],"comments":"Accepted in 32nd IEEE International Requirements Engineering 2024\n  conference, Iceland","categories":["cs.AI"],"primary_category":"cs.AI","doi":null,"journal_ref":null,"peer_reviewed":true,"primary_category_readable":"Artificial Intelligence","gpt4_jargon_list":"SafetyOps, HARA, design science","human_jargon_list":"requirement artifacts,decomposing requirements,requirement dataset"},"7":{"arxiv_id":"2403.17419v1","reader_id":"rid0","len_gpt_jargon":3,"len_human_jargon":0,"precision":0.0,"recall":0.0,"f1_score":0.0,"f2_score":0.0,"fuzzy_true_positives":0,"fuzzy_false_positives":3,"fuzzy_false_negatives":0,"url":"http:\/\/arxiv.org\/abs\/2403.17419v1","title":"AI Safety: Necessary, but insufficient and possibly problematic","summary":"This article critically examines the recent hype around AI safety. We first start with noting the nature of the AI safety hype as being dominated by governments and corporations, and contrast it with other avenues within AI research on advancing social good. We consider what 'AI safety' actually means, and outline the dominant concepts that the digital footprint of AI safety aligns with. We posit that AI safety has a nuanced and uneasy relationship with transparency and other allied notions associated with societal good, indicating that it is an insufficient notion if the goal is that of societal good in a broad sense. We note that the AI safety debate has already influenced some regulatory efforts in AI, perhaps in not so desirable directions. We also share our concerns on how AI safety may normalize AI that advances structural harm through providing exploitative and harmful AI with a veneer of safety.","updated":1711433922000,"published":1711433922000,"authors":["Deepak P"],"comments":"AI & Soc (2024)","categories":["cs.AI","cs.CY"],"primary_category":"cs.AI","doi":"10.1007\/s00146-024-01899-y","journal_ref":null,"peer_reviewed":true,"primary_category_readable":"Artificial Intelligence","gpt4_jargon_list":"AI safety, digital footprint of AI safety, structural harm","human_jargon_list":""},"8":{"arxiv_id":"2402.01786v2","reader_id":"rid1","len_gpt_jargon":9,"len_human_jargon":3,"precision":0.1111111111,"recall":0.3333333333,"f1_score":0.1666666667,"f2_score":0.2380952381,"fuzzy_true_positives":1,"fuzzy_false_positives":8,"fuzzy_false_negatives":2,"url":"http:\/\/arxiv.org\/abs\/2402.01786v2","title":"COA-GPT: Generative Pre-trained Transformers for Accelerated Course of\n  Action Development in Military Operations","summary":"The development of Courses of Action (COAs) in military operations is traditionally a time-consuming and intricate process. Addressing this challenge, this study introduces COA-GPT, a novel algorithm employing Large Language Models (LLMs) for rapid and efficient generation of valid COAs. COA-GPT incorporates military doctrine and domain expertise to LLMs through in-context learning, allowing commanders to input mission information - in both text and image formats - and receive strategically aligned COAs for review and approval. Uniquely, COA-GPT not only accelerates COA development, producing initial COAs within seconds, but also facilitates real-time refinement based on commander feedback. This work evaluates COA-GPT in a military-relevant scenario within a militarized version of the StarCraft II game, comparing its performance against state-of-the-art reinforcement learning algorithms. Our results demonstrate COA-GPT's superiority in generating strategically sound COAs more swiftly, with added benefits of enhanced adaptability and alignment with commander intentions. COA-GPT's capability to rapidly adapt and update COAs during missions presents a transformative potential for military planning, particularly in addressing planning discrepancies and capitalizing on emergent windows of opportunities.","updated":1711639362000,"published":1706824269000,"authors":["Vinicius G. Goecks","Nicholas Waytowich"],"comments":"Accepted at the NATO Science and Technology Organization Symposium\n  (ICMCIS) organized by the Information Systems Technology (IST) Panel,\n  IST-205-RSY - the ICMCIS, held in Koblenz, Germany, 23-24 April 2024","categories":["cs.AI","cs.CL","cs.HC","cs.LG","I.2.6; I.2.7; J.7"],"primary_category":"cs.AI","doi":null,"journal_ref":null,"peer_reviewed":true,"primary_category_readable":"Artificial Intelligence","gpt4_jargon_list":"Courses of Action (COAs),in-context learning,military doctrine,domain expertise,reinforcement learning algorithms,military-relevant scenario,militarized version of the StarCraft II game,planning discrepancies,emergent windows of opportunities","human_jargon_list":"Courses of Action,COA-GPT,commander feedback"},"9":{"arxiv_id":"2403.07131v1","reader_id":"rid0","len_gpt_jargon":5,"len_human_jargon":8,"precision":0.2,"recall":0.125,"f1_score":0.1538461538,"f2_score":0.1351351351,"fuzzy_true_positives":1,"fuzzy_false_positives":4,"fuzzy_false_negatives":7,"url":"http:\/\/arxiv.org\/abs\/2403.07131v1","title":"Bigraph Matching Weighted with Learnt Incentive Function for Multi-Robot\n  Task Allocation","summary":"Most real-world Multi-Robot Task Allocation (MRTA) problems require fast and efficient decision-making, which is often achieved using heuristics-aided methods such as genetic algorithms, auction-based methods, and bipartite graph matching methods. These methods often assume a form that lends better explainability compared to an end-to-end (learnt) neural network based policy for MRTA. However, deriving suitable heuristics can be tedious, risky and in some cases impractical if problems are too complex. This raises the question: can these heuristics be learned? To this end, this paper particularly develops a Graph Reinforcement Learning (GRL) framework to learn the heuristics or incentives for a bipartite graph matching approach to MRTA. Specifically a Capsule Attention policy model is used to learn how to weight task\/robot pairings (edges) in the bipartite graph that connects the set of tasks to the set of robots. The original capsule attention network architecture is fundamentally modified by adding encoding of robots' state graph, and two Multihead Attention based decoders whose output are used to construct a LogNormal distribution matrix from which positive bigraph weights can be drawn. The performance of this new bigraph matching approach augmented with a GRL-derived incentive is found to be at par with the original bigraph matching approach that used expert-specified heuristics, with the former offering notable robustness benefits. During training, the learned incentive policy is found to get initially closer to the expert-specified incentive and then slightly deviate from its trend.","updated":1710186908000,"published":1710186908000,"authors":["Steve Paul","Nathan Maurer","Souma Chowdhury"],"comments":"This paper was accepted for presentation in proceedings of IEEE\n  International Conference on Robotics and Automation 2024","categories":["cs.AI","cs.MA"],"primary_category":"cs.AI","doi":null,"journal_ref":null,"peer_reviewed":true,"primary_category_readable":"Artificial Intelligence","gpt4_jargon_list":"Capsule Attention policy model, Multihead Attention based decoders, LogNormal distribution matrix, bigraph matching approach, GRL-derived incentive","human_jargon_list":"Multi-Robot Task Allocation (MRTA) problems,Graph Reinforcement Learning (GRL) framework,bipartite graph matching approach,,Capsule Attention policy mode,robots' state graph,positive bigraph weights,learned incentive policy,expert-specified incentive"},"10":{"arxiv_id":"2403.17911v1","reader_id":"rid0","len_gpt_jargon":4,"len_human_jargon":0,"precision":0.0,"recall":0.0,"f1_score":0.0,"f2_score":0.0,"fuzzy_true_positives":0,"fuzzy_false_positives":4,"fuzzy_false_negatives":0,"url":"http:\/\/arxiv.org\/abs\/2403.17911v1","title":"Domain-Specific Evaluation Strategies for AI in Journalism","summary":"News organizations today rely on AI tools to increase efficiency and productivity across various tasks in news production and distribution. These tools are oriented towards stakeholders such as reporters, editors, and readers. However, practitioners also express reservations around adopting AI technologies into the newsroom, due to the technical and ethical challenges involved in evaluating AI technology and its return on investments. This is to some extent a result of the lack of domain-specific strategies to evaluate AI models and applications. In this paper, we consider different aspects of AI evaluation (model outputs, interaction, and ethics) that can benefit from domain-specific tailoring, and suggest examples of how journalistic considerations can lead to specialized metrics or strategies. In doing so, we lay out a potential framework to guide AI evaluation in journalism, such as seen in other disciplines (e.g. law, healthcare). We also consider directions for future work, as well as how our approach might generalize to other domains.","updated":1711475245000,"published":1711475245000,"authors":["Sachita Nishal","Charlotte Li","Nicholas Diakopoulos"],"comments":"Accepted to the Workshop on Evaluating AI at the ACM CHI conference\n  on Human Factors in Computing Systems","categories":["cs.CY","I.2.1; H.5; K.4"],"primary_category":"cs.CY","doi":null,"journal_ref":null,"peer_reviewed":true,"primary_category_readable":"Computers and Society","gpt4_jargon_list":"domain-specific strategies, model outputs, interaction, return on investments","human_jargon_list":""},"11":{"arxiv_id":"2403.17911v1","reader_id":"rid1","len_gpt_jargon":5,"len_human_jargon":0,"precision":0.0,"recall":0.0,"f1_score":0.0,"f2_score":0.0,"fuzzy_true_positives":0,"fuzzy_false_positives":5,"fuzzy_false_negatives":0,"url":"http:\/\/arxiv.org\/abs\/2403.17911v1","title":"Domain-Specific Evaluation Strategies for AI in Journalism","summary":"News organizations today rely on AI tools to increase efficiency and productivity across various tasks in news production and distribution. These tools are oriented towards stakeholders such as reporters, editors, and readers. However, practitioners also express reservations around adopting AI technologies into the newsroom, due to the technical and ethical challenges involved in evaluating AI technology and its return on investments. This is to some extent a result of the lack of domain-specific strategies to evaluate AI models and applications. In this paper, we consider different aspects of AI evaluation (model outputs, interaction, and ethics) that can benefit from domain-specific tailoring, and suggest examples of how journalistic considerations can lead to specialized metrics or strategies. In doing so, we lay out a potential framework to guide AI evaluation in journalism, such as seen in other disciplines (e.g. law, healthcare). We also consider directions for future work, as well as how our approach might generalize to other domains.","updated":1711475245000,"published":1711475245000,"authors":["Sachita Nishal","Charlotte Li","Nicholas Diakopoulos"],"comments":"Accepted to the Workshop on Evaluating AI at the ACM CHI conference\n  on Human Factors in Computing Systems","categories":["cs.CY","I.2.1; H.5; K.4"],"primary_category":"cs.CY","doi":null,"journal_ref":null,"peer_reviewed":true,"primary_category_readable":"Computers and Society","gpt4_jargon_list":"domain-specific strategies, model outputs, interaction, return on investments, specialized metrics","human_jargon_list":""},"12":{"arxiv_id":"2403.11952v1","reader_id":"rid0","len_gpt_jargon":6,"len_human_jargon":0,"precision":0.0,"recall":0.0,"f1_score":0.0,"f2_score":0.0,"fuzzy_true_positives":0,"fuzzy_false_positives":6,"fuzzy_false_negatives":0,"url":"http:\/\/arxiv.org\/abs\/2403.11952v1","title":"Exploring Estonia's Open Government Data Development as a Journey\n  towards Excellence: Unveiling the Progress of Local Governments in Open Data\n  Provision","summary":"Estonia has a global reputation of a digital state or e-country. However, despite the success in digital governance, the country has faced challenges in the realm of Open Government Data (OGD) area, with significant advancements in its OGD ecosystem, as reflected in various open data rankings from 2020 and onwards, in the recent years being recognized among trend-setters. This paper aims to explore the evolution and positioning of Estonia's OGD development, encompassing national and local levels, through an integrated analysis of various indices, primary data from the Estonian OGD portal, and a thorough literature review. The research shows that Estonia has made progress in the national level open data ecosystem, primarily due to improvements in the OGD portal usability and legislation amendments. However, the local level is not as developed, with local governments lagging behind in OGD provision. The literature review highlights the lack of previous research focusing on Estonian and European local open data, emphasizing the need for future studies to explore the barriers and enablers of municipal OGD. This study contributes to a nuanced understanding of Estonia's dynamic journey in the OGD landscape, shedding light on both achievements and areas warranting further attention for establishing a sustainable open data ecosystem.","updated":1710780605000,"published":1710780605000,"authors":["Katrin Rajam\u00e4e-Soosaar","Anastasija Nikiforova"],"comments":"This paper has been accepted for publication in Proceedings of the\n  25th Annual International Conference on Digital Government Research and this\n  is a pre-print version of the manuscript. It is posted here for your personal\n  use. Not for redistribution","categories":["cs.CY","cs.CE","cs.DB","cs.SE","cs.SI"],"primary_category":"cs.CY","doi":null,"journal_ref":null,"peer_reviewed":true,"primary_category_readable":"Computers and Society","gpt4_jargon_list":"Open Government Data (OGD), OGD ecosystem, OGD portal, open data ecosystem, municipal OGD, open data ecosystem","human_jargon_list":""},"13":{"arxiv_id":"2403.08451v1","reader_id":"rid0","len_gpt_jargon":3,"len_human_jargon":0,"precision":0.0,"recall":0.0,"f1_score":0.0,"f2_score":0.0,"fuzzy_true_positives":0,"fuzzy_false_positives":3,"fuzzy_false_negatives":0,"url":"http:\/\/arxiv.org\/abs\/2403.08451v1","title":"An Integrated Usability Framework for Evaluating Open Government Data\n  Portals: Comparative Analysis of EU and GCC Countries","summary":"This study explores the critical role of open government data (OGD) portals in fostering transparency and collaboration between diverse stakeholders. Recognizing the challenges of usability, communication with diverse populations, and strategic value creation, this paper develops an integrated framework for evaluating OGD portal effectiveness that accommodates user diversity (regardless of their data literacy and language), evaluates collaboration and participation, and the ability of users to explore and understand the data provided through them. The framework is validated by applying it to 33 national portals across European Union and Gulf Cooperation Council (GCC) countries, as a result of which we rank OGD portals, identify some good practices that lower-performing portals can learn from, and common shortcomings. Notably, the study unveils the competitive and innovative nature of GCC OGD portals, pinpointing specific improvement areas such as multilingual support and data understandability. The findings underscore the growing trend of exposing data quality metrics and advocate for enhanced two-way communication channels between users and portal representatives. Overall, the study contributes to accelerating the development of user-friendly, collaborative, and sustainable OGD portals while addressing gaps identified in previous research.","updated":1710331602000,"published":1710331602000,"authors":["Fillip Molodtsov","Anastasija Nikiforova"],"comments":"This paper has been accepted for publication in Proceedings of the\n  25th Annual International Conference on Digital Government Research and this\n  is a preprint version of the manuscript","categories":["cs.CY","cs.SE"],"primary_category":"cs.CY","doi":null,"journal_ref":null,"peer_reviewed":true,"primary_category_readable":"Computers and Society","gpt4_jargon_list":"open government data (OGD) portals, data literacy, data quality metrics","human_jargon_list":""},"14":{"arxiv_id":"2403.07082v1","reader_id":"rid0","len_gpt_jargon":3,"len_human_jargon":0,"precision":0.0,"recall":0.0,"f1_score":0.0,"f2_score":0.0,"fuzzy_true_positives":0,"fuzzy_false_positives":3,"fuzzy_false_negatives":0,"url":"http:\/\/arxiv.org\/abs\/2403.07082v1","title":"Exploring the Impact of ChatGPT on Student Interactions in\n  Computer-Supported Collaborative Learning","summary":"The growing popularity of generative AI, particularly ChatGPT, has sparked both enthusiasm and caution among practitioners and researchers in education. To effectively harness the full potential of ChatGPT in educational contexts, it is crucial to analyze its impact and suitability for different educational purposes. This paper takes an initial step in exploring the applicability of ChatGPT in a computer-supported collaborative learning (CSCL) environment. Using statistical analysis, we validate the shifts in student interactions during an asynchronous group brainstorming session by introducing ChatGPT as an instantaneous question-answering agent.","updated":1710181098000,"published":1710181098000,"authors":["Han Kyul Kim","Shriniwas Nayak","Aleyeh Roknaldin","Xiaoci Zhang","Marlon Twyman","Stephen Lu"],"comments":"AAAI2024 Workshop on AI for Education (AI4ED)","categories":["cs.CY"],"primary_category":"cs.CY","doi":null,"journal_ref":null,"peer_reviewed":true,"primary_category_readable":"Computers and Society","gpt4_jargon_list":"computer-supported collaborative learning (CSCL), asynchronous group brainstorming session, instantaneous question-answering agent","human_jargon_list":""},"15":{"arxiv_id":"2308.10148v3","reader_id":"rid0","len_gpt_jargon":1,"len_human_jargon":0,"precision":0.0,"recall":0.0,"f1_score":0.0,"f2_score":0.0,"fuzzy_true_positives":0,"fuzzy_false_positives":1,"fuzzy_false_negatives":0,"url":"http:\/\/arxiv.org\/abs\/2308.10148v3","title":"Privacy Perceptions and Behaviors of Google Personal Account Holders in\n  Saudi Arabia","summary":"While privacy perceptions and behaviors have been investigated in Western societies, little is known about these issues in non-Western societies. To bridge this gap, we interviewed 30 Google personal account holders in Saudi Arabia about their privacy perceptions and behaviors regarding the activity data that Google saves about them. Our study focuses on Google's Activity Controls, which enable users to control whether, and how, Google saves their Web \\& App Activity, Location History, and YouTube History. Our results show that although most participants have some level of awareness about Google's data practices and the Activity Controls, many have only vague awareness, and the majority have not used the available controls. When participants viewed their saved activity data, many were surprised by what had been saved. While many participants find Google's use of their data to improve the services provided to them acceptable, the majority find the use of their data for ad purposes unacceptable. We observe that our Saudi participants exhibit similar trends and patterns in privacy awareness, attitudes, preferences, concerns, and behaviors to what has been found in studies in the US. Our results emphasize the need for: 1) improved techniques to inform users about privacy settings during account sign-up, to remind users about their settings, and to raise awareness about privacy settings; 2) improved privacy setting interfaces to reduce the costs that deter many users from changing the settings; and 3) further research to explore privacy concerns in non-Western cultures.","updated":1710788822000,"published":1692501918000,"authors":["Eman Alashwali","Lorrie Faith Cranor"],"comments":"To appear in Proceedings of Human Computer Interaction International\n  (HCII) 2024","categories":["cs.CY","cs.CR","cs.HC"],"primary_category":"cs.CY","doi":null,"journal_ref":null,"peer_reviewed":true,"primary_category_readable":"Computers and Society","gpt4_jargon_list":"No jargon found.","human_jargon_list":""},"16":{"arxiv_id":"2308.10148v3","reader_id":"rid1","len_gpt_jargon":4,"len_human_jargon":0,"precision":0.0,"recall":0.0,"f1_score":0.0,"f2_score":0.0,"fuzzy_true_positives":0,"fuzzy_false_positives":4,"fuzzy_false_negatives":0,"url":"http:\/\/arxiv.org\/abs\/2308.10148v3","title":"Privacy Perceptions and Behaviors of Google Personal Account Holders in\n  Saudi Arabia","summary":"While privacy perceptions and behaviors have been investigated in Western societies, little is known about these issues in non-Western societies. To bridge this gap, we interviewed 30 Google personal account holders in Saudi Arabia about their privacy perceptions and behaviors regarding the activity data that Google saves about them. Our study focuses on Google's Activity Controls, which enable users to control whether, and how, Google saves their Web \\& App Activity, Location History, and YouTube History. Our results show that although most participants have some level of awareness about Google's data practices and the Activity Controls, many have only vague awareness, and the majority have not used the available controls. When participants viewed their saved activity data, many were surprised by what had been saved. While many participants find Google's use of their data to improve the services provided to them acceptable, the majority find the use of their data for ad purposes unacceptable. We observe that our Saudi participants exhibit similar trends and patterns in privacy awareness, attitudes, preferences, concerns, and behaviors to what has been found in studies in the US. Our results emphasize the need for: 1) improved techniques to inform users about privacy settings during account sign-up, to remind users about their settings, and to raise awareness about privacy settings; 2) improved privacy setting interfaces to reduce the costs that deter many users from changing the settings; and 3) further research to explore privacy concerns in non-Western cultures.","updated":1710788822000,"published":1692501918000,"authors":["Eman Alashwali","Lorrie Faith Cranor"],"comments":"To appear in Proceedings of Human Computer Interaction International\n  (HCII) 2024","categories":["cs.CY","cs.CR","cs.HC"],"primary_category":"cs.CY","doi":null,"journal_ref":null,"peer_reviewed":true,"primary_category_readable":"Computers and Society","gpt4_jargon_list":"Activity Controls,Web & App Activity,Location History,YouTube History","human_jargon_list":""},"17":{"arxiv_id":"2403.02908v1","reader_id":"rid0","len_gpt_jargon":2,"len_human_jargon":0,"precision":0.0,"recall":0.0,"f1_score":0.0,"f2_score":0.0,"fuzzy_true_positives":0,"fuzzy_false_positives":2,"fuzzy_false_negatives":0,"url":"http:\/\/arxiv.org\/abs\/2403.02908v1","title":"Preserving Tangible and Intangible Cultural Heritage: the Cases of\n  Volterra and Atari","summary":"At first glance, the ruins of the Roman Theatre in the Italian town of Volterra have little in common with cassette tapes containing Atari games. One is certainly considered an important historical landmark, while the consensus on the importance of the other is partial at best. Still, both are remnants of times vastly different from the present and are at risk of oblivion. Unearthed architectural structures are exposed to the elements just as the deteriorating signals stored on magnetic tapes. However, the rate of deterioration is much faster with the magnetic media, as their life expectancy is counted in decades, whereas the Roman Theater, which is already in ruin, measures its lifespan in centuries. Hence, both would benefit from some form of digital preservation and reconstruction. In this panel, we discuss how to sustainably preserve tangible and intangible cultural artifacts for future generations.","updated":1709641088000,"published":1709641088000,"authors":["Maciej Grzeszczuk","Kinga Skorupska","Pawe\u0142 Grabarczyk","W\u0142adys\u0142aw Fuchs","Paul F. Aubin","Mark E. Dietrick","Barbara Karpowicz","Rafa\u0142 Mas\u0142yk","Pavlo Zinevych","Wiktor Stawski","Stanis\u0142aw Knapi\u0144ski","Wies\u0142aw Kope\u0107"],"comments":"8 pages, including 1 page of bibliography, 9 figures. Panel summary\n  to be published in proceedings from 11th Machine Intelligence and Digital\n  Interaction MIDI Conference","categories":["cs.CY","cs.DL","cs.HC"],"primary_category":"cs.CY","doi":null,"journal_ref":null,"peer_reviewed":true,"primary_category_readable":"Computers and Society","gpt4_jargon_list":"intangible cultural artifacts, digital preservation","human_jargon_list":""},"18":{"arxiv_id":"2403.02908v1","reader_id":"rid1","len_gpt_jargon":1,"len_human_jargon":0,"precision":0.0,"recall":0.0,"f1_score":0.0,"f2_score":0.0,"fuzzy_true_positives":0,"fuzzy_false_positives":1,"fuzzy_false_negatives":0,"url":"http:\/\/arxiv.org\/abs\/2403.02908v1","title":"Preserving Tangible and Intangible Cultural Heritage: the Cases of\n  Volterra and Atari","summary":"At first glance, the ruins of the Roman Theatre in the Italian town of Volterra have little in common with cassette tapes containing Atari games. One is certainly considered an important historical landmark, while the consensus on the importance of the other is partial at best. Still, both are remnants of times vastly different from the present and are at risk of oblivion. Unearthed architectural structures are exposed to the elements just as the deteriorating signals stored on magnetic tapes. However, the rate of deterioration is much faster with the magnetic media, as their life expectancy is counted in decades, whereas the Roman Theater, which is already in ruin, measures its lifespan in centuries. Hence, both would benefit from some form of digital preservation and reconstruction. In this panel, we discuss how to sustainably preserve tangible and intangible cultural artifacts for future generations.","updated":1709641088000,"published":1709641088000,"authors":["Maciej Grzeszczuk","Kinga Skorupska","Pawe\u0142 Grabarczyk","W\u0142adys\u0142aw Fuchs","Paul F. Aubin","Mark E. Dietrick","Barbara Karpowicz","Rafa\u0142 Mas\u0142yk","Pavlo Zinevych","Wiktor Stawski","Stanis\u0142aw Knapi\u0144ski","Wies\u0142aw Kope\u0107"],"comments":"8 pages, including 1 page of bibliography, 9 figures. Panel summary\n  to be published in proceedings from 11th Machine Intelligence and Digital\n  Interaction MIDI Conference","categories":["cs.CY","cs.DL","cs.HC"],"primary_category":"cs.CY","doi":null,"journal_ref":null,"peer_reviewed":true,"primary_category_readable":"Computers and Society","gpt4_jargon_list":"No jargon terms identified.","human_jargon_list":""},"19":{"arxiv_id":"2403.06267v1","reader_id":"rid1","len_gpt_jargon":19,"len_human_jargon":5,"precision":0.1052631579,"recall":0.4,"f1_score":0.1666666667,"f2_score":0.2564102564,"fuzzy_true_positives":2,"fuzzy_false_positives":17,"fuzzy_false_negatives":3,"url":"http:\/\/arxiv.org\/abs\/2403.06267v1","title":"FARPLS: A Feature-Augmented Robot Trajectory Preference Labeling System\n  to Assist Human Labelers' Preference Elicitation","summary":"Preference-based learning aims to align robot task objectives with human values. One of the most common methods to infer human preferences is by pairwise comparisons of robot task trajectories. Traditional comparison-based preference labeling systems seldom support labelers to digest and identify critical differences between complex trajectories recorded in videos. Our formative study (N = 12) suggests that individuals may overlook non-salient task features and establish biased preference criteria during their preference elicitation process because of partial observations. In addition, they may experience mental fatigue when given many pairs to compare, causing their label quality to deteriorate. To mitigate these issues, we propose FARPLS, a Feature-Augmented Robot trajectory Preference Labeling System. FARPLS highlights potential outliers in a wide variety of task features that matter to humans and extracts the corresponding video keyframes for easy review and comparison. It also dynamically adjusts the labeling order according to users' familiarities, difficulties of the trajectory pair, and level of disagreements. At the same time, the system monitors labelers' consistency and provides feedback on labeling progress to keep labelers engaged. A between-subjects study (N = 42, 105 pairs of robot pick-and-place trajectories per person) shows that FARPLS can help users establish preference criteria more easily and notice more relevant details in the presented trajectories than the conventional interface. FARPLS also improves labeling consistency and engagement, mitigating challenges in preference elicitation without raising cognitive loads significantly","updated":1710090440000,"published":1710090440000,"authors":["Hanfang Lyu","Yuanchen Bai","Xin Liang","Ujaan Das","Chuhan Shi","Leiliang Gong","Yingchi Li","Mingfei Sun","Ming Ge","Xiaojuan Ma"],"comments":"Accepted to ACM Conference on Intelligent User Interfaces (IUI) 2024,\n  March 18-21, 2024, Greenville, SC, USA","categories":["cs.HC","cs.AI"],"primary_category":"cs.HC","doi":"10.1145\/3640543.3645145","journal_ref":null,"peer_reviewed":true,"primary_category_readable":"Human-Computer Interaction","gpt4_jargon_list":"pairwise comparisons, robot task trajectories, preference labeling systems, labelers, non-salient task features, preference elicitation process, mental fatigue, Feature-Augmented Robot trajectory Preference Labeling System, outliers, task features, video keyframes, labeling order, disagreements, labelers' consistency, between-subjects study, robot pick-and-place trajectories, labeling consistency, preference elicitation, cognitive loads","human_jargon_list":"Preference-based learning,non-salient,FARPLS,trajectory pair,cognitive loads"},"20":{"arxiv_id":"2403.06039v1","reader_id":"rid0","len_gpt_jargon":1,"len_human_jargon":0,"precision":0.0,"recall":0.0,"f1_score":0.0,"f2_score":0.0,"fuzzy_true_positives":0,"fuzzy_false_positives":1,"fuzzy_false_negatives":0,"url":"http:\/\/arxiv.org\/abs\/2403.06039v1","title":"A Preliminary Exploration of YouTubers' Use of Generative-AI in Content\n  Creation","summary":"Content creators increasingly utilize generative artificial intelligence (Gen-AI) on platforms such as YouTube, TikTok, Instagram, and various blogging sites to produce imaginative images, AI-generated videos, and articles using Large Language Models (LLMs). Despite its growing popularity, there remains an underexplored area concerning the specific domains where AI-generated content is being applied, and the methodologies content creators employ with Gen-AI tools during the creation process. This study initially explores this emerging area through a qualitative analysis of 68 YouTube videos demonstrating Gen-AI usage. Our research focuses on identifying the content domains, the variety of tools used, the activities performed, and the nature of the final products generated by Gen-AI in the context of user-generated content.","updated":1710026576000,"published":1710026576000,"authors":["Yao Lyu","He Zhang","Shuo Niu","Jie Cai"],"comments":"Accepted at CHI LBW 2024","categories":["cs.HC","cs.AI"],"primary_category":"cs.HC","doi":"10.1145\/3613905.3651057","journal_ref":null,"peer_reviewed":true,"primary_category_readable":"Human-Computer Interaction","gpt4_jargon_list":"qualitative analysis","human_jargon_list":""},"21":{"arxiv_id":"2403.06039v1","reader_id":"rid1","len_gpt_jargon":4,"len_human_jargon":0,"precision":0.0,"recall":0.0,"f1_score":0.0,"f2_score":0.0,"fuzzy_true_positives":0,"fuzzy_false_positives":4,"fuzzy_false_negatives":0,"url":"http:\/\/arxiv.org\/abs\/2403.06039v1","title":"A Preliminary Exploration of YouTubers' Use of Generative-AI in Content\n  Creation","summary":"Content creators increasingly utilize generative artificial intelligence (Gen-AI) on platforms such as YouTube, TikTok, Instagram, and various blogging sites to produce imaginative images, AI-generated videos, and articles using Large Language Models (LLMs). Despite its growing popularity, there remains an underexplored area concerning the specific domains where AI-generated content is being applied, and the methodologies content creators employ with Gen-AI tools during the creation process. This study initially explores this emerging area through a qualitative analysis of 68 YouTube videos demonstrating Gen-AI usage. Our research focuses on identifying the content domains, the variety of tools used, the activities performed, and the nature of the final products generated by Gen-AI in the context of user-generated content.","updated":1710026576000,"published":1710026576000,"authors":["Yao Lyu","He Zhang","Shuo Niu","Jie Cai"],"comments":"Accepted at CHI LBW 2024","categories":["cs.HC","cs.AI"],"primary_category":"cs.HC","doi":"10.1145\/3613905.3651057","journal_ref":null,"peer_reviewed":true,"primary_category_readable":"Human-Computer Interaction","gpt4_jargon_list":"generative artificial intelligence, qualitative analysis, content domains, user-generated content","human_jargon_list":""},"22":{"arxiv_id":"2402.09494v2","reader_id":"rid0","len_gpt_jargon":3,"len_human_jargon":0,"precision":0.0,"recall":0.0,"f1_score":0.0,"f2_score":0.0,"fuzzy_true_positives":0,"fuzzy_false_positives":3,"fuzzy_false_negatives":0,"url":"http:\/\/arxiv.org\/abs\/2402.09494v2","title":"Can AI and humans genuinely communicate?","summary":"Can AI and humans genuinely communicate? In this article, after giving some background and motivating my proposal (sections 1 to 3), I explore a way to answer this question that I call the \"mental-behavioral methodology\" (sections 4 and 5). This methodology follows the following three steps: First, spell out what mental capacities are sufficient for human communication (as opposed to communication more generally). Second, spell out the experimental paradigms required to test whether a behavior exhibits these capacities. Third, apply or adapt these paradigms to test whether an AI displays the relevant behaviors. If the first two steps are successfully completed, and if the AI passes the tests with human-like results, this constitutes evidence that this AI and humans can genuinely communicate. This mental-behavioral methodology has the advantage that we don't need to understand the workings of black-box algorithms, such as standard deep neural networks. This is comparable to the fact that we don't need to understand how human brains work to know that humans can genuinely communicate. This methodology also has its disadvantages and I will discuss some of them (section 6).","updated":1711384364000,"published":1707915640000,"authors":["Constant Bonard"],"comments":"March 2024 preprint","categories":["cs.HC","cs.AI"],"primary_category":"cs.HC","doi":null,"journal_ref":null,"peer_reviewed":true,"primary_category_readable":"Human-Computer Interaction","gpt4_jargon_list":"mental-behavioral methodology,black-box algorithms,standard deep neural networks","human_jargon_list":""},"23":{"arxiv_id":"2403.06431v1","reader_id":"rid0","len_gpt_jargon":2,"len_human_jargon":0,"precision":0.0,"recall":0.0,"f1_score":0.0,"f2_score":0.0,"fuzzy_true_positives":0,"fuzzy_false_positives":2,"fuzzy_false_negatives":0,"url":"http:\/\/arxiv.org\/abs\/2403.06431v1","title":"From Fitting Participation to Forging Relationships: The Art of\n  Participatory ML","summary":"Participatory machine learning (ML) encourages the inclusion of end users and people affected by ML systems in design and development processes. We interviewed 18 participation brokers -- individuals who facilitate such inclusion and transform the products of participants' labour into inputs for an ML artefact or system -- across a range of organisational settings and project locations. Our findings demonstrate the inherent challenges of integrating messy contextual information generated through participation with the structured data formats required by ML workflows and the uneven power dynamics in project contexts. We advocate for evolution in the role of brokers to more equitably balance value generated in Participatory ML projects for design and development teams with value created for participants. To move beyond `fitting' participation to existing processes and empower participants to envision alternative futures through ML, brokers must become educators and advocates for end users, while attending to frustration and dissent from indirect stakeholders.","updated":1710132274000,"published":1710132274000,"authors":["Ned Cooper","Alex Zafiroglu"],"comments":"To appear in Proceedings of the 2024 CHI Conference on Human Factors\n  in Computing Systems (CHI '24)","categories":["cs.HC","cs.CY"],"primary_category":"cs.HC","doi":null,"journal_ref":null,"peer_reviewed":true,"primary_category_readable":"Human-Computer Interaction","gpt4_jargon_list":"participation brokers, ML artefact","human_jargon_list":""},"24":{"arxiv_id":"2403.06431v1","reader_id":"rid1","len_gpt_jargon":5,"len_human_jargon":1,"precision":0.0,"recall":0.0,"f1_score":0.0,"f2_score":0.0,"fuzzy_true_positives":0,"fuzzy_false_positives":5,"fuzzy_false_negatives":1,"url":"http:\/\/arxiv.org\/abs\/2403.06431v1","title":"From Fitting Participation to Forging Relationships: The Art of\n  Participatory ML","summary":"Participatory machine learning (ML) encourages the inclusion of end users and people affected by ML systems in design and development processes. We interviewed 18 participation brokers -- individuals who facilitate such inclusion and transform the products of participants' labour into inputs for an ML artefact or system -- across a range of organisational settings and project locations. Our findings demonstrate the inherent challenges of integrating messy contextual information generated through participation with the structured data formats required by ML workflows and the uneven power dynamics in project contexts. We advocate for evolution in the role of brokers to more equitably balance value generated in Participatory ML projects for design and development teams with value created for participants. To move beyond `fitting' participation to existing processes and empower participants to envision alternative futures through ML, brokers must become educators and advocates for end users, while attending to frustration and dissent from indirect stakeholders.","updated":1710132274000,"published":1710132274000,"authors":["Ned Cooper","Alex Zafiroglu"],"comments":"To appear in Proceedings of the 2024 CHI Conference on Human Factors\n  in Computing Systems (CHI '24)","categories":["cs.HC","cs.CY"],"primary_category":"cs.HC","doi":null,"journal_ref":null,"peer_reviewed":true,"primary_category_readable":"Human-Computer Interaction","gpt4_jargon_list":"participation brokers, messy contextual information, structured data formats, uneven power dynamics, indirect stakeholders","human_jargon_list":"Participatory machine learning,"},"25":{"arxiv_id":"2403.06651v1","reader_id":"rid0","len_gpt_jargon":6,"len_human_jargon":0,"precision":0.0,"recall":0.0,"f1_score":0.0,"f2_score":0.0,"fuzzy_true_positives":0,"fuzzy_false_positives":6,"fuzzy_false_negatives":0,"url":"http:\/\/arxiv.org\/abs\/2403.06651v1","title":"SoniWeight Shoes: Investigating Effects and Personalization of a\n  Wearable Sound Device for Altering Body Perception and Behavior","summary":"Changes in body perception influence behavior and emotion and can be induced through multisensory feedback. Auditory feedback to one's actions can trigger such alterations; however, it is unclear which individual factors modulate these effects. We employ and evaluate SoniWeight Shoes, a wearable device based on literature for altering one's weight perception through manipulated footstep sounds. In a healthy population sample across a spectrum of individuals (n=84) with varying degrees of eating disorder symptomatology, physical activity levels, body concerns, and mental imagery capacities, we explore the effects of three sound conditions (low-frequency, high-frequency and control) on extensive body perception measures (demographic, behavioral, physiological, psychological, and subjective). Analyses revealed an impact of individual differences in each of these dimensions. Besides replicating previous findings, we reveal and highlight the role of individual differences in body perception, offering avenues for personalized sonification strategies. Datasets, technical refinements, and novel body map quantification tools are provided.","updated":1710159374000,"published":1710159374000,"authors":["A. D'Adamo","M. Roel-Lesur","L. Turmo-Vidal","M. M. Dehshibi","D. De La Prida","J. R. Diaz-Duran","L. A. Azpicueta-Ruiz","A. V\u00e4ljam\u00e4e","A. Tajadura-Jim\u00e9nez"],"comments":"Conditionally Accepted in CHI '24 Conference","categories":["cs.HC"],"primary_category":"cs.HC","doi":"10.1145\/3613904.3642651","journal_ref":null,"peer_reviewed":true,"primary_category_readable":"Human-Computer Interaction","gpt4_jargon_list":"SoniWeight Shoes, multisensory feedback, manipulated footstep sounds, extensive body perception measures, personalized sonification strategies, body map quantification tools","human_jargon_list":""},"26":{"arxiv_id":"2403.08041v1","reader_id":"rid0","len_gpt_jargon":4,"len_human_jargon":0,"precision":0.0,"recall":0.0,"f1_score":0.0,"f2_score":0.0,"fuzzy_true_positives":0,"fuzzy_false_positives":4,"fuzzy_false_negatives":0,"url":"http:\/\/arxiv.org\/abs\/2403.08041v1","title":"What would Plato say? Concepts and notions from Greek philosophy applied\n  to gamification mechanics for a meaningful and ethical gamification","summary":"Gamification, the integration of game mechanics in non-game settings, has become increasingly prevalent in various digital platforms; however, its ethical and societal impacts are often overlooked. This paper delves into how Platonic and Aristotelian philosophies can provide a critical framework for understanding and evaluating the ethical dimensions of gamification. Plato's allegory of the cave and theory of forms are used to analyse the perception of reality in gamified environments, questioning their authenticity and the value of virtual achievements, while Aristotle's virtue ethics, with its emphasis on moderation, virtue, and eudaimonia (true and full happiness), can help assess how gamification influences user behaviour and ethical decision-making. The paper critically examines various gamification elements, such as the hero's journey, altruistic actions, badge levels, and user autonomy, through these philosophical lenses, and addresses the ethical responsibilities of gamification designers, advocating for a balanced approach that prioritizes user well-being and ethical development over commercial interests. By bridging ancient philosophical insights with modern digital culture, this research contributes to a deeper understanding of the ethical implications of gamification, emphasizing the need for responsible and virtuous design in digital applications.","updated":1710271513000,"published":1710271513000,"authors":["Kostas Karpouzis"],"comments":"Accepted for presentation at GamiFIN 2024","categories":["cs.HC"],"primary_category":"cs.HC","doi":null,"journal_ref":null,"peer_reviewed":true,"primary_category_readable":"Human-Computer Interaction","gpt4_jargon_list":"Plato's allegory of the cave, theory of forms, virtue ethics, eudaimonia","human_jargon_list":""},"27":{"arxiv_id":"2403.12344v1","reader_id":"rid0","len_gpt_jargon":5,"len_human_jargon":0,"precision":0.0,"recall":0.0,"f1_score":0.0,"f2_score":0.0,"fuzzy_true_positives":0,"fuzzy_false_positives":5,"fuzzy_false_negatives":0,"url":"http:\/\/arxiv.org\/abs\/2403.12344v1","title":"Human Factors in Space Exploration: Opportunities for International and\n  Interdisciplinary Collaboration","summary":"As humanity pushes the boundaries of space exploration, human factors research becomes more important. Human factors encompass a broad spectrum of psychological, physiological, and ergonomic factors that affect human performance, well-being, and safety in the unique and challenging space environment. This panel explores the multifaceted field of human factors in space exploration and highlights the opportunities that lie in fostering international and interdisciplinary cooperation. This exploration delves into the current state of research on human factors in space missions, addressing the physiological and psychological challenges astronauts face during long space flights. It emphasizes the importance of interdisciplinary collaboration, combining knowledge from fields such as psychology, medicine, engineering, and design to address the complex interaction of factors affecting human performance and adaptation to the space environment","updated":1710811635000,"published":1710811635000,"authors":["Wies\u0142aw Kope\u0107","Grzegorz Pochwatko","Monika Kornacka","Wiktor Stawski","Maciej Grzeszczuk","Kinga Skorupska","Barbara Karpowicz","Rafa\u0142 Mas\u0142yk","Pavlo Zinevych","Stanis\u0142aw Knapi\u0144ski","Steven Barnes","Cezary Biele"],"comments":"13 pages including bibliography, 4 figures. To be published by\n  Springer as MIDI 2023 Conference proceedings","categories":["cs.HC"],"primary_category":"cs.HC","doi":null,"journal_ref":null,"peer_reviewed":true,"primary_category_readable":"Human-Computer Interaction","gpt4_jargon_list":"psychological, physiological, ergonomic factors, human performance, well-being","human_jargon_list":""},"28":{"arxiv_id":"2403.19436v1","reader_id":"rid0","len_gpt_jargon":5,"len_human_jargon":0,"precision":0.0,"recall":0.0,"f1_score":0.0,"f2_score":0.0,"fuzzy_true_positives":0,"fuzzy_false_positives":5,"fuzzy_false_negatives":0,"url":"http:\/\/arxiv.org\/abs\/2403.19436v1","title":"\"At the end of the day, I am accountable\": Gig Workers' Self-Tracking\n  for Multi-Dimensional Accountability Management","summary":"Tracking is inherent in and central to the gig economy. Platforms track gig workers' performance through metrics such as acceptance rate and punctuality, while gig workers themselves engage in self-tracking. Although prior research has extensively examined how gig platforms track workers through metrics -- with some studies briefly acknowledging the phenomenon of self-tracking among workers -- there is a dearth of studies that explore how and why gig workers track themselves. To address this, we conducted 25 semi-structured interviews, revealing how gig workers self-tracking to manage accountabilities to themselves and external entities across three identities: the holistic self, the entrepreneurial self, and the platformized self. We connect our findings to neoliberalism, through which we contextualize gig workers' self-accountability and the invisible labor of self-tracking. We further discuss how self-tracking mitigates information and power asymmetries in gig work and offer design implications to support gig workers' multi-dimensional self-tracking.","updated":1711634670000,"published":1711634670000,"authors":["Rie Helene Hernandez","Qiurong Song","Yubo Kou","Xinning Gui"],"comments":"Accepted to CHI 2024","categories":["cs.HC"],"primary_category":"cs.HC","doi":null,"journal_ref":null,"peer_reviewed":true,"primary_category_readable":"Human-Computer Interaction","gpt4_jargon_list":"neoliberalism, entrepreneurial self, platformized self, semi-structured interviews, design implications","human_jargon_list":""},"29":{"arxiv_id":"2403.19436v1","reader_id":"rid1","len_gpt_jargon":11,"len_human_jargon":2,"precision":0.0,"recall":0.0,"f1_score":0.0,"f2_score":0.0,"fuzzy_true_positives":0,"fuzzy_false_positives":11,"fuzzy_false_negatives":2,"url":"http:\/\/arxiv.org\/abs\/2403.19436v1","title":"\"At the end of the day, I am accountable\": Gig Workers' Self-Tracking\n  for Multi-Dimensional Accountability Management","summary":"Tracking is inherent in and central to the gig economy. Platforms track gig workers' performance through metrics such as acceptance rate and punctuality, while gig workers themselves engage in self-tracking. Although prior research has extensively examined how gig platforms track workers through metrics -- with some studies briefly acknowledging the phenomenon of self-tracking among workers -- there is a dearth of studies that explore how and why gig workers track themselves. To address this, we conducted 25 semi-structured interviews, revealing how gig workers self-tracking to manage accountabilities to themselves and external entities across three identities: the holistic self, the entrepreneurial self, and the platformized self. We connect our findings to neoliberalism, through which we contextualize gig workers' self-accountability and the invisible labor of self-tracking. We further discuss how self-tracking mitigates information and power asymmetries in gig work and offer design implications to support gig workers' multi-dimensional self-tracking.","updated":1711634670000,"published":1711634670000,"authors":["Rie Helene Hernandez","Qiurong Song","Yubo Kou","Xinning Gui"],"comments":"Accepted to CHI 2024","categories":["cs.HC"],"primary_category":"cs.HC","doi":null,"journal_ref":null,"peer_reviewed":true,"primary_category_readable":"Human-Computer Interaction","gpt4_jargon_list":"acceptance rate, punctuality, semi-structured interviews, accountabilities, entrepreneurial self, platformized self, neoliberalism, invisible labor, information and power asymmetries, design implications, multi-dimensional self-tracking","human_jargon_list":"gig economy,dearthneoliberalism,"},"30":{"arxiv_id":"2403.16018v1","reader_id":"rid0","len_gpt_jargon":7,"len_human_jargon":0,"precision":0.0,"recall":0.0,"f1_score":0.0,"f2_score":0.0,"fuzzy_true_positives":0,"fuzzy_false_positives":7,"fuzzy_false_negatives":0,"url":"http:\/\/arxiv.org\/abs\/2403.16018v1","title":"Understanding the Impact of Referent Design on Scale Perception in\n  Immersive Data Visualization","summary":"Referents are often used to enhance scale perception in immersive visualizations. Common referent designs include the considerations of referent layout (side-by-side vs. in-situ) and referent size (small vs. medium vs. large). This paper introduces a controlled user study to assess how different referent designs affect the efficiency and accuracy of scale perception across different data scales, on the performance of the size-matching task in the virtual environment. Our results reveal that in-situ layouts significantly enhance accuracy and confidence across various data scales, particularly with large referents. Linear regression analyses further confirm that in-situ layouts exhibit greater resilience to changes in data scale. For tasks requiring efficiency, medium-sized referents emerge as the preferred choice. Based on these findings, we offer design guidelines for selecting referent layouts and sizes in immersive visualizations.","updated":1711258709000,"published":1711258709000,"authors":["Yihan Hou","Hao Cui","Rongrong Chen","Wei Zeng"],"comments":"7 pages, 6 figures, Accepted to Extended Abstracts of the CHI\n  Conference on Human Factors in Computing Systems (CHI EA '24)","categories":["cs.HC"],"primary_category":"cs.HC","doi":"10.1145\/3613905.3650783","journal_ref":null,"peer_reviewed":true,"primary_category_readable":"Human-Computer Interaction","gpt4_jargon_list":"referent layout, in-situ, size-matching task, in-situ layouts, Linear regression analyses, data scale, immersive visualizations","human_jargon_list":""},"31":{"arxiv_id":"2403.08057v1","reader_id":"rid0","len_gpt_jargon":7,"len_human_jargon":0,"precision":0.0,"recall":0.0,"f1_score":0.0,"f2_score":0.0,"fuzzy_true_positives":0,"fuzzy_false_positives":7,"fuzzy_false_negatives":0,"url":"http:\/\/arxiv.org\/abs\/2403.08057v1","title":"MineXR: Mining Personalized Extended Reality Interfaces","summary":"Extended Reality (XR) interfaces offer engaging user experiences, but their effective design requires a nuanced understanding of user behavior and preferences. This knowledge is challenging to obtain without the widespread adoption of XR devices. We introduce MineXR, a design mining workflow and data analysis platform for collecting and analyzing personalized XR user interaction and experience data. MineXR enables elicitation of personalized interfaces from participants of a data collection: for any particular context, participants create interface elements using application screenshots from their own smartphone, place them in the environment, and simultaneously preview the resulting XR layout on a headset. Using MineXR, we contribute a dataset of personalized XR interfaces collected from 31 participants, consisting of 695 XR widgets created from 178 unique applications. We provide insights for XR widget functionalities, categories, clusters, UI element types, and placement. Our open-source tools and data support researchers and designers in developing future XR interfaces.","updated":1710273914000,"published":1710273914000,"authors":["Hyunsung Cho","Yukang Yan","Kashyap Todi","Mark Parent","Missie Smith","Tanya R. Jonker","Hrvoje Benko","David Lindlbauer"],"comments":"17 pages, 18 figures, Proceedings of the 2024 CHI Conference on Human\n  Factors in Computing Systems","categories":["cs.HC","H.5.2"],"primary_category":"cs.HC","doi":"10.1145\/3613904.3642394","journal_ref":null,"peer_reviewed":true,"primary_category_readable":"Human-Computer Interaction","gpt4_jargon_list":"MineXR, design mining workflow, personalized XR user interaction, XR widget functionalities, XR widget categories, XR widget clusters, UI element types","human_jargon_list":""},"32":{"arxiv_id":"2403.12730v1","reader_id":"rid0","len_gpt_jargon":9,"len_human_jargon":0,"precision":0.0,"recall":0.0,"f1_score":0.0,"f2_score":0.0,"fuzzy_true_positives":0,"fuzzy_false_positives":9,"fuzzy_false_negatives":0,"url":"http:\/\/arxiv.org\/abs\/2403.12730v1","title":"What Does Evaluation of Explainable Artificial Intelligence Actually\n  Tell Us? A Case for Compositional and Contextual Validation of XAI Building\n  Blocks","summary":"Despite significant progress, evaluation of explainable artificial intelligence remains elusive and challenging. In this paper we propose a fine-grained validation framework that is not overly reliant on any one facet of these sociotechnical systems, and that recognises their inherent modular structure: technical building blocks, user-facing explanatory artefacts and social communication protocols. While we concur that user studies are invaluable in assessing the quality and effectiveness of explanation presentation and delivery strategies from the explainees' perspective in a particular deployment context, the underlying explanation generation mechanisms require a separate, predominantly algorithmic validation strategy that accounts for the technical and human-centred desiderata of their (numerical) outputs. Such a comprehensive sociotechnical utility-based evaluation framework could allow to systematically reason about the properties and downstream influence of different building blocks from which explainable artificial intelligence systems are composed -- accounting for a diverse range of their engineering and social aspects -- in view of the anticipated use case.","updated":1710855934000,"published":1710855934000,"authors":["Kacper Sokol","Julia E. Vogt"],"comments":"Published in Extended Abstracts of the 2024 CHI Conference on Human\n  Factors in Computing Systems (CHI EA '24)","categories":["cs.HC","cs.AI"],"primary_category":"cs.HC","doi":"10.1145\/3613905.3651047","journal_ref":null,"peer_reviewed":true,"primary_category_readable":"Human-Computer Interaction","gpt4_jargon_list":"fine-grained validation framework, sociotechnical systems, technical building blocks, user-facing explanatory artefacts, social communication protocols, explanation generation mechanisms, predominantly algorithmic validation strategy, human-centred desiderata, sociotechnical utility-based evaluation framework","human_jargon_list":""},"33":{"arxiv_id":"2403.18173v1","reader_id":"rid0","len_gpt_jargon":4,"len_human_jargon":0,"precision":0.0,"recall":0.0,"f1_score":0.0,"f2_score":0.0,"fuzzy_true_positives":0,"fuzzy_false_positives":4,"fuzzy_false_negatives":0,"url":"http:\/\/arxiv.org\/abs\/2403.18173v1","title":"LLMs in HCI Data Work: Bridging the Gap Between Information Retrieval\n  and Responsible Research Practices","summary":"Efficient and accurate information extraction from scientific papers is significant in the rapidly developing human-computer interaction research in the literature review process. Our paper introduces and analyses a new information retrieval system using state-of-the-art Large Language Models (LLMs) in combination with structured text analysis techniques to extract experimental data from HCI literature, emphasizing key elements. Then We analyze the challenges and risks of using LLMs in the world of research. We performed a comprehensive analysis on our conducted dataset, which contained the specified information of 300 CHI 2020-2022 papers, to evaluate the performance of the two large language models, GPT-3.5 (text-davinci-003) and Llama-2-70b, paired with structured text analysis techniques. The GPT-3.5 model gains an accuracy of 58\\% and a mean absolute error of 7.00. In contrast, the Llama2 model indicates an accuracy of 56\\% with a mean absolute error of 7.63. The ability to answer questions was also included in the system in order to work with streamlined data. By evaluating the risks and opportunities presented by LLMs, our work contributes to the ongoing dialogue on establishing methodological validity and ethical guidelines for LLM use in HCI data work.","updated":1711501269000,"published":1711501269000,"authors":["Neda Taghizadeh Serajeh","Iman Mohammadi","Vittorio Fuccella","Mattia De Rosa"],"comments":"5 pages, CHI2024 Workshop on LLMs as Research Tools: Applications and\n  Evaluations in HCI Data Work","categories":["cs.HC","cs.IR"],"primary_category":"cs.HC","doi":null,"journal_ref":null,"peer_reviewed":true,"primary_category_readable":"Human-Computer Interaction","gpt4_jargon_list":"Large Language Models (LLMs), GPT-3.5 (text-davinci-003), Llama-2-70b, mean absolute error","human_jargon_list":""},"34":{"arxiv_id":"2403.18173v1","reader_id":"rid1","len_gpt_jargon":4,"len_human_jargon":0,"precision":0.0,"recall":0.0,"f1_score":0.0,"f2_score":0.0,"fuzzy_true_positives":0,"fuzzy_false_positives":4,"fuzzy_false_negatives":0,"url":"http:\/\/arxiv.org\/abs\/2403.18173v1","title":"LLMs in HCI Data Work: Bridging the Gap Between Information Retrieval\n  and Responsible Research Practices","summary":"Efficient and accurate information extraction from scientific papers is significant in the rapidly developing human-computer interaction research in the literature review process. Our paper introduces and analyses a new information retrieval system using state-of-the-art Large Language Models (LLMs) in combination with structured text analysis techniques to extract experimental data from HCI literature, emphasizing key elements. Then We analyze the challenges and risks of using LLMs in the world of research. We performed a comprehensive analysis on our conducted dataset, which contained the specified information of 300 CHI 2020-2022 papers, to evaluate the performance of the two large language models, GPT-3.5 (text-davinci-003) and Llama-2-70b, paired with structured text analysis techniques. The GPT-3.5 model gains an accuracy of 58\\% and a mean absolute error of 7.00. In contrast, the Llama2 model indicates an accuracy of 56\\% with a mean absolute error of 7.63. The ability to answer questions was also included in the system in order to work with streamlined data. By evaluating the risks and opportunities presented by LLMs, our work contributes to the ongoing dialogue on establishing methodological validity and ethical guidelines for LLM use in HCI data work.","updated":1711501269000,"published":1711501269000,"authors":["Neda Taghizadeh Serajeh","Iman Mohammadi","Vittorio Fuccella","Mattia De Rosa"],"comments":"5 pages, CHI2024 Workshop on LLMs as Research Tools: Applications and\n  Evaluations in HCI Data Work","categories":["cs.HC","cs.IR"],"primary_category":"cs.HC","doi":null,"journal_ref":null,"peer_reviewed":true,"primary_category_readable":"Human-Computer Interaction","gpt4_jargon_list":"Large Language Models,structured text analysis techniques,methodological validity,ethical guidelines","human_jargon_list":""},"35":{"arxiv_id":"2403.01697v1","reader_id":"rid0","len_gpt_jargon":6,"len_human_jargon":0,"precision":0.0,"recall":0.0,"f1_score":0.0,"f2_score":0.0,"fuzzy_true_positives":0,"fuzzy_false_positives":6,"fuzzy_false_negatives":0,"url":"http:\/\/arxiv.org\/abs\/2403.01697v1","title":"Dismantling Gender Blindness in Online Discussion of a Crime\/Gender\n  Dichotomy","summary":"Contemporary feminists utilize social media for activism, while backlashes come along. The gender-related discourses are often diminished when addressing public events regarding sexism and gender inequality on social media platforms. The dichotomized debate around the Tangshan beating incident in China epitomized how criminal interpretations of gender-related violence became a backlash against feminist expressions. By analyzing posts on Weibo using mixed methods, we describe the emerging discursive patterns around crime and gender, uncovering the inherent gender-blind sexism that refutes feminist discourses on the social platform. We also highlight the critical restrictions facing grassroots feminist activism in Chinese cyberspace and propose implications for the design and research related to digital feminist activism.","updated":1709522274000,"published":1709522274000,"authors":["Yigang Qin","Weilun Duan","Qunfang Wu","Zhicong Lu"],"comments":"31 pages, 3 figures, Accepted for publication in Proceedings of the\n  ACM on Human-Computer Interaction (CSCW 2024)","categories":["cs.HC"],"primary_category":"cs.HC","doi":null,"journal_ref":null,"peer_reviewed":true,"primary_category_readable":"Human-Computer Interaction","gpt4_jargon_list":"Tangshan beating incident, mixed methods, gender-blind sexism, grassroots feminist activism, Chinese cyberspace, digital feminist activism","human_jargon_list":""},"36":{"arxiv_id":"2403.01697v1","reader_id":"rid1","len_gpt_jargon":5,"len_human_jargon":3,"precision":0.2,"recall":0.3333333333,"f1_score":0.25,"f2_score":0.2941176471,"fuzzy_true_positives":1,"fuzzy_false_positives":4,"fuzzy_false_negatives":2,"url":"http:\/\/arxiv.org\/abs\/2403.01697v1","title":"Dismantling Gender Blindness in Online Discussion of a Crime\/Gender\n  Dichotomy","summary":"Contemporary feminists utilize social media for activism, while backlashes come along. The gender-related discourses are often diminished when addressing public events regarding sexism and gender inequality on social media platforms. The dichotomized debate around the Tangshan beating incident in China epitomized how criminal interpretations of gender-related violence became a backlash against feminist expressions. By analyzing posts on Weibo using mixed methods, we describe the emerging discursive patterns around crime and gender, uncovering the inherent gender-blind sexism that refutes feminist discourses on the social platform. We also highlight the critical restrictions facing grassroots feminist activism in Chinese cyberspace and propose implications for the design and research related to digital feminist activism.","updated":1709522274000,"published":1709522274000,"authors":["Yigang Qin","Weilun Duan","Qunfang Wu","Zhicong Lu"],"comments":"31 pages, 3 figures, Accepted for publication in Proceedings of the\n  ACM on Human-Computer Interaction (CSCW 2024)","categories":["cs.HC"],"primary_category":"cs.HC","doi":null,"journal_ref":null,"peer_reviewed":true,"primary_category_readable":"Human-Computer Interaction","gpt4_jargon_list":"dichotomized debate, gender-blind sexism, grassroots feminist activism, Chinese cyberspace, digital feminist activism","human_jargon_list":"Tangshan beating incident,Weibo,grassroots feminist activism"},"37":{"arxiv_id":"2403.01055v1","reader_id":"rid0","len_gpt_jargon":8,"len_human_jargon":0,"precision":0.0,"recall":0.0,"f1_score":0.0,"f2_score":0.0,"fuzzy_true_positives":0,"fuzzy_false_positives":8,"fuzzy_false_negatives":0,"url":"http:\/\/arxiv.org\/abs\/2403.01055v1","title":"Towards Full Authorship with AI: Supporting Revision with AI-Generated\n  Views","summary":"Large language models (LLMs) are shaping a new user interface (UI) paradigm in writing tools by enabling users to generate text through prompts. This paradigm shifts some creative control from the user to the system, thereby diminishing the user's authorship and autonomy in the writing process. To restore autonomy, we introduce Textfocals, a UI prototype designed to investigate a human-centered approach that emphasizes the user's role in writing. Textfocals supports the writing process by providing LLM-generated summaries, questions, and advice (i.e., LLM views) in a sidebar of a text editor, encouraging reflection and self-driven revision in writing without direct text generation. Textfocals' UI affordances, including contextually adaptive views and scaffolding for prompt selection and customization, offer a novel way to interact with LLMs where users maintain full authorship of their writing. A formative user study with Textfocals showed promising evidence that this approach might help users develop underdeveloped ideas, cater to the rhetorical audience, and clarify their writing. However, the study also showed interaction design challenges related to document navigation and scoping, prompt engineering, and context management. Our work highlights the breadth of the design space of writing support interfaces powered by generative AI that maintain authorship integrity.","updated":1709341895000,"published":1709341895000,"authors":["Jiho Kim","Ray C. Flanagan","Noelle E. Haviland","ZeAi Sun","Souad N. Yakubu","Edom A. Maru","Kenneth C. Arnold"],"comments":"15 pages, 2 figures; Accepted to 5th Workshop on Human-AI Co-Creation\n  with Generative Models (HAI-GEN) at ACM IUI 2024","categories":["cs.HC","cs.AI","cs.CY","H.5.2; I.7.1; I.2.7"],"primary_category":"cs.HC","doi":null,"journal_ref":null,"peer_reviewed":true,"primary_category_readable":"Human-Computer Interaction","gpt4_jargon_list":"LLM views, UI affordances, contextually adaptive views, scaffolding for prompt selection and customization, formative user study, interaction design challenges, prompt engineering, context management","human_jargon_list":""},"38":{"arxiv_id":"2403.01055v1","reader_id":"rid1","len_gpt_jargon":5,"len_human_jargon":1,"precision":0.0,"recall":0.0,"f1_score":0.0,"f2_score":0.0,"fuzzy_true_positives":0,"fuzzy_false_positives":5,"fuzzy_false_negatives":1,"url":"http:\/\/arxiv.org\/abs\/2403.01055v1","title":"Towards Full Authorship with AI: Supporting Revision with AI-Generated\n  Views","summary":"Large language models (LLMs) are shaping a new user interface (UI) paradigm in writing tools by enabling users to generate text through prompts. This paradigm shifts some creative control from the user to the system, thereby diminishing the user's authorship and autonomy in the writing process. To restore autonomy, we introduce Textfocals, a UI prototype designed to investigate a human-centered approach that emphasizes the user's role in writing. Textfocals supports the writing process by providing LLM-generated summaries, questions, and advice (i.e., LLM views) in a sidebar of a text editor, encouraging reflection and self-driven revision in writing without direct text generation. Textfocals' UI affordances, including contextually adaptive views and scaffolding for prompt selection and customization, offer a novel way to interact with LLMs where users maintain full authorship of their writing. A formative user study with Textfocals showed promising evidence that this approach might help users develop underdeveloped ideas, cater to the rhetorical audience, and clarify their writing. However, the study also showed interaction design challenges related to document navigation and scoping, prompt engineering, and context management. Our work highlights the breadth of the design space of writing support interfaces powered by generative AI that maintain authorship integrity.","updated":1709341895000,"published":1709341895000,"authors":["Jiho Kim","Ray C. Flanagan","Noelle E. Haviland","ZeAi Sun","Souad N. Yakubu","Edom A. Maru","Kenneth C. Arnold"],"comments":"15 pages, 2 figures; Accepted to 5th Workshop on Human-AI Co-Creation\n  with Generative Models (HAI-GEN) at ACM IUI 2024","categories":["cs.HC","cs.AI","cs.CY","H.5.2; I.7.1; I.2.7"],"primary_category":"cs.HC","doi":null,"journal_ref":null,"peer_reviewed":true,"primary_category_readable":"Human-Computer Interaction","gpt4_jargon_list":"UI affordances, contextually adaptive views, scaffolding, prompt engineering, context management","human_jargon_list":"Textfocals"},"39":{"arxiv_id":"2305.11927v2","reader_id":"rid0","len_gpt_jargon":4,"len_human_jargon":0,"precision":0.0,"recall":0.0,"f1_score":0.0,"f2_score":0.0,"fuzzy_true_positives":0,"fuzzy_false_positives":4,"fuzzy_false_negatives":0,"url":"http:\/\/arxiv.org\/abs\/2305.11927v2","title":"Evaluating how interactive visualizations can assist in finding samples\n  where and how computer vision models make mistakes","summary":"Creating Computer Vision (CV) models remains a complex practice, despite their ubiquity. Access to data, the requirement for ML expertise, and model opacity are just a few points of complexity that limit the ability of end-users to build, inspect, and improve these models. Interactive ML perspectives have helped address some of these issues by considering a teacher in the loop where planning, teaching, and evaluating tasks take place. We present and evaluate two interactive visualizations in the context of Sprite, a system for creating CV classification and detection models for images originating from videos. We study how these visualizations help Sprite's users identify (evaluate) and select (plan) images where a model is struggling and can lead to improved performance, compared to a baseline condition where users used a query language. We found that users who had used the visualizations found more images across a wider set of potential types of model errors.","updated":1710526996000,"published":1684507380000,"authors":["Hayeong Song","Gonzalo Ramos","Peter Bodik"],"comments":"Hayeong Song, Gonzalo Ramos, and Peter Bodik. \"Evaluating how\n  interactive visualizations can assist in finding samples where and how\n  computer vision models make mistakes\" 2024 IEEE Pacific Visualization\n  Symposium (PacificVis). Ieee, 2024","categories":["cs.HC","cs.CV","cs.LG"],"primary_category":"cs.HC","doi":null,"journal_ref":null,"peer_reviewed":true,"primary_category_readable":"Human-Computer Interaction","gpt4_jargon_list":"model opacity, teacher in the loop, CV classification and detection models, baseline condition","human_jargon_list":""},"40":{"arxiv_id":"2305.11927v2","reader_id":"rid1","len_gpt_jargon":8,"len_human_jargon":1,"precision":0.0,"recall":0.0,"f1_score":0.0,"f2_score":0.0,"fuzzy_true_positives":0,"fuzzy_false_positives":8,"fuzzy_false_negatives":1,"url":"http:\/\/arxiv.org\/abs\/2305.11927v2","title":"Evaluating how interactive visualizations can assist in finding samples\n  where and how computer vision models make mistakes","summary":"Creating Computer Vision (CV) models remains a complex practice, despite their ubiquity. Access to data, the requirement for ML expertise, and model opacity are just a few points of complexity that limit the ability of end-users to build, inspect, and improve these models. Interactive ML perspectives have helped address some of these issues by considering a teacher in the loop where planning, teaching, and evaluating tasks take place. We present and evaluate two interactive visualizations in the context of Sprite, a system for creating CV classification and detection models for images originating from videos. We study how these visualizations help Sprite's users identify (evaluate) and select (plan) images where a model is struggling and can lead to improved performance, compared to a baseline condition where users used a query language. We found that users who had used the visualizations found more images across a wider set of potential types of model errors.","updated":1710526996000,"published":1684507380000,"authors":["Hayeong Song","Gonzalo Ramos","Peter Bodik"],"comments":"Hayeong Song, Gonzalo Ramos, and Peter Bodik. \"Evaluating how\n  interactive visualizations can assist in finding samples where and how\n  computer vision models make mistakes\" 2024 IEEE Pacific Visualization\n  Symposium (PacificVis). Ieee, 2024","categories":["cs.HC","cs.CV","cs.LG"],"primary_category":"cs.HC","doi":null,"journal_ref":null,"peer_reviewed":true,"primary_category_readable":"Human-Computer Interaction","gpt4_jargon_list":"Computer Vision (CV) models, model opacity, Interactive ML perspectives, teacher in the loop, interactive visualizations, CV classification and detection models, baseline condition, query language","human_jargon_list":"Sprite"},"41":{"arxiv_id":"2403.00632v1","reader_id":"rid0","len_gpt_jargon":4,"len_human_jargon":1,"precision":0.0,"recall":0.0,"f1_score":0.0,"f2_score":0.0,"fuzzy_true_positives":0,"fuzzy_false_positives":4,"fuzzy_false_negatives":1,"url":"http:\/\/arxiv.org\/abs\/2403.00632v1","title":"Metamorpheus: Interactive, Affective, and Creative Dream Narration\n  Through Metaphorical Visual Storytelling","summary":"Human emotions are essentially molded by lived experiences, from which we construct personalised meaning. The engagement in such meaning-making process has been practiced as an intervention in various psychotherapies to promote wellness. Nevertheless, to support recollecting and recounting lived experiences in everyday life remains under explored in HCI. It also remains unknown how technologies such as generative AI models can facilitate the meaning making process, and ultimately support affective mindfulness. In this paper we present Metamorpheus, an affective interface that engages users in a creative visual storytelling of emotional experiences during dreams. Metamorpheus arranges the storyline based on a dream's emotional arc, and provokes self-reflection through the creation of metaphorical images and text depictions. The system provides metaphor suggestions, and generates visual metaphors and text depictions using generative AI models, while users can apply generations to recolour and re-arrange the interface to be visually affective. Our experience-centred evaluation manifests that, by interacting with Metamorpheus, users can recall their dreams in vivid detail, through which they relive and reflect upon their experiences in a meaningful way.","updated":1709309372000,"published":1709309372000,"authors":["Qian Wan","Xin Feng","Yining Bei","Zhiqi Gao","Zhicong Lu"],"comments":"Accepted by CHI 2024","categories":["cs.HC","cs.AI","cs.CL","cs.CY"],"primary_category":"cs.HC","doi":null,"journal_ref":null,"peer_reviewed":true,"primary_category_readable":"Human-Computer Interaction","gpt4_jargon_list":"affective mindfulness, emotional arc, visual metaphors, experience-centred evaluation","human_jargon_list":"affective interface"},"42":{"arxiv_id":"2403.00632v1","reader_id":"rid1","len_gpt_jargon":4,"len_human_jargon":1,"precision":0.0,"recall":0.0,"f1_score":0.0,"f2_score":0.0,"fuzzy_true_positives":0,"fuzzy_false_positives":4,"fuzzy_false_negatives":1,"url":"http:\/\/arxiv.org\/abs\/2403.00632v1","title":"Metamorpheus: Interactive, Affective, and Creative Dream Narration\n  Through Metaphorical Visual Storytelling","summary":"Human emotions are essentially molded by lived experiences, from which we construct personalised meaning. The engagement in such meaning-making process has been practiced as an intervention in various psychotherapies to promote wellness. Nevertheless, to support recollecting and recounting lived experiences in everyday life remains under explored in HCI. It also remains unknown how technologies such as generative AI models can facilitate the meaning making process, and ultimately support affective mindfulness. In this paper we present Metamorpheus, an affective interface that engages users in a creative visual storytelling of emotional experiences during dreams. Metamorpheus arranges the storyline based on a dream's emotional arc, and provokes self-reflection through the creation of metaphorical images and text depictions. The system provides metaphor suggestions, and generates visual metaphors and text depictions using generative AI models, while users can apply generations to recolour and re-arrange the interface to be visually affective. Our experience-centred evaluation manifests that, by interacting with Metamorpheus, users can recall their dreams in vivid detail, through which they relive and reflect upon their experiences in a meaningful way.","updated":1709309372000,"published":1709309372000,"authors":["Qian Wan","Xin Feng","Yining Bei","Zhiqi Gao","Zhicong Lu"],"comments":"Accepted by CHI 2024","categories":["cs.HC","cs.AI","cs.CL","cs.CY"],"primary_category":"cs.HC","doi":null,"journal_ref":null,"peer_reviewed":true,"primary_category_readable":"Human-Computer Interaction","gpt4_jargon_list":"affective interface, emotional arc, metaphorical images, experience-centred evaluation","human_jargon_list":"Metamorpheus"},"43":{"arxiv_id":"2309.15723v2","reader_id":"rid0","len_gpt_jargon":7,"len_human_jargon":0,"precision":0.0,"recall":0.0,"f1_score":0.0,"f2_score":0.0,"fuzzy_true_positives":0,"fuzzy_false_positives":7,"fuzzy_false_negatives":0,"url":"http:\/\/arxiv.org\/abs\/2309.15723v2","title":"Where Are We So Far? Understanding Data Storytelling Tools from the\n  Perspective of Human-AI Collaboration","summary":"Data storytelling is powerful for communicating data insights, but it requires diverse skills and considerable effort from human creators. Recent research has widely explored the potential for artificial intelligence (AI) to support and augment humans in data storytelling. However, there lacks a systematic review to understand data storytelling tools from the perspective of human-AI collaboration, which hinders researchers from reflecting on the existing collaborative tool designs that promote humans' and AI's advantages and mitigate their shortcomings. This paper investigated existing tools with a framework from two perspectives: the stages in the storytelling workflow where a tool serves, including analysis, planning, implementation, and communication, and the roles of humans and AI in each stage, such as creators, assistants, optimizers, and reviewers. Through our analysis, we recognize the common collaboration patterns in existing tools, summarize lessons learned from these patterns, and further illustrate research opportunities for human-AI collaboration in data storytelling.","updated":1710766817000,"published":1695828650000,"authors":["Haotian Li","Yun Wang","Huamin Qu"],"comments":"Accepted by CHI 2024","categories":["cs.HC","cs.AI"],"primary_category":"cs.HC","doi":null,"journal_ref":null,"peer_reviewed":true,"primary_category_readable":"Human-Computer Interaction","gpt4_jargon_list":"data storytelling tools, storytelling workflow, creators, assistants, optimizers, reviewers, collaboration patterns","human_jargon_list":""},"44":{"arxiv_id":"2309.15723v2","reader_id":"rid1","len_gpt_jargon":4,"len_human_jargon":0,"precision":0.0,"recall":0.0,"f1_score":0.0,"f2_score":0.0,"fuzzy_true_positives":0,"fuzzy_false_positives":4,"fuzzy_false_negatives":0,"url":"http:\/\/arxiv.org\/abs\/2309.15723v2","title":"Where Are We So Far? Understanding Data Storytelling Tools from the\n  Perspective of Human-AI Collaboration","summary":"Data storytelling is powerful for communicating data insights, but it requires diverse skills and considerable effort from human creators. Recent research has widely explored the potential for artificial intelligence (AI) to support and augment humans in data storytelling. However, there lacks a systematic review to understand data storytelling tools from the perspective of human-AI collaboration, which hinders researchers from reflecting on the existing collaborative tool designs that promote humans' and AI's advantages and mitigate their shortcomings. This paper investigated existing tools with a framework from two perspectives: the stages in the storytelling workflow where a tool serves, including analysis, planning, implementation, and communication, and the roles of humans and AI in each stage, such as creators, assistants, optimizers, and reviewers. Through our analysis, we recognize the common collaboration patterns in existing tools, summarize lessons learned from these patterns, and further illustrate research opportunities for human-AI collaboration in data storytelling.","updated":1710766817000,"published":1695828650000,"authors":["Haotian Li","Yun Wang","Huamin Qu"],"comments":"Accepted by CHI 2024","categories":["cs.HC","cs.AI"],"primary_category":"cs.HC","doi":null,"journal_ref":null,"peer_reviewed":true,"primary_category_readable":"Human-Computer Interaction","gpt4_jargon_list":"data storytelling tools, human-AI collaboration, storytelling workflow, collaboration patterns","human_jargon_list":""}}