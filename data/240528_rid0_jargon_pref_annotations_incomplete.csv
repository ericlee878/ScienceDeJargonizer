arxiv_id,reader_id,human_jargon_term,definition_text,model
2007.00714v4,rid0,Shapley based symmetrization,"Shapley based symmetrization is a method that averages contributions from different factors or players in a way that treats each factor fairly, ensuring no particular order or arrangement of factors influences the final outcome disproportionately. This approach is often used in fields like game theory or data analysis to distribute or allocate value among contributors evenly.",gpt4_rag
2007.00714v4,rid0,Shapley based symmetrization,"Shapley based symmetrization is a method used to ensure that the measure of influence or contribution of different elements (such as nodes in a network) remains consistent, no matter how these elements are labeled or arranged. This technique borrows from game theory, where Shapley values help determine the fair distribution of payoffs among players, applying this concept to balance the contributions of different factors in a system.",gpt4_abstract
2007.00714v4,rid0,relabelling nodes,Relabelling nodes refers to renaming the points or elements in a network or diagram without altering the connections or relationships between them. It's similar to changing the names in your phone contact list without changing the phone numbers linked to each name.,gpt4_rag
2007.00714v4,rid0,relabelling nodes,Relabelling nodes refers to changing the names or identifiers of the nodes in a diagram or network without altering the actual connections or relationships between them. This process is used to ensure that the analysis or conclusions drawn from the network do not depend on the specific labels of the nodes.,gpt4_abstract
2007.00714v4,rid0,structure-preserving interventions,"Structure-preserving interventions are changes made to a specific part of a system that are carefully designed to continue mimicking the usual behavior of that part in relation to the rest of the system, without altering the overall function or output observed in the system. This type of intervention allows researchers to study the impact of specific changes while keeping everything else normally interacting as it would.",gpt4_abstract
2007.00714v4,rid0,structure-preserving interventions,"Structure-preserving interventions are a type of modification used in experiments where each element is adjusted in a way that maintains the normal relationships and dependencies it has with other elements, without disrupting the overall system's behavior. This approach helps researchers understand the intrinsic effects of specific changes while keeping the rest of the system stable and predictable.",gpt4_rag
2301.13755v3,rid0,multi-step planners,"Multi-step planners are tools used to outline a series of steps in complex processes like chemical synthesis, where they help determine the sequence of reactions needed to create a desired molecule from simpler starting materials. These planners iteratively use predictions from simpler models to navigate through possible pathways until reaching the end goal.",gpt4_rag
2301.13755v3,rid0,multi-step planners,"Multi-step planners in the context of chemical synthesis are tools that help devise a series of chemical reactions needed to create a target molecule from simpler starting substances. These planners work by figuring out each individual reaction step required to gradually build up to the final molecule, ensuring the overall process is possible and efficient.",gpt4_abstract
2301.13755v3,rid0,single-step reaction predictors,"Single-step reaction predictors are tools used in chemistry to forecast the outcome of an individual chemical reaction, such as determining what product would result from combining certain reactants. These predictors help chemists understand one part of a larger sequence in the synthesis of a complex molecule, such as a drug.",gpt4_abstract
2301.13755v3,rid0,single-step reaction predictors,"Single-step reaction predictors are tools used in chemistry to suggest possible ways a single chemical reaction can break down a molecule into simpler parts. These predictors help chemists understand how complex molecules can be decomposed, guiding them in synthesizing new compounds.",gpt4_rag
2301.13755v3,rid0,synthesis routes,Synthesis routes refer to the step-by-step methods used to create a desired chemical compound from simpler starting materials. These routes outline the sequence of chemical reactions that lead to the final product.,gpt4_abstract
2301.13755v3,rid0,synthesis routes,"Synthesis routes are the step-by-step plans or procedures used to create complex molecules from simpler substances. These routes outline the specific reactions and conditions needed to systematically build up the desired molecule, similar to a recipe in cooking.",gpt4_rag
2301.13755v3,rid0,synthesizability,"Synthesizability refers to the likelihood or ease with which a specific chemical compound can be manufactured or created in a laboratory setting using chemical reactions from available substances. This term is important in assessing whether a theoretical molecule can be practically made and used, for instance, in drug development or materials science.",gpt4_abstract
2301.13755v3,rid0,synthesizability,"Synthesizability refers to the likelihood that a proposed chemical synthesis route can successfully produce a desired molecule in a practical and efficient manner. Essentially, it measures whether a theoretical path for creating a chemical compound can actually be realized in a laboratory setting.",gpt4_rag
2301.13755v3,rid0,tree-shaped MDP,"A tree-shaped MDP (Markov Decision Process) is a framework used in computational models where decisions branch out like a tree, with each branch representing a different sequence of choices and outcomes. This structure helps in making decisions that consider various possible future scenarios in a structured manner.",gpt4_abstract
2301.13755v3,rid0,tree-shaped MDP,"A tree-shaped MDP (Markov Decision Process) is a model used to represent decision-making where choices branch out like a tree. Each branch represents a possible outcome of a decision, leading to further decisions or endpoints, allowing for the chronological organization of events and decisions in a structured way.",gpt4_rag
2307.03067v2,rid0,normalisation,"Normalisation is a process in which complex rules or patterns are simplified into a standard format without losing their original meaning, making it easier to manage and analyze data effectively. This technique is often used in computer science and data processing to organize information in a clear and consistent way.",gpt4_rag
2307.03067v2,rid0,normalisation,"Normalisation, in the context of ontology engineering, refers to the process of standardizing and organizing data within an ontology so that it follows a consistent format and structure. This makes the data easier to manage, compare, and integrate with other data sources.",gpt4_abstract
2307.03067v2,rid0,projection,"Projection in the context of ontologies involves transforming complex structures into simpler, more manageable forms, often represented as sets of basic relationships or connections. This simplification makes it easier to understand, analyze, or work with the data, especially when applying certain computational methods.",gpt4_rag
2307.03067v2,rid0,projection,"In the context of ontology engineering, ""projection"" refers to the process of selecting and abstracting relevant parts or aspects from an extensive set of information or an entire ontology to focus on specific elements or relationships that are most pertinent to a particular task or application. This helps in managing complexity and enhancing the processing efficiency of the ontology for targeted uses.",gpt4_abstract
2307.03067v2,rid0,verbalisation,Verbalisation in the context of ontology engineering refers to the process of converting the structured content of an ontology—like relationships and data properties—into understandable natural language text. This makes the information more accessible to individuals who are not experts in ontology languages.,gpt4_abstract
2307.03067v2,rid0,verbalisation,"Verbalisation refers to the process of converting complex ideas, such as those represented in a mathematical or logical format, into simple, easy-to-understand natural language text. This makes the information more accessible to people who may not be experts in the field.",gpt4_rag
2307.05300v4,rid0,multi-turn,"Multi-turn refers to a process where there are multiple rounds or exchanges of communication, much like a back-and-forth conversation between people, allowing an AI or system to gather more information, clarify details, and refine its responses or actions incrementally. Each ""turn"" represents one instance of interaction or response in the sequence.",gpt4_abstract
2307.05300v4,rid0,multi-turn,"Multi-turn refers to a process where there is a back-and-forth exchange of information or conversation, happening in multiple rounds or iterations, until a conclusion or solution is reached.",gpt4_rag
2307.05300v4,rid0,persona,"In the context of the described study, a ""persona"" refers to a simulated identity or role that an intelligent system, like a language model, adopts during a task. These personas are designed to represent different ways of thinking or problem-solving approaches, helping the system to tackle complex tasks by mimally emulating collaboration among multiple minds.",gpt4_abstract
2307.05300v4,rid0,persona,"A persona is a character or identity assumed by a system, often used to simulate a specific type of user such as a domain expert or a layperson, to tailor responses according to varying needs and expertise. This method helps in addressing specific scenarios or problems by adopting the relevant perspective or knowledge base.",gpt4_rag
2309.03685v2,rid0,description logic (DL) reasoner,"A description logic (DL) reasoner is a software tool designed to check and infer logical relationships and properties within a dataset, ensuring that the data follows specific rules and is logically consistent. It helps in maintaining the accuracy and integrity of the information in systems that manage complex data.",gpt4_abstract
2309.03685v2,rid0,description logic (DL) reasoner,"A description logic (DL) reasoner is a software tool that helps to check if a set of information, or data, follows certain rules and is logically consistent. It is commonly used to ensure that the way data is connected and organized makes sense according to predefined rules.",gpt4_rag
2310.06155v3,rid0,breadth-first,Breadth-first is an approach that explores a wide range of ideas or topics at an initial level before diving deeper into any specific area. This method allows for a broader overview and comparison of possible areas of interest before selecting one for further exploration.,gpt4_abstract
2310.06155v3,rid0,breadth-first,"Breadth-first is a method where multiple items or tasks are explored at the same level simultaneously. For example, in generating research questions, the breadth-first approach would produce several questions all at once, allowing for side-by-side comparison and exploration of different ideas at the same time.",gpt4_rag
2310.06155v3,rid0,depth-first RQ generation,"Depth-first RQ generation is a method where each new research question builds off the previous one, diving deeper into a specific topic in a sequential manner. This allows for a thorough exploration and deeper understanding of each topic as it progresses.",gpt4_rag
2310.06155v3,rid0,depth-first RQ generation,"Depth-first RQ generation is a method where researchers focus intensively on developing one research question at a time, exploring its various aspects deeply before moving on to create another question. This approach allows for a thorough examination of each topic before branching out to others.",gpt4_abstract
2310.08992v3,rid0,APPS,"APPS refers to a collection of coding problems used to test and compare the capabilities of different programming models, particularly in how well they can solve various types of coding challenges. These problems are used in research to help improve and evaluate artificial intelligence systems that generate code.",gpt4_rag
2310.08992v3,rid0,APPS,"APPS refers to a benchmark used to evaluate the performance of programming solutions generated by models or software, particularly focusing on the ability to solve more complex and varied programming tasks.",gpt4_abstract
2310.08992v3,rid0,CodeContests,"CodeContests are competitive programming events where participants try to solve complex coding problems, testing their ability to write efficient and accurate software solutions under time constraints.",gpt4_abstract
2310.08992v3,rid0,CodeContests,"CodeContests are competitive events where participants write and submit computer programs with the goal of solving specified problems or challenges. These contests test the coding skills, problem-solving ability, and speed of the programmers.",gpt4_rag
2310.08992v3,rid0,pass@1,Pass@1 refers to a performance metric used to evaluate how often a model correctly solves a problem on its first attempt without any retries or corrections.,gpt4_abstract
2310.08992v3,rid0,pass@1,Pass@1 is a measurement used to determine the percentage of tasks a system or model can solve correctly on its first attempt without any errors. This metric is often used to evaluate the performance of artificial intelligence systems when they are given a single opportunity to get the answer right.,gpt4_rag
2311.02760v2,rid0,large action spaces,"Large action spaces refer to situations in decision-making processes, such as games or simulations, where there are many possible choices or actions available at any given moment. This can make deciding the best course of action more complex because of the vast number of options to consider.",gpt4_rag
2311.02760v2,rid0,large action spaces,Large action spaces in the context of reinforcement learning refer to environments where an agent has a vast number of possible actions to choose from at each step. This can make finding the optimal actions to achieve a goal more complex and computationally demanding.,gpt4_abstract
2311.02760v2,rid0,relations' provenance data,Relations' provenance data refers to the original sources or background information regarding how the connections between different noun phrases in a causality graph were established. This information ensures that the links in the graph are transparent and verifiable.,gpt4_abstract
2311.02760v2,rid0,relations' provenance data,"Provenance data in the context of relations refers to additional information about where and how each relationship was established. This can include details such as the original sentences from which the relationships were extracted, and URLs of the web sources where these sentences can be found, providing insight into the origin and verification of the information.",gpt4_rag
2311.02760v2,rid0,sparse rewards,Sparse rewards in reinforcement learning refer to situations where feedback or rewards given to an agent are infrequent. This means the agent receives very little information about how well it is doing until specific and rare conditions are met. Such a setup can make learning the correct actions more challenging due to the scarcity of direct success indicators.,gpt4_rag
2311.02760v2,rid0,sparse rewards,Sparse rewards in reinforcement learning refer to a scenario where an agent receives meaningful feedback or rewards infrequently throughout its learning process. This means the agent has to make many decisions without getting immediate indications of whether each decision is beneficial toward achieving its overall goal.,gpt4_abstract
2311.10112v2,rid0,TKG forecasting,TKG forecasting involves predicting how connections between entities in a temporal knowledge graph (a type of dynamic database that includes time-specific information) will evolve over time. This process helps in understanding and anticipating future relationships or interactions within the graph based on past and present data.,gpt4_abstract
2311.10112v2,rid0,TKG forecasting,TKG forecasting involves predicting future events or facts in a framework where information is structured with relationships and time-specific details. Think of it as a method to forecast what happens next in a sequence of time-stamped events based on past information.,gpt4_rag
2311.10112v2,rid0,embedding-based TKGF methods,Embedding-based TKGF (Temporal Knowledge Graph Forecasting) methods are techniques that learn and utilize numerical representations of entities and relationships in a graph to predict future connections or events. These methods leverage mathematical models and data from past interactions to forecast what might happen next in the network.,gpt4_rag
2311.10112v2,rid0,embedding-based TKGF methods,"Embedding-based TKGF methods refer to techniques used in modeling temporal knowledge graphs by creating and using digital representations (or embeddings) of the knowledge graph's entities and relationships. These embeddings capture and represent the connections and characteristics of the entities and relationships, facilitating the prediction and understanding of how they evolve over time.",gpt4_abstract
2311.10112v2,rid0,temporal knowledge graphs,"Temporal knowledge graphs are a type of database that not only stores facts like who, what, when, and where but also includes the time period during which each fact is valid. This helps in understanding how information or relationships change over time.",gpt4_rag
2311.10112v2,rid0,temporal knowledge graphs,"Temporal knowledge graphs (TKGs) are advanced databases that not only store facts and information like traditional databases but also include the dimension of time. This means TKGs can track how relationships and data change over time, making them useful for understanding patterns and trends in the information they contain.",gpt4_abstract
2312.00812v4,rid0,Model Predictive Control (MPC),Model Predictive Control (MPC) is a method used in control systems which predicts and optimizes the future behavior of a system to make decisions. It repeatedly solves a mathematical model to determine the best action by anticipating future events over a set period of time.,gpt4_abstract
2312.00812v4,rid0,Model Predictive Control (MPC),Model Predictive Control (MPC) is a method used in advanced systems to predict and optimize future actions based on current data. It helps in making decisions that ensure safety and performance by considering future potential scenarios.,gpt4_rag
2312.00812v4,rid0,behavior planning scheme,"A behavior planning system in autonomous vehicles helps decide the future actions of the vehicle, such as when to change lanes or how to navigate traffic, based on current and predicted environmental conditions and scenarios.",gpt4_rag
2312.00812v4,rid0,behavior planning scheme,"A behavior planning scheme in the context of autonomous driving is a method used to decide how a vehicle will act in various traffic situations, such as when to change lanes, how to react to other vehicles, and when to accelerate or slow down, ensuring safe and efficient travel.",gpt4_abstract
2312.00812v4,rid0,contextual safety learning,Contextual safety learning in the abstract refers to a method where safety mechanisms in autonomous driving systems improve by continually adapting and learning from the specific situations and environments they encounter during operation. This allows the system to make safer decisions based on the unique circumstances it faces at any given time.,gpt4_abstract
2312.00812v4,rid0,contextual safety learning,"Contextual safety learning refers to the process where systems, such as autonomous vehicles, adjust and improve their responses based on specific situations they encounter, making decisions safer and more effective by learning from real-time data and past experiences. This approach helps the system understand and react appropriately to different driving conditions and scenarios.",gpt4_rag
2312.00812v4,rid0,safety verifier shield,"A safety verifier shield is a tool or system in technology that checks and ensures the actions or decisions made by a device or software are safe and will not lead to any harm or danger. The ""shield"" acts like a safeguard, constantly evaluating if the outcomes of these actions are safe before allowing them to proceed.",gpt4_rag
2312.00812v4,rid0,safety verifier shield,"A safety verifier shield is a protective feature added to autonomous driving systems. It checks and ensures that the decisions made by the system, such as steering or speed changes, are safe and appropriate under current driving conditions, thereby enhancing overall driving safety.",gpt4_abstract
2312.14106v2,rid0,domain shifts,"Domain shifts refer to situations where an AI system trained in one kind of environment or on a specific type of data encounters new, different conditions. This change can affect the AI's performance because the new environment may not match the one it was originally trained to handle.",gpt4_abstract
2312.14106v2,rid0,domain shifts,"Domain shifts refer to changes or variations in the environment or conditions where a model is used, compared to where it was initially trained. This can cause the model to perform worse because it encounters data or scenarios it hasn't seen before.",gpt4_rag
2312.14106v2,rid0,moral acceptability,Moral acceptability refers to whether an action or decision is considered right or wrong based on societal and cultural standards of behavior. It involves assessing whether something meets the ethical norms and values commonly upheld by a community or group.,gpt4_rag
2312.14106v2,rid0,moral acceptability,Moral acceptability refers to how appropriate or right an action is deemed based on societal values and ethical standards. It involves judging whether a behavior aligns with what is generally considered good or acceptable by society.,gpt4_abstract
2401.09210v2,rid0,moral narratives,"Moral narratives are stories or messages that emphasize specific ethical values and duties, aiming to guide behavior and influence beliefs about what is right or wrong in a particular context. These narratives often focus on promoting certain ideals, such as compassion, justice, or personal responsibility, to encourage specific actions or attitudes.",gpt4_rag
2401.09210v2,rid0,moral narratives,"Moral narratives refer to stories or messages that emphasize principles of right and wrong behavior, aiming to inspire or motivate people towards certain actions based on ethical values. These narratives are often used to shape opinions and encourage social or environmental initiatives.",gpt4_abstract
2401.10838v2,rid0,gist-level manipulation,"Gist-level manipulation refers to the process of editing and rearranging the main ideas or core messages of a text, rather than focusing on the detailed wording or structure. This allows users to modify the overarching themes or summaries of their content to better align with their goals or intentions.",gpt4_rag
2401.10838v2,rid0,gist-level manipulation,"Gist-level manipulation refers to the process of editing and refining a text based on its main ideas or core messages, rather than focusing on detailed word-by-word edits. This approach helps users quickly organize and improve the overall clarity and coherence of their text.",gpt4_abstract
2402.01786v2,rid0,Courses of Action (COAs),Courses of Action (COAs) are planned strategies or procedures developed for military operations to achieve specific objectives. They are essentially different options or paths that can be taken to respond to various scenarios or challenges in a strategic context.,gpt4_abstract
2402.01786v2,rid0,Courses of Action (COAs),"Courses of Action (COAs) are different plans or strategies that can be followed to achieve a specific mission or objective in military operations. They outline what actions to take, direct resources and personnel, and aim to accomplish goals efficiently and effectively.",gpt4_rag
2402.07398v2,rid0,HatefulMemes,HatefulMemes refers to a set of images combined with text that are used to evaluate how well computer systems can identify and differentiate hate speech within visual and textual content. This helps in preventing the spread of harmful or offensive material on the internet.,gpt4_rag
2402.07398v2,rid0,HatefulMemes,HatefulMemes is a dataset used for training and evaluating artificial intelligence models; it consists of various images combined with text captions that contain offensive or divisive content intended to promote discord or prejudice. This dataset helps developers train AI to identify and potentially moderate such harmful content in digital platforms.,gpt4_abstract
2402.07398v2,rid0,TextVQA,"TextVQA refers to a type of visual question answering where the task is to answer questions based on both the text appearing within an image and the image itself. For example, if an image contains a sign saying ""Exit"" and the question is ""What does the sign in the picture say?"", the correct answer would be ""Exit"".",gpt4_rag
2402.07398v2,rid0,TextVQA,"TextVQA refers to a task where a computer model is used to answer questions about text that appears within images. For example, given a photo of a street sign, the model would need to read the text on the sign and use it to answer a question such as ""What does the sign say?""",gpt4_abstract
2402.07398v2,rid0,visual feature extraction modules,"Visual feature extraction modules are parts of a computer system designed to identify and process specific visual elements from images or videos, such as shapes, colors, or textures. This helps the system understand and analyze the content of these visual inputs more effectively.",gpt4_abstract
2402.07398v2,rid0,visual feature extraction modules,Visual feature extraction modules are parts of a computer system designed to identify and capture specific visual details from images or videos. These details help the system understand and respond to the visual data more effectively.,gpt4_rag
2402.09565v2,rid0,background nodes,"Background nodes in the context of web graph mining refer to the majority of nodes within a large web graph that are not directly being analyzed but play a supporting role in understanding the relationships and properties of the few key nodes of interest, termed target nodes. These background nodes help enhance the connectivity and feature relevance among the target nodes, thereby aiding in their classification and analysis.",gpt4_abstract
2402.09565v2,rid0,background nodes,"Background nodes are elements in a network that, while not the primary focus of analysis, support key functions such as enhancing connections and sharing relevant data properties with the main elements (called ""target nodes"") being studied or analyzed.",gpt4_rag
2402.09565v2,rid0,massive background nodes compression,"Massive background nodes compression refers to the process of reducing and simplifying the number of less important or secondary nodes (background nodes) in a large network or graph, to focus on and enhance the analysis of the more crucial or significant nodes (target nodes). This method helps manage large datasets more efficiently by decreasing the amount of data that needs to be processed and stored, while maintaining the essential connections and characteristics needed for analysis.",gpt4_abstract
2402.09565v2,rid0,massive background nodes compression,"Massive background nodes compression refers to the process of reducing and simplifying a large number of less critical nodes in a network or graph, while retaining the essential nodes and their connections that are crucial for analyses and predictions. This helps in managing data more efficiently and improves performance in tasks such as node classification.",gpt4_rag
2402.09565v2,rid0,structural connectivity,"Structural connectivity refers to how different parts or points in a network, like a web graph, are connected or linked together. Essentially, it looks at how nodes (individual elements) in the network are arranged and interact with each other to form a structure.",gpt4_abstract
2402.09565v2,rid0,structural connectivity,"Structural connectivity refers to the way different parts or nodes in a network, such as in a brain or a social platform, are linked to each other. It focuses on the physical or logical connections that allow these parts to interact or communicate.",gpt4_rag
2402.09565v2,rid0,taget-background local structures,Target-background local structures refer to specific areas within a large web graph where key nodes (target nodes) and their surrounding nodes (backgroundonodes) are closely connected or related in some way. This term highlights the importance of both the key nodes and their immediate network in analyzing large datasets.,gpt4_abstract
2402.09565v2,rid0,taget-background local structures,Target-background local structures refer to the specific arrangements and connections between primary nodes of interest (target nodes) and the surrounding supportive nodes (background nodes) in a network or graph. These structures help in understanding how target nodes are influenced or supported by those around them.,gpt4_rag
2403.00431v1,rid0,contingency table analysis,"Contingency table analysis is a statistical method used to determine if there are relationships between two categorical variables by observing the frequency of each variable's occurrence. It involves organizing data into a table format, which allows for easy comparison and analysis to see how often certain outcomes coexist.",gpt4_abstract
2403.00431v1,rid0,contingency table analysis,Contagency table analysis involves using a specialized table to organize and display the frequency of occurrence between different categories of two variables to determine if there is a relationship between them. This helps researchers decide whether changes in one variable correspond to changes in the other.,gpt4_rag
2403.00431v1,rid0,robotic process automation (RPA),"Robotic process automation (RPA) is a technology that uses software robots to automate repetitive and routine tasks that are typically done by humans. This allows businesses to streamline operations, reduce errors, and save time.",gpt4_abstract
2403.00431v1,rid0,robotic process automation (RPA),"Robotic Process Automation (RPA) refers to the use of software tools that automate routine and repetitive tasks traditionally performed by humans, helping to streamline workflows and improve efficiency in various industries.",gpt4_rag
2403.00632v1,rid0,affective interface,An affective interface is a type of computer system designed to interact with users by detecting and responding to their emotions. This can help make technology more intuitive and engaging by aligning with human feelings and behaviors.,gpt4_rag
2403.00632v1,rid0,affective interface,"An affective interface is a type of technology designed to interact with users in a way that responds to and influences their emotions. This kind of interface aims to enhance user experiences by engaging emotionally, such as through customizing visual storytelling or feedback based on the user's feelings.",gpt4_abstract
2403.01783v1,rid0,diffractice analysis,"Diffractive analysis is a research method used to explore and understand how different ideas or elements interact and influence each other, often revealing new insights or perspectives. In the context of the study described, it was used to analyze how artists integrate and adapt AI technology into their creative processes.",gpt4_abstract
2403.01783v1,rid0,diffractice analysis,"Diffractive analysis is a research approach that focuses on examining how various differences intersect and influence each other, rather than just looking at individual elements in isolation. This method allows researchers to explore the complex interactions and effects within a study, providing a deeper understanding of the subject matter.",gpt4_rag
2403.02928v1,rid0,feedback-driven adaptation,Feedback-driven adaptation is a process where systems change and improve based on the input and reactions they receive from users. This approach allows the system to continually evolve and tailor its behavior to better meet the specific needs and preferences of its users.,gpt4_rag
2403.02928v1,rid0,feedback-driven adaptation,Feedback-driven adaptation refers to a process where a system adjusts its behavior based on input or complaints from users. This allows the system to better meet the users' needs and preferences by continually learning from the feedback provided.,gpt4_abstract
2403.03822v1,rid0,H-Flow,"The H-Flow in the context of the scientific abstract refers to a visualization technique used to display higher-order movement patterns on a map. It helps in visually representing complex movement sequences and transitions, making it easier to understand and analyze patterns in urban movements.",gpt4_abstract
2403.03822v1,rid0,H-Flow,"H-Flow is a visual tool designed to display complex relationships and patterns, such as sequences and repetitions, among different elements or data points in a graphical form using curves and colors to make it easier to understand the underlying structure.",gpt4_rag
2403.03822v1,rid0,"auto-adaptive movement aggregation
algorithm","An auto-adaptive movement aggregation algorithm is a computerized method that automatically organizes and groups data about movements, such as vehicles in a city, by considering factors like how close they are to each other, the surrounding environment, and when the movements happen. This method adjusts itself to handle different conditions without needing manual changes.",gpt4_abstract
2403.03822v1,rid0,"auto-adaptive movement aggregation
algorithm","An auto-adaptive movement aggregation algorithm is a type of software that automatically groups and organizes data about movements, such as people or vehicles, based on patterns and changes detected over time and location. This method adjusts itself to ensure it remains effective as the conditions or data characteristics change.",gpt4_rag
2403.03822v1,rid0,origin-destination analysis,"Origin-destination analysis is a method used to study the movement between a starting point (origin) and an ending point (destination) without examining the details of the path or the steps taken between these two points. It focuses on where movements begin and end, rather than how they occur.",gpt4_abstract
2403.03822v1,rid0,origin-destination analysis,"Origin-destination analysis is a technique used to study the travel patterns between where trips start and where they end, helping to understand how people move from one location to another. This can be used for planning transportation systems, analyzing traffic flow, and many other applications where knowing travel routes is important.",gpt4_rag
2403.03822v1,rid0,sequential multistep state transitions,"Sequential multistep state transitions refer to the process where each step or state follows another in a specific order, forming a chain of events or actions that develop over time. This concept is often used to understand patterns and relationships in complex systems, like tracking the route a person takes as they move through different locations.",gpt4_rag
2403.03822v1,rid0,sequential multistep state transitions,"Sequential multistep state transitions refer to processes where something progresses or changes through several different stages or conditions one after another. Each transition from one state to another follows a specific, ordered sequence.",gpt4_abstract
2403.04124v1,rid0,appropriate weight flatness,Appropriate weight flatness in the context of training large language models refers to adjusting the model's parameters such that the landscape of possible solutions (or predictions) becomes smoother. This smoother landscape can help enhance the model's performance and maintain privacy by making the model less sensitive to small changes in data or adjustments in its settings.,gpt4_rag
2403.04124v1,rid0,appropriate weight flatness,"Appropriate weight flatness refers to the specific level of uniformity in the numerical values that make up a model's parameters, which helps balance the need for the model to maintain privacy while still performing well on tasks such as understanding or generating text. In simpler terms, it ensures that the model's settings are optimized to protect user data without sacrificing its ability to produce accurate results.",gpt4_abstract
2403.04124v1,rid0,flatness-guided sparse prefix-tuning,"Flatness-guided sparse prefix-tuning is a method used in tuning large language models; it selectively applies small adjustments to only a few important parts of the model, guided by the goal of creating a smoother, more stable performance across different calculations. This approach helps enhance the model's consistency without needing extensive adjustment of all parts of the model.",gpt4_rag
2403.04124v1,rid0,flatness-guided sparse prefix-tuning,"Flatness-guided sparse prefix-tuning is a technique designed to adjust the flexibility of certain parts of a computer model's decision-making process. This is done by selectively simplifying (making ""sparse"") the adjustments needed for the model to perform tasks, guided by a focus on maintaining a smooth (or ""flat"") performance across different scenarios, which helps to deliver reliable outcomes while keeping data private.",gpt4_abstract
2403.04124v1,rid0,generalization degradation,"Generalization degradation occurs when a model, trained on specific data, performs poorly on new, unseen data. This means the model might do well in experiments or tests but fails to predict or behave correctly when faced with real-world situations that weren't covered in its training.",gpt4_rag
2403.04124v1,rid0,generalization degradation,"Generalization degradation refers to the decline in a model's ability to perform well on new, unseen data after being trained to minimize errors on its training data. This happens when optimizing for privacy, such as in large language models, compromises the model's broader applicability outside the specific examples it was trained on.",gpt4_abstract
2403.04124v1,rid0,"perturbation-aware
min-max optimization",Perturbation-aware min-max optimization is a strategy in model training where adjustments are carefully made to minimize the maximum possible negative impact that small changes or disturbances might have on the model’s performance. This method helps ensure the model remains robust and performs well even when subjected to slight variations in data or conditions.,gpt4_abstract
2403.04124v1,rid0,"perturbation-aware
min-max optimization",Perturbation-aware min-max optimization is a strategy used in computing and data analysis that involves making a system more robust against small disturbances or changes. This method tries to find the best worst-case scenario by considering potential small alterations that might impact the system's performance.,gpt4_rag
2403.04124v1,rid0,privacy budget,"A privacy budget, often represented by the symbol ϵ, is a number used in data privacy management to balance the amount of information shared and the protection of individual privacy. Smaller values of this budget mean stronger privacy, as less information is allowed to be revealed.",gpt4_rag
2403.04124v1,rid0,privacy budget,"A privacy budget in the context of differential privacy is a numerical limit set on the amount of information an individual's data can reveal during data analysis or processing. The lower the privacy budget, the higher the privacy protection, but potentially at the cost of the usefulness or accuracy of the output data.",gpt4_abstract
2403.04124v1,rid0,weight knowledge distillation,"Weight knowledge distillation is a technique where the knowledge from one model is used to guide the training of another model to help it learn better. This approach typically involves using the well-trained (non-private) model's weights to influence the training of another model that adheres to privacy or other constraints, aiming to achieve similar performance as the non-private model.",gpt4_rag
2403.04124v1,rid0,weight knowledge distillation,"Weight knowledge distillation is a technique where the information or knowledge from one set of model parameters (weights) is transferred to another, often making the receiving model more efficient or better performing without compromising privacy protections. This method is particularly useful in scenarios where one model has privacy safeguards like Differential Privacy, and aims to achieve a good balance between maintaining privacy and delivering high performance.",gpt4_abstract
2403.04732v2,rid0,Raven's Progressiive Matrices (RPMs),Raven's Progressive Matrices (RPMs) are a type of visual puzzle used primarily to assess a person's ability to recognize patterns and deduce rules from abstract shapes. Participants solve these puzzles by identifying the missing piece that completes a larger pattern made up of various geometric shapes.,gpt4_rag
2403.04732v2,rid0,Raven's Progressiive Matrices (RPMs),"Raven's Progressive Matrices (RPMs) are a series of visual puzzles that are used to measure a person's ability to think logically and solve problems using visual information. Each puzzle shows a matrix of geometric designs with one piece missing, and the challenge is to find the correct piece that completes the overall pattern from a set of options.",gpt4_abstract
2403.04732v2,rid0,multi-hop relational and deductive reasoning,Multi-hop relational and deductive reasoning refers to the process of making logical conclusions by connecting multiple pieces of information or steps in a sequence. This kind of reasoning requires understanding how different elements relate to each other and using this understanding to solve complex problems or puzzles.,gpt4_abstract
2403.04732v2,rid0,multi-hop relational and deductive reasoning,"Multi-hop relational and deductive reasoning refers to the process of drawing logical conclusions by connecting multiple sets of relationships or pieces of information, step-by-step, based on visual or other types of clues. This method involves analyzing several layers or stages of information to arrive at a reasoned decision or answer.",gpt4_rag
2403.04732v2,rid0,self-consistency,"Self-consistency is a method used in processing information where multiple answers are generated for a question, and then the most common answer among them is chosen as the final solution. This approach helps in making the decision-making more reliable.",gpt4_rag
2403.04732v2,rid0,self-consistency,"Self-consistency in this context refers to the idea of a model consistently arriving at the same conclusions or answers when given similar types of data or queries, ensuring its responses are reliable regardless of slight variations in input.",gpt4_abstract
2403.04760v1,rid0,score provenance,"Score provenance refers to the ability to track and understand the origin of the scores given by automated systems, such as large language models, to student summaries. This includes identifying what specific parts of the text or which factors influenced the final score assigned by the model.",gpt4_abstract
2403.04760v1,rid0,score provenance,"Score provenance refers to the history and origin of scores assigned to summaries, including details about when and how each score was generated during different runs of evaluations. This helps users understand the progression and changes in scoring over time.",gpt4_rag
2403.05112v1,rid0,initial stimulus values,"Initial stimulus values refer to the starting brightness levels of the lights used in the visual perimetry test, which are adjusted based on the patient's responses to accurately determine their range and sensitivity of vision.",gpt4_abstract
2403.05112v1,rid0,initial stimulus values,"Initial stimulus values refer to the starting levels of light intensity used in a visual field test to determine at what point a patient can first detect light. These values are adjusted based on the patient's responses to find the specific light intensity where the patient can consistently see the light, helping to measure their sensitivity to light.",gpt4_rag
2403.05112v1,rid0,"reward shaping
techniques","Reward shaping techniques in reinforcement learning involve giving additional feedback to an agent (a system designed to make decisions) to help it learn more effectively. This approach adjusts the standard rewards the agent receives for its actions, guiding it more directly toward achieving its goal.",gpt4_rag
2403.05112v1,rid0,"reward shaping
techniques","Reward shaping techniques in the context of optimizing visual perimetry testing involve adjusting the method by which success is measured during the test. This allows the system to provide more immediate and relevant feedback, helping to refine the procedure quickly and effectively to achieve better results in less time.",gpt4_abstract
2403.06034v1,rid0,restorative moderation strategies,Restorative moderation strategies on social media involve approaches that aim to repair harm and rebuild relationships instead of simply punishing the user who broke the rules. These strategies may include actions like encouraging discussions that lead to mutual understanding or facilitating apologies between users.,gpt4_abstract
2403.06034v1,rid0,restorative moderation strategies,"Restorative moderation strategies involve a more forgiving approach where offenders are given explanations of the rules and warned about the consequences of future violations, allowing them to understand their mistakes and encouraging them to behave appropriately in the community.",gpt4_rag
2403.06034v1,rid0,retributive,"Retributive refers to a concept where the focus is on punishment for wrongdoing, typically aiming to provide a penalty that corresponds to the severity of the offense. This approach emphasizes justice by ensuring that offenders face consequences directly related to their actions.",gpt4_abstract
2403.06034v1,rid0,retributive,"Retributive refers to a concept in justice where individuals who commit wrongful acts receive punishment proportional to their misdeeds, essentially focusing on delivering punishment that 'fits' the crime.",gpt4_rag
2403.06267v1,rid0,robot task trajectories,"Robot task trajectories refer to the paths that a robot arm or tool takes to complete a specific task, like moving an object from one place to another. These trajectories include the movements and actions taken by the robot to accomplish its assigned job.",gpt4_rag
2403.06267v1,rid0,robot task trajectories,Robot task trajectories refer to the specific paths or series of actions that a robot follows while completing a task. These trajectories capture how the robot moves and behaves as it progresses from the start to the end of a task.,gpt4_abstract
2403.06823v2,rid0,5W1H framework,"The 5W1H framework is a simple tool used for gathering comprehensive information about a particular topic or problem. It involves asking questions based on six key aspects: Who, What, When, Where, Why, and How, to ensure a thorough understanding or analysis.",gpt4_rag
2403.06823v2,rid0,5W1H framework,"The 5W1H framework is a methodical approach used to explore and understand problems or topics by asking six basic questions: Who, What, When, Where, Why, and How. This technique helps in breaking down and organizing information to make the analysis more comprehensive and effective.",gpt4_abstract
2403.07131v1,rid0,Capsule Attention policy mode,The Capsule Attention policy model is a type of artificial intelligence used to decide how robots and tasks are paired together efficiently. It improves upon traditional methods by learning from data to optimize these pairings automatically.,gpt4_rag
2403.07131v1,rid0,Capsule Attention policy mode,"The Capsule Attention policy model is a type of AI technology used to selectively focus on certain parts of data, enabling a robot or computer to effectively decide which tasks to prioritize when working with other robots. This model helps in learning the importance or weight of different robot-task pairings in a structured way, similar to how humans might weigh options before making a decision.",gpt4_abstract
2403.07131v1,rid0,Graph Reinforcement Learning (GRL) framework,"The Graph Reinforcement Learning (GRL) framework is a method used in computer science to help improve decision-making processes, particularly in systems involving complex interactions like those between multiple robots and tasks. In GRL, networks of nodes (representing things like robots or tasks) are used to learn the best actions to take in various scenarios to achieve a goal, such as efficiently allocating tasks to robots.",gpt4_rag
2403.07131v1,rid0,Graph Reinforcement Learning (GRL) framework,"The Graph Reinforcement Learning (GRL) framework is a method used in computer science where a system learns to make decisions by understanding and using the relationships between different elements represented in a graph structure. This learning approach combines graph theory, which studies how things are interconnected, with reinforcement learning, a type of machine learning where an agent learns to make decisions by trying to maximize some notion of cumulative reward.",gpt4_abstract
2403.07131v1,rid0,Multi-Robot Task Allocation (MRTA) problems,"Multi-Robot Task Allocation (MRTA) problems involve determining how to best distribute different tasks among a group of robots, ensuring that each task is completed efficiently and effectively. This includes deciding which robot should perform which task based on factors such as location, workload, and timing to optimize overall performance.",gpt4_rag
2403.07131v1,rid0,Multi-Robot Task Allocation (MRTA) problems,Multi-Robot Task Allocation (MRTA) problems involve determining the best way for a group of robots to divide and complete a set of tasks efficiently. These decisions need to be made quickly and smartly to ensure all tasks are handled effectively by the appropriate robots.,gpt4_abstract
2403.07131v1,rid0,bipartite graph matching approach,"A bipartite graph matching approach is a method used to pair two different types of items (such as tasks and robots) by connecting them in a graph where each connection, or ""edge,"" represents a potential assignment of one item to the other. The goal is to find the best way to pair these items based on specific rules or conditions to achieve the most effective outcome.",gpt4_abstract
2403.07131v1,rid0,bipartite graph matching approach,"A bipartite graph matching approach involves connecting two separate groups of items, such as robots and tasks, where lines (or edges) are drawn to pair items from one group to another. This method is used to find the best pairs based on certain criteria, ensuring each item from one group is ideally matched with an item from the other group.",gpt4_rag
2403.07131v1,rid0,expert-specified incentive,An expert-specified incentive refers to guidelines or rules set by human experts that determine how tasks should be assigned to robots in a way that optimizes the system's performance. These incentives are designed based on the expert's knowledge and experience with the aim of guiding the system to achieve its desired outcomes efficiently.,gpt4_abstract
2403.07131v1,rid0,expert-specified incentive,"An expert-specified incentive refers to guidance or criteria developed by someone with specialized knowledge, used to influence decisions or actions, such as a robot choosing which task to perform based on certain conditions and priorities.",gpt4_rag
2403.07131v1,rid0,learned incentive policy,A learned incentive policy refers to a system developed using a type of artificial intelligence that teaches itself the best strategies or rewards to use in order to effectively match tasks with robots. This approach allows the system to discover these strategies on its own rather than relying on rules provided by humans.,gpt4_abstract
2403.07131v1,rid0,learned incentive policy,"A learned incentive policy is a set of rules or guidelines created by a machine learning process, which helps robots or systems decide what tasks to perform next by evaluating various options based on past experiences or data analyses. This approach is intended to automate and optimize decision-making, making the system efficient in task allocation without needing explicit instructions for every situation.",gpt4_rag
2403.07131v1,rid0,positive bigraph weights,"Positive bigraph weights are numerical values assigned to the connections between tasks and robots in a graph, where a higher weight indicates a more favorable or preferred pairing for task allocation. These weights are utilized to effectively determine the best task assignment to each robot based on their individual capabilities and the nature of the tasks.",gpt4_abstract
2403.07131v1,rid0,positive bigraph weights,"Positive bigraph weights refer to the values assigned to the connections between two sets of elements, such as robots and tasks in a control system. These weights indicate the strength or importance of each connection, and a positive weight implies a beneficial or desired link between a robot and a task.",gpt4_rag
2403.07131v1,rid0,robots' state graph,"The robots' state wait represents a detailed display of various statuses or conditions of each robot at any given time, showing information like their locations, energy levels, and current tasks. This helps in managing and optimizing how robots are assigned and perform tasks in a multi-robot task system.",gpt4_abstract
2403.07131v1,rid0,robots' state graph,A robots' state graph is a visual representation that shows the different states or conditions of robots and how they can change from one state to another based on certain actions or events. This graph is typically used to understand and organize how robots are functioning and interacting within a system.,gpt4_rag
2403.07997v1,rid0,context-aware policies,"Context-aware policies (CAPs) are rules set up in technology systems, like smart home devices, that automatically perform actions based on specific situations or environments. For example, a CAP might turn on your house lights when it detects that it is evening or adjust the thermostat when you enter a room.",gpt4_rag
2403.07997v1,rid0,context-aware policies,"Context-aware policies (CAPs) are rules or guidelines used by smart devices that change their behavior based, depending on the specific situations or environments a user is in. For example, a CAP might automatically adjust the lighting and temperature in a room based on the time of day, the weather outside, and the presence of people in the room.",gpt4_abstract
2403.08940v1,rid0,Additive manufacturing (AM),"Additive manufacturing, often known as 3D printing, involves creating objects by adding material layer by layer according to a digital design. This process allows for the production of complex structures and geometries that would be difficult to achieve with traditional manufacturing methods.",gpt4_abstract
2403.08940v1,rid0,Additive manufacturing (AM),"Additive manufacturing, commonly known as 3D printing, is a process where materials are layered successively to create complex shapes and parts from a digital design, often allowing for more intricate and customized items than traditional manufacturing methods.",gpt4_rag
2403.08940v1,rid0,Nielsen's heuristics approach,"Nielsen's heuristics approach refers to a set of guidelines used to evaluate and improve the usability of interfaces in systems such as software or websites, ensuring they are easy and efficient for users to interact with.",gpt4_rag
2403.08940v1,rid0,Nielsen's heuristics approach,Nielsen's heuristics approach refers to a set of guidelines developed by usability expert Jakob Nielsen to evaluate the user-friendliness and functionality of user interfaces. These guidelines help designers identify problems and improve the ease of use and overall experience of a system.,gpt4_abstract
2403.09308v1,rid0,expressive robot behavior,"Expressive robot behavior refers to the ability of a robot to display actions or gestures, like nodding or shaking its head, that mimic human expressions and help in communicating its state or response to humans.",gpt4_rag
2403.09308v1,rid0,expressive robot behavior,"Expressive robot behavior refers to the ability of a robot to display actions or communications that can convey emotions, intentions, or responses, making interactions with humans more intuitive and engaging. This helps in making the robot seem more life-like and relatable to users.",gpt4_abstract
2403.09308v1,rid0,skill generation,"Skill generation in robotics refers to the process where robots learn or acquire new abilities, such as nodding or picking up objects. This can be done through programming or by using advanced technologies that enable robots to learn from examples or through interaction with their environment.",gpt4_rag
2403.09308v1,rid0,skill generation,"Skill generation in this context refers to the process by which a robot learns or acquires new abilities, such as picking up different objects, that enable it to perform tasks more effectively. This learning can occur through interactions within its environment or from user inputs.",gpt4_abstract
2403.10112v1,rid0,EAHT approaches,"EAHT approaches refer to methods used in active hypothesis testing which apply evolutionary algorithms to improve decision-making and detection processes in environments where security is a concern, such as in scenarios where sensitive communications may be intercepted by unauthorized parties. These approaches are designed to outperform traditional testing methods by evolving strategies that are better at predicting and identifying unusual or anomalous behavior.",gpt4_abstract
2403.10112v1,rid0,EAHT approaches,"EAHT approaches, short for Evasive Active Hypthesis Testing, involve techniques where a legitimate agent, or a group of agents, actively chooses actions to gather data and determine a hidden truth or pattern while trying to keep this information secret from an unauthorized observer or eavesdropper.",gpt4_rag
2403.10112v1,rid0,NeuroEvolution (NE),"NeuroEvolution (NE) is a technique used in artificial intelligence where algorithms, inspired by the process of natural evolution, are employed to automatically develop and improve neural networks. This allows computers to learn and adapt to various tasks over time without human intervention.",gpt4_abstract
2403.10112v1,rid0,NeuroEvolution (NE),"NeuroEvolution (NE) is a type of artificial intelligence technique that evolves and optimizes neural networks using algorithms inspired by nature, such as evolution. It works by simulating a process similar to natural selection, where the best-performing networks are chosen and combined to create even better ones over successive generations.",gpt4_rag
2403.10112v1,rid0,centralized problem,"A centralized problem refers to a situation or task that is managed or solved by a single entity or agent from a central location, allowing for uniform decision-making and control over the entire process.",gpt4_abstract
2403.10112v1,rid0,centralized problem,"A centralized problem refers to a scenario where there is a single decision-making agent or entity that has access to data and information. This agent is responsible for making decisions and performing actions based on the information it gathers, all without the cooperation or involvement of other agents.",gpt4_rag
2403.10112v1,rid0,collaborative multi-agent tasks,"Collaborative multi-agent tasks involve a group of agents, which could be software programs or robots, working together to complete tasks that are too complex for a single agent to handle alone. Each agent contributes by sharing information and coordinating actions with the others to achieve a common goal.",gpt4_rag
2403.10112v1,rid0,collaborative multi-agent tasks,"Collaborative multi-agent tasks involve multiple agents, which can be computers or robots, working together to complete a shared objective or solve a problem. Each agent contributes to the task by sharing information or performing actions that help the group achieve their goal more effectively than if each were working alone.",gpt4_abstract
2403.10112v1,rid0,decentralized problem,"A decentralized problem refers to a scenario where multiple independent agents or entities work together to solve a task, without relying on one central authority or controller to manage their actions or decisions. Each agent operates autonomously and collaboratively contributes to the overall goal or solution.",gpt4_abstract
2403.10112v1,rid0,decentralized problem,"A decentralized problem refers to a situation where multiple independent agents or groups work separately on different aspects of a task or problem, without having one single central point of control or decision-making. Each agent has access to its own unique information and makes decisions based on that data, often communicating and cooperating with other agents to achieve a common goal.",gpt4_rag
2403.10112v1,rid0,legitimate agent,A legitimate agent refers to an authorized or genuine decision-maker or system in a process or setup that is involved in collecting and analyzing information in order to accurately determine or predict a particular outcome or condition.,gpt4_rag
2403.10112v1,rid0,legitimate agent,"A legitimate agent refers to an authorized participant or entity in a system that carries out specific tasks or actions according to established rules or guidelines, especially in scenarios where secure or sensitive information is involved.",gpt4_abstract
2403.10851v1,rid0,gustosonic eating system,"A gustosonic eating system is a type of technology that enhances the experience of eating by using sensors, like those in wireless earbuds, to detect when someone is eating or drinking. It then uses this information to play enjoyable sounds that are designed to make the experience of eating more fun and engaging.",gpt4_abstract
2403.10851v1,rid0,gustosonic eating system,"A gustosonic eating system is a device that uses technology, like earbuds, to detect when you are eating or drinking and then plays sounds that can enhance the experience of consuming food or beverages. For example, it might play a crunching sound when you eat crisps or a fizzing sound when you drink carbonated water.",gpt4_rag
2403.10851v1,rid0,hedonism,"Hedonism is the idea that pleasure is the most important goal in life, and people should seek to maximize their enjoyment and indulgence in activities.",gpt4_rag
2403.10851v1,rid0,hedonism,"Hedonism is the idea that pleasure and happiness are the most important goals in life. In the context of eating, hedonism refers to the pursuit of pleasure derived from the taste, textures, and overall enjoyment of food.",gpt4_abstract
2403.10851v1,rid0,reflexivity,"Reflexivity, in the context of the abstract, refers to the ability of individuals to critically reflect on their own experiences, behavior, and preferences during their interactions with food, particularly as influenced by the use of technology like the GustosonicSense system. This process fosters a deeper personal engagement and awareness of their eating experience.",gpt4_abstract
2403.10851v1,rid0,reflexivity,"Reflexivity in this context refers to the ability of the participants to use the system on their own terms, adapting it to their individual needs and circumstances outside of a controlled research environment. This allows them to explore and find creative ways to make the system work best for them.",gpt4_rag
2403.10851v1,rid0,stimulation,"Stimulation refers to the process of encouraging or arousing interest or excitement in someone, usually through specific actions or interventions designed to activate sensory experiences or emotional responses.",gpt4_rag
2403.10851v1,rid0,stimulation,"Stimulation, in the context described, refers to the activation or encouragement of sensory or mental excitement, which in this case, is achieved through the use of sounds while eating to enhance the overall dining experience.",gpt4_abstract
2403.14686v1,rid0,Bayesian network analysis,"Bayesian network analysis is a statistical method that uses diagrams to represent and analyze the relationships between different sets of data, showing how the knowledge of one piece of information can influence our understanding of another. This approach helps in predicting outcomes by estimating the probabilities based on the connections within the data.",gpt4_rag
2403.14686v1,rid0,Bayesian network analysis,Bayesian network analysis is a statistical method that uses a network of interconnected elements (like steps in a process or variables in a study) to predict the relationships between them and understand how changes in one element might influence others. This approach is particularly useful in identifying and visualizing complex interactions and dependencies.,gpt4_abstract
2403.14686v1,rid0,blended learning environments,"Blended learning environments refer to educational settings where traditional face-to-face instruction is combined with online learning activities, allowing students to experience both classroom interactions and digital content access. This approach integrates direct teacher support with technology-based tools to enhance learning flexibility and accessibility.",gpt4_abstract
2403.14686v1,rid0,blended learning environments,"Blended learning environments combine traditional classroom teaching with online educational methods. This approach allows students to learn through both face-to-face interactions and digital tools, creating a versatile learning experience.",gpt4_rag
2403.15875v1,rid0,PLMs,"Pre-trained language models (PLMs) are advanced computer programs designed to understand and generate human-like text based on training from vast amounts of existing text data. These models can help automate and enhance various tasks involving natural language, such as translating languages, answering questions, and summarizing texts.",gpt4_rag
2403.15875v1,rid0,PLMs,"PLMs, or pre-trained language models, are advanced computer programs that have already been trained on a large amount of text data. This training helps them understand and process new text in various tasks without needing to learn from scratch each time.",gpt4_abstract
2403.15875v1,rid0,UCR archive,"The UCR archive is a collection of datasets that are commonly used for benchmarking algorithms in time series classification, offering a wide range of real-life data for experimental purposes.",gpt4_abstract
2403.15875v1,rid0,UCR archive,"The UCR archive is a collection of datasets specifically designed for benchmarking and testing time series analysis methods. Time series analysis involves techniques for analyzing sequences of data points, which are typically measured at successive times and are used to track the behavior of certain phenomena over time.",gpt4_rag
2403.15875v1,rid0,feature representation capacity,"Feature representation capacity refers to a system's ability to capture and summarize the important information from data in a way that helps in performing specific tasks like recognizing patterns or making predictions. Essentially, it is how well a system can transform raw data into a useful format that highlights its key characteristics.",gpt4_rag
2403.15875v1,rid0,feature representation capacity,"The term ""feature representation capacity"" refers to the ability of a model to capture and utilize the important elements or characteristics of the data it is provided, which ultimately influences how well the model can perform its tasks, such as classifying data or making predictions.",gpt4_abstract
2403.15875v1,rid0,maximum input token threshold,"The maximum input token threshold refers to the limit on the number of units (or tokens) of information, like words or characters, that a computer program can handle at one time when processing data. This limit affects how much data can be analyzed or processed in one go by the program.",gpt4_rag
2403.15875v1,rid0,maximum input token threshold,The maximum input token site threshold refers to the upper limit on the number of individual pieces of information (tokens) that a language model can process at one time. This limitation affects how much data the model can consider when making its predictions or analyses.,gpt4_abstract
2403.15875v1,rid0,zero-shot time series (TS) classification,"Zero-shot time series classification refers to the ability of a system to correctly categorize time-based data it has never seen before during its training. This is achieved by using knowledge the system has learned from different but related tasks, allowing it to make predictions without prior direct experience with the specific type of data it is classifying.",gpt4_rag
2403.15875v1,rid0,zero-shot time series (TS) classification,"Zero-shot time series classification is a method where a model can identify and categorize sequences of data it has never seen before, based on learning from different but related tasks. This allows the model to apply its knowledge to new situations without needing additional training on those specific tasks.",gpt4_abstract
2403.16190v1,rid0,Anchors,"In the given context, ""Anchors"" refers to a type of algorithm used to generate explanations about decisions made by a machine learning model. These explanations help to clarify why certain decisions or predictions were made by the model.",gpt4_abstract
2403.16190v1,rid0,Anchors,"Anchors is a method used in the field of artificial intelligence, specifically in explainable AI, to determine which features of an input data example are key to the predictions made by a model. It helps in understanding why a specific decision or classification was made by the model.",gpt4_rag
2403.16190v1,rid0,correctness,"Correctness, in this context, refers to the degree to which the explanations provided by the method perfectly match or align with the actual reasons for the decisions made by the machine learning model, ensuring they are accurate and true to the cause.",gpt4_abstract
2403.16190v1,rid0,correctness,"Correctness in this context refers to whether an explanation accurately represents why a machine learning model made a specific prediction, ensuring that the explanation is both true and reliable.",gpt4_rag
2403.16190v1,rid0,minimality,"In the given context, ""minimality"" refers to the property of an explanation being as simple or concise as possible, containing only the essential information needed to understand why a decision was made, without any unnecessary details.",gpt4_abstract
2403.16190v1,rid0,minimality,"Minimality refers to the concept of using the smallest or simplest explanation necessary to understand something effectively. In the context of explaining decisions made by machine learning models, a minimal explanation includes only the most relevant features needed to justify a prediction, without any superfluous information. This makes the explanation easier to understand.",gpt4_rag
2403.16289v1,rid0,decomposing requirements,"Decomposing requirements involves breaking down complex safety requirements into simpler, more manageable components or tasks. This makes it easier to understand and address each part of a larger requirement individually, ensuring thorough and precise development and assessment.",gpt4_abstract
2403.16289v1,rid0,decomposing requirements,"Decomposing requirements involves breaking down complex specifications into simpler, more manageable parts. This makes it easier to understand, analyze, and verify each part of the specification step by step.",gpt4_rag
2403.16289v1,rid0,requirement artifacts,"Requirement artifacts are documents or pieces of information used during the development of a product to describe what the product should do, such as specifications, standards, or user stories. These artifacts help ensure that the final product meets all the necessary requirements and functions as intended.",gpt4_abstract
2403.16289v1,rid0,requirement artifacts,"Requirement artifacts are documents or files created during the process of designing and developing a software or system. They outline what the system needs to do, such as features and functions, to ensure it meets the desired standards and user needs.",gpt4_rag
2403.16289v1,rid0,requirement dataset,"A requirement dataset is a collection of rules and conditions that a specific project, like developing software, must follow to ensure it meets all necessary standards and functions correctly.",gpt4_rag
2403.16289v1,rid0,requirement dataset,"A requirement dataset in this context refers to a collection of specific needs and conditions that a software or system, such as a car's safety operations system, must meet or adhere to, often compiled into a structured format for easy analysis and review.",gpt4_abstract
2403.16508v1,rid0,Description Logic Features,Description Logic Features refer to specific attributes or characteristics extracted from a problem based on logical rules and structure. These features help in understanding and solving the problem by breaking it down into logical components.,gpt4_abstract
2403.16508v1,rid0,Description Logic Features,"Description Logic Features are a set of tools used in computer science to help differentiate between various planning tasks by examining the roles and relationships within the data. Essentially, they analyze how different elements are connected or related to each other in order to make distinctions or recognize patterns.",gpt4_rag
2403.16508v1,rid0,FF heuristic,"The FF heuristic is a method used in planning systems to estimate the shortest path or least number of steps required to achieve a goal from a current position. It simplifies complex decision-making by predicting the easiest way to reach the end goal, helping the system make efficient choices.",gpt4_rag
2403.16508v1,rid0,FF heuristic,The FF heuristic is a technique used in planning systems (like those found in artificial intelligence) to quickly estimate the most efficient way to achieve a goal. It helps the system decide which actions to take to reach the desired outcome by predicting how close each action gets to the goal.,gpt4_abstract
2403.16508v1,rid0,WL algorithm,"The WL algorithm, short for Weisfeiler-Lehman algorithm, is a method used to generate features from graphs. It helps in identifying unique structures within graphs by analyzing their shapes and connections, which can be useful for comparing different graphs and understanding their properties.",gpt4_abstract
2403.16508v1,rid0,WL algorithm,"The WL algorithm is a method used in graph theory, primarily to determine if two graphs are identical in structure. It works by labeling each node (or point) in the graph and iteratively updating these labels based on the structure of its neighboring nodes until the labels can help in distinguishing the graphs or confirming their similarity.",gpt4_rag
2403.16508v1,rid0,classical planners,"Classical planners are tools used in artificial intelligence that help figure out a sequence of actions to achieve a specific goal, starting from a defined beginning state. These planners work within set rules and predefined steps, much like solving a puzzle by following a clear and specific set of instructions to reach the end solution.",gpt4_rag
2403.16508v1,rid0,classical planners,"Classical planners are tools used in artificial intelligence that help design sequences of actions to achieve a specific goal starting from a defined situation, operating within a predetermined set of rules and conditions. These planners map out step-by-step solutions that transition from the beginning state to the desired end state efficiently.",gpt4_abstract
2403.16508v1,rid0,learning for planning model,"A learning for planning model is a type of computer program designed to improve how it makes decisions and plans actions by learning from data. Its goal is to find the most efficient or effective way to achieve a set of tasks, often improving over time as it gains more experience.",gpt4_rag
2403.16508v1,rid0,learning for planning model,"A learning for planning model is a type of artificial intelligence that is specifically designed to learn how to make plans or decisions. This kind of model uses data to train itself to efficiently solve planning tasks, improving its ability to come up with effective strategies over time.",gpt4_abstract
2403.16508v1,rid0,lifted planning tasks,"Lifted planning tasks refer to planning activities where the specifics of individuals or objects are abstracted away. Instead, these tasks focus on the general types of objects and the actions that can be applied to them, allowing for planning that is more efficient and scalable by applying the same logic to multiple instances of a type.",gpt4_abstract
2403.16508v1,rid0,lifted planning tasks,"Lifted planning tasks involve planning using abstract descriptions where specific details like the exact objects involved are not defined. Instead, they use general categories and rules that can be applied to any relevant objects or situations, making the planning process more flexible and widely applicable.",gpt4_rag
2403.16750v1,rid0,CWE-prone hardware designs,"CWE-prone hardware designs refer to hardware components or systems that are likely to have vulnerabilities or weaknesses, categorized as Common Weakness Enumerations (CWEs), which could potentially be exploited to cause failures or security breaches. These designs have not adequately addressed these known types of flaws, making them susceptible to issues that can compromise their intended operation.",gpt4_abstract
2403.16750v1,rid0,CWE-prone hardware designs,"CWE-prone hardware designs refer to hardware systems that are susceptible to specific types of security weaknesses, making them more likely to be exploited or malfunction due to these vulnerabilities. These weaknesses are cataloged as Common Weakness Enumerations (CWEs).",gpt4_rag
2403.16750v1,rid0,Regenrative Artificial Intelligence,"Regenerative Artificial Intelligence refers to a type of AI that has the capability to generate new information or data, such as hardware designs in this case, by itself. This is typically powered by large language models that can learn from vast amounts of existing data and create outputs that are novel and not simply reproductions of what they have been trained on.",gpt4_abstract
2403.16750v1,rid0,Regenrative Artificial Intelligence,"Regenerative Artificial Intelligence refers to AI systems that have the ability to continuously generate new content or solutions, often improving or diversifying their outputs over time. This kind of AI learns from existing data and adapts to create a variety of results based on the learned information.",gpt4_rag
2403.16750v1,rid0,Register Transfer Level (RTL) code,"Register Transfer Level (RTL) code is a type of computer programming used in the design of electronic systems where the code specifies how data moves between different parts of a device and what transformations occur during that movement. This code level is used to detail how hardware like microprocessors execute commands and handle information, providing a bridge between conceptual design and actual hardware creation.",gpt4_abstract
2403.16750v1,rid0,Register Transfer Level (RTL) code,"Register Transfer Level (RTL) code is a type of design code used in creating electronic systems, where the code specifies how data moves between different parts of these systems at every clock cycle. It's like writing the step-by-step blueprints for each part of an electronic device to communicate and function correctly.",gpt4_rag
2403.16750v1,rid0,SystemVerilog,"SystemVerilog is a programming language used to model, design, and verify electronic systems, particularly focusing on the behavior of complex circuits and systems at the hardware level. It provides specific constructs and methodologies for efficiently creating and testing hardware designs before they are physically manufactured.",gpt4_abstract
2403.16750v1,rid0,SystemVerilog,"SystemVerilog is a programming language used to model, design, and verify electronic systems. It allows engineers to create and test the design of chips before they are actually manufactured.",gpt4_rag
2403.16750v1,rid0,common weakeness enumerations,"Common Weakness Enumerations (CWEs) refer to a list of known security vulnerabilities or weaknesses that are frequently found in software and hardware designs. They serve as a standardized classification for these issues, helping developers recognize and address potential threats in their designs.",gpt4_abstract
2403.16750v1,rid0,common weakeness enumerations,Common Weakness Enumerations (CWEs) are a categorized list of common security flaws that can occur in software and hardware designs. These listings help developers recognize potential vulnerabilities in their systems so they can prevent security risks.,gpt4_rag
2403.16750v1,rid0,formal verification,Formal verification is a process used to check whether a hardware design meets specific requirements by using mathematical and logical methods. It ensures that the design functions correctly and safely by rigorously proving its correctness under all possible conditions.,gpt4_abstract
2403.16750v1,rid0,formal verification,"Formal verification is a method used to check that a system's design meets specific requirements by using mathematical analysis. This process involves proving mathematically that a design behaves as intended in all possible scenarios, ensuring its correctness and reliability.",gpt4_rag
2403.17358v1,rid0,Lagrangian-guided Monte Carlo tree search,"""Lagrangian-guided Monte Carlo tree search"" is a computational technique used to make decisions by exploring various possible actions and outcomes, much like mapping possible moves in a complex game. It uses mathematical rules (Lagrangian) to manage constraints or restrictions while searching through these possibilities to find the best sequence of actions.",gpt4_abstract
2403.17358v1,rid0,Lagrangian-guided Monte Carlo tree search,"Lagrangian-guided Monte Carlo tree search is a computational strategy used to make optimal decisions by exploring different possible actions in a simulated environment. The method uses mathematical guidelines, called Lagrangian functions, to balance the goals of achieving high rewards while adhering to specific rules or constraints during the search process.",gpt4_rag
2403.17358v1,rid0,global dual ascent,Global dual ascent is a mathematical technique used in decision-making processes where a single set of guidelines or rules is optimized and applied across all parts of a problem to minimize the overall cost or maximize the benefit. This approach is often used in complex systems to guide decisions towards the most beneficial outcomes.,gpt4_rag
2403.17358v1,rid0,global dual ascent,"Global dual ascent is a method used in optimization where the overall problem is improved step by step by adjusting certain parameters, and these adjustments are applied uniformly across the entire problem, rather than focusing on individual parts. This technique helps in finding the best overall solution by incrementally optimizing these parameters globally.",gpt4_abstract
2403.17358v1,rid0,"large constrained partially observable Markov decision
processes (CPOMDPs)",Large constrained partially observable Markov decision processes (CPOMDPs) are mathematical frameworks used to make decisions in complex situations where all relevant factors aren't fully known and there are rules limiting the decisions that can be made. These are particularly useful in scenarios where the decision-maker needs to balance achieving certain goals while adhering to specific constraints.,gpt4_rag
2403.17358v1,rid0,"large constrained partially observable Markov decision
processes (CPOMDPs)",Large constrained partially observable Markov decision processes (CPOMDPs) are complex mathematical models used to make decisions where only limited information is available about the current state of the system and there are specific rules or restrictions that must be followed. These models help in figuring out the best sequence of actions in scenarios where all factors influencing the outcomes are not clearly visible or known.,gpt4_abstract
2403.17358v1,rid0,myopic action selection,Myopic action selection refers to making decisions based solely on immediate benefits without considering long-term consequences. This approach can lead to choices that seem good in the short term but are suboptimal for long-term success.,gpt4_abstract
2403.17358v1,rid0,myopic action selection,Myopic action selection refers to decision-making that focuses on immediate benefits without considering the long-term consequences of those decisions. This often leads to suboptimal outcomes because it fails to account for future impacts and possibilities.,gpt4_rag
2403.17358v1,rid0,recursive dual ascent,"Recursive dual ascent is an optimization method where certain variables, which are adjusted to reduce violations of rules or constraints, are updated in a step-by-step process that goes back and forth through different levels or stages of a problem to progressively improve the solution.",gpt4_rag
2403.17358v1,rid0,recursive dual ascent,"Recursive dual ascent is a method used to improve decision-making in complex algorithms by iteratively refining certain parameters or decisions, and then using those refinements to influence subsequent choices, leading to better and more informed outcomes over time. This technique adjusts and optimizes decisions based on previous results, similar to learning from past experiences to make better choices in the future.",gpt4_abstract
2403.17873v1,rid0,Social Transparency (ST) framework,"The Social Transparency (ST) framework is a concept in artificial intelligence that aims to make the organizational and decision-making contexts of AI systems clear and understandable to users. This helps people know how and why decisions are made by AI, promoting trust and responsible use.",gpt4_rag
2403.17873v1,rid0,Social Transparency (ST) framework,"The Social Transparency (ST) framework is designed to help users understand the social and organizational context behind artificial intelligence systems, making it clear how these systems are intended to interact within human environments and their societal impact.",gpt4_abstract
2403.17873v1,rid0,W-question,"A ""W-question"" refers to a question that starts with a word beginning with the letter 'W,' such as who, what, where, when, and why. These questions are used to gather detailed information and are important for clarifying and understanding complex situations or concepts.",gpt4_abstract
2403.17873v1,rid0,W-question,"A ""W-question"" is a type of question that seeks specific information and typically starts with words like who, what, where, when, why, and which. These questions help clarify and provide details about a particular situation or subject.",gpt4_rag
